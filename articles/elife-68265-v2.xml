<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">68265</article-id><article-id pub-id-type="doi">10.7554/eLife.68265</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Spectral signature and behavioral consequence of spontaneous shifts of pupil-linked arousal in human</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-19653"><name><surname>Podvalny</surname><given-names>Ella</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6810-2770</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-213919"><name><surname>King</surname><given-names>Leana E</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-71932"><name><surname>He</surname><given-names>Biyu J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1549-1351</contrib-id><email>biyu.jade.he@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Neuroscience Institute, New York University School of Medicine</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Departments of Neurology, Neuroscience &amp; Physiology, and Radiology, New York University School of Medicine</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role>Reviewing Editor</role><aff><institution>University of Lübeck</institution><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>31</day><month>08</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e68265</elocation-id><history><date date-type="received" iso-8601-date="2021-03-10"><day>10</day><month>03</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-08-27"><day>27</day><month>08</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Podvalny et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Podvalny et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-68265-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-68265-figures-v2.pdf"/><abstract><p>Arousal levels perpetually rise and fall spontaneously. How markers of arousal—pupil size and frequency content of brain activity—relate to each other and influence behavior in humans is poorly understood. We simultaneously monitored magnetoencephalography and pupil in healthy volunteers at rest and during a visual perceptual decision-making task. Spontaneously varying pupil size correlates with power of brain activity in most frequency bands across large-scale resting state cortical networks. Pupil size recorded at prestimulus baseline correlates with subsequent shifts in detection bias (<italic>c</italic>) and sensitivity (<italic>d</italic>’). When dissociated from pupil-linked state, prestimulus spectral power of resting state networks still predicts perceptual behavior. Fast spontaneous pupil constriction and dilation correlate with large-scale brain activity as well but not perceptual behavior. Our results illuminate the relation between central and peripheral arousal markers and their respective roles in human perceptual decision-making.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>spontaneous activity</kwd><kwd>electrophysiological arousal</kwd><kwd>pupil-linked arousal</kwd><kwd>perceptual decision-making</kwd><kwd>signal detection theory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>BCS- 1753218</award-id><principal-award-recipient><name><surname>He</surname><given-names>Biyu J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Fluctuations of spectral power in large-scale cortical networks shape behavior in a perceptual decision-making task through arousal-linked and arousal-independent mechanisms.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Arousal level constantly fluctuates during wakefulness. These spontaneous fluctuations are controlled by brain states that constrain sensory information processing and shape behavioral responses (<xref ref-type="bibr" rid="bib50">McCormick et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Joshi and Gold, 2020</xref>). To infer the level of arousal, investigators typically use one of two physiological markers: pupil size and spectral content of cortical activity. Larger pupil or more desynchronized (i.e., higher-frequency) brain activity generally correspond to higher arousal. While the two arousal markers correlate with each other in animals (<xref ref-type="bibr" rid="bib72">Stitt et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">McGinley et al., 2015b</xref>; <xref ref-type="bibr" rid="bib38">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib89">Yüzgeç et al., 2018</xref>; <xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>; <xref ref-type="bibr" rid="bib59">Reimer et al., 2014</xref>), they historically have motivated two separate lines of research in humans (outlined below). In addition, it remains unknown to what extent spectral content of cortical activity serves functional roles distinct from those related to pupil-linked arousal. A lack of understanding on how the two physiological markers of arousal relate to each other in humans prevents the synthesis of previous findings and leaves new findings in humans difficult to interpret in the context of the quickly advancing research of arousal in animal models.</p><p>The quest to characterize the behavioral states associated with changes in pupil size in humans began more than a century ago. The Yerkes–Dodson law (1908) (<xref ref-type="bibr" rid="bib88">Yerkes and Dodson, 1908</xref>) describes behavioral performance in difficult tasks as an inverted-U function of arousal, where intermediate levels of arousal (inferred from pupil size) are most beneficial to task performance. This law has been criticized, however, for not taking into account that performance efficiency cannot be captured by a single behavioral variable in most tasks (<xref ref-type="bibr" rid="bib20">Eysenck, 1982</xref>) and later studies have focused on more extensive research of pupil-linked behavior (e.g., <xref ref-type="bibr" rid="bib40">Kahneman and Beatty, 1966</xref>). These studies, however, did not make the distinction between ongoing pupil-linked state (e.g., prestimulus baseline) and event-related pupillary response (<xref ref-type="bibr" rid="bib24">Goldwater, 1972</xref>) that are likely governed by distinct neuromodulatory circuits and/or modes of brain activity (<xref ref-type="bibr" rid="bib50">McCormick et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Joshi and Gold, 2020</xref>; <xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>). A few recent studies show that baseline pupil size predicts perceptual decisions in humans (<xref ref-type="bibr" rid="bib83">Waschke et al., 2019</xref>; <xref ref-type="bibr" rid="bib78">van Kempen et al., 2019</xref>) and animals (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>; <xref ref-type="bibr" rid="bib71">Steinmetz et al., 2019</xref>), but the timescale of the arousal fluctuations shaping behavior and their underlying cortical mechanisms remain poorly understood.</p><p>A parallel line of research concerns the spectral content of electrophysiological activity and its relationship to behavior. At a very slow timescale, such as during a transition between states of waking and sleep, variations in the broadband power spectrum of cortical EEG activity are well documented in humans and animals (e.g., <xref ref-type="bibr" rid="bib10">Buzsáki, 2006</xref>; <xref ref-type="bibr" rid="bib29">He et al., 2010</xref>). More recent research reveals that changes in cortical spectral power within the waking state (e.g., measured as prestimulus baseline spectral power) also predict (trial-to-trial) variations in behavior. At this timescale, while some animal studies show that broadband changes in cortical spectral power correlate with moment-to-moment arousal fluctuation and influence behavioral performance (<xref ref-type="bibr" rid="bib52">McGinley et al., 2015b</xref>; <xref ref-type="bibr" rid="bib67">Sederberg et al., 2019</xref>), human studies mostly focus on band-limited power with no control for spontaneous arousal shifts (<xref ref-type="bibr" rid="bib46">Linkenkaer-Hansen et al., 2004</xref>; <xref ref-type="bibr" rid="bib85">Wyart and Tallon-Baudry, 2009</xref>; <xref ref-type="bibr" rid="bib1">Arnal et al., 2015</xref>). For example, prestimulus power in the alpha band (<xref ref-type="bibr" rid="bib64">Samaha et al., 2020</xref>) inversely relates to stimulus detection (<xref ref-type="bibr" rid="bib19">Ergenoglu et al., 2004</xref>; <xref ref-type="bibr" rid="bib77">van Dijk et al., 2008</xref>; <xref ref-type="bibr" rid="bib45">Limbach and Corballis, 2016</xref>; <xref ref-type="bibr" rid="bib8">Busch et al., 2009</xref>) and attentional allocation (<xref ref-type="bibr" rid="bib35">Jensen et al., 2012</xref>). Whether the effect of prestimulus power in alpha and other frequency bands on behavioral performance can be partially explained by spontaneous fluctuations of arousal remains unknown (<xref ref-type="bibr" rid="bib78">van Kempen et al., 2019</xref>; <xref ref-type="bibr" rid="bib32">Hong et al., 2014</xref>).</p><p>Importantly, previous studies in this domain have not investigated how pupil-linked arousal covaries with large-scale cortical spectral power across a wide range of frequencies. Without understanding the respective contributions of general arousal states and arousal-independent changes in cortical activity, a comprehensive view of the neural mechanisms governing state-dependent behavior remains elusive. Supporting this distinction, a recent study (<xref ref-type="bibr" rid="bib83">Waschke et al., 2019</xref>) showed that pupil-linked arousal and desynchronization in auditory cortex have distinct contributions to perceptual behavior, but this study only investigated the auditory cortex.</p><p>The overarching goal of our study is to shed light on how ongoing fluctuations in brain state shape human visual perceptual decision-making, using a task that probes both detection and discrimination, and metrics that capture perceptual sensitivity, criterion, and reaction time. Using simultaneous recordings of brain activity (magnetoencephalography [MEG]) and pupil size in resting state and in task, we uncover a strong association between pupil size and large-scale cortical power across a wide range of frequencies. MEG provides superior signal-to-noise ratio and source modeling allowed us to investigate the unique behavioral contributions of spectral power modulation in different large-scale brain networks. We show that pupil size fluctuations reflect antagonistic shifts in spectral power between low-frequency and high-frequency bands, while the intermediate alpha band relates to pupil size according to an inverted-U function. Both pupil-linked and pupil-independent brain states influence perceptual decision-making, albeit in different manners. These findings indicate that the prestimulus brain state influencing perceptual decisions contains a strong component linked to global electrophysiological arousal fluctuations in conjunction with the unique contributions of specific frequency bands localized to specialized brain networks.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We simultaneously monitored pupil size and brain activity (using MEG) in 24 participants during eyes-open rest and a visual perceptual decision-making task (<xref ref-type="fig" rid="fig1">Figure 1A–B</xref>). During eyes-open rest, participants were instructed to fixate on a central fixation cross and avoid any focused mental activity. We acquired two 5 min rest sessions in 21 participants and one rest session in the three remaining participants (see Materials and methods and <xref ref-type="fig" rid="fig1">Figure 1B</xref>). The task included long prestimulus intervals (3–6 s) wherein a fixation cross on a gray background was identical to the one used in eyes-open rest sessions (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). This design allowed us to investigate the spontaneous variation in pupil size and brain activity under identical and minimal visual stimulation during the eyes-open rest and the prestimulus task baseline.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Magnetoencephalography (MEG) and pupil size monitoring in rest and task.</title><p>(<bold>A</bold>) The experiment included simultaneous MEG recordings and eye-tracking while participants (<italic>N</italic> = 24) fixated at all times the fixation cross is present. (<bold>B</bold>) Acquisition timeline: two 5 min rest sessions (beginning and end), a staircase procedure determining the threshold contrast and a main task involving liminal stimuli presented at a staircase-determined contrast. (<bold>C</bold>) Each trial of the task included a prestimulus interval, followed by a liminal object stimulus (i.e., leading to ~50% ‘yes’ reports) and two forced-choice decisions: first, ‘category’ (face, house, object, or animal) of the stimulus and, second, ‘recognition’ (yes or no) to indicate whether a meaningful stimulus was perceived or not. A meaningful stimulus was present on most trials (n = 300) whereas a scrambled image was presented on the remaining trials (n = 60, more details in <xref ref-type="fig" rid="fig4">Figure 4</xref>). (<bold>D</bold>) An example 1-min pupil size recording during rest. Light gray trace depicts raw data and dark gray trace depicts the same time course with blink periods excluded and 5 Hz low-pass filter applied. The blue-frame inset shows magnified 10 s recording with pupillary constriction/dilation ‘events’ (red/cyan) and examples of slower ‘states’ spanning 2 s non-overlapping time windows. (<bold>E</bold>) To study variation in slow states, we defined consecutive non-overlapping 2 s epochs in rest and 2 s baseline periods before each stimulus presentation in task. (<bold>F</bold>) Power spectrum of a 5 min pupil size recording in rest reveals aperiodic pupil fluctuations since no oscillatory peaks are evident. Transparent light gray curves denote individual subjects and solid black curve denotes across-subject average spectrum. (<bold>G</bold>) Example distribution of ‘slow state’ pupil size (i.e., averaged in 2 s windows) recorded during rest for one subject. The black lines depict percentiles (20, 40, 60, 80) according to which the 2 s windows were split in groups in Figures 2 and 4. Source data is available as a supplementary file.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig1">Figure 1F</xref>, including power spectrum of pupil size fluctuations from individual subjects.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig1-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig1-v2.tif"/></fig><p>Pupil size was monitored at all times during the experiment. <xref ref-type="fig" rid="fig1">Figure 1D</xref> depicts a 1-min example of such recording during rest before (light gray) and after (dark gray) exclusion of blink periods (see Materials and methods). The pupil size was analyzed according to ‘slow states’ and ‘fast events’, capturing two timescales of spontaneous pupil changes. ‘Slow states’ are defined as the averaged pupil size within 2 s non-overlapping windows (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). The time interval of 2 s considers the slow nature of pupil size fluctuations, as shown in <xref ref-type="fig" rid="fig1">Figure 1F</xref>: the power spectrum of pupil size fluctuations is dominated by power in low frequencies, exhibiting a 1/f-type spectrum, consistent with previous reports (<xref ref-type="bibr" rid="bib86">Yellin et al., 2015</xref>). The longer timescale (2 s windows) was also chosen to facilitate spectral analysis of brain activity at low-frequency ranges (delta-theta). Pupil size extracted from 2 s windows was approximately normally distributed (<xref ref-type="fig" rid="fig1">Figure 1G</xref>). ‘Fast events’ are defined as spontaneous momentary constrictions and dilations, starting at local peaks and troughs in the pupil size timeseries, respectively (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, blue-frame inset).</p><p>While baseline pupil diameter (‘slow state’ equivalent) correlates with subsequent perceptual detection in humans (<xref ref-type="bibr" rid="bib83">Waschke et al., 2019</xref>; <xref ref-type="bibr" rid="bib78">van Kempen et al., 2019</xref>; <xref ref-type="bibr" rid="bib56">Podvalny et al., 2019</xref>) and mice (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>, <xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib71">Steinmetz et al., 2019</xref>), it is currently unknown whether momentary spontaneous dilations and constriction (‘fast events’) during a baseline period play a functional role in behavior. Animal studies show that fast pupil events are regulated by neural activity in cortex, superior colliculi, and locus coeruleus (LC) (<xref ref-type="bibr" rid="bib38">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib59">Reimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib60">Reimer et al., 2016</xref>), with distinct neuromodulatory control as compared to slow pupil states: rapid and longer-lasting pupil dilations are associated with phasic activity of LC noradrenergic (LC-NE) projections and sustained activity in basal forebrain cholinergic (BF-Ach) projections, respectively (<xref ref-type="bibr" rid="bib60">Reimer et al., 2016</xref>). In the following sections, we report the electrophysiological neural correlates of pupillary slow states and fast events and expose the behavioral consequences of these spontaneous changes.</p><sec id="s2-1"><title>Spectral power covaries with pupil size across large-scale cortical networks</title><p>We first investigate the link between spectral content of ongoing brain activity and pupil size during eyes-open rest and prestimulus baseline in task. The spectral power of brain activity in 2 s epochs was localized using dynamic imaging of coherent sources (DICS) (<xref ref-type="bibr" rid="bib27">Gross et al., 2001</xref>) (for details, see Materials and methods). <xref ref-type="fig" rid="fig2">Figure 2</xref> depicts the distribution of power across the whole brain grouped by ‘slow state’ pupil size (using percentiles illustrated in <xref ref-type="fig" rid="fig1">Figure 1G</xref>). These results show widely distributed changes in power with slow fluctuations of pupil size: low-frequency (delta) power decreases and high-frequency (beta-gamma) power increases with larger pupil size. Such widespread cortical activity modulation could stem from the activity of neuromodulatory systems that regulate pupil size, such as the LC system, with LC-NE axons projecting widely to many cortical areas (<xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Dynamic imaging of coherent sources (DICS) power maps of resting state and prestimulus baseline brain activity grouped according to pupil size.</title><p>(<bold>A</bold>) The source power analysis (DICS) conducted in 2 s non-overlapping time windows recorded during continuous resting state fixation. The 2 s windows were grouped according to the five pupil size percentiles (0–20%, 20–40%, 40–60%, 60–80%, 80–100%). Power in each frequency band is normalized by average power across all pupil sizes. (<bold>B</bold>) Same as A but for 2 s prestimulus intervals extracted from task data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig2-v2.tif"/></fig><p>We next subjected the single-trial DICS power maps to quantitative analyses according to large-scale brain networks. Because human (<xref ref-type="bibr" rid="bib86">Yellin et al., 2015</xref>) and monkey (<xref ref-type="bibr" rid="bib13">Chang et al., 2016</xref>) functional magnetic resonance imaging (fMRI) studies report correlations between pupil size and activity in large-scale resting state networks (RSNs), we used a functional atlas (<xref ref-type="bibr" rid="bib87">Yeo et al., 2011</xref>) estimated from a large resting state fMRI dataset (<italic>N</italic> = 1000) by clustering functionally connected cortical areas into seven large-scale RSNs (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Previous work using resting state MEG data have also revealed similar topography of large-scale networks (<xref ref-type="bibr" rid="bib16">de Pasquale et al., 2010</xref>; <xref ref-type="bibr" rid="bib31">Hipp et al., 2012</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Spectral power of spontaneous activity in all frequency bands covaries with pupil size across large-scale resting state networks (RSNs).</title><p>(<bold>A</bold>) Human functional RSNs according to Yeo 2011 atlas (<xref ref-type="bibr" rid="bib87">Yeo et al., 2011</xref>). (<bold>B</bold>) Predicted fit of spectral power based on pupil size was estimated using linear mixed models in prestimulus baseline data (equivalent results from rest are shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, and single-subject data in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> and <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). For visualization purposes only, the spectral power was binned by pupil size percentiles in 5% intervals; colored circles and error bars represent mean and standard error of the mean across subjects, respectively. The models were fit using all individual epochs (<italic>n</italic> = 8460 prestimulus, <italic>n</italic> = 6705 rest, <italic>N</italic> = 24). Only models with a lower Bayesian information criterion (BIC) and a significant parameter estimate (p &lt; 0.05, FDR-corrected) are plotted. (<bold>C</bold>) Parameter estimates of the quadratic (<inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) and linear (<inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) components of each model fit to resting state and prestimulus baseline data. Gray color indicates that a model with a linear component only was preferred (lower BIC), otherwise both <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are plotted for the quadratic model. Vis: visual, SM: somatomotor, DAN: dorsal attention network, VAN: ventral attention network, Lim: limbic, FPN: frontoparietal network, DMN: default-mode network. Asterisks denote p &lt; 0.05 after FDR correction across RSNs. Figure source data is available as a supplementary file.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3">Figure 3B</xref>, including individual subject-level data for power-pupil relationship per RSN and frequency band using prestimulus baseline data.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig3-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><label>Figure 3—source data 2.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, including individual subject-level data for power-pupil relationship per RSN and frequency band using resting state data.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig3-data2-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Same as <xref ref-type="fig" rid="fig3">Figure 3B</xref>, but for resting state data.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Same as <xref ref-type="fig" rid="fig3">Figure 3B</xref>, with individual subject data.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Same as <xref ref-type="fig" rid="fig3">Figure 3B</xref>, but for resting state with individual subject data.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Analysis of pupil-linked spectral power in sensor-level magnetoencephalography (MEG) data.</title><p>(<bold>A</bold>) Parameters estimates of a quadratic model. Black dots indicate significance after spatial cluster correction. (<bold>B</bold>) Averaged relative spectral power in significant sensors, shading indicates standard error of the mean across subjects.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig3-figsupp4-v2.tif"/></fig></fig-group><p>The relationship between pupil size and spectral power was investigated using a linear mixed-effects model (LMM, see Materials and methods). For each frequency band, we averaged spectral power within each RSN (colored areas in <xref ref-type="fig" rid="fig3">Figure 3A</xref>) and fit an LMM to samples of individual 2 s windows of rest and task baseline (which avoids the arbitrary percentile grouping). We fit two types of models, one with both linear and quadratic components (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, Materials and methods), following previous reports of the relationship between pupil size and membrane potentials in the mouse auditory cortex (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>), and one with a linear component only (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>, Materials and methods) for comparison. <xref ref-type="fig" rid="fig3">Figure 3B</xref> presents the fitted curves from the task baseline data (similar plots from rest are shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) for the models with lower Bayesian information criterion (BIC), and <xref ref-type="fig" rid="fig3">Figure 3C</xref> presents the linear parameter estimates for both task baseline and rest, and a quadratic parameter estimate in case the model that included this parameter was preferred according to BIC. The parameter estimates vary across frequency bands but follow a qualitatively similar pattern across RSNs, reinforcing the above impression of widespread pupil-linked spectral power changes (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The full statistics are given in <xref ref-type="table" rid="table1">Table 1</xref>. Below, we describe the results of individual frequency bands in detail.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Behavioral consequence of pupil-linked states.</title><p>Gray shading indicates models plotted in <xref ref-type="fig" rid="fig4">Figure 4C–D</xref>, where p &lt; 0.05 for <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in Q-models and <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in L-models. HR: hit rate, FAR: false alarm rate; <italic>c</italic>: criterion, <italic>d</italic>’: sensitivity, Acc: accuracy, RT: reaction time. L-model and Q-model denote models with linear only or both linear and quadratic components, specified in and <xref ref-type="disp-formula" rid="equ4">Equations 4</xref> and <xref ref-type="disp-formula" rid="equ5">5</xref>, respectively. Marginal and conditional <italic>R</italic><sup>2</sup> indicate the proportion of total variance explained by fixed effects only and the proportion of variance explained by both fixed and random effects, respectively. BIC: Bayesian information criterion.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"><break/><break/></th><th align="left" valign="top">BHV</th><th align="left" valign="top"><italic>χ</italic><sub><italic>Q</italic></sub></th><th align="left" valign="top">Std</th><th align="left" valign="top">pval</th><th align="left" valign="top"><italic>χ</italic><sub><italic>L</italic></sub></th><th align="left" valign="top">Std</th><th align="left" valign="top">pval</th><th align="left" valign="top">BIC</th><th align="left" valign="top">Marginal <italic>R</italic><sup>2</sup></th><th align="left" valign="top">Conditional <italic>R</italic><sup>2</sup></th></tr></thead><tbody><tr><td align="left" rowspan="6" valign="top"><bold>Q-model</bold></td><td align="left" valign="top">HR</td><td align="left" valign="top">–0.020</td><td align="char" char="." valign="top">0.007</td><td align="char" char="." valign="top">0.006</td><td align="char" char="." valign="top">0.043</td><td align="char" char="." valign="top">0.007</td><td align="left" valign="top">8.48E-09</td><td align="left" valign="top">–166.659</td><td align="char" char="." valign="top">0.037</td><td align="char" char="." valign="top">0.923</td></tr><tr><td align="left" valign="top">FAR</td><td align="left" valign="top">0.002</td><td align="char" char="." valign="top">0.010</td><td align="char" char="." valign="top">0.85</td><td align="char" char="." valign="top">0.009</td><td align="char" char="." valign="top">0.009</td><td align="left" valign="top">0.299</td><td align="left" valign="top">–131.423</td><td align="char" char="." valign="top">0.002</td><td align="char" char="." valign="top">0.850</td></tr><tr><td align="left" valign="top"><italic>c</italic></td><td align="left" valign="top">0.021</td><td align="char" char="." valign="top">0.022</td><td align="char" char="." valign="top">0.34</td><td align="char" char="." valign="top">–0.083</td><td align="char" char="." valign="top">0.022</td><td align="left" valign="top">1.655E-04</td><td align="left" valign="top">82.371</td><td align="char" char="." valign="top">0.016</td><td align="char" char="." valign="top">0.917</td></tr><tr><td align="left" valign="top"><italic>d</italic>’</td><td align="left" valign="top">–0.080</td><td align="char" char="." valign="top">0.034</td><td align="char" char="." valign="top">0.0196</td><td align="char" char="." valign="top">0.098</td><td align="char" char="." valign="top">0.017</td><td align="left" valign="top">4.38E-09</td><td align="left" valign="top">141.827</td><td align="char" char="." valign="top">0.036</td><td align="char" char="." valign="top">0.660</td></tr><tr><td align="left" valign="top">Acc</td><td align="left" valign="top">–0.013</td><td align="char" char="." valign="top">0.007</td><td align="char" char="." valign="top">0.063</td><td align="char" char="." valign="top">0.031</td><td align="char" char="." valign="top">0.008</td><td align="left" valign="top">3.745E-05</td><td align="left" valign="top">–205.201</td><td align="char" char="." valign="top">0.052</td><td align="char" char="." valign="top">0.816</td></tr><tr><td align="left" valign="top">RT</td><td align="left" valign="top">0.013</td><td align="char" char="." valign="top">0.008</td><td align="char" char="." valign="top">0.096</td><td align="char" char="." valign="top">–0.029</td><td align="char" char="." valign="top">0.008</td><td align="left" valign="top">7.248E-04</td><td align="left" valign="top">–192.939</td><td align="char" char="." valign="top">0.020</td><td align="char" char="." valign="top">0.938</td></tr><tr><td align="left" rowspan="6" valign="top"><bold>L-model</bold></td><td align="left" valign="top">HR</td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="char" char="." valign="top">0.043</td><td align="char" char="." valign="top">0.007</td><td align="left" valign="top">6.943E−09</td><td align="left" valign="top">–178.111</td><td align="char" char="." valign="top">0.057</td><td align="char" char="." valign="top">0.846</td></tr><tr><td align="left" valign="top">FAR</td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="char" char="." valign="top">0.009</td><td align="char" char="." valign="top">0.009</td><td align="left" valign="top">0.299</td><td align="left" valign="top">–149.132</td><td align="char" char="." valign="top">0.003</td><td align="char" char="." valign="top">0.746</td></tr><tr><td align="left" valign="top"><italic>c</italic></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="char" char="." valign="top">–0.083</td><td align="char" char="." valign="top">0.022</td><td align="left" valign="top">1.31E−04</td><td align="left" valign="top">67.171</td><td align="char" char="." valign="top">0.027</td><td align="char" char="." valign="top">0.848</td></tr><tr><td align="left" valign="top"><italic>d’</italic></td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="char" char="." valign="top">0.098</td><td align="char" char="." valign="top">0.039</td><td align="left" valign="top">0.011</td><td align="left" valign="top">187.050</td><td align="char" char="." valign="top">0.036</td><td align="char" char="." valign="top">0.446</td></tr><tr><td align="left" valign="top">Acc</td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="char" char="." valign="top">0.031</td><td align="char" char="." valign="top">0.008</td><td align="left" valign="top">3.539E−05</td><td align="left" valign="top">–220.347</td><td align="char" char="." valign="top">0.078</td><td align="char" char="." valign="top">0.676</td></tr><tr><td align="left" valign="top">RT</td><td align="left" valign="top"/><td align="left" valign="top"/><td align="left" valign="top"/><td align="char" char="." valign="top">–0.029</td><td align="char" char="." valign="top">0.008</td><td align="left" valign="top">7.346E−04</td><td align="left" valign="top">–200.883</td><td align="char" char="." valign="top">0.033</td><td align="char" char="." valign="top">0.854</td></tr></tbody></table></table-wrap><p>Delta power generally decreases with increasing pupil size, as can be inferred from the negative parameter estimate of the linear model component (<inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig3">Figure 3C</xref>, right), which was significant in somatomotor, ventral attention, frontoparietal, and default mode networks in the prestimulus baseline, but not at rest (FDR-corrected). This finding is consistent with previous studies reporting a reduction in delta power of cortical EEG and of membrane potential with increased arousal, such as during walking (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>; <xref ref-type="bibr" rid="bib9">Buzsaki et al., 1988</xref>). It is also consistent with findings of higher delta power during deep sleep, corresponding to a very low arousal state. A positive quadratic component (<inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) can be observed in the limbic network, for both baseline and rest data, suggesting a more complex U-shaped relationship (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, left).</p><p>Theta power shows an inverted U-shaped relationship with pupil size (<inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), which was significant at both task baseline and rest in dorsal attention network (DAN) and at baseline in visual network. The linear component was mostly positive (<inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), indicating that theta power increases with larger pupil size, but this effect was not significant in the RSNs we examined.</p><p>The relationship between alpha power and pupil size had a negative quadratic component (<inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) in all RSNs except the limbic network at both rest and task baseline where the model with the quadratic component produced a lower BIC, indicating an inverted U-shaped relationship. This finding is consistent with a previous EEG study (<xref ref-type="bibr" rid="bib32">Hong et al., 2014</xref>). The linear component was positive in all RSNs and both conditions, pointing to a nonintuitive trend of alpha power increasing with higher pupil-linked arousal. Consistent with recent suggestions (<xref ref-type="bibr" rid="bib63">Sadaghiani and Kleinschmidt, 2016</xref>; <xref ref-type="bibr" rid="bib14">Clayton et al., 2018</xref>), these results indicate that eyes-open alpha power does not index transitioning to a state of relaxation (‘idling’) as was traditionally considered in EEG research.</p><p>Both beta and gamma power show strong positive linear correlation (<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) with pupil size in all RSNs and both conditions. Such a positive correlation was recently observed in the EEG beta range, but not in the gamma range (<xref ref-type="bibr" rid="bib83">Waschke et al., 2019</xref>). The inconsistency in the gamma range may stem from the superior MEG sensitivity to high-frequency activity. In addition, beta and gamma power exhibit weakly negative and positive quadratic components, respectively (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, left), consistent with their respective saturating and U-shaped relationship with pupil size (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>While source modeling was necessary to determine how cortical power changes with pupil size, we tested whether a simpler spectral analysis in the sensor space leads to comparable results. To this end, we estimated the power spectrum for each MEG sensor in every 2 s epoch and fit a mixed-effects model for each sensor to estimate the linear and quadratic components according to pupil size (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). The fitted parameter estimates of the models in the sensor space were consistent with those from the source-space analysis.</p><p>Together, these findings indicate that power in most large-scale networks and most frequency bands significantly correlates with pupil size according to at least one model component (linear, <inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , and/or quadratic, <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) in models fit to prestimulus baseline data. While the parameter estimates were also generally similar between the baseline and rest models, several rest models did not show a significant coupling between power and pupil size. This discrepancy could either stem from suboptimal model fit in rest (where less data is available) or from decoupling of activity in some RSNs from the neuromodulatory systems governing arousal during rest.</p></sec><sec id="s2-2"><title>Behavioral consequence of prestimulus pupil-linked states</title><p>Next, we investigated how spontaneous fluctuations in pupil-linked brain states shape perceptual decisions in an object recognition task. The task details and behavior were previously reported (<xref ref-type="bibr" rid="bib56">Podvalny et al., 2019</xref>). Briefly, the task entails recognition and categorization of liminal object images (<xref ref-type="fig" rid="fig1">Figure 1C</xref>): the image contrast was titrated for each participant in a pre-task staircase procedure, such that the same image was reported as recognized in 44.9% ± 3.5% (i.e., %‘yes’ reports, mean ± s.e.m., <italic>N</italic> = 24) of trials during the main task, not significantly different from the intended 50% recognition rate. The task included real images and their scrambled counterparts. Scrambled images were generated by phase-scrambling real images, which preserves low-level image features that differ between categories. Real-image trials were used to determine the hit rate and scrambled-image trials were used to determine the false alarm rate (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), which were subsequently used to calculate shifts in criterion (<italic>c</italic>) and sensitivity (<italic>d</italic>’) as a function of prestimulus pupil/brain state (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). In addition to these subjective recognition reports (‘yes’/‘no’), subjects were also asked to report the object category (‘face’/‘animal’/‘house’/‘object’) whereby they were instructed to guess the category if they could not recognize an object. Categorization accuracy (%correct) and reaction time were obtained from the category reports for both real and scrambled images.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Behavioral and neural consequence of variation in baseline pupil-linked state.</title><p>(<bold>A</bold>) Schematic of experimental stimulus types and their classification into behavioral metrics. C: correct, I: incorrect, FA: false alarm, CR: correct rejection. (<bold>B</bold>) Illustration of changes in detection criterion and sensitivity with prestimulus baseline pupil-linked state, summarizing results in (<bold>C</bold>). (<bold>C</bold>) Recognition behavior in a perceptual decision-making task in groups of trials sorted in bins according to prestimulus baseline pupil size. Statistical tests were performed using linear mixed model (LMM). Models with quadratic and linear or only linear terms were considered and plotted when the fit was significant (p &lt; 0.05, full statistics are given in <xref ref-type="table" rid="table1">Table 1</xref>). (<bold>D</bold>) Categorization behavior: reaction time (top) and categorization accuracy (bottom) as a function of prestimulus baseline pupil size. (<bold>E</bold>) Single-trial decoding of stimulus category from whole-brain sensor-level stimulus-triggered magnetoencephalography (MEG) activity. The heatmap shows decoding accuracy in trials sorted according to prestimulus baseline pupil size (rows) and in 100 ms time windows following stimulus onset (columns). The top and right panels show averaged decoding accuracy across pupil-linked states or time; red dashed lines indicate the empirical chance level obtained through label permutations (<italic>K</italic> = 500) and asterisks indicate the time points/conditions where decoding accuracy was significantly better than chance (p &lt; 0.05, FDR-corrected, label permutation test). Two-way repeated-measures ANOVA shows significant main effects of decoding time and prestimulus pupil diameter on decoding accuracy (p &lt; 0.05) with no significant interaction. Error bars in all panels indicate s.e.m. across subjects.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4C,D</xref>, including individual subject-level data for perceptual behavior as a function of pupil size.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig4-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig4sdata2"><label>Figure 4—source data 2.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4E</xref>, including individual subject-level data for post-stimulus category decoding accuracy according to time point and prestimulus pupil size.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig4-data2-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Individual-subject data accompanying <xref ref-type="fig" rid="fig4">Figure 4C,D,E</xref>.</title><p>(A) Behavior in a perceptual decision-making task in groups of trials sorted in bins according to prestimulus baseline pupil size. Individual subject data and model fit are shown. Each color represents one subject. (B) Decoding accuracy for individual subjects.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig4-figsupp1-v2.tif"/></fig></fig-group><p>To investigate how perceptual behavior is affected by pupil-linked arousal, we sorted task trials into five groups (with equal number of trials) according to the prestimulus pupil size (‘slow states’) and calculated behavioral metrics within each group of trials (see Materials and methods and <xref ref-type="fig" rid="fig4">Figure 4A</xref>). Previous studies reported linear and/or quadric models fitting such behavioral metrics and task-evoked pupil responses (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>; <xref ref-type="bibr" rid="bib83">Waschke et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">de Gee et al., 2017</xref>) and, accordingly, we also report the results of both model types to allow comparison (see Materials and methods, <xref ref-type="disp-formula" rid="equ5">Equations 5</xref>–<xref ref-type="disp-formula" rid="equ6">6</xref>).</p><p>Our results indicate that hit rate (i.e., proportion of ‘yes’ responses to images containing real objects) increases with baseline pupil size (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), whereby both model types produce significant positive linear component (p &lt; 0.05, see <xref ref-type="table" rid="table1">Table 1</xref> for exact statistics). By contrast, false alarm rate did not change with pupil size. The increase in hit rate can be explained by a participant either adopting a more liberal decision criterion or improving sensitivity, or both. To test these potential accounts, we calculated criterion and sensitivity (following the signal detection theory [SDT]; <xref ref-type="bibr" rid="bib26">Green and Swets, 1966</xref>) within each group of trials sorted by prestimulus baseline pupil size. We observed that detection criterion linearly decreases (i.e., becoming more liberal) with increasing pupil size (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Sensitivity (<italic>d</italic>’) is related with prestimulus pupil size in an inverted U-shaped relationship, potentially following the classic Yerkes–Dodson law (<xref ref-type="table" rid="table1">Table 1</xref>). We also observed faster and more accurate object categorization responses following larger baseline pupil size (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, <xref ref-type="table" rid="table1">Table 1</xref>). Data and model fit for individual subjects are plotted in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</p><p>We next tested whether pupil-linked states influence perceptual behavior by shaping the neural representation of stimulus content. Such a prediction might be expected since larger baseline pupil size predicts higher categorization accuracy behaviorally (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). To this end, we used a single-trial multivariate decoder (logistic regression) trained to predict stimulus category from MEG sensor-level stimulus-triggered activity. The MEG activity was averaged within consecutive 100 ms time windows and the decoders were fit for each time window and each pupil-linked group of trials separately, using a leave-one-out cross-validation scheme (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). The effects of time from stimulus onset and pupil-linked baseline state on decoding accuracy were tested by a two-way repeated-measures ANOVA (angular transformation was applied to accuracy scores before entering into the ANOVA, see Materials and methods). As expected, neural representation of stimulus category significantly changed over time following the stimulus onset (<italic>F</italic> = 3.81, p = 1.8 × 10<sup>–7</sup>). Importantly, pupil-linked states significantly affected the stimulus-triggered category representation (<italic>F</italic> = 2.97, p = 0.03), with larger pupil size preceding better neural representation of stimulus category, consistently with a previous report (<xref ref-type="bibr" rid="bib82">Warren et al., 2016</xref>). No effect of interaction between baseline pupil size and time from stimulus onset was observed (<italic>F</italic> = 1.02, p = 0.43). In addition, the decoding accuracy was significantly above the chance level (obtained by label permutations) from 200 ms to 1 s after stimulus onset (p &lt; 0.05, FDR-corrected) and significantly above the chance level for trials in the second, fourth, and fifth pupil size groups.</p></sec><sec id="s2-3"><title>Arousal-linked and arousal-independent contributions of spectral power to behavior</title><p>To understand the respective contributions of spectral power that can be explained by pupil-linked arousal (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>) and of spectral power independent of arousal to perceptual behavior, we first fit logistic regression models predicting ‘yes’/‘no’ recognition behavior from baseline fluctuations of spectral power in all frequency bands and RSNs (‘power only’), models with pupil size in addition (‘pupil and power’), models using residual power independent of pupil size (‘residual power’) and models with pupil size as a single feature (‘pupil only’) (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, see Materials and methods). The residual power was calculated by first fitting LMMs for each frequency band and each RSN for each participant, whereby the model with lower BIC at the group level was chosen between <xref ref-type="disp-formula" rid="equ3">equations 3</xref> and <xref ref-type="disp-formula" rid="equ4">4</xref> (see Materials and methods, <xref ref-type="table" rid="table1">Table 1</xref>). We find that all logistic regression models predict ‘yes’/‘no’ behavior better than chance (permutation test, p &lt; 0.05 FDR-corrected). Interestingly, the performance of ‘power only’ model does not improve by adding pupil size information (<italic>W</italic> = 143, p = 0.86, Wilcoxon signed-rank test), but the performance is worsened by regressing out the pupil-linked spectral power (<italic>W</italic> = 241, p = 0.008, Wilcoxon signed-rank test). These results indicate that both arousal-linked and arousal-independent spectral power fluctuations at baseline predict subsequent recognition behavior, but our recordings of pupil size did not provide additional information contributing to the prediction of behavior that was not already present in cortical spectral power.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Spontaneous fluctuations of power shape behavior through both arousal-linked and arousal-independent mechanisms.</title><p>(<bold>A</bold>) Performance of logistic regression models (quantified as AUROC [area under the receiver-operator curve]) predicting recognition behavior (‘yes’/’no’ reports) from prestimulus power in all frequency bands and resting state networks (RSNs) (‘power only’), with prestimulus pupil size in addition to power (‘pupil and power’), with residual power that was independent from pupil size (‘residual power’), and with prestimulus pupil size as a single model feature (‘pupil only’). Model performance was compared against chance through label permutation tests (* indicates p &lt; 0.05, **p &lt; 0.01 after FDR correction). ‘Power only’ model performance was compared with other models by Wilcoxon signed-rank test. (<bold>B</bold>) Parameter estimates of fitted linear mixed-effects model (LMM) where the trials were sorted according to the residual (independent-of-pupil) power. Each table element indicates parameter estimate for one frequency band and one RSN. * indicate p &lt; 0.05 after FDR correction across RSNs, and + indicate p &lt; 0.05 uncorrected (full statistics can be found in Table S2). Source data is available as a supplementary file.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5A</xref>, including individual subject-level data for “Yes”/“No” discrimination.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig5-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata2"><label>Figure 5—source data 2.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5B</xref>, including individual subject-level data for residual power’s relationship to perceptual behavior, separately for each RSN and frequency band.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig5-data2-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig5-v2.tif"/></fig><p>Next, we aimed to clarify the effects of residual power within each frequency band and RSN on behavior. To this end, we sorted the trials into five groups according to the residual power in each frequency band and RSN, and calculated behavioral metrics for each group of trials. Using an LMM (Materials and methods, <xref ref-type="disp-formula" rid="equ5">equations 5</xref>–<xref ref-type="disp-formula" rid="equ6">6</xref>), we then determined whether pupil-independent spectral power in a given RSN could explain shifts in behavior. Analysis using the linear model (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) revealed pupil-independent negative correlation of power in delta and theta bands with hit rate, with the largest effect size in the visual RSN (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Alpha and beta power in visual RSN also negatively correlated with hit rate. A negative correlation between alpha power and hit rate was previously reported in visual detection tasks and interpreted as spontaneous fluctuations of arousal (<xref ref-type="bibr" rid="bib19">Ergenoglu et al., 2004</xref>). Our result, however, suggests that alpha power’s effect on hit rate in our task is independent from pupil-linked arousal (in fact, alpha power’s relation with pupil size predicts a positive correlation with hit rate, opposite to the experimental findings; see <xref ref-type="fig" rid="fig3">Figures 3B</xref> and <xref ref-type="fig" rid="fig4">4C</xref>).</p><p>The effects on hit rate may stem from changes in criterion, sensitivity, or both. Using SDT analysis, we found that residual delta power in the dorsal attention network (DAN) and visual network has an effect on detection criterion, such that higher delta power results in a more conservative criterion. DAN includes the decision-making-related frontal eye field (FEF) and posterior parietal cortex areas (<xref ref-type="bibr" rid="bib17">Dorris and Glimcher, 2004</xref>), which were shown to reflect decision criterion in non-human primates (<xref ref-type="bibr" rid="bib23">Gold and Shadlen, 2007</xref>). Interestingly, detection sensitivity, but not criterion, was influenced by pupil-independent alpha power in the visual and default mode RSNs. This result complements the previous findings of visual alpha power influencing detection criterion instead of sensitivity (<xref ref-type="bibr" rid="bib64">Samaha et al., 2020</xref>), and underscores the importance of considering pupil-linked state. In addition, visual delta and theta power and limbic beta power negatively correlate with sensitivity. Lastly, categorization accuracy is affected by pupil-independent prestimulus power several frequency bands and RSNs. In sum, spontaneous fluctuations in cortical spectral power contribute to perceptual decision-making independently of arousal-linked fluctuations.</p><p>Fitting the model type with quadratic and linear components (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>) produced smaller BIC only in 9 out of 210 cases, indicated that the models with a linear component only is a better choice in 96% of cases. Out of the nine quadratic models with the lower BIC, however, none produced a significant quadratic component (p &gt; 0.05).</p></sec><sec id="s2-4"><title>Pupil size also reflects brain activity on a faster timescale, but with no discernable effect on behavior</title><p>Our analyses so far have revolved around slow (seconds) timescales of brain state fluctuations, in contrast to previous studies in animals showing that pupil size also changes with brain activity on a faster (milliseconds) timescale: specifically, pupil dilates after increased LC neuronal firing with an ~300 ms delay in non-human primates (<xref ref-type="bibr" rid="bib38">Joshi et al., 2016</xref>). While signals from brainstem nuclei such as LC are difficult to detect with MEG, the brainstem nuclei send widespread cortical projections and cortical activity is readily detected by MEG. Thus, we hypothesized that covariation between pupil size and cortical activity at a fast timescale can be detected by MEG, which provides excellent temporal resolution (1200 Hz).</p><p>To estimate the time lag of correspondence between brain activity and pupil size, we computed time-resolved cross-correlation between each MEG sensor within each 2 s window during rest and prestimulus baseline with 100 ms time lags. Brain activity recorded from most MEG sensors correlated with pupil diameter at this fast timescale (<xref ref-type="fig" rid="fig6">Figure 6A</xref>; spatiotemporal cluster-based permutation test, p &lt; 0.05). The correlation values were highest at a lag of 400 ms in most MEG sensors (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), suggesting that cortical activity precedes fast pupil events by ~400 ms.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Fast (sub-second) timescale of pupil and brain interaction.</title><p>(<bold>A</bold>) Cross-correlation between pupil size and sensor-level magnetoencephalography (MEG) activity during rest and prestimulus baseline. (<bold>B</bold>) Distribution of the cross-correlation peak and trough times in MEG sensors that showed significant correlation at any time point. Most sensors correlate with pupil size with a 400 ms delay. (<bold>C</bold>) Example of identified pupillary events, spontaneous constriction and dilation, and MEG activity triggered by such events in two occipital MEG sensors. (<bold>D</bold>) Same analysis as (<bold>C</bold>) across all sensors. Black dots in A and D indicate significant sensor-time locations (p &lt; 0.05, spatiotemporal cluster-based permutation test). (<bold>E</bold>) A lack of behavioral consequence of stimulus presentation during a constriction or a dilation event. Constriction and dilatation are defined as a decreasing/increasing pupil size in the 100 ms before stimulus presentation.</p><p><supplementary-material id="fig6sdata1"><label>Figure 6—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig6">Figure 6E</xref>, including individual subject-level data for perceptual behavior sorted by prestimulus fast pupil dynamics.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-68265-fig6-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Additional analyses of dilation and constriction events.</title><p>(<bold>A</bold>) Distribution of inter-event intervals combined for all subjects. Diamonds show median of each subject. (<bold>B</bold>) Brain response to events identified by peak prominence (i.e., peak height in relationship to local minima) of &gt;0.5 s.d. with an inter-event interval restricted to at least 0.5, 1, 1.5, 2, 2.5 s (color bar). Time courses are from the same magnetoencephalography (MEG) channels shown in <xref ref-type="fig" rid="fig6">Figure 6C</xref>. (<bold>C</bold>) Same analysis as presented in 6C but events are identified on unfiltered pupil data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-fig6-figsupp1-v2.tif"/></fig></fig-group><p>To investigate whether this prominent cross-correlation between pupil size fluctuation and MEG activity is related to the pupillary ‘fast events’—spontaneous momentary constrictions and dilations (<xref ref-type="fig" rid="fig1">Figure 1D</xref>)—we calculated event-related field time-locked to fast pupil events in the resting state. <xref ref-type="fig" rid="fig6">Figure 6C</xref> shows example fast pupillary events (left) and averaged MEG activity time-locked to these constriction and dilation events in two occipital sensors (right). Both dilation- and constriction-related MEG activity shows one peak and one trough at ~0 and –400 ms. Control analyses confirmed that the distance between peaks, method of peak selection, or filtering the pupil time course do not influence the identified time courses of these fast pupil events (Materials and methods, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). <xref ref-type="fig" rid="fig6">Figure 6D</xref> shows MEG activity time-locked to fast pupillary events across the whole brain, with many sensors exhibiting significant activity preceding and following spontaneous pupil dilation and constriction. Assuming that human LC activity leads pupil changes with the same time delay as in monkeys, these findings are compatible with the possibility that cortical activity leads LC activity in the resting state (<xref ref-type="bibr" rid="bib38">Joshi et al., 2016</xref>).</p><p>Together with previous animal findings (<xref ref-type="bibr" rid="bib38">Joshi et al., 2016</xref>), our results in humans (<xref ref-type="fig" rid="fig6">Figure 6A–D</xref>) show that spontaneous pupil constrictions and dilations follow cortical and subcortical neural activity on a fast timescale (with a 300–400 ms lag). Do these fast, spontaneous pupil events influence perceptual behavior? To answer this question, we sorted the trials according to whether the stimulus was presented during a dilation or a constriction event (see Materials and methods, Eye-tracking and pupil size analysis) and calculated the behavioral metrics for these two groups of trials separately. We did not observe any difference in perceptual behavior according to whether the stimulus was presented during a dilation or a constriction event (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). A control analysis using more stringent thresholds (50% of trials with largest constriction or dilation slopes) yielded similar null results (p &gt; 0.05 for all behavioral variables). Together, these findings suggest that only slower pupil-linked states shape perceptual decision-making, but not fast pupillary events, even though these fast events are associated with robust changes in neural activity.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study we characterized the relationship between spontaneous fluctuations in central and peripheral markers of arousal (cortical spectral power and pupil size) and delineated their contributions to behavior in a visual perceptual decision-making task. We uncovered that slow (~seconds) fluctuations in pupil size differentially relate to spontaneous large-scale changes in cortical spectral power across a broad range of frequencies. Spontaneous fluctuations of cortical activity power influenced perceptual behavior through arousal-linked and arousal-independent mechanisms. Lastly, transient pupillary events (constriction and dilation) were preceded by spontaneous cortical activity at a fast timescale (~400 ms) but did not have discernable influence on perceptual behavior.</p><sec id="s3-1"><title>Spontaneous fluctuations in cortical spectral power are associated with pupil-linked arousal</title><p>Our data suggest that pupil-linked arousal covaries with spontaneous widespread changes in electrophysiological brain activity in humans (<xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s4">4</xref>, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). This widespread arousal effect on cortical activity is consistent with previous human fMRI studies showing that large-scale fluctuations of BOLD signal in the resting state correlate with pupil size (<xref ref-type="bibr" rid="bib86">Yellin et al., 2015</xref>; <xref ref-type="bibr" rid="bib68">Shine et al., 2016</xref>; <xref ref-type="bibr" rid="bib65">Schneider et al., 2016</xref>), as well as the widespread cortical projections from subcortical neuromodulatory systems including the LC-NE or BF-ACh systems. Activity of both systems correlates with pupil size and cortical activity in mice (<xref ref-type="bibr" rid="bib60">Reimer et al., 2016</xref>) and non-human primates (<xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>, <xref ref-type="bibr" rid="bib74">Turchi et al., 2018</xref>), but only limited data is available in humans (<xref ref-type="bibr" rid="bib15">de Gee et al., 2017</xref>, <xref ref-type="bibr" rid="bib53">Murphy et al., 2014</xref>). The full circuit-level mechanisms of these two systems are not fully understood and are currently under investigation (<xref ref-type="bibr" rid="bib50">McCormick et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Joshi and Gold, 2020</xref>). Additional subcortical neuromodulatory systems (such as dopaminergic and serotonergic) send widespread projections to the cortex (reviewed by <xref ref-type="bibr" rid="bib76">van den Brink et al., 2019</xref>) and their relationship to spontaneous fluctuations in pupil size and cortical activity deserves further investigation.</p><p>Pupil-linked arousal has widespread effects in the frequency domain as well, influencing cortical activity power from delta to gamma bands. Such a cross-frequency effect is consistent with intracranial EEG studies reporting that the spectral power of cortical activity follows a 1/<italic>f</italic> function, the exponent of which links the power across frequencies (<xref ref-type="bibr" rid="bib29">He et al., 2010</xref>; <xref ref-type="bibr" rid="bib55">Podvalny et al., 2015</xref>; <xref ref-type="bibr" rid="bib22">Freeman and Zhai, 2009</xref>; <xref ref-type="bibr" rid="bib30">He, 2014</xref>). Because the effect of pupil-linked arousal spans all frequencies, it likely stems at least partly from aperiodic brain activity, where the 1/<italic>f</italic> exponent decreases during high arousal sates, leading to simultaneous increase of high-frequency power and decrease of low-frequency power. Indeed, a recent study demonstrated that 1/<italic>f</italic> exponent of intracranial EEG power spectrum in the frequency range of 30–45 Hz is smaller (i.e., the power spectrum is shallower) in wakefulness than under anesthesia, pointing to the effect in the expected direction (<xref ref-type="bibr" rid="bib44">Lendner et al., 2020</xref>). Furthermore, both BF-ACh (<xref ref-type="bibr" rid="bib73">Szerb, 1967</xref>) and LC-NE (<xref ref-type="bibr" rid="bib6">Berridge and Waterhouse, 2003</xref>) activity and increase in pupil size (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>; <xref ref-type="bibr" rid="bib59">Reimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib80">Vinck et al., 2015</xref>; <xref ref-type="bibr" rid="bib72">Stitt et al., 2018</xref>) are associated with spectral modulation following the same principle: increase in high-frequency and decrease in low-frequency power. Importantly, our findings extend these previous findings from single cortical areas to large-scale cortical networks and from animal models to humans. In addition, we report a more complex and nonlinear relationship of spectral power and pupil size than was previously known.</p><p>We observed an inverted U-shaped relationship between alpha power and pupil size in the resting state and prestimulus baseline, consistent with recent EEG studies (<xref ref-type="bibr" rid="bib78">van Kempen et al., 2019</xref>; <xref ref-type="bibr" rid="bib32">Hong et al., 2014</xref>). These previous studies only investigated the alpha band, while our results show that pupil-linked arousal correlates with global electrophysiological power shift between low- and high-frequency bands, whereby the alpha band appears to constitute the intermediate transition point. This relationship between prestimulus alpha power and pupil size is consistent with a previous suggestion that alpha power positively correlates with tonic alertness (<xref ref-type="bibr" rid="bib63">Sadaghiani and Kleinschmidt, 2016</xref>; <xref ref-type="bibr" rid="bib62">Sadaghiani et al., 2010</xref>), which might correspond to the dominant left-hand side of the inverted-U function (<xref ref-type="fig" rid="fig3">Figure 3B</xref>); further, the inverted U-shaped relationship we observed is consistent with the disappearance of alpha oscillations during drowsiness and light sleep—states with very low arousal (<xref ref-type="bibr" rid="bib11">Cantero et al., 1999</xref>).</p><p>The brain activity modulation by pupil-linked arousal systems, while similar across RSNs, is not entirely uniform. We observed, for example, differences in parameter estimates across networks and behavioral conditions: modulation of alpha power by arousal in the visual RSN is stronger than in other networks at rest, whereas modulation of beta power is strongest in the DAN in task baseline (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, linear components). Such non-uniform effects are consistent with the intriguing proposals of pupil-linked arousal systems playing an important role in dynamic reconfiguration of large-scale networks topology responding to cognitive demands (<xref ref-type="bibr" rid="bib76">van den Brink et al., 2019</xref>; <xref ref-type="bibr" rid="bib69">Shine, 2019</xref>). Indeed, while the arousal neuromodulatory systems send widespread projections to cortex, recent studies also report complex topographic organization which may produce such non-uniform modulatory effects (<xref ref-type="bibr" rid="bib75">Uematsu et al., 2017</xref>; <xref ref-type="bibr" rid="bib12">Chandler et al., 2019</xref>). A greater understanding of the function of uniform vs. modular effects on cortical power by arousal systems in various cognitive states is an important goal for future investigation.</p></sec><sec id="s3-2"><title>Behavioral relevance of pupil-linked brain state</title><p>We found that prestimulus pupil-linked brain state influences both the detection sensitivity (<italic>d</italic>’) and criterion (<italic>c</italic>) in a visual perceptual decision-making task (<xref ref-type="fig" rid="fig4">Figure 4</xref>). While the relationship between pupil size and behavior received much attention in the last century, most of the early studies dismissed the importance of prestimulus pupil size’s effect on subsequent behavior (<xref ref-type="bibr" rid="bib24">Goldwater, 1972</xref>). The effect of prestimulus pupil size on perceptual behavior was evaluated in several recent studies. A previous study (<xref ref-type="bibr" rid="bib83">Waschke et al., 2019</xref>) using an auditory discrimination task observed a similar inverted-U function between perceptual sensitivity and prestimulus pupil size as we observed here. A null effect of baseline pupil size on behavior was reported in a previous visual detection study (<xref ref-type="bibr" rid="bib15">de Gee et al., 2017</xref>), but the analyzed baseline period in this study coincided with the appearance of a noise stimulus, which may have influenced pupil diameter during the baseline period. Lastly, we found an opposite effect of prestimulus pupil size on reaction time as compared to an earlier study (<xref ref-type="bibr" rid="bib78">van Kempen et al., 2019</xref>); this difference might result from different task designs and/or the two studies sampling different regions of arousal variation that constitute the left vs. right arm of a U-shaped function.</p><p>Recent animal studies report effects of baseline pupil size on behavior as well. An inverted U-shaped relationship between baseline pupil size and subsequent hit rate and detection sensitivity was reported in the mouse (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>; <xref ref-type="bibr" rid="bib71">Steinmetz et al., 2019</xref>), consistent with our findings. Criterion was reported to follow a U-shaped function with baseline pupil size (<xref ref-type="bibr" rid="bib51">McGinley et al., 2015a</xref>); our data is consistent with the left-hand side of this relationship, potentially due to the mouse achieving higher arousal levels during the experiment. Future human studies involving higher arousal states will allow a more comprehensive comparison between mouse and human studies.</p><p>Extending the classic Yerkes–Dodson law, the adaptive gain theory (<xref ref-type="bibr" rid="bib2">Aston-Jones and Cohen, 2005</xref>) postulates that ongoing changes in pupil size reflect transitions between several states: exploration, when the tonic LC activity is high and the pupil is large; exploitation, when the LC activity is bursty and the pupil is of intermediate size; and drowsiness, when the tonic LC activity is low and the pupil is small. Here, we observed the lowest perceptual sensitivity with the smallest pupil size (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), which might be explained by low arousal or drowsiness. Sensitivity was higher with intermediate pupil size, potentially due to transition to the state of exploitation. The largest pupil recorded in our study corresponded to the decay phase of the quadratic model, potentially indicating a decreasing sensitivity with the transition to the exploratory behavioral state. Interestingly, the largest prestimulus pupil also cooccurs with a subsequent shift to a more liberal decision criterion, which intuitively fits with the adaptive gain theory framework because exploration requires accepting a less rewarding option. It has been shown indeed that a larger baseline pupil diameter precedes more exploratory choices (<xref ref-type="bibr" rid="bib36">Jepma and Nieuwenhuis, 2011</xref>). Further research on a link between the exploration-exploitation behavior according to the adaptive gain theory and detection criterion and sensitivity according to SDT could constitute an exciting new direction as it seems that both types of behavioral state transitions could be controlled by the same underlying mechanism.</p></sec><sec id="s3-3"><title>Behavioral consequences of spectral power associated with and dissociated from pupil-linked arousal</title><p>Interestingly, recognition behavior (‘yes’/‘no’ reports) could be predicted better than chance from single-trial baseline spectral power and, while pupil size did not provide additional predictive power to the model, removing the pupil-linked spectral power fluctuations significantly reduced the model performance (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). This result indicates that behavior in a visual perceptual decision-making task is influenced by both arousal-linked and arousal-independent fluctuations of cortical spectral power.</p><p>After controlling for the effect of pupil-linked arousal, we found that alpha power in the visual network predicted detection sensitivity but not criterion (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). A large body of previous work has shown a link between prestimulus alpha power and perceptual behavior, (for example, <xref ref-type="bibr" rid="bib77">van Dijk et al., 2008</xref>; <xref ref-type="bibr" rid="bib45">Limbach and Corballis, 2016</xref>; <xref ref-type="bibr" rid="bib33">Iemi et al., 2017</xref>), and the predominant pattern from these studies is that spontaneous fluctuations of alpha power in visual areas influence detection criterion (and associated subjective visibility) but not sensitivity (reviewed recently in <xref ref-type="bibr" rid="bib64">Samaha et al., 2020</xref>). These previous studies, however, did not account for behavioral modulation by pupil-linked arousal states, which, as we have shown, influence most frequency bands. Our results indicate that, first, prestimulus alpha power is modulated by both pupil-linked and pupil-independent mechanisms; and second, the pupil-independent alpha power fluctuation appears to affect perceptual sensitivity but not criterion, while pupil-linked arousal influences both sensitivity and criterion.</p><p>Previous studies have also shown that alpha power modulation plays an important role in attentional gating, such that alpha power suppression corresponds to the allocation of spatial- and feature-based attention (<xref ref-type="bibr" rid="bib21">Foxe and Snyder, 2011</xref>; <xref ref-type="bibr" rid="bib34">Jensen and Mazaheri, 2010</xref>). Given that attentional cueing typically increases detection accuracy (<xref ref-type="bibr" rid="bib28">Haegens et al., 2011</xref>; <xref ref-type="bibr" rid="bib81">Voytek and Knight, 2010</xref>) and sensitivity (<italic>d</italic>’) (<xref ref-type="bibr" rid="bib41">Kelly et al., 2009</xref>; <xref ref-type="bibr" rid="bib70">Smith, 2000</xref>), our observed negative relationship between pupil-independent alpha power and detection sensitivity is consistent with the attention effect. However, because our task did not explicitly manipulate spatial- or feature-based attention, how the pupil-independent alpha power fluctuations relate to attention-related alpha modulations, and whether their influences on perceptual behavior share the same underlying mechanism, remains to be tested.</p><p>After controlling for the effect of pupil-linked arousal, we also found that prestimulus delta power (1–4 Hz) in the DAN and visual network influences subsequent detection criterion, but not sensitivity, with higher delta power preceding a more conservative criterion. This finding is inconsistent with previous studies reporting a null effect of prestimulus EEG delta power on visual (<xref ref-type="bibr" rid="bib19">Ergenoglu et al., 2004</xref>) or auditory (<xref ref-type="bibr" rid="bib83">Waschke et al., 2019</xref>) stimulus detection. Consistent with our result, spontaneous fMRI activity in DAN was shown to correlate with subsequent stimulus detection in humans (<xref ref-type="bibr" rid="bib7">Boly et al., 2007</xref>; <xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2009</xref>). Previous fMRI research also revealed an effect of prestimulus DAN activity on subjective perceptual bias in a random dot motion detection task (<xref ref-type="bibr" rid="bib58">Rahnev et al., 2012</xref>). DAN includes the decision-making-related FEF and posterior parietal cortex (<xref ref-type="bibr" rid="bib17">Dorris and Glimcher, 2004</xref>), which were shown to reflect decision criterion in non-human primates (<xref ref-type="bibr" rid="bib23">Gold and Shadlen, 2007</xref>); electrical stimulation of FEF also affects the pupil size, potentially due to mechanisms related to selective attention (<xref ref-type="bibr" rid="bib18">Ebitz et al., 2017</xref>). Together, the effect of delta power in DAN on detection criterion is consistent with previous human fMRI and non-human primate electrophysiology studies; but our study specifically rules out pupil-linked arousal in this effect and provides a frequency domain localization to the delta band.</p></sec><sec id="s3-4"><title>The timescale of pupil size fluctuations and momentary events</title><p>Pupil size correlates with large-scale MEG activity on a faster timescale as well: first, spontaneous variations in MEG activity precede spontaneous variations in the pupil size with a lag of 400 ms (<xref ref-type="fig" rid="fig6">Figure 6A–B</xref>); second, pupillary events (constriction and dilation) coincide with MEG activity peak at lag zero and are preceded by an MEG activity peak occurring 400 ms earlier (<xref ref-type="fig" rid="fig6">Figure 6C–D</xref>). A similar pattern of two peaks (at 0 and –300 ms) was observed in monkey LC spike rates (<xref ref-type="bibr" rid="bib38">Joshi et al., 2016</xref>). The zero-lag peak we observed could result from a neural event occurring earlier in time and influencing both pupil size and MEG activity at the same time lag. Since MEG activity originates mostly in the cortex, the peak at –400 ms lag (100 ms earlier than the peak in monkey LC) could point to an influence of cortical resting state fluctuations on LC activity which then triggers pupillary events. Such a potential influence, however, does not seem to be behaviorally relevant: whether a liminal visual stimulus is presented during ongoing pupil dilation or constriction did not influence perceptual behavior in our task (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). This result is surprising considering that pupil dilation and constriction events are controlled by sympathetic and parasympathetic pathways, respectively, activation of which is considered to have distinct effects on behavior (‘fight or flight’ vs. ‘rest and digest’). On the other hand, the sympathetic and parasympathetic pathways are also indirectly affected by the shared neuromodulatory central arousal systems (<xref ref-type="bibr" rid="bib47">Lowenstein et al., 1963</xref>), and it is possible that in our task the pupillary dilation and constriction events merely reflect the adjustment of this central arousal state, not reaching the threshold of unique sympathetic or parasympathetic effects on behavior. A previous study in the mouse reported that orientation tuning in V1 is better when a stimulus is presented during pupillary dilation as compared to constriction (<xref ref-type="bibr" rid="bib59">Reimer et al., 2014</xref>); however, it remains unknown if such improved tuning affects behavior. Future research is needed to fully map out the relationship between pupil-linked state and behavioral measurements across different timescales and in variety of tasks.</p></sec><sec id="s3-5"><title>Limitations and future directions</title><p>First, the continuum of behavioral states studied herein is inherently limited. Animals and humans in natural settings exhibit states of much lower arousal, such as deep sleep, and of much higher arousal, such as escape from danger. Understanding how such extreme states extend the link between pupil size and spectral power will be crucial to understanding the full range of state modulation of perceptual behavior. Second, spontaneous fluctuations in pupil size on a timescale longer than a run length (5.6 ± 0.38 min) might be important. In the present experiment such longer timescales could not be assessed since we used a relative measure of pupil size change within each experiment block, whereas an absolute pupil size measure (not available using the present eye-tracking set-up) is necessary to assess change in pupil size across blocks. Third, while the quadratic model we used herein provides an excellent fit to our data, it offers a simplified view of human brain state regulation. Future work focusing on normative approaches to understanding state regulation (e.g., considering optimal states for behavior) may lead to alternatives by expanding the model families and their parameters. For example, models from sigmoidal or Gaussian families might be more biologically plausible. Finally, the full composition of endogenous events driving spontaneous fluctuations in pupil size remains incompletely understood. While a causal association between activity in brainstem neuromodulatory centers and pupil size has been established, additional endogenous factors, ranging from cognitive (e.g., an exciting thought) to physiological (e.g., blinks), affect the pupil size. For example, it has been shown that blinks correlate with a subsequent fluctuation in pupil size lasting for up to 4 s (<xref ref-type="bibr" rid="bib42">Knapen et al., 2016</xref>). Importantly, it is unclear if such endogenous effect can be dissociated from arousal or not. Given such a long-lasting effect, excluding trials with blinks within 4 s intervals is not feasible (normal human blink rate can reach ~1/3 s). Thus, future research is needed to determine to what extent different endogenous events drive the spontaneous fluctuations in pupil size in addition to the known neuromodulatory effects.</p></sec><sec id="s3-6"><title>Implications</title><p>Our first aim in this study was to fill in the missing link between two well-known markers of human arousal—pupil size and cortical spectral power. The models characterizing this relationship will serve the research community in need to interpret pure eye-tracking studies in terms of neurophysiological mechanisms shaping behavior. In addition, our findings provide insights enabling the interpretation of human findings in the context of rapidly advancing knowledge about circuit-level mechanisms of arousal in animal models. Our second aim was to delineate the contributions of prestimulus pupil-linked arousal and cortical spectral power to human perceptual behavior. Our findings shed new light on the functional significance of prestimulus brain state at large, showing that both pupil-linked and pupil-independent spontaneous activity serves more than one function in human perceptual behavior. By presenting the distinct behavioral consequences of different prestimulus brain states, we begin to uncover the rich variety of spontaneous neural processes shaping behavior.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>MEG data acquisition</title><p>MEG data were recorded at a sampling rate of 1200 Hz using a 275-channel scanner (CTF, VSM MedTech). Before and after each block, the head position of the subject was measured using coils placed on the ear canals and the bridge of the nose. Between blocks, the head position of the subject was measured with respect to the MEG sensor array using coils placed on the left and right preauricular points and the nasion, and the subject self-corrected their head position to the same position recorded at the start of the first block using a custom visual-feedback program in order to minimize head displacement across the experiment. The task data analyzed herein have been used in a previously published report (<xref ref-type="bibr" rid="bib56">Podvalny et al., 2019</xref>), which included multivariate models of prestimulus sensor-level MEG activity predicting forthcoming perceptual decisions according to content-specific and non-content-specific ongoing processes. The data from rest periods analyzed in this paper have not been previously published, and the questions addressed in this study are distinct from previous publication.</p></sec><sec id="s4-2"><title>MEG data preprocessing</title><p>Three dysfunctional sensors were removed from all analyses. Independent component analysis was performed on each experiment run to remove blink, cardiac, and movement-related artifacts. The linear trend was removed from each experiment run. No frequency domain filtering was applied in order to avoid artifactual signal bleeding from the post-stimulus signal into the prestimulus period. MEG data were preprocessed using Python and the MNE toolbox (<xref ref-type="bibr" rid="bib25">Gramfort et al., 2014</xref>) (version 0.19.1).</p></sec><sec id="s4-3"><title>Participants</title><p>All participants (<italic>N</italic> = 25, 15 females, mean age 26, range 22–34) provided written informed consent. The experiment was approved by the Institutional Review Board of the National Institute of Neurological Disorders and Stroke (protocol #14 N-0002). The participants were right-handed, neurologically healthy, and had normal or corrected-to-normal vision. One enrolled participant decided to stop the experiment after finishing one experiment block due to discomfort and is not included in data analyses. Three subjects did not perform the second 5 min rest recordings due to time constraints.</p></sec><sec id="s4-4"><title>Rest</title><p>Participants were instructed to fixate at a crosshair in the middle of a gray screen and to avoid meditating or engaging in repetitive mental activity, such as counting. We recorded one 5 min session before the task onset in all 24 participants and one 5 min session after the task in 21 participants (second session recording of three participants was omitted due to time constraints).</p></sec><sec id="s4-5"><title>Task</title><p>Participants engaged in a threshold object detection task where they were instructed to report object category (face, house, object, animal) and their subjective recognition experience (‘yes’ or ‘no’) following a briefly presented low-contrast object stimulus. Subjective recognition experience has been defined as seeing an actual object versus seeing a noise pattern or seeing nothing at all. Prior to the beginning of the main task, we used an adaptive staircase procedure ‘QUEST’ (<xref ref-type="bibr" rid="bib84">Watson and Pelli, 1983</xref>) to identify image contrast resulting in subjective recognition rate of ~50% ‘yes’ reports for the same image. The main task included 300 real object images and 60 images of their phase-scrambled counterparts and was conducted in 10 experiment runs with self-paced breaks. The subjects were instructed to fixate on the center crosshair during the prestimulus interval and to avoid blinking to the best they can until after stimulus arrival. Each unique image was presented at a staircase-determined contrast and was identical across trials. Task details are also fully available in our previous publication (<xref ref-type="bibr" rid="bib56">Podvalny et al., 2019</xref>).</p></sec><sec id="s4-6"><title>Data epoch analysis</title><p>Continuous data (rest) were cut into 2 s segments (epochs), non-overlapping in time, such that 5 min recording led to 149 epochs. Task data was cut in 2 s fragments before each stimulus onset, which led to 360 epochs, corresponding to number of trials.</p></sec><sec id="s4-7"><title>Eye-tracking and pupil size analysis</title><p>The recordings were made in a dimly lit room with a screen as an additional source of luminance. Subjects’ pupil size was continuously monitored using a video-based eye-tracking system (EyeLink 1000+), in the binocular mode with a sampling rate of 1000 Hz. Only right eye recordings were used in the analysis since no difference in pupil size between eyes was expected in healthy volunteers. Blinks or missing data periods were detected by identifying the time points where the recorded pupil size of the right eye dropped below a constant threshold. The missing data detection threshold was determined for each participant by visual inspection of data and was between –3.5 and –4 in EyeLink provided arbitrary units. Blink onset was defined as 100 ms before crossing the threshold and blink offset was defined as 100 ms after. ‘Slow states’ were calculated as a simple averaged pupil size in consecutive 2 s interval in rest and 2 s before stimulus onset in task, with the blink periods excluded from average calculation. The averaged prestimulus pupil size then was z-scored within each block. ‘Fast events’ were calculated on pupil time course after blink interval interpolation using piecewise cubic Hermite interpolating polynomial. Next, in order to remove potential high-frequency artifacts, we applied a 5 Hz low-pass Butterworth filter to continued resting state data forward and backward in time using <italic>filtfilt</italic> function (<italic>Scipy</italic>), assuring no phase shifts. Peaks and troughs were defined as time points where constriction and dilation begin respectively. To identify peaks/troughs, for each data point in the pupil size time course, we tested whether its amplitude is the highest/lowest in a 1 s time window centered on that data point (using ‘argrelextrema’ method of <italic>scipy</italic>). Finally, to calculate whether a stimulus is presented during ongoing constriction or dilation, we fit a linear regression to pupil size in a 100 ms window before stimulus onset. To make sure the linear fit is less susceptible to high-frequency artifacts, a 5 Hz low-pass filter was applied on prestimulus data only (using <italic>MNE epochs.filter</italic> zero-phase FIR with Hamming window). A negative slope of the line indicates constriction and a positive slope indicates dilation.</p></sec><sec id="s4-8"><title>Forward model</title><p>We constructed the forward model using structural MRI scans (1 mm isotropic voxels, MP-RAGE sequence), acquired on a either 3T Siemens Skyra (Siemens, Erlangen, Germany), General Electric 3T scanner with an 8-channel head coil or Siemens 7T MRI system equipped with a 32-channel head coil (Nova Medical, Wilmington, MA). Images were processed in Freesurfer (recon-all). Skull strip and pial surfaces were inspected and manually corrected if necessary. We used a boundary element method (Watershed method) to create a head shape and then aligned it with MEG coordinate system according to fiducial markers (nasion, left and right preauricular points, using MNE coreg tool). For two subjects no MRI scans were available and for two additional subjects the MRI quality was too low to identify the brain surfaces. For these four subjects, we used another subject’s MRI as a template. A realistic single-shell brain volume conduction model was then constructed for each participant, based on these structural MRIs.</p></sec><sec id="s4-9"><title>Spectral analysis in source space</title><p>To localize power changes of pre-defined frequency bands, we used DICS technique (<xref ref-type="bibr" rid="bib27">Gross et al., 2001</xref>) implemented in MNE-Python, following the analysis pipeline of <xref ref-type="bibr" rid="bib79">van Vliet et al., 2018</xref>. DICS is a linearly constrained minimum variance beamforming method applied to time-frequency transformation of the original signals. Cross-spectral density (CSD) matrix was computed between signals recorded with each pair of MEG sensors using a multitaper method in frequency range of 1–100 Hz (DPSS taper windows). CSD was computed for each 2 s epoch defined in resting state or prestimulus period during task recordings. Next, a beamformer spatial filter is created for each frequency band using CSD matrix averaged across all epochs with a regularization parameter of 0.05. The frequency bands were defined as follows: delta 1–4 Hz, theta 4–8 Hz, alpha 8–13 Hz, beta 13–30 Hz, gamma 30–90 Hz. These filters were applied to the CSD matrices that were averaged across epochs corresponding to each pupil-linked group and each frequency range to obtain the group source power maps. The source power maps were then transformed to common space and submitted to group analysis.</p></sec><sec id="s4-10"><title>Analysis of behavior</title><p>We employed SDT to quantify task behavior. We first calculated hit rate (HR) and false alarms rate (FAR) as fraction of real-image trials and scrambled-image trials that were reported as recognized (i.e., the response to the question about object recognition was ‘yes’), respectively. We implemented Macmillan and Kaplan correction (<xref ref-type="bibr" rid="bib48">Macmillan and Kaplan, 1985</xref>) of FAR = 0 and HR = 1: the FAR was corrected to <inline-formula><mml:math id="inf15"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula> in the case of no FA trials, where <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the total number of scrambled-image trials; the HR was corrected to <inline-formula><mml:math id="inf17"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></inline-formula> in the case of HR equal to 1, where <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the total number of real-image trials. Next, we calculated measures of sensitivity (<italic>d</italic>’) and bias (<italic>c</italic>) following standard SDT analysis (<xref ref-type="bibr" rid="bib26">Green and Swets, 1966</xref>) using subjective reports of recognition. <italic>d</italic>’ indicates the ability to discriminate between real images containing objects and scrambled images that do not contain objects but preserve low-level features of the object images. It is computed by subtracting the Z-transformed FAR from the Z-transformed HA:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <italic>Z</italic> is an inverse normal cumulative distribution function. <italic>c</italic> criterion represents the tendency to make ‘yes’ reports to indicate recognition, regardless of whether the stimulus is a real or scrambled image and is computed as follows:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Categorization accuracy was simply calculated as a fraction of trials with correctly reported category. The time from the first question appearing on the screen to the button press corresponding to the categorization response was measured as the reaction time.</p></sec><sec id="s4-11"><title>Statistical modeling</title><p>We used LMMs with the maximal random effects structure justified by the design (<xref ref-type="bibr" rid="bib3">Barr et al., 2013</xref>). LMMs allow modeling of data with repeated measures, where we considered the participants as a random effect on the intercept. All the non-categorial predictors were z-scored before fitting the models. The p-values of the model parameters were calculated via Wald tests and were corrected across RSNs using Benjamini–Hochberg procedure (<xref ref-type="bibr" rid="bib5">Benjamini and Hochberg, 1995</xref>) controlling for false discovery rate. The models were fit using Powell’s algorithm (<xref ref-type="bibr" rid="bib57">Powell, 1964</xref>) minimizing standard (rather than restricted) likelihood to assure the meaningful information criterion calculation. BIC was used for comparison between linear and quadratic models. The models were implemented using <italic>statsmodels</italic> (<xref ref-type="bibr" rid="bib66">Seabold and Perktold, 2010</xref>) Python toolbox. We verified that the parameters estimates acquired with statsmodels were nearly identical to the ones acquired with a more widely used R lme4 (<xref ref-type="bibr" rid="bib4">Bates et al., 2015</xref>) toolbox implemented through Python wrapper pymer (<xref ref-type="bibr" rid="bib37">Jolly, 2018</xref>). We used piecewiseSEM (<xref ref-type="bibr" rid="bib43">Lefcheck and Freckleton, 2015</xref>) R package to estimate marginal and conditional variance-explained values indicating the proportion of total variance explained by fixed effects only and the proportion of variance explained by both fixed and random effects, respectively (<xref ref-type="bibr" rid="bib54">Nakagawa et al., 2017</xref>). It is important to note, however, these metrics were developed specifically for LMMs and are useful in the relative sense for comparison between such models’ fit to the data but they do not have the same properties as linear models <italic>R</italic><sup>2</sup>.</p><p><italic>First,</italic> to model the relationship between pupil size and spectral power in rest and prestimulus task intervals we used both a model with a linear and a quadratic term and a model with a linear term only, defined as follows:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:msubsup><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:msubsup><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are fixed effects parameters (shared by all subjects) and <inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are random effects parameters for subject <italic>i,</italic> and <italic>j</italic> represents the individual measurement in a 2 s interval. The model parameters with lower BIC are reported in all figures and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. Spectral power was log-transformed to bring its distribution close to normal and the mean was removed for each subject (hence no random intercepts in the model: <inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>). Pupil size was z-scored to produce standardized effect size.</p><p><italic>Second,</italic> we used an LMM to assess whether behavioral metrics change with pupil or with residual power. To this end, we first split the experimental trials into five groups according to quintiles of the distribution of pupil size or residual power (i.e., the groups contained equal number of trials (20%), see <xref ref-type="fig" rid="fig1">Figure 1G</xref>). The split was necessary since the calculation of the SDT metrics of behavior requires a group of trials. Within each group we calculated six behavioral variables: HR, FAR, <italic>d</italic>’, <italic>c</italic>, accuracy, reaction time (see the definitions above). We used two types of models, one with linear component only and one with both linear and quadratic components to study how behavior depends on the trial grouping:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>χ</mml:mi><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>here <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are fixed effects parameters (shared by all subjects) and <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf27"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are random effects parameters for subject <italic>i</italic>, and <italic>G</italic> represents the group of trials (1–5) the behavioral metrics were calculated for. The group numbers were z-scored to produce standardized effect size.</p><p><italic>Finally,</italic> to calculate residual prestimulus spectral power in various frequency bands and RSNs, we fit a model with predictors given in <xref ref-type="disp-formula" rid="equ3">equations 3</xref> or <xref ref-type="disp-formula" rid="equ4">4</xref>, selected based on lower BIC, individually for each subject and submit its residual power to analysis of behavior using the models defined in <xref ref-type="disp-formula" rid="equ5">equations 5</xref> and <xref ref-type="disp-formula" rid="equ6">6</xref>, after calculating the behavior in trial groups split according to this residual power.</p></sec><sec id="s4-12"><title>Decoding</title><p>Logistic regression models were used to predict the presented object category or the recognition (‘yes’/‘no’) reports on the single-trial level using a leave-one-out cross-validation scheme. The model was fit to all trials except one that was used for determining the accuracy of model’s prediction and this leave-one-out cross-validation procedure was repeated for each trial in a group. To decode <italic>object category,</italic> the models were fit to averaged MEG sensor-space signal in each consecutive 50 ms window in the period of 0–2 s from stimulus onset, with trials split into five groups according to prestimulus baseline pupil size quintiles (0–20%, 20–40%, 40–60%, 60–80%, 80–100%). The effects of pupil-linked group and of time window from stimulus onset on model’s prediction accuracy were tested using a repeated-measures ANOVA. The proportion of correct predictions made by the model was transformed from binomial to normal distribution using angular transformation before entering into the ANOVA: <inline-formula><mml:math id="inf28"><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mo>⁡</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msqrt><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:mfenced></mml:math></inline-formula> . To determine the empirical chance level, we shuffled the category labels and re-computed the decoding accuracy 500 times for each logistic regression model. We then calculated the proportion of times the accuracy predicted from actual data exceeded the permutation-derived chance level to assess the decoding significance. To decode the ‘yes’/‘no’ report we used four types of models: (a) ‘power only’ included the estimates of power in all frequency bands and RSNs at baseline as model’s features; (b) ‘pupil and power’ model included the same features as (a) and an additional feature of pupil size; (c) ‘residual power’ model included the residual power in all frequency bands and RSNs unexplained by pupil diameter fluctuations; (d) ‘pupil only’ model included the pupil size as a single feature. Model performance was quantified by area under the ROC (receiver-operator curve) for each subject and compared using Wilcoxon signed-rank tests.</p></sec><sec id="s4-13"><title>Pupil-MEG lagged correlation</title><p>For each 2 s epoch, a Pearson correlation coefficient was computed with 100 ms time lags between pupil diameter and activity at each MEG sensor. The correlation coefficients were Fisher-transformed and averaged across epochs for each participant and these averages were submitted to second-level group analysis. To assess significance of correlation coefficients at a group level and to address multiple comparisons, we employed a non-parametric spatiotemporal cluster-based permutation test (<xref ref-type="bibr" rid="bib49">Maris and Oostenveld, 2007</xref>) using 1000 permutations and sensor-level and cluster-level thresholds of 0.05 (MNE toolbox implementation).</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Software, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Investigation, Visualization</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Funding acquisition, Project administration, Resources, Supervision, Writing - original draft, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants provided written informed consent. The experiment was approved by the Institutional Review Board of the National Institute of Neurological Disorders and Stroke (protocol #14-N-0002).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Supplementary tables 1 and 2 containing detailed statistics related to <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig5">5</xref>.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-68265-supp1-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-68265-transrepform1-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Source data are available as csv files for all figures except for whole brain images. Analysis code supporting this study is available at a dedicated Github repository <ext-link ext-link-type="uri" xlink:href="https://github.com/BiyuHeLab/eLife_Podvalny2021">https://github.com/BiyuHeLab/eLife_Podvalny2021</ext-link>, copy archived at https://archive.softwareheritage.org/swh:1:rev:0422a1992d1dfcfd14bfa4403dac7f50668c831c.</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Navin Kariyawasam for help with literature review. This research was supported by an NSF CAREER Award (grant ID: BCS- 1753218; to BJH).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname><given-names>LH</given-names></name><name><surname>Doelling</surname><given-names>KB</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Delta-beta coupled oscillations underlie temporal prediction accuracy</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3077</fpage><lpage>3085</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu103</pub-id><pub-id pub-id-type="pmid">24846147</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: Adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barr</surname><given-names>DJ</given-names></name><name><surname>Levy</surname><given-names>R</given-names></name><name><surname>Scheepers</surname><given-names>C</given-names></name><name><surname>Tily</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Random effects structure for confirmatory hypothesis testing: Keep it maximal</article-title><source>Journal of Memory and Language</source><volume>68</volume><fpage>255</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2012.11.001</pub-id><pub-id pub-id-type="pmid">24403724</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>BM</given-names></name><name><surname>Walker</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Fitting linear mixed-effects models using LME4</article-title><source>Journal of Statistical Software</source><volume>67</volume><elocation-id>i07</elocation-id><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Controlling the false discovery rate: A practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berridge</surname><given-names>CW</given-names></name><name><surname>Waterhouse</surname><given-names>BD</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The Locus coeruleus-noradrenergic system: Modulation of behavioral state and state-dependent cognitive processes</article-title><source>Brain Research. Brain Research Reviews</source><volume>42</volume><fpage>33</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/s0165-0173(03)00143-7</pub-id><pub-id pub-id-type="pmid">12668290</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boly</surname><given-names>M</given-names></name><name><surname>Balteau</surname><given-names>E</given-names></name><name><surname>Schnakers</surname><given-names>C</given-names></name><name><surname>Degueldre</surname><given-names>C</given-names></name><name><surname>Moonen</surname><given-names>G</given-names></name><name><surname>Luxen</surname><given-names>A</given-names></name><name><surname>Phillips</surname><given-names>C</given-names></name><name><surname>Peigneux</surname><given-names>P</given-names></name><name><surname>Maquet</surname><given-names>P</given-names></name><name><surname>Laureys</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Baseline brain activity fluctuations predict somatosensory perception in humans</article-title><source>PNAS</source><volume>104</volume><fpage>12187</fpage><lpage>12192</lpage><pub-id pub-id-type="doi">10.1073/pnas.0611404104</pub-id><pub-id pub-id-type="pmid">17616583</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname><given-names>NA</given-names></name><name><surname>Dubois</surname><given-names>J</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The phase of ongoing eeg oscillations predicts visual perception</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>7869</fpage><lpage>7876</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0113-09.2009</pub-id><pub-id pub-id-type="pmid">19535598</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsaki</surname><given-names>G</given-names></name><name><surname>Bickford</surname><given-names>RG</given-names></name><name><surname>Ponomareff</surname><given-names>G</given-names></name><name><surname>Thal</surname><given-names>LJ</given-names></name><name><surname>Mandel</surname><given-names>R</given-names></name><name><surname>Gage</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Nucleus basalis and thalamic control of neocortical activity in the freely moving rat</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>4007</fpage><lpage>4026</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-11-04007.1988</pub-id><pub-id pub-id-type="pmid">3183710</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Rhythms of the Brain</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantero</surname><given-names>JL</given-names></name><name><surname>Atienza</surname><given-names>M</given-names></name><name><surname>Gómez</surname><given-names>C</given-names></name><name><surname>Salas</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Spectral structure and brain mapping of human alpha activities in different arousal states</article-title><source>Neuropsychobiology</source><volume>39</volume><fpage>110</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1159/000026569</pub-id><pub-id pub-id-type="pmid">10072668</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandler</surname><given-names>DJ</given-names></name><name><surname>Jensen</surname><given-names>P</given-names></name><name><surname>McCall</surname><given-names>JG</given-names></name><name><surname>Pickering</surname><given-names>AE</given-names></name><name><surname>Schwarz</surname><given-names>LA</given-names></name><name><surname>Totah</surname><given-names>NK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Redefining noradrenergic neuromodulation of behavior: Impacts of a modular locus coeruleus architecture</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>8239</fpage><lpage>8249</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1164-19.2019</pub-id><pub-id pub-id-type="pmid">31619493</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Schölvinck</surname><given-names>ML</given-names></name><name><surname>Mandelkow</surname><given-names>H</given-names></name><name><surname>Picchioni</surname><given-names>D</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Turchi</surname><given-names>JN</given-names></name><name><surname>Duyn</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Tracking brain arousal fluctuations with FMRI</article-title><source>PNAS</source><volume>113</volume><fpage>4518</fpage><lpage>4523</lpage><pub-id pub-id-type="doi">10.1073/pnas.1520613113</pub-id><pub-id pub-id-type="pmid">27051064</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clayton</surname><given-names>MS</given-names></name><name><surname>Yeung</surname><given-names>N</given-names></name><name><surname>Cohen Kadosh</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The many characters of visual alpha oscillations</article-title><source>The European Journal of Neuroscience</source><volume>48</volume><fpage>2498</fpage><lpage>2508</lpage><pub-id pub-id-type="doi">10.1111/ejn.13747</pub-id><pub-id pub-id-type="pmid">29044823</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic modulation of decision biases by brainstem arousal systems</article-title><source>eLife</source><volume>6</volume><elocation-id>e23232</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23232</pub-id><pub-id pub-id-type="pmid">28383284</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Pasquale</surname><given-names>F</given-names></name><name><surname>Della Penna</surname><given-names>S</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Lewis</surname><given-names>C</given-names></name><name><surname>Mantini</surname><given-names>D</given-names></name><name><surname>Marzetti</surname><given-names>L</given-names></name><name><surname>Belardinelli</surname><given-names>P</given-names></name><name><surname>Ciancetta</surname><given-names>L</given-names></name><name><surname>Pizzella</surname><given-names>V</given-names></name><name><surname>Romani</surname><given-names>GL</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Temporal dynamics of spontaneous MEG activity in brain networks</article-title><source>PNAS</source><volume>107</volume><fpage>6040</fpage><lpage>6045</lpage><pub-id pub-id-type="doi">10.1073/pnas.0913863107</pub-id><pub-id pub-id-type="pmid">20304792</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorris</surname><given-names>MC</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Activity in posterior parietal cortex is correlated with the relative subjective desirability of action</article-title><source>Neuron</source><volume>44</volume><fpage>365</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.09.009</pub-id><pub-id pub-id-type="pmid">15473973</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebitz</surname><given-names>RB</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Becket Ebitz</surname><given-names>R</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Selective modulation of the pupil light reflex by microstimulation of prefrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>5008</fpage><lpage>5018</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2433-16.2017</pub-id><pub-id pub-id-type="pmid">28432136</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ergenoglu</surname><given-names>T</given-names></name><name><surname>Demiralp</surname><given-names>T</given-names></name><name><surname>Bayraktaroglu</surname><given-names>Z</given-names></name><name><surname>Ergen</surname><given-names>M</given-names></name><name><surname>Beydagi</surname><given-names>H</given-names></name><name><surname>Uresin</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Alpha rhythm of the EEG modulates visual detection performance in humans</article-title><source>Cognitive Brain Research</source><volume>20</volume><fpage>376</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1016/j.cogbrainres.2004.03.009</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eysenck</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="1982">1982</year><chapter-title>Theories of arousal and performance</chapter-title><person-group person-group-type="editor"><name><surname>Eysenck</surname><given-names>MW</given-names></name></person-group><source>Attention and Arousal</source><publisher-name>Springer</publisher-name><fpage>47</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-68390-9_4</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foxe</surname><given-names>JJ</given-names></name><name><surname>Snyder</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The role of alpha-band brain oscillations as a sensory suppression mechanism during selective attention</article-title><source>Frontiers in Psychology</source><volume>2</volume><elocation-id>154</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2011.00154</pub-id><pub-id pub-id-type="pmid">21779269</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name><name><surname>Zhai</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Simulated power spectral density (PSD) of background electrocorticogram (ECOG</article-title><source>Cognitive Neurodynamics</source><volume>3</volume><fpage>97</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1007/s11571-008-9064-y</pub-id><pub-id pub-id-type="pmid">19003455</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldwater</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Psychological significance of pupillary movements</article-title><source>Psychological Bulletin</source><volume>77</volume><fpage>340</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1037/h0032456</pub-id><pub-id pub-id-type="pmid">5021049</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Hämäläinen</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>MNE software for processing MEG and EEG data</article-title><source>NeuroImage</source><volume>86</volume><fpage>446</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.027</pub-id><pub-id pub-id-type="pmid">24161808</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DG</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-name>Wiley &amp; Sons, Inc</publisher-name><pub-id pub-id-type="doi">10.1901/jeab.1969.12-475</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>J</given-names></name><name><surname>Kujala</surname><given-names>J</given-names></name><name><surname>Hamalainen</surname><given-names>M</given-names></name><name><surname>Timmermann</surname><given-names>L</given-names></name><name><surname>Schnitzler</surname><given-names>A</given-names></name><name><surname>Salmelin</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamic imaging of coherent sources: Studying neural interactions in the human brain</article-title><source>PNAS</source><volume>98</volume><fpage>694</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1073/pnas.98.2.694</pub-id><pub-id pub-id-type="pmid">11209067</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Händel</surname><given-names>BF</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Top-down controlled alpha band activity in somatosensory areas determines behavioral performance in a discrimination task</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>5197</fpage><lpage>5204</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5199-10.2011</pub-id><pub-id pub-id-type="pmid">21471354</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>BJ</given-names></name><name><surname>Zempel</surname><given-names>JM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The temporal structures and functional significance of scale-free brain activity</article-title><source>Neuron</source><volume>66</volume><fpage>353</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.04.020</pub-id><pub-id pub-id-type="pmid">20471349</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Scale-free brain activity: Past, present, and future</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>480</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.04.003</pub-id><pub-id pub-id-type="pmid">24788139</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hipp</surname><given-names>JF</given-names></name><name><surname>Hawellek</surname><given-names>DJ</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Large-scale cortical correlation structure of spontaneous oscillatory activity</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>884</fpage><lpage>890</lpage><pub-id pub-id-type="doi">10.1038/nn.3101</pub-id><pub-id pub-id-type="pmid">22561454</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>L</given-names></name><name><surname>Walz</surname><given-names>JM</given-names></name><name><surname>Sajda</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Your eyes give you away: Prestimulus changes in pupil diameter correlate with poststimulus task-related eeg dynamics</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e91321</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0091321</pub-id><pub-id pub-id-type="pmid">24618591</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iemi</surname><given-names>L</given-names></name><name><surname>Chaumon</surname><given-names>M</given-names></name><name><surname>Crouzet</surname><given-names>SM</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spontaneous neural oscillations bias perception by modulating baseline excitability</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>807</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1432-16.2016</pub-id><pub-id pub-id-type="pmid">28123017</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Mazaheri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Shaping functional architecture by oscillatory alpha activity: Gating by inhibition</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>186</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00186</pub-id><pub-id pub-id-type="pmid">21119777</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Bonnefond</surname><given-names>M</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>An oscillatory mechanism for prioritizing salient unattended stimuli</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>200</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.03.002</pub-id><pub-id pub-id-type="pmid">22436764</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil Diameter Predicts Changes in the Exploration-Exploitation Trade-off: Evidence for the Adaptive Gain Theory</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>1587</fpage><lpage>1596</lpage><pub-id pub-id-type="doi">10.1162/jocn.2010.21548</pub-id><pub-id pub-id-type="pmid">20666595</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jolly</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pymer4: Connecting R and Python for Linear Mixed Modeling</article-title><source>Journal of Open Source Software</source><volume>3</volume><elocation-id>862</elocation-id><pub-id pub-id-type="doi">10.21105/joss.00862</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil size as a window on neural substrates of cognition</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>466</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.005</pub-id><pub-id pub-id-type="pmid">32331857</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Pupil diameter and load on memory</article-title><source>Science</source><volume>154</volume><fpage>1583</fpage><lpage>1585</lpage><pub-id pub-id-type="doi">10.1126/science.154.3756.1583</pub-id><pub-id pub-id-type="pmid">5924930</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>SP</given-names></name><name><surname>Gomez-Ramirez</surname><given-names>M</given-names></name><name><surname>Foxe</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The strength of anticipatory spatial biasing predicts target discrimination at attended locations: A high-density EEG study</article-title><source>The European Journal of Neuroscience</source><volume>30</volume><fpage>2224</fpage><lpage>2234</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2009.06980.x</pub-id><pub-id pub-id-type="pmid">19930401</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Brascamp</surname><given-names>J</given-names></name><name><surname>Nuiten</surname><given-names>S</given-names></name><name><surname>Hoppenbrouwers</surname><given-names>S</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cognitive and ocular factors jointly determine pupil responses under equiluminance</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0155574</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0155574</pub-id><pub-id pub-id-type="pmid">27191166</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lefcheck</surname><given-names>JS</given-names></name><name><surname>Freckleton</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>piecewiseSEM : Piecewise structural equation modelling in r for ecology, evolution, and systematics</article-title><source>Methods in Ecology and Evolution</source><volume>7</volume><fpage>573</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.12512</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lendner</surname><given-names>JD</given-names></name><name><surname>Helfrich</surname><given-names>RF</given-names></name><name><surname>Mander</surname><given-names>BA</given-names></name><name><surname>Romundstad</surname><given-names>L</given-names></name><name><surname>Lin</surname><given-names>JJ</given-names></name><name><surname>Walker</surname><given-names>MP</given-names></name><name><surname>Larsson</surname><given-names>PG</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An electrophysiological marker of arousal level in humans</article-title><source>eLife</source><volume>9</volume><elocation-id>e55092</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55092</pub-id><pub-id pub-id-type="pmid">32720644</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Limbach</surname><given-names>K</given-names></name><name><surname>Corballis</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Prestimulus alpha power influences response criterion in a detection task</article-title><source>Psychophysiology</source><volume>53</volume><fpage>1154</fpage><lpage>1164</lpage><pub-id pub-id-type="doi">10.1111/psyp.12666</pub-id><pub-id pub-id-type="pmid">27144476</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name><name><surname>Nikulin</surname><given-names>VV</given-names></name><name><surname>Palva</surname><given-names>S</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Palva</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Prestimulus oscillations enhance psychophysical performance in humans</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>10186</fpage><lpage>10190</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2584-04.2004</pub-id><pub-id pub-id-type="pmid">15537890</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lowenstein</surname><given-names>O</given-names></name><name><surname>Feinberg</surname><given-names>R</given-names></name><name><surname>Loewenfeld</surname><given-names>IE</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Pupillary movements during acute and chronic fatigue: A new test for the objective evaluation of tiredness</article-title><source>Investigative Ophthalmology &amp; Visual Science</source><volume>2</volume><fpage>138</fpage><lpage>157</lpage></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>NA</given-names></name><name><surname>Kaplan</surname><given-names>HL</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Detection theory analysis of group data: estimating sensitivity from average hit and false-alarm rates</article-title><source>Psychological Bulletin</source><volume>98</volume><fpage>185</fpage><lpage>199</lpage><pub-id pub-id-type="pmid">4034817</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of eeg- and Meg-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Nestvogel</surname><given-names>DB</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neuromodulation of brain state and behavior</article-title><source>Annual Review of Neuroscience</source><volume>43</volume><fpage>391</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-100219-105424</pub-id><pub-id pub-id-type="pmid">32250724</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>David</surname><given-names>S</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Cortical Membrane Potential Signature of Optimal States for Sensory Signal Detection</article-title><source>Neuron</source><volume>87</volume><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.038</pub-id><pub-id pub-id-type="pmid">26074005</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Zagha</surname><given-names>E</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Waking state: Rapid variations modulate neural and behavioral responses</article-title><source>Neuron</source><volume>87</volume><fpage>1143</fpage><lpage>1161</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.012</pub-id><pub-id pub-id-type="pmid">26402600</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>O’Connell</surname><given-names>RG</given-names></name><name><surname>O’Sullivan</surname><given-names>M</given-names></name><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil diameter covaries with bold activity in human locus coeruleus</article-title><source>Human Brain Mapping</source><volume>35</volume><fpage>4140</fpage><lpage>4154</lpage><pub-id pub-id-type="doi">10.1002/hbm.22466</pub-id><pub-id pub-id-type="pmid">24510607</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakagawa</surname><given-names>S</given-names></name><name><surname>Johnson</surname><given-names>PCD</given-names></name><name><surname>Schielzeth</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The coefficient of determination r2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded</article-title><source>Journal of the Royal Society, Interface</source><volume>14</volume><elocation-id>20170213</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2017.0213</pub-id><pub-id pub-id-type="pmid">28904005</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Podvalny</surname><given-names>E</given-names></name><name><surname>Noy</surname><given-names>N</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Bickel</surname><given-names>S</given-names></name><name><surname>Chechik</surname><given-names>G</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A unifying principle underlying the extracellular field potential spectral responses in the human cortex</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>505</fpage><lpage>519</lpage><pub-id pub-id-type="doi">10.1152/jn.00943.2014</pub-id><pub-id pub-id-type="pmid">25855698</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Podvalny</surname><given-names>E</given-names></name><name><surname>Flounders</surname><given-names>MW</given-names></name><name><surname>King</surname><given-names>LE</given-names></name><name><surname>Holroyd</surname><given-names>T</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A dual role of prestimulus spontaneous neural activity in visual object recognition</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>3910</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-11877-4</pub-id><pub-id pub-id-type="pmid">31477706</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Powell</surname><given-names>MJD</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>An efficient method for finding the minimum of a function of several variables without calculating derivatives</article-title><source>The Computer Journal</source><volume>7</volume><fpage>155</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1093/comjnl/7.2.155</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahnev</surname><given-names>DA</given-names></name><name><surname>Bahdo</surname><given-names>L</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Prestimulus hemodynamic activity in dorsal attention network is negatively associated with decision confidence in visual perception</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>1529</fpage><lpage>1536</lpage><pub-id pub-id-type="doi">10.1152/jn.00184.2012</pub-id><pub-id pub-id-type="pmid">22723670</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Yatsenko</surname><given-names>D</given-names></name><name><surname>Denfield</surname><given-names>GH</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil fluctuations track fast switching of cortical states during quiet wakefulness</article-title><source>Neuron</source><volume>84</volume><fpage>355</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.033</pub-id><pub-id pub-id-type="pmid">25374359</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Rodenkirch</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13289</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id><pub-id pub-id-type="pmid">27824036</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadaghiani</surname><given-names>S</given-names></name><name><surname>Hesselmann</surname><given-names>G</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Distributed and antagonistic contributions of ongoing activity fluctuations to auditory stimulus detection</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>13410</fpage><lpage>13417</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2592-09.2009</pub-id><pub-id pub-id-type="pmid">19846728</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadaghiani</surname><given-names>S</given-names></name><name><surname>Scheeringa</surname><given-names>R</given-names></name><name><surname>Lehongre</surname><given-names>K</given-names></name><name><surname>Morillon</surname><given-names>B</given-names></name><name><surname>Giraud</surname><given-names>A-L</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Intrinsic connectivity networks, alpha oscillations, and tonic alertness: A simultaneous electroencephalography/functional magnetic resonance imaging study</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>10243</fpage><lpage>10250</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1004-10.2010</pub-id><pub-id pub-id-type="pmid">20668207</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadaghiani</surname><given-names>S</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Brain networks and α-oscillations: Structural and functional foundations of cognitive control</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>805</fpage><lpage>817</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.09.004</pub-id><pub-id pub-id-type="pmid">27707588</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samaha</surname><given-names>J</given-names></name><name><surname>Iemi</surname><given-names>L</given-names></name><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Spontaneous brain oscillations and perceptual decision-making</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>639</fpage><lpage>653</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.05.004</pub-id><pub-id pub-id-type="pmid">32513573</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>M</given-names></name><name><surname>Hathway</surname><given-names>P</given-names></name><name><surname>Leuchs</surname><given-names>L</given-names></name><name><surname>Sämann</surname><given-names>PG</given-names></name><name><surname>Czisch</surname><given-names>M</given-names></name><name><surname>Spoormaker</surname><given-names>VI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spontaneous pupil dilations during the resting state are associated with activation of the Salience network</article-title><source>NeuroImage</source><volume>139</volume><fpage>189</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.06.011</pub-id><pub-id pub-id-type="pmid">27291493</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Seabold</surname><given-names>S</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><conf-name>Statsmodels: Econometric and statistical modeling with Python</conf-name><article-title>Proceedings of the 9th Python in Science conference</article-title></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sederberg</surname><given-names>AJ</given-names></name><name><surname>Pala</surname><given-names>A</given-names></name><name><surname>Zheng</surname><given-names>HJ</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name><name><surname>Stanley</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>State-aware detection of sensory stimuli in the cortex of the awake mouse</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006716</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006716</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shine</surname><given-names>JM</given-names></name><name><surname>Bissett</surname><given-names>PG</given-names></name><name><surname>Bell</surname><given-names>PT</given-names></name><name><surname>Koyejo</surname><given-names>O</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Moodie</surname><given-names>CA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The dynamics of functional brain networks: Integrated network states during cognitive task performance</article-title><source>Neuron</source><volume>92</volume><fpage>544</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.018</pub-id><pub-id pub-id-type="pmid">27693256</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shine</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuromodulatory influences on integration and segregation in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>572</fpage><lpage>583</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.04.002</pub-id><pub-id pub-id-type="pmid">31076192</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Attention and luminance detection: Effects of cues, masks, and pedestals</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>26</volume><fpage>1401</fpage><lpage>1420</lpage><pub-id pub-id-type="doi">10.1037//0096-1523.26.4.1401</pub-id><pub-id pub-id-type="pmid">10946722</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Zatka-Haas</surname><given-names>P</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title><source>Nature</source><volume>576</volume><fpage>266</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1787-x</pub-id><pub-id pub-id-type="pmid">31776518</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stitt</surname><given-names>I</given-names></name><name><surname>Zhou</surname><given-names>ZC</given-names></name><name><surname>Radtke-Schuller</surname><given-names>S</given-names></name><name><surname>Fröhlich</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Arousal dependent modulation of thalamo-cortical functional interaction</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2455</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04785-6</pub-id><pub-id pub-id-type="pmid">29941957</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szerb</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Cortical acetylcholine release and electroencephalographic arousal</article-title><source>The Journal of Physiology</source><volume>192</volume><fpage>329</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1967.sp008303</pub-id><pub-id pub-id-type="pmid">6050151</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turchi</surname><given-names>J</given-names></name><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Russ</surname><given-names>BE</given-names></name><name><surname>Yu</surname><given-names>DK</given-names></name><name><surname>Cortes</surname><given-names>CR</given-names></name><name><surname>Monosov</surname><given-names>IE</given-names></name><name><surname>Duyn</surname><given-names>JH</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The basal forebrain regulates global resting-state fmri fluctuations</article-title><source>Neuron</source><volume>97</volume><fpage>940</fpage><lpage>952</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.032</pub-id><pub-id pub-id-type="pmid">29398365</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uematsu</surname><given-names>A</given-names></name><name><surname>Tan</surname><given-names>BZ</given-names></name><name><surname>Ycu</surname><given-names>EA</given-names></name><name><surname>Cuevas</surname><given-names>JS</given-names></name><name><surname>Koivumaa</surname><given-names>J</given-names></name><name><surname>Junyent</surname><given-names>F</given-names></name><name><surname>Kremer</surname><given-names>EJ</given-names></name><name><surname>Witten</surname><given-names>IB</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Johansen</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Modular organization of the brainstem noradrenaline system coordinates opposing learning states</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1602</fpage><lpage>1611</lpage><pub-id pub-id-type="doi">10.1038/nn.4642</pub-id><pub-id pub-id-type="pmid">28920933</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Brink</surname><given-names>RL</given-names></name><name><surname>Pfeffer</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brainstem modulation of large-scale intrinsic cortical activity correlations</article-title><source>Frontiers in Human Neuroscience</source><volume>13</volume><elocation-id>340</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2019.00340</pub-id><pub-id pub-id-type="pmid">31649516</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Dijk</surname><given-names>H</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Prestimulus oscillatory activity in the alpha band predicts visual discrimination ability</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>1816</fpage><lpage>1823</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1853-07.2008</pub-id><pub-id pub-id-type="pmid">18287498</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kempen</surname><given-names>J</given-names></name><name><surname>Loughnane</surname><given-names>GM</given-names></name><name><surname>Newman</surname><given-names>DP</given-names></name><name><surname>Kelly</surname><given-names>SP</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>O’Connell</surname><given-names>RG</given-names></name><name><surname>Bellgrove</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Behavioural and neural signatures of perceptual decision-making are modulated by pupil-linked arousal</article-title><source>eLife</source><volume>8</volume><elocation-id>e42541</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.42541</pub-id><pub-id pub-id-type="pmid">30882347</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Vliet</surname><given-names>M</given-names></name><name><surname>Liljeström</surname><given-names>M</given-names></name><name><surname>Aro</surname><given-names>S</given-names></name><name><surname>Salmelin</surname><given-names>R</given-names></name><name><surname>Kujala</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Analysis of functional connectivity and oscillatory power using dics: From raw MEG data to group-level statistics in Python</article-title><source>Frontiers in Neuroscience</source><volume>12</volume><elocation-id>586</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2018.00586</pub-id><pub-id pub-id-type="pmid">30271317</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id><pub-id pub-id-type="pmid">25892300</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voytek</surname><given-names>B</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Prefrontal cortex and basal ganglia contributions to visual working memory</article-title><source>PNAS</source><volume>107</volume><fpage>18167</fpage><lpage>18172</lpage><pub-id pub-id-type="doi">10.1073/pnas.1007277107</pub-id><pub-id pub-id-type="pmid">20921401</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname><given-names>CM</given-names></name><name><surname>Eldar</surname><given-names>E</given-names></name><name><surname>van den Brink</surname><given-names>RL</given-names></name><name><surname>Tona</surname><given-names>K-D</given-names></name><name><surname>van der Wee</surname><given-names>NJ</given-names></name><name><surname>Giltay</surname><given-names>EJ</given-names></name><name><surname>van Noorden</surname><given-names>MS</given-names></name><name><surname>Bosch</surname><given-names>JA</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Catecholamine-mediated increases in gain enhance the precision of cortical representations</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>5699</fpage><lpage>5708</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3475-15.2016</pub-id><pub-id pub-id-type="pmid">27225761</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waschke</surname><given-names>L</given-names></name><name><surname>Tune</surname><given-names>S</given-names></name><name><surname>Obleser</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Local cortical desynchronization and pupil-linked arousal differentially shape brain states for optimal sensory performance</article-title><source>eLife</source><volume>8</volume><elocation-id>e51501</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51501</pub-id><pub-id pub-id-type="pmid">31820732</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>AB</given-names></name><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Quest: A bayesian adaptive psychometric method</article-title><source>Perception &amp; Psychophysics</source><volume>33</volume><fpage>113</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.3758/bf03202828</pub-id><pub-id pub-id-type="pmid">6844102</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Tallon-Baudry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>How ongoing fluctuations in human visual cortex predict perceptual awareness: Baseline shift versus decision bias</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>8715</fpage><lpage>8725</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0962-09.2009</pub-id><pub-id pub-id-type="pmid">19587278</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yellin</surname><given-names>D</given-names></name><name><surname>Berkovich-Ohana</surname><given-names>A</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Coupling between pupil fluctuations and resting-state fmri uncovers a slow build-up of antagonistic responses in the human cortex</article-title><source>NeuroImage</source><volume>106</volume><fpage>414</fpage><lpage>427</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.11.034</pub-id><pub-id pub-id-type="pmid">25463449</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Sabuncu</surname><given-names>MR</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Hollinshead</surname><given-names>M</given-names></name><name><surname>Roffman</surname><given-names>JL</given-names></name><name><surname>Smoller</surname><given-names>JW</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><pub-id pub-id-type="pmid">21653723</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yerkes</surname><given-names>RM</given-names></name><name><surname>Dodson</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1908">1908</year><article-title>The relation of strength of stimulus to rapidity of habit-formation</article-title><source>Journal of Comparative Neurology and Psychology</source><volume>18</volume><fpage>459</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1002/cne.920180503</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yüzgeç</surname><given-names>Ö</given-names></name><name><surname>Prsa</surname><given-names>M</given-names></name><name><surname>Zimmermann</surname><given-names>R</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupil size coupling to cortical states protects the stability of deep sleep via parasympathetic modulation</article-title><source>Current Biology</source><volume>28</volume><fpage>392</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.12.049</pub-id><pub-id pub-id-type="pmid">29358069</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.68265.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role>Reviewing Editor</role><aff><institution>University of Lübeck</institution><country>Germany</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>de Gee</surname><given-names>Jan Willem</given-names></name><role>Reviewer</role><aff><institution>Baylor College of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>David</surname><given-names>Stephen</given-names></name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This study takes a comprehensive look at the relationship between pupil-indexed arousal and cortical MEG activity and performance on a demanding sensory behaviour in humans subjects. Understanding how pupil activity, widely interpreted as a proxy of arousal, ties in with the dynamics of neural activity and behaviour is a key challenge in systems and cognitive neuroscience. The authors identified a widespread component of cortical activity that can be explained by changes in pupil dilation and which in turn predicts performance in participants' decision-making. This work will help build an important bridge between animal models of arousal and human cognition and behaviour.</p><p><bold>Decision letter after peer review:</bold></p><p>[Editors’ note: the authors submitted for reconsideration following the decision after peer review. What follows is the decision letter after the first round of review.]</p><p>Thank you for submitting your work entitled &quot;Spectral signature and behavioral consequence of spontaneous shifts of pupil-linked arousal in human&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and a Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Jan Willem de Gee (Reviewer #3).</p><p>Our decision has been reached after consultation between the reviewers.</p><p>The reviewers and editors felt that this manuscript aims at offering important insights. First, brain-wide relationships across a wide range of spectra have only rarely been tested in humans. Second, testing direct and indirect links between baseline pupil size, spectral power and behaviour, separately, has not been done before in humans, to the best of our knowledge. Finally, the authors try to combine and compare the behavioural relevance of slow as well as fast pupil size fluctuations, linking to previous research in non-human animals.</p><p>Our enthusiasm was tempered, however, as the methodical issues raised by all reviewers are substantial. The editors were not convinced that these are outweighed by the potential advance in the results. The main concerns tie into issues raised by all reviewers about what appear to us as somewhat arbitrary decisions in how the models were formulated. The individual reviews, attached below, will delineate these concerns in greater detail.</p><p><italic>Reviewer #3:</italic></p><p>I think this is an important paper. The characterization of the relationship between baseline pupil size and large-scale cortical spectral power across a wide range of frequencies (localized using Dynamic Imaging of Coherent Sources) is state of the art and novel. However, I do have a number of serious issues with the methods. I expect at least some of the results will change when the authors address these.</p><p>I have a number of issues about the mixed effects modeling.</p><p>– The authors write that they only considered random intercepts, and not random slopes. Why? See for example Barr et al., Journal of Memory and Language, 2013. I believe two common approaches to keep the random structure maximal (random intercepts and random slopes) are: (i) fit the model with the maximal random structure, and stick to that model if it converges, (ii) start with the maximal random structure, and formally compare that model (with AIC/BIC) to models in which you drop one random factor at a time and choose the model with the lowest AIC/BIC.</p><p>– Since the authors compare models, I think they were not fitted through restricted maximum likelihood estimation (REML); what method did they use?</p><p>– I think it's commendable that the authors considered quadratic models. However, I think they should formally test whether adding a quadratic component significantly improves the fit (via AIC/BIC), and present result accordingly.</p><p>– I'm confused about the way &quot;residual pupil size&quot; is calculated. Why is it necessary to first fit a group level model, and then a subject-level? Why not do subject-level directly? Furthermore, it seems very award to not regress out the quadratic relationships here, as we have learned that they are important. I understand the multicollinearity problem, but there may be a more elegant way to deal with this?</p><p>I think that the question whether &quot;the effect of baseline pupil state (a peripheral marker of arousal) on perceptual behavior is mediated by the shift in cortical spectral power (a central marker of arousal)&quot; is important. However, I think that the partial correlation approach they use is not ideal to answer this question. Have the authors instead considered to perform an actual mediation analysis? If they want to stick to partial correlation, I think they should do proper partial correlation, and not only regress out cortical spectral power from baseline pupil size, but also from their behavioral metrics, and only then compute the residual relationship between pupil and behavior.</p><p>Eyelink records pupil data in arbitrary units. How did the authors meaningfully pool &quot;slow states&quot; across different experimental runs? Z-scoring does not do the trick here. For example, a pupil that is consistently large all the time will result in slow states close to Z=0. Also, strong slow drift results in a large standard deviation, and will push the z-scores down, which is precisely not what you want in that case. Related, why are the units in Figure 3B (z-score) different than in Figure 4C,D (%). In the latter case, % of what?</p><p>Are results the same after excluding slow states including blinks? I understand that the authors used ICA to remove blink-related artifacts from the MEG data. However, blinks also cause relatively large transient pupil constrictions (Knapen et al., PLOS ONE, 2016), which will work into the 2-s averages. Related, how often did subjects blink? From Figure 1D it seems about 10 times per minute, which means that 33% of &quot;slow states&quot; might be affected. Finally, why did the authors not use the blink onset and offset timestamps provided by Eyelink? I'm asking because using a constant threshold will miss partial blinks. If the authors want to detect blinks themselves, they should do so based on outliers in the first derivative of the pupil time series.</p><p>I think the authors should better integrate their findings with the existing literature, and be more precise with their citations:</p><p>– Line 42: &quot;and animals&quot; -&gt; ref. 7 should be cited here as well.</p><p>– Line 54: &quot;across a wide range of frequencies&quot; -&gt; ref. 14 did, albeit only in auditory cortex.</p><p>– Line 96: &quot;play a functional role in behavior&quot; -&gt; ref. 15, 41 should be cited, and see also de Gee et al., PNAS, 2014; de Gee et al., <italic>eLife</italic>, 2020; Krishnamurthy et al., NHB, 2017; Urai et al., Nat Comm, 2017.</p><p>– Line 322: &quot;limited data is available in humans&quot; -&gt; ref. 41 should be cited.</p><p>– Line 326: &quot;deserved further investigation&quot; -&gt; ref. 41 should be cited.</p><p><italic>Reviewer #4:</italic></p><p>Podvalny and colleagues investigate the links between spontaneous variations in arousal, as indexed by varying pupil size, and spectral power as well as perceptual decision performance. The study represents extends previous work in non-human animals, initial findings in humans, and improves our understanding of behaviourally relevant changes in arousal and their effects on mesoscopic measures of brain activity (M/EEG). Despite these valuable contributions to the field, central results hinge on methodical approaches that are potentially problematic. In addition to these methodical issues, the transparency and clarity with which results are presented should be improved.</p><p>1) Linear mixed effect models:</p><p>Although I applaud the general approach of fitting linear mixed effect models to neural and behavioural data, the exact implementation in the current manuscript could be improved and is potentially problematic. First of all, it remains unclear why the authors do not use the potential of LMMs and also fit random slopes to test effects on the single subject level. This is only carried out to partialize pupil size and spectral power, respectively, but not in any models that concern behaviour or the link between spectral power and pupil size. Is there a reason the authors did not fit random slopes? I advocate for the inclusion of random slopes (depending on the model fit) for variables of interest and the inclusion of single subject estimates in all figures. If random slopes for all predictors within the same model lead to convergence issues or problematic model fit, the use of multiple models that only differ in their random slopes (e.g., pupil or spectral power) is acceptable. In this context, it seems to me as if the authors never model behaviour as a joint function of pupil size and spectral power. I strongly suggest to include both spectral power and pupil size in models of behaviour to account for shared variance in the dependent variable of interest (e.g. hit rate or false alarm rate). Furthermore, although the comparison of purely linear and quadratic (including a linear term) models represents an aptly chosen approach, the authors should handle their inferences regarding these model terms with great care and report them more cautiously. Figure 4C for example features visualized quadratic trends that do not represent significant model terms (e.g., sensitivity, response times, etc.). It should be made very clear to the reader that these quadratic effects do not explain additional variance in behaviour and do not fit the data well. In addition, in models where quadratic trends explain significant portions of variance, linear and quadratic effects should be compared directly (e.g., Wald-z statistic) and the results of these comparisons should be reported. Only this way, readers can be able to judge whether linear or quadratic trends are pervasive in a certain relationship. On another note, it is unclear to me if the model coefficients that are presented (e.g., Figure 5) represent standardized betas. If this is the case, they can also work as effect size estimates and an intuitive interpretation should be offered (e.g., &quot;one unit change in pupil size coincides with x…&quot;).</p><p>2) Stats reporting:</p><p>Although the authors have included tables in their manuscript, essential test statistics should be reported within the main text (estimates, confidence intervals, p-values). Despite some p-values, this is missing entirely and should be added. Additionally, I suggest to report standardized effect size estimates to allow for an intuitive interpretation of results. Furthermore, it would be important to note how much variance in brain, behavioural, or pupil data were explained by the winning models. Maybe I have missed this information, if not, it should be added.</p><p>3) Stimulus category decoding:</p><p>While this is an elegant approach to study the representation of sensory stimuli within neural data and compare them across conditions, the employed chance level is problematic. While it is true that 25% represents the theoretical chance level in a case where four alternatives are discriminated, this is only true for infinite numbers of trials – or at least large datasets (Combrisson et al., 2015, JNeuroMeth). If I understood the approach of bin-wise leave-one out classification correctly, each bin contained about 70 trials. In this case, the empirical chance rate can be calculated as Emp_chance = binoinv(1-α,n_trials,1/n_classes)/n_trials; Where α corresponds to the desired significance level (.05), n_trials to the number of trials and n_classes (4) to the number of possible outcomes. Using this approach, an empirical chance level of 34.2 % is calculated which clearly differs from the theoretical level 0f 25 %. I suggest to either test against the empirical chance level or establish a noise distribution of prediction accuracies using permutations, against which to test.</p><p><italic>Reviewer #5:</italic></p><p>The study by Podvalny et al. measured the relationship between pupil diameter and cortical spectral power, assessing how they provide overlapping versus complementary indices of brain state. The authors used regression analysis to identify relationships between spontaneous, pre-stimulus fluctuations in pupil and MEG spectral power and performance on a visual discrimination task. The analysis revealed correlations between pupil and cortical spectral power but also unique variance between each of these signals and task performance. The experiments and data are novel and are nicely designed and executed. While the results are interesting, they appear in many cases to replicate previous findings. It would help if the authors could more clearly explain the gaps the new results fill in the existing literature.</p><p>1. The authors cite work several previous studies in human (Washke et al., Van Kempen et al., de Gee et al) and animal (McGinley et al., Joshi et al., Reimer et al) that explored similar questions and appear to be largely consistent with the current data. This study does appear make a few new comparisons and identifies some differences with the previous work, but the new results appear as a scattered list of observations throughout the discussion. The main observation of explanatory overlap between pupil and cortical spectral power appears to be a replication. It would help if the authors could clarify the novelty of their main results.</p><p>2. The modeling results could be presented more clearly. While the general methodology appears sound, it is difficult to discern what aspects of the cortical spectral power are shared with pupil versus not. For example, would it be possible to contrast coefficients for the pupil-independent spectral power model (Figure 5) with coefficients for a model without removing pupil? This information is available in some form in Figures 3 and 4, but it is unclear if and how the units of these different models can be compared. It seems like there should be a unified way to present the joint versus unique contributions of the pupil and MEG signals in terms of variance explained, which would make the results much easier to digest. Without a more comprehensive summary, the results appear as mostly disparate observations.</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Spectral signature and behavioral consequence of spontaneous shifts of pupil-linked arousal in human&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Joshua Gold (Senior Editor), a Reviewing Editor, the original reviewers, and a new reviewer.</p><p>This study takes a comprehensive look at the relationship between pupil-indexed arousal and cortical MEG activity and performance on a demanding sensory behavior in humans subjects. Understanding how pupil activity, widely interpreted as a marker of arousal, relates to cortical activity, is a key challenge in systems and cognitive neuroscience. The authors identified a widespread component of cortical activity that can be explained by changes in pupil and that predict performance on a behavioral task. This work helps build an important bridge between animal models of arousal and human cognitive behavior.</p><p>Essential revisions:</p><p>Presentation of single subject data (as per Rev #1).</p><p>1) Presentation of effect sizes and explained variance (as per Rev #1).</p><p>2) Are pupil-related effects really essentially uniform across the cortex? Or are the differences really the important thing? It would be nice if this could be addressed even briefly in the Discussion. (as per Rev #3)</p><p>3) Since the present analysis is focused on quantifying pupil size it is important to account for other factors which might affect measured pupil size, notably, fixation and saccades. The section devoted to detailing the analysis of the pupil data omits any discussion of these factors. Did the authors check that fixation is maintained at all times? Were periods associated with saccades away from fixation (which will result in apparent changes to pupil size) removed from the analysis? (as per Rev #4)</p><p>4) The analysis of &quot;fast events&quot; was not very clear to us (as per Rev #4, please follow the details for an additional/re-analysis there):</p><p>a) we are worried about the low-pass filter and a potential acausal smearing it might have contributed.</p><p>b) The statement (line 492) &quot;to be considered a peak/through, the data point should have highest/lowest amplitude within 500 ms vicinity&quot; was also not clear. It would be helpful if you plotted (or reported) the duration distribution of the events you ended up analyzing (as per Rev #4, see details also below).</p><p><italic>Reviewer #1:</italic></p><p>The authors have revised large parts of their manuscript and addressed most comments.</p><p>However, two of my previous concerns have not been resolved entirely.</p><p>1) Presentation of single subject data.</p><p>The authors argue that this is not feasible as it would require to plot more than 8000 data points. This likely is a misunderstanding. While it is true that plotting single subject points for all power / frequency / ROI bins is not feasible, this is not what I asked for. Take figure 3B as an example. In every panel, the authors plot spectral power (in bins) as a function of pupil size (in bins). They plot one data point per bin (with an error bar around it). If I am not entirely mistaken, this data point represents the group average. It is essential, however, to show single subject data at this point. What speaks against plotting a cloud of N=24 dots around their mean instead of each dot? I realize that this might take up a bit more space but I am convinced that this is an essential service to every reader. Importantly, the same comment applies to figure panels 4C, 4D, and 4E.</p><p>2) Effect sizes and explained variance</p><p>While it is true that the concept of variance is explained is not easily transferred to the world of linear mixed models, it is entirely possible to offer such an estimate, both for linear mixed models as well as generalized mixed models. Even if imperfect, such an approximation represents an important piece of information since it puts the models in perspective to the space they were trying to capture. I allow myself to recommend the excellent R-package lme4 which allows the fitting of such models and in combination with functions from the sj_plot package (e.g., tab_model) offers all relevant information. I am sure transferring their models from python to R should be a simple task for the authors.</p><p>Furthermore, I suggest to offer an explicit discussion of model fits and effect sizes which is missing in the current version of the manuscript. The supplementary tables illustrate that effects rather are small and likely don't account for large parts of variance in the data. This does not have to be an issue but it should be acknowledged prominently and discussed.</p><p><italic>Reviewer #2:</italic></p><p>The authors have performed a thorough revision and addressed my concerns. I have no remaining issues.</p><p><italic>Reviewer #3:</italic>The authors were responsive to all the concerns raised in the initial review. The revised manuscript clarifies the significance of the work and more rigorously identifies the link between pupil size, cortical activity and task performance.Overall, the manuscript looks great. Just a small lingering question. The effects in Figure 3 appear strikingly consistent across brain networks, and any differences appear to be quantitative more than qualitative (ie, even where a quadratic effect may not be significant, one can still see a trend that is consistent with networks showing a quadratic effect). Does this mean that pupil-related effects are more or less uniform across the cortex? Or are the differences really the important thing? It would be nice if this could be addressed even briefly in the Discussion.</p><p><italic>Reviewer #4:</italic></p><p>I joined the review process at the revision stage. I did not read the previous version of the manuscript or the rebuttal later in order to form an unbiased view of the work.</p><p>1) The experiment is quite long (over an hour and a half). In addition to task related effort, experimental length can have consequences for pupil dynamics due to effort related to maintain fixation and accommodation. It is critical that the authors demonstrate that pre-stimulus pupil size is not correlated with time within the experiment.</p><p>2) Similarly, since the present analysis is focused on quantifying pupil size it is important to account for other factors which might affect measured pupil size, notably, fixation and saccades. The section devoted to detailing the analysis of the pupil data omits any discussion of these factors. Did the authors check that fixation is maintained at all times? Were periods associated with saccades away from fixation (which will result in apparent changes to pupil size) removed from the analysis?</p><p>3) The analysis of &quot;fast events&quot; was not very clear to me.</p><p>a) Why was a low pass filter applied to the data before identifying the phasic events? Wouldn't a low pass filter smear the timing of these events? Depending on the filter (no details are provided) this could result in latency shifts on the order of 200ms, making the &quot;fast event&quot; analysis (Figure 6) difficult to interpret.</p><p>b) The statement (line 492) &quot;to be considered a peak/through, the data point should have highest/lowest amplitude within 500 ms vicinity&quot; was also not clear. It would be helpful if you plotted (or reported) the duration distribution of the events you ended up analyzing and maybe follow the analysis approach as used in e.g. Joshi et al. (2016; Neuron) where phasic events are defined as zero-crossings of the pupil slope separated by {greater than or equal to}75 ms. This will make it easier to relate your findings to the literature on phasic pupil responses.</p><p>4) Analysis in Figure 6 (and page 12).</p><p>a) Why was a Pearson and not spearman correlation used? The latter is less sensitive to outliers and would provide stronger evidence for the claims the authors wish to make.</p><p>b) Panel C: I am a bit confused by the example of identified pupil events provided. In the methods you state that you defined dilation/constriction events as having a duration of at most 500 ms. But from eye balling the figure the first dilation event (left most blue dot) appears to last more than a second? (Similarly the right most blue dot in the plot).</p><p>c) I would like to see more discussion of the shape of the patter of MEG activity triggered by the pupil events. I found the pattern extremely surprising. e.g. that the sharp peak/trough exactly coincides with 0; is it possible that the preceding peak at ~-400 relates to a previous dilation/constriction event? I would appreciate more detailed discussion of what this all means. Similarly the pattern of correlation across channels looks quite systematic. Did the authors try to source localize this pattern?</p><p>Other points</p><p>1) It is stated that sensitivity (d') is related to prestimulus size in an inverted U-shaped relationship. This is not obvious at all from looking at the data points in the figure. Instead the behavioral performance appears to not differ much for pupil bins 2-5.</p><p>2) I understand it is difficult to control in the present experiment, but doesn't a larger pupil also imply stronger visual input? Would this be able to explain the largely linear link between pupil size and brain activity in the β and γ ranges?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.68265.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the authors resubmitted a revised version of the paper for consideration. What follows is the authors’ response to the first round of review.]</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>I think this is an important paper. The characterization of the relationship between baseline pupil size and large-scale cortical spectral power across a wide range of frequencies (localized using Dynamic Imaging of Coherent Sources) is state of the art and novel. However, I do have a number of serious issues with the methods. I expect at least some of the results will change when the authors address these.</p></disp-quote><p>We thank the reviewer for recognizing the importance of our study. The methodological issues raised by the reviewer have now been fully addressed, as explained below.</p><disp-quote content-type="editor-comment"><p>I have a number of issues about the mixed effects modeling.</p><p>– The authors write that they only considered random intercepts, and not random slopes. Why? See for example Barr et al., Journal of Memory and Language, 2013. I believe two common approaches to keep the random structure maximal (random intercepts and random slopes) are: (i) fit the model with the maximal random structure, and stick to that model if it converges, (ii) start with the maximal random structure, and formally compare that model (with AIC/BIC) to models in which you drop one random factor at a time and choose the model with the lowest AIC/BIC.</p></disp-quote><p>We now followed suggestion (i) by the reviewer – the models converged in the vast majority of cases.</p><p>The methods section on “Statistical modeling” (PP. 20-21) has been thoroughly updated. E.g., we explain:</p><p>“We used LMMs with the maximal random effects structure justified by the design (Barr et al., 2013).”</p><p>The equations for the LMM models (Equation 3-6) have been expanded to include the random intercepts (ℓ<sub>!&quot;</sub>), random slopes (ℓ<sub>#&quot;</sub>) and random-effects quadratic coefficients (ℓ<sub>$&quot;</sub>). In Equation 3-4, because spectral power was demeaned before the analysis, random intercepts were 0 and thus omitted from the equation.</p><p>Figure 3B-C, Figure 4C-D, Figure 5, Supplementary figure 1, Table 1, Supplementary tables 1-2 have been updated along with the corresponding Results sections.</p><p>The results remained qualitatively similar: first, spontaneous fluctuations in pupil size were significantly associated with power fluctuations in most resting state networks and frequency bands (Figure 3B-C); second, spontaneous fluctuations in pupil size before stimulus onset predicted behavior (Figure 4C-D); third, residual power unpredicted by pupil-linked arousal had additional effects on behavior (Figure 5).</p><disp-quote content-type="editor-comment"><p>– Since the authors compare models, I think they were not fitted through restricted maximum likelihood estimation (REML); what method did they use?</p></disp-quote><p>We now use the standard (not restricted) likelihood in all cases, as clarified in Methods (lines 541-542):</p><p>“The models were fit using Powell’s algorithm (Powell, 1964) minimizing standard (rather than restricted) likelihood to assure the meaningful information criterion calculation”.</p><disp-quote content-type="editor-comment"><p>– I think it's commendable that the authors considered quadratic models. However, I think they should formally test whether adding a quadratic component significantly improves the fit (via AIC/BIC), and present result accordingly.</p></disp-quote><p>Following the reviewer’s suggestion, in Figure 3B-C and Supplementary Figure 1, we now only present the winning models. That is, models with quadratic components are now only plotted if their BIC values are lower than the corresponding linear models (lines 124-129):</p><p>“We fit two types of models, one with both linear and quadratic components (Equation 3, Methods), […] and one with a linear component only (Equation 4, Methods) for comparison. Figure 3B presents the fitted curves from the task baseline data (similar plots from rest are shown in Supplementary Figure 1) for the models with lower BIC, and Figure 3C presents the linear parameter estimates for both task baseline and rest, and a quadratic parameter estimate in case the model that included this parameter was preferred according to BIC” .</p><p>In Figure 4C-D, to facilitate comparison with earlier studies that have reported both linear and quadratic relationships between pupil size and perceptual behavior, we present both models with and without the quadratic component as long as the parameter estimates are significant. We further report the full statistics for each model and their BIC values in Table 1 and in lines 186-188:</p><p>“Previous studies reported linear and/or quadric models fitting such behavioral metrics and task-evoked pupil responses(de Gee et al., 2017; McGinley et al., 2015; Waschke et al., 2019) and, accordingly, we also report the results of both model types to allow comparison (see Methods, Equation 5-6).”</p><disp-quote content-type="editor-comment"><p>– I'm confused about the way &quot;residual pupil size&quot; is calculated. Why is it necessary to first fit a group level model, and then a subject-level? Why not do subject-level directly? Furthermore, it seems very award to not regress out the quadratic relationships here, as we have learned that they are important. I understand the multicollinearity problem, but there may be a more elegant way to deal with this?</p></disp-quote><p>We originally fit the model on the group level to select a set of regressors which subsequently would be shared by the individual subjects to increase interpretability and reproducibility. The selection process was needed to attempt to solve the multicollinearity problem because the whole-brain model including all RSNs and frequency bands produced a large number of correlated regressors. However, because of the issue with quadratic relationships raised by the reviewer, we have decided to remove this analysis (originally presented in Supplementary figure 4) and instead introduce a new analysis testing whether pupil size contains additional information that contributes to the prediction of “yes”/”no” reports on a single-trial level (new Figure 5A, and see more details in the point below). In this new analysis, residual power was calculated by using either the linear or the quadratic model—selected for individual subjects based on BIC (explained on lines 566-569).</p><disp-quote content-type="editor-comment"><p>I think that the question whether &quot;the effect of baseline pupil state (a peripheral marker of arousal) on perceptual behavior is mediated by the shift in cortical spectral power (a central marker of arousal)&quot; is important. However, I think that the partial correlation approach they use is not ideal to answer this question. Have the authors instead considered to perform an actual mediation analysis? If they want to stick to partial correlation, I think they should do proper partial correlation, and not only regress out cortical spectral power from baseline pupil size, but also from their behavioral metrics, and only then compute the residual relationship between pupil and behavior.</p></disp-quote><p>Because the behavioral metrics (e.g., d’, c, hit rate and false alarm rates) are calculated on groups of trials (instead of single trials), it is unfortunately not possible to regress out the cortical power from behavioral metrics as the reviewer suggested. We have now removed the analysis of residual pupil-linked arousal and included a new analysis testing whether pupil size contains additional information that contributes to the prediction of “yes”/”no” reports on a single-trial level beyond information contained in cortical spectral power (new Figure 5A; described in lines 218-231):</p><p>“To understand the respective contributions of spectral power that can be explained by pupil-linked arousal (Figures 2-3) and of spectral power independent of arousal to perceptual behavior, we first fit logistic regression models predicting “yes”/”no” recognition behavior from baseline fluctuations of spectral power in all frequency bands and RSNs only (“power only”), models with pupil size in addition (“pupil and power”), models using residual power independent of pupil size (“residual power”) and models with pupil size as a single feature (“pupil only”) (Figure 5A, see Methods). The residual power was calculated by first fitting LMM models for each frequency band and each RSN for each participant, whereby the model with lower BIC at the group level was chosen between Equation 3 and Equation 4 (see Methods, Table 1). We find that all logistic regression models predict “yes”/”no” behavior better than chance (permutation test, p&lt;0.05 FDR corrected). Interestingly, the performance of “power only” model does not improve by adding pupil size information (W = 143, p = 0.86, Wilcoxon signed-rank test), but the performance is worsened by regressing out the pupil-linked spectral power (W = 241, p = 0.008, Wilcoxon signed-rank test). These results indicate that both arousal-linked and arousal-independent spectral power fluctuations at baseline predict subsequent recognition behavior, but our recordings of pupil size did not provide additional information contributing to the prediction of behavior that was not already present in cortical spectral power.”</p><p>This new analysis confirms our main conclusion that both arousal-linked and arousal-independent spectral power fluctuations at baseline predict subsequent recognition behavior.</p><disp-quote content-type="editor-comment"><p>Eyelink records pupil data in arbitrary units. How did the authors meaningfully pool &quot;slow states&quot; across different experimental runs? Z-scoring does not do the trick here. For example, a pupil that is consistently large all the time will result in slow states close to Z=0. Also, strong slow drift results in a large standard deviation, and will push the z-scores down, which is precisely not what you want in that case. Related, why are the units in Figure 3B (z-score) different than in Figure 4C,D (%). In the latter case, % of what?</p></disp-quote><p>The reviewer is correct in that the timescales longer than an experiment run could not be assessed in the present study, we now discuss this limitation in lines 413-417:</p><p>“…spontaneous fluctuations in pupil size on a timescale longer than a run length (5.6 ± 0.38 min) might be important. In the present experiment such longer time scales could not be assessed since we used a relative measure of pupil size change within each experiment block, whereas an absolute pupil size measure (not available using the present eye-tracking set-up) is necessary to assess change in pupil size across blocks.”</p><p>We note that “slow” and “fast” are relative terminology. The fast pupil changes investigated herein are at the time scale of tens to hundreds of milliseconds (Figure 6). By contrast, for the slow states, we average pupil size in 2-sec time windows, which corresponds to a &lt;0.5 Hz filter. Therefore, our ‘slow states’ reflect pupil size changes in the range of 0.003–0.5 Hz. We note that our method to assess slow states, involving normalization (z-scoring) within a block, is very similar to resting-state fMRI studies. fMRI also does not provide measures of BOLD signal in absolute unit; therefore, it is customary to normalize the fMRI signal per experimental run (~5 min) to change it into a z-score or %change unit. Similar to the present study, resting-state fMRI research is unable to assess slow changes at timescales beyond that of an experimental run, and this has not prevented that field from generating a wealth of insightful findings about slow fMRI activity fluctuations. Z-scoring per run was also used in previous pupil studies (e.g., Knapen et al., 2016 referred by the reviewer, which had 2–2.5 min runs).</p><p>Lastly, we note that the relationship between the ‘slow states’ investigated herein (at 0.003–0.5 Hz range) and the ‘tonic pupil size’ investigated in previous studies such as Knapen et al., 2016 (at &lt;0.02 Hz range) requires additional investigation; in both studies, relatively arbitrary frequency cut-offs were used for these definitions.</p><p>The unit in Figure 3B is z-score, which reflects per-block normalized pupil size fluctuations averaged in 2sec prestimulus windows (i.e., slow states), which were used to fit the models relating to MEG power using single-trial data. For Figure 4C-D the trials were binned into five groups according to quintiles of the 2-sec averaged prestimulus pupils size in order to calculate behavioral metrics (such as d’ and c). We have now clarified that the x-axis in Figure 4C-D is pupil size bin, defined according to pupil size quintiles.</p><disp-quote content-type="editor-comment"><p>Are results the same after excluding slow states including blinks? I understand that the authors used ICA to remove blink-related artifacts from the MEG data. However, blinks also cause relatively large transient pupil constrictions (Knapen et al., PLOS ONE, 2016), which will work into the 2-s averages.</p></disp-quote><p>Given that normal spontaneous blink rate can reach 20/min and the blink-related transients last for up to 4 seconds (Knapen et al., 2016), excluding data would mean throwing away most experiment trials. We now discuss this limitation in lines 421-429:</p><p>“…the full composition of endogenous events driving spontaneous fluctuations in pupil size remains incompletely understood. While a causal association between activity in brainstem neuromodulatory centers and pupil size has been established, additional endogenous factors, ranging from cognitive (e.g., an exciting thought) to physiological (e.g., blinks), affect the pupil size. For example, it has been shown that blinks correlate with a subsequent fluctuation in pupil size lasting for up to 4 seconds (Knapen et al., 2016). Importantly, it is unclear if such endogenous effect can be dissociated from arousal or not. Given such a long-lasting effect, excluding trials with blinks within 4-sec intervals is not feasible (normal human blink rate can reach ~1/3 sec). Thus, future research is needed to determine to what extent different endogenous events drive the spontaneous fluctuations in pupil size in addition to the known neuromodulatory effects.”</p><disp-quote content-type="editor-comment"><p>Related, how often did subjects blink? From Figure 1D it seems about 10 times per minute, which means that 33% of &quot;slow states&quot; might be affected.</p></disp-quote><p>The blink rate is 17.62 ± 1.77 times per minute in our data. Note that our relatively liberal criterion for blink definition does not dissociate between the potential loss of tracking and blinks (explained in the comment below), hence the actual blink rate could be lower. We instructed the subjects to try and blink after the stimulus presentation and avoid blinking during the prestimulus interval whenever possible, in order to better assess how prestimulus baseline pupil size varies as a function of cortical spectral power (Figures 2-3) and subsequent perceptual behavior (Figure 4). In our data, only 33.08 ± 4.6% of 2-sec prestimulus intervals analyzed were affected by blinks.</p><disp-quote content-type="editor-comment"><p>Finally, why did the authors not use the blink onset and offset timestamps provided by Eyelink? I'm asking because using a constant threshold will miss partial blinks. If the authors want to detect blinks themselves, they should do so based on outliers in the first derivative of the pupil time series.</p></disp-quote><p>The reviewer is correct in that our procedure might miss incomplete blinks or partial eye closures. Our understanding is that EyeLink’s detection procedure would miss the incomplete blinks as well. EyeLink blink detection code is proprietary and is not publicly available; however, from reading the User Manual (page 24), it seems that to identify an event as a blink the pupil data must be missing: “A blink is defined as a period of saccade detector activity with the pupil data missing for three or more samples in a sequence.” Our understanding is that such a procedure as implemented in Eyelink will not identify events as blinks when the pupil data is not missing at all, as in the case of partial eye closure.</p><p>Without using an additional criterion of velocity change, our procedure will identify all events with missing data, wherein the missing data could be due to eye closure or due to lost tacking, as “blinks”. This was intended since we do want to exclude the instances of lost tracking (instead of using interpolation) to be conservative, but it might slightly increase the identified blink rate. We have now clarified this in methods (lines 483-485, new text underlined):</p><p>“Blinks or missing data periods were detected by identifying the time points where the recorded pupil size of the right eye dropped below a constant threshold”</p><disp-quote content-type="editor-comment"><p>I think the authors should better integrate their findings with the existing literature, and be more precise with their citations:</p><p>– Line 42: &quot;and animals&quot; -&gt; ref. 7 should be cited here as well.</p></disp-quote><p>Done.</p><disp-quote content-type="editor-comment"><p>– Line 54: &quot;across a wide range of frequencies&quot; -&gt; ref. 14 did, albeit only in auditory cortex.</p></disp-quote><p>The full sentence including the clause mentioned above is: “Importantly, previous studies in this domain have not investigated how pupil-linked arousal covaries with large-scale cortical spectral power across a wide range of frequencies”. Our understanding is that ref. 14 did not investigate large-scale cortical spectral power.</p><disp-quote content-type="editor-comment"><p>– Line 96: &quot;play a functional role in behavior&quot; -&gt; ref. 15, 41 should be cited, and see also de Gee et al., PNAS, 2014; de Gee et al., eLife, 2020; Krishnamurthy et al., NHB, 2017; Urai et al., Nat Comm, 2017.</p></disp-quote><p>The sentence including the clause mentioned above began with: <italic>“While baseline pupil diameter …”</italic>, to clarify that we specifically refer to spontaneous (non-stimulus-triggered) dilation and constrictions, we edited the sentence as follow: (lines 95-97, new text underlined)</p><p>“While baseline pupil diameter (“slow state” equivalent) correlates with subsequent perceptual detection in humans (Podvalny et al., 2019; Van Kempen et al., 2019; Waschke et al., 2019) and mice (Aston-Jones and Cohen, 2005; McGinley et al., 2015; Steinmetz et al., 2019), it is currently unknown whether momentary spontaneous dilations and constriction (“fast events”) during a baseline period play a functional role in behavior.”</p><p>The papers mentioned by the reviewer investigated stimulus-triggered pupil responses and therefore were not cited here in particular.</p><disp-quote content-type="editor-comment"><p>– Line 322: &quot;limited data is available in humans&quot; -&gt; ref. 41 should be cited</p></disp-quote><p>Done (though we again refer to spontaneous activity).</p><disp-quote content-type="editor-comment"><p>– Line 326: &quot;deserved further investigation&quot; -&gt; ref. 41 should be cited</p></disp-quote><p>Our understanding is that <italic>“spontaneous pupil size fluctuations”</italic> were not investigated in 41. No doubt Ref 41 is an important paper, but we are afraid that citing it here in the context of spontaneous fluctuations could cause confusion for the reader.</p><disp-quote content-type="editor-comment"><p>Reviewer #4:</p><p>Podvalny and colleagues investigate the links between spontaneous variations in arousal, as indexed by varying pupil size, and spectral power as well as perceptual decision performance. The study represents extends previous work in non-human animals, initial findings in humans, and improves our understanding of behaviourally relevant changes in arousal and their effects on mesoscopic measures of brain activity (M/EEG). Despite these valuable contributions to the field, central results hinge on methodical approaches that are potentially problematic. In addition to these methodical issues, the transparency and clarity with which results are presented should be improved.</p></disp-quote><p>We thank the reviewer for recognizing the value of these contributions. The methodological issues identified by the reviewer have been fully addressed, and the transparency and clarity of the presentation has been enhanced.</p><disp-quote content-type="editor-comment"><p>1) Linear mixed effect models:</p><p>Although I applaud the general approach of fitting linear mixed effect models to neural and behavioural data, the exact implementation in the current manuscript could be improved and is potentially problematic. First of all, it remains unclear why the authors do not use the potential of LMMs and also fit random slopes to test effects on the single subject level. This is only carried out to partialize pupil size and spectral power, respectively, but not in any models that concern behaviour or the link between spectral power and pupil size. Is there a reason the authors did not fit random slopes? I advocate for the inclusion of random slopes (depending on the model fit) for variables of interest and the inclusion of single subject estimates in all figures. If random slopes for all predictors within the same model lead to convergence issues or problematic model fit, the use of multiple models that only differ in their random slopes (e.g., pupil or spectral power) is acceptable.</p></disp-quote><p>We have now included random slopes in all LMM analyses in the present study to keep the random structure maximal (please also see our response to Reviewer #3’s point 1 above). We added Supplementary figure 3 showing individual-subject data and model fit for analyses presented in Figure 4C-D (including radom slopes and random intercepts). We did not include individual subject data and model fit for analyses presented in Figure 3B since they include 8460 data points for each frequency band and RSN (the visualization in Figure 3B uses 5% pupil-size bins) and it is difficult to obtain a useful visual representation of such extensive data at the individual-subject level.</p><disp-quote content-type="editor-comment"><p>In this context, it seems to me as if the authors never model behaviour as a joint function of pupil size and spectral power. I strongly suggest to include both spectral power and pupil size in models of behaviour to account for shared variance in the dependent variable of interest (e.g. hit rate or false alarm rate).</p></disp-quote><p>To calculate the behavioral variables according to Signal Detection Theory we had to split the trials in groups. These behavioral variables (HR, FAR, d’, c) cannot be computed at the single-trial level. For this reason, we split the trials into groups according to an independent variable (i.e., prestimulus spectral power or pupil size) and test whether such grouping predicts behavioral changes (dependent variable). As far as we understand, it is not possible to define groups of trials and calculate SDT metrics according to more than one independent variables at the same time.</p><p>However, to address the reviewer concern, we have now introduced an additional single-trial level analysis of a model predicting behavioral responses (“yes”/”no”) using both prestimulus pupil size and spectral power, as the reviewer suggested. This analysis allowed us to test whether pupil size contains additional information that contributes to the prediction of “yes”/”no” reports on a single-trial level beyond information contained in cortical spectral power (reported in new Figure 5A; described in lines 218231):</p><p>“To understand the respective contributions of spectral power that can be explained by pupil-linked arousal (Figures 2-3) and of spectral power independent of arousal to perceptual behavior, we first fit logistic regression models predicting “yes”/”no” recognition behavior from baseline fluctuations of spectral power in all frequency bands and RSNs only (“power only”), models with pupil size in addition (“pupil and power”), models using residual power independent of pupil size (“residual power”) and models with pupil size as a single feature (“pupil only”) (Figure 5A, see Methods). The residual power was calculated by first fitting LMM models for each frequency band and each RSN for each participant, whereby the model with lower BIC at the group level was chosen between Equation 3 and Equation 4 (see Methods, Table 1). We find that all logistic regression models predict “yes”/”no” behavior better than chance (permutation test, p&lt;0.05 FDR corrected). Interestingly, the performance of “power only” model does not improve by adding pupil size information (W = 143, p = 0.86, Wilcoxon signed-rank test), but the performance is worsened by regressing out the pupil-linked spectral power (W = 241, p = 0.008, Wilcoxon signed-rank test). These results indicate that both arousal-linked and arousal-independent spectral power fluctuations at baseline predict subsequent recognition behavior, but our recordings of pupil size did not provide additional information contributing to the prediction of behavior that was not already present in cortical spectral power.”</p><p>This new analysis confirms our main conclusion that both arousal-linked and arousal-independent spectral power fluctuations at baseline predict subsequent recognition behavior.</p><disp-quote content-type="editor-comment"><p>Furthermore, although the comparison of purely linear and quadratic (including a linear term) models represents an aptly chosen approach, the authors should handle their inferences regarding these model terms with great care and report them more cautiously. Figure 4C for example features visualized quadratic trends that do not represent significant model terms (e.g., sensitivity, response times, etc.). It should be made very clear to the reader that these quadratic effects do not explain additional variance in behaviour and do not fit the data well.</p></disp-quote><p>We thank the reviewer for raising this issue. We have now updated Figure 4C-D to include only models with significant parameter estimates. As such, the quadratic models for categorization behavior (including reaction times and accuracy in Figure 4D) have now been removed.</p><disp-quote content-type="editor-comment"><p>In addition, in models where quadratric trends explain significant portions of variance, linear and quadratic effects should be compared directly (e.g., Wald-z statistic) and the results of these comparisons should be reported. Only this way, readers can be able to judge whether linear or quadratic trends are pervasive in a certain relationship.</p></disp-quote><p>We have used Bayesian information criterion (BIC) to select a better model between the linear and quadratic models. In response to Reviewer #3’s point 3, in Figure 3B-C and Supplementary figure 1, we now only present the winning models. That is, models with quadratic components are now only plotted if their BIC values are lower than the corresponding linear models. In Figure 4C-D, to facilitate comparison with earlier studies that have reported both linear and quadratic relationships between pupil size and perceptual behavior, we present both models with and without the quadratic component as long as the quadratic component is significant (also see our response to the point above). We further report the full statistics for each model and their BIC values in Table 1.</p><disp-quote content-type="editor-comment"><p>On another note, it is unclear to me if the model coefficients that are presented (e.g., Figure 5) represent standardized betas. If this is the case, they can also work as effect size estimates and an intuitive interpretation should be offered (e.g., &quot;one unit change in pupil size coincides with x…&quot;).</p></disp-quote><p>All reported coefficients are standardized now:</p><p>“Pupil size was z-scored to produce standardized effect size” (lines 553)</p><p>“The group numbers were z-scored to produce standardized effect size” (line 565)</p><disp-quote content-type="editor-comment"><p>2) Stats reporting:</p><p>Although the authors have included tables in their manuscript, essential test statistics should be reported within the main text (estimates, confidence intervals, p-values). Despite some p-values, this is missing entirely and should be added.</p></disp-quote><p>We report the full statistics, including coefficient estimates, standard deviations, BIC values, for all tested models (including 70 models in Figure 3 and 210 models in Figure 5, both significant and non-significant) in supplementary tables. Due to the large number of models tested, even if we only restrict the statistical reporting to significant models in the main text, including the full statistics would be impractical—the sheer length of statistical reporting would severely impair readability of the text. Our SI tables are well organized such that it is easy for the reader to find the full statistics for any of the tested models.</p><disp-quote content-type="editor-comment"><p>Additionally, I suggest to report standardized effect size estimates to allow for an intuitive interpretation of results.</p></disp-quote><p>Done.</p><disp-quote content-type="editor-comment"><p>Furthermore, it would be important to note how much variance in brain, behavioural, or pupil data were explained by the winning models. Maybe I have missed this information, if not, it should be added.</p></disp-quote><p>While the concept of ‘variance explained’ is indeed intuitive and is very often used as a summary statistic to quantify the goodness-of-fit of fixed-effects models (e.g., linear regressions, ANOVA, or generalized linear models (GLMs)), generalization of R<sup>2</sup> to LMM is challenging. There are some theoretical developments on this topic (e.g., Nakagawa and Schielzeth, 2013), but these methods are not yet implemented in the software package we are using (<italic>statsmodels</italic> python toolbox, version 0.12.2).</p><disp-quote content-type="editor-comment"><p>3) Stimulus category decoding:</p><p>While this is an elegant approach to study the representation of sensory stimuli within neural data and compare them across conditions, the employed chance level is problematic. While it is true that 25% represents the theoretical chance level in a case where four alternatives are discriminated, this is only true for infinite numbers of trials – or at least large datasets (Combrisson et al., 2015, JNeuroMeth). If I understood the approach of bin-wise leave-one out classification correctly, each bin contained about 70 trials. In this case, the empirical chance rate can be calculated as Emp_chance = binoinv(1-α,n_trials,1/n_classes)/n_trials; Where α corresponds to the desired significance level (.05), n_trials to the number of trials and n_classes (4) to the number of possible outcomes. Using this approach, an empirical chance level of 34.2 % is calculated which clearly differs from the theoretical level 0f 25 %. I suggest to either test against the empirical chance level or establish a noise distribution of prediction accuracies using permutations, against which to test.</p></disp-quote><p>In the previous version of the manuscript we did not address the question of whether the decoding accuracy is above chance within a specific group of trials. Instead, we were interested in the question of whether the prestimulus pupil size has an effect on subsequent neural representation of the stimulus. We realize, however, it is important to show the empirical (or permutation-derived) chance level and to assess whether the decoding accuracy is significantly higher than that. We now address this question by performing 500 permutations with shuffled object category labels within each bin, and derived the permutation-established chance level, which was 0.246 ± 0.06 (mean ± sd). We now added the permutation-derived chance level and decoding significance (computed using the 500-permutation null distribution) to Figure 4E and we report the results in text (lines 211-214):</p><p>“In addition, the decoding accuracy was significantly above the chance level (obtained by label permutations) from 200 ms to 1 s after stimulus onset (p &lt; 0.05, FDR corrected) and significantly above the chance level for trials in the second, forth, and fifth pupil size groups.”</p><disp-quote content-type="editor-comment"><p>Reviewer #5:</p><p>The study by Podvalny et al. measured the relationship between pupil diameter and cortical spectral power, assessing how they provide overlapping versus complementary indices of brain state. The authors used regression analysis to identify relationships between spontaneous, pre-stimulus fluctuations in pupil and MEG spectral power and performance on a visual discrimination task. The analysis revealed correlations between pupil and cortical spectral power but also unique variance between each of these signals and task performance. The experiments and data are novel and are nicely designed and executed. While the results are interesting, they appear in many cases to replicate previous findings. It would help if the authors could more clearly explain the gaps the new results fill in the existing literature.</p></disp-quote><p>We thank the reviewer for appreciating our study design and analysis, and the novelty thereof.</p><disp-quote content-type="editor-comment"><p>1. The authors cite work several previous studies in human (Washke et al., Van Kempen et al., de Gee et al) and animal (McGinley et al., Joshi et al., Reimer et al) that explored similar questions and appear to be largely consistent with the current data. This study does appear make a few new comparisons and identifies some differences with the previous work, but the new results appear as a scattered list of observations throughout the discussion. The main observation of explanatory overlap between pupil and cortical spectral power appears to be a replication. It would help if the authors could clarify the novelty of their main results.</p></disp-quote><p>Our study contributes several novel results and below we address the reviewer’s concern in the context of the previous studies mentioned:</p><p>First, we provide the characterization of the relationship between the spectral power of neural activity localized in large-scale cortical networks during <italic>spontaneous</italic> fluctuations of pupil-linked arousal at rest and prestimulus baseline. While the results of this analysis are mostly, but not always, consistent with prior studies in humans and animals, the scale of this analysis and the precise characterization of the pupil-brain relationship are novel. Waschke et al. 2019 described pupil-brain relationships before stimulus onset using EEG activity in the auditory cortex only, for example. Furthermore, our study is the first study using MEG, which provides superior signal-to-noise and source localization as compared to EEG. This may explain why some previous studies reported null effects, such as no relationship between α power and pupil size reported in Waschke et al. 2019, while we found a significant inverted-U relationship. While our results are consistent with prior findings from animal electrophysiology, these animal studies have recorded a small number of brain regions (auditory cortex in McGinley et al.; LC in Joshi et al; V1 and S1 in Reimer et al.); as such, the large-scale distribution of pupil-power relationship across the whole cortex was not known.</p><p>Second, we report the effect of pupil-linked arousal fluctuations <italic>at baseline</italic> on behavior in visual perceptual decision-making task. Our study was specifically designed to examine prestimulus baseline activity by utilizing longer prestimulus intervals than in previous studies, variable stimulus presentation times to reduce the stimulus expectation effects, and a lack of any additional task-relevant stimuli present during baseline. Van Kempen et al. 2019 and de Gee et al. 2017, for example, defined baseline while a non-target stimulus was in fact present on the screen, which may mask the spontaneous arousal fluctuations. Our study design also allowed us to study changes in multiple metrics of behavior, whereas previous studies, such as Van Kempen et al. 2019, reported the effect of pre-target baseline pupil size on reaction times only (accuracy was at ceiling). In sum, our study was designed to provide a more complete picture specifically on the topic of spontaneous arousal fluctuations and their role in perceptual decision making under uncertainty.</p><p>Third, in the present work we delineate the specific behavioral effects of pupil-linked and pupil independent spectral power fluctuations at baseline. Multiple previous studies explored spectral power within one limited frequency band (usually α) localized to one brain area without controlling for arousal. In the present study we study this question using MEG (better SNR, better source localization) and controlling for arousal. We find that a significant portion of spectral power’s effect on behavior is arousal mediated and but arousal-independent cortical activity power fluctuations also contribute significantly to perceptual behavior. Partitioning cortical activity power’s influence on perceptual behavior into components that are arousal-linked and arousal-independent is a novel step undertaken in this study.</p><p>Finally, our study is the first to begin to identify the large-scale neural mechanisms of spontaneous pupil linked arousal <italic>on a faster time-scale in human</italic>. We show that large-scale brain activity correlates with pupil size on a millisecond time scale in human. While a similar analysis was conducted in animals using intracranial electrophysiology, a time lag of 400ms that we found in human, considering the monkey LC time lag is 300 ms (Joshi et al. 2016, brain activity preceding the pupil size), calls for investigation of the feedback loops from cortex to LC as a mechanism of arousal control during baseline and rest. Furthermore, we found that spontaneous pupillary events in human at this time scale did not correlate with subsequent visual perceptual decision-making. Such events and their neural correlates were studied in animals (Reimer et al. 2014) but their behavioral relevance was not tested.</p><p>In sum, our study makes several novel contributions to the field, which were summarized very well in the editors’ decision letter: “The reviewers and editors felt that this manuscript aims at offering important insights. First, brain-wide relationships across a wide range of spectra have only rarely been tested in humans. Second, testing direct and indirect links between baseline pupil size, spectral power and behaviour, separately, has not been done before in humans, to the best of our knowledge. Finally, the authors try to combine and compare the behavioural relevance of slow as well as fast pupil size fluctuations, linking to previous research in non-human animals.” The decision letter further specified that the main issue with our previous submission was methodological, which we have fully addressed now.</p><disp-quote content-type="editor-comment"><p>2. The modeling results could be presented more clearly. While the general methodology appears sound, it is difficult to discern what aspects of the cortical spectral power are shared with pupil versus not. For example, would it be possible to contrast coefficients for the pupil-independent spectral power model (Figure 5) with coefficients for a model without removing pupil? This information is available in some form in Figures 3 and 4, but it is unclear if and how the units of these different models can be compared. It seems like there should be a unified way to present the joint versus unique contributions of the pupil and MEG signals in terms of variance explained, which would make the results much easier to digest. Without a more comprehensive summary, the results appear as mostly disparate observations.</p></disp-quote><p>While the concept of ‘variance explained’ is indeed intuitive and is often used as a summary statistic to quantify the goodness-of-fit of fixed-effects models (e.g., linear regressions, ANOVA, or generalized linear models), generalization of R<sup>2</sup> to LMM is challenging. There are some theoretical developments on this topic (e.g., Nakagawa and Schielzeth, 2013), but these methods are not yet implemented in the software package we are using (<italic>statsmodels</italic> python toolbox, version 0.12.2). However, we have implemented a new analysis to address this concern, as described below.</p><p>The reviewer inquired about whether it is possible to compare the regression coefficients of two models, one predicting behavior with pupil-independent power and one with full power. In the linear case of a model for criterion (c), such analysis would constitute a comparison between the coefficients <italic>X<sub>L</sub></italic><sub>1</sub> and <italic>X<sub>L</sub></italic><sub>2</sub> of the models below:</p><p><inline-formula><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:mi>G</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p><inline-formula><mml:math id="sa2m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:mi>G</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p>Please note that our behavioral metrics here cannot be computed on a single-trial level (i.e., one needs to analyze a group of trials to estimate criterion), and they vary with prestimulus states, which were defined differently for the two models. For these reasons, we cannot draw conclusions about the differences between the coefficients of the two models, as this would call for a single model explaining behavior with both full and residual power and testing the interaction between these terms, which is not possible in this case.</p><p>However, to address the reviewer’s concern, we have now implemented Logistic regression models predicting subjects’ recognition behavior (“yes”/”no”) on a single-trial level, using baseline cortical spectral power alone, baseline pupil size alone, power plus pupil, and pupil-independent residual power. The new analysis is reported in the new Figure 5A and described in lines 218-231. It was also referred to in response to Reviewer #3’s point 2 and Reviewer #4’s point 1.</p><p>“To understand the respective contributions of spectral power that can be explained by pupil-linked arousal (Figures 2-3) and of spectral power independent of arousal to perceptual behavior, we first fit logistic regression models predicting “yes”/”no” recognition behavior from baseline fluctuations of spectral power in all frequency bands and RSNs (“power only”), models with pupil size in addition (“pupil and power”), models using residual power independent of pupil size (“residual power”) and models with pupil size as a single feature (“pupil only”) (Figure 5A, see Methods). The residual power was calculated by first fitting LMM models for each frequency band and each RSN for each participant, whereby the model with lower BIC at the group level was chosen between Equation 3 and Equation 4 (see Methods, Table 1). We find that all logistic regression models predict “yes”/”no” behavior better than chance (permutation test, p&lt;0.05 FDR corrected). Interestingly, the performance of “power only” model does not improve by adding pupil size information (W = 143, p = 0.86, Wilcoxon signed-rank test), but the performance is worsened by regressing out the pupil-linked spectral power (W = 241, p = 0.008, Wilcoxon signed-rank test). These results indicate that both arousal-linked and arousal-independent spectral power fluctuations at baseline predict subsequent recognition behavior, but our recordings of pupil size did not provide additional information contributing to the prediction of behavior that was not already present in cortical spectral power.”</p><p>This new analysis confirms our main conclusion that both arousal-linked and arousal-independent spectral power fluctuations at baseline predict subsequent recognition behavior.</p><p>References:</p><p>Aston-Jones G, Cohen JD. 2005. An integrative theory of locus coeruleus-Norepinephrine function: Adaptive Gain and Optimal Performance. Annu Rev Neurosci 28:403–450. doi:10.1146/annurev.neuro.28.061604.135709</p><p>Barr DJ, Levy R, Scheepers C, Tily HJ. 2013. Random effects structure for confirmatory hypothesis testing: Keep it maximal. J Mem Lang 68:255–278. doi:10.1016/j.jml.2012.11.001</p><p>de Gee JW, Colizoli O, Kloosterman NA, Knapen T, Nieuwenhuis S, Donner TH. 2017. Dynamic modulation of decision biases by brainstem arousal systems. <italic>ELife</italic> 6:e23232. doi:10.7554/<italic>eLife</italic>.23232</p><p>Hong L, Walz JM, Sajda P. 2014. Your eyes give you away: Prestimulus changes in pupil diameter correlate with poststimulus task-related EEG dynamics. PLoS One 9:e91321.</p><p>doi:10.1371/journal.pone.0091321</p><p>Knapen T, De Gee JW, Brascamp J, Nuiten S, Hoppenbrouwers S, Theeuwes J. 2016. Cognitive and ocular factors jointly determine pupil responses under equiluminance. PLoS One 11.</p><p>doi:10.1371/journal.pone.0155574</p><p>Lendner JD, Helfrich RF, Mander BA, Romundstad L, Lin JJ, Walker MP, Larsson PG, Knight RT. 2020. An electrophysiological marker of arousal level in humans. <italic>ELife</italic> 9:1–29. doi:10.7554/<italic>eLife</italic>.55092</p><p>McGinley MJ, David S V., McCormick DA. 2015. Cortical Membrane Potential Signature of Optimal States for Sensory Signal Detection. Neuron 87:179–192. doi:10.1016/j.neuron.2015.05.038</p><p>Nakagawa S, Schielzeth H. 2013. A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods Ecol Evol 4:133–142. doi:10.1111/j.2041-210x.2012.00261.x</p><p>Podvalny E, Flounders MW, King LE, Holroyd T, He BJ. 2019. A dual role of prestimulus spontaneous neural activity in visual object recognition. Nat Commun 10:3910. doi:10.1038/s41467-019-11877-4</p><p>Powell MJD. 1964. An efficient method for finding the minimum of a function of several variables without calculating derivatives. Comput J 7:155–162. doi:10.1093/comjnl/7.2.155</p><p>Steinmetz NA, Zatka-Haas P, Carandini M, Harris KD. 2019. Distributed coding of choice, action and engagement across the mouse brain. Nature 576:266–273. doi:10.1038/s41586-019-1787-x</p><p>Van Kempen J, Loughnane GM, Newman DP, Kelly SP, Thiele A, O’Connell RG, Bellgrove MA, O’Connell RG, Bellgrove MA. 2019. Behavioural and neural signatures of perceptual decisionmaking are modulated by pupil-linked arousal. <italic>ELife</italic> 8:e42541. doi:10.7554/<italic>eLife</italic>.42541</p><p>Waschke L, Tune S, Obleser J. 2019. Local cortical desynchronization and pupil-linked arousal differentially shape brain states for optimal sensory performance. <italic>ELife</italic> 8. doi:10.7554/<italic>eLife</italic>.51501 Watson AB, Pelli DG. 1983. Quest: A Bayesian adaptive psychometric method. Percept Psychophys 33:113–120. doi:10.3758/BF03202828</p><p>[Editors’ note: what follows is the authors’ response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Presentation of single subject data (as per Rev #1)</p></disp-quote><p>The individual subject data for the effect of prestimulus pupil size on task performance (Figures 4C-D) was already presented in the previous version of the manuscript in Supplementary figure 3 (Figure 4—figure supplement 1 in the revised version). We now add individual subject data to show the relationship between pupil size and spectral power in Figure 3—figure supplements 2 and 3, for task baseline and rest respectively. Given the large number of data points we made these figures larger and we hope this visual presentation will be helpful to some readers. We also now added individual subject data for decoding accuracy in Figure 4—figure supplement 1.</p><disp-quote content-type="editor-comment"><p>1) Presentation of effect sizes and explained variance (as per Rev #1).</p></disp-quote><p>Marginal and conditional variance explained values are now added to Table 1, Supplementary tables 1 and 2. We used <italic>R’s lme4</italic> through <italic>pymer</italic>, a python wrapper package, to fit the models, and found nearly identical model parameters to stats models:</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68265-sa2-fig1-v2.tif"/></fig><p>For this reason, we opted to not transfer all our code to R as it is streamlined in python already. Since our models include more than one random factor in the case of quadratic model, we used <italic>PiecewiseSEM R</italic> package to quantify the marginal and conditional R<sup>2</sup>. The methods section is updated as follow (lines 570-576):“We verified that the parameters estimates acquired with stats models were nearly identical to the ones acquired with a more widely used R lme4<sup>86</sup> toolbox (implemented through python wrapper pymer<sup>87</sup>). We used piecewiseSEM<sup>88</sup> R package to estimate marginal and conditional variance-explained values indicating the proportion of total variance explained by fixed effects only and the proportion of variance explained by both fixed and random effects, respectively<sup>89</sup>. It is important to note, however, these metrics were developed specifically for linear mixed-effects models and are useful in the relative sense for comparison between such models’ fit to the data but they do not have the same properties as linear models R<sup>2</sup>. ”</p><disp-quote content-type="editor-comment"><p>2) Are pupil-related effects really essentially uniform across the cortex? Or are the differences really the important thing? It would be nice if this could be addressed even briefly in the Discussion. (as per Rev #3)</p></disp-quote><p>We now added a discussion paragraph addressing this topic (lines 334-343):</p><p>“The brain activity modulation by pupil-linked arousal systems, while similar across resting state networks, is not entirely uniform. We observed, for example, differences in parameter estimates across networks and behavioral conditions: modulation of α power by arousal in the visual RSN is stronger than in other networks at rest, whereas modulation of β power is strongest in the dorsal attention network in task baseline (Figure 3C, linear components). Such non-uniform effects are consistent with the intriguing proposals of pupil-linked arousal systems playing an important role in dynamic reconfiguration of large-scale networks topology responding to cognitive demands<sup>50,61</sup>. Indeed, while the arousal neuromodulatory systems send widespread projections to cortex, recent studies also report complex topographic organization which may produce such non-uniform modulatory effects<sup>62,63</sup>. A greater understanding of the function of uniform vs. modular effects on cortical power by arousal systems in various cognitive states is an important goal for future investigation.”</p><disp-quote content-type="editor-comment"><p>3) Since the present analysis is focused on quantifying pupil size it is important to account for other factors which might affect measured pupil size, notably, fixation and saccades. The section devoted to detailing the analysis of the pupil data omits any discussion of these factors. Did the authors check that fixation is maintained at all times? Were periods associated with saccades away from fixation (which will result in apparent changes to pupil size) removed from the analysis? (as per Rev #4)</p></disp-quote><p>The subjects were instructed (and reminded between blocks) to fixate on the center crosshair and to avoid blinking to the best they can until after stimulus arrival (now clarified in lines 495-497) and the experimenters monitored the subjects at all times. The time periods with missing pupil data were removed from the analysis (lines 505-507). These time periods include both blinks and potential saccades, since missing pupil data points is a necessary condition for both saccade and blink detection in EyeLink data (see also our detailed response to reviewer #3, point 5, in previous revision).</p><disp-quote content-type="editor-comment"><p>4) The analysis of &quot;fast events&quot; was not very clear to us (as per Rev #4, please follow the details for an additional/re-analysis there):</p><p>a) we are worried about the low-pass filter and a potential acausal smearing it might have contributed.</p></disp-quote><p>We used a zero-phase filter – now clarified in the methods section (lines 513-515):</p><p>“Next, in order to remove potential high-frequency artifacts, we applied a 5-Hz low-pass Butterworth filter to continued resting state data forward and backward in time using filtfilt function (Scipy), assuring no phase shifts.“</p><p>We have repeated the analysis without filtering the pupil signal and the results (now reported in Figure 6-figure supplement 1C) are virtually the same.</p><disp-quote content-type="editor-comment"><p>b) The statement (line 492) &quot;to be considered a peak/through, the data point should have highest/lowest amplitude within 500 ms vicinity&quot; was also not clear. It would be helpful if you plotted (or reported) the duration distribution of the events you ended up analyzing</p><p>(as per Rev #4, see details also below).</p></disp-quote><p>We have now simplified and clarified the methods for pupillary events identification (lines 516-518):</p><p>“To identify peaks/troughs, for each data point in the pupil size time course, we tested whether its amplitude is the highest/lowest in comparison to the data points in a 1-sec time window centered on that data point (using “argrelextrema” method of scipy).”</p><p>Because in the present study the events were defined as momentary peaks/troughs, duration of each event is undefined. In contrast to Joshi et al. 2016 where each dilation and constriction event were included in the analysis and a dilation necessarily follows constriction and vice versa, in our analysis constriction and dilations are identified independently, generally allowing for more than one dilation/constriction event in a row and not limiting inter-event interval timing. From the inter-event interval histogram of the events identified in our study (now added as Figure 6—figure supplement 1A) it is possible to conclude that our events could be sparser than those defined in Joshi et al. 2016.</p><p>We suspect the reviewers might be interested to know whether the event-related brain activity we report is sensitive to event definition or specifically inter-event interval (duration). To this end, we replicated the analysis with a different method for event identification. This time we used <italic>scipy “findpeaks”</italic> method, where we defined local events by minimal prominence (i.e., peak height in relationship to local minima) of 0.5 standard deviations and selected events with minimal inter-event distance of 0.5, 1, 1.5, 2, 2.5 s. The results (now reported as Figure 6—figure supplement 1B) show virtually no difference from our report (compare to figure 6C)</p><p>Thus, we conclude that our reported results are robust to the particular method used to identify these fast events.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>The authors have revised large parts of their manuscript and addressed most comments.</p><p>However, two of my previous concerns have not been resolved entirely.</p><p>1) Presentation of single subject data.</p><p>The authors argue that this is not feasible as it would require to plot more than 8000 data points. This likely is a misunderstanding. While it is true that plotting single subject points for all power / frequency / ROI bins is not feasible, this is not what I asked for. Take figure 3B as an example. In every panel, the authors plot spectral power (in bins) as a function of pupil size (in bins). They plot one data point per bin (with an error bar around it). If I am not entirely mistaken, this data point represents the group average. It is essential, however, to show single subject data at this point. What speaks against plotting a cloud of N=24 dots around their mean instead of each dot? I realize that this might take up a bit more space but I am convinced that this is an essential service to every reader. Importantly, the same comment applies to figure panels 4C, 4D, and 4E.</p></disp-quote><p>We thank the reviewer for the clarification. We now address this comment in essential revisions point #1 above.</p><disp-quote content-type="editor-comment"><p>2) Effect sizes and explained variance</p><p>While it is true that the concept of variance is explained is not easily transferred to the world of linear mixed models, it is entirely possible to offer such an estimate, both for linear mixed models as well as generalized mixed models. Even if imperfect, such an approximation represents an important piece of information since it puts the models in perspective to the space they were trying to capture. I allow myself to recommend the excellent R-package lme4 which allows the fitting of such models and in combination with functions from the sj_plot package (e.g., tab_model) offers all relevant information. I am sure transferring their models from python to R should be a simple task for the authors.</p><p>Furthermore, I suggest to offer an explicit discussion of model fits and effect sizes which is missing in the current version of the manuscript. The supplementary tables illustrate that effects rather are small and likely don't account for large parts of variance in the data. This does not have to be an issue but it should be acknowledged prominently and discussed.</p></disp-quote><p>We now address this comment in detail under essential revisions point #2 above. Variances explained (marginal and conditional R<sup>2</sup>) are now reported in Table 1, Supplementary Tables 1 and 2. Conditional R<sup>2</sup> (i.e., proportion of variance explained by both fixed and random effects) in Table 1 and Table S2 (corresponding to Figures 4C-D and 5B) are in the range of ~0.5–0.9, suggesting that both pupil and residual power explain substantial fractions of variance in the behavioral measures (HR, FAR, c, d’, Accuracy and RT). Conditional R<sup>2</sup> in Table S1 (corresponding to Figure 3B and Figure 3—figure supplement 1) are much lower. This is expected, because spontaneous cortical power fluctuations have many sources of contributions such as recurrent corticocortical activity, thalamocortical loops, and subcortical neuromodulatory influences. Pupil-linked arousal (part of subcortical neuromodulation) is only one of many sources of influence that contribute to spontaneous cortical power fluctuations.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The authors were responsive to all the concerns raised in the initial review. The revised manuscript clarifies the significance of the work and more rigorously identifies the link between pupil size, cortical activity and task performance.</p></disp-quote><p>Thank you.</p><disp-quote content-type="editor-comment"><p>Overall, the manuscript looks great. Just a small lingering question. The effects in Figure 3 appear strikingly consistent across brain networks, and any differences appear to be quantitative more than qualitative (ie, even where a quadratic effect may not be significant, one can still see a trend that is consistent with networks showing a quadratic effect). Does this mean that pupil-related effects are more or less uniform across the cortex? Or are the differences really the important thing? It would be nice if this could be addressed even briefly in the Discussion.</p></disp-quote><p>Thank you! We now address this question as part of essential revisions point #3 part above.</p><disp-quote content-type="editor-comment"><p>Reviewer #4:</p><p>I joined the review process at the revision stage. I did not read the previous version of the manuscript or the rebuttal later in order to form an unbiased view of the work.</p><p>1) The experiment is quite long (over an hour and a half). In addition to task related effort, experimental length can have consequences for pupil dynamics due to effort related to maintain fixation and accommodation. It is critical that the authors demonstrate that pre-stimulus pupil size is not correlated with time within the experiment.</p></disp-quote><p>The pupil size data was centered within each block, removing any potential correlation between pupil-size and block number (now clarified in Methods, line 511). The subjects were taking breaks of self-paced duration between blocks (line 495) and were encouraged to close their eyes and continue the experiment only as they are ready. Our pupil recording methodology does not allow testing whether the pupil size is correlated to time within experiment because the recording is stopped and restarted between blocks.</p><disp-quote content-type="editor-comment"><p>2) Similarly, since the present analysis is focused on quantifying pupil size it is important to account for other factors which might affect measured pupil size, notably, fixation and saccades. The section devoted to detailing the analysis of the pupil data omits any discussion of these factors. Did the authors check that fixation is maintained at all times? Were periods associated with saccades away from fixation (which will result in apparent changes to pupil size) removed from the analysis?</p></disp-quote><p>We addressed this comment in the essential revisions section #4.</p><disp-quote content-type="editor-comment"><p>3) The analysis of &quot;fast events&quot; was not very clear to me.</p><p>a) Why was a low pass filter applied to the data before identifying the phasic events? Wouldn't a low pass filter smear the timing of these events? Depending on the filter (no details are provided) this could result in latency shifts on the order of 200ms, making the &quot;fast event&quot; analysis (Figure 6) difficult to interpret.</p></disp-quote><p>We addressed this comment in the essential revisions section #5.</p><disp-quote content-type="editor-comment"><p>b) The statement (line 492) &quot;to be considered a peak/through, the data point should have highest/lowest amplitude within 500 ms vicinity&quot; was also not clear. It would be helpful if you plotted (or reported) the duration distribution of the events you ended up analyzing and maybe follow the analysis approach as used in e.g. Joshi et al. (2016; Neuron) where phasic events are defined as zero-crossings of the pupil slope separated by {greater than or equal to}75 ms. This will make it easier to relate your findings to the literature on phasic pupil responses.</p></disp-quote><p>We addressed this comment in the essential revisions section #5.</p><disp-quote content-type="editor-comment"><p>4) Analysis in Figure 6 (and page 12).</p><p>a) Why was a Pearson and not spearman correlation used? The latter is less sensitive to outliers and would provide stronger evidence for the claims the authors wish to make.</p></disp-quote><p>We are not sure we understand the reviewer’s concern. We tested for a linear relationship between MEG and pupil size data and therefore chose Pearson correlation. In addition, both MEG signal and pupil size are roughly normally distributed (for an example of pupil size distribution, see Figure 1G), fulfilling the requirement of Pearson correlation.</p><disp-quote content-type="editor-comment"><p>b) Panel C: I am a bit confused by the example of identified pupil events provided. In the methods you state that you defined dilation/constriction events as having a duration of at most 500 ms. But from eye balling the figure the first dilation event (left most blue dot) appears to last more than a second? (Similarly the right most blue dot in the plot).</p></disp-quote><p>We address this comment as part of the essential revision section #5.</p><disp-quote content-type="editor-comment"><p>c) I would like to see more discussion of the shape of the patter of MEG activity triggered by the pupil events. I found the pattern extremely surprising. e.g. that the sharp peak/trough exactly coincides with 0; is it possible that the preceding peak at ~-400 relates to a previous dilation/constriction event? I would appreciate more detailed discussion of what this all means. Similarly the pattern of correlation across channels looks quite systematic. Did the authors try to source localize this pattern?</p></disp-quote><p>We have now expanded discussion on this topic in lines 411-417:</p><p>“Pupil size correlates with large-scale MEG activity on a faster timescale as well: first, spontaneous variations in MEG activity precede spontaneous variations in the pupil size with a lag of 400 ms (Figure 6A-B); second, pupillary events (constriction and dilation) coincide with MEG activity peak at lag zero and are preceded by an MEG activity peak occurring 400 ms earlier (Figure 6C-D). A similar pattern of two peaks (at 0 ms and -300 ms) was observed in monkey LC spike rates<sup>5</sup>. The zero-lag peak we observed could result from a neural event occurring earlier in time and influencing both pupil size and MEG activity at the same time lag. Since MEG activity originates mostly in the cortex, the peak at -400 ms lag (100 ms earlier than the peak in monkey LC) could point to an influence of cortical resting state fluctuations on LC activity which then triggers pupillary events.”</p><p>We do not think the -400ms peak relates to previous pupillary event since there are no evident rhythms in pupil size fluctuations (Figure 1F). Furthermore, the distribution of inter-event intervals for both dilation and constriction peaks at ~1 sec but with a very long tail (Supplementary figure 6A).</p><p>We did not attempt to localize the MEG activity patterns related to pupillary fast events, which we believe is beyond the scope of this paper.</p><disp-quote content-type="editor-comment"><p>Other points</p><p>1) It is stated that sensitivity (d') is related to prestimulus size in an inverted U shaped relationship. This is not obvious at all from looking at the data points in the figure. Instead the behavioral performance appears to not differ much for pupil bins 2-5.</p></disp-quote><p>Our data is consistent with an inverted-U-shaped relationship suggested by Yerkes-Dodson law. We explain that our study does not explore the whole continuum of arousal states (lines 431-432), which may have limited our ability to capture the full inverted-U-shape function.</p><disp-quote content-type="editor-comment"><p>2) I understand it is difficult to control in the present experiment, but doesn't a larger pupil also imply stronger visual input? Would this be able to explain the largely linear link between pupil size and brain activity in the β and γ ranges?</p></disp-quote><p>Visual input leads to α power suppression, which would be inconsistent with our observation of a positive/inverted-U function between pupil size and α power. Γ power in localized visual areas indeed is known to increase with visual input, however, this phenomenon would not explain the largescale changes in γ power we observed.</p></body></sub-article></article>