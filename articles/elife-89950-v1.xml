<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">89950</article-id><article-id pub-id-type="doi">10.7554/eLife.89950</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89950.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Midbrain encodes sound detection behavior without auditory cortex</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Lee</surname><given-names>Tai-Ying</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8072-1219</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Weissenberger</surname><given-names>Yves</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>King</surname><given-names>Andrew J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5180-7179</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Dahmen</surname><given-names>Johannes C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9889-8303</contrib-id><email>johannes.dahmen@dpag.ox.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Physiology, Anatomy and Genetics, University of Oxford</institution></institution-wrap><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>CNRS</institution></institution-wrap><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Shinn-Cunningham</surname><given-names>Barbara G</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05x2bcf33</institution-id><institution>Carnegie Mellon University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>17</day><month>12</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP89950</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-06-20"><day>20</day><month>06</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-06-07"><day>07</day><month>06</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.06.07.544013"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-08-22"><day>22</day><month>08</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89950.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-05-16"><day>16</day><month>05</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89950.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-06-07"><day>07</day><month>06</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89950.3"/></event></pub-history><permissions><copyright-statement>© 2023, Lee et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Lee et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-89950-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-89950-figures-v1.pdf"/><abstract><p>Hearing involves analyzing the physical attributes of sounds and integrating the results of this analysis with other sensory, cognitive, and motor variables in order to guide adaptive behavior. The auditory cortex is considered crucial for the integration of acoustic and contextual information and is thought to share the resulting representations with subcortical auditory structures via its vast descending projections. By imaging cellular activity in the corticorecipient shell of the inferior colliculus of mice engaged in a sound detection task, we show that the majority of neurons encode information beyond the physical attributes of the stimulus and that the animals’ behavior can be decoded from the activity of those neurons with a high degree of accuracy. Surprisingly, this was also the case in mice in which auditory cortical input to the midbrain had been removed by bilateral cortical lesions. This illustrates that subcortical auditory structures have access to a wealth of non-acoustic information and can, independently of the auditory cortex, carry much richer neural representations than previously thought.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>Making sense of a sound and responding to it appropriately requires various parts of the nervous system to work together in a hierarchical and interconnected manner. For example, after the ear converts sound vibrations into electric signals, this information is sent to and pre-processed by the midbrain, a brain structure tasked with linking the auditory brain stem to sensory and motor systems. The signals are then relayed to the auditory cortex where they are further decoded and integrated with information emerging from other sensory and behavioral systems. These integrated auditory signals can then be fed back to the midbrain, potentially adjusting the signals delivered to its downstream targets.</p><p>Due to its integrative nature, neural activity in the auditory cortex is also shaped by non-acoustic input. Yet a growing body of evidence points to auditory neurons present in other regions than the cortex, such as the midbrain, being able to respond to non-acoustic information as well. It has typically been assumed that such responses are mediated by feedback from the auditory cortex.</p><p>To test this assumption, Lee et al. recorded the activity of auditory neurons in the midbrain of mice performing a sound detection task (that is, responding to a clicking sound by licking a waterspout). The analyses showed that most cells encoded not only basic sound properties (such as amplitude) but also information about the animal’s behavioral response; in fact, the performance of an animal could be accurately inferred based on the activity patterns of such neurons. This was the case even in mice in which the auditory cortex had been removed, suggesting that the activity detected in the midbrain had not emerged due to cortical signals.</p><p>The findings by Lee et al. help refine our understanding of the brain processes that underpin hearing, in particular by highlighting tight links between behavioral information and neural activity in the midbrain. These results should help guide further research into how various brain regions participate in the processing of auditory input and the production of sound-guided behaviors, including when these mechanisms are affected by factors such as health or disease.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>auditory</kwd><kwd>midbrain</kwd><kwd>cortex</kwd><kwd>sound detection</kwd><kwd>corticocollicular</kwd><kwd>feedback</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000769</institution-id><institution>University of Oxford</institution></institution-wrap></funding-source><award-id>Oxford-Taiwan Graduate Scholarship</award-id><principal-award-recipient><name><surname>Lee</surname><given-names>Tai-Ying</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010002</institution-id><institution>Taiwan Ministry of Education</institution></institution-wrap></funding-source><award-id>Oxford-Taiwan Graduate Scholarship</award-id><principal-award-recipient><name><surname>Lee</surname><given-names>Tai-Ying</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010269</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.35802/102372</award-id><principal-award-recipient><name><surname>Weissenberger</surname><given-names>Yves</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010269</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.35802/108369</award-id><principal-award-recipient><name><surname>King</surname><given-names>Andrew J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Behavior is a major determinant of the activity of auditory midbrain neurons and can shape their responses independently of input from the auditory cortex.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Classically, perception is considered to rely on the flow of information from the sensory periphery via a sequence of hierarchically-organized brain structures up to the cortex. The ascending sensory pathways connecting these structures have been studied extensively and much has been learned about how signals are relayed, how features are extracted, and how information is integrated to produce increasingly abstract representations of the sensory environment. These pathways are paralleled by descending pathways that can feed information back to lower-order sensory structures. The fact that descending projections often outnumber their feedforward counterparts (<xref ref-type="bibr" rid="bib60">Sherman, 2007</xref>) attests to their likely importance for brain function. This may include turning an otherwise passive, stimulus-driven device into an active and adaptive brain that is capable of processing sensory input within its behavioral context and, therefore, able to learn and create meaning (<xref ref-type="bibr" rid="bib15">Engel et al., 2001</xref>; <xref ref-type="bibr" rid="bib27">Kraus and White-Schwoch, 2015</xref>; <xref ref-type="bibr" rid="bib34">Malmierca et al., 2015</xref>).</p><p>The descending projections of the auditory cortex target all major subcortical stations of the auditory pathway and are among the largest pathways of the brain (<xref ref-type="bibr" rid="bib72">Winer, 2005</xref>; <xref ref-type="bibr" rid="bib3">Bajo and King, 2013</xref>; <xref ref-type="bibr" rid="bib1">Antunes and Malmierca, 2021</xref>), making them a particularly suitable system for investigating the behavioral and physiological consequences of corticofugal processing. One of their main targets is the inferior colliculus (IC), an obligatory midbrain relay for nearly all ascending auditory input. The corticocollicular projection primarily terminates in the non-lemniscal shell of the IC. The shell encapsulates and is extensively connected with the central nucleus of the IC, which forms part of the tonotopically organized core or lemniscal auditory pathway to the primary auditory cortex. The projection from the auditory cortex to the midbrain was identified almost a century ago (<xref ref-type="bibr" rid="bib37">Mettler, 1935</xref>) and decades of research have since demonstrated that manipulating the activity of descending projection neurons can alter the collicular representations of multiple sound features, influence adaptive plasticity and perceptual learning, and even trigger an innate flight response (<xref ref-type="bibr" rid="bib66">Suga, 2008</xref>; <xref ref-type="bibr" rid="bib41">Nakamoto et al., 2008</xref>; <xref ref-type="bibr" rid="bib2">Bajo et al., 2010</xref>; <xref ref-type="bibr" rid="bib73">Xiong et al., 2015</xref>; <xref ref-type="bibr" rid="bib5">Blackwell et al., 2020</xref>). However, experimental evidence, especially from behaving animals, that could help explain what information the auditory midbrain and other subcortical sensory structures rely on their cortical input for is still very limited.</p><p>Interactions between different sensory pathways occur at multiple processing levels and they are also closely linked with the brain’s motor centers and neuromodulatory regions. Indeed, recordings in awake animals have shown that behavior, cognition, and brain state can strongly influence activity in the sensory pathways (<xref ref-type="bibr" rid="bib58">Schneider and Mooney, 2018</xref>; <xref ref-type="bibr" rid="bib35">McCormick et al., 2020</xref>; <xref ref-type="bibr" rid="bib50">Parker et al., 2020</xref>). Consistent with a hierarchical view of sensory processing in which neurons at higher levels carry progressively more complex representations of the world, such contextual influences appear particularly strong in the cortex (<xref ref-type="bibr" rid="bib65">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="bib40">Musall et al., 2019</xref>) and may to a large extent be the result of intracortical processing (<xref ref-type="bibr" rid="bib44">Noudoost et al., 2010</xref>; <xref ref-type="bibr" rid="bib57">Schneider et al., 2014</xref>; <xref ref-type="bibr" rid="bib63">Song et al., 2017</xref>). Nevertheless, non-acoustic and contextual variables can also alter sensory processing at subcortical levels, including the IC and particularly its shell (<xref ref-type="bibr" rid="bib38">Metzger et al., 2006</xref>; <xref ref-type="bibr" rid="bib19">Gruters and Groh, 2012</xref>; <xref ref-type="bibr" rid="bib11">Chen and Song, 2019</xref>; <xref ref-type="bibr" rid="bib74">Yang et al., 2020</xref>; <xref ref-type="bibr" rid="bib51">Parras et al., 2017</xref>; <xref ref-type="bibr" rid="bib56">Saderi et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Shaheen et al., 2021</xref>). This raises the possibility that these context-dependent effects may be inherited from the auditory cortex (<xref ref-type="bibr" rid="bib16">Ford et al., 2024</xref>).</p><p>To test whether auditory midbrain neurons convey behaviorally-relevant signals that depend on descending cortical inputs, we imaged corticorecipient IC shell neurons in mice engaged in a sound detection task. We found that the activity of most neurons contained information beyond the physical attributes of the sound and that this information could be used to decode the animals’ behavior with a high degree of accuracy. Surprisingly, this was the case both in mice with an intact cortex and those in which the auditory cortex had been lesioned. These findings suggest that subcortical auditory structures have access to a wealth of non-auditory information independently of descending inputs from the auditory cortex. Consequently, the contextually-enriched representations that are characteristic of sensory cortices can arise from subcortical processing.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Transient suppression of the auditory cortex impairs sound detection</title><p>Our aim was to characterize the activity of neurons in the shell of the IC in animals engaged in sound-guided behavior and assess how this activity is influenced by the input from the auditory cortex. To this end, we trained water-regulated mice on a sound detection task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) in which they were rewarded with a drop of water for licking in response to a click sound. Transient pharmacological silencing of the auditory cortex using the GABA-A agonist muscimol has been shown to abolish the ability of rodents (<xref ref-type="bibr" rid="bib67">Talwar et al., 2001</xref>), including head-fixed mice (<xref ref-type="bibr" rid="bib31">Li et al., 2017</xref>), to perform a sound detection task, making this approach unsuitable for our aim of exploring the role of IC during behavior. We found that optogenetic suppression of cortical activity by photoactivating ChR2-expressing inhibitory neurons in <italic>Gad2-IRES-cre</italic> mice (<xref ref-type="bibr" rid="bib33">Lohse et al., 2020</xref>) also significantly impaired sound detection performance (<xref ref-type="fig" rid="fig1">Figure 1B and C</xref>), albeit not to the same degree as pharmacological silencing. Although a control group in which the auditory cortex was injected with an EYFP virus lacking ChR2 would be required to confirm that the altered behavior results from an opsin-dependent perturbation of cortical activity, this result shows that this manipulation is also unsuitable for our study as it would leave us unable to determine whether any changes in the activity of IC neurons arise from removal of their auditory cortical input or are a consequence of alterations in the animals’ behavior.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Optogenetic inactivation of the auditory cortex impairs sound detection performance in head-fixed mice.</title><p>(<bold>A</bold>) Schematic of the click detection task. (<bold>B</bold>) Trial structure for experiments involving optogenetic manipulation. Stimulus trials (click) and catch trials (no click) were randomly interleaved and consecutive trials were separated by a randomly varying inter-trial interval (ITI). LEDs placed over each auditory cortex were switched on randomly in half of the stimulus and catch trials to photoactivate the opsin. A separate set of LEDs (Mask LEDs) placed directly in front of the mouse’s eyes were switched on in all Opto-on and Opto-off trials to prevent mice from visually registering the light from the photoactivation LEDs. (<bold>C</bold>) Detection performance in trials during which light was shone on the auditory cortex for optogenetic silencing (Opto LED – on) vs control trials (Opto LED - off). Different line styles indicate different mice (n=3). Numbers next to data points indicate the numbers of hit and false alarm trials over a total number of stimulus and catch trials, respectively. *p&lt;0.001, two-sided Chi-squared proportion test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig1-v1.tif"/></fig></sec><sec id="s2-2"><title>Auditory cortex lesions leave detection ability intact</title><p>Several recent studies have shown that in contrast to the disruptive effects of transient silencing, cortical lesions leave performance in some sensory tasks intact (<xref ref-type="bibr" rid="bib21">Hong et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">Ceballo et al., 2019</xref>; <xref ref-type="bibr" rid="bib47">O’Sullivan et al., 2019</xref>). In order to assess how auditory cortex lesions impact sound detection performance, we therefore compared the performance of mice with bilateral lesions of the auditory cortex (n=7) with non-lesioned controls (n=9).</p><p>Most corticocollicular neurons project ipsilaterally, with a substantial proportion also sending axons to the contralateral midbrain (<xref ref-type="bibr" rid="bib64">Stebbings et al., 2014</xref>). The majority of corticocollicular neurons are found in the temporal cortex, and overwhelmingly in the auditory fields, while a small fraction populates adjacent areas, such as the temporal association area (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). After the experiments, we injected a retrogradely-transported viral tracer (rAAV2-retro-tdTomato) into the right IC to determine whether any corticocollicular neurons remained after the auditory cortex lesions (<xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). The presence of retrogradely-labeled corticocollicular neurons in non-temporal cortical areas (<xref ref-type="fig" rid="fig2">Figure 2</xref>) was not the result of viral leakage from the dorsal IC injection sites into the superior colliculus (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Retrograde viral tracing of inferior colliculus (IC)-projecting neurons in bilaterally lesioned mice.</title><p>(<bold>A</bold>) Timeline of experimental procedures. AAV1.hSyn.cre.WPRE was injected into the right auditory cortex of GCaMP6f-reporter (Ai95D) mice. This causes transsynaptic delivery of the virus to the IC and expression of GCaMP6f in corticorecipient IC neurons. Several weeks later, the mice underwent bilateral lesioning of the auditory cortex either by aspiration or by thermocoagulation (see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> for histological sections from a mouse that underwent thermocoagulation) and were implanted with a glass window over the right auditory cortex. Following recovery from this procedure, water access was restricted and, 2–3 days later, behavioral training and imaging commenced. After data collection had been completed, rAAV2-retro-tdTomato was injected in the dorsal IC in order to label corticocollicular neurons that had remained intact. (<bold>B, C</bold>) Coronal sections showing lesion extent at different rostrocaudal positions for one example mouse. Area borders were drawn onto the images according to <xref ref-type="bibr" rid="bib52">Paxinos et al., 2001</xref>. No retrogradely-labeled neurons were found near the lesion borders, suggesting that the auditory cortex had been completely removed. Corticocollicular projections from non-temporal regions as well as thalamocollicular projections remained intact. Scale bars, 200 µm. (<bold>D</bold>) High magnification image (location shown by the upper rectangle in (<bold>B</bold>)) showing corticocollicular neurons in the visual cortex. Scale bar, 100 µm. (<bold>E</bold>) High magnification image (location shown by the lower rectangle in (<bold>B</bold>)) showing thalamocollicular neurons in the peripeduncular nucleus of the thalamus (PP). Scale bar, 100 µm. (<bold>F, G</bold>) High magnification images (locations shown by the left and right rectangles in (<bold>C</bold>), respectively) showing corticocollicular neurons in the parietal cortex. Scale bars,100 µm. Cortical area abbreviations: Au1, primary auditory; AuD, secondary auditory, dorsal; AuV, secondary auditory, ventral; Ect, ectorhinal; LPta, lateral parietal association; MPta, medial parietal association; Prh, perirhinal; RSG, retrosplenial granular; RSA, retrosplenial agranular; S1BF, primary somatosensory, barrel field; TeA, temporal association; V1, primary visual; V2L, secondary visual, lateral; V2ML, secondary visual, mediolateral; V2MM, secondary visual, mediomedial.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Contra- and ipsilateral corticocollicular neurons along the rostrocaudal axis.</title><p>Seven coronal sections are shown from each hemisphere covering approximately 2.5 mm of the rostrocaudal axis. Corticocollicular neurons were labeled by injecting a total of 150 nL of rAAV2-CAG-cre into the dorsal inferior colliculus (IC) (at three sites and several depths from 100 µm - 400 µm below the brain surface) of a tdTomato reporter mouse (Ai9). Data were obtained using whole-brain laser scanning two-photon tomography. The resulting images were grayscale inverted and thresholded to remove all background labeling so that they could be more easily arranged into a common figure. Area borders were drawn onto the images according to <xref ref-type="bibr" rid="bib52">Paxinos et al., 2001</xref>. Cortical area abbreviations: Au1, primary auditory; AuD, secondary auditory, dorsal; AuV, secondary auditory, ventral; Ect, ectorhinal; Prh, perirhinal; S1, primary somatosensory; S1BF, primary somatosensory, barrel field; S1Tr, primary somatosensory, trunk region; S2, secondary somatosensory; TeA, temporal association; V2L, secondary visual, lateral. Scale bar, 200 µm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Lesioning by thermocoagulation.</title><p>(<bold>A</bold>) Coronal section showing lesion extent in a mouse that had undergone lesioning by thermocoagulation. After data collection had been completed, rAAV2-retro-tdTomato was injected along the dorsal inferior colliculus (IC) in order to label corticocollicular neurons that had remained intact. Area borders were drawn onto the images according to <xref ref-type="bibr" rid="bib52">Paxinos et al., 2001</xref>. Scale bar, 500 µm. (<bold>B, C</bold>) Higher magnification images showing tdTomato-labeled corticocollicular neurons in the left and right visual cortex. Scale bars, 200 µm. (<bold>D, E</bold>) Higher magnification images of the temporal regions surrounding the lesion sites, show a very small number of residual corticocollicular neurons in the left and right temporal association area and the right dorsal auditory field. Scale bars, 200 µm. (<bold>F</bold>) Same as (<bold>A</bold>) for a different coronal section of the same mouse. (<bold>G, H</bold>) Higher magnification images show tdTomato-labeled corticocollicular neurons in the right visual cortex and thalamocollicular neurons in the right peripeduncular nucleus. Scale bars, 200 µm. (<bold>I, J</bold>) Higher magnification images of the temporal regions surrounding the lesion sites showing a very small number of residual corticocollicular neurons in the left and right ectorhinal cortex and the right dorsal auditory field. Scale bars, 200 µm. While the lesion procedure spared some auditory cortex tissue in this animal, its visual appearance and the fact that barely any corticocollicular neurons could be found suggests that this residual tissue was almost completely destroyed. Consequently, we categorized this animal as having a (near-)complete lesion, meaning that 5% or less of the auditory cortex was left intact. Cortical area abbreviations: Au1, primary auditory; AuD, secondary auditory, dorsal; AuV, secondary auditory, ventral; Ect, ectorhinal; TeA, temporal association; V2L, secondary visual, lateral.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Retrograde labeling of corticocollicular neurons in non-temporal areas of the cerebral cortex is not the result of viral leakage into the superior colliculus.</title><p>(<bold>A</bold>) Coronal sections showing the right midbrain of one example mouse (same mouse as in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Sections are ordered caudo-rostrally from top left to bottom right. Red lines indicate the approximate outline of the inferior colliculus, and green lines indicate the approximate outline of the superior colliculus. Red triangles indicate rAAV2-retro-tdTomato injection locations. In addition to the labeling near the injection sites, widespread retrograde labeling is found in the central nucleus of the inferior colliculus. No labeled cell bodies were found in the superior colliculus. Scale bar, 500 µm. (<bold>B</bold>) Coronal sections showing corticocollicular neurons in non-temporal areas of the right cerebral cortex labeled as a result of the rAAV2-retro-tdTomato injections in the inferior colliculus illustrated in (<bold>A</bold>). Sections are ordered caudo-rostrally from top left to bottom right. Area borders were drawn onto the images according to <xref ref-type="bibr" rid="bib52">Paxinos et al., 2001</xref>. Scale bar, 500 µm. Cortical area abbreviations: LPta, lateral parietal association; MPta, medial parietal association; M1: primary motor; M2: secondary motor; RSA, retrosplenial agranular; S1BF, primary somatosensory, barrel field; S1DZ, primary somatosensory, dysgranular region; S1HL, primary somatosensory, hindlimb region; S1Sh, primary somatosensory, shoulder region; S1ShNc, primary somatosensory, shoulder/neck region; S1Tr, primary somatosensory, trunk field; V1, primary visual; V2L, secondary visual, lateral; V2ML, secondary visual, mediolateral; V2MM, secondary visual, mediomedial.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig2-figsupp3-v1.tif"/></fig></fig-group><p>The ability of the mice to learn and perform the click detection task was evident in increasing hit rates and decreasing false alarm rates across training days (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, p&lt;0.01, mixed-design ANOVAs). There was no difference between lesioned and non-lesioned mice in their learning speed (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, p&gt;0.05, mixed-design ANOVAs) or psychometric functions (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, p&gt;0.05, mixed-design ANOVA). Cortical lesioning thus leaves behavioral sensitivity to clicks intact and therefore provides a means of examining the effects of removing corticocollicular input, albeit non-reversibly, without directly affecting sound detection performance.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Lesioned and non-lesioned mice are indistinguishable in their click detection learning rate and sensitivity.</title><p>(<bold>A</bold>) Hit rate, false alarm rate, and d’ over time for lesioned and non-lesioned animals. (<bold>B</bold>) d’ as a function of sound level. The sound levels used were not identical across all mice and were, therefore, combined into 10 dB wide bins. Error bars indicate 95% confidence intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig3-v1.tif"/></fig></sec><sec id="s2-3"><title>Transsynaptic labeling and two-photon calcium imaging of auditory corticorecipient IC neurons</title><p>Manipulations of auditory cortical activity can influence the activity of neurons throughout the IC, including the central nucleus (<xref ref-type="bibr" rid="bib66">Suga, 2008</xref>; <xref ref-type="bibr" rid="bib41">Nakamoto et al., 2008</xref>), where corticocollicular axons are relatively sparse (<xref ref-type="bibr" rid="bib64">Stebbings et al., 2014</xref>). The strongest effects, however, tend to be observed in the shell, where cortical input is densest (<xref ref-type="bibr" rid="bib41">Nakamoto et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Vila et al., 2019</xref>; <xref ref-type="bibr" rid="bib5">Blackwell et al., 2020</xref>). But even here, effects can be subtle (<xref ref-type="bibr" rid="bib69">Vila et al., 2019</xref>) or undetectable (<xref ref-type="bibr" rid="bib5">Blackwell et al., 2020</xref>), especially for cortical silencing. It is also unclear whether the IC neurons recorded in these studies receive cortical input or not. Therefore, we took a projection-specific approach to record the activity of IC neurons that receive direct input from the auditory cortex. More specifically, we injected AAV1.hSyn.Cre.WPRE, a virus with anterograde transsynaptic spread properties (<xref ref-type="bibr" rid="bib75">Zingg et al., 2017</xref>), into the right auditory cortex of, initially, a tdTomato (Ai9) reporter mouse. This resulted in the expression of Cre recombinase and the reporter gene in neurons that receive input from the auditory cortex, including the corticorecipient neurons of the IC (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). By employing this approach in GCaMP6f (Ai95D) reporter mice, we could target the expression of a calcium indicator to corticorecipient IC neurons. We then proceeded to record the activity of corticorecipient neurons within about 150 µm of the dorsal surface of the IC using two-photon microscopy (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Transsynaptic targeting and two-photon calcium imaging of corticorecipient inferior colliculus (IC) shell neurons.</title><p>(<bold>A</bold>) Coronal section of the left and right IC of a tdTomato-reporter (Ai9) mouse in which AAV1.hSyn.Cre.WPRE had been injected into the right auditory cortex three weeks before perfusion. The transsynaptically transported virus drove the expression of Cre recombinase and tdTomato in neurons that receive input from the auditory cortex, including the corticorecipient neurons in the IC. tdTomato-labeled neurons were predominantly found in the shell of the ipsilateral (right) IC. Scale bar, 500 µm. (<bold>B</bold>) In vivo two-photon micrograph taken approximately 100 µm below the dorsal surface of the right IC of a GCaMP6f-reporter mouse (Ai95D) in which GCaMP6f expression had been driven in corticorecipient IC neurons by injection of AAV1.hSyn.Cre.WPRE into the right auditory cortex. See <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref> for the corresponding video recording. Scale bar, 100 µm. (<bold>C</bold>) Example average response profiles of five corticorecipient IC neurons for different trial outcomes. Vertical line at time 0 s indicates the time of click presentation. Shaded areas represent 95% confidence intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Averaged response profiles for stimulus and catch trials.</title><p>Stimulus trials are binned into four different sound level ranges and separated into hit and miss trials. Catch trials are separated into false alarms and correct rejections. Shaded areas represent 95% confidence intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig4-figsupp1-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-89950-fig4-video1.mp4" id="fig4video1"><label>Figure 4—video 1.</label><caption><title>Two-photon calcium imaging was performed approximately 100 µm below the dorsal surface of the right inferior colliculus (IC) of a GCaMP6f-reporter mouse (Ai95D) engaged in a sound detection task.</title><p>GCaMP6f expression had been driven in corticorecipient IC neurons by injection of AAV1.hSyn.Cre.WPRE into the right auditory cortex. Video is played at twice the speed of acquisition and corresponds to the micrograph shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>.</p></caption></media></fig-group></sec><sec id="s2-4"><title>Corticorecipient IC neurons display heterogeneous response profiles</title><p>The activity of individual corticorecipient IC neurons showed distinct response profiles across neurons and trial outcomes (hit vs miss) (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). While averaging across all neurons cannot capture the diversity of responses, the averaged response profiles suggest that it is mostly trial outcome rather than the acoustic stimulus and neuronal sensitivity to sound level that shapes those responses (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Indeed, close to half (1272/2649) of all neurons showed a statistically significant difference in response magnitude between hit and miss trials, while only a small fraction (97/2649) exhibited a significant response to the sound. While the number of sound-responsive neurons is low, this is not necessarily surprising given the moderate intensity and very short duration of the stimuli. For comparison: Using the same transgenics, labeling approach, and imaging setup and presenting 200 ms long pure tones at 60 dB SPL with frequencies between 2 kHz and 64 kHz, we typically find that between a quarter and a third of neurons in a given imaging area exhibit a statistically significant response (data not shown).</p><p>To capture the heterogeneity of response patterns across all recorded neurons, we used an unsupervised clustering algorithm (<xref ref-type="bibr" rid="bib42">Namboodiri et al., 2019</xref>) to group the average responses on hit and miss trials for each neuron. This yielded 10 clusters that displayed different response patterns over the course of the trial (<xref ref-type="fig" rid="fig5">Figure 5A and B</xref>). Most of the clusters exhibited distinct activity for hit vs miss trials. Some hit trial profiles were characterized by increases or decreases in activity, with a very sharp, short-latency onset, as in clusters 4 and 10 (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for a scaled version of cluster 10), and others by much more gradual changes in which a peak occurred seconds after the trial onset, as in clusters 5 and 9. Cluster 3, which contained the smallest number of neurons, was an exception in that it showed a transient, short latency response to the stimulus for both trial outcomes. The response profiles of some other clusters, especially clusters 6 and 8, were also qualitatively similar across hit and miss trials and/or only weakly modulated across both trial types.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Corticorecipient inferior colliculus (IC) neurons display heterogeneous response profiles.</title><p>(<bold>A</bold>) Peri-stimulus time histograms for all neurons in the dataset separated by cluster identity: hit trials (top) vs miss trials (bottom). (<bold>B</bold>) Averaged response profiles obtained by taking the mean across all neurons in a cluster separately for hit (red) and miss (blue) trials. (<bold>C</bold>) Pie charts illustrate the proportion of neurons from lesioned and non-lesioned mice in each cluster. The size of each pie chart is proportional to the total number of neurons in each cluster. Given the unequal number of neurons from lesioned (952 neurons) and non-lesioned (1697 neurons) mice, the pie charts were normalized to the overall sample size such that a 50/50 split indicates a lesioned/non-lesioned distribution that is identical to that of the overall population. Asterisks indicate a significant difference between the lesioned/non-lesioned distribution in the given cluster and that in the overall population. *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001, two-sided one proportion Z-test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Rescaled response profiles for each cluster.</title><p>Averaged response profiles were obtained by taking the mean across all neurons in a cluster separately for hit (red) and miss (blue) trials. Same as <xref ref-type="fig" rid="fig5">Figure 5B</xref> except that here each panel has an individualized y-axis range.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Number of sessions for each imaging field of view size.</title><p>A greater number of recordings happened to be made with a larger field of view in non-lesioned (28 of 38) than in lesioned (13 of 37) mice. Consequently, the number of neurons recorded in non-lesioned mice was greater than that recorded in lesioned mice (1697 vs 952). Error bars represent 95% confidence intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>High correspondence between cluster profiles of lesioned and non-lesioned mice.</title><p>(<bold>A</bold>) Peri-stimulus time histograms for all neurons recorded in non-lesioned mice separated by cluster identity: hit trials (top) vs miss trials (bottom). (<bold>B</bold>) Averaged response profiles obtained by taking the mean across all neurons in each cluster separately for hit (red) and miss (blue) trials. (<bold>C, D</bold>) Same as (<bold>A</bold>) and (<bold>B</bold>) for neurons recorded in lesioned mice.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig5-figsupp3-v1.tif"/></fig></fig-group><p>This suggests that the activity of the majority of neurons in the recorded population contained information beyond the physical properties of the stimulus. Given that licking causes self-generated sounds, IC neurons could, in principle, respond to the sound of licking. However, given how quiet these are - estimated to be just 12 dB SPL (<xref ref-type="bibr" rid="bib62">Singla et al., 2017</xref>) - and that much of the response to such lick-related sounds is already canceled out at the level of the cochlear nucleus (<xref ref-type="bibr" rid="bib62">Singla et al., 2017</xref>; but see <xref ref-type="bibr" rid="bib59">Shaheen et al., 2021</xref>), it is highly unlikely that lick-related sounds play a major role in driving activity in the IC.</p><p>To assess whether certain response profiles depended on auditory cortical input, we compared the ratio of neurons from lesioned vs non-lesioned mice in each cluster to that of the overall recorded population. The number of recorded neurons was unequal for lesioned and non-lesioned mice (952 vs 1697, respectively), reflecting the fact that a greater proportion of imaging sessions in non-lesioned animals were carried out using a larger field of view, which contained larger numbers of neurons (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). To account for this, the percentages shown on the pie charts were normalized to the ratio of the overall population (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Neurons from both groups were well represented across all 10 clusters and while a significant difference in the lesioned/non-lesioned ratio was found for four clusters, the difference between the groups was greater than 20% for only one of them. Furthermore, there was a close correspondence between the cluster averages of lesioned and non-lesioned mice (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). This suggests that the IC shell can produce very similar output regardless of whether auditory cortical input is available or not.</p></sec><sec id="s2-5"><title>Behavior can be accurately decoded from neural activity in lesioned and non-lesioned mice</title><p>The average responses of individual neurons in the IC shell exhibited a variety of activity patterns associated with both the stimulus and the trial outcome (<xref ref-type="fig" rid="fig5">Figure 5A and B</xref>). To gain insight into how these activity patterns can be read out collectively on a trial-by-trial basis, we assessed the relationship between the trial-by-trial network activity and the trial outcome. We trained logistic regression models to classify hit vs miss trials on a trial-by-trial, frame-by-frame basis. As different populations of neurons were recorded in different imaging sessions, the models were trained separately for each session. ‘Dummy models,’ which randomly classified trials while taking into account the probability of hit vs miss trials in a given session, were used as the baseline model performance. If the population activity of the IC shell contained information about the trial outcome, the performance of the models would be significantly above baseline.</p><p>In both lesioned and non-lesioned mice, the average model performance was significantly above baseline in classifying hit vs miss trials (p&lt;0.05, one-sided Wilcoxon signed-rank test or paired t-test with Bonferroni correction, <xref ref-type="fig" rid="fig6">Figure 6A</xref>), showed a temporal profile that is consistent with the dynamics of the activity profiles of some of the clusters, in particular clusters 1, 2, 4, 5, 9, 10 (<xref ref-type="fig" rid="fig5">Figure 5A and B</xref>), and was not meaningfully affected by differences in sound level distributions between hit and miss trials (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Additionally, the model performance in non-lesioned mice was significantly better than that in lesioned mice (p&lt;0.05, one-sided Mann-Whitney U test or t-test with Bonferroni correction, <xref ref-type="fig" rid="fig6">Figure 6A</xref>). This difference in the decoding performance was not the result of the difference in the number of neurons between non-lesioned and lesioned mice (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Trial outcomes can be accurately decoded from neural activity in lesioned and non-lesioned mice.</title><p>(<bold>A</bold>) Average decoding accuracy of logistic regression models as a function of time against dummy models with a score of 0.5 meaning chance performance and a score of 1 being the maximum. Data shown depict the mean model accuracy across 37 (lesioned) and 38 (non-lesioned) sessions, respectively. Dots at the top indicate the time points (frames) where the model performance was significantly different between trained and dummy models for non-lesioned mice (teal) or lesioned mice (orange) (p&lt;0.05, one-sided Wilcoxon signed-rank test or paired t-test with Bonferroni correction, depending on whether normality assumption was met), and between the trained models for non-lesioned vs lesioned mice (blue) (p&lt;0.05, one-sided Mann-Whitney U test or t-test with Bonferroni correction, depending on whether normality assumption was met). (<bold>B</bold>) Same as (<bold>A</bold>) but the average model accuracy is plotted separately for mice with (near-)complete (22 sessions) and partial lesions (15 sessions). Dots at the top indicate the time points where the model performance was significantly different between partial vs (near-)complete mice (purple), (near-)complete vs non-lesioned mice (blue), and partial vs non-lesioned mice (red) (p&lt;0.05, one-sided Mann-Whitney U test or t-test with Bonferroni correction, depending on whether normality assumption was met). Shaded areas represent 95% confidence intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Trial outcome decoding is not meaningfully affected by differences in sound level distributions between hit and miss trials.</title><p>(<bold>A</bold>) Decoding results for one imaging session based on trials in which stimuli were presented at five (left), three (middle), or a single sound level (right). Thin colored lines show the results of each of the five cross-validation folds. Thick colored lines indicate averages across all five folds. Gray lines show results for the corresponding dummy models. (<bold>B</bold>) Superimposed averages from (<bold>A</bold>). (<bold>C</bold>) Hit and miss trial distributions for each of the five sound levels, as well as the mean sound level difference (Δ) between hit and miss trials for the three decoding conditions shown in (<bold>A</bold>) and (<bold>B</bold>). The mean difference was 3.08 dB, 1.01 dB, and 0 dB for the five, three, and one sound level conditions, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Greater number of recorded neurons was not associated with better decoding performance.</title><p>(<bold>A, B</bold>) Decoding performance (balanced accuracy) of the logistic regression models averaged over different 1 s time periods relative to stimulus onset as a function of the number of neurons recorded in a given session. A greater number of neurons obtained in a field of view was not associated with better decoding performance. Values above panels indicate Spearman’s rank correlation coefficient ρ. The only statistically significant relationship between the number of recorded neurons and decoding performance was found for late trial periods in non-lesioned mice (<bold>A</bold>), and indicated that for time periods &gt;2 s after stimulus onset a smaller sample size was associated with better decoding performance. **p&lt;0.01.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig6-figsupp2-v1.tif"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 3.</label><caption><title>Similar fractions of task-modulated and sound-driven neurons in lesioned and non-lesioned mice.</title><p>(<bold>A</bold>) Fraction of neurons per session that exhibit a significant difference in response magnitude between hit and miss trials. (<bold>B</bold>) Fraction of neurons per session that exhibit a significant stimulus response in miss trials. *p&lt;0.01, Mann Whitney U test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig6-figsupp3-v1.tif"/></fig><fig id="fig6s4" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 4.</label><caption><title>Lick rates in peri-catch trial periods approximate next-trial-probability.</title><p>(<bold>A</bold>) Peri-catch trial lick raster for all catch trials that followed a hit trial for one example mouse. The peri-catch trial period was defined as the period from the reward delivery in the hit trial to the onset of the trial following the catch trial. (<bold>B</bold>) Lick rate averaged across the peri-catch trial periods shown in (<bold>A</bold>) and binned into 100ms wide bins. The thick blue line shows the smoothed (20-point running average) lick rate. The inset gives a magnified view of the average lick rate during the period indicated by the gray rectangle. The red line illustrates the distribution of ‘reward-to-next-trial-onset’ intervals experienced by the example mouse. Given that licks are plotted time-locked to reward delivery, we plotted the distribution of intervals between reward delivery and the onset of the next trial rather than the inter-trial interval (ITI) distribution. In practice, the difference between the two is roughly the latency between the stimulus and the first lick and thus barely distinguishable at this scale. As the distribution indicates the probability of the next trial presentation as a function of time since the preceding reward delivery we refer to it as ‘next-trial-probability’. (<bold>C</bold>) Same as the inset in (<bold>B</bold>) averaged across all mice. Next-trial-probability was smoothed with a 20-point running average. (<bold>D</bold>) Next-trial probability as a predictor of lick rate. The dotted lines indicate the 95% confidence bounds around the regression fit. Adjusted R<sup>2</sup>=0.59. Although the next-trial probability is a good predictor of changes in the average lick rate, the lick rate at the peak of the distribution is merely about a quarter higher than at its tails where next-trial probability approaches zero. Furthermore, to put the average lick rates into perspective, note that mice tend to lick in bouts, typically consisting of two to six licks in very quick succession (see lick raster in (<bold>A</bold>)), and that, consequently, the lick rate exceeds the underlying bout rate by a factor of about four. (<bold>E</bold>) Same as (<bold>C</bold>) but with peri-catch trials binned into four quarters before averaging in order to illustrate changes in lick behavior across different stages of the experiment. (<bold>F</bold>) Same as (<bold>E</bold>) for all peri-catch trials during the initial training with a single-level stimulus. While the peri-catch trial lick rate profile changed substantially over the course of the initial training (<bold>F</bold>) and started to approximate the stimulus probability distribution towards the end of training, it remained broadly stable throughout the main experiment (<bold>E</bold>). In order to increase the statistical power of this analysis, we included data from several additional mice used in other projects. These additional mice received the same training and performed the same task, but differed from those in the main dataset in that they had a different genetic background and/or had been fitted with a cranial implant for cortical rather than midbrain imaging. N for panels (<bold>C–F</bold>) = 34 mice.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89950-fig6-figsupp4-v1.tif"/></fig></fig-group><p>By examining the corticocollicular labeling and referencing the histological sections against a mouse brain atlas (<xref ref-type="bibr" rid="bib52">Paxinos et al., 2001</xref>), we categorized the mice according to lesion size. Four of the seven lesioned animals had ‘(near-)complete’ lesions, meaning that all (<xref ref-type="fig" rid="fig2">Figure 2</xref>) or an estimated ~95% (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>) of the auditory cortex had been lesioned, while the remaining mice had ‘partial’ lesions, with an estimated 15–25% of the auditory cortex left intact. To assess whether the size of the lesions impacted the decoding performance, we compared the model performance between mice that had (near-)complete lesions and mice that had partial lesions. This revealed that the average decoding performance for mice with (near-)complete lesions was significantly better than that measured for mice with partial lesions. While this pattern of results may be unexpected, it is consistent with work showing smaller lesions being associated with greater somatosensory processing deficits (<xref ref-type="bibr" rid="bib21">Hong et al., 2018</xref>). Additionally, the decoding performance in mice with (near-)complete lesions was largely indistinguishable from that in mice with an intact auditory cortex. Although the proportion of individual neurons with distinct response magnitudes in hit and miss trials in lesioned mice did not differ from that in non-lesioned mice, it was significantly lower when separating out mice with partial lesions (<xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3</xref>). These results imply that the activity of IC shell neurons can contain similar amounts of information about the animal’s behavior regardless of whether descending input from the cortex is available or not (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p></sec><sec id="s2-6"><title>Pre-stimulus activity is predictive of the upcoming trial outcome</title><p>Remarkably, decoding accuracy was better than baseline even before stimulus onset. This could reflect changes in the network state that led or contributed to the upcoming trial outcome. For instance, changes in arousal or motivation can alter both the probability that an upcoming stimulus is detected and the activity of neurons in the network (<xref ref-type="bibr" rid="bib28">Lee and Dan, 2012</xref>; <xref ref-type="bibr" rid="bib36">McGinley et al., 2015</xref>). The decoding models might detect such changes in activity, resulting in higher decoding accuracy prior to stimulus onset. Additionally, pre-stimulus differences in hit and miss trial activity could also reflect the anticipation of an upcoming stimulus (<xref ref-type="bibr" rid="bib55">Ruth et al., 1974</xref>; <xref ref-type="bibr" rid="bib43">Nienhuis and Olds, 1978</xref>; <xref ref-type="bibr" rid="bib38">Metzger et al., 2006</xref>) and the resulting change in attentional state. Inter-trial intervals in our experiments were randomly drawn from a normal distribution with a mean and standard deviation of 8 s and 2 s, respectively, and a lower bound of 3 s. Nevertheless, spontaneous licks did not occur at random times during the peri-catch trial periods following hit trials. Instead, average lick rates approximated the inter-trial interval distribution (<xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4A–D</xref>), suggesting that mice learned to adapt their behavior to this distribution and anticipate the timing of upcoming stimuli (<xref ref-type="fig" rid="fig6s4">Figure 6—figure supplement 4E and F</xref>). Assuming that successfully anticipating the timing of an upcoming stimulus confers a greater chance of detecting the stimulus, neurons whose activity reflects that anticipation might be expected to show differences in pre-trial activity between hit and miss trials that could be detected by a decoding model. Note that for the analysis illustrated in <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref>, hit trials were excluded if there were any licks between –500 ms and +120 ms (the latter number representing the lower bound of the animals’ lick-latency) relative to stimulus onset, suggesting that changes in pre-stimulus activity cannot be directly related to licking.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Imaging auditory corticorecipient neurons in the dorsal shell of the IC in mice trained to perform a sound detection task revealed that the majority of neurons exhibited distinct activity profiles for hit and miss trials, implying that they encode information beyond just the physical attributes of the stimulus. Indeed, using logistic regression models to classify hit vs miss trials, we found that the animals’ behavioral choices can be read out from these neurons with a high degree of accuracy. Importantly, the difference in IC activity between hit and miss trials was observed across different sound levels and was not due to a difference in the sound level distribution for these two trial outcomes. Surprisingly, neural activity profiles and the decoding performance were similar in mice in which the auditory cortex had been lesioned bilaterally, suggesting that the midbrain has, independently of the auditory cortex, access to a wealth of non-acoustic information, which may be sufficient to support sound detection behavior.</p><p>Auditory corticocollicular axons terminate predominantly in the shell of the IC (<xref ref-type="bibr" rid="bib64">Stebbings et al., 2014</xref>; <xref ref-type="bibr" rid="bib3">Bajo and King, 2013</xref>) and the strongest effects of cortical manipulations have been reported in this region (<xref ref-type="bibr" rid="bib41">Nakamoto et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Vila et al., 2019</xref>; <xref ref-type="bibr" rid="bib5">Blackwell et al., 2020</xref>). However, these effects can be subtle (<xref ref-type="bibr" rid="bib13">Cruces-Solís et al., 2018</xref>; <xref ref-type="bibr" rid="bib69">Vila et al., 2019</xref>) or undetectable, especially when optogenetic silencing is used (<xref ref-type="bibr" rid="bib5">Blackwell et al., 2020</xref>). Because of this and uncertainties over exactly what proportion of neurons in the shell of the IC is innervated by the auditory cortex and even where the border lies with the underlying central nucleus (<xref ref-type="bibr" rid="bib4">Barnstedt et al., 2015</xref>), we used an anterograde transsynaptic tagging approach (<xref ref-type="bibr" rid="bib75">Zingg et al., 2017</xref>) to identify corticorecipient neurons. This, therefore, maximized the chances of revealing the contribution of descending cortical input to the response properties of these midbrain neurons. We imaged across the optically accessible dorsal surface of the IC down to a depth of about 150 µm below the surface. Consequently, the neurons we recorded were located predominantly in the dorsal cortex. However, identifying the borders between different subdivisions of the IC is not straightforward and we cannot rule out the possibility that some were located in the lateral cortex.</p><sec id="s3-1"><title>Inferior colliculus neurons exhibit task-related activity</title><p>Our recordings from corticorecipient neurons in the IC are consistent with previous studies demonstrating that neural representations of behavioral variables can be found in the auditory midbrain (<xref ref-type="bibr" rid="bib55">Ruth et al., 1974</xref>; <xref ref-type="bibr" rid="bib43">Nienhuis and Olds, 1978</xref>; <xref ref-type="bibr" rid="bib38">Metzger et al., 2006</xref>; <xref ref-type="bibr" rid="bib19">Gruters and Groh, 2012</xref>; <xref ref-type="bibr" rid="bib11">Chen and Song, 2019</xref>; <xref ref-type="bibr" rid="bib74">Yang et al., 2020</xref>; <xref ref-type="bibr" rid="bib56">Saderi et al., 2021</xref>; <xref ref-type="bibr" rid="bib14">De Franceschi and Barkat, 2021</xref>; <xref ref-type="bibr" rid="bib59">Shaheen et al., 2021</xref>; <xref ref-type="bibr" rid="bib54">Quass et al., 2024</xref>). In keeping with responses recorded in the auditory cortex (<xref ref-type="bibr" rid="bib17">Francis et al., 2018</xref>; <xref ref-type="bibr" rid="bib14">De Franceschi and Barkat, 2021</xref>) and IC (<xref ref-type="bibr" rid="bib11">Chen and Song, 2019</xref>; <xref ref-type="bibr" rid="bib74">Yang et al., 2020</xref>; <xref ref-type="bibr" rid="bib14">De Franceschi and Barkat, 2021</xref>) of behaving mice, we found that the activity of most neurons was facilitated and about a third were suppressed during the sound detection task. Overall, only a small minority of clusters (mostly cluster 3) in our dataset showed what could be characterized as largely behavior-invariant response profiles to the auditory stimulus. In contrast, a large number of neurons were clearly driven by variables other than the stimulus itself. Their activity may represent the choice (to lick or not to lick) that an animal made, preparatory motor activity, corollary discharge, or the reward and the somatosensory or gustatory feedback associated with its consumption, as well as modulation by the animal’s cognitive and behavioral state. Due to the task structure used, for the most part, it was not possible to unambiguously assign activity profiles to a particular variable. Nevertheless, we can speculate that neurons with late transients, such as in cluster 5, are more likely to represent corollary discharge and signals associated with the consumption of the reward, while those with very short latency peaks, as in clusters 4 and 10, may represent the animals’ choice and/or preparatory motor activity.</p><p>When engaged in the detection task, an animal’s arousal or motivational state may vary spontaneously or as a result of changes in, for instance, thirst, time of day, or time into a session. In addition, cognitive factors, such as expectations about the timing of an upcoming trial (<xref ref-type="bibr" rid="bib55">Ruth et al., 1974</xref>; <xref ref-type="bibr" rid="bib43">Nienhuis and Olds, 1978</xref>; <xref ref-type="bibr" rid="bib38">Metzger et al., 2006</xref>), which mice may have derived by learning the shape of the inter-trial interval distribution, may lead to variations in arousal or attentional state. Pre-trial differences in activity as well as the above-chance decoding performance before trial onset likely reflect the joint impact of those state changes on the activity of IC corticorecipient neurons and detection sensitivity (<xref ref-type="bibr" rid="bib35">McCormick et al., 2020</xref>).</p></sec><sec id="s3-2"><title>Contribution of the auditory cortex to task-related activity in the midbrain</title><p>Given the massive corticofugal projections that exist within the auditory system (<xref ref-type="bibr" rid="bib3">Bajo and King, 2013</xref>), we hypothesized that task-related activity in the IC might depend on descending inputs from the auditory cortex. To address this, we imaged corticorecipient IC neurons during the same sound detection task after removing the cortical input. Consistent with previous work in the auditory (<xref ref-type="bibr" rid="bib47">O’Sullivan et al., 2019</xref>) and somatosensory systems (<xref ref-type="bibr" rid="bib21">Hong et al., 2018</xref>), we found that transient optogenetic silencing of the auditory cortex impaired sound detection, whereas cortical lesions had no effect on detection behavior, with lesioned mice learning the task as quickly as non-lesioned animals and achieving the same level of performance. In order to determine whether the absence of auditory cortical input alters the activity of IC neurons during sound detection behavior, we therefore focused on mice with bilateral cortical lesions to avoid the potentially confounding effects that reduced detection sensitivity produced by transient cortical silencing might have on the activity of IC neurons. For the same reason, we opted against the more targeted approach of optogenetic silencing of corticocollicular axons. Furthermore, it would have been difficult to silence the entire corticocollicular projection and the higher light powers required for manipulating axons compared to somata would have risked transmitting light to the cortex or other corticofugal targets, potentially causing behavioral changes and/or sacrificing specificity. Locally silencing corticocollicular axons would also have left indirect transmission via the thalamus between the auditory cortex and IC intact and would have been very challenging to verify. Finally, it has been reported that using optogenetic silencing tools in axons can have unintended consequences (<xref ref-type="bibr" rid="bib71">Wiegert et al., 2017</xref>).</p><p>In keeping with our findings, numerous studies (reviewed in e.g. <xref ref-type="bibr" rid="bib53">Pickles, 1988</xref>; <xref ref-type="bibr" rid="bib7">Buser and Imbert, 1992</xref>) have shown that simple auditory skills, including the ability of freely moving rats to detect sounds (<xref ref-type="bibr" rid="bib26">Kelly, 1970</xref>), are unaffected by the removal of the auditory cortex. However, transient pharmacological silencing of the auditory cortex in freely moving rats (<xref ref-type="bibr" rid="bib67">Talwar et al., 2001</xref>), as well as head-fixed mice (<xref ref-type="bibr" rid="bib31">Li et al., 2017</xref>), completely abolishes sound detection (but see <xref ref-type="bibr" rid="bib18">Gimenez et al., 2015</xref>). The time course of the effects produced by muscimol application (<xref ref-type="bibr" rid="bib67">Talwar et al., 2001</xref>) suggests that there is a relationship between the size of the behavioral deficit and the degree of cortical inactivation. Consequently, milder impairments may be produced by the optogenetic approaches employed by us and others (<xref ref-type="bibr" rid="bib24">Kato et al., 2015</xref>; <xref ref-type="bibr" rid="bib47">O’Sullivan et al., 2019</xref>) because of incomplete suppression of cortical activity. Alternatively, the larger behavioral effects reported following muscimol application may be due to diffusion of the drug to other brain structures, potentially including the IC. Although our results cannot speak directly to the question of whether the preservation of sound detection without auditory cortex reflects a rewiring or repurposing of circuits in the brain, this seems unlikely given that other studies have shown that trained mice achieve pre-lesion performance levels on simple auditory discrimination (<xref ref-type="bibr" rid="bib9">Ceballo et al., 2019</xref>; <xref ref-type="bibr" rid="bib47">O’Sullivan et al., 2019</xref>) or somatosensory detection (<xref ref-type="bibr" rid="bib21">Hong et al., 2018</xref>) tasks suddenly and within 48 hr following cortical ablation.</p><p>Why then does transient inactivation produce behavioral deficits? One possibility is that disabling the auditory cortex impacts behavior not because it contributes necessary computations or information, but because of the sudden and disruptive removal of tonic excitation (<xref ref-type="bibr" rid="bib45">Oberle et al., 2022</xref>) to downstream targets (<xref ref-type="bibr" rid="bib48">Otchy et al., 2015</xref>) that are indispensable for successful sound detection. In this scenario, normal operation would resume once synaptic scaling (<xref ref-type="bibr" rid="bib25">Keck et al., 2013</xref>) had homeostatically restored normal activity in these structures, a process that has been suggested to take up to 48 hr and is consistent with the time course of recovery after lesions (<xref ref-type="bibr" rid="bib9">Ceballo et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Hong et al., 2018</xref>). Alternatively, several circuits may redundantly support sound detection. Silencing the auditory cortex might then transiently impede sound detection until the relevant downstream decision and motor structures have updated their synaptic weights and/or processing has shifted to the other circuits. Two observations, however, argue against this possibility. First, removing one of several redundant structures should leave some residual function intact and not have the devastating effect that pharmacological cortical silencing achieves (<xref ref-type="bibr" rid="bib67">Talwar et al., 2001</xref>, <xref ref-type="bibr" rid="bib31">Li et al., 2017</xref>). Second, other circuits mediating the acousticomotor transformation required for successful sound detection behavior very likely incorporate subcortical auditory structures, including the auditory midbrain. Activity in the IC may trigger actions (<xref ref-type="bibr" rid="bib8">Casseday and Covey, 1996</xref>), such as licking, via its direct projections to the superior colliculus, pontine nuclei and the periaqueductal gray (<xref ref-type="bibr" rid="bib22">Huffman and Henson, 1990</xref>; <xref ref-type="bibr" rid="bib70">Wenstrup et al., 1994</xref>; <xref ref-type="bibr" rid="bib8">Casseday and Covey, 1996</xref>; <xref ref-type="bibr" rid="bib73">Xiong et al., 2015</xref>) or indirectly via its projections to the auditory thalamus. If cortical lesioning results in a greater weight being placed on the activity in spared subcortical circuits for perceptual judgements, we would expect the accuracy with which trial-by-trial outcomes could be read out from IC neurons to be greater in mice without auditory cortex. However, that was not the case. This could imply that, following cortical lesions, greater weight is placed on structures other than the IC, with the thalamus being an obvious candidate, or that the auditory midbrain, thalamus and cortex are bypassed entirely if simple acousticomotor transformations, such as licking a spout in response to a sound, are handled by circuits linking the auditory brainstem and motor thalamus via pedunculopontine and midbrain reticular nuclei (<xref ref-type="bibr" rid="bib23">Inagaki et al., 2022</xref>).</p><p>Some differences were observed for mice with only partial lesions of the auditory cortex. Those mice had a lower proportion of neurons with distinct response magnitudes in hit and miss trials than mice with (near-)complete lesions. Furthermore, trial outcomes could be read out with lower accuracy from these mice. While this finding is somewhat counterintuitive and is based on only three mice with partial lesions, it has been observed before that smaller lesions can have a more disruptive effect than larger, more complete lesions, in that the time it takes mice to learn a whisker-dependent sensory detection task is anticorrelated with the size of their somatosensory cortex lesion (<xref ref-type="bibr" rid="bib21">Hong et al., 2018</xref>). While the complete destruction of a cortical area severs all its communication with downstream structures, a partial lesion may actually be more disruptive by eradicating normal local processing while at the same time leaving intact some tissue, especially in the deeper output layers, which continues to transmit what are now aberrant activity patterns. The difference in decoding accuracy that we observed in the IC could thus be a consequence of residual and now disruptive cortical input.</p><p>Our results show that behavioral variables are encoded by corticorecipient neurons in the dorsal shell of the IC independently of their main source of descending input, the auditory cortex. It therefore seems likely that this region of the auditory midbrain is part of the circuit that supports sound detection behavior in the absence of the auditory cortex. Nevertheless, except for the regions immediately bordering the auditory cortex, corticocollicular neurons located in other areas were left intact. These relatively sparse descending projections to the IC, such as those originating from somatosensory cortical areas (<xref ref-type="bibr" rid="bib33">Lohse et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Lesicko et al., 2016</xref>) and the parietal cortex, may have contributed to the response profiles that we observed. Additional non-acoustic sensory input can reach the IC via brainstem nuclei (<xref ref-type="bibr" rid="bib30">Lesicko et al., 2016</xref>; <xref ref-type="bibr" rid="bib61">Shore and Zhou, 2006</xref>) and the superior colliculus (<xref ref-type="bibr" rid="bib10">Chen et al., 2018</xref>; <xref ref-type="bibr" rid="bib12">Coleman and Clerici, 1987</xref>). The latter, together with input from the substantia nigra (<xref ref-type="bibr" rid="bib46">Olaźabal and Moore, 1989</xref>) and the globus pallidus (<xref ref-type="bibr" rid="bib39">Moriizumi and Hattori, 1991</xref>) may also be a source of motor signals, while state changes may impact on the IC via inputs from neuromodulatory structures, including the locus coeruleus and the subparafascicular, dorsal raphe and tegmental nuclei (<xref ref-type="bibr" rid="bib11">Chen and Song, 2019</xref>, <xref ref-type="bibr" rid="bib32">Liu et al., 2023</xref>).</p></sec><sec id="s3-3"><title>Conclusion</title><p>Behavior is a major determinant of activity in the non-lemniscal auditory midbrain and thus key to understanding how it contributes to hearing. The anatomical feature that defines this structure more than any others is its connection with the auditory cortex. While modulation of IC activity by this descending projection has been implicated in various functions, most notably in the plasticity of auditory processing, we have shown in mice performing a sound detection task that IC neurons show task-related activity in the absence of auditory cortical input. These results, therefore, emphasize more than ever the need to factor in subcortical processing when considering how the cortex contributes to sound-guided behavior.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>All experiments were approved by the Committee on Animal Care and Ethical Review at the University of Oxford and were licensed by the UK Home Office (Animal Scientific Procedures Act, 1986, amended in 2012). We used 22 (three female, 19 male) B6;129S-<italic>Gt(ROSA)26Sor<sup>tm95.1(CAG-GCaMP6f)Hze</sup></italic>/J (Ai95D, JAX 024105, Jackson Laboratories, USA), three (one female, two male) Gad2<sup>tm2(cre)Zjh</sup>/J (JAX 010802), six female B6.Cg-<italic>Gt(ROSA)26Sor<sup>tm9(CAG-tdTomato)Hze</sup></italic>/J (Ai9, JAX 007909), two female Ai95D X Slc32a1<sup>tm2(cre)Lowl</sup>/J (JAX 016962), three female Ai95D X B6.Cg-Tg(<italic>Camk2a</italic>-cre)T29-1Stl/J (JAX 005359, Jackson Laboratories, USA), and three (one male, two female) C57BL/6NTac.<italic>Cdh23<sup>753A&gt;G</sup></italic> (MRC Harwell, UK) mice. All mice were 9–15 weeks old during data collection. They were maintained on a 12 hr light/dark cycle and were housed at 20–24°C with a relative humidity of 45–65%.</p></sec><sec id="s4-2"><title>Surgeries</title><p>For all surgical procedures, mice were premedicated with intraperitoneal injections of dexamethasone (Dexadreson, 4 mg), atropine (Atrocare, 1 mg), and carprofen (Rimadyl, 0.15 mg) before being anesthetized with isoflurane (1.5–2%) and administered with buprenorphine (Vetergesic, 1 ml/kg) postoperatively. Mice were then placed in a stereotaxic frame (Model 900LS, David Kopf Instruments, CA, USA) and their body temperature was kept constant at 37 °C by the use of a heating mat and a DC temperature controller in conjunction with a temperature probe (FHC, ME, USA).</p><p>For injections in the auditory cortex of AAV1.hSyn.Cre.WPRE (Penn Vector Core), the skin over this part of the brain was shaved and an incision was made, after which three small holes were drilled (Foredom K.1070, Blackstone Industries, CT, USA) into the skull with a 0.4 mm drill bit and the virus injected using a pulled glass pipette and a custom pressure injection system. In order to express GCaMP6f or tdTomato in IC neurons that receive auditory cortical inputs, a total of 150–200 nl of AAV1.hSyn.Cre.WPRE was injected at three sites in the right auditory cortex of GCaMP6f (Ai95D) or tdTomato (Ai9) reporter mice, respectively, at depths of 450–550 μm below the brain surface. Given the anterograde transsynaptic spread properties of AAV1 (<xref ref-type="bibr" rid="bib75">Zingg et al., 2017</xref>), this caused the expression of the desired fluorescent protein in structures that the auditory cortex projects to, including the shell of the IC (<xref ref-type="fig" rid="fig4">Figure 4A and B</xref>).</p><p>In order to prepare Gad2-Ires-Cre mice for the optogenetics experiments, we removed a large flap of skin over the parietal and temporal bones, partially removed the temporal muscles, and performed a circular craniotomy of 3 mm diameter over each auditory cortex. We then injected a total of 500 nl of AAV5-EF1a-DIO-hChR2-EYFP (UNC Vector Core) bilaterally across four sites and two depths (200 and 600 μm) into the auditory cortex. Each craniotomy was covered with a circular 3 mm glass window that was attached to the edges of the skull with cyanoacrylate glue (Pattex Ultra Gel, Henkel), and the exposed skull was sealed with dental acrylic (C&amp;B Superbond, Sun Medical, Japan) into which a custom steel bar was embedded for head fixation. Experiments commenced approximately three weeks afterward.</p><p>The IC window implantation and cortical lesioning in the Ai95D mice were performed at least three weeks after the injections. The window implantation involved removing a flap of skin over the (inter-)parietal and occipital bone and making a circular 3 mm craniotomy over the midbrain. A 3 mm diameter glass coverslip that had been glued to a ~1 mm tall steel cylinder with 0.5 mm wall thickness was inserted into this craniotomy. The cylinder allowed us to press the glass window gently onto the brain (in order to minimize brain movement during experiments) and was then glued to the edges of the skull. For head fixation, we embedded a custom steel plate in the dental acrylic used to seal the exposed bone.</p><p>Lesions were performed as part of the cranial window implantation surgery. In those mice undergoing lesions, we removed a slightly larger flap of skin on both sides in order to expose the temporal bone, detached and deflected and/or partly removed the temporal muscle, and then made, on both sides, an elliptical craniotomy over the auditory cortex of ~3 mm (dorsoventral) by 4 mm (rostrocaudal). The exposed tissue was then aspirated (<xref ref-type="bibr" rid="bib21">Hong et al., 2018</xref>) with a blunted 19 G needle connected to a suction pump (Eschmann Vp25, UK) or destroyed by thermocoagulation (<xref ref-type="bibr" rid="bib9">Ceballo et al., 2019</xref>) with a cauterizer (Small Vessel Cauterizer Kit, FST, Germany) and the piece of skull that had been removed for the craniotomy was glued (Pattex Ultra Gel) back in place. In some of the lesioned mice, after completion of the imaging, 150 nl of a retrograde viral construct (rAAV2-CAG-tdTomato, UNC Vector Core) was injected into the dorsal IC across two to three sites at depths of 100–400 μm below the brain surface in order to visualize the remaining IC-projecting cortical neurons. The extent of the lesions was estimated from the histological sections and by referencing them against sections from a mouse brain atlas (<xref ref-type="bibr" rid="bib52">Paxinos et al., 2001</xref>). The experimenters were not blinded to the treatment group, i.e., lesioned or non-lesioned, but they were blind to the lesion size both during the behavior experiments and most of the data processing.</p><p>In order to visualize the distribution of IC-projecting neurons in mice without cortical lesions, 150 nl of the retrograde rAAV2-CAG-cre (UNC Vector Core) construct was injected into the dorsal IC of one Ai9 mouse with an intact cortex across three sites at depths of 100–400 μm below the brain surface.</p></sec><sec id="s4-3"><title>Histology</title><p>For histological processing, mice were perfused transcardially, first with phosphate-buffered saline (PBS) and then with 4% paraformaldehyde in (PBS), and their brains were sectioned coronally (100 μm thick) with a vibratome (Leica). Images were taken manually using a Leica DMR microscope, a confocal laser scanning microscope (Olympus FV1000), or with an automated slide scanner (Zeiss Axioscan Z1). The brain of one mouse (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) was sectioned and imaged on a custom-built two-photon whole brain tomograph.</p></sec><sec id="s4-4"><title>Click detection task</title><p>Starting 2–3 days before training commenced, the mice were habituated to head fixation in the experimental setup, and their access to water was restricted to about ~1 ml per day, bringing their body weight down to about ~85% of the pre-restriction values. During the training phase, the mice were required to report a 0.5ms broadband click stimulus of 80 dB SPL by licking a waterspout positioned in front of them. Licking within a 1.5 s response window (occasionally this was reduced in duration to discourage excessive licking) triggered an immediate water reward (~2 μl). Stimulus trials and catch (no stimulus) trials were randomly interleaved with an inter-trial interval drawn from a normal distribution with a mean and standard deviation of 8 s and 2 s, respectively, and a lower bound of 3 s. Successful reporting of the sound within the response window was scored a ‘hit,’ while failure to respond was scored a ‘miss.’ During catch trials, neither licking (‘false alarm’) during the 1.5 s response window nor withholding licking (‘correct rejection’) triggered a reward. To help the mice form an association between sound and reward, they received occasional ‘free’ rewards in stimulus trials during the initial training even when no licking occurred.</p><p>Once the mice had achieved a stable level of performance (typically two days with d’&gt;1.5), quieter stimuli (41–71 dB SPL) were introduced. For each mouse, a total of 9 different sound levels were used and the range of sound levels was adjusted to each animal’s behavioral performance to avoid floor and ceiling effects and could, therefore, differ from mouse to mouse. The behavioral experiments were run using custom MATLAB (MathWorks) scripts interfacing with a National Instruments board (NI USB-6501) for reward delivery and lick registration. The stimuli were presented using Psychtoolbox through a free-field speaker (Vifa, Avisoft Bioacoustics, Germany), positioned about ~15 cm from the snout of the mouse. Stimuli were calibrated using a Pettersson M500 microphone, which was itself referenced to a sound-level calibrator (Iso-Tech SLC-1356). Stimulus levels were calibrated by integrating the recorded RMS of clicks over the mouse hearing range (1–100 kHz) and comparing this to the RMS of stimuli from the reference sound-level calibrator.</p><p>In the optogenetics experiments, the behavioral task was identical except that a single sound level (80 dB SPL) was used and on 50% of the trials bilateral photostimulation (20 Hz, 10ms pulses, 0.2 mW/mm<sup>2</sup>) was performed via two 470 nm LEDs (CREE-XP-E2, LED-Tech, Germany) positioned above the cranial windows. LED-on and LED-off trials were randomly interleaved and stimulation lasted for 700 ms starting 50 ms before trial onset. Furthermore, masking flashes were presented in all trials from two bright LEDs (60 mW) positioned a few cm in front of the animals’ eyes.</p></sec><sec id="s4-5"><title>Two-photon calcium imaging</title><p>Imaging was performed at a depth of 50 μm – 150 μm from the IC surface using a commercial two-photon laser-scanning microscope (B-Scope, ThorLabs, VA, USA), a SpectraPhysics Mai-Tai eHP laser (Spectra-Physics, CA, USA) tuned to 930 nm, and a Nikon 16 × 0.8 NA objective. Images were acquired with a resolution of 512 by 512 pixels at a rate of ~28 Hz. The size of the field of view was either 500 µm by 500 µm or 666 µm by 666 µm, which allowed us to, typically, image dozens of corticorecipient IC neurons simultaneously. Each imaging session lasted around 1–2 hr.</p></sec><sec id="s4-6"><title>Image processing</title><p>Rigid and non-rigid image registration, segmentation, neuropil, and signal extraction were performed using the Python version of suite2p (<xref ref-type="bibr" rid="bib49">Pachitariu et al., 2017</xref>). Neuropil extraction was performed using default suite2p parameters (<ext-link ext-link-type="uri" xlink:href="https://suite2p.readthedocs.io/en/latest/settings.html">https://suite2p.readthedocs.io/en/latest/settings.html</ext-link>), neuropil correction was done using a coefficient of 0.7 and calcium ΔF/F signals were obtained by using the median over the entire fluorescence trace as F0. To remove slow fluctuations in the signal, a baseline of each neuron’s entire trace was calculated by Gaussian filtering as well as minimum and maximum filtering using default suite2p parameters. This baseline was then subtracted from the signal. To assess the extent of image displacement in the z-axis, we compared the average of the top and the bottom 500 frames of each spatial principal component (PC) of the registered images for every 8–16 min of the recordings. Any region of interest (ROI) with substantial z-axis movement was excluded from further analysis. Sessions in which the majority of ROIs had to be excluded were discarded entirely. Furthermore, in order to specifically assess brain motion caused by the motor component of the task, i.e., the animal’s licking, lick-triggered movies of the imaging frames were created for every 8–16 min of the recordings. The rationale here is that if licking causes a stereotypical displacement of the imaging plane, this will become apparent when image sequences are averaged across lick events. Specifically, non-registered image sequences surrounding (from 2 s before to 2 s after) lick events were used to produce averaged lick-triggered movies. These lick-triggered movies, as well as non-averaged sequences, were then visually inspected and ROIs were excluded from subsequent analysis if they were affected by substantial z-motion.</p></sec><sec id="s4-7"><title>Analysis of task-modulated and sound-driven neurons</title><p>To identify individual neurons that produced significantly different response magnitudes in hit and miss trials, we calculated the mean activity for each stimulus trial by taking the mean activity over the 5 s following the stimulus presentation and subtracting the mean activity over the 2 s preceding the stimulus during that same trial. A Mann-Whitney U test was then performed to assess whether a neuron showed a statistically significant difference (Benjamini-Hochberg adjusted p-value of 0.05) in response magnitude between hit and miss trials. The analysis was performed using equal numbers of hit and miss trials at each sound level to ensure balanced sound level distributions. If, for a given sound level, there were more hit than miss trials, we randomly selected a sample of hit trials (without substitution) to match the sample size for the miss trials and vice versa. Sound-driven neurons were identified by comparing the mean miss trial activity before and after stimulus presentation. Specifically, we performed a Wilcoxon signed rank test to assess whether there was a statistically significant difference (Benjamini-Hochberg adjusted p-value of 0.05) between the mean activity over the 2 s preceding the stimulus and the mean activity over the 1-s period following stimulus presentation. This analysis was performed using miss trials with click intensities from 53 dB SPL to 65 dB SPL (many sessions contained very few or no miss trials for higher sound levels).</p></sec><sec id="s4-8"><title>Clustering analysis</title><p>To identify sub-populations of neurons with distinct response profiles, a clustering analysis was performed. While clustering is a useful approach for organizing and visualizing the activity of large and heterogeneous populations of neurons, we need to be mindful that, given continuous distributions of response properties, the locations of cluster boundaries can be somewhat arbitrary and/or reflect idiosyncrasies of the chosen method and thus vary from one algorithm to another. We employed an approach very similar to that described in <xref ref-type="bibr" rid="bib42">Namboodiri et al., 2019</xref> because it is thought to produce stable results in high-dimensional neural data (<xref ref-type="bibr" rid="bib20">Hirokawa et al., 2019</xref>). For each neuron, the trial-averaged activity was obtained by averaging across all the sound levels presented in a given session separately for hit and miss trials (given the small number of catch trials, approximately one-tenth of all trials, this analysis was restricted to stimulus trials only). Differences in the field of view size between sessions resulted in slight differences in frame rate and thus frame duration. Therefore, the activity traces were linearly interpolated to have the same number of data points (193 frames). For each neuron, the trial-averaged activity for missed trials was appended to that for hit trials, producing 386 data points per neuron for a total of 2649 neurons (n=1,697 neurons from 40 sessions with nine non-lesioned mice; n=952 neurons from 40 sessions with seven lesioned mice). To reduce the dimensionality of this dataset before applying the clustering algorithm, we performed principal components analysis (PCA) along the time axis to capture the temporal response profile for each neuron. Guided by the ‘elbow’ point in a scree plot visualizing the fraction of variance explained by each PC, we decided to project the dataset to the lower dimensional subspace formed by the first nine PCs.</p><p>Spectral clustering was used to cluster the resulting data. The affinity matrix was constructed by computing a graph of nearest neighbors. The hyperparameters of the clustering algorithm, including the number of nearest neighbors and the number of clusters, were optimized by a grid search to maximize the mean Silhouette Score for all samples. The Silhouette Score is a measure of the compactness of individual clusters (intra-cluster distance) and the separation amongst clusters (inter-cluster distance). For a given sample <inline-formula><mml:math id="inf1"><mml:mi>i</mml:mi></mml:math></inline-formula> that belongs to a cluster <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the Silhouette Score is defined as:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean distance between sample <inline-formula><mml:math id="inf4"><mml:mi>i</mml:mi></mml:math></inline-formula> and all the other samples in the same cluster, and <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean distance of sample <inline-formula><mml:math id="inf6"><mml:mi>i</mml:mi></mml:math></inline-formula> to the nearest cluster that sample <inline-formula><mml:math id="inf7"><mml:mi>i</mml:mi></mml:math></inline-formula> is not part of. Let <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>∨</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mo>∨</mml:mo></mml:math></inline-formula> be the number of samples belonging to clusters <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf12"><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> be the distance between samples <inline-formula><mml:math id="inf13"><mml:mi>i</mml:mi></mml:math></inline-formula> and <italic>j</italic>; <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are defined as:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>∨</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>J</mml:mi><mml:mo>≠</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mo>∨</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The resulting clusters from the hyperparameter search were further examined by plotting clusters in pairs against each other with t-distributed Stochastic Neighbor Embedding, a statistical method for visualizing high-dimensional data that involves giving each data point a location in a two or three-dimensional space (<xref ref-type="bibr" rid="bib68">van der Maaten and Hinton, 2008</xref>).</p></sec><sec id="s4-9"><title>Population decoding</title><p>Logistic regression models were trained on the network activity of each session, i.e., the ΔF/F values of all ROIs in each session, to classify hit vs miss trials. This was done on a frame-by-frame basis, meaning that each time point (frame) of each session was trained separately. Rather than including all the trials in a given session, only trials of intermediate difficulty were used for the decoding analysis. More specifically, we only included trials across five sound levels, comprising the lowest sound level that exceeded a d’ of 1.5 plus the two sound levels below and above that level. That ensured that differences in sound level distributions would be small, while still giving us a sufficient number of trials to perform the decoding analysis. Sessions were only included if there were at least 15 instances for both hit and miss trials. The models were trained with L2 regularization, which gave similar contributions to correlated features (i.e. individual neuronal activity) instead of discarding some of the correlated features that were also related to behaviorally-relevant information. The strength of the regularization for each model was hyperparameter-tuned and the reported results were cross-validated. Specifically, neuronal data in each session was split into five stratified folds, and each fold preserved the percentage of hit and miss trials in a given session. Four folds were used for cross-validated hyperparameter search (randomized search drawn from the log-uniform distribution between 1 × 10<sup>-4</sup> and 1 × 10<sup>2</sup>), and the remaining 1 fold was used for evaluating the model after the best hyperparameters were refitted on the four folds of data. To more reliably estimate the model results, the evaluation was done for each of the five folds for each session and the average of these 5 results was taken as each session’s model performance at each timepoint.</p><p>The percentage of hit and miss trials was different in each session, and the number of hit trials often exceeded the number of miss trials. To include as many trials as possible while preventing the models from taking advantage of class imbalances, balancing procedures were performed at both the model-level and the metrics-level. First, logistic regression was trained with the class weights adjusted inversely proportional to the frequency of each trial type in the training data, giving higher weights to the minority class and lower weights to the majority class. Given the total number of trials in the training data <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the number of classes <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and the number of trials for a given class <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the weight for a given class <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was defined as follows:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>These weights were then applied to the cost function during the training process to increase the penalty for minority class misclassifications and reduce the penalty for majority class misclassifications. Second, to avoid the estimated model performance being inflated due to class imbalance, balanced accuracy (<xref ref-type="bibr" rid="bib6">Brodersen et al., 2010</xref>) was used to report the model performance. Balanced accuracy was defined as the arithmetic mean of the true positive rate and the true negative rate. For a model performing equally well on either class, the balanced accuracy is the same as the conventional accuracy (i.e. the number of correct predictions divided by the total number of predictions). However, for a model scoring above chance only because the model takes advantage of the class imbalance (i.e. consistently predicts the majority class), the balanced accuracy is at the chance level.<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>B</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Additionally, dummy models were used as baseline models to compare against the performance of the logistic regression models. Dummy models predicted the class labels (i.e. hit or miss trials) randomly while taking into account the probability of each class.</p><p>To assess whether the model performance was correlated with the number of ROIs recorded in a session, Spearman’s correlation coefficient was computed between the number of ROIs in a session and the mean model performance over different 1-s time periods relative to stimulus onset (from 2 s before to 5 s after stimulus onset).</p><p>Statistical tests were conducted to compare the model performance between lesioned and non-lesioned mice, as well as between the trained models and dummy models. Since the frame rate varied slightly with the size of the field of view, the numbers of frames (193–197 frames) per 7-s trial could be different across sessions. Thus, model performance was linearly interpolated to make all sessions contain the same number of frames before statistical tests were performed at each timepoint. The model performance of each session was cross-validated and averaged across folds, and the statistical tests were performed on the distributions of the sessions’ model performance. The Shapiro–Wilk test was used to determine whether a parametric or nonparametric test should be used, using p&lt;0.05 as a criterion. A one-sided Wilcoxon signed-rank test or paired t-test was performed for comparing trained vs dummy models, while a one-sided Mann-Whitney U test or t-test was performed for comparing trained models for different groups of mice. Because of the smaller sample sizes, the statistical tests in <xref ref-type="fig" rid="fig6">Figure 6B</xref> were carried out after binning the scores for every two timepoints. Statistical significance was defined as p&lt;0.05 after Bonferroni correction.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Senior editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Investigation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Resources, Supervision, Funding acquisition, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experiments were approved by the Committee on Animal Care and Ethical Review at the University of Oxford and were licensed by the UK Home Office (Animal Scientific Procedures Act, 1986, amended in 2012).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-89950-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data and code associated with this study are available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.b2rbnzspz">https://doi.org/10.5061/dryad.b2rbnzspz</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/leetaiying/lee-et-al-2024">https://github.com/leetaiying/lee-et-al-2024</ext-link> (copy archived at <xref ref-type="bibr" rid="bib29">Lee, 2024</xref>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>T-Y</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Data from: Midbrain encodes sound detection behavior without auditory cortex</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.b2rbnzspz</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We are grateful to Christopher Breen and Robert Campbell for helping with the histology, to Ben Willmore for discussing the decoding analysis and for the financial assistance provided by an Oxford-Taiwan Graduate Scholarship from the University of Oxford and the Taiwan Ministry of Education to TYL, a Wellcome 4 year PhD Studentship to YW (102372/Z/13/Z), and by a Wellcome Principal Research Fellowship to AJK (WT108369/Z/2015/Z). For the purpose of Open Access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antunes</surname><given-names>FM</given-names></name><name><surname>Malmierca</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Corticothalamic pathways in auditory processing: Recent advances and insights from other sensory systems</article-title><source>Frontiers in Neural Circuits</source><volume>15</volume><elocation-id>721186</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2021.721186</pub-id><pub-id pub-id-type="pmid">34489648</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bajo</surname><given-names>VM</given-names></name><name><surname>Nodal</surname><given-names>FR</given-names></name><name><surname>Moore</surname><given-names>DR</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The descending corticocollicular pathway mediates learning-induced auditory plasticity</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>253</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1038/nn.2466</pub-id><pub-id pub-id-type="pmid">20037578</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bajo</surname><given-names>VM</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical modulation of auditory processing in the midbrain</article-title><source>Frontiers in Neural Circuits</source><volume>6</volume><elocation-id>114</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2012.00114</pub-id><pub-id pub-id-type="pmid">23316140</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnstedt</surname><given-names>O</given-names></name><name><surname>Keating</surname><given-names>P</given-names></name><name><surname>Weissenberger</surname><given-names>Y</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Dahmen</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional microarchitecture of the mouse dorsal inferior colliculus revealed through in vivo two-photon calcium imaging</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>10927</fpage><lpage>10939</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0103-15.2015</pub-id><pub-id pub-id-type="pmid">26245957</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackwell</surname><given-names>JM</given-names></name><name><surname>Lesicko</surname><given-names>AM</given-names></name><name><surname>Rao</surname><given-names>W</given-names></name><name><surname>De Biasi</surname><given-names>M</given-names></name><name><surname>Geffen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Auditory cortex shapes sound responses in the inferior colliculus</article-title><source>eLife</source><volume>9</volume><elocation-id>e51890</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51890</pub-id><pub-id pub-id-type="pmid">32003747</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Brodersen</surname><given-names>KH</given-names></name><name><surname>Ong</surname><given-names>CS</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Buhmann</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The balanced accuracy and its posterior distribution</article-title><conf-name>ICPR ’10: Proceedings of the 2010 20th International Conference on Pattern Recognition</conf-name><pub-id pub-id-type="doi">10.1109/icpr.2010.764</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buser</surname><given-names>PA</given-names></name><name><surname>Imbert</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1992">1992</year><source>Audition</source><publisher-loc>Cambridge, Mass</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casseday</surname><given-names>JH</given-names></name><name><surname>Covey</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A neuroethological theory of the operation of the inferior colliculus</article-title><source>Brain, Behavior and Evolution</source><volume>47</volume><fpage>311</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1159/000113249</pub-id><pub-id pub-id-type="pmid">8796964</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ceballo</surname><given-names>S</given-names></name><name><surname>Piwkowska</surname><given-names>Z</given-names></name><name><surname>Bourg</surname><given-names>J</given-names></name><name><surname>Daret</surname><given-names>A</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Targeted cortical manipulation of auditory perception</article-title><source>Neuron</source><volume>104</volume><fpage>1168</fpage><lpage>1179</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.043</pub-id><pub-id pub-id-type="pmid">31727548</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Cheng</surname><given-names>M</given-names></name><name><surname>Ito</surname><given-names>T</given-names></name><name><surname>Song</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuronal organization in the inferior colliculus revisited with cell-type-dependent monosynaptic tracing</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>3318</fpage><lpage>3332</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2173-17.2018</pub-id><pub-id pub-id-type="pmid">29483283</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Song</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Differential cell-type dependent brain state modulations of sensory representations in the non-lemniscal mouse inferior colliculus</article-title><source>Communications Biology</source><volume>2</volume><elocation-id>356</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-019-0602-4</pub-id><pub-id pub-id-type="pmid">31583287</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coleman</surname><given-names>JR</given-names></name><name><surname>Clerici</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Sources of projections to subdivisions of the inferior colliculus in the rat</article-title><source>The Journal of Comparative Neurology</source><volume>262</volume><fpage>215</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1002/cne.902620204</pub-id><pub-id pub-id-type="pmid">3624552</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cruces-Solís</surname><given-names>H</given-names></name><name><surname>Jing</surname><given-names>Z</given-names></name><name><surname>Babaev</surname><given-names>O</given-names></name><name><surname>Rubin</surname><given-names>J</given-names></name><name><surname>Gür</surname><given-names>B</given-names></name><name><surname>Krueger-Burg</surname><given-names>D</given-names></name><name><surname>Strenzke</surname><given-names>N</given-names></name><name><surname>de Hoz</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Auditory midbrain coding of statistical learning that results from discontinuous sensory stimulation</article-title><source>PLOS Biology</source><volume>16</volume><elocation-id>e2005114</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2005114</pub-id><pub-id pub-id-type="pmid">30048446</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Franceschi</surname><given-names>G</given-names></name><name><surname>Barkat</surname><given-names>TR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Task-induced modulations of neuronal activity along the auditory pathway</article-title><source>Cell Reports</source><volume>37</volume><elocation-id>110115</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.110115</pub-id><pub-id pub-id-type="pmid">34910908</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>AK</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamic predictions: oscillations and synchrony in top-down processing</article-title><source>Nature Reviews Neuroscience</source><volume>2</volume><fpage>704</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1038/35094565</pub-id><pub-id pub-id-type="pmid">11584308</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ford</surname><given-names>AN</given-names></name><name><surname>Czarny</surname><given-names>JE</given-names></name><name><surname>Rogalla</surname><given-names>MM</given-names></name><name><surname>Quass</surname><given-names>GL</given-names></name><name><surname>Apostolides</surname><given-names>PF</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Auditory corticofugal neurons transmit auditory and non-auditory information during behavior</article-title><source>The Journal of Neuroscience</source><volume>44</volume><elocation-id>e1190232023</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1190-23.2023</pub-id><pub-id pub-id-type="pmid">38123993</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francis</surname><given-names>NA</given-names></name><name><surname>Winkowski</surname><given-names>DE</given-names></name><name><surname>Sheikhattar</surname><given-names>A</given-names></name><name><surname>Armengol</surname><given-names>K</given-names></name><name><surname>Babadi</surname><given-names>B</given-names></name><name><surname>Kanold</surname><given-names>PO</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Small networks encode decision-making in primary auditory cortex</article-title><source>Neuron</source><volume>97</volume><fpage>885</fpage><lpage>897</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.019</pub-id><pub-id pub-id-type="pmid">29398362</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gimenez</surname><given-names>TL</given-names></name><name><surname>Lorenc</surname><given-names>M</given-names></name><name><surname>Jaramillo</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Adaptive categorization of sound frequency does not require the auditory cortex in rats</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>1137</fpage><lpage>1145</lpage><pub-id pub-id-type="doi">10.1152/jn.00124.2015</pub-id><pub-id pub-id-type="pmid">26156379</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruters</surname><given-names>KG</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sounds and beyond: multisensory and other non-auditory signals in the inferior colliculus</article-title><source>Frontiers in Neural Circuits</source><volume>6</volume><elocation-id>96</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2012.00096</pub-id><pub-id pub-id-type="pmid">23248584</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirokawa</surname><given-names>J</given-names></name><name><surname>Vaughan</surname><given-names>A</given-names></name><name><surname>Masset</surname><given-names>P</given-names></name><name><surname>Ott</surname><given-names>T</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Frontal cortex neuron types categorically encode single decision variables</article-title><source>Nature</source><volume>576</volume><fpage>446</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1816-9</pub-id><pub-id pub-id-type="pmid">31801999</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>YK</given-names></name><name><surname>Lacefield</surname><given-names>CO</given-names></name><name><surname>Rodgers</surname><given-names>CC</given-names></name><name><surname>Bruno</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Sensation, movement and learning in the absence of barrel cortex</article-title><source>Nature</source><volume>561</volume><fpage>542</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0527-y</pub-id><pub-id pub-id-type="pmid">30224746</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huffman</surname><given-names>RF</given-names></name><name><surname>Henson</surname><given-names>OW</given-names><suffix>Jr</suffix></name></person-group><year iso-8601-date="1990">1990</year><article-title>The descending auditory pathway and acousticomotor systems: connections with the inferior colliculus</article-title><source>Brain Research. Brain Research Reviews</source><volume>15</volume><fpage>295</fpage><lpage>323</lpage><pub-id pub-id-type="doi">10.1016/0165-0173(90)90005-9</pub-id><pub-id pub-id-type="pmid">2289088</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inagaki</surname><given-names>HK</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Ridder</surname><given-names>MC</given-names></name><name><surname>Sah</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Hasanbegovic</surname><given-names>H</given-names></name><name><surname>Gao</surname><given-names>Z</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A midbrain-thalamus-cortex circuit reorganizes cortical dynamics to initiate movement</article-title><source>Cell</source><volume>185</volume><fpage>1065</fpage><lpage>1081</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2022.02.006</pub-id><pub-id pub-id-type="pmid">35245431</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname><given-names>HK</given-names></name><name><surname>Gillet</surname><given-names>SN</given-names></name><name><surname>Isaacson</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Flexible sensory representations in auditory cortex driven by behavioral relevance</article-title><source>Neuron</source><volume>88</volume><fpage>1027</fpage><lpage>1039</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.10.024</pub-id><pub-id pub-id-type="pmid">26586181</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keck</surname><given-names>T</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Jacobsen</surname><given-names>RI</given-names></name><name><surname>Eysel</surname><given-names>UT</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Synaptic scaling and homeostatic plasticity in the mouse visual cortex in vivo</article-title><source>Neuron</source><volume>80</volume><fpage>327</fpage><lpage>334</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.018</pub-id><pub-id pub-id-type="pmid">24139037</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>The effects of lateral lemniscal and neocortical lesions on auditory absolute thresholds and frequency difference thresholds of the rat</article-title><source>Dissertation Abstracts International</source><volume>31</volume><fpage>1566</fpage><lpage>1567</lpage></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraus</surname><given-names>N</given-names></name><name><surname>White-Schwoch</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Unraveling the biology of auditory learning: A cognitive-sensorimotor-reward framework</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>642</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.08.017</pub-id><pub-id pub-id-type="pmid">26454481</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuromodulation of brain states</article-title><source>Neuron</source><volume>76</volume><fpage>209</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.012</pub-id><pub-id pub-id-type="pmid">23040816</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>TY</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Lee-et-al-2024</data-title><version designator="swh:1:rev:0796f8e7e13ff1e9d579dcc452e968680076377c">swh:1:rev:0796f8e7e13ff1e9d579dcc452e968680076377c</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:35522dcd9a68e0bc3472b3bb6713114a2f7d62c8;origin=https://github.com/leetaiying/lee-et-al-2024;visit=swh:1:snp:3bf95211051936b3ccc6354601b1a29186341963;anchor=swh:1:rev:0796f8e7e13ff1e9d579dcc452e968680076377c">https://archive.softwareheritage.org/swh:1:dir:35522dcd9a68e0bc3472b3bb6713114a2f7d62c8;origin=https://github.com/leetaiying/lee-et-al-2024;visit=swh:1:snp:3bf95211051936b3ccc6354601b1a29186341963;anchor=swh:1:rev:0796f8e7e13ff1e9d579dcc452e968680076377c</ext-link></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lesicko</surname><given-names>AMH</given-names></name><name><surname>Hristova</surname><given-names>TS</given-names></name><name><surname>Maigler</surname><given-names>KC</given-names></name><name><surname>Llano</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Connectional modularity of top-down and bottom-up multimodal inputs to the lateral cortex of the mouse inferior colliculus</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>11037</fpage><lpage>11050</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4134-15.2016</pub-id><pub-id pub-id-type="pmid">27798184</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Liao</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>N</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Lv</surname><given-names>G</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Lu</surname><given-names>J</given-names></name><name><surname>Ding</surname><given-names>R</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Guang</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Qin</surname><given-names>H</given-names></name><name><surname>Jin</surname><given-names>W</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>He</surname><given-names>C</given-names></name><name><surname>Jia</surname><given-names>H</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name><name><surname>Hu</surname><given-names>Z</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Primary auditory cortex is required for anticipatory motor response</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>3254</fpage><lpage>3271</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx079</pub-id><pub-id pub-id-type="pmid">28379350</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Xie</surname><given-names>F</given-names></name><name><surname>Dai</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Yuan</surname><given-names>K</given-names></name><name><surname>Wang</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Brain-wide inputs to the non-lemniscal inferior colliculus in mice</article-title><source>Neuroscience Letters</source><volume>793</volume><elocation-id>136976</elocation-id><pub-id pub-id-type="doi">10.1016/j.neulet.2022.136976</pub-id><pub-id pub-id-type="pmid">36427816</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohse</surname><given-names>M</given-names></name><name><surname>Bajo</surname><given-names>VM</given-names></name><name><surname>King</surname><given-names>AJ</given-names></name><name><surname>Willmore</surname><given-names>BDB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural circuits underlying auditory contrast gain control and their perceptual implications</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>324</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-14163-5</pub-id><pub-id pub-id-type="pmid">31949136</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malmierca</surname><given-names>MS</given-names></name><name><surname>Anderson</surname><given-names>LA</given-names></name><name><surname>Antunes</surname><given-names>FM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cortical modulation of stimulus-specific adaptation in the auditory midbrain and thalamus: a potential neuronal correlate for predictive coding</article-title><source>Frontiers in Systems Neuroscience</source><volume>9</volume><elocation-id>19</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2015.00019</pub-id><pub-id pub-id-type="pmid">25805974</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Nestvogel</surname><given-names>DB</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neuromodulation of brain state and behavior</article-title><source>Annual Review of Neuroscience</source><volume>43</volume><fpage>391</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-100219-105424</pub-id><pub-id pub-id-type="pmid">32250724</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Zagha</surname><given-names>E</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Waking state: Rapid variations modulate neural and behavioral responses</article-title><source>Neuron</source><volume>87</volume><fpage>1143</fpage><lpage>1161</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.012</pub-id><pub-id pub-id-type="pmid">26402600</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mettler</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="1935">1935</year><article-title>Corticifugal fiber connections of the cortex of <italic>Macaca mulatta</italic>. The temporal region</article-title><source>Journal of Comparative Neurology</source><volume>63</volume><fpage>25</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1002/cne.900630104</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Metzger</surname><given-names>RR</given-names></name><name><surname>Greene</surname><given-names>NT</given-names></name><name><surname>Porter</surname><given-names>KK</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Effects of reward and behavioral context on neural activity in the primate inferior colliculus</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>7468</fpage><lpage>7476</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5401-05.2006</pub-id><pub-id pub-id-type="pmid">16837595</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moriizumi</surname><given-names>T</given-names></name><name><surname>Hattori</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Pallidotectal projection to the inferior colliculus of the rat</article-title><source>Experimental Brain Research</source><volume>87</volume><fpage>223</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1007/BF00228524</pub-id><pub-id pub-id-type="pmid">1721879</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakamoto</surname><given-names>KT</given-names></name><name><surname>Jones</surname><given-names>SJ</given-names></name><name><surname>Palmer</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Descending projections from auditory cortex modulate sensitivity in the midbrain to cues for spatial position</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>2347</fpage><lpage>2356</lpage><pub-id pub-id-type="doi">10.1152/jn.01326.2007</pub-id><pub-id pub-id-type="pmid">18385487</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Namboodiri</surname><given-names>VMK</given-names></name><name><surname>Otis</surname><given-names>JM</given-names></name><name><surname>van Heeswijk</surname><given-names>K</given-names></name><name><surname>Voets</surname><given-names>ES</given-names></name><name><surname>Alghorazi</surname><given-names>RA</given-names></name><name><surname>Rodriguez-Romaguera</surname><given-names>J</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Stuber</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-cell activity tracking reveals that orbitofrontal neurons acquire and maintain a long-term memory to guide behavioral adaptation</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1110</fpage><lpage>1121</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0408-1</pub-id><pub-id pub-id-type="pmid">31160741</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienhuis</surname><given-names>R</given-names></name><name><surname>Olds</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Changes in unit responses to tones after food reinforcement in the auditory pathway of the rat: intertrial arousal</article-title><source>Experimental Neurology</source><volume>59</volume><fpage>229</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1016/0014-4886(78)90152-8</pub-id><pub-id pub-id-type="pmid">639917</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noudoost</surname><given-names>B</given-names></name><name><surname>Chang</surname><given-names>MH</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Top-down control of visual attention</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>183</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.02.003</pub-id><pub-id pub-id-type="pmid">20303256</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberle</surname><given-names>HM</given-names></name><name><surname>Ford</surname><given-names>AN</given-names></name><name><surname>Dileepkumar</surname><given-names>D</given-names></name><name><surname>Czarny</surname><given-names>J</given-names></name><name><surname>Apostolides</surname><given-names>PF</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Synaptic mechanisms of top-down control in the non-lemniscal inferior colliculus</article-title><source>eLife</source><volume>10</volume><elocation-id>e72730</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.72730</pub-id><pub-id pub-id-type="pmid">34989674</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olaźabal</surname><given-names>UE</given-names></name><name><surname>Moore</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Nigrotectal projection to the inferior colliculus: Horseradish peroxidase transport and tyrosine hydroxylase immunohistochemical studies in rats, cats, and bats</article-title><source>Journal of Comparative Neurology</source><volume>282</volume><fpage>98</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1002/cne.902820108</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Sullivan</surname><given-names>C</given-names></name><name><surname>Weible</surname><given-names>AP</given-names></name><name><surname>Wehr</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Auditory cortex contributes to discrimination of pure tones</article-title><source>eNeuro</source><volume>6</volume><elocation-id>ENEURO.0340-19.2019</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0340-19.2019</pub-id><pub-id pub-id-type="pmid">31591138</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otchy</surname><given-names>TM</given-names></name><name><surname>Wolff</surname><given-names>SBE</given-names></name><name><surname>Rhee</surname><given-names>JY</given-names></name><name><surname>Pehlevan</surname><given-names>C</given-names></name><name><surname>Kawai</surname><given-names>R</given-names></name><name><surname>Kempf</surname><given-names>A</given-names></name><name><surname>Gobes</surname><given-names>SMH</given-names></name><name><surname>Ölveczky</surname><given-names>BP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Acute off-target effects of neural circuit manipulations</article-title><source>Nature</source><volume>528</volume><fpage>358</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/nature16442</pub-id><pub-id pub-id-type="pmid">26649821</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Dipoppa</surname><given-names>M</given-names></name><name><surname>Schröder</surname><given-names>S</given-names></name><name><surname>Rossi</surname><given-names>LF</given-names></name><name><surname>Dalgleish</surname><given-names>H</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Suite2p: Beyond 10,000 neurons with standard two-photon microscopy</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/061507</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>PRL</given-names></name><name><surname>Brown</surname><given-names>MA</given-names></name><name><surname>Smear</surname><given-names>MC</given-names></name><name><surname>Niell</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Movement-related signals in sensory areas: roles in natural behavior</article-title><source>Trends in Neurosciences</source><volume>43</volume><fpage>581</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2020.05.005</pub-id><pub-id pub-id-type="pmid">32580899</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parras</surname><given-names>GG</given-names></name><name><surname>Nieto-Diego</surname><given-names>J</given-names></name><name><surname>Carbajal</surname><given-names>GV</given-names></name><name><surname>Valdés-Baizabal</surname><given-names>C</given-names></name><name><surname>Escera</surname><given-names>C</given-names></name><name><surname>Malmierca</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neurons along the auditory pathway exhibit a hierarchical organization of prediction error</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>2148</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-02038-6</pub-id><pub-id pub-id-type="pmid">29247159</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paxinos</surname><given-names>G</given-names></name><name><surname>Franklin</surname><given-names>KBJ</given-names></name><name><surname>Franklin</surname><given-names>KBJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>The Mouse Brain in Stereotaxic Coordinates</source><publisher-loc>San Diego</publisher-loc><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib53"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pickles</surname><given-names>JO</given-names></name></person-group><year iso-8601-date="1988">1988</year><source>An Introduction to the Physiology of Hearing</source><publisher-loc>London ; San Diego</publisher-loc><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quass</surname><given-names>GL</given-names></name><name><surname>Rogalla</surname><given-names>MM</given-names></name><name><surname>Ford</surname><given-names>AN</given-names></name><name><surname>Apostolides</surname><given-names>PF</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Mixed representations of sound and action in the auditory midbrain</article-title><source>The Journal of Neuroscience</source><volume>44</volume><elocation-id>e1831232024</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1831-23.2024</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruth</surname><given-names>RE</given-names></name><name><surname>Rosenfeld</surname><given-names>JP</given-names></name><name><surname>Harris</surname><given-names>DM</given-names></name><name><surname>Birkel</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Effects of aversive and rewarding electrical brain stimulation on auditory evoked responses in albino rat tectum</article-title><source>Physiology &amp; Behavior</source><volume>13</volume><fpage>729</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1016/0031-9384(74)90254-6</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saderi</surname><given-names>D</given-names></name><name><surname>Schwartz</surname><given-names>ZP</given-names></name><name><surname>Heller</surname><given-names>CR</given-names></name><name><surname>Pennington</surname><given-names>JR</given-names></name><name><surname>David</surname><given-names>SV</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dissociation of task engagement and arousal effects in auditory cortex and midbrain</article-title><source>eLife</source><volume>10</volume><elocation-id>e60153</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.60153</pub-id><pub-id pub-id-type="pmid">33570493</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>DM</given-names></name><name><surname>Nelson</surname><given-names>A</given-names></name><name><surname>Mooney</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A synaptic and circuit basis for corollary discharge in the auditory cortex</article-title><source>Nature</source><volume>513</volume><fpage>189</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature13724</pub-id><pub-id pub-id-type="pmid">25162524</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>DM</given-names></name><name><surname>Mooney</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How movement modulates hearing</article-title><source>Annual Review of Neuroscience</source><volume>41</volume><fpage>553</fpage><lpage>572</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031215</pub-id><pub-id pub-id-type="pmid">29986164</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaheen</surname><given-names>LA</given-names></name><name><surname>Slee</surname><given-names>SJ</given-names></name><name><surname>David</surname><given-names>SV</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Task engagement improves neural discriminability in the auditory midbrain of the marmoset monkey</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>284</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1112-20.2020</pub-id><pub-id pub-id-type="pmid">33208469</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The thalamus is more than just a relay</article-title><source>Current Opinion in Neurobiology</source><volume>17</volume><fpage>417</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2007.07.003</pub-id><pub-id pub-id-type="pmid">17707635</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shore</surname><given-names>SE</given-names></name><name><surname>Zhou</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Somatosensory influence on the cochlear nucleus and beyond</article-title><source>Hearing Research</source><volume>216–217</volume><fpage>90</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2006.01.006</pub-id><pub-id pub-id-type="pmid">16513306</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singla</surname><given-names>S</given-names></name><name><surname>Dempsey</surname><given-names>C</given-names></name><name><surname>Warren</surname><given-names>R</given-names></name><name><surname>Enikolopov</surname><given-names>AG</given-names></name><name><surname>Sawtell</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A cerebellum-like circuit in the auditory system cancels responses to self-generated sounds</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>943</fpage><lpage>950</lpage><pub-id pub-id-type="doi">10.1038/nn.4567</pub-id><pub-id pub-id-type="pmid">28530663</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>YH</given-names></name><name><surname>Kim</surname><given-names>JH</given-names></name><name><surname>Jeong</surname><given-names>HW</given-names></name><name><surname>Choi</surname><given-names>I</given-names></name><name><surname>Jeong</surname><given-names>D</given-names></name><name><surname>Kim</surname><given-names>K</given-names></name><name><surname>Lee</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A neural circuit for auditory dominance over visual perception</article-title><source>Neuron</source><volume>93</volume><fpage>940</fpage><lpage>954</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.01.006</pub-id><pub-id pub-id-type="pmid">28162806</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stebbings</surname><given-names>KA</given-names></name><name><surname>Lesicko</surname><given-names>AMH</given-names></name><name><surname>Llano</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The auditory corticocollicular system: molecular and circuit-level considerations</article-title><source>Hearing Research</source><volume>314</volume><fpage>51</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2014.05.004</pub-id><pub-id pub-id-type="pmid">24911237</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>eaav7893</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suga</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Role of corticofugal feedback in hearing</article-title><source>Journal of Comparative Physiology A</source><volume>194</volume><fpage>169</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1007/s00359-007-0274-2</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talwar</surname><given-names>SK</given-names></name><name><surname>Musial</surname><given-names>PG</given-names></name><name><surname>Gerstein</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Role of mammalian auditory cortex in the perception of elementary sound properties</article-title><source>Journal of Neurophysiology</source><volume>85</volume><fpage>2350</fpage><lpage>2358</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.85.6.2350</pub-id><pub-id pub-id-type="pmid">11387381</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Maaten</surname><given-names>L</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Visualizing data using t-SNE</article-title><source>Journal of Machine Learning Research</source><volume>9</volume><fpage>2579</fpage><lpage>2605</lpage></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vila</surname><given-names>CH</given-names></name><name><surname>Williamson</surname><given-names>RS</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optimizing optogenetic stimulation protocols in auditory corticofugal neurons based on closed-loop spike feedback</article-title><source>Journal of Neural Engineering</source><volume>16</volume><elocation-id>066023</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/ab39cf</pub-id><pub-id pub-id-type="pmid">31394519</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wenstrup</surname><given-names>JJ</given-names></name><name><surname>Larue</surname><given-names>DT</given-names></name><name><surname>Winer</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Projections of physiologically defined subdivisions of the inferior colliculus in the mustached bat: targets in the medial geniculate body and extrathalamic nuclei</article-title><source>The Journal of Comparative Neurology</source><volume>346</volume><fpage>207</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1002/cne.903460204</pub-id><pub-id pub-id-type="pmid">7962717</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiegert</surname><given-names>JS</given-names></name><name><surname>Mahn</surname><given-names>M</given-names></name><name><surname>Prigge</surname><given-names>M</given-names></name><name><surname>Printz</surname><given-names>Y</given-names></name><name><surname>Yizhar</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Silencing neurons: Tools applications, and experimental constraints</article-title><source>Neuron</source><volume>95</volume><fpage>504</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.050</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winer</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Decoding the auditory corticofugal systems</article-title><source>Hearing Research</source><volume>207</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2005.06.007</pub-id><pub-id pub-id-type="pmid">16091301</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiong</surname><given-names>XR</given-names></name><name><surname>Liang</surname><given-names>F</given-names></name><name><surname>Zingg</surname><given-names>B</given-names></name><name><surname>Ji</surname><given-names>X</given-names></name><name><surname>Ibrahim</surname><given-names>LA</given-names></name><name><surname>Tao</surname><given-names>HW</given-names></name><name><surname>Zhang</surname><given-names>LI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Auditory cortex controls sound-driven innate defense behaviour through corticofugal projections to inferior colliculus</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>7224</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms8224</pub-id><pub-id pub-id-type="pmid">26068082</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Kim</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Integration of locomotion and auditory signals in the mouse inferior colliculus</article-title><source>eLife</source><volume>9</volume><elocation-id>e52228</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.52228</pub-id><pub-id pub-id-type="pmid">31987070</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zingg</surname><given-names>B</given-names></name><name><surname>Chou</surname><given-names>XL</given-names></name><name><surname>Zhang</surname><given-names>ZG</given-names></name><name><surname>Mesik</surname><given-names>L</given-names></name><name><surname>Liang</surname><given-names>F</given-names></name><name><surname>Tao</surname><given-names>HW</given-names></name><name><surname>Zhang</surname><given-names>LI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>AAV-mediated anterograde transsynaptic tagging: Mapping corticocollicular input-defined neural pathways for defense behaviors</article-title><source>Neuron</source><volume>93</volume><fpage>33</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.045</pub-id><pub-id pub-id-type="pmid">27989459</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89950.4.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>CNRS</institution><country>France</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This study demonstrates that neurons receiving inputs from auditory cortex in the inferior colliculus widely encode the outcome of a sound detection task independent of the presence of auditory cortex. This <bold>valuable</bold> study based on imaging of transsynaptically labelled neurons provides <bold>convincing</bold> evidence that auditory cortex is necessary neither for sound detection, nor to channel information related to behavioral outcome to the subcortical auditory system. This study will be of wide interest for sensory neuroscientists.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89950.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The inferior colliculus (IC) is the central auditory system's major hub. It integrates ascending brainstem signals to provide acoustic information to the auditory thalamus. The superficial layers of the IC (&quot;shell&quot; IC regions as defined in the current manuscript) also receive a massive descending projection from the auditory cortex. This auditory cortico-collicular pathway has long fascinated the hearing field, as it may provide a route to funnel &quot;high-level&quot; cortical signals and impart behavioral salience upon an otherwise behaviorally agnostic midbrain circuit.</p><p>Accordingly, IC neurons can respond differently to the same sound depending on whether animals engage in a behavioral task (Ryan and Miller 1977; Ryan et al., 1984; Slee &amp; David, 2015; Saderi et al., 2021; De Franceschi &amp; Barkat, 2021). Many studies also report a rich variety of non-auditory responses in the IC, far beyond the simple acoustic responses one expects to find in a &quot;low-level&quot; region (Sakurai, 1990; Metzger et al., 2006; Porter et al., 2007). A tacit assumption is that the behaviorally relevant activity of IC neurons is inherited from the auditory cortico-collicular pathway. However, this assumption has never been tested, owing to two main limitations of past studies:</p><p>(1) Prior studies could not confirm if data were obtained from IC neurons that receive monosynaptic input from the auditory cortex.</p><p>(2) Many studies have tested how auditory cortical inactivation impacts IC neuron activity; the consequence of cortical silencing is sometimes quite modest. However, all prior inactivation studies were conducted in anesthetized or passively listening animals. These conditions may not fully engage the auditory cortico-collicular pathway. Moreover, the extent of cortical inactivation in prior studies was sometimes ambiguous, which complicates interpreting modest or negative results.</p><p>Here, the authors' goal is to directly test if the auditory cortex is necessary for behaviorally relevant activity in IC neurons. They conclude that surprisingly, task relevant activity in cortico-recipient IC neuron persists in absence of auditory cortico-collicular transmission. To this end, a major strength of the paper is that the authors combine a sound-detection behavior with clever approaches that unambiguously overcome the limitations of past studies.</p><p>First the authors inject a transsynaptic virus into the auditory cortex, thereby expressing a genetically encoded calcium indicator in the auditory cortex's postsynaptic targets in the IC. This powerful approach enables 2-photon Ca2+ imaging from IC neurons that unambiguously receive monosynaptic input from auditory cortex. Thus, any effect of cortical silencing should be maximally observable in this neuronal population. Second, they abrogate auditory cortico-collicular transmission using lesions of auditory cortex. This &quot;sledgehammer&quot; approach is arguably the most direct test of whether cortico-recipient IC neurons will continue to encode task-relevant information in absence of descending feedback. Indeed, their method circumvents the known limitations of more modern optogenetic or chemogenetic silencing, e.g. variable efficacy.</p><p>The authors have revised their manuscript and adequately addressed the major concerns. Although more in depth analyses of these rich datasets are definitely possible, the current results nevertheless stand on their own. Indeed, the work serves as a beacon to move away from the idea that cortico-collicular projections function primarily to impart behavioral relevance upon auditory midbrain neurons. This knowledge inspires a search for alternative explanations as to the role of auditory cortico-collicular synapses in behavior.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89950.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This study takes a new approach to studying the role of corticofugal projections from auditory cortex to inferior colliculus. The authors performed two-photon imaging of cortico-recipient IC neurons during a click detection task in mice with and without lesions of auditory cortex. In both groups of animals, they observed similar task performance and relatively small differences in the encoding of task-response variables in the IC population. They conclude that non-cortical inputs to the IC can provide substantial task-related modulation, at least when AC is absent.</p><p>Strengths:</p><p>This study provides valuable new insight into big and challenging questions around top-down modulation of activity in the IC. The approach here is novel and appears to have been executed thoughtfully. Thus, it should be of interest to the community.</p><p>Weaknesses:</p><p>Analysis of single unit activity is limited in its scope.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89950.4.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This study aims to demonstrate that cortical feedback is not necessary to signal behavioral outcome to shell neurons of the inferior colliculus during a sound detection task. The demonstration is achieved in a very clear manner by the observation of the activity of cortico-recepient neurons in animals which have received lesions of the auditory cortex. The experiment shows that neither behavior performance nor neuronal responses are significantly impacted by cortical lesions except for the case of partial lesions which seem to have a disruptive effect on behavioral outcome signaling.</p><p>Strengths:</p><p>The demonstration of the main conclusions is based on state-of-the-art, carefully controlled methods and is highly convincing. There is an in depth discussion of the different effects of auditory cortical lesions on sound detection behavior.</p><p>Weaknesses:</p><p>The description of feedback signals could be more detailed although it is difficult to achieve good temporal resolution with the calcium imaging technique necessary for targeting cortico-recipient neurons.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89950.4.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Lee</surname><given-names>Tai-Ying</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Weissenberger</surname><given-names>Yves</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>King</surname><given-names>Andrew J</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Dahmen</surname><given-names>Johannes C</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Weaknesses:</p><p>There are however, substantial concerns about the interpretation of the findings and limitations to the current analysis. In particular, Analysis of single unit activity is absent, making interpretation of population clusters and decoding less interpretable. These concerns should be addressed to make sure that the results can be interpreted clearly in an active field that already contains a number of confusing and possibly contradictory findings.</p></disp-quote><p>We addressed this important point (which was also made by reviewer #1) in our previous revision. Specifically, we included additional analyses that operate at the level of single units rather than the population level, as requested by the reviewer. For example, we assessed, separately for each recorded neuron, whether there was a statistically significant difference in the magnitude of neural activity between hit and miss trials. This approach allowed us to fully balance the numbers of hit and miss trials at each sound level that were entered into the analysis. The results revealed that a large proportion (close to 50%) of units were task modulated, i.e. had significantly different response magnitudes between hit and miss trials, and that this proportion was not significantly different between lesioned and non-lesioned mice. It is therefore no longer correct to say that “analysis of single unit activity is absent”, and we would be grateful if this statement could be changed.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>The authors have done a good job addressing the main concerns from the previous review. There are a few additional points that hopefully do not require substantial additional edits.</p><p>Figure 5/supplements. While the authors provide compelling evidence that clusters and overall activity patterns are similar for lesioned and control animals, there do appear to be some differences. For instance, the hit/miss difference for cluster 3 (the &quot;auditory&quot; cluster) appears to be absent for lesioned mice (Fig 5S3 D). Can the hit-miss difference be quantified?</p></disp-quote><p>We agree that there are some differences between the activity profiles of lesioned and non-lesioned mice: Inspection of panels A and C of Figure 5 – figure supplement 3, for instance, indicates that there is a relatively high proportion of neurons in cluster 3 of the non-lesioned mice that exhibit prolonged elevated activity in hit trials and a relatively lower proportion of those neurons in cluster 3 of lesioned mice. This likely explains the difference in the average response profiles of cluster 3 between the two groups pointed out by the reviewer. Furthermore, there is a slightly larger pre-stimulus dip in hit trial activity for lesioned than non-lesioned mice in cluster 1, a more pronounced short latency peak in hit trial activity for lesioned mice in cluster 2 as well as differences in other clusters. However, these differences are not inconsistent with our interpretation of these data in that we describe the activity profiles as being “similar” and exhibiting a “close correspondence” (rather than as being identical). Having considered this carefully, we do not believe that attempting to quantify these small differences would add much value here or help the reader with the interpretation of these data, especially given that the activity profiles of all neurons that make up each cluster are plotted in panels A and C.</p><disp-quote content-type="editor-comment"><p>Could the mice have been using somatosensory information to perform the task? A wideband click presented from a free-field speaker could have energy in a low frequency range that triggers a whisker response. Given the moderate but not insignificant somatosensory input into the IC shell, this doesn't seem like a trivial concern, and it could substantially impact interpretation of the results. Without wanting to complicate things too much, the authors might consider one or more of these questions: What's the frequency content of the click? Can a deaf mouse perform the task? Can an AC-lesioned mouse learn/perform the task with close-field acoustic stimulation? Or for a highfrequency tone target rather than a click?</p></disp-quote><p>This is an interesting suggestion. We have, in the context of another study, trained mice in our lab to detect somatosensory stimulation (a brush stroke to their whiskers) and consistently found that it takes them much longer (often two weeks or more) to learn to respond to a stimulation of their whiskers than to the presentation of a sound. The brush strokes applied to the whiskers in those experiments were 50-150 ms in duration and were thus orders of magnitude greater in both their duration and amplitude and considerably more salient than any somatosensory stimulus that could potentially arise from the clicks presented here. Therefore, we consider it highly unlikely that mice learned to use somatosensory information potentially picked up by their whiskers to perform the click detection task.</p><disp-quote content-type="editor-comment"><p>L. 63. The authors might want to cite some recent work from the Apostilides lab on the properties of AC-IC projections as well as non-auditory signals in the IC.</p></disp-quote><p>There are two recent papers from the Apostolides lab that are relevant to our study. We already cite Quass et al., 2023. We have now added Ford et al., 2024 as well.</p><p>Changes to manuscript:</p><p>Line 81: “This raises the possibility that these context-dependent effects may be inherited from the auditory cortex (Ford et al., 2024)”.</p><disp-quote content-type="editor-comment"><p>L. 220. &quot;sound-responsive neurons&quot; It is possible to report the representation of sound-responsive neurons in the different clusters? This might help tease apart what processes contribute to their respective activity. Not a big problem if the samples can't be registered easily.</p></disp-quote><p>Sound-driven neurons were identified on the basis of a subset (those trials in which sounds were presented at levels from 53 dB SPL to 65 dB SPL) of the trials used for the clustering analysis so the analyses are not directly comparable.</p><disp-quote content-type="editor-comment"><p>p. 603. &quot;quieter stimuli&quot; What sound level was actually used in the 2p experiments? Was it fixed at a single level per animal?</p></disp-quote><p>Sound level was not fixed at a single level. A total of nine different sound levels were used per mouse. We apologize that this was not made clear previously.</p><p>Changes to manuscript:</p><p>Line 603: “Once the mice had achieved a stable level of performance (typically two days with d’ &gt; 1.5), quieter stimuli (41-71 dB SPL) were introduced. For each mouse a total of 9 different sound levels were used and the range of sound levels was adjusted to each animal’s behavioral performance to avoid floor and ceiling effects and could, therefore, differ from mouse to mouse.”</p><disp-quote content-type="editor-comment"><p>L. 747. Something is not right with this formula. It appears that it will always reduce to a value of 1/2.</p></disp-quote><p>Thanks for spotting this. There are two typos in this formula. This has been fixed and now reads (line 749):<disp-formula id="sa4equ1"><mml:math id="sa4m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>B</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></body></sub-article></article>