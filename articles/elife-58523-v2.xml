<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">58523</article-id><article-id pub-id-type="doi">10.7554/eLife.58523</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Sniff-synchronized, gradient-guided olfactory search by freely moving mice</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-188827"><name><surname>Findley</surname><given-names>Teresa M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2050-4869</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-188841"><name><surname>Wyrick</surname><given-names>David G</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8096-5766</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188830"><name><surname>Cramer</surname><given-names>Jennifer L</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188829"><name><surname>Brown</surname><given-names>Morgan A</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188831"><name><surname>Holcomb</surname><given-names>Blake</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-216815"><name><surname>Attey</surname><given-names>Robin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9652-8103</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188833"><name><surname>Yeh</surname><given-names>Dorian</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188834"><name><surname>Monasevitch</surname><given-names>Eric</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188835"><name><surname>Nouboussi</surname><given-names>Nelly</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188836"><name><surname>Cullen</surname><given-names>Isabelle</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188837"><name><surname>Songco</surname><given-names>Jeremea O</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-188838"><name><surname>King</surname><given-names>Jared F</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-95019"><name><surname>Ahmadian</surname><given-names>Yashar</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5942-0697</contrib-id><email>ya311@cam.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-95017"><name><surname>Smear</surname><given-names>Matthew C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4689-388X</contrib-id><email>smear@uoregon.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Biology and Institute of Neuroscience, University of Oregon</institution><addr-line><named-content content-type="city">Eugene</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Department of Psychology and Institute of Neuroscience, University of Oregon</institution><addr-line><named-content content-type="city">Eugene</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Computational &amp; Biological Learning Lab, University of Cambridge</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Dulac</surname><given-names>Catherine</given-names></name><role>Senior Editor</role><aff><institution>Harvard University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors also contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>04</day><month>05</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e58523</elocation-id><history><date date-type="received" iso-8601-date="2020-05-03"><day>03</day><month>05</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-04-22"><day>22</day><month>04</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Findley et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Findley et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-58523-v2.pdf"/><abstract><p>For many organisms, searching for relevant targets such as food or mates entails active, strategic sampling of the environment. Finding odorous targets may be the most ancient search problem that motile organisms evolved to solve. While chemosensory navigation has been well characterized in microorganisms and invertebrates, spatial olfaction in vertebrates is poorly understood. We have established an olfactory search assay in which freely moving mice navigate noisy concentration gradients of airborne odor. Mice solve this task using concentration gradient cues and do not require stereo olfaction for performance. During task performance, respiration and nose movement are synchronized with tens of milliseconds precision. This synchrony is present during trials and largely absent during inter-trial intervals, suggesting that sniff-synchronized nose movement is a strategic behavioral state rather than simply a constant accompaniment to fast breathing. To reveal the spatiotemporal structure of these active sensing movements, we used machine learning methods to parse motion trajectories into elementary movement motifs. Motifs fall into two clusters, which correspond to investigation and approach states. Investigation motifs lock precisely to sniffing, such that the individual motifs preferentially occur at specific phases of the sniff cycle. The allocentric structure of investigation and approach indicates an advantage to sampling both sides of the sharpest part of the odor gradient, consistent with a serial-sniff strategy for gradient sensing. This work clarifies sensorimotor strategies for mouse olfactory search and guides ongoing work into the underlying neural mechanisms.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>olfaction</kwd><kwd>active sensing</kwd><kwd>sniff</kwd><kwd>neuroethology</kwd><kwd>search</kwd><kwd>navigation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><award-id>2015-12-201</award-id><principal-award-recipient><name><surname>Smear</surname><given-names>Matthew C</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R56DC015584</award-id><principal-award-recipient><name><surname>Smear</surname><given-names>Matthew C</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>R21NS104935</award-id><principal-award-recipient><name><surname>Smear</surname><given-names>Matthew C</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>R34NS116731</award-id><principal-award-recipient><name><surname>Smear</surname><given-names>Matthew C</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000055</institution-id><institution>National Institute on Deafness and Other Communication Disorders</institution></institution-wrap></funding-source><award-id>F31DC016799</award-id><principal-award-recipient><name><surname>Findley</surname><given-names>Teresa M</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>F32MH118724</award-id><principal-award-recipient><name><surname>Brown</surname><given-names>Morgan A</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011348</institution-id><institution>University of Oregon</institution></institution-wrap></funding-source><award-id>Start up funds</award-id><principal-award-recipient><name><surname>Brown</surname><given-names>Morgan A</given-names></name><name><surname>Smear</surname><given-names>Matthew C</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>To track odors borne on turbulent airflow, mice strategically follow their nose, with sampling movements and sensory computations reminiscent of those demonstrated in nematodes and insects.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Sensory observations are often made in concert with movements (<xref ref-type="bibr" rid="bib1">Ahissar and Assa, 2016</xref>; <xref ref-type="bibr" rid="bib28">Gibson, 1966</xref>). During active search behavior, animals make sampling movements in order to extract relevant sensory information from the environment (<xref ref-type="bibr" rid="bib27">Gibson, 1962</xref>; <xref ref-type="bibr" rid="bib78">Schroeder et al., 2010</xref>). Sampling behavior is flexible and can be customized for the problem the animal is trying to solve (<xref ref-type="bibr" rid="bib46">Kleinfeld et al., 2006</xref>; <xref ref-type="bibr" rid="bib97">Yarbus, 1967</xref>). In the brain, sensory and motor systems interact extensively (<xref ref-type="bibr" rid="bib4">Andersen and Mountcastle, 1983</xref>; <xref ref-type="bibr" rid="bib20">Duhamel et al., 1992</xref>; <xref ref-type="bibr" rid="bib59">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib66">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib73">Poulet and Hedwig, 2006</xref>; <xref ref-type="bibr" rid="bib80">Sommer and Wurtz, 2002</xref>; <xref ref-type="bibr" rid="bib83">Stringer et al., 2019</xref>), which reflects the importance of interpreting self-induced stimulus dynamics (<xref ref-type="bibr" rid="bib81">Sommer and Wurtz, 2008</xref>; <xref ref-type="bibr" rid="bib82">Sperry, 1950</xref>; <xref ref-type="bibr" rid="bib89">von Holst and Mittelstaedt, 1950</xref>; <xref ref-type="bibr" rid="bib91">Webb, 2004</xref>). Here, we show how mice sample the environment while navigating a noisy odor gradient.</p><p>Navigating by chemical cues may be one of the most ancient problems motile organisms evolved to solve, and it remains crucial in the lives of almost all modern species. Unicellular organisms and some invertebrates navigate chemical gradients by chemotaxis (<xref ref-type="bibr" rid="bib6">Bargmann, 2006</xref>; <xref ref-type="bibr" rid="bib7">Berg, 2000</xref>; <xref ref-type="bibr" rid="bib51">Lockery, 2011</xref>). In essence, their movement programs can be described as having two states: they move straight when the concentration is increasing and reorient their movements when the concentration is decreasing. Whereas chemical gradients are stable and informative at the spatial scale of these organisms, for many larger or flying organisms, odor gradient cues do not provide useful positional information (<xref ref-type="bibr" rid="bib16">Crimaldi et al., 2002</xref>; <xref ref-type="bibr" rid="bib62">Murlis et al., 1992</xref>; <xref ref-type="bibr" rid="bib5">Baker et al., 2018</xref>). At this larger spatial scale, turbulent airflow moves odor molecules in dynamic spatiotemporal patterns, disrupting concentration gradients and nullifying classical chemotaxis strategies. Instead, olfactory cues often gate movements that depend on other sensory modalities. Here too, these organisms' behavioral structure can be described as transitions between two states: detection of odor promotes upwind movement while the absence of odor promotes crosswind casting movement (<xref ref-type="bibr" rid="bib43">Kennedy and Marsh, 1974</xref>; <xref ref-type="bibr" rid="bib85">van Breugel and Dickinson, 2014</xref>; <xref ref-type="bibr" rid="bib88">Vickers and Baker, 1994</xref>). In this behavioral program, known as odor-gated anemotaxis, odor cues gate behavioral responses to positional information provided by another modality. In both chemotaxis and odor-gated anemotaxis, search tasks can be described with a two-state search model.</p><p>In comparison to invertebrates, our understanding of olfactory search behavior in vertebrates is more rudimentary, even in commonly studied rodent models. In these animals, access to the olfactory environment is gated by respiration, which is in turn responsive to incoming olfactory stimulation (<xref ref-type="bibr" rid="bib44">Kepecs et al., 2006</xref>; <xref ref-type="bibr" rid="bib90">Wachowiak, 2011</xref>). Novel odors evoke rapid sniffing, during which respiration synchronizes with whisker, nose, and head movements on a cycle-by-cycle basis (<xref ref-type="bibr" rid="bib48">Kurnikova et al., 2017</xref>; <xref ref-type="bibr" rid="bib61">Moore et al., 2013</xref>; <xref ref-type="bibr" rid="bib76">Ranade et al., 2013</xref>). Thus, during active mammalian olfaction, sensory and motor systems interact in a closed loop via the environment, as is true for other sensory modalities such as vision or somatosensation (<xref ref-type="bibr" rid="bib1">Ahissar and Assa, 2016</xref>; <xref ref-type="bibr" rid="bib28">Gibson, 1966</xref>). The cyclical sampling movements coordinated by respiration further synchronize with activity in widespread brain regions (<xref ref-type="bibr" rid="bib41">Karalis and Sirota, 2018</xref>; <xref ref-type="bibr" rid="bib42">Kay, 2005</xref>; <xref ref-type="bibr" rid="bib53">Macrides et al., 1982</xref>; <xref ref-type="bibr" rid="bib86">Vanderwolf, 1992</xref>; <xref ref-type="bibr" rid="bib96">Yanovsky et al., 2014</xref>; <xref ref-type="bibr" rid="bib99">Zelano et al., 2016</xref>) similarly to correlates of locomotor, pupillary, and facial movements observed throughout the brain (<xref ref-type="bibr" rid="bib59">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib66">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib83">Stringer et al., 2019</xref>). Respiratory central pattern generators may coordinate sampling movements to synchronize sensory dynamics across modalities with internal brain rhythms (<xref ref-type="bibr" rid="bib47">Kleinfeld et al., 2014</xref>).</p><p>Previous work has shown that rodents follow odor trails, where the concentration gradient is steep and stable, with rapid sniffing accompanied by side-to-side head movements (<xref ref-type="bibr" rid="bib39">Jones and Urban, 2018</xref>; <xref ref-type="bibr" rid="bib45">Khan et al., 2012</xref>). In these conditions, serial sniffing and stereo olfactory cues guide movements of the nose. Likewise, moles used concentration comparisons across space and time to locate a food source in a sealed experimental chamber in which a lack of airflow allowed for even diffusion of a chemical gradient (<xref ref-type="bibr" rid="bib13">Catania, 2013</xref>). In this study, when input to the nares was reversed, moles navigated towards odor sources at a distance, but demonstrated significant deficits at identifying odor location when near the source. Behavioral modeling in mice further supports that inter-naris concentration comparison plays a more important role in search near the source (<xref ref-type="bibr" rid="bib50">Liu et al., 2020</xref>). Thus, both serial sniffing and stereo cues can guide olfactory search behavior. The sensory computations and movement strategies employed during navigation of an airborne odor plume are less clear. In previous experiments where rodents searched in airborne odor plumes, mice developed a memory-based strategy of serially sampling each possible reward location for the presence of odor, turning search tasks into detection tasks (<xref ref-type="bibr" rid="bib10">Bhattacharyya and Bhalla, 2015</xref>; <xref ref-type="bibr" rid="bib29">Gire et al., 2016</xref>). Thus, it remains unclear whether mammals can follow noisy concentration gradients under turbulent conditions.</p><p>To better understand the sensory computations and sampling strategies for olfactory search, we designed a two-choice behavioral assay where mice use olfactory cues to locate an odor source while we monitor sniffing and movements of the head, nose, and body. We found that mice use a concentration gradient-guided search strategy to navigate olfactory environments that contain turbulent flow. We found that these navigational behaviors are robust to perturbations including introduction of a novel odorant, varying the concentration gradient, and naris occlusion. Given the fundamental importance of sniffing to olfactory function, we hypothesized that mice would selectively sample the environment such that nose movement would be tightly coupled to respiration. Consistent with this hypothesis, we found that mice synchronize rhythmic three-dimensional head movements with the sniff cycle during search. These sniff-synchronized movement rhythms are prominent during trials, and largely absent during the inter-trial interval (ITI), suggesting that sniff synchronous movement is a proactive strategy rather than a reactive reflex. To find structure in this search strategy, we used unsupervised computational methods to parse movement trajectories into discrete motifs. These movement motifs are organized into two distinguishable behavioral states corresponding to investigation and approach, reminiscent of the two-state olfactory search programs described in smaller organisms. Temporally, investigation motifs lock to the sniff cycle with precision at a tens of milliseconds scale. Spatially, patterns of investigation and approach usage indicate a strategic advantage for investigating across the steepest part of the odor gradient. Our findings reveal the microstructure of olfactory search behavior in mice, identifying sensory computations and movement strategies that are shared across a broad range of species.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Olfactory search in noisy gradients of airborne odor</title><p>We developed a two-alternative choice task in which freely moving mice report odor source location for water rewards (Materials and methods and <xref ref-type="fig" rid="fig1">Figure 1A</xref>). To capture the search behavior, we measured respiration using nasal thermistors (<xref ref-type="bibr" rid="bib58">McAfee et al., 2016</xref>) and video-tracked the animal’s body, head, and nose position in real time at 80 frames/s (<xref ref-type="fig" rid="fig1">Figure 1B, E</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). The mouse initiates a trial by inserting its nose in a port (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, ‘initiation’), which activates odor release from two ports at the opposite end of the arena. The mouse reports the location of higher odor concentration by walking toward it (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, ‘search’). In previous studies, rodents performing olfactory search tasks developed memory-guided foraging strategies. In essence, animals run directly to potential odor sources and sample each in turn, thus converting the search tasks to detection tasks (<xref ref-type="bibr" rid="bib10">Bhattacharyya and Bhalla, 2015</xref>; <xref ref-type="bibr" rid="bib29">Gire et al., 2016</xref>). To prevent mice from adopting sample-and-detect strategies, our task forces mice to commit to a decision at a distance from the actual source. Using real-time video-tracking (<xref ref-type="bibr" rid="bib52">Lopes et al., 2015</xref>), we enforced a virtual ‘decision line’, such that the trial outcome is determined by the mouse’s location when it crosses this decision line (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, ‘outcome’). For stimuli, we deliver odor from two separate flow-dilution olfactometers, giving independent control over odor concentration on the two sides. To test olfactory search over a range of difficulties, we presented four odor patterns, defined by the ratio of odor concentration released from the two sides (<xref ref-type="video" rid="video1">Video 1</xref>, 100:0,80:20, 60:40, 0:0).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Behavioral assay for freely moving olfactory search.</title><p>(<bold>A</bold>) Diagram of experimental chamber where mice are tracked by an overhead camera while performing olfactory search. (<bold>B</bold>) Top: nose and head positions are tracked using red paint at the top of the head. Sniffing is monitored via an intranasally implanted thermistor. Bottom: example of sniffing overlaid on a trace of nose position across a single trial. (<bold>C</bold>) Diagram of trial structure. Initiation. Mice initiate a trial via an initiation poke (gray oval). Search. Odor is then released from both odor ports (gray rectangles) at different concentrations. Outcome. Mice that cross the decision line (red) on the side delivering the higher concentration as tracked by the overhead camera receive a reward at the corresponding water port (blue ovals). (<bold>D</bold>) Colormaps of average odor concentration across ~15 two-second trials captured by a 7 × 5 grid of sequential photoionization detector recordings. Rows represent side of stimulus presentation (left or right). Odor concentrations beyond the decision line were not measured. (<bold>E</bold>) Comparison of sniff recordings taken with an intranasally implanted thermistor and intranasally implanted pressure cannula. These are implanted on the same mouse in different nostrils. Top: example trace of simultaneous pressure cannula (blue) and thermistor (red) recordings with inhalation points (as detected in all future analyses) overlaid on the traces in their respective colors. Bottom left: histogram of peak latencies (pressure inhalation onset – thermistor inhalation onset). 14/301 inhalations (4.7%) were excluded as incorrect sniff detections. These were determined as incorrect because they fell more than 2 standard deviations outside the mean in peak latency (mean = 1.61585 ms, SD = ±14.93223 ms). Bottom right: peak latencies, defined as the difference between pressure inhalation onset and thermistor inhalation onset, plotted against instantaneous sniff frequency.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Calibrating alignment of video frames with sniff signal.</title><p>(<bold>A</bold>) Sinusoidal signals (5, 8, 10, and 15 Hz) were simultaneously sent to the analog input channel (used to capture sniffing) and to a phosphor-display oscilloscope (Tektronix). The display of the oscilloscope was reflected by mirrors to allow it to be video-captured inside the behavioral arena. (<bold>B</bold>) The timing relationship is given by the lag between peaks in the analog input channel and the vertical peaks in the position of the oscilloscope trace. Analog input led video frames by 23.5 ± 15.7 ms (mean ± sd; approximately two frames at 80 frames/s).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Characterizing the odor stimulus conditions.</title><p>(<bold>A</bold>) Colormaps of average odor concentration across ~15 two-second trials captured by a 7 × 5 grid of sequential photoionization detector (PID) recordings. -- Each row represents trial type (left correct or right correct). 80:20 odor condition (see Materials and methods: behavioral training: 80:20). (<bold>B</bold>) Same as (<bold>A</bold>), for the 60:40 odor condition (see Materials and methods: interleaved: 60:40). (<bold>C</bold>) Absolute concentration discriminability map based on PID recordings (see Materials and methods). Darker shades indicate regions where absolute concentrations are most discriminable according to ROC analysis (see Methods: Mapping the Olfactory Environment). Essentially, these regions downwind of the odor ports have the largest differences in absolute concentration between left and right trials. (<bold>D</bold>) Concentration gradient discriminability map based on PID recordings. Darker shades indicate regions where odor concentration gradient angles are most discriminable according to ROC analysis. Essentially, this region around the lateral midline of the arena has the largest differences in concentration gradient between left and right trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig1-figsupp2-v2.tif"/></fig></fig-group><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video1.mp4"><label>Video 1.</label><caption><title>Odor gradients are temporally dynamic and noisy.</title><p>Colormaps represent the time course of odor concentration for pseudo-trials assembled from individual trials at each sampling location.</p></caption></media><p>We measured the spatiotemporal distribution of odor using a photoionization detector (PID) in a 5 × 7 grid of sampling locations (<xref ref-type="fig" rid="fig1">Figure 1D</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Pinene was used for the majority of experiments because it is a neutral-valence odorant that is sensitively detected by the PID. As designed, varying the concentration ratios produced across-trial-averaged gradients of different magnitudes. Airflow in the arena is turbulent, imposing temporal fluctuations on the odor gradient (<xref ref-type="video" rid="video2">Video 2</xref>). Thus, our assay tests an animal’s ability to navigate noisy odor gradients.</p><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video2.mp4"><label>Video 2.</label><caption><title>Example trials with sniffing.</title><p>Three dots on the mouse represent the coordinates of front of snout, back of head, and center of mass extracted using Deeplabcut. Sniffing is indicated by color (blue = inhalation, pink = exhalation) and sound (higher tone = inhalation, lower tone = exhalation). Video frame rate is slowed by 4×.</p></caption></media><p>Mice learn the olfactory search task rapidly and robustly. We trained mice in the following sequence (<xref ref-type="fig" rid="fig2">Figure 2A</xref>): first, naïve, water-restricted mice obtained water rewards from all ports in an alternating sequence (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>; 'Water sampling'). In the next phase of training, we added odor stimulation such that odor delivery alternated in the same sequence as reward, so that the mice would learn to associate odor with reward ports (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>; 'Odor association'). Following these initial training steps, mice were introduced to the olfactory search paradigm. Odor was pseudo-randomly released from either the left or right odor source ('100:0'), signaling water availability at the corresponding reward port. Almost all mice performed above chance in the first session (<xref ref-type="fig" rid="fig2">Figure 2B</xref>; binomial test, p&lt;0.05 for 24 out of 25 mice, 75 ± 9.2% correct, mean ± sd). Within four sessions, most animals exceeded 80% performance (19 out of 26). Following 100:0, mice were introduced to the 80:20 condition with mean performance across mice in the first session reaching ~60% (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Most subjects improved to exceed 70% performance over the next seven sessions (17 out of 24). The mice that did not were excluded from subsequent experiments.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Mice use concentration gradient cues in turbulent flow to perform search.</title><p>(<bold>A</bold>) Initial training steps. Water sampling. In this task, mice alternate in sequence between the initiation, left, and right nose pokes to receive water rewards. Odor association. Next, mice run the alternation sequence as above without water rewards released from the initiation poke, making its only utility to initiate a trial. Further, odor is released on the same side of water availability to create an association between odor and reward. Odor search. Here, mice initiate trials by poking the initiation poke. Odor is then randomly released from the left or right odor port. Correct localization (see <xref ref-type="fig" rid="fig1">Figure 1C</xref>, decision line) results in a water reward and incorrect is deterred by an increased inter-trial interval (ITI). (<bold>B</bold>) Performance curve across sessions for the odor search (100:0) training step (<italic>n</italic> = 26). (<bold>C–F</bold>) Session statistics for four different experiments. Each colored line is the average of an individual mouse across all sessions, black points are means across mice, and whiskers are ±1 standard deviation across mice. Top: percent of correct trials. Middle: average trial duration. Bottom: average path tortuosity (total path length of nose trajectory/shortest possible path length). (<bold>C</bold>) Odor omission. The 80:20 concentration ratio (<xref ref-type="fig" rid="fig1">Figure 1</xref>) and odor omission (0:0) conditions randomly interleaved across a session. Data shown includes all sessions for each mouse (<italic>n</italic> = 19). (<bold>D</bold>) Variable <italic>ΔC</italic>, Constant <italic>|C|</italic>. Three concentration ratio conditions (100:0, 80:20, 60:40) randomly interleaved across a session. Data shown includes all sessions for each mouse (<italic>n</italic> = 15). (<bold>E</bold>) Constant <italic>ΔC</italic>, Variable <italic>|C|</italic>. Concentration ratio conditions 90:30 and 30:10 randomly interleaved across a session (<italic>n</italic> = 5). Data shown for first session only. (<bold>F</bold>) Naris occlusion. 80:20 sessions for mice with no naris stitch, a sham stitch that did not occlude the nostril, and a naris stitch that occluded one nostril (<italic>n</italic> = 13). Data shown includes all naris occlusion sessions even if the mouse did not perform under every experimental condition.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Session statistics across trainer sessions.</title><p>Individual mice are depicted by colored lines, average across mice are black points, and whiskers are ±1 standard deviation from the average across mice. Mice 2054–2062 did not have trainer 1 and 2 recorded (this accounts for increasing <italic>n</italic>), and mice were commonly removed from the experiment if they lost sniff signal (this accounts for the reducing <italic>n</italic>). Above: number of trials performed or percent of correct trials. Middle: average trial duration. Below: average trial path tortuosity (total path length/shortest possible path length). (<bold>A</bold>) Session statistics for the first trainer, water sampling (<italic>n</italic> = 19). (<bold>B</bold>) Session statistics for the second trainer, odor association (<italic>n</italic> = 19). (<bold>C</bold>) Session statistics for the third trainer, 100:0 or olfactory search (<italic>n</italic> = 26). Mice perform above 70% in first session. (<bold>D</bold>) Session statistics for final training step, 80:20, that preceded experiments shown in <xref ref-type="fig" rid="fig2">Figure 2</xref> (<italic>n</italic> = 24).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Mice generalize search task to novel odorants and variable <italic>|C|</italic> session.</title><p>(<bold>A</bold>) Performance, trial duration, and trial tortuosity (total path length/shortest possible path length) for the last session of pinene training in 80:20 and the first session of vanillin in 80:20 across mice (<italic>n</italic> = 3). (<bold>B</bold>) Grouped by stimulus condition (90:30, 30:10, 0:0), each line represents the rolling average across mice (window = 10) for the first session (<italic>n</italic> = 5). Shaded regions represent ±1 standard deviation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig2-figsupp2-v2.tif"/></fig></fig-group><p>Next, we tested whether mice trained to search pinene plumes would generalize their search behavior to a novel odorant. We chose vanillin as the novel odorant because, unlike pinene, vanillin does not activate the trigeminal fibers of the nose (<xref ref-type="bibr" rid="bib15">Cometto-Muñiz and Abraham, 2010</xref>; <xref ref-type="bibr" rid="bib19">Doty et al., 1978</xref>; <xref ref-type="bibr" rid="bib36">Hummel et al., 2009</xref>). Thus, we could test whether trigeminal chemosensation is necessary for performance in our task. We found no differences in performance between vanillin and pinene sessions for these mice (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A</xref>; Wilcoxon rank-sum test, p=0.827, <italic>n</italic> = 3). These data suggest that this search behavior generalizes across odors and does not rely on the trigeminal system.</p></sec><sec id="s2-2"><title>Mice can use gradient cues in turbulent flow</title><p>We reasoned that mice would solve this task using odor gradient cues. To vary odor gradients between trials, we trained mice in sessions with interleaved concentration ratios (100:0, 80:20, 60:40) across the trials of a session. In addition to these concentration ratios, odor omission probe trials (0:0) were randomly interleaved into all experimental sessions. During these trials, airflow was identical to 80:20 trials, but air was directed through an empty vial rather than a vial containing odorant solution. These odor omission trials served a twofold purpose: they acted as controls to ensure behavior was indeed odor-guided, and they allowed us to observe how absence of odor impacts search behavior. On these probe trials, mice performed at chance (binomial test, p=0.9989), with longer trial durations (Wilcoxon rank-sum test, p&lt;0.05) and more tortuous trajectories (Wilcoxon rank-sum test, p&lt;0.05) than on non-probe trials (<xref ref-type="fig" rid="fig2">Figure 2C</xref>; <italic>n</italic> = 19, all data from 80:20 condition with probe trials). Performance drops with the concentration ratio (<italic>ΔC</italic>), consistent with our reasoning that mice would use odor gradient cues in this task (<xref ref-type="fig" rid="fig2">Figure 2D</xref>; pairwise Wilcoxon rank-sum tests, p&lt;0.05, <italic>n</italic> = 15). Varying the concentration ratio from 80:20 to 60:40 did not affect trial duration or path tortuosity, defined as actual path length divided by direct path length (<xref ref-type="fig" rid="fig2">Figure 2D</xref>; pairwise Wilcoxon rank-sum tests, p&gt;0.05). However, trial duration and path tortuosity were slightly, but statistically significantly, longer in the 100:0 condition (pairwise Wilcoxon rank-sum tests, p&lt;0.05).</p><p>Given that these results were obtained using a single absolute concentration (<italic>|C|</italic>) across ratios, mice could be solving our task with two distinct categories of sensory computation. One possibility is that information about source location is extracted from the odor gradient. An alternative strategy would be to make an odor intensity judgment that gates a response to positional information from non-olfactory cues, such as wind direction, visual landmarks, or self-motion. This computation would be reminiscent of the odor-gated visual and mechanosensory behaviors observed in insects (<xref ref-type="bibr" rid="bib3">Álvarez-Salvado et al., 2018</xref>; <xref ref-type="bibr" rid="bib43">Kennedy and Marsh, 1974</xref>; <xref ref-type="bibr" rid="bib85">van Breugel and Dickinson, 2014</xref>). To distinguish between these possible strategies, we tested mice in sessions interleaving the air dilution ratios 90:30 and 30:10. 30 is the correct answer in one condition and incorrect in the other, so that mice cannot use an intensity judgment strategy to perform well in both ratio conditions. In both conditions, mice performed equally well in the first session of training (<xref ref-type="fig" rid="fig2">Figure 2E</xref>; Wilcoxon rank-sum test, p=0.465, <italic>n</italic> = 5). This equal performance is true within the first 20 trials of the session (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>; Wilcoxon rank-sum test, p=0.296). These results indicate that odor gradients guide olfactory search under these conditions.</p><p>We next asked how the mice are sensing the concentration gradient. Many mammals can use stereo olfaction: comparing odor concentration samples between the nares (<xref ref-type="bibr" rid="bib13">Catania, 2013</xref>; <xref ref-type="bibr" rid="bib68">Parthasarathy and Bhalla, 2013</xref>; <xref ref-type="bibr" rid="bib72">Porter et al., 2007</xref>; <xref ref-type="bibr" rid="bib74">Rabell et al., 2017</xref>; <xref ref-type="bibr" rid="bib75">Rajan et al., 2006</xref>). To test the role of stereo comparisons in our olfactory search task, we performed naris occlusion experiments. Mice were tested in three conditions on alternating days: naris occlusion, sham occlusion, and no procedure. We found that naris occlusion did not significantly impact performance or path tortuosity (pairwise Wilcoxon rank-sum tests, p&gt;0.05). When compared with the no-stitch condition, the naris stitch condition resulted in a slight, but statistically significant, increase in trial duration (pairwise Wilcoxon rank-sum test, p&lt;0.05).</p><p>This is not true when the stitch condition is compared with the sham condition (pairwise Wilcoxon rank-sum test, p&gt;0.05), indicating this may be a result of undergoing a surgical procedure. These overall results indicate that stereo comparison is not necessary in this task (<xref ref-type="fig" rid="fig2">Figure 2F</xref>; <italic>n</italic> = 13), and that temporal comparisons across sniffs (<xref ref-type="bibr" rid="bib13">Catania, 2013</xref>; <xref ref-type="bibr" rid="bib67">Parabucki et al., 2019</xref>) play a larger role under our task conditions.</p></sec><sec id="s2-3"><title>Sniff rate and occupancy are consistent across trials and gradient conditions</title><p>To investigate active sampling over the time course of trials, we tracked the animals’ sniffing, position, and posture during behavioral sessions. The overall sniff pattern was consistent across trials, with an inhalation just before trial initiation followed by a long exhalation or pause at the beginning of the trial (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Next, the mice performed a rapid burst of sniffs, then sniffed more slowly as they approached the target (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). In this active behavioral state, inhalation and sniff durations were shorter during trials than during ITIs (p<italic>&lt;&lt;</italic>0.01 for all mice; Kolmogorov–Smirnov test; <xref ref-type="fig" rid="fig3">Figure 3B, C</xref>), and strikingly shorter than those observed in head-fixed rodents (<xref ref-type="bibr" rid="bib12">Bolding and Franks, 2017</xref>; <xref ref-type="bibr" rid="bib79">Shusterman et al., 2011</xref>; <xref ref-type="bibr" rid="bib94">Wesson et al., 2009</xref>). After the decision, there is a second rapid burst of sniffing followed by a long exhalation or pause during reward anticipation and retrieval (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The overall sniff pattern was consistent across trials with an inhalation just before trial initiation followed by a long exhalation or pause at the beginning of the trial (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). During this sniffing behavior, the mice moved their nose through tortuous trajectories that were not stereotyped from trial to trial (<xref ref-type="fig" rid="fig3">Figure 3D, E</xref>; <xref ref-type="video" rid="video1">Video 1</xref>). Although individual mice showed position biases (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), these biases were not systematic across mice, so that the across-mouse mean occupancy distribution was evenly distributed across the two sides of the arena (<xref ref-type="fig" rid="fig3">Figure 3F</xref>; <italic>n</italic> = 19). Consistent with this sniffing and movement pattern, the sniff rate was highest near the initiation port and slower on the approach to target (<xref ref-type="fig" rid="fig3">Figure 3G</xref>). These measures of active sampling were not statistically distinguishable across gradient or naris occlusion conditions, but changed significantly on odor omission probe trials, with more fast sniffing and head turns overall.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Distributions of sniffs and nose positions during search task.</title><p>(<bold>A</bold>) Above: sniff raster plot for three sessions. Each black point is an inhalation, each row is a trial aligned to trial initiation (dashed line). Rows are sorted by trial length. Blue region represents trial initiation to trial end. Below: mean instantaneous sniff rate across all trials for all mice aligned to time from trial initiation. Thin lines are individual mice, the thick line is the mean across mice, and shaded region is ±1 standard deviation. (<bold>B</bold>) Histogram of inhalation duration time across all mice (<italic>n</italic> = 11). Thick lines and shaded regions are mean and ±1 standard deviation, thin lines are individual mice. Green: within-trial sniffs; pink: inter-trial interval sniffs. (<bold>C</bold>) Histogram of sniff duration time across all mice (<italic>n</italic> = 11). (<bold>D</bold>) The nose traces of each trial across a single session, colored by chosen side. (<bold>E</bold>) Location of all inhalations across a single session, colored by chosen side. (<bold>F</bold>) Two-dimensional histogram of occupancy (fraction of frames spent in each 0.5 cm² bin). Colormap represents grand mean across mice (<italic>n</italic> = 19). (<bold>G</bold>) Grand mean sniff rate colormap across mice (<italic>n</italic> = 11).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Idiosyncratic occupancy distributions across individual mice.</title><p>Two-dimensional histogram of occupancy (fraction of frames spent in each 0.5 cm² bin).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig3-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Mice synchronize three-dimensional kinematic rhythms with sniffing during olfactory search</title><p>To test the hypothesis that nose movement locks to respiration during olfactory search, we aligned movement dynamics with the sniff signal. Using Deeplabcut (<xref ref-type="bibr" rid="bib56">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib57">Mathis and Mathis, 2020</xref>), we tracked the position of three points: tip of snout, back of head, and center of mass (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="video" rid="video3">Video 3</xref>). From the dynamics of these three points, we extracted the kinematic parameters nose speed, head yaw velocity, and Z-velocity (<xref ref-type="fig" rid="fig4">Figure 4B–D</xref>). Synchrony between movement oscillations and sniffing is apparent on a sniff-by-sniff basis (<xref ref-type="fig" rid="fig5">Figure 5</xref>), Video consistent across mice, and selectively executed during olfactory search. On average, nose speed accelerates during exhalation, peaks at inhalation onset, and decelerates during inhalation (<xref ref-type="fig" rid="fig5">Figure 5Ai</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Quantifying kinematic parameters during olfactory search.</title><p>(<bold>A</bold>) Schematic of kinematic parameters. Left: two example frames from one mouse, with the three tracked points marked: tip of snout, back of head, and center of mass. (<bold>B</bold>) Quantified kinematic parameters: ‘nose speed’: displacement of the tip of the snout per frame (12.5 ms inter-frame interval). ‘Yaw velocity’: change in angle between the line segment connecting snout and head and the line segment connecting head and center of mass. Centrifugal movement is positive, centripetal movement is negative. ‘Z-velocity’: change in distance between tip of snout and back of head. Note that this measure confounds pitch angle and Z-axis translational movements. (<bold>C</bold>) Segments of example trajectories. Left: the trajectory of the nose during 1 s of trial time. Green: path during inhalations. Black: path during the rest of the sniff. Right: same for an inter-trial interval trajectory. (<bold>D</bold>) Traces of sniff and kinematic parameters during the time windows shown in (<bold>C</bold>). Color scheme as in (<bold>C</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig4-v2.tif"/></fig><media id="video3" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video3.mp4"><label>Video 3.</label><caption><title>Movement trajectories for individual sniffs.</title><p>Each video snippet corresponds to one sniff, where the frames are translated so that the back of the head is centered, and rotated so that the head angle is vertical, in the first frame of each sniff. Blue = inhalation, pink = exhalation. Video frame rate is slowed by 10×.</p></caption></media><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Kinematic rhythms synchronize with the sniff cycle selectively during olfactory search.</title><p>(i–iii) Nose speed, yaw velocity, and Z-velocity, respectively (see <xref ref-type="fig" rid="fig4">Figure 4</xref> for definitions). (<bold>A</bold>) Top: color plot showing movement parameter aligned to inhalation onset for within-trial sniffs taken before crossing the decision line. Taken from one mouse, one behavioral session. Dotted line at time 0 shows inhalation onset, the second line demarcates the end of the sniff cycle, sorted by duration. Data are taken from one behavioral session. Middle: color plot showing each movement parameter aligned to inhalation onset for inter-trial interval sniffs taken before the first attempt at premature trial initiation. Bottom: sniff-aligned average of each movement parameter. Thin lines represent individual mice (<italic>n</italic> = 11), bolded lines and shaded regions represent the grand mean ± standard deviation. Green: within-trial sniffs; pink: inter-trial interval sniffs. (<bold>B</bold>) Normalized cross-correlation between movement parameter and sniff signal for the same sniffs as above. (<bold>C</bold>) Spectral coherence of movement parameter and sniff signal for the same sniffs as above.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Sniff synchronization shuffle test.</title><p>Sniff-aligned grand mean (<italic>n</italic> = 11 mice) of (<bold>A</bold>) nose speed, (<bold>B</bold>) yaw velocity, and (<bold>C</bold>) Z-velocity for within-trial (top) and inter-trial interval (bottom) sniffs, overlaid on 1000 iterations of trial-shuffled grand means. Thin black lines represent individual iterations, all of which are shown.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Kinematic rhythms for premature initiations during the inter-trial interval and between decision line and reward port during trials.</title><p>Sniff-aligned average of (<bold>A</bold>) nose speed, (<bold>B</bold>) yaw velocity, and (<bold>C</bold>) Z-velocity. Thin lines represent individual mice (<italic>n</italic> = 11), bolded lines and shaded regions represent the grand mean ± standard deviation. Top: green: within-trial sniffs from the time between crossing the decision line and entering the reward port. Pink: inter-trial interval sniffs from the time between the first premature trial initiation attempt and the successful initiation of the next trial. Bottom: green: within-trial sniffs at nose speeds above the threshold 15 cm/s. Pink: inter-trial interval sniffs at nose speeds above the threshold 15 cm/s.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig5-figsupp2-v2.tif"/></fig></fig-group><p>Head yaw velocity, which we define as toward or away (<xref ref-type="fig" rid="fig4">Figure 4</xref>; centripetal or centrifugal) from the body-head axis, reaches peak centrifugal velocity at inhalation, decelerates and moves centripetally over the course of inhalation (<xref ref-type="fig" rid="fig5">Figure 5Aii</xref>). Although our videos are in two dimensions, we can approximate movement in depth by analyzing the distance between the tip of the snout and the back of the head (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). This measure confounds pitch angular motion and vertical translational motion, so we conservatively refer to this parameter as ‘Z-velocity’. Because mice point their head downward during task performance, shortening of the distance between the tip of the snout and the back of the head indicates downward movement, while increases in the distance correspond to upward movements. The Z-velocity reaches peak upward velocity at inhalation onset, decelerates and goes downward during inhalation, and rises again at exhalation (<xref ref-type="fig" rid="fig5">Figure 5Aiii</xref>). These modulations were absent from trial-shuffled data (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>; permutation test, p&lt;0.001). Cross-correlation and spectral coherence analysis further demonstrates the synchrony between nose movement and sniffing (<xref ref-type="fig" rid="fig5">Figure 5B, C</xref>). These results demonstrate that kinematic rhythms lock to sniffing with tens of milliseconds precision, consistent with a previous report demonstrating that rats make similar movements during novel odor-evoked investigative behavior (<xref ref-type="bibr" rid="bib48">Kurnikova et al., 2017</xref>). Our findings show that precise cycle-by-cycle synchronization can also be a feature of goal-directed odor-guided behavior. Mice selectively deploy this pattern of sniff-synchronized three-dimensional nose movement. For nose speed, yaw velocity, and Z-velocity, sniff synchrony is significantly reduced during the ITI when the mouse is returning from the reward port to initiate the next trial, even when the mouse is sniffing rapidly. Modulations in nose speed were slightly different than trial-shuffled data, showing that sniff-synchronized movement is not totally absent during the ITI, whereas modulations in yaw velocity and Z-velocity were indistinguishable from trial-shuffled data (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). This difference between within-trial and between-trial sniff synchrony was not contingent on the mouse’s slower nose speed during the ITI (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Kinematic synchrony was the same when only periods of high-speed nose movement in the ITI are included in the analysis (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). This reduction of kinematic synchrony when the mouse is not performing the task suggests that sniff-synchronized movement is not an inevitable biomechanical accompaniment to fast sniffing, but rather reflects a strategic behavioral state. Further support for this idea comes from analyzing time intervals when the mouse attempts to initiate a trial before the end of the ITI.</p><p>After such premature attempts at trial initiation, the mice execute sniff-synchronized movement, despite the absence of the experimenter-applied odor stimulus (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). Lastly, sniff synchrony changes dramatically in the time interval between crossing the virtual decision line and entering the reward port, when odor is still present yet the animal has committed to a decision (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). Taken together, our observations indicate that sniff synchronous movement is a proactive, odor-seeking strategy rather than a reactive, odor-gated reflex.</p></sec><sec id="s2-5"><title>State space modeling finds recurring motifs that are sequenced diversely across mice</title><p>In our olfactory search paradigm, the overall rhythm of nose movement synchronizes with sniffing (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>), and yet the mice move through a different trajectory on every trial (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Given this heterogeneity, it was not obvious to us how to best quantify common features of movement trajectories across trials and subjects. Rather than guess at suitable features, we used an unsupervised machine learning tool, modeling the movement data with an auto-regressive hidden Markov model (AR-HMM) (<xref ref-type="bibr" rid="bib63">Murphy, 2012</xref>; <xref ref-type="bibr" rid="bib71">Poritz, 1982</xref>). This model parses continuous sequential data into a discrete set of simpler movement motif sequences, similarly to ‘Motion Sequencing’ (MoSeq) (<xref ref-type="bibr" rid="bib95">Wiltschko et al., 2015</xref>). We fit AR-HMMs to the allocentric three-point coordinate data (front of snout, back of head, and center of mass <xref ref-type="video" rid="video4">Video 4</xref>) pooled across a subset of mice and trial conditions (see Materials and methods and <xref ref-type="fig" rid="fig2">Figure 2</xref>; e.g., 80:20, 90:30, nostril stitch). Models were then tested for their ability to explain a separate set of held-out trials (see Materials and methods). These models defined discrete movement patterns, or ‘motifs’, that recur throughout our dataset (e.g., <xref ref-type="fig" rid="fig6">Figure 6A</xref>). We fit different AR-HMMs each constrained to find a particular number of motifs (between 6 and 100) and found that the cross-validated log-likelihood of these fits continued to rise up to 100 motifs (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). For visualization, we will focus on a model with 16 states, which we narrow to 11, by excluding rare motifs that take up &lt;5% of the assigned video frames (<xref ref-type="fig" rid="fig6">Figure 6B</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C, D</xref>). Models with more or fewer states gave equivalent results (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplements 2</xref>–<xref ref-type="fig" rid="fig6s4">4</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Recurring movement motifs are sequenced diversely across mice and consistently across stimuli.</title><p>(<bold>A</bold>) Eight example frames from one instance of a behavioral motif with tracking overlaid. (<bold>B</bold>) Average motif shapes. Dots and lines show the average time course of posture for eight frames of each of the 11 motifs (<italic>n</italic> = 9 mice). All instances of each motif are translated and rotated so that the head is centered and the head-body axis is oriented upward in the first frame. Subsequent frames of each instance are translated and rotated the same as the first frame. Time is indicated by color (dark to light). Background color in each panel shows the color assigned to each motif. (<bold>C</bold>) Across-trial motif sequences for two behavioral sessions for one mouse. Trials are separated into trials where the mouse chose left and those in which the mouse chose right. Trials are sorted by duration. Both correct and incorrect trials are included. Color scheme as in (<bold>B</bold>). (<bold>D</bold>) Linear classifier analysis shows that mice can be identified from motif sequences on a trial-by-trial basis. Grayscale represents the fraction of trials from a given mouse (rows) that are decoded as belonging the data of a given mouse (columns). The diagonal cells represent the accuracy with which the decoded label matched the true label, while off-diagonal cells represent trials that were mislabeled by the classifier. Probabilities along rows sum to 1. Cells marked with asterisks indicate above chance performance (label permutation test, p&lt;0.01). (<bold>E</bold>) Linear classifier analysis identifies odor omission trials above chance, but does not discriminate across odor concentration ratios (<italic>n</italic> = 9 mice). (<bold>F</bold>) Cross-validated log-likelihood (evaluated on trials not used for model fitting) for fit auto-regressive hidden Markov model (AR-HMM) models with different numbers of motifs, <italic>S</italic>, shows that model log-likelihood does not peak or plateau up to <italic>S</italic> = 100.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Motif statistics and examples and linear decoder results for 80:20 experiments.</title><p>(<bold>A</bold>) Example nose trace across a single trial colored by motif identity. (<bold>B</bold>) Linear decoder (<xref ref-type="fig" rid="fig6">Figure 6</xref>; Materials and methods: linear decoding section) results for Variable <italic>|C|</italic> experiments (<italic>n</italic> = 5). (<bold>C</bold>) Fraction of motif usage across all mice (<italic>n</italic> = 8) for the model with <italic>S</italic> = 16. Black points are individual mice, black line is average across mice, and shaded region is ±1 standard deviation. Colors on x-axis represent motifs used in analysis (<xref ref-type="fig" rid="fig6">Figure 6</xref>) and y-axis are fractions of frames that motif occupies. (<bold>D</bold>) The average dwell time of each motif across all mice (<italic>n</italic> = 8) for the model with <italic>S</italic> = 16. Black points are individual mice, black line is average across mice, and shaded region is ±1 standard deviation. Colors on x-axis represent motifs used in analysis (<xref ref-type="fig" rid="fig6">Figure 6</xref>) and y-axis are fractions of frames that motif occupies.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Motif shapes, sequences, transition matrices, and sniff synchronization for an auto-regressive hidden Markov model capped at a maximum of six states.</title><p>(<bold>A-E</bold>) As in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig6-figsupp2-v2.tif"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 3.</label><caption><title>Motif shapes, sequences, transition matrices, and sniff synchronization for an auto-regressive hidden Markov model capped at a maximum of 10 states.</title><p>(<bold>A-E</bold>) As in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig6-figsupp3-v2.tif"/></fig><fig id="fig6s4" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 4.</label><caption><title>Motif shapes, sequences, transition matrices, and sniff synchronization for an auto-regressive hidden Markov model capped at a maximum of 20 states.</title><p>(<bold>A-E</bold>) As in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig6-figsupp4-v2.tif"/></fig><fig id="fig6s5" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 5.</label><caption><title>Motif shapes across individuals.</title><p>Average of first eight frames of the 11 commonly used motifs across individuals. Dots and lines show the average time course of posture for eight frames of each of the 11 motifs. All instances of each motif are translated and rotated so that the head is centered and the head-body axis is oriented upward in the first frame. Subsequent frames of each instance are translated and rotated the same as the first frame. Time is indicated by color (dark to light). Each color/column represents a single motif and each row an individual mouse.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig6-figsupp5-v2.tif"/></fig></fig-group><media id="video4" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video4.mp4"><label>Video 4.</label><caption><title>Example trials with motif sequences.</title><p>Three dots on the mouse represent the coordinates of front of snout, back of head, and center of mass extracted using Deeplabcut. Dots and lines are colored according to the motif to which that frame was assigned by the auto-regressive hidden Markov model. Video frame rate is slowed by 8×.</p></caption></media><p>The motifs extracted by this model have interpretable spatiotemporal trajectories on average (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, <xref ref-type="video" rid="video5">Video 5</xref>), although averaging masks considerable across-instance variability (<xref ref-type="video" rid="video6">Video 6</xref>). Across trials for a given mouse, motifs occurred in consistent but non-stereotyped sequences (<xref ref-type="fig" rid="fig6">Figure 6C</xref>, <xref ref-type="video" rid="video5">Video 5</xref>). Across mice, the model identified consistent behavioral features as motifs (<xref ref-type="fig" rid="fig6s5">Figure 6—figure supplement 5</xref>), but most mice were uniquely identifiable from how they sequenced motifs across trials. A classifier trained to decode mouse identity from the motif sequences on a trial-by-trial basis was able to perform above chance for eight out of nine mice (<xref ref-type="fig" rid="fig6">Figure 6D</xref>; p&lt;0.01). Across the different concentration ratios (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), movement sequences were not statistically distinguishable (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). The only condition that gave distinguishable motif patterns were the odor omission trials (0:0), in which the mice made longer, more tortuous trajectories (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Thus, although this model is sensitive enough to decode mouse identity (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), it does not detect stimulus-dependent modifications of sampling behavior, suggesting that the mice do not modify their sampling behavior in a gradient-dependent manner, at least in the movement parameters we measured. This lack of modification ran counter to our expectations because we reasoned that making the task harder would make the mice adjust their strategy to maintain high performance. We speculate that this absence of an adaptive strategy is due to impulsivity (<xref ref-type="bibr" rid="bib60">Miyazaki et al., 2012</xref>; <xref ref-type="bibr" rid="bib23">Fonseca et al., 2015</xref>).</p><media id="video5" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video5.mp4"><label>Video 5.</label><caption><title>Moving occupancy histograms for motifs show their average movement dynamics.</title><p>We aligned every instance of a given motif such that that instance’s frames were translated to position the center of mass in frame 1 at consistent location in the image and rotated so that the body axis points upward in frame 1. Colormap represents regions of high occupancy with brighter, warmer colors, and lower occupancies with darker, colder colors. Video frame rate is slowed by 8×.</p></caption></media><media id="video6" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video6.mp4"><label>Video 6.</label><caption><title>Moving wireframes for motifs show the variability of movement dynamics for a given motif.</title><p>Wireframes consist of two lines connecting coordinates of front of snout, back of head, and center of mass extracted using Deeplabcut. Each wireframe represents a single instance of every motif. We aligned frames as in <xref ref-type="video" rid="video5">Video 5</xref>. Lines are colored arbitrarily to facilitate visualization of individual wireframes. Video frame rate is slowed by 8×.</p></caption></media></sec><sec id="s2-6"><title>Movement motifs reveal two-state organization of olfactory search</title><p>Many behaviors have hierarchical structure that is organized at multiple temporal scales. Brief movements are grouped into progressively longer modules and are ultimately assembled into purposive behavioral programs (<xref ref-type="bibr" rid="bib8">Berman et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Gallistel, 1982</xref>; <xref ref-type="bibr" rid="bib84">Tolman, 1932</xref>; <xref ref-type="bibr" rid="bib92">Weiss, 1968</xref>).</p><p>Olfactory search programs in smaller organisms are often organized into two overarching states: move straight when concentration is increasing and reorient when concentration is decreasing (<xref ref-type="bibr" rid="bib6">Bargmann, 2006</xref>; <xref ref-type="bibr" rid="bib7">Berg, 2000</xref>; <xref ref-type="bibr" rid="bib30">Gomez-Marin et al., 2011</xref>; <xref ref-type="bibr" rid="bib43">Kennedy and Marsh, 1974</xref>; <xref ref-type="bibr" rid="bib51">Lockery, 2011</xref>; <xref ref-type="bibr" rid="bib85">van Breugel and Dickinson, 2014</xref>; <xref ref-type="bibr" rid="bib88">Vickers and Baker, 1994</xref>). We hypothesized that olfactory search motifs in mice are organized similarly. To reveal higher-order structure in the temporal organization of these motifs, we applied a clustering algorithm that minimizes the Euclidean distance between rows of the Markov transition matrix (i.e., purely based on the conditional probabilities of motifs following them). This clustering separated motifs into two groups (<xref ref-type="fig" rid="fig7">Figure 7A</xref>), with several distinct properties. These properties were present in models with more or fewer states (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplements 2</xref>–<xref ref-type="fig" rid="fig6s4">4</xref>). Based on these differences (see below), we label these groups as putative ‘investigation’ and ‘approach’ states. First, investigation and approach motifs cluster their onset times in the trial, with investigation motifs tending to occur early in the trial, while approach motifs tend to begin later (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). Grouping motifs into these higher-order states shows a consistent trial sequence, with trials beginning with investigation and ending with approach (<xref ref-type="fig" rid="fig7">Figure 7C, D</xref>). Importantly, entering the approach state is not a final, ballistic commitment to a given water port – switches from approach back to investigation were common (<xref ref-type="fig" rid="fig7">Figure 7C, D</xref>, <xref ref-type="video" rid="video7">Video 7</xref>). This pattern suggests that the mice are continuously integrating evidence about the odor gradient throughout their trajectory to the target. Second, these states correlated with distinct sniff rates and movement speeds. During investigation motifs, the mice moved more slowly and sniffed more rapidly, whereas the approach states were associated with faster movement and slower sniffing (<xref ref-type="fig" rid="fig7">Figure 7E</xref>) (<xref ref-type="video" rid="video8">Video 8</xref>). Third, the sniff-synchronized kinematic rhythms (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>) were distinct in the two states (<xref ref-type="fig" rid="fig7">Figure 7F</xref>; Kolmogorov–Smirnov test, p&lt;0.01). Specifically, nose speed and yaw velocity are more synchronized with sniffing during the investigation state (<xref ref-type="fig" rid="fig7">Figure 7F</xref>). Given the consistent sequence from investigation to approach and given that mice sniff faster during the early part of trial, these differences in kinematic parameters could reflect across-trial tendencies instead of within-trial synchrony. To test this possibility, we calculated the Kolmogorov–Smirnov statistic, which quantifies the difference between two cumulative distributions, for real and trial-shuffled data (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). This analysis showed that nose speed and yaw velocity modulation exceeded what would be expected from across-trial tendencies (1000 shuffles, p&lt;0.001), while the Z-velocity modulation did not (p=0.31). Switches between the investigation and approach state mark behavioral inflection points that can be identified from trial to trial. We reason that these behavioral inflection points are a signature of key moments in the mouse’s evolving decision process. Thus, our analysis can provide a framework for temporal alignment of diverse movement trajectories with simultaneously recorded physiological data (<xref ref-type="bibr" rid="bib55">Markowitz et al., 2018</xref>).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Behavioral motifs can be categorized into two distinct groups, which we putatively label as investigation (blue) and approach motifs (orange).</title><p>Colors in panel A &amp; B refer to motifs specified in <xref ref-type="fig" rid="fig6">Figure 6</xref>. (<bold>A</bold>) Transition probability matrix. Grayscale represents the log probability with which a given motif (rows) will be followed by another (columns). Clustering by minimizing Euclidean distance between rows reveals two distinct blocks of motifs. We label the top-left block as 'investigation' and the bottom-right block as 'approach'. (<bold>B</bold>) Distribution of onset times for each motif, normalized by trial duration. Investigation motifs tend to occur early in trials, while approach motifs tend to occur later (<italic>n</italic> = 9 mice). (<bold>C</bold>) Across-trial motif sequences for two behavioral sessions for one mouse, with motifs classified into investigation and approach. Trials are separated into correct trials (above) and incorrect trials (below). Motif sequences are sourced from the same data as <xref ref-type="fig" rid="fig6">Figure 6C</xref>. (<bold>D</bold>) Temporal details of investigation-approach transitions with overlaid sniff signal. Data come from a subset of trials shown in (<bold>C</bold>). In the sniff signal, green represents inhalations, black represents the rest of the sniff. (<bold>E</bold>) Investigation and approach motifs differ in nose speed and sniff rate. Individual markers represent one motif from one mouse. Marker shapes correspond to the individual mice (<italic>n</italic> = 4). Sniff rate and nose speed are normalized within mice. (<bold>F</bold>) Investigation and approach motifs differ in the kinematic rhythms (same parameters as in <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>). Thin lines represent individual mice (<italic>n</italic> = 4), thick lines and shaded regions represent the grand mean ± standard deviation. Blue: within-trial sniffs; orange: inter-trial interval sniffs. Top: nose speed modulation, defined by a modulation index <inline-formula><mml:math id="inf1"><mml:mfenced separators="|"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> calculated from the grand mean, is significantly greater for investigation motifs than approach motifs (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>; p&lt;0.001, permutation test). Middle: yaw velocity modulation is significantly greater for investigation motifs than approach motifs (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>; p&lt;0.001, permutation test). Bottom: Z-velocity modulation does not significantly differ between approach motifs and investigation motifs (p=0.31, permutation test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig7-v2.tif"/></fig><media id="video7" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video7.mp4"><label>Video 7.</label><caption><title>Example trials with investigation/approach overlaid.</title><p>Three dots on the mouse represent the coordinates of front of snout, back of head, and center of mass extracted using Deeplabcut. Dots and lines are colored according to whether that frame was assigned by the auto-regressive hidden Markov model to an investigation motif or an approach motif. Sniffing is indicated by sound (higher tone = inhalation, lower tone = exhalation). Video frame rate is slowed by 8×.</p></caption></media><media id="video8" mime-subtype="mp4" mimetype="video" xlink:href="elife-58523-video8.mp4"><label>Video 8.</label><caption><title>Movement trajectories for individual sniffs separated into investigation and approach.</title><p>Each video snippet corresponds to one sniff, where the frames are translated so that the back of the head is centered and rotated so that the head angle is vertical, in the first frame of each sniff. Blue = inhalation, pink = exhalation. Video frame rate is slowed by 10×.</p></caption></media></sec><sec id="s2-7"><title>Investigation motif onsets are precisely locked to sniffing</title><p>If motif transitions correspond to relevant behavioral events, their temporal structure should correlate with the temporal structure of neural activity (<xref ref-type="bibr" rid="bib55">Markowitz et al., 2018</xref>). During fast sniffing, respiration matches with the rhythms of head movement (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>), whisking, and nose twitches (<xref ref-type="bibr" rid="bib48">Kurnikova et al., 2017</xref>; <xref ref-type="bibr" rid="bib61">Moore et al., 2013</xref>; <xref ref-type="bibr" rid="bib76">Ranade et al., 2013</xref>). These motor rhythms correlate with activity in numerous brain regions, including brainstem, olfactory structures, hippocampus, amygdala, and numerous neocortical regions (<xref ref-type="bibr" rid="bib41">Karalis and Sirota, 2018</xref>; <xref ref-type="bibr" rid="bib42">Kay, 2005</xref>; <xref ref-type="bibr" rid="bib53">Macrides et al., 1982</xref>; <xref ref-type="bibr" rid="bib86">Vanderwolf, 1992</xref>; <xref ref-type="bibr" rid="bib96">Yanovsky et al., 2014</xref>; <xref ref-type="bibr" rid="bib99">Zelano et al., 2016</xref>). We hypothesized that movement motifs would lock with these behavioral and neural rhythms, so we aligned sniff signals with motif onset times. Importantly, the breath signal was not input to the model.</p><p>This alignment revealed a striking organization of motif sequences relative to the sniff rhythm. For example, the onset times of motif 6 (dark blue) occurred in a precise timing relationship with sniffing (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). To visualize the timing relationship between onsets of all motifs and sniffing, we calculated the equivalent of a peristimulus time histogram for inhalation times relative to the onset time of each motif and took the grand mean across all mice (<xref ref-type="fig" rid="fig8">Figure 8B</xref>; <italic>n</italic> = 4). Further, to determine how motif onset times are organized relative to the sniff cycle, for each motif we calculated a histogram of motif onset in sniff phase coordinates (<xref ref-type="fig" rid="fig8">Figure 8C</xref>; relative position in the sniff cycle). Sharp peaks are apparent in both histograms for investigation motifs, and less so for approach motifs (quantified below; <xref ref-type="fig" rid="fig8">Figure 8B, C</xref>). Importantly, these timing relationships are consistent across mice, with some motifs tending to occur early in the sniff cycle during inhalation and others occurring later in the sniff cycle (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). Thus, parsing diverse movement trajectories into sequences of recurring movement motifs reveals additional sniff-synchronized kinematic structure in a consistent manner across mice.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Motif onsets synchronize to the sniff cycle.</title><p>(<bold>A</bold>) Alignment of the sniff signal to an example motif. Top: color scheme shows sniff cycles aligned to the onsets of motif 6 (blue). Motif instances are in chronological order. Green: inhalation; black: rest of sniff. Bottom: peristimulus time histogram of inhalation times aligned to the onset of motif 6. (<bold>B</bold>) Alignment of sniff signal to onset times of all motifs across mice (<italic>n</italic> = 4). Motifs categorized into two types we call investigation (light blue) and approach (orange). Colormap represents the grand means for peristimulus time histograms of inhalation times aligned to the onset of motifs. (<bold>C</bold>) Alignment of motif onset times in sniff phase. Colormap represents peristimulus time histograms of motif onsets (bin width = 12.5 ms) times aligned to inhalation onset, with all sniff durations normalized to 1. Dotted line shows the mean phase of the end of inhalation. (<bold>D</bold>) Motif alignment to sniff phase is consistent across mice. Thin lines represent individual mice, black points are means, and whiskers are ±1 standard deviation (<italic>n</italic> = 4 mice). (<bold>E</bold>) Investigation motifs are more synchronized to the sniff cycle than approach motifs. Dots represent the modulation index in time on the x-coordinates and in phase on the y-coordinates. Filled dots represent motifs that are significantly modulated in both time and phase (p&lt;0.01, permutation test). Half-filled dots represent motifs that are significantly modulated in time (left half filled) or phase (right half filled).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig8-v2.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Shuffle test for the difference in sniff synchronization between investigation and approach motifs for movement parameters.</title><p>We quantified the difference by calculating the Kolmogorov–Smirnov statistic for the comparison between the sniff-triggered averages in the two states, first for real data, and then for 1000 iterations of trial-shuffled data. Red shows the value for the real data, while the black histogram plots the distribution of Kolmogorov–Smirnov statistic for the 1000 iterations. (<bold>A</bold>) Nose speed. (<bold>B</bold>) Yaw velocity. (<bold>C</bold>) Z-velocity. </p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig8-figsupp1-v2.tif"/></fig><fig id="fig8s2" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 2.</label><caption><title>Shuffle test for sniff synchronization of motif onset for investigation and approach motifs.</title><p>We calculated a modulation index <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> for each motif's across-mouse mean histogram (<italic>n</italic> = 4) and calculated the same for 1000 trial-shuffled across-mouse mean histograms. Blue and orange lines give the value from the real data, while the black histogram shows the distribution of <italic>MI</italic> across shuffle iterations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig8-figsupp2-v2.tif"/></fig></fig-group><p>Are motif onsets timed with respect to inhalation times, or do they coordinate with the entire sniff cycle? In other words, is motif onset probability more modulated in time or phase? To quantify the sniff synchronization of motif onset times, we calculated a modulation index <inline-formula><mml:math id="inf3"><mml:mo>(</mml:mo><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:math></inline-formula> for each motif’s across-mouse mean histogram (<italic>n</italic> = 4). To test whether these trial-by-trial modulation indices exceeded what would be expected from across-trial tendencies, we compared real and trial-shuffled data (<xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>). All investigation motifs were significantly modulated for both time and phase coordinates (<xref ref-type="fig" rid="fig8">Figure 8E</xref>; filled symbols, permutation test, p&lt;0.001), with some having higher <italic>MI</italic> in time, and others in phase. One approach motif was significantly modulated in time coordinates (<xref ref-type="fig" rid="fig8">Figure 8E</xref>; right-half filled symbol, p=0.003), while two approach motifs were significantly modulated in phase coordinates (<xref ref-type="fig" rid="fig8">Figure 8E</xref>; left-half filled symbols, p=0.015 and p&lt;0.001). Comparing the modulation indices between time and phase coordinates does not reveal a consistent pattern of modulation in time vs. phase – some motifs had higher <italic>MI</italic> in phase, others in time. Thus, our data are inconclusive as to how motif onsets organize relative to the sniff cycle. Nevertheless, these analyses demonstrate that kinematic inflection points synchronize with breathing during olfactory search. Given that breathing synchronizes to other motor and brain rhythms, these motifs likewise correlate to the structure of activity of many neurons. Thus, our analysis will be a useful tool to pinpoint behaviorally relevant activity in widespread brain regions.</p></sec><sec id="s2-8"><title>Investigation and approach occupancy maps suggest a serial-sniff comparison strategy</title><p>We propose that motif transition times indicate ‘decision points’ at which the animal chooses its next move (<xref ref-type="bibr" rid="bib55">Markowitz et al., 2018</xref>). The transitions between investigation and approach motifs are particularly relevant since investigation motifs may correspond to an evidence-gathering state, while approach motifs may correspond to a reward-gathering state. What kind of sensory evidence guides transitions between investigation and approach? Although we cannot determine the precise odor inputs the mice acquire on a sniff-by-sniff basis, we reasoned that we could elucidate the search strategy by examining aggregate across-trial patterns in allocentric maps of investigation and approach occupancy.</p><p>As expected from the temporal structure of investigation and approach (<xref ref-type="fig" rid="fig7">Figure 7C, D</xref>), the mice primarily investigate near the initiation port (<xref ref-type="fig" rid="fig9">Figure 9A</xref>; <italic>n</italic> = 9 mice) and primarily approach close to the decision line (<xref ref-type="fig" rid="fig9">Figure 9A</xref>, orange). Along the longitudinal axis of the arena, the two occupancy maps overlap in a region between initiation port and decision line (<xref ref-type="fig" rid="fig9">Figure 9A</xref>, black) where overall occupancy also peaks (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). Along the lateral axis of the arena, on average the overlap region is roughly centered on the lateral midline between left and right sides (<xref ref-type="fig" rid="fig9">Figure 9A</xref>). However, this centered position is not representative of the individual mice, which have their overlap region in different positions relative to the lateral midline, with some on the left, and others on the right (<xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1A</xref>). However, if trials are oriented such that the chosen side is always up in the occupancy maps, the overlap region is displaced toward the chosen side of the arena in all individual mice (<xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1B</xref>). Thus, the mice primarily switched states while located on the side they would ultimately choose. To quantify the overlap between states, we calculated a relative occupancy index, defined as the difference in investigation and approach occupancy divided by their sum (<xref ref-type="fig" rid="fig9">Figure 9C</xref>, I.A.I.). For this index, a bin where the mice primarily investigated has a positive value, while a bin primarily occupied during the approach state has a negative value. Along the longitudinal axis, most of the change in this index occurred between inflection points at 5 and 10 cm, which we define as a ‘transition zone’ for the analyses below (<xref ref-type="fig" rid="fig9">Figure 9D</xref>).</p><fig-group><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>The allocentric spatial distribution of investigation and approach occupancy.</title><p>(<bold>A</bold>) Colormaps show two-dimensional histograms of the occupancy density (1 cm² bins, <italic>n</italic> = 9 mice) with investigation density in blue, approach density in orange, and overlap shown by darker coloring (key in top-left corner). Histograms around the colormaps show the state occupancy projected onto the longitudinal (top) and lateral (left) axes of the arena. (<bold>B</bold>) Occupancy distributions after the right-choice trials are flipped upward so that the chosen side is always facing up in the diagram. (<bold>C</bold>) Relative usage is quantified with an investigation approach index (I.A.I.), defined as the difference between investigation and approach occupancy divided by their sum. Blue and orange triangles are visual aids that represent the I.A.I. (<bold>D</bold>) Relative occupancy density of investigation and approach (I.A.I.), plotted along the longitudinal axis of the arena from the initiation port to the decision line. We define the region between 5 cm and 10 cm as a ‘transition zone’, in which most transitions between investigation and approach take place. Thin lines are individual mice (<italic>n</italic> = 9), thick line and shaded region are mean ± s.e.m. (<bold>E</bold>) I.A.I. plotted along the lateral axis in real space (i.e., left-right orientation) for all occupancy throughout the arena (left) and for the transition zone only (right). Thin lines are individual mice (<italic>n</italic> = 9), thick line and shaded region are mean ± s.e.m. (<bold>F</bold>) Same as (<bold>E</bold>), but after the lateral axis has been reoriented so that the chosen side is always up.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig9-v2.tif"/></fig><fig id="fig9s1" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 1.</label><caption><title>The allocentric spatial distribution of investigation and approach occupancy for individual mice.</title><p>(<bold>A</bold>) Colormaps show two-dimensional histograms of the occupancy density (1 cm² bins, <italic>n</italic> = 9 mice), with investigation density in blue, approach density in orange, and overlap shown by darker coloring (key in top-left corner). Each map corresponds to a single mouse. Trials are oriented with respect to real space, such that the left side of the arena faces up in the figure. (<bold>B</bold>) Same as (<bold>A</bold>), except that trials are reoriented so that the chosen side always faces up in the figure.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig9-figsupp1-v2.tif"/></fig></fig-group><p>Along the lateral axis of the arena, I.A.I. was quite variably distributed across mice, both for the entire occupancy map and within the transition zone (<xref ref-type="fig" rid="fig9">Figure 9E</xref>), consistent with the individual mouse occupancy maps (<xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1A</xref>). Orienting trials with respect to the chosen side demonstrates a clearer pattern, with primarily investigation on the unchosen side and primarily approach on the chosen side (<xref ref-type="fig" rid="fig9">Figure 9F</xref> and <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1B</xref>).</p><p>Occupancy maps allowed us to further evaluate hypotheses about the search strategy mice use in these conditions. One hypothetical strategy is that the mice memorize absolute concentrations across trials and compare each individual sniff to an internal threshold learned over previous trials (single-sniff hypothesis). Another possible strategy would be serial-sniff comparison, where the mouse senses changes between sequential samples within individual trials (serial-sniff hypothesis). These hypotheses make distinct predictions about where the mouse should sample. For the single-sniff hypothesis, the most informative location to sample is directly downwind of the odor ports, where concentration differences between left and right trials are maximal (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). For gradient sensing, the optimal location is instead across the lateral midline, where the gradients are sharpest (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>; <xref ref-type="bibr" rid="bib98">Yovel et al., 2010</xref>). We tested these predictions by comparing occupancy maps between correct and incorrect trials. For the single-sniff strategy, the mouse should get it correct more often when it investigates downwind of the odor ports, while a serial sniff hypothesis predicts that correct trials should show increased investigation at the midline.</p><p>Correct and incorrect trials yielded qualitatively similar occupancy maps (<xref ref-type="fig" rid="fig10">Figure 10A</xref>). To quantify their differences, we first compared their occupancy indices along the longitudinal axis of the arena (<xref ref-type="fig" rid="fig10">Figure 10B, C</xref>). Correct trials featured significantly higher I.A.I. (greater investigation) in the latter part of the transition zone, while past the decision zone the I.A.I. was higher for incorrect trials (<xref ref-type="fig" rid="fig10">Figure 10C</xref>; permutation test, p&lt;0.001, <italic>n</italic> = 9 mice). Thus, increased investigation in the transition zone was associated with correct trials, while increased investigation near the decision line was associated with incorrect trials. This pattern suggests that investigation is not inherently advantageous to olfactory search irrespective of location. Instead, it matters where the mouse investigates, and some locations are less advantageous. Notably, absolute concentrations are most discriminable near the decision line (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>), suggesting that mice may not be able to capitalize on this cue under these conditions.</p><fig-group><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Occupancy maps indicate an advantage for investigation of both sides.</title><p>(<bold>A</bold>) Colormaps show two-dimensional histograms of the occupancy density (1 cm² bins, <italic>n</italic> = 9 mice) with investigation density in blue, approach density in orange, and overlap shown by darker coloring (key in top-left corner). Histograms around the colormaps show the state density projected onto the longitudinal (top) and lateral (left) axes of the arena. Left: correct trials. Right: incorrect trials. (<bold>B</bold>) Investigation approach index (I.A.I.) for correct (purple) and incorrect (green) trials. Thick lines and shaded region are mean ± s.e.m., thin lines are individual mice. (<bold>C</bold>) Difference in I.A.I. between correct and incorrect trials along the longitudinal axis (2.5 cm bins, <italic>n</italic> = 9). Thick line is the across-mouse mean difference, thin gray lines are 1000 permutations in which correct and incorrect trial labels were scrambled. (<bold>D</bold>) Investigation occupancy along the lateral axis, within the transition zone (5–10 cm longitudinal) for correct and incorrect trials. Thick lines and shaded region are mean ± s.e.m., thin lines are individual mice. (<bold>E</bold>) Approach occupancy along the lateral axis, within the transition zone (5–10 cm longitudinal) for correct and incorrect trials. Thick lines and shaded region are mean ± s.e.m., thin lines are individual mice. (<bold>F</bold>) I.A.I. along the lateral axis, within the transition zone (5–10 cm longitudinal) for correct and incorrect trials. Thick lines and shaded region are mean ± s.e.m., thin lines are individual mice. (<bold>G</bold>) Difference in investigation occupancy between correct and incorrect trials along the lateral axis, within the transition zone. Thick blue line is the across-mouse mean difference, thin blue lines are 1000 permutations in which correct and incorrect trial labels were scrambled. (<bold>H</bold>) Difference in approach occupancy between correct and incorrect trials. Thick orange line is the across-mouse mean difference, thin orange lines are 1000 permutations in which correct and incorrect trial labels were scrambled. (<bold>I</bold>) Difference in I.A.I. between correct and incorrect trials. Thick orange line is the across-mouse mean difference, thin orange lines are 1000 permutations in which correct and incorrect trial labels were scrambled.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig10-v2.tif"/></fig><fig id="fig10s1" position="float" specific-use="child-fig"><label>Figure 10—figure supplement 1.</label><caption><title>Occupancy maps indicate an advantage for investigation of both sides for both stay trials and switch trials.</title><p>(<bold>A</bold>) Occupancy map analysis for ‘stay’ trials (trials where the mouse chooses the side it first turned to, analyses as in <xref ref-type="fig" rid="fig10">Figure 10</xref>). (<bold>B</bold>) Occupancy map analysis for ‘switch’ trials (trials where the mouse chooses the opposite side from its first turn).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-58523-fig10-figsupp1-v2.tif"/></fig></fig-group><p>We next quantified state occupancies along the lateral axis within the transition zone (<xref ref-type="fig" rid="fig10">Figure 10D–F</xref>). Correct trials featured significantly increased investigation at and on the unchosen side of the midline relative to incorrect trials (<xref ref-type="fig" rid="fig10">Figure 10G</xref>; permutation test, p&lt;0.001, <italic>n</italic> = 9 mice). By definition, occupancy of the unchosen side precedes a crossing of the midline to get to the chosen side. This suggests an advantage to sampling both sides of the midline, consistent with a serial-sniff gradient sensing strategy. Further, investigation more laterally, downwind of the odor port, was increased on incorrect trials, suggesting that sampling this location was not advantageous for task performance, contrary to the single-sniff absolute concentration hypothesis. Approach occupancy showed a different pattern, with significantly higher approach at and around the midline on incorrect trials, and a significant increase in approach occupancy closer to the chosen water port (<xref ref-type="fig" rid="fig10">Figure 10H</xref>; permutation test, p&lt;0.001). Consistent with these observations, on correct trials I.A.I. showed significant elevation at the midline and into the unchosen side of the arena, while increased I.A.I. of the chosen side was associated with incorrect trials (<xref ref-type="fig" rid="fig10">Figure 10I</xref>; permutation test, p&lt;0.001). Altogether, these results suggest that it is advantageous to sample both sides of the midline in this task, consistent with the serial-sniff hypothesis.</p><p>An important consideration in interpreting these results pertains to the construction of our task. Before choosing a side, the mice have to turn out of the initiation port in one direction or the other on every trial. On some trials they stay and choose the side of the first turn, while on other trials they switch and choose the other side. A single-sniff hypothesis predicts that if the mouse happens to turn first toward the correct side, it will tend to encounter above threshold concentrations during the turn and should therefore tend to transition to approach without crossing the midline. However, if the mouse turns first to the incorrect side, threshold crossings will tend not to occur and the mouse can initiate approach before crossing the midline.</p><p>Thus, this hypothesis predicts that correct vs. incorrect occupancy differences should occur at different positions along the lateral axis for stay and switch trials. To test this prediction, we performed the same analyses separately for stay and switch trials. Although not identical, both stay and switch trials showed significantly increased investigation at and on the unchosen side of the midline for correct trials (<xref ref-type="fig" rid="fig10s1">Figure 10—figure supplement 1</xref>). This analysis demonstrates that the apparent advantage of sampling across the midline is not an artifact of the asymmetry between switch and stay trials. Taken together, investigation and approach occupancy mapping provides further evidence, suggesting that mice use a serial-sniff strategy to sense gradient cues in this task (<xref ref-type="bibr" rid="bib13">Catania, 2013</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>This study elucidates sensory computations and movement strategies for olfactory search by freely moving mice. Mice learn our behavioral task in days, after which they perform approximately 150 trials daily, sometimes for months. Task performance worsens for shallower odor gradients at a fixed absolute concentration, but is unaffected by varying absolute concentrations at a fixed concentration gradient. Taken together, these results show that mice can navigate noisy gradients formed by turbulent odor plumes. This gradient-guided search is robust to perturbations including novel odorant introduction and naris occlusion. These results give insight into sensory computations for olfactory search and constrain the possible underlying neural mechanisms.</p><p>Mice perform this task with a strategic behavioral program. During search, mice synchronize rapid three-dimensional head movements with fast sniffing. This synchrony is not a default accompaniment of fast sniffing – synchrony is absent when the mice are not searching. Movement trajectories are not stereotyped, but vary considerably across trials. To manage this complexity, we took an unsupervised computational approach to parse heterogeneous trajectories into a small number of movement motifs that recur across trials and subjects. This analysis captures common movement features across mice, but individual mice can be identified by how they sequence these motifs. Our model was not constrained to find structure at a specific timescale, and consequently identified very brief, simple motifs. To find higher-order temporal structure in the data, we clustered motifs by their transition probabilities, which revealed two clear categories, putatively corresponding to investigation and approach. Investigation motifs tend to be executed early in the trial, and entail slower movement, faster sniffing, and more sniff synchrony than approach motifs. Even so, approach motifs are not ballistic commitments to an answer – switches from approach to investigation occurred on many trials. Lastly, the onset times of motifs were precisely locked to sniffing, with investigation motifs starting at characteristic phases of the sniff cycle.</p><p>The allocentric structure of investigation and approach suggests that the investigation state is not inherently advantageous. Rather, where the mouse investigates matters for performance. This dependence of performance on location indicates the spatial distribution of informative features in this olfactory scene. Notably, incorrect trials feature more investigation directly downwind of the odor source, along the axis of maximal odor concentration, which would be optimal if the mouse were using a single-sniff, absolute concentration strategy (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C</xref>). Thus, these analyses provide further evidence that the mice do not capitalize on absolute concentration information to guide performance in this task. Instead, correct trials feature more investigation at and across the axis of maximal odor gradient (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2D</xref>), reminiscent of an object localization strategy observed in Egyptian fruit bats. When approaching an object, these bats do not center their sonar beams directly at the object, but rather point them off axis, so that the maximum slope of the acoustic profile intersects the object (<xref ref-type="bibr" rid="bib98">Yovel et al., 2010</xref>). Likewise, in this task mice do not gain an advantage by centering their sniffing directly downwind of the odor sources, but rather perform best when they investigate the location of the steepest slope of the odor gradient, consistent with a serial-sniff gradient sensing strategy. Thus, our unsupervised computational analysis of airborne odor tracking supports the idea that sampling off axis can be an optimal strategy for localization across diverse sensory systems and species (<xref ref-type="bibr" rid="bib98">Yovel et al., 2010</xref>).</p><p>Olfactory navigation can be either guided or gated by odor (<xref ref-type="bibr" rid="bib5">Baker et al., 2018</xref>). Some organisms operate in a regime where diffusion forms smooth chemical gradients, in which classical chemotaxis strategies can be effective (<xref ref-type="bibr" rid="bib6">Bargmann, 2006</xref>; <xref ref-type="bibr" rid="bib7">Berg, 2000</xref>; <xref ref-type="bibr" rid="bib32">Gomez-Marin and Louis, 2012</xref>; <xref ref-type="bibr" rid="bib51">Lockery, 2011</xref>). In contrast, other organisms, such as flying insects, often operate in a highly turbulent regime where concentration gradients are not reliably informative (<xref ref-type="bibr" rid="bib16">Crimaldi et al., 2002</xref>; <xref ref-type="bibr" rid="bib62">Murlis et al., 1992</xref>; <xref ref-type="bibr" rid="bib77">Riffell et al., 2008</xref>). By design, mice in our task operate in an intermediate regime, where turbulent odor plumes close to the ground form noisy gradients (<xref ref-type="bibr" rid="bib29">Gire et al., 2016</xref>; <xref ref-type="bibr" rid="bib77">Riffell et al., 2008</xref>). By varying the absolute concentration and the concentration difference between the two sides, we tested whether performance in this regime is guided or gated by odor. Because behavior varies with the gradient and not the absolute concentration (<xref ref-type="fig" rid="fig2">Figure 2C–E</xref>), we have shown that mice are guided by gradient cues in this regime. Further, performance is higher when the mice sample both sides of the midline, suggesting that they sense the gradient by comparing sniff sequences across time.</p><p>Our naris occlusion experiments demonstrate that performance is statistically indistinguishable with naris occlusion, suggesting that stereo olfaction does not play a major role in our task. This finding contrasts with previous studies of olfactory navigation in a different regime: following a depositional odor trail. In these studies, stereo manipulations had small but significant effects on performance, and led to changes in movement strategy (<xref ref-type="bibr" rid="bib39">Jones and Urban, 2018</xref>; <xref ref-type="bibr" rid="bib45">Khan et al., 2012</xref>). Importantly, a study of olfactory search in moles showed that stereo reversal did not affect navigation at a distance from the target, but reversed turning behavior in the target’s immediate vicinity (<xref ref-type="bibr" rid="bib13">Catania, 2013</xref>). These results suggest that stereo cues may be informative near a source, where gradients are steep, but that stereo cues play less of a role at a greater distance from the source where gradients are more shallow. In this more distant condition, serial-sniff comparisons have been hypothesized as a potential sensory computation for odor gradient following <xref ref-type="bibr" rid="bib13">Catania, 2013</xref>. We propose that our task design, in which mice must commit to a side at a distance from the source, forces mice out of the stereo regime and into the serial-sniff comparison regime. Neurons sensitive to sniff-to-sniff odor concentration changes have been observed in the olfactory bulb of head-fixed mice (<xref ref-type="bibr" rid="bib67">Parabucki et al., 2019</xref>), providing a potential physiological mechanism for this sensory computation.</p><p>On the other hand, physiological mechanisms revealed in head-fixed mice may not generalize to the freely moving search condition. The external stimulus obtained by moving the nose through a noisy gradient differs dramatically from the square odor pulses delivered during head-fixed or odor-poke olfactory tasks. Further, the sniff statistics we observe in our mice are qualitatively faster than those reported in head-fixed mice under most conditions (<xref ref-type="bibr" rid="bib12">Bolding and Franks, 2017</xref>; <xref ref-type="bibr" rid="bib79">Shusterman et al., 2011</xref>; <xref ref-type="bibr" rid="bib94">Wesson et al., 2009</xref>). One exception is that mice sniff fast in response to a novel odor (<xref ref-type="bibr" rid="bib94">Wesson et al., 2009</xref>). Such fast stimulation impacts the responsiveness of olfactory sensory neurons (<xref ref-type="bibr" rid="bib21">Esclassan et al., 2012</xref>; <xref ref-type="bibr" rid="bib26">Ghatpande and Reisert, 2011</xref>; <xref ref-type="bibr" rid="bib87">Verhagen et al., 2007</xref>). In addition to the temporal properties of odor transduction, short- and long-term synaptic and network plasticity mechanisms will influence the olfactory bulb’s responses during fast sniffing (<xref ref-type="bibr" rid="bib9">Beshel et al., 2007</xref>; <xref ref-type="bibr" rid="bib18">Díaz-Quesada et al., 2018</xref>; <xref ref-type="bibr" rid="bib35">Gupta et al., 2015</xref>; <xref ref-type="bibr" rid="bib40">Jordan et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Mandairon and Linster, 2009</xref>; <xref ref-type="bibr" rid="bib69">Patterson et al., 2013</xref>; <xref ref-type="bibr" rid="bib100">Zhou et al., 2020</xref>). Without tapping into the fast sniffing regime, the understanding we can gain from head-fixed studies in olfaction will be incomplete at best. In the future, it will be necessary to complement well-controlled reductionist behavioral paradigms with less-controlled, more natural paradigms like ours.</p><p>Mice execute a strategic behavioral program when searching, synchronizing fast sniffing with three-dimensional head movements at a tens of milliseconds timescale. It has long been known that rodents investigate their environment with active sniffing and whisking behaviors (<xref ref-type="bibr" rid="bib44">Kepecs et al., 2006</xref>; <xref ref-type="bibr" rid="bib90">Wachowiak, 2011</xref>; <xref ref-type="bibr" rid="bib93">Welker, 1964</xref>). More recent work has established that under some conditions sniffing locks with whisking, nose twitches, and head movement on a cycle-by-cycle basis (<xref ref-type="bibr" rid="bib48">Kurnikova et al., 2017</xref>; <xref ref-type="bibr" rid="bib61">Moore et al., 2013</xref>; <xref ref-type="bibr" rid="bib76">Ranade et al., 2013</xref>). Sniffing also synchronizes with brain oscillations not only in olfactory regions, but also in hippocampus, amygdala, and neocortex (<xref ref-type="bibr" rid="bib41">Karalis and Sirota, 2018</xref>; <xref ref-type="bibr" rid="bib42">Kay, 2005</xref>; <xref ref-type="bibr" rid="bib53">Macrides et al., 1982</xref>; <xref ref-type="bibr" rid="bib86">Vanderwolf, 1992</xref>; <xref ref-type="bibr" rid="bib96">Yanovsky et al., 2014</xref>; <xref ref-type="bibr" rid="bib99">Zelano et al., 2016</xref>). Respiratory central pattern generators may coordinate sampling movements to synchronize sensory dynamics across modalities with internal brain rhythms (<xref ref-type="bibr" rid="bib47">Kleinfeld et al., 2014</xref>). Further, locomotor and facial movement, which are often synchronized to respiration, drive activity in numerous brain regions, including primary sensory areas (<xref ref-type="bibr" rid="bib59">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib66">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib83">Stringer et al., 2019</xref>). Why are respiration and other movements correlated with activity in seemingly unrelated sensory regions? In the real world, sensory receptors operate in closed loop with movement (<xref ref-type="bibr" rid="bib1">Ahissar and Assa, 2016</xref>; <xref ref-type="bibr" rid="bib28">Gibson, 1966</xref>). Consequently, sensory systems must disambiguate self-induced stimulus dynamics from changes in the environment. Further, active sampling movements can provide access to sensory information that is not otherwise available to a stationary observer (<xref ref-type="bibr" rid="bib27">Gibson, 1962</xref>; <xref ref-type="bibr" rid="bib78">Schroeder et al., 2010</xref>; <xref ref-type="bibr" rid="bib97">Yarbus, 1967</xref>). Widespread movement-related signals may allow the brain to compensate for and capitalize on self-induced stimulus dynamics (<xref ref-type="bibr" rid="bib73">Poulet and Hedwig, 2006</xref>; <xref ref-type="bibr" rid="bib81">Sommer and Wurtz, 2008</xref>; <xref ref-type="bibr" rid="bib82">Sperry, 1950</xref>; <xref ref-type="bibr" rid="bib89">von Holst and Mittelstaedt, 1950</xref>; <xref ref-type="bibr" rid="bib91">Webb, 2004</xref>). Our work advances understanding of how sensation and movement interact during active sensing.</p><p>Rigorously quantifying the behavior of freely moving animals is more feasible than ever, thanks to recent developments in machine vision, deep learning, and probabilistic generative modeling (<xref ref-type="bibr" rid="bib17">Datta et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Gomez-Marin et al., 2014</xref>; <xref ref-type="bibr" rid="bib57">Mathis and Mathis, 2020</xref>), as our work shows. In particular, the motifs we have defined provide a compact description of the behavior, while still capturing the idiosyncrasies of individual mice. Importantly, these motifs can be grouped into two larger-scale behavioral states that we putatively call ‘investigation’ and ‘approach’. Two-state search strategies are common across phylogeny (<xref ref-type="bibr" rid="bib6">Bargmann, 2006</xref>; <xref ref-type="bibr" rid="bib7">Berg, 2000</xref>; <xref ref-type="bibr" rid="bib43">Kennedy and Marsh, 1974</xref>; <xref ref-type="bibr" rid="bib51">Lockery, 2011</xref>; <xref ref-type="bibr" rid="bib85">van Breugel and Dickinson, 2014</xref>; <xref ref-type="bibr" rid="bib88">Vickers and Baker, 1994</xref>). In smaller organisms, state switches have provided a useful behavioral readout for understanding the neural mechanisms of odor-guided behavior (<xref ref-type="bibr" rid="bib11">Bi and Sourjik, 2018</xref>; <xref ref-type="bibr" rid="bib49">Larsch et al., 2015</xref>; <xref ref-type="bibr" rid="bib5">Baker et al., 2018</xref>). Here, we have shown that where switches between investigation and approach occur in allocentric space can reveal the location of informative features in an olfactory scene. The transition points between ‘investigation’ and ‘approach’ serve as a principled template against which to compare neural activity. Our work thus establishes a framework for studying neural mechanisms of active sensing in an unrestrained mammal.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th valign="top">Reagent type (species) or resource</th><th valign="top">Designation</th><th valign="top">Source or reference</th><th valign="top">Identifiers</th><th valign="top">Additional information</th></tr></thead><tbody><tr><td valign="top">Software, algorithm</td><td valign="top">Bonsai</td><td valign="top">Open Ephys <break/><xref ref-type="bibr" rid="bib52">Lopes et al., 2015</xref></td><td valign="top"/><td valign="top">Visual reactive programming</td></tr><tr><td valign="top">Software, algorithm</td><td valign="top">Deeplabcut</td><td valign="top">The Mathis Lab of Adaptive Motor Control <break/><xref ref-type="bibr" rid="bib65">Nath et al., 2019</xref></td><td valign="top"/><td valign="top">Animal pose estimation</td></tr><tr><td valign="top">Software, algorithm</td><td valign="top">Pyhsmm</td><td valign="top">Matthew Johnson,<xref ref-type="bibr" rid="bib37">Johnson et al., 2013a</xref> and <xref ref-type="bibr" rid="bib38">Johnson et al., 2013b</xref></td><td valign="top"/><td valign="top">Bayesian inference in HSMMs and HMMs</td></tr></tbody></table></table-wrap><p>Custom-written task control, analysis, and visualization code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/SmearLab/Freely-moving-olfactory-search">https://github.com/SmearLab/Freely-moving-olfactory-search</ext-link> (<xref ref-type="bibr" rid="bib22">Findley et al., 2021</xref>).</p><sec id="s4-1"><title>Animals: housing and care</title><p>All experimental procedures were approved by the Institutional Animal Care and Use Committee (IACUC) at the University of Oregon and are compliant with the National Institutes of Health Guide to the Care and Use of Laboratory Animals. C57BL/6J mice (2–14 months old) from the Terrestrial Animal Care Services (TeACS) at University of Oregon (19 males, 7 females) were used for behavioral experiments. Mice were housed individually in plastic cages with bedding and running wheels provided by TeACS. Mice were fed standard rodent chow ad libitum and were water-restricted, receiving a daily allotment (1–1.5 mL) of acidified or chlorinated water. Animal health was monitored daily, and mice were taken off water restriction if they met the ‘sick animal’ criteria of a custom IACUC-approved health assessment.</p></sec><sec id="s4-2"><title>Behavioral assay design</title><sec id="s4-2-1"><title>Arena and task structure</title><p>Mice were trained to perform a two-choice behavioral task where they must locate an odor source for a water reward. This 15 × 25 cm behavioral arena was largely custom-designed in lab (all designs available upon request). The behavioral arena contains a custom-designed and 3D-printed honeycomb wall through which continuous clean air is delivered to the arena and a latticed wall opposite to the honeycomb allowing airflow to exit the arena. Two odor tubes (Cole-Parmer Instrument Company, #06605-27) are embedded inside the honeycomb wall and consistently deliver either clean or odorized air. There are three nose pokes in the arena: one trial initiation poke and two reward pokes. The initiation poke is embedded inside the latticed wall (where airflow exits) and is poked to initiate trials. The left and right reward pokes are embedded in the left and right arena walls against the honeycomb airflow delivery and are used for water reward delivery. Mice initiate odor release by entering the initiation poke. If the mouse locates the odor source successfully (by entering the quadrant of the arena containing the correct odor port), water (~6–8 µL) is available at the corresponding nose poke. An ITI of 4 s is then initiated. If the mouse goes to the incorrect side, water is not made available and they must wait an increased ITI of 10 s.</p></sec><sec id="s4-2-2"><title>Odor delivery</title><p>Odor is delivered to the arena using two custom-designed and built olfactometers. For a single olfactometer, air and nitrogen are run through separate mass flow controllers (MFCs) (Alicat Scientific, #MC-100SCCM-RD) that can deliver 1000 mL/min and 100 mL/min at full capacity, respectively. We can use these MFCs to control the percentage of total nitrogen flow (100 mL/min) that runs through liquid odorant. Consequently, we can approximately control the amount of odor molecules in the resulting odorized air stream. Total flow is maintained at 1000 mL/min (e.g., if we are delivering 80 mL/min of nitrogen, we will deliver 920 mL/min of air). Nitrogen MFC output is directed through a manifold (NResearch Incorporated, #225T082) with embedded solenoids that direct flow to one of four possible vials. These vials contain odorant diluted in mineral oil or are empty. To odorize air, nitrogen is directed through a vial containing liquid odorant. The nitrogen aerosolizes the odorant and combines with airflow MFC output at the exit point of the manifold. If nitrogen is directed through an empty vial, unodorized nitrogen will combine with airflow at the exit point. The resulting combined flow of air and nitrogen is then directed to a final valve (NResearch Incorporated, #SH360T042). Odorized air continuously runs to exhaust until this final valve is switched on at which point clean air is directed to exhaust and odorized air to the behavioral assay. Therefore, we can control the percentage of odorized flow (using the MFCs), the presence or absence of odorized flow (using the vials and solenoids), and the flow of odorized air to the assay (using the final valve). There are two olfactometers (one for each odor port), which are calibrated weekly to match outputs using a PID.</p></sec><sec id="s4-2-3"><title>Video-tracking</title><p>We use a Pointgrey Fly Capture Chameleon 3.0 camera (FLIR Integrated Imaging Solutions Inc, #CM3-U3-13Y3C) for video-tracking. We capture frames at 80 Hz at 1200 × 720 pixel resolution. All real-time tracking is executed using a custom Bonsai program. We isolate the mouse’s centroid by gray-scaling a black mouse on a white background and finding the center of the largest object. We track head position by applying red paint on the mouse’s implant between the ears and thresholding the real-time HSV image to identify the center of the largest red shape. We can then identify nose position by calculating the extremes of the long axis of the mouse shape and isolating the extreme in closer proximity to the head point. These three points are sent to Python at 80 Hz for real-time tracking in our assay. We use this real-time tracking to determine successful odor localization; if the mouse enters the quadrant of the arena that contains the correct odor port, it has answered correctly. Bonsai is an open-source computer vision software available online (<xref ref-type="bibr" rid="bib52">Lopes et al., 2015</xref>), and our custom code is available upon request.</p><p>For more rigorous behavioral analysis, we increased our tracking accuracy by using the open-source tracking software Deeplabcut (<xref ref-type="bibr" rid="bib56">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib57">Mathis and Mathis, 2020</xref>). All Deeplabcut tracking occurred offline following experimentation.</p></sec><sec id="s4-2-4"><title>Sniff recordings</title><p>We record sniffing using intranasally implanted thermistors (TE Sensor Solutions, #GAG22K7MCD419; see Materials and methods: Surgical Procedures). These thermistors are attached to pins (Assmann WSW Components, #A-MCK-80030) that can be connected to an overhead commutator (Adafruit, #736) and run through a custom-built amplifier (Texas Instruments, #TLV2460, amplifier circuit design available upon request).</p></sec><sec id="s4-2-5"><title>Software</title><p>All behavioral experiments were run using custom code in Python, Bonsai, and Arduino. Behavioral boards designed at Janelia Research Farms that use Arduino software and hardware were used to control all hardware. Bonsai was used to execute real-time tracking of animals, and Python was used to run the assay, communicate with Arduino and Bonsai, and save data during experiments. All programs used are open source, and all custom code is available upon request.</p></sec></sec><sec id="s4-3"><title>Surgical procedures</title><p>For all surgical procedures, animals were anesthetized with 3% isoflurane; concentration of isoflurane was altered during surgery depending on response of the animal to anesthesia. Incision sites were numbed prior to incision with 20 mg/mL lidocaine.</p><sec id="s4-3-1"><title>Thermistor implantation</title><p>To measure respiration during behavior, thermistors were implanted between the nasal bone and inner nasal epithelium of mice. Following an incision along the midline, a small hole was drilled through the nasal bone to expose the underlying epithelium ~2 mm lateral of the midline in the nasal bone. The glass bead of the thermistor was then partially inserted into the cavity between the nasal bone and the underlying epithelium. Correct implantation resulted in minimal damage to the nasal epithelium. The connector pins were fixed upright against an ~3 cm headbar (custom-designed and 3D printed) placed directly behind the animals’ ears and the thermistor wire was fixed in place using cyanoacrylate. The headbar was secured against a small skull screw (Antrin Minature Specialties, #B002SG89OI) implanted above cerebellum. A second skull screw was placed at the juncture of the nasal bones to secure the anterior portion of the implant. All exposed skull and tissue were secured and sealed using cyanoacrylate. At the end of surgery, a small amount of fluorescent tempera red paint (Pro Art, #4435-2) was applied to the center of the headbar for tracking. Immediately following surgery, animals received 0.1 mg/kg buprenorphine followed by 3 days of 0.03 mg/kg ketoprofen. All but nine mice were implanted prior to training. Mice that were implanted post-training were taken off water restriction at least 2 days prior to surgery and were not placed back on water restriction for at least 1 week following all analgesic administration.</p></sec><sec id="s4-3-2"><title>Naris occlusion</title><p>To test the necessity of stereo olfaction as a sampling strategy, we occluded the nostrils of C57BL/6J mice using 6-0 gauge surgical suture (SurgiPro, #MSUSP5698GMDL). Mice were given 0.03 mg/kg ketoprofen and topical lidocaine on the nostril prior to induction. Suture was either pulled through the upper lip of the nostril and maxillary region to fully occlude the desired nostril or looped at the upper lip of the nostril for a sham stitch. Commercially available VetBond was applied to protect the suture knot. To ensure full occlusion, a small water droplet was placed on the occluded nostril. The absence of bubbles or seepage indicated a successful occlusion. Occlusion was retested in the same manner directly before each experimental session. All stitches were removed within a week of application, and animals were stitched a total of three times per nostril.</p></sec></sec><sec id="s4-4"><title>Behavioral training</title><p>All mice were trained to locate an odor source from one of two possible sources in the olfactory arena. Mice were removed from training and future experiments if they lost sniff signal or did not exceed 50 trials/perform above 60% correct in 15 sessions. The training process was divided into four primary stages.</p><sec id="s4-4-1"><title>Water sampling</title><p>Mice were trained to alternate between the three pokes in the behavioral arena. Water (~5–8 µL) was made available at the nose pokes in the following order: initiation port, left reward port, initiation port, and right reward port (repeat). Mice were trained in this task for 30 min per session until the mouse completed 70 iterations. This took mice 2–9 sessions. Data are only shown for 19 mice because earlier iterations of the system did not save training data.</p></sec><sec id="s4-4-2"><title>Odor association</title><p>Mice were trained in the same sequence as water sampling. However, in odor association, water availability was removed from the initiation poke, and odor was released from whichever side water was available. Therefore, the mouse must initiate water availability by poking the initiation poke and then is further guided to the correct reward port by odor release. This task taught mice to initiate trials using the initiation poke and to associate odor with reward. However, in this step, odor is not required for reward acquisition as the task alternates left and right trials. Mice were trained in this task for 30 min per session until the mouse completed 70 iterations. This took mice 1–5 sessions. Data are only shown for 19 mice because earlier iterations of the system did not save training data.</p></sec><sec id="s4-4-3"><title>100:0</title><p>Mice were given the same task as odor association, but with odor now randomly being released from the left or right odor port following an initiation poke. 10% of these trials were randomly 0:0 condition trials. To correctly answer, animals had to enter the quadrant of the arena (as tracked by the overhead camera) where odor was being released. If they answered correctly, water was made available at the reward port on the corresponding side. If they answered incorrectly, water was not made available and the mouse received an increased ITI. Mice were trained in this task for 40 min per session until they exceeded 80% accuracy, which took 1–4 sessions (<italic>n</italic> = 26).</p></sec><sec id="s4-4-4"><title>80:20</title><p>When trials were initiated in this task, odor was released from both odor ports, but at differing concentrations. The animal had to enter the quadrant containing the odor port releasing the higher concentration. In this case, 80 means that the nitrogen MFC was set to 80 mL/min on one olfactometer (see Materials and methods: behavioral assay). Therefore, one odor port would release roughly 80% of the total possible odorant concentration. If one olfactometer was set to 80, then the other olfactometer would be set to 20 in this condition. 10% of these trials were randomly 0:0 condition. Mice were trained in this task for 40 min per session, taking 1–9 sessions to exceed 60% performance (<italic>n</italic> = 24).</p></sec></sec><sec id="s4-5"><title>Behavioral experiments</title><sec id="s4-5-1"><title>Variable <italic>ΔC</italic>, Constant |<italic>C</italic>|</title><p>This experiment tested how performance and sampling strategy changes with task difficulty. In this experiment, mice performed a two-choice behavioral task where they located an odor source for a water reward at varying concentration differences between the two ports. This experiment interleaved several possible conditions: 100:0 (all odor released from one port or the other), 80:20 (odor is released from both ports at different concentrations: 80% of the total possible airborne concentration and 20% of the total possible airborne concentration), and 60:40 (60% and 40%). Additionally, there was a control condition where all system settings were the same as the 80:20 condition, but nitrogen flow was directed through a clean vial so that the final flow was not odorized. 10% of the total number of trials were the 0:0 condition. Mice ran 40 min experimental sessions and totaled 5–50 sessions (<italic>n</italic> = 19). These experiments were run with 1% liquid dilution of pinene.</p></sec><sec id="s4-5-2"><title>Novel odorant</title><p>This experiment tested how mice generalized our olfactory search task. A subset of mice were run with 1% liquid dilution of vanillin, which, unlike pinene, does not activate the trigeminal system (<italic>n</italic> = 3).</p></sec><sec id="s4-5-3"><title>Constant <italic>ΔC</italic>, Variable |<italic>C</italic>|</title><p>This experiment tested if the animals use a thresholding strategy based on a fixed concentration threshold to solve the localization task. We ran this experiment using air dilution delivering the concentration ratios 90:30 and 30:10 interleaved randomly (<italic>n</italic> = 5). Mice ran 40 min sessions, and we analyzed data from the first session.</p></sec><sec id="s4-5-4"><title>Naris occlusion</title><p>This experiment tested the necessity of stereo olfaction in our localization task. Mice were run in the interleaved experiment (see above) initially. However, after observing no differences between concentration groups, we continued this experiment running mice in the 80:20 and 0:0 conditions only. Mice were run in one of five categories: left occlusion, left sham stitch, right occlusion, right sham stitch, and no stitch (see Materials and methods: surgical procedures). Mice ran 40 min experimental sessions and totaled 5–30 sessions (<italic>n</italic> = 13). Stitches were always removed after 4 days. These experiments were run using 1% pinene dilutions.</p></sec></sec><sec id="s4-6"><title>Mapping the olfactory environment</title><p>We used a PID (Aurora Scientific Inc, #201A) to capture real-time odor concentration at a grid of 7 × 5 sampling locations in the assay. Using vials of 50% liquid dilution of pinene, we captured ~15 two-second trials per sampling point. Odor maps were generated using the average concentration detected across all trials at each location. These maps were smoothed via interpolation across space. Discriminability maps in <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2C, D</xref> were calculated with ROC analysis on the PID data (<xref ref-type="bibr" rid="bib34">Green and Swets, 1966</xref>). To generate the distributions, each 2 s trial was divided into 25 ms chunks (approximately the mean inhalation duration during the task). For each space bin, the mean value of each 25 ms chunk was compiled into a distribution of odor concentration values for right and left trials (the different gradient conditions were pooled for this analysis). To map concentration gradient discriminability, 25 ms samples from each bin were assembled into a pseudosample, such that each sampling position had a concentration value. The gradient angle in each bin of this pseudosample was then calculated (imgradient function in MATLAB) and compiled into a distribution of angles for right and left trials (the different gradient conditions were pooled for this analysis). For both absolute concentration and gradient maps, the area under the ROC curve was calculated for each bin, scaled to between −1 and 1, and absolute valued, and these were assembled into a map and smoothed. Values are thresholded and shown at low bit depth (eight grayscale values) to facilitate perception of where the auROC values are highest.</p></sec><sec id="s4-7"><title>Data analysis</title><p>Analyses of odormaps, sniffing, DLC tracking, and motif sequences were performed in MATLAB. Inhalation and exhalation times were extracted by finding peaks and troughs in the temperature signal after smoothing with a 25 ms moving window. Sniffs with duration less than the 5th percentile and greater than the 95th percentile were excluded from analysis. For alignment of movement with sniffing, tracking and motif sequences were shifted forward in time by 25 ms (two frames), the temporal offset revealed by video calibration (<xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><sec id="s4-7-1"><title><xref ref-type="fig" rid="fig1">Figure 1</xref></title><p>Odormaps were visualized by smoothing the PID sampling grid with a Gaussian and colored using Cubehelix (<xref ref-type="bibr" rid="bib33">Green, 2011</xref>).</p></sec><sec id="s4-7-2"><title><xref ref-type="fig" rid="fig2">Figure 2</xref></title><p>Sessions where mice performed less than 60% correct on 80:20 (90:30 for Constant <italic>ΔC</italic>, Variable <italic>|C|</italic>) were less than 80 trials or had any missing folders or files were excluded. Trials longer than 10 s were excluded. Percent correct was calculated by dividing the correct trials by total trials in a single session and was averaged across all sessions, all mice. Trial duration was measured between nose poke initiation and reward poke and was averaged across all trials, all sessions, all mice. Tortuosity was measured by dividing the total path length by the shortest possible path length and was averaged across all trials, all sessions, all mice.</p><p>Statistical tests were performed in Python using the scipy package (<xref ref-type="bibr" rid="bib70">Peterson et al., 2001</xref>). A binomial test was used to test statistical significance of above-chance performance. Wilcoxon rank-sum tests were used for all group comparisons with pairwise comparisons for more than two groups. Two group comparisons were tested using all trials pooled together, and pairwise comparisons of three groups or more were tested across mice using individual mouse averages.</p></sec><sec id="s4-7-3"><title><xref ref-type="fig" rid="fig3">Figure 3</xref></title><p>Occupancy and sniff rate colormaps were generated by down-sampling the tracking data to a 50 × 30 grid of bins (0.5 cm<sup>2</sup>). Occupancy colormaps are a 2D histogram of the nose position data. Sniff rate histograms were generated by dividing the sniff count in each position bin by the corresponding bin in the occupancy histogram. Both histograms were Gaussian-smoothed and colored using Cubehelix (<xref ref-type="bibr" rid="bib33">Green, 2011</xref>). Grand means are shown in <xref ref-type="fig" rid="fig3">Figure 3F, G</xref>, while individual mouse occupancy heatmaps are shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>. Maps were colored using Cubehelix (<xref ref-type="bibr" rid="bib33">Green, 2011</xref>).</p></sec><sec id="s4-7-4"><title><xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref></title><p>Nose speed, yaw velocity, and Z-velocity were calculated from the three-point position time series generated by Deeplabcut. For analysis, a 400 ms window centered on each inhalation time was extracted from the kinematic time series. Colormaps in <xref ref-type="fig" rid="fig4">Figure 4</xref> show traces surrounding individual sniffs, while colormaps were generated using Bluewhitered (<xref ref-type="bibr" rid="bib14">Childress, 2020</xref>). For within-trial sniffs, only those inhaled before the decision line were included. The ITI sniffs are taken from the time of reward port entry to the time of the first initiation port entry in the ITI. For cross-correlation and coherence analysis, we aligned the time series of sniffing and kinematic parameters from the entire trial or from the interval between reward and initiation port in the ITI. Tracking glitches were excluded by discarding trials or ITIs that contained frames with nose speed above a criterion value (100 pixels per frame).</p></sec><sec id="s4-7-5"><title><xref ref-type="fig" rid="fig6">Figure 6</xref></title><p>Average motif shapes were generated from the mean positions of the nose, head, and body points from the first eight frames of every instance of a given motif as determined by the AR-HMM. Decoding analysis is described in the following section.</p></sec><sec id="s4-7-6"><title><xref ref-type="fig" rid="fig7">Figure 7</xref></title><p>The transition probability matrix was clustered by minimizing Euclidean distance between rows. For analyses separating investigation and approach sniffs, sniffs were defined as investigation or approach sniffs based on the state at the inhalation time. Colors for investigation and approach were selected from the Josef Albers painting, Tautonym, (B) (<xref ref-type="bibr" rid="bib2">Albers and Tautonym, 1944</xref>).</p></sec><sec id="s4-7-7"><title><xref ref-type="fig" rid="fig8">Figure 8</xref></title><p>Figures are generated by motif-onset triggered averages of inhalation times determined as described above. <xref ref-type="fig" rid="fig8">Figure 8B, C</xref> are the grand mean of the motif onset-triggered average for each motif. Maps were colored using Cubehelix (<xref ref-type="bibr" rid="bib33">Green, 2011</xref>). Sniff phase (relative time in sniff) was determined by dividing the motif onset latency from inhalation by the total duration (i.e., inhalation time to inhalation time) of each sniff. Modulation index was calculated as the difference between maximum and minimum instantaneous sniff rate, divided by the sum <inline-formula><mml:math id="inf4"><mml:mfenced separators="|"><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>/</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p></sec><sec id="s4-7-8"><title><xref ref-type="fig" rid="fig9">Figure 9</xref>, <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1</xref>, <xref ref-type="fig" rid="fig10">Figure 10</xref>, <xref ref-type="fig" rid="fig10s1">Figure 10—figure supplement 1</xref></title><p>Investigation and approach occupancy maps were generated by down-sampling the tracking data to a 25 × 15 grid of bins (1 cm<sup>2</sup>). Occupancy maps are a 2D histogram of the nose position data, compiled separately for investigation and approach frames (see below for details of ARHMM analysis). In plots where the data are reoriented with respect to the choice, the lateral axis of all right-choice trials has been flipped so that the trajectories always end on the left side (top side in the displayed occupancy maps). Both histograms were normalized to the total occupancy in a given bin (i.e., investigation + approach), Gaussian-smoothed, and merged and colored using a scheme adapted from fluorescence microscopy (<xref ref-type="bibr" rid="bib25">Geissbuehler and Lasser, 2013</xref>). Grand means (<italic>n</italic> = 9) are shown in <xref ref-type="fig" rid="fig9">Figures 9A, B</xref> and <xref ref-type="fig" rid="fig10">10A</xref>, and S16, while individual mouse mean occupancy maps are shown in <xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1</xref>. I.A.I. is calculated as the difference between investigation and approach occupancies over their sum for a given bin. I.A.I. is taken from histograms that are the projection of the 2D maps onto the longitudinal or lateral axes. The ‘transition zone’ is defined as the region between 5 and 10 cm from the longitudinal axis origin (i.e., the initiation port), and lateral axis histograms are taken from within this region in <xref ref-type="fig" rid="fig10">Figure 10D–F</xref> and <xref ref-type="fig" rid="fig10s1">Figure 10—figure supplement 1</xref>. Correct-incorrect occupancy and index differences are grand mean of the individual mouse differences in <xref ref-type="fig" rid="fig10">Figure 10C, G–I</xref> and <xref ref-type="fig" rid="fig10s1">Figure 10—figure supplement 1</xref>. These differences are evaluated statistically against a null distribution generated by scrambling the correct and incorrect trial labels 1000 times and re-running this analysis. Importantly, these shuffles are performed within mice before taking the post-shuffle grand means, so that these null distributions incorporate both within-mouse and across-mouse variability.</p></sec><sec id="s4-7-9"><title>Sniff synchronization</title><p>Sniff cycles were compared with kinematics to determine the extent of movement modulation at individual sampling points. Individual sniffs were cross-correlated with each kinematic signal (i.e., nose speed) at −200 ms from inhalation onset to +200 ms from inhalation onset. To further determine synchrony between the two signals, we measured the coherence of signal oscillation between sniff signals and individual kinematic measurements at −200 ms from inhalation onset to +200 ms from inhalation onset.</p></sec></sec><sec id="s4-8"><title>Auto-regressive hidden Markov model</title><p>Let <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denote the six-dimensional vector of nose-head-body coordinates at video frame <italic>t</italic> (sampled at 80 Hz), with components <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. We fit an AR-HMM to mouse trajectory data, <inline-formula><mml:math id="inf7"><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:math></inline-formula>, across trials (indexed by <italic>i</italic>) from 13 out of 15 mice (two mice were excluded a priori due to low task performance). These mice performed olfactory search under the following experimental conditions: Variable <italic>ΔC</italic>, Constant <italic>|C|</italic> (nine mice); naris occlusion (seven mice); and Constant <italic>ΔC</italic>, Variable <italic>|C|</italic> experiments (five mice).</p><sec id="s4-8-1"><title>The generative view</title><p>Viewed as a generative model (that generates simulated data), the AR-HMM has two 'layers': a layer of hidden discrete states (corresponding to discrete movement motifs) and an observed layer that is the continuous trajectory <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. We denote the temporal sequence of discrete states by <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. In each time step, <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula>, that is, it is one of an <italic>S</italic> number of states, or movement motifs. The discrete hidden states evolve in time according to a Markov chain: going from time step <italic>t</italic> to <italic>t +</italic> 1, the discrete state may change to another state according to a transition probability matrix <inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula>, which denotes the conditional probability of switching to <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> having started in <inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. The probability distribution over the initial state, <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, of the Markov chain at the start of each trial was taken to be the uniform distribution.</p><p>Now suppose for time steps <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> to <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (inclusive) the discrete layer remained in state <italic>z</italic>. The continuous or auto-regressive (AR) part of the model dictates that, over this time interval, the continuous trajectory, <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, evolves according to a linear AR process. The parameters of this AR process can be different in different states or motifs, <italic>z</italic>. In other words, <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is governed by<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a 6 × 6 matrix and <italic>b</italic> is a 6 × 1 vector, and the noise vector <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is sampled from the multi-variate zero-mean Gaussian distribution <inline-formula><mml:math id="inf21"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a 6 × 6 noise covariance matrix. Moreover, the parameters <inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> depend on the discrete state <italic>z</italic>, and in general are different in different discrete states. The simple stochastic linear dynamics described by <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> can describe simple motions of the mouse, such as turning left/right, dashing towards a certain direction, freezing (when <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the identity matrix and <inline-formula><mml:math id="inf27"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is zero), etc. The switches between these simple behaviors allow the model to generate complex trajectories.</p><p>The AR-HMM is an example of a model with latent variables, which in this case are the discrete state sequence <inline-formula><mml:math id="inf28"><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> in each trial. The model, as a whole, is specified by the set of parameters (<inline-formula><mml:math id="inf29"><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula>), which we will denote by <inline-formula><mml:math id="inf30"><mml:mi>θ</mml:mi></mml:math></inline-formula>. For a <italic>d</italic>-dimensional trajectory (<italic>d</italic> = 6 here) and <italic>S</italic> states, comprises <inline-formula><mml:math id="inf31"><mml:mi>S</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>S</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>S</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mi>d</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> parameters.</p></sec><sec id="s4-8-2"><title>Model fits</title><p>Models with latent variables are often fit using the expectation-maximization (EM) algorithm, which maximizes the likelihood of the model in terms of the parameters <inline-formula><mml:math id="inf32"><mml:mi>θ</mml:mi><mml:mo>≡</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> for a given set of observed data <inline-formula><mml:math id="inf33"><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:math></inline-formula>. In this work, we did not use the EM algorithm, but adopted a fully Bayesian approach in which both the hidden variables and the model parameters were inferred by drawing samples from their posterior distribution (<xref ref-type="bibr" rid="bib95">Wiltschko et al., 2015</xref>). The posterior distribution combines the model likelihood and Bayesian priors imposed on its parameters, according to Bayes' rule. If we denote the joint likelihood of observed trajectories, <inline-formula><mml:math id="inf34"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:math></inline-formula>, and the latent variables, <inline-formula><mml:math id="inf35"><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:math></inline-formula>, by <inline-formula><mml:math id="inf36"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> and the prior distribution over model parameters by <inline-formula><mml:math id="inf37"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, then up to normalization, the joint posterior distribution of latent variables and model parameters is given by<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:mfenced><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>{</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>For the AR-HMM, the (logarithm of the) joint log-likelihood is given by<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>]</mml:mo><mml:mo>.</mml:mo></mml:math></disp-formula>where <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the length of trial <italic>i</italic>, and we use the notation <inline-formula><mml:math id="inf39"><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:msqrt><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:mfenced></mml:msqrt></mml:math></inline-formula> to denote the density at point <italic>x</italic> of a multivariate Gaussian with mean vector μ and covariance matrix <italic>Q</italic>.</p><p>We imposed loose conjugate priors on the model parameters, which were factorized over the parameters of the AR process, <inline-formula><mml:math id="inf40"><mml:mfenced separators="|"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula>, in different discrete states <italic>z</italic>, and the different rows of the Markov transition matrix, <inline-formula><mml:math id="inf41"><mml:mi>π</mml:mi></mml:math></inline-formula>. On the rows of <inline-formula><mml:math id="inf42"><mml:mi>π</mml:mi></mml:math></inline-formula>, we imposed Dirichlet distribution priors with uniform distribution means and concentration hyperparameter <inline-formula><mml:math id="inf43"><mml:mi>α</mml:mi></mml:math></inline-formula>, which was set to 4. We imposed matrix normal inverse Wishart priors on the AR parameters, independently for different discrete states. Under this prior, the noise covariance <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> has an inverse Wishart distribution with a 'scale matrix' hyperparameter, which was set to the <italic>d</italic> × <italic>d</italic> ( = 6 × 6) identity matrix, and a 'degrees-of-freedom' scalar hyperparameter set to <italic>d</italic> + 2 = 8. Conditional on <inline-formula><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the remaining AR parameters, <inline-formula><mml:math id="inf46"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, have a joint multivariate normal distribution under the prior, which can be specified by the prior mean and joint prior covariance matrix of <inline-formula><mml:math id="inf47"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The prior means of <inline-formula><mml:math id="inf49"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf50"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were set to the <italic>d</italic> × <italic>d</italic> identity matrix and the <italic>d</italic>-dimensional zero vector, respectively, while the prior covariance matrix of the concatenation <inline-formula><mml:math id="inf51"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> was given by the tensor product of <inline-formula><mml:math id="inf52"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and the (<italic>d</italic> + 1) × (<italic>d</italic> + 1)( = 7 × 7) identity matrix (equivalently, under this prior, <inline-formula><mml:math id="inf53"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and different columns of <inline-formula><mml:math id="inf54"><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are independent and uncorrelated, while each of these column vectors has a prior covariance equal to the [prior] AR noise covariance, <inline-formula><mml:math id="inf55"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>).</p><p>Bayesian model inference was carried out by sampling from (instead of maximizing) the joint posterior distribution of the model parameters and latent state variables conditioned on the observed trajectory data (<xref ref-type="disp-formula" rid="equ2">Equation 2)</xref>. We did this by Gibbs sampling (an example of Markov chain Monte Carlo; not to be confused with the Markov chain in the AR-HMM), which works in a manner conceptually similar to the EM algorithm: it switches between sampling <inline-formula><mml:math id="inf56"><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> in all trials, conditioned on previously sampled parameters, and then sampling the parameters <inline-formula><mml:math id="inf57"><mml:mi>θ</mml:mi></mml:math></inline-formula> given the previous sample of <inline-formula><mml:math id="inf58"><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:math></inline-formula>. To carry out this model inference procedure, we used the Python package developed by M.J. Johnson and colleagues, publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/mattjj/pyhsmm">https://github.com/mattjj/pyhsmm</ext-link> (<xref ref-type="bibr" rid="bib37">Johnson et al., 2013a</xref>).</p><p>We ran the Gibbs sampler for 300 iterations and burned the first 200 samples, retaining 100. We used the remaining samples to obtain the posterior probabilities of hidden discrete states at each time step of each trial (by calculating the frequency of different state in that time step and trial, across the retained Gibbs samples), as well as posterior expectation of the model parameters (by calculating their averages over the retained Gibbs samples). We refer to the AR-HMM with parameters given by these latter posterior expectations as the ‘fit model’.</p></sec><sec id="s4-8-3"><title>Model selection</title><p>We fit AR-HMM's with different numbers of states (motifs), <italic>S</italic>, to mouse trajectory data pooled across animals. To evaluate the statistical goodness of fit of these fit model and select the best <italic>S</italic> (the number of states or motifs), we evaluated the log-likelihoods of fit models on trajectory data from a held-out set of trials, not used for model fitting. The corresponding plot of log-likelihoods is shown in <xref ref-type="fig" rid="fig6">Figure 6F</xref>. As seen, the log-likelihood keeps increasing with <italic>S</italic>, up to <italic>S</italic> = 100. This shows that, up to at least <italic>S</italic> = 100, additional motifs do have utility in capturing more variability in mouse trajectories. These variabilities may include differences in movement across mice, as well as movement variations in the same mouse but across different trials or different instances of the same movement; for example, a clockwise head turn executed with different speeds in different instances or trials. In the AR-HMM, the AR observation distribution of a given Markov state corresponds to a very simple (linear) dynamical system that cannot capture many natural and continuous variations in movement, such as changes in movement speed. Nevertheless, AR-HMM models with higher <italic>S</italic> can capture such variations with more precision by specializing different discrete Markov states, with different AR distributions, to movement motifs of different mice, or, for example, to capture different speeds of the same qualitative movement motif.</p><p>The goal for this modeling was to give a compact description of recurring movement features across animals and conditions, suitable for visualization and alignment. For these purposes, the goodness of fit did not provide a suitable criterion because the log-likelihood plots did not peak or plateau even at very large numbers of states. Guided by visual inspection, we thus chose the model with <italic>S</italic> = 16 for the main figures (<xref ref-type="fig" rid="fig6">Figures 6</xref>–<xref ref-type="fig" rid="fig8">8</xref>). Although this was a somewhat arbitrary choice, we show that the findings in <xref ref-type="fig" rid="fig6">Figures 6</xref>–<xref ref-type="fig" rid="fig8">8</xref> do not depend on the choice of <italic>S</italic> – models with <italic>S</italic> = 6, 10, or 20 gave equivalent results (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplements 2</xref>–<xref ref-type="fig" rid="fig6s4">4</xref>).</p></sec><sec id="s4-8-4"><title>MAP sequences</title><p>The Gibbs sampling algorithm that we used for model inference yields (time-wise marginal) maximum a posteriori (MAP) estimates of the latent variables <inline-formula><mml:math id="inf59"><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:math></inline-formula>, as follows. Using the Gibbs samples for the latent variables, we can estimate the posterior probability of the mouse being in any of the <italic>S</italic> states in any given time step of a given trial. We made MAP sequences by picking, at any time step and trial, the state with the highest posterior probability. The inferred MAP motifs tended to have high posterior probability, which exceeded 0.8 in 66.2% of all time steps across the 17,195 trials in the modeled dataset.</p></sec></sec><sec id="s4-9"><title>Decoding analysis</title><p>We decoded experimental conditions and animal identities from single-trial MAP motif sequences inferred using the AR-HMM. Specifically, we trained multi-class decoders with linear decision boundaries (linear discriminant analysis) to decode the above categorical variables from the single-trial empirical state transition probability matrices derived from the MAP sequence of each trial. If <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the motif MAP sequence for trial <italic>i</italic>, the empirical transition probability, <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:msubsup><mml:mi>π</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, from state <italic>a</italic> to state <inline-formula><mml:math id="inf62"><mml:mi>b</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula>, for that trial was calculated by<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:msubsup><mml:mi>π</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>≡</mml:mo><mml:mfrac><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>≡</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mtext>1</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf63"><mml:msup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:math></inline-formula> is the length of trial <italic>i</italic>, and <inline-formula><mml:math id="inf64"><mml:mi>I</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is an indicator function, returning 1 or 0 when its argument is true or false, respectively.</p><p>We used the decoder to either classify experimental condition or mouse identity, in different trials (<xref ref-type="fig" rid="fig6">Figure 6D, E</xref>). For decoders trained to classify the trials' experimental condition, we used pooled data across mice. For decoders trained to classify mouse identity, we only used data from the 80:20 odor condition. Data was split into training and test dataset in a stratified fivefold cross-validation manner, ensuring equal proportions of trials of different types in both datasets. The trial type was the combination of left vs. right decision, experimental condition, and mouse identity.</p><p>To calculate the statistical significance of decoding accuracies, we performed an iterative shuffle procedure on each fold of the cross-validation. In each shuffle, the training labels that the classifier was trained to decode were shuffled randomly across trials of the training set, and the classifier's accuracy was evaluated on the unshuffled test dataset. This shuffle was performed 100 times to create a shuffle distribution of decoding accuracies for each fold of the cross-validation. From these distributions, we calculated the z-score of decoding accuracy for each class in each cross-validation fold. These z-scores were then averaged across the folds of cross-validation and used to calculate the overall p-value of the decoding accuracy obtained on the original data.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Z Mainen for initiating this area of research with MS and for advising on interpretation of behavioral results, B Datta for advising on AR-HMM analysis, L Mazzucato for advice on the decoding analysis, S Shoham for advising on allocentric analyses, and P Gupta for suggesting behavioral experiments. We thank A Singh Bala, C Niell, S Lockery, M Wehr, and B Datta for helpful comments on the manuscript. MS was supported by grants from the NIH (R56DC015584, R21NS104935, and R34NS116731), the Whitehall Foundation, and start-up funds from the University of Oregon. TF was supported by an NIH fellowship (F31DC016799). MB was supported by an NIH fellowship (F32MH118724). DW and YA were supported by start-up funds from the University of Oregon.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Investigation, Methodology</p></fn><fn fn-type="con" id="con4"><p>Resources, Software, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Investigation, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con6"><p>Software, Formal analysis, Investigation, Methodology</p></fn><fn fn-type="con" id="con7"><p>Investigation</p></fn><fn fn-type="con" id="con8"><p>Investigation</p></fn><fn fn-type="con" id="con9"><p>Investigation</p></fn><fn fn-type="con" id="con10"><p>Investigation</p></fn><fn fn-type="con" id="con11"><p>Supervision, Investigation</p></fn><fn fn-type="con" id="con12"><p>Supervision, Investigation</p></fn><fn fn-type="con" id="con13"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con14"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocols (AUP-17-23) of the University of Oregon. All surgery was performed under sodium isofluorane anesthesia, and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-58523-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Source code is available on github at <ext-link ext-link-type="uri" xlink:href="https://github.com/Smear-Lab/Olfactory_Search">https://github.com/Smear-Lab/Olfactory_Search</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:fcb2c2aa1a4438f22d622f29b01a0c64e8e4df85">https://archive.softwareheritage.org/swh:1:rev:fcb2c2aa1a4438f22d622f29b01a0c64e8e4df85</ext-link>), and source data files are uploaded to Dryad.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Smear</surname><given-names>M</given-names></name><name><surname>Findley</surname><given-names>T</given-names></name><name><surname>Wyrick</surname><given-names>D</given-names></name><name><surname>Ahmadian</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Sniff-synchronized, gradient-guided olfactory search by freely-moving mice</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.r7sqv9sc0</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname> <given-names>E</given-names></name><name><surname>Assa</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Perception as a closed-loop convergence process</article-title><source>eLife</source><volume>5</volume><elocation-id>e12830</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12830</pub-id><pub-id pub-id-type="pmid">27159238</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Albers</surname> <given-names>J</given-names></name><name><surname>Tautonym</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1944">1944</year><source>The Josef and Anni Albers Foundation</source><publisher-loc>New York</publisher-loc><publisher-name>Artists Rights Society (ARS)</publisher-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Álvarez-Salvado</surname> <given-names>E</given-names></name><name><surname>Licata</surname> <given-names>AM</given-names></name><name><surname>Connor</surname> <given-names>EG</given-names></name><name><surname>McHugh</surname> <given-names>MK</given-names></name><name><surname>King</surname> <given-names>BMN</given-names></name><name><surname>Stavropoulos</surname> <given-names>N</given-names></name><name><surname>Victor</surname> <given-names>JD</given-names></name><name><surname>Crimaldi</surname> <given-names>JP</given-names></name><name><surname>Nagel</surname> <given-names>KI</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Elementary sensory-motor transformations underlying olfactory navigation in walking fruit-flies</article-title><source>eLife</source><volume>7</volume><elocation-id>e04577</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.37815</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname> <given-names>RA</given-names></name><name><surname>Mountcastle</surname> <given-names>VB</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The influence of the angle of gaze upon the excitability of the light-sensitive neurons of the posterior parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>3</volume><fpage>532</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.03-03-00532.1983</pub-id><pub-id pub-id-type="pmid">6827308</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname> <given-names>KL</given-names></name><name><surname>Dickinson</surname> <given-names>M</given-names></name><name><surname>Findley</surname> <given-names>TM</given-names></name><name><surname>Gire</surname> <given-names>DH</given-names></name><name><surname>Louis</surname> <given-names>M</given-names></name><name><surname>Suver</surname> <given-names>MP</given-names></name><name><surname>Verhagen</surname> <given-names>JV</given-names></name><name><surname>Nagel</surname> <given-names>KI</given-names></name><name><surname>Smear</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Algorithms for olfactory search across species</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>9383</fpage><lpage>9389</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1668-18.2018</pub-id><pub-id pub-id-type="pmid">30381430</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bargmann</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Comparative chemosensation from receptors to ecology</article-title><source>Nature</source><volume>444</volume><fpage>295</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1038/nature05402</pub-id><pub-id pub-id-type="pmid">17108953</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berg</surname> <given-names>HC</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Motile behavior of bacteria</article-title><source>Physics Today</source><volume>53</volume><fpage>24</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1063/1.882934</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname> <given-names>GJ</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Predictability and hierarchy in <italic>Drosophila</italic> behavior</article-title><source>PNAS</source><volume>113</volume><fpage>11943</fpage><lpage>11948</lpage><pub-id pub-id-type="doi">10.1073/pnas.1607601113</pub-id><pub-id pub-id-type="pmid">27702892</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beshel</surname> <given-names>J</given-names></name><name><surname>Kopell</surname> <given-names>N</given-names></name><name><surname>Kay</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Olfactory bulb gamma oscillations are enhanced with task demands</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>8358</fpage><lpage>8365</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1199-07.2007</pub-id><pub-id pub-id-type="pmid">17670982</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhattacharyya</surname> <given-names>U</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Robust and rapid Air-Borne odor tracking without casting</article-title><source>Eneuro</source><volume>2</volume><fpage>ENEURO.0102-15.2015</fpage><lpage>.0102-15.2026</lpage><pub-id pub-id-type="doi">10.1523/ENEURO.0102-15.2015</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bi</surname> <given-names>S</given-names></name><name><surname>Sourjik</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Stimulus sensing and signal processing in bacterial chemotaxis</article-title><source>Current Opinion in Microbiology</source><volume>45</volume><fpage>22</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.mib.2018.02.002</pub-id><pub-id pub-id-type="pmid">29459288</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolding</surname> <given-names>KA</given-names></name><name><surname>Franks</surname> <given-names>KM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Complementary codes for odor identity and intensity in olfactory cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e22630</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.22630</pub-id><pub-id pub-id-type="pmid">28379135</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Catania</surname> <given-names>KC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Stereo and serial sniffing guide navigation to an odour source in a mammal</article-title><source>Nature Communications</source><volume>4</volume><fpage>1441</fpage><lpage>1448</lpage><pub-id pub-id-type="doi">10.1038/ncomms2444</pub-id><pub-id pub-id-type="pmid">23385586</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Childress</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Bluewhitered</data-title><source>MATLAB Central File Exchange</source><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/matlabcentral/fileexchange/">https://www.mathworks.com/matlabcentral/fileexchange/</ext-link></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cometto-Muñiz</surname> <given-names>JE</given-names></name><name><surname>Abraham</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Odor detection by humans of lineal aliphatic aldehydes and helional as gauged by dose-response functions</article-title><source>Chemical Senses</source><volume>35</volume><fpage>289</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1093/chemse/bjq018</pub-id><pub-id pub-id-type="pmid">20190010</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crimaldi</surname> <given-names>JP</given-names></name><name><surname>Wiley</surname> <given-names>MB</given-names></name><name><surname>Koseff</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The relationship between mean and instantaneous structure in turbulent passive scalar plumes</article-title><source>Journal of Turbulence</source><volume>3</volume><elocation-id>N14</elocation-id><pub-id pub-id-type="doi">10.1088/1468-5248/3/1/014</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname> <given-names>SR</given-names></name><name><surname>Anderson</surname> <given-names>DJ</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name><name><surname>Perona</surname> <given-names>P</given-names></name><name><surname>Leifer</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational neuroethology: a call to action</article-title><source>Neuron</source><volume>104</volume><fpage>11</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.038</pub-id><pub-id pub-id-type="pmid">31600508</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Díaz-Quesada</surname> <given-names>M</given-names></name><name><surname>Youngstrom</surname> <given-names>IA</given-names></name><name><surname>Tsuno</surname> <given-names>Y</given-names></name><name><surname>Hansen</surname> <given-names>KR</given-names></name><name><surname>Economo</surname> <given-names>MN</given-names></name><name><surname>Wachowiak</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inhalation frequency controls reformatting of mitral/Tufted cell odor representations in the olfactory bulb</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>2189</fpage><lpage>2206</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0714-17.2018</pub-id><pub-id pub-id-type="pmid">29374137</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doty</surname> <given-names>RL</given-names></name><name><surname>Brugger</surname> <given-names>WE</given-names></name><name><surname>Jurs</surname> <given-names>PC</given-names></name><name><surname>Orndorff</surname> <given-names>MA</given-names></name><name><surname>Snyder</surname> <given-names>PJ</given-names></name><name><surname>Lowry</surname> <given-names>LD</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Intranasal trigeminal stimulation from odorous volatiles: psychometric responses from anosmic and normal humans</article-title><source>Physiology &amp; Behavior</source><volume>20</volume><fpage>175</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1016/0031-9384(78)90070-7</pub-id><pub-id pub-id-type="pmid">662939</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duhamel</surname> <given-names>JR</given-names></name><name><surname>Colby</surname> <given-names>CL</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The updating of the representation of visual space in parietal cortex by intended eye movements</article-title><source>Science</source><volume>255</volume><fpage>90</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1126/science.1553535</pub-id><pub-id pub-id-type="pmid">1553535</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esclassan</surname> <given-names>F</given-names></name><name><surname>Courtiol</surname> <given-names>E</given-names></name><name><surname>Thévenet</surname> <given-names>M</given-names></name><name><surname>Garcia</surname> <given-names>S</given-names></name><name><surname>Buonviso</surname> <given-names>N</given-names></name><name><surname>Litaudon</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Faster, deeper, better: the impact of sniffing modulation on bulbar olfactory processing</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e40927</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0040927</pub-id><pub-id pub-id-type="pmid">22815871</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Findley</surname> <given-names>T</given-names></name><name><surname>Wyrick</surname> <given-names>D</given-names></name><name><surname>Smear</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><source>Freely Moving Olfactory Search</source><ext-link ext-link-type="uri" xlink:href="https://github.com/SmearLab/Freely-moving-olfactory-search">https://github.com/SmearLab/Freely-moving-olfactory-search</ext-link></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonseca</surname> <given-names>MS</given-names></name><name><surname>Murakami</surname> <given-names>M</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Activation of dorsal raphe serotonergic neurons promotes waiting but is not reinforcing</article-title><source>Current Biology</source><volume>25</volume><fpage>306</fpage><lpage>315</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.12.002</pub-id><pub-id pub-id-type="pmid">25601545</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gallistel</surname> <given-names>CR</given-names></name></person-group><year iso-8601-date="1982">1982</year><source>The Organization of Action: A New Synthesis</source><publisher-loc>Abingdon, United Kingdom</publisher-loc><publisher-name>Taylor &amp; francis group</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissbuehler</surname> <given-names>M</given-names></name><name><surname>Lasser</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How to display data by color schemes compatible with red-green color perception deficiencies</article-title><source>Optics Express</source><volume>21</volume><fpage>9862</fpage><lpage>9874</lpage><pub-id pub-id-type="doi">10.1364/OE.21.009862</pub-id><pub-id pub-id-type="pmid">23609692</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghatpande</surname> <given-names>AS</given-names></name><name><surname>Reisert</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Olfactory receptor neuron responses coding for rapid odour sampling</article-title><source>The Journal of Physiology</source><volume>589</volume><fpage>2261</fpage><lpage>2273</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2010.203687</pub-id><pub-id pub-id-type="pmid">21486768</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibson</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Observations on active touch</article-title><source>Psychological Review</source><volume>69</volume><fpage>477</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1037/h0046962</pub-id><pub-id pub-id-type="pmid">13947730</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gibson</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>The Senses Considered as Perceptual Systems</source><publisher-loc>Massachusetts, United States</publisher-loc><publisher-name>Houghton Mifflin</publisher-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gire</surname> <given-names>DH</given-names></name><name><surname>Kapoor</surname> <given-names>V</given-names></name><name><surname>Arrighi-Allisan</surname> <given-names>A</given-names></name><name><surname>Seminara</surname> <given-names>A</given-names></name><name><surname>Murthy</surname> <given-names>VN</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mice develop efficient strategies for foraging and navigation using complex natural stimuli</article-title><source>Current Biology</source><volume>26</volume><fpage>1261</fpage><lpage>1273</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.03.040</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Stephens</surname> <given-names>GJ</given-names></name><name><surname>Louis</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Active sampling and decision making in <italic>Drosophila</italic> chemotaxis</article-title><source>Nature Communications</source><volume>2</volume><elocation-id>441</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1455</pub-id><pub-id pub-id-type="pmid">21863008</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Kampff</surname> <given-names>AR</given-names></name><name><surname>Costa</surname> <given-names>RM</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Big behavioral data: psychology, ethology and the foundations of neuroscience</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1455</fpage><lpage>1462</lpage><pub-id pub-id-type="doi">10.1038/nn.3812</pub-id><pub-id pub-id-type="pmid">25349912</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Louis</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Active sensation during orientation behavior in the <italic>Drosophila</italic> larva: more sense than luck</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>208</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2011.11.008</pub-id><pub-id pub-id-type="pmid">22169055</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A colour scheme for the display of astronomical intensity images</article-title><source>Bulletin of the Astronomical Society of India</source><volume>39</volume><fpage>289</fpage><lpage>295</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname> <given-names>DM</given-names></name><name><surname>Swets</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-loc>Amsterdam, Netherlands</publisher-loc><publisher-name>Elsevier</publisher-name></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname> <given-names>P</given-names></name><name><surname>Albeanu</surname> <given-names>DF</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Olfactory bulb coding of odors, mixtures and sniffs is a linear sum of odor time profiles</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>272</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1038/nn.3913</pub-id><pub-id pub-id-type="pmid">25581362</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hummel</surname> <given-names>T</given-names></name><name><surname>Iannilli</surname> <given-names>E</given-names></name><name><surname>Frasnelli</surname> <given-names>J</given-names></name><name><surname>Boyle</surname> <given-names>J</given-names></name><name><surname>Gerber</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Central processing of trigeminal activation in humans</article-title><source>Annals of the New York Academy of Sciences</source><volume>1170</volume><fpage>190</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2009.03910.x</pub-id><pub-id pub-id-type="pmid">19686136</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Johnson</surname> <given-names>M</given-names></name><name><surname>Wiltschko</surname> <given-names>A</given-names></name><name><surname>Katz</surname> <given-names>Y</given-names></name><name><surname>Chia-Ying (Jackie) Lee</surname></name><name><surname>Linderman</surname> <given-names>S</given-names></name><name><surname>Squire</surname> <given-names>K</given-names></name><name><surname>Foti</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013a</year><source>Pyhsmm</source><ext-link ext-link-type="uri" xlink:href="https://github.com/mattjj/pyhsmm">https://github.com/mattjj/pyhsmm</ext-link></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname> <given-names>MJ</given-names></name><name><surname>Willsky</surname> <given-names>AS</given-names></name><name><surname>Alan</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Bayesian nonparametric hidden Semi-Markov models</article-title><source>Journal of Machine Learning Research</source><volume>14</volume><fpage>673</fpage><lpage>701</lpage></element-citation></ref><ref id="bib39"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>PW</given-names></name><name><surname>Urban</surname> <given-names>NN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mice follow odor trails using stereo olfactory cues and rapid sniff to sniff comparisons</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/293746</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname> <given-names>R</given-names></name><name><surname>Kollo</surname> <given-names>M</given-names></name><name><surname>Schaefer</surname> <given-names>AT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Sniffing fast: paradoxical effects on odor concentration discrimination at the levels of olfactory bulb output and behavior</article-title><source>Eneuro</source><volume>5</volume><elocation-id>ENEURO.0148-18.2018</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0148-18.2018</pub-id><pub-id pub-id-type="pmid">30596145</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karalis</surname> <given-names>N</given-names></name><name><surname>Sirota</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Breathing coordinates limbic network dynamics underlying memory consolidation</article-title><source>SSRN Electronic Journal</source><volume>18</volume><elocation-id>11</elocation-id><pub-id pub-id-type="doi">10.2139/ssrn.3283711</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Theta oscillations and sensorimotor performance</article-title><source>PNAS</source><volume>102</volume><fpage>3863</fpage><lpage>3868</lpage><pub-id pub-id-type="doi">10.1073/pnas.0407920102</pub-id><pub-id pub-id-type="pmid">15738424</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kennedy</surname> <given-names>JS</given-names></name><name><surname>Marsh</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Pheromone-regulated anemotaxis in flying moths</article-title><source>Science</source><volume>184</volume><fpage>999</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1126/science.184.4140.999</pub-id><pub-id pub-id-type="pmid">4826172</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname> <given-names>A</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The sniff as a unit of olfactory processing</article-title><source>Chemical Senses</source><volume>31</volume><fpage>167</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1093/chemse/bjj016</pub-id><pub-id pub-id-type="pmid">16339265</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khan</surname> <given-names>AG</given-names></name><name><surname>Sarangi</surname> <given-names>M</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rats track odour trails accurately using a multi-layered strategy with near-optimal sampling</article-title><source>Nature Communications</source><volume>3</volume><elocation-id>703</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1712</pub-id><pub-id pub-id-type="pmid">22426224</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleinfeld</surname> <given-names>D</given-names></name><name><surname>Ahissar</surname> <given-names>E</given-names></name><name><surname>Diamond</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Active sensation: insights from the rodent vibrissa sensorimotor system</article-title><source>Current Opinion in Neurobiology</source><volume>16</volume><fpage>435</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2006.06.009</pub-id><pub-id pub-id-type="pmid">16837190</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleinfeld</surname> <given-names>D</given-names></name><name><surname>Deschênes</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>F</given-names></name><name><surname>Moore</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>More than a rhythm of life: breathing as a binder of orofacial sensation</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>647</fpage><lpage>651</lpage><pub-id pub-id-type="doi">10.1038/nn.3693</pub-id><pub-id pub-id-type="pmid">24762718</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurnikova</surname> <given-names>A</given-names></name><name><surname>Moore</surname> <given-names>JD</given-names></name><name><surname>Liao</surname> <given-names>SM</given-names></name><name><surname>Deschênes</surname> <given-names>M</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Coordination of orofacial motor actions into exploratory behavior by rat</article-title><source>Current Biology</source><volume>27</volume><fpage>688</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.01.013</pub-id><pub-id pub-id-type="pmid">28216320</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsch</surname> <given-names>J</given-names></name><name><surname>Flavell</surname> <given-names>SW</given-names></name><name><surname>Liu</surname> <given-names>Q</given-names></name><name><surname>Gordus</surname> <given-names>A</given-names></name><name><surname>Albrecht</surname> <given-names>DR</given-names></name><name><surname>Bargmann</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A circuit for gradient climbing in <italic>C. elegans</italic> chemotaxis</article-title><source>Cell Reports</source><volume>12</volume><fpage>1748</fpage><lpage>1760</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2015.08.032</pub-id><pub-id pub-id-type="pmid">26365196</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>A</given-names></name><name><surname>Papale</surname> <given-names>AE</given-names></name><name><surname>Hengenius</surname> <given-names>J</given-names></name><name><surname>Patel</surname> <given-names>K</given-names></name><name><surname>Ermentrout</surname> <given-names>B</given-names></name><name><surname>Urban</surname> <given-names>NN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Mouse navigation strategies for odor source localization</article-title><source>Frontiers in Neuroscience</source><volume>14</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.3389/fnins.2020.00218</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lockery</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The computational worm: spatial orientation and its neuronal basis in <italic>C. elegans</italic></article-title><source>Current Opinion in Neurobiology</source><volume>21</volume><fpage>782</fpage><lpage>790</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2011.06.009</pub-id><pub-id pub-id-type="pmid">21764577</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lopes</surname> <given-names>G</given-names></name><name><surname>Bonacchi</surname> <given-names>N</given-names></name><name><surname>Frazão</surname> <given-names>J</given-names></name><name><surname>Neto</surname> <given-names>JP</given-names></name><name><surname>Atallah</surname> <given-names>BV</given-names></name><name><surname>Soares</surname> <given-names>S</given-names></name><name><surname>Moreira</surname> <given-names>L</given-names></name><name><surname>Matias</surname> <given-names>S</given-names></name><name><surname>Itskov</surname> <given-names>PM</given-names></name><name><surname>Correia</surname> <given-names>PA</given-names></name><name><surname>Medina</surname> <given-names>RE</given-names></name><name><surname>Calcaterra</surname> <given-names>L</given-names></name><name><surname>Dreosti</surname> <given-names>E</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Kampff</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Bonsai: an event-based framework for processing and controlling data streams</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00007</pub-id><pub-id pub-id-type="pmid">25904861</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macrides</surname> <given-names>F</given-names></name><name><surname>Eichenbaum</surname> <given-names>HB</given-names></name><name><surname>Forbes</surname> <given-names>WB</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Temporal relationship between sniffing and the limbic theta rhythm during odor discrimination reversal learning</article-title><source>The Journal of Neuroscience</source><volume>2</volume><fpage>1705</fpage><lpage>1717</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.02-12-01705.1982</pub-id><pub-id pub-id-type="pmid">7143047</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mandairon</surname> <given-names>N</given-names></name><name><surname>Linster</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Odor perception and olfactory bulb plasticity in adult mammals</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>2204</fpage><lpage>2209</lpage><pub-id pub-id-type="doi">10.1152/jn.00076.2009</pub-id><pub-id pub-id-type="pmid">19261715</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markowitz</surname> <given-names>JE</given-names></name><name><surname>Gillis</surname> <given-names>WF</given-names></name><name><surname>Beron</surname> <given-names>CC</given-names></name><name><surname>Neufeld</surname> <given-names>SQ</given-names></name><name><surname>Robertson</surname> <given-names>K</given-names></name><name><surname>Bhagat</surname> <given-names>ND</given-names></name><name><surname>Peterson</surname> <given-names>RE</given-names></name><name><surname>Peterson</surname> <given-names>E</given-names></name><name><surname>Hyun</surname> <given-names>M</given-names></name><name><surname>Linderman</surname> <given-names>SW</given-names></name><name><surname>Sabatini</surname> <given-names>BL</given-names></name><name><surname>Datta</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The striatum organizes 3D behavior via Moment-to-Moment action selection</article-title><source>Cell</source><volume>174</volume><fpage>44</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.04.019</pub-id><pub-id pub-id-type="pmid">29779950</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Mamidanna</surname> <given-names>P</given-names></name><name><surname>Cury</surname> <given-names>KM</given-names></name><name><surname>Abe</surname> <given-names>T</given-names></name><name><surname>Murthy</surname> <given-names>VN</given-names></name><name><surname>Mathis</surname> <given-names>MW</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname> <given-names>MW</given-names></name><name><surname>Mathis</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Deep learning tools for the measurement of animal behavior in neuroscience</article-title><source>Current Opinion in Neurobiology</source><volume>60</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.10.008</pub-id><pub-id pub-id-type="pmid">31791006</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAfee</surname> <given-names>SS</given-names></name><name><surname>Ogg</surname> <given-names>MC</given-names></name><name><surname>Ross</surname> <given-names>JM</given-names></name><name><surname>Liu</surname> <given-names>Y</given-names></name><name><surname>Fletcher</surname> <given-names>ML</given-names></name><name><surname>Heck</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Minimally invasive highly precise monitoring of respiratory rhythm in the mouse using an epithelial temperature probe</article-title><source>Journal of Neuroscience Methods</source><volume>263</volume><fpage>89</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2016.02.007</pub-id><pub-id pub-id-type="pmid">26868731</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname> <given-names>MJ</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>McCormick</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title><source>Neuron</source><volume>87</volume><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.038</pub-id><pub-id pub-id-type="pmid">26074005</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyazaki</surname> <given-names>K</given-names></name><name><surname>Miyazaki</surname> <given-names>KW</given-names></name><name><surname>Doya</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The role of serotonin in the regulation of patience and impulsivity</article-title><source>Molecular Neurobiology</source><volume>45</volume><fpage>213</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1007/s12035-012-8232-6</pub-id><pub-id pub-id-type="pmid">22262065</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname> <given-names>JD</given-names></name><name><surname>Deschênes</surname> <given-names>M</given-names></name><name><surname>Furuta</surname> <given-names>T</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Smear</surname> <given-names>MC</given-names></name><name><surname>Demers</surname> <given-names>M</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hierarchy of orofacial rhythms revealed through whisking and breathing</article-title><source>Nature</source><volume>497</volume><fpage>205</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1038/nature12076</pub-id><pub-id pub-id-type="pmid">23624373</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murlis</surname> <given-names>J</given-names></name><name><surname>Elkinton</surname> <given-names>JS</given-names></name><name><surname>Cardé</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Odor plumes and how insects use them</article-title><source>Annual Review of Entomology</source><volume>37</volume><fpage>505</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1146/annurev.en.37.010192.002445</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>KP</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning Series</source><publisher-loc>Massachusetts</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname> <given-names>S</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Juavinett</surname> <given-names>AL</given-names></name><name><surname>Gluf</surname> <given-names>S</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nath</surname> <given-names>T</given-names></name><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Chen</surname> <given-names>AC</given-names></name><name><surname>Patel</surname> <given-names>A</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Mathis</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title><source>Nature Protocols</source><volume>14</volume><fpage>2152</fpage><lpage>2176</lpage><pub-id pub-id-type="doi">10.1038/s41596-019-0176-0</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parabucki</surname> <given-names>A</given-names></name><name><surname>Bizer</surname> <given-names>A</given-names></name><name><surname>Morris</surname> <given-names>G</given-names></name><name><surname>Munoz</surname> <given-names>AE</given-names></name><name><surname>Bala</surname> <given-names>ADS</given-names></name><name><surname>Smear</surname> <given-names>M</given-names></name><name><surname>Shusterman</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Odor concentration change coding in the olfactory bulb</article-title><source>Eneuro</source><volume>6</volume><fpage>ENEURO.0396-18.2019</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1523/ENEURO.0396-18.2019</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname> <given-names>K</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Laterality and symmetry in rat olfactory behavior and in physiology of olfactory input</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>5750</fpage><lpage>5760</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1781-12.2013</pub-id><pub-id pub-id-type="pmid">23536088</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname> <given-names>MA</given-names></name><name><surname>Lagier</surname> <given-names>S</given-names></name><name><surname>Carleton</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Odor representations in the olfactory bulb evolve after the first breath and persist as an odor afterimage</article-title><source>PNAS</source><volume>110</volume><fpage>E3340</fpage><lpage>E3349</lpage><pub-id pub-id-type="doi">10.1073/pnas.1303873110</pub-id><pub-id pub-id-type="pmid">23918364</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Peterson</surname> <given-names>P</given-names></name><name><surname>Jones</surname> <given-names>E</given-names></name><name><surname>Oliphant</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>SciPy: Open Source Scientific Tools for Python</source><ext-link ext-link-type="uri" xlink:href="https://www.scienceopen.com/document?vid=ab12905a-8a5b-43d8-a2bb-defc771410b9">https://www.scienceopen.com/document?vid=ab12905a-8a5b-43d8-a2bb-defc771410b9</ext-link></element-citation></ref><ref id="bib71"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Poritz</surname> <given-names>AB</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Linear predictive hidden markov models and the speech signal</article-title><conf-name>ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing</conf-name><pub-id pub-id-type="doi">10.1109/ICASSP.1982.1171633</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porter</surname> <given-names>J</given-names></name><name><surname>Craven</surname> <given-names>B</given-names></name><name><surname>Khan</surname> <given-names>RM</given-names></name><name><surname>Chang</surname> <given-names>SJ</given-names></name><name><surname>Kang</surname> <given-names>I</given-names></name><name><surname>Judkewitz</surname> <given-names>B</given-names></name><name><surname>Judkewicz</surname> <given-names>B</given-names></name><name><surname>Volpe</surname> <given-names>J</given-names></name><name><surname>Settles</surname> <given-names>G</given-names></name><name><surname>Sobel</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Mechanisms of scent-tracking in humans</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>27</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1038/nn1819</pub-id><pub-id pub-id-type="pmid">17173046</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulet</surname> <given-names>JF</given-names></name><name><surname>Hedwig</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The cellular basis of a corollary discharge</article-title><source>Science</source><volume>311</volume><fpage>518</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1126/science.1120847</pub-id><pub-id pub-id-type="pmid">16439660</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabell</surname> <given-names>JE</given-names></name><name><surname>Mutlu</surname> <given-names>K</given-names></name><name><surname>Noutel</surname> <given-names>J</given-names></name><name><surname>del Olmo</surname> <given-names>PM</given-names></name><name><surname>Haesler</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spontaneous rapid odor source localization behavior requires interhemispheric communication</article-title><source>Current Biology</source><volume>27</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.04.027</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajan</surname> <given-names>R</given-names></name><name><surname>Clement</surname> <given-names>JP</given-names></name><name><surname>Bhalla</surname> <given-names>US</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Rats smell in stereo</article-title><source>Science</source><volume>311</volume><fpage>666</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1126/science.1122096</pub-id><pub-id pub-id-type="pmid">16456082</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranade</surname> <given-names>S</given-names></name><name><surname>Hangya</surname> <given-names>B</given-names></name><name><surname>Kepecs</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multiple modes of phase locking between sniffing and whisking during active exploration</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>8250</fpage><lpage>8256</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3874-12.2013</pub-id><pub-id pub-id-type="pmid">23658164</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riffell</surname> <given-names>JA</given-names></name><name><surname>Abrell</surname> <given-names>L</given-names></name><name><surname>Hildebrand</surname> <given-names>JG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Physical processes and real-time chemical measurement of the insect olfactory environment</article-title><source>Journal of Chemical Ecology</source><volume>34</volume><fpage>837</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1007/s10886-008-9490-7</pub-id><pub-id pub-id-type="pmid">18548311</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Wilson</surname> <given-names>DA</given-names></name><name><surname>Radman</surname> <given-names>T</given-names></name><name><surname>Scharfman</surname> <given-names>H</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dynamics of active sensing and perceptual selection</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>172</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.02.010</pub-id><pub-id pub-id-type="pmid">20307966</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shusterman</surname> <given-names>R</given-names></name><name><surname>Smear</surname> <given-names>MC</given-names></name><name><surname>Koulakov</surname> <given-names>AA</given-names></name><name><surname>Rinberg</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Precise olfactory responses tile the sniff cycle</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1039</fpage><lpage>1044</lpage><pub-id pub-id-type="doi">10.1038/nn.2877</pub-id><pub-id pub-id-type="pmid">21765422</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommer</surname> <given-names>MA</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A pathway in primate brain for internal monitoring of movements</article-title><source>Science</source><volume>296</volume><fpage>1480</fpage><lpage>1482</lpage><pub-id pub-id-type="doi">10.1126/science.1069590</pub-id><pub-id pub-id-type="pmid">12029137</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommer</surname> <given-names>MA</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Brain circuits for the internal monitoring of movements</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>317</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.060407.125627</pub-id><pub-id pub-id-type="pmid">18558858</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sperry</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="1950">1950</year><article-title>Neural basis of the spontaneous optokinetic response produced by visual inversion</article-title><source>Journal of Comparative and Physiological Psychology</source><volume>43</volume><fpage>482</fpage><lpage>489</lpage><pub-id pub-id-type="doi">10.1037/h0055479</pub-id><pub-id pub-id-type="pmid">14794830</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Reddy</surname> <given-names>CB</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>eaav7893</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tolman</surname> <given-names>EC</given-names></name></person-group><year iso-8601-date="1932">1932</year><source>Purposive Behavior in Animals and Men</source><publisher-loc>New York, United States</publisher-loc><publisher-name>Appleton-Century</publisher-name></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Breugel</surname> <given-names>F</given-names></name><name><surname>Dickinson</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Plume-tracking behavior of flying <italic>Drosophila</italic> emerges from a set of distinct sensory-motor reflexes</article-title><source>Current Biology</source><volume>24</volume><fpage>274</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.12.023</pub-id><pub-id pub-id-type="pmid">24440395</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwolf</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Hippocampal activity, olfaction, and sniffing: an olfactory input to the dentate gyrus</article-title><source>Brain Research</source><volume>593</volume><fpage>197</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(92)91308-2</pub-id><pub-id pub-id-type="pmid">1450928</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verhagen</surname> <given-names>JV</given-names></name><name><surname>Wesson</surname> <given-names>DW</given-names></name><name><surname>Netoff</surname> <given-names>TI</given-names></name><name><surname>White</surname> <given-names>JA</given-names></name><name><surname>Wachowiak</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Sniffing controls an adaptive filter of sensory input to the olfactory bulb</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>631</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1038/nn1892</pub-id><pub-id pub-id-type="pmid">17450136</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname> <given-names>NJ</given-names></name><name><surname>Baker</surname> <given-names>TC</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Reiterative responses to single strands of odor promote sustained upwind flight and odor source location by moths</article-title><source>PNAS</source><volume>91</volume><fpage>5756</fpage><lpage>5760</lpage><pub-id pub-id-type="doi">10.1073/pnas.91.13.5756</pub-id><pub-id pub-id-type="pmid">11607476</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Holst</surname> <given-names>E</given-names></name><name><surname>Mittelstaedt</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1950">1950</year><article-title>Das reafferenzprinzip</article-title><source>Naturwissenschaften</source><volume>37</volume><fpage>464</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1007/BF00622503</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wachowiak</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>All in a sniff: olfaction as a model for active sensing</article-title><source>Neuron</source><volume>71</volume><fpage>962</fpage><lpage>973</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.08.030</pub-id><pub-id pub-id-type="pmid">21943596</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Webb</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neural mechanisms for prediction: do insects have forward models?</article-title><source>Trends in Neurosciences</source><volume>27</volume><fpage>278</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.03.004</pub-id><pub-id pub-id-type="pmid">15111010</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Weiss</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1968">1968</year><chapter-title>Self-differentiation of the basic patterns of coordination</chapter-title><source>Dynamics of Development: Experiments and Inferences</source><publisher-loc>Massachusetts, United States</publisher-loc><publisher-name>Academic Press</publisher-name><fpage>486</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1016/C2013-0-12166-6</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welker</surname> <given-names>WI</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Analysis of sniffing of the albino rat 1</article-title><source>Behaviour</source><volume>22</volume><fpage>223</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1163/156853964X00030</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wesson</surname> <given-names>DW</given-names></name><name><surname>Verhagen</surname> <given-names>JV</given-names></name><name><surname>Wachowiak</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Why sniff fast? the relationship between sniff frequency, odor discrimination, and receptor neuron activation in the rat</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>1089</fpage><lpage>1102</lpage><pub-id pub-id-type="doi">10.1152/jn.90981.2008</pub-id><pub-id pub-id-type="pmid">19052108</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname> <given-names>AB</given-names></name><name><surname>Johnson</surname> <given-names>MJ</given-names></name><name><surname>Iurilli</surname> <given-names>G</given-names></name><name><surname>Peterson</surname> <given-names>RE</given-names></name><name><surname>Katon</surname> <given-names>JM</given-names></name><name><surname>Pashkovski</surname> <given-names>SL</given-names></name><name><surname>Abraira</surname> <given-names>VE</given-names></name><name><surname>Adams</surname> <given-names>RP</given-names></name><name><surname>Datta</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mapping Sub-Second structure in mouse behavior</article-title><source>Neuron</source><volume>88</volume><fpage>1121</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.031</pub-id><pub-id pub-id-type="pmid">26687221</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yanovsky</surname> <given-names>Y</given-names></name><name><surname>Ciatipis</surname> <given-names>M</given-names></name><name><surname>Draguhn</surname> <given-names>A</given-names></name><name><surname>Tort</surname> <given-names>AB</given-names></name><name><surname>Brankačk</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Slow oscillations in the mouse Hippocampus entrained by nasal respiration</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>5949</fpage><lpage>5964</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5287-13.2014</pub-id><pub-id pub-id-type="pmid">24760854</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yarbus</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="1967">1967</year><source>Eye Movements and Vision</source><publisher-loc>Boston</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4899-5379-7</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yovel</surname> <given-names>Y</given-names></name><name><surname>Falk</surname> <given-names>B</given-names></name><name><surname>Moss</surname> <given-names>CF</given-names></name><name><surname>Ulanovsky</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Optimal localization by pointing off Axis</article-title><source>Science</source><volume>327</volume><fpage>701</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1126/science.1183310</pub-id><pub-id pub-id-type="pmid">20133574</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zelano</surname> <given-names>C</given-names></name><name><surname>Jiang</surname> <given-names>H</given-names></name><name><surname>Zhou</surname> <given-names>G</given-names></name><name><surname>Arora</surname> <given-names>N</given-names></name><name><surname>Schuele</surname> <given-names>S</given-names></name><name><surname>Rosenow</surname> <given-names>J</given-names></name><name><surname>Gottfried</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Nasal respiration entrains human limbic oscillations and modulates cognitive function</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>12448</fpage><lpage>12467</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2586-16.2016</pub-id><pub-id pub-id-type="pmid">27927961</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>FW</given-names></name><name><surname>Shao</surname> <given-names>ZY</given-names></name><name><surname>Shipley</surname> <given-names>MT</given-names></name><name><surname>Puche</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Short-term plasticity in glomerular inhibitory circuits shapes olfactory bulb output</article-title><source>Journal of Neurophysiology</source><volume>123</volume><fpage>1120</fpage><lpage>1132</lpage><pub-id pub-id-type="doi">10.1152/jn.00628.2019</pub-id><pub-id pub-id-type="pmid">31995427</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.58523.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper is a clear account of an odor-guided behavior in which the authors use machine-learning movement analysis to work out how mice combine odor sampling with a set of sniff-locked movement motifs in their decision-making. The authors find that in this task, the mice use odor gradients, but do not use stereo olfaction. The careful characterization of movement motifs during the task will be useful to relate olfactory decision-making with neuronal activity.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Sniff-synchronized, gradient-guided olfactory search by freely-moving mice&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Catherine Dulac as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional analysis is required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>This paper is a clear account of an odor-guided behavior in which the authors use machine-learning movement analysis to characterize the behavior in detail. The key findings are sniff-synchronized movement (already known), the ability to classify a number of movement motifs (but not strikingly distinct) and the further analysis of relationships between these movements and sniffing.</p><p>All reviewers felt that this detailed analysis of behavior in a non-invasive manner was exciting and has much promise for the field.</p><p>Essential revisions:</p><p>The reviewers felt that the interpretation of sampling and movement needed a better understanding of the strategy used by the mice.</p><p>They suggest that there are several possibilities:</p><p>– The animals could be memorizing absolute concentrations.</p><p>– The animals could use two samples during the turn, to ascertain gradients.</p><p>Further, they felt that the motif analysis might be useful to elucidate how the animal corrects an initial decision.</p><p>They feel that the authors need to provide the reader with a detailed and rigorous analysis of the decision strategy. As the discussion on this topic was extensive, I have provided excerpts below to help the authors.</p><p>In addition the authors need to do more with the analysis, clarifying:</p><p>– Animal differences and lack of stereotypy in movements;</p><p>– Nose speed during ITI;</p><p>- State transitions and error correction;</p><p>- Decision points.</p><p>Here I provide excerpts from the extensive discussions on this paper. The intention is to give the authors an understanding of the key points that the reviewers took from the paper, and where they felt that its analysis could be strengthened.</p><p>After watching the videos several times, here is my interpretation of the decision strategy: when the trial starts, the mouse faces away from the gradient. It must make a rotation of ~180 degrees to align its body with the direction of the gradient. This stereotyped movement forms an arc of the alpha shape of Figure 3D. While rotating, the mouse could already detect whether the concentration increases or not. Upon the detection of an increase, the mouse infers that the gradient points in that direction, and it initiates a walk toward the corresponding odor port. During that walk/approach, the mouse sniffs a couple of times. If a decrease in concentration is measured during these sniffs/samples, the mouse might still be able to stop and reorient before the decision boundary.</p><p>In addition, I don't think that a sequence of samples on the left and the right side must be taken for the mouse to infer the direction of the gradient. All it needs to do is compare the intensity when the head is aligned with the body (before ) with the intensity after a lateral sample (after). If an increase is detected, the head must be pointing toward the gradient. In the videos, I didn't see systematic left-right samples.</p><p>…</p><p>sampling a landscape with two longitudinal asymmetric gradients would be challenging. This situation would make the sensory experience associated with an alpha turn largely inconclusive. Without making multiple samples on the left and right sides of the midline, a mouse would not be able to obtain a coarse map of the landscape to inform its decision.</p><p>But the intensity landscapes reported in Figure S2 indicate that most gradients do not really have two real maxima (or two lobes). Even for the 60:40 condition, the landscape essentially looks like one smooth gradient with a maximum on one side. So the sensory experiences produced by an alpha turn toward the left and the right side might be different – a signal the mouse might learn?</p><p>That said, I was puzzled by the fact that the two landscapes corresponding to the 60:40 conditions are quite different when 60 is located on the left or the right side (top versus bottom panels in Figure S2B). So, one might expect that the 60:40 – right would be harder to scan than 60:40 – left. Since the performances of the left and the right conditions were lumped together, it's impossible to tell whether this prediction is correct.</p><p>And here is another possible strategy:</p><p>An alternative possibility is that animals are not actually making L-R comparisons and just memorizing 'expected' gradients or absolute concentrations (100, 80, 60 etc) – which is actually quite easy for mice to learn!</p><p>In that case, indeed the mouse actually already knows which side the reward will be. If during the alpha turn it smells concentrations 100 or 80 or 60, it sticks to that side, otherwise walk to the other side. Indeed in this scenario – there is no need for lateral comparisons – and the knowledge gathered during the alpha turn already tells the animals which side it should go towards.</p><p>But this in principle is a different task than the authors intended to set up!</p><p>The authors actually do try to rule out the possibility that animals learn absolute concentrations by doing what they refer to as variable |C| sessions (Figure S4 B). i.e. by present the same absolute concentration, but in opposing contexts – one where its the higher of the two concentrations (30:10) versus one where its the lower of the two concentrations (30:90).</p><p>But the data presented is not really conclusive –.…</p><p>performance in the first 10 trials is quite low – so its very likely that the animals just learn a new rule..</p><p><italic>Reviewer #1:</italic></p><p>This paper is a clear account of an odor-guided behavior in which the authors use machine-learning movement analysis to characterize the behavior in detail. The key findings are sniff-synchronized movement (already known), the ability to classify a number of movement motifs (but not strikingly distinct) and the further analysis of relationships between these movements and sniffing.</p><p>The basic behavioural checks and controls are thoroughly done. It is interesting that there is no stereo component to these decisions.</p><p>A key finding is sniff-synchronized movement. This has also been seen in other studies (Kurnikova et al. 2017, Moore et al. 2013, Ranade et al. 2013) as the authors point out. I was looking for a clear statement of how the current work advances this understanding.</p><p>Motif analysis.</p><p>The motifs don't appear to be particularly crisp, in that they continue to contribute up to 100 motifs. I was looking to see this enumerated, as in % of variance explained (or in this case cross-validated log-likelihood). It turns out it is done in Figure S8C. This should be in the main text.</p><p>There is nice but not much explored finding of there being distinct movement patterns between individual mice.</p><p>The motif correlation to stage of trial and to sniffing and nose speed is interesting but maybe not surprising. The subsequent analysis shows up a number of patterns here which are suggestive of general synchronization between breathing and other motor rhythms. I wonder if the authors could do a zero-order correlation, of something simple like leg movements which are much more directly quantifiable than these motifs. Or has such work been done?</p><p>The main accomplishment, to my reading, is the detailed characterization of sniffing and its relation to movement. The authors are candid about the being mostly a descriptive account of behavior and movement and make a case for this being a prerequisite for subsequent mechanistic and interventional studies.</p><p>On the one hand, I appreciate the value of a thorough descriptive account of freely moving behavior. However, it seems to me that the motifs are fuzzy and the core outcome of sniff-locked movement has been reported. I wonder if there is more to be gleaned from this rich dataset, such as an analysis of what differs between mice or whether there is something underlying the lack of stereotypy in the movements of the mice.</p><p><italic>Reviewer #2:</italic></p><p>In this study, Smear et al. aim to investigate how mice sample the noisy stimulus information from olfactory plumes such as to navigate towards their source. To this end, they developed a 2AFC task for freely moving mice where the same odor emanates from two lateral sources, at independently controllable concentrations. Mice are required to identify the more intense of the two sources and collect water from reward port located on the side with the higher odor concentration. The authors improve on previous attempts at studying this problem by requiring the mice to commit to their decision at a substantial distance from the odor ports. This forces the mice to assess odor concentration from distal cues rather than via serial sampling of the sources themselves. Interestingly, the authors find that stereo olfaction (comparing concentration across two nostrils) is not required to determine source location from distal cues. Using a series of stimulus conditions, the authors convincingly show that in their paradigm, mice rely on olfactory cues and specifically the relative, not absolute, concentration difference between the two sources.</p><p>The relevance of stereo olfaction for airborne odor cues has been long debated. In my opinion, the authors results in principle resolve this debate – stereo comparisons allow finer source localisation near the source, while serial sampling may play a larger role farther away from source. One concern however is that this lack of reliance on stereo sampling may result from the specific task design and the constraints it imposes on the behavior (see concerns).</p><p>Further, the authors characterise the sampling behaviors of mice during this task by monitoring respiration (thermistor) as well as nose, head and body positions (video tracking). The authors find a striking, active synchronisation of sniffing and nose (and body) movements that gets selectively recruited during putative investigatory phase of the task i.e. when mice are actively exploring the concentration gradient. The authors do exhaustive analysis to show that such synchronisation is not a default state and the coupling is much weaker during other phases within the same trial. While such coupling of movement and intrinsic rhythms has been proposed previously, to my knowledge this is the first careful characterisation of this phenomenon in freely moving mice. Importantly, the authors results not only confirm the existence of such coupling but also clarify that this synchronisation is an active feature of olfactory navigation. Interestingly however, the authors do not find any significant difference in sampling strategies across different stimulus difficulties (see concerns).</p><p>Lastly, the authors use machine learning to parse motion trajectories into identifiable behavioral motifs. With their approach, they find that a range of motifs that are stereotyped across mice and occur in non-random sequences during each trial. Further, a trained decoder can successfully decode mouse identity from the sequences in which these motifs in each animal. While these motif based analysis are well done, the data presented do not seem to make any clear predictions about how these motif sequences would change in different task conditions. The authors do not find any obvious relationship between trial types (difficult versus easy stimuli) and motif sequences and the presented analyses do not add much to the main message of the paper. I therefore lack the imagination to accurately assess the relevance of this portion of the study.</p><p>Overall, the study is well executed – the data presented are clear with numerous controls at each step. In my opinion, the evidence provided for lack of need for stereo olfaction for distal source assessment and active synchronisation of sniffing and sampling movements are important contributions to the field of olfaction that warrant publication in <italic>eLife</italic>. However, I have several conceptual concern about the task design and the interpretations of the results that the authors should clarify prior to publication.</p><p>1. My primary concern is about the task design. I commend the authors for the careful control of olfactory stimuli and substantial improvements over previously published odor localisation assays by separating the reward port from the odor source and forcing decisions at locations distant from the source. However, the task design chosen does not really require the mice to localize odor sources beyond just indicating whether there is more odor on the right versus left. This is different from natural conditions, where the necessary spatial resolution may be much higher. In fact, finer source localization confers no additional benefit for maximizing reward in this task. Therefore, the sampling strategies exhibited by the subjects here may be different from those employed during natural odor navigation where the motivation is to precisely locate the source of mate, food or predators.</p><p>2. Along the same lines, it is surprising that even for the easiest version of the task, the performance hovers around 80%, even though PID characterisations show very clear differences between the two halves of the arena. Furthermore, performance drops with increasing stimulus difficulty but mice do not appear to change their sampling strategies to compensate for the lower reward rate. I am trying to reconcile these two facts. At first pass, given known olfactory acuity of rodents, it seems that trained mice should have no trouble handling the easiest stimuli (reach almost 100% success). One possibility is that the mice are not fully motivated/engaged in the task. An alternate explanation is that mice are fully motivated to reach maximum reward rate, but the task is just too hard and the sampling strategies employed at 100:0 condition are their best, and therefore with increasing stimulus difficulty, they cannot perform any better. Yet, the latter possibility appears very unlikely. Can the authors comment on these two possibilities? The question remains whether mice when pushed to achieve higher performances would employ different sampling strategies.</p><p>3. Lastly, looking at Figure 5Ai it appears that overall nose speeds are significantly lower during ITI than during the investigatory bouts within the trial. While the authors rule out that sniffing-movement synchronisation is simply a feature of rapid sniffing, they do not rule out the dependence on running speeds. Perhaps the apparent lack of synchrony in ITI results from poorer ability to resolve decelerations, given lower speeds on average. This is also consistent with reduced, but significant synchrony during premature initiations in the ITI (Figure S7A) where speeds tend to be higher than those shown in Figure 5Ai. This should be easily addressable by repeating the analysis on speed matched datasets.</p><p><italic>Reviewer #3:</italic></p><p>In this manuscript, Findley and colleagues propose a novel assay to study the behavioral strategy freely moving mice adopt to navigate turbulent odor gradients. This assay is neat and well-thought. It sheds light into the control of active sampling through sniffing and search patterns involving head and body movements. The work is an admirable technical tour de force. The results are built on solid data analysis, which makes use of unsurprised machine learning to avoid subjective biases in the categorization of behavioral states. The manuscript offers a wealth of data that should be a wide interest to the field of olfaction. Finally, the conclusions are presented in a way that is balanced and supported by the well-controlled experimental data. This manuscript combines innovation with rigor to advance our understanding of olfaction in rodents (and beyond).</p><p>I have a few suggestions to improve the manuscript. These suggestions do not require any additional experiments.</p><p>1. An exciting finding of the manuscript is the description of two behavioral states underlying odor search: investigation and approach. The authors might want to push the analysis of the search strategy one step further by defining whether/how mice can switch from investigation to approach, back to investigation to perform error correction. This process would rule out that animals find the gradient through an initial guess that leads to a full commitment to one side during the approach phase. The data suggests that error correction takes place (Figure 7C and D), but those cases are not analyzed in detail. Can a statistical analysis of the state transitions reveal any principles in the organization of error correction? Does the animal's state indeed switch from approach to investigation during error correction?</p><p>2. The occupancy diagram of Figure 3F is fascinating. Together with panel 3D, it suggests that mice undergo fairly stereotyped searches: after poking their nose out of the initiation port, they appear to make a 180 degree rotation (sweep) to face the gradient. The density reaches a maximum at that point (opposite to the position of the initiation port). Is this position (crossing of the alpha shape) dominated by an &quot;investigation&quot; state? Can this position be viewed as a decision point? When/where does the animal tend switch to the &quot;approach&quot; state? More generally, could you map dominate trends in behavioral motifs of Figure 6B onto the stereotyped alpha shape of the occupancy diagram of Figure 3F?</p><p>3. Figure 2D: Could you speculate about the reason why trials tend to be longer for the 100:0 conditions compared to the more difficult 60:40? Do mice spend more time in the investigation phase when gradient is stronger? Although this result would be counter-intuitive, it might suggest that mice learn (?) to spend less time on the initial search when less information is available to them.</p><p>4. Figure 1D indicates that the average gradient's geometry is not the same when the odor is delivered on the left side (100:0) compared to the right side (0:100). This observation appears to be true for the other odor ratios reported in Figure S2. This asymmetry should affect the gradient that the animal experiences during the investigation phase, which should in turn influence the accuracy of the decisions. Do you expect a 50:50 condition to produce no preference (on average)?</p><p>5. Figure 7F: What are you concluding from this panel? Are you sure that the shaded areas represent the standard deviation and not the SEM? If the standard deviation is shown, how do you explain the existence of stereotypical wiggles on a timescale of 50 ms? It would be very useful to represent a variant of Figure 7C where the trials are sorted between correct and incorrect.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.58523.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Summary</p><p>This paper is a clear account of an odor-guided behavior in which the authors use machine-learning movement analysis to characterize the behavior in detail. The key findings are sniff-synchronized movement (already known), the ability to classify a number of movement motifs (but not strikingly distinct) and the further analysis of relationships between these movements and sniffing. All reviewers felt that this detailed analysis of behavior in a non-invasive manner was exciting and has much promise for the field.</p></disp-quote><p>We are gratified by the overall positivity of the review and we are most grateful to the reviewers for thoughtful and thought-provoking comments. We recognize and appreciate the effort and time these reviews must have taken. Most importantly, we feel that we have substantially improved our manuscript by responding to these reviews.</p><p>We have organized our response into sections that address the major issues raised in Dr. Bhalla’s summary. To do so, we have organized the comments from individual reviewers into these sections. All comments about other issues are addressed after that.</p><disp-quote content-type="editor-comment"><p>Essential revisions</p><p>Decision points and sensory strategy. Where and when are the mice making decisions, and are these decisions based on absolute concentration or the gradient?</p></disp-quote><p>We thank the reviewers for encouraging us to delve deeper into the sensory strategy the mice are using to solve this task. In our revision, we now present data that support our contention that the mice are guided by serial sniffs across odor gradients. To further test this model, we visualized the allocentric structure of investigation and approach, as suggested by reviewer 3.</p><disp-quote content-type="editor-comment"><p>The occupancy diagram of Figure 3F is fascinating. Together with panel 3D, it suggests that mice undergo fairly stereotyped searches: after poking their nose out of the initiation port, they appear to make a 180 degree rotation (sweep) to face the gradient. The density reaches a maximum at that point (opposite to the position of the initiation port). Is this position (crossing of the alpha shape) dominated by an &quot;investigation&quot; state? Can this position be viewed as a decision point? When/where does the animal tend switch to the &quot;approach&quot; state? More generally, could you map dominate trends in behavioral motifs of Figure 6B onto the stereotyped alpha shape of the occupancy diagram of Figure 3F?</p></disp-quote><p>We thank reviewer 3 for these ideas. In a new section of the results with 4 new figures (2 main and 2 supplementary), we now show occupancy maps of investigation and approach states. By overlaying the occupancy histograms from the two states, we show that most of the overlap is restricted to the center of the region between initiation port and decision line. This is at the crossing of the alpha shape of occupancy maps (Figure 9A) where overall occupancy also peaks (Figure 3F). To better quantify this overlap, we show an index of the relative values of investigation and approach occupancy as a function of distance from the initiation port. These data show that the index switches from predominantly investigation to predominantly approach within the alpha shape crossing region, between 5 and 10 cm from initiation. Based on this observation, we now refer to this region (between 5 and 10 cm), as a &quot;transition zone&quot; for the purposes of further analysis. We do not view this region as a &quot;decision point&quot;, because we think that term only applies to an instantaneous event, not an across-trial pattern. Investigation-approach transitions are our best guess at the decision points in each individual trial. What we are calling the &quot;transition zone&quot; is the region where most of these transitions occur.</p><p>We next use these occupancy maps to evaluate alternative models of the sensory strategy – do the mice use absolute concentration or gradients? As argued by Dr. Bhalla:</p><disp-quote content-type="editor-comment"><p>The animals could be memorizing absolute concentrations… just memorizing 'expected' gradients or absolute concentrations (100, 80, 60 etc) – which is actually quite easy for mice to learn! In that case, indeed the mouse actually already knows which side the reward will be. If during the alpha turn it smells concentrations 100 or 80 or 60, it sticks to that side, otherwise walk to the other side. Indeed in this scenario – there is no need for lateral comparisons – and the knowledge gathered during the alpha turn already tells the animals which side it should go towards.</p></disp-quote><p>We agree that this possibility is logically consistent with the evidence provided in the original submission. We thank Dr. Bhalla for articulating such a clear prediction of the absolute concentration model. Indeed, an absolute concentration-sensing mouse would not need lateral comparisons. If they first turn toward higher concentration, they should stick to that side, and proceed straight to the water port, rather than waste time and sniffs at the midline. They would only need to cross the midline if they sense low concentration while turning out of the initiation port. To depict this intuitive prediction, we have now added auROC maps based on our PID recordings as panel C and D in Figure 1—figure supplement 2. This map (Figure 1—figure supplement 2C) shows absolute concentration differences between left and right trials can best be discriminated if the animal samples directly downwind of the odor ports, along the axes of maximal odor concentration.</p><p>On the other hand, if the mouse is using a gradient sensing strategy, it would seem that the best strategy is to sample both sides. As stated by Dr. Bhalla:</p><disp-quote content-type="editor-comment"><p>I don't think that a sequence of samples on the left and the right side must be taken for the mouse to infer the direction of the gradient… In the videos, I didn't see systematic left-right samples.</p></disp-quote><p>We agree that sampling both sides is not necessary for performing the task. However, because the airflow in the arena is turbulent, odor released on one side spreads some distance into the other. Nevertheless, while sampling both sides is not a must, we agree that the gradient sensing model predicts that the animal would achieve the highest performance by sampling across the midline. To depict this intuition, in (Figure 1—figure supplement 2D) we show an auROC map based on gradients derived from the same PID recordings. This map shows that for gradient-sensing, the most informative place to sample is indeed across the midline.</p><p>In Figure 10, we use investigation and approach occupancy maps to test these predictions. We show that correct trials are associated with more investigation at and around the midline, particularly on the unchosen side of the arena. By definition, sampling the unchosen side precedes crossing the midline to the chosen side, showing that correct trials feature more sampling on both sides. Incorrect trials have more investigation downwind of the odor ports, particularly near the decision line, where Figure 1—figure supplement 2D shows is the most informative location for absolute concentration discrimination. Thus, these data are inconsistent with the absolute concentration model, and consistent with the gradient model.</p><p>One concern with our task is that it forces mice to turn in one direction or the other out of the initiation port. Sometimes the mouse stays on the side it started towards, sometimes it switches to the other side. Could this asymmetry explain why correct trials seem to feature more investigation at the midline? In Figure 10—figure supplement 1, we analyzed stay and switch trials separately. The performance correlations shown in Figure 10 are essentially the same. In both conditions, correct trials are associated with more investigating at the midline and on the unchosen side. Although there are intriguing differences between the patterns, we feel that these are beyond the scope of the present manuscript.</p><p>Our analysis of the allocentric structure of state usage supports a serial-sniff gradient sensing model and is inconsistent with an absolute concentration sensing model. On that same topic:</p><disp-quote content-type="editor-comment"><p>The authors actually do try to rule out the possibility that animals learn absolute concentrations by doing what they refer to as variable |C| sessions… But the data presented is not really conclusive – performance in the first 10 trials is quite low – so its very likely that the animals just learn a new rule.”</p></disp-quote><p>We respectfully disagree. Figure 2—figure supplement 2 shows the across-mouse average performance over trials. In the first 10 trials of the first session in which the mice have encountered the 90:30/30:10 version of the task, the mice perform at 75% correct. Therefore, on average, the mice make only 2 or 3 errors in these trials. Even for an ideal observer mouse, we think it would take at least two errors to ascertain that they should learn a new rule. Slotnick and Katz (1974) showed that rats can show learning-set performance for new odor-pair discriminations in a nearly-errorless way, but only after they have already experienced 16 previous odor-pair switches, and thousands of trials. So, while it may be mathematically possible for a mouse to immediately change sensory strategies from C to delta-C, the possibility does not seem very likely given our data.</p><p>State transitions and error correction</p><disp-quote content-type="editor-comment"><p>The authors might want to push the analysis of the search strategy one step further by defining whether/how mice can switch from investigation to approach, back to investigation to perform error correction. This process would rule out that animals find the gradient through an initial guess that leads to a full commitment to one side during the approach phase. The data suggests that error correction takes place (Figure 7C and D), but those cases are not analyzed in detail. Can a statistical analysis of the state transitions reveal any principles in the organization of error correction? Does the animal's state indeed switch from approach to investigation during error correction?</p></disp-quote><p>Our new analysis shows that transitions from investigation to approach in the region just before the decision line are more common on error trials (Figure 10C and supplement 1). This pattern shows that the investigation state is not inherently beneficial to performance. Instead, it matters where the mouse investigates, which gives us indication of where informative stimulus features are in the arena. The auROC map (Figure 1—figure supplement 2) shows that absolute concentration features are most informative in this position near the decision line, where investigation is associated with incorrect trials. Thus we interpret this result as further evidence against the absolute concentration model.</p><disp-quote content-type="editor-comment"><p>What are individual animal differences and how do you explain the lack of stereotypy in movement?</p></disp-quote><p>We have shown that a classifier can uniquely identify individual animals based on our ARHMM. Is this because the motifs themselves differ across mice, or does it reflect diversity in how different mice sequence and deploy the motifs? To test the former possibility, in Figure 6—figure supplement 5 we present average shapes of each motif (as in Figure 6B) for each individual mouse. The shapes match across mice, suggesting that the algorithm is identifying consistent behavioral features. Instead, the differences have more to do with where and when the mice deploy different motifs. To accompany Figures 9 and 10, we provide investigation and approach occupancy maps for individual mice in Figure 9—figure supplement 1, showing that mice are diverse in where they transition from investigation and approach. For example, some mice are biased to one side, other mice to the other. We think these are the idiosyncrasies that the classifier is picking up on. Interestingly, we show in Figure 9—figure supplement 1 that if trials are re-oriented with respect to the chosen side (i.e., right-choice trials are flipped so that the trajectory always ends on the upward side of the diagram), all the mice tend to transition from investigation to approach on the chosen side. In this sense, the mice are quite consistent.</p><p>We think it is most likely that the lack of stereotypy in individual trial trajectories is attributable to the variable and turbulent nature of our odor stimuli.</p><p>Additional comments</p><disp-quote content-type="editor-comment"><p>1. Poor performance and lack of adaptive strategy:</p></disp-quote><p>We too were surprised that the mice did not perform better in the 100:0 condition. Additionally, Reviewer #2 points out mice do not adapt their strategy as the task is made presumably more difficult (i.e. from 80:20 to 60:40). We can only speculate as to why.</p><p>First, we don’t know that this is necessarily an easy task for rodents. In previous studies by the Bhalla and Murthy groups, the rodents were able to improve performance by using a memory-guided strategy, and to some degree avoid the problem of tracking the odor source from a distance. Maybe the animals in these studies used memory-guided strategies because odor-guided navigation is harder for them than our intuition and our PID maps would suggest. We know frustratingly little about the statistics of natural olfactory scenes, so perhaps the mice are evolutionarily optimized to operate in different stimulus conditions than we have contrived for this paradigm.</p><p>Alternatively, another likely explanation which we have added to the manuscript (lines 460-464) is that mice are strong delay-discounters – they are in a hurry to collect as much reward as possible in as little time as possible. Perhaps if we could more exhaustively search the task parameter space (e.g., ITI durations, reward sizes), we could find a way to slow them down and improve performance, but this has exceeded our experimental bandwidth so far.</p><disp-quote content-type="editor-comment"><p>2. Nose speed during ITI versus trial:</p></disp-quote><p>Reviewer #2 raised the concern that our analysis of sniff-locked movement with regards to nose speed is biased, because of differing nose speeds during the inter-trial interval and the trial. In Figure 5—figure supplement 2, we now separately analyze ITI sniffs in which the mice were moving at or above the average nose speed during the trials. Even in these sniffs, we see very little modulation of nose speed, and none for yaw or z-velocity, consistent with our assertion that sniff-synchronized movement is a pro-active search strategy, and not a default accompaniment of fast locomotion.</p><disp-quote content-type="editor-comment"><p>3. Asymmetrical odor distribution:</p></disp-quote><p>Reviewers and Dr. Bhalla pointed out that there is asymmetry in the right versus left odor delivery, particularly apparent in our 60:40 PID maps. This asymmetry is due to a difference in airflow distribution across the arena. If this asymmetry were relevant to performance, we would see systematic patterns in the position biases across mice. However, our data show no such patterns in the left-right distribution of occupancy as far as we can tell (see Figures 3-supplement 1, 9-supplement 1).</p><disp-quote content-type="editor-comment"><p>4. Sniff-synchronization novelty:</p></disp-quote><p>We have been asked to provide a statement on how our sniff-synchronization finding expands upon what is already known, particularly from the work of Kleinfeld’s group. Most importantly, our task design, which includes trial and ITI periods, allows us to show that kinematic rhythms do not always lock to the sniff cycle. Instead, we show that sniff-synchronized movement is specific to periods when the mouse is searching. From this we can infer that sniff synchronization is a pro-active sampling behavior rather than an odor-gated orientation reflex or a default accompaniment to fast sniffing. This could only be speculated upon in the previous work.</p><disp-quote content-type="editor-comment"><p>5. Ethological gap between task design and natural conditions:</p></disp-quote><p>Reviewer #2 points out that our binary choice-based task design may not require the fine spatial resolution likely needed for olfactory search in natural conditions where the number of possible target locations is quite a bit larger than 2. We agree and acknowledge this limitation of our study. We also have no doubt that there are many features of olfactory search that we cannot capture with a paradigm like this. Despite these limitations, we feel confident that the primary findings of the study – gradient guidance, sniff synchronization, and two-state organization of search behavior – will hold true under more naturalistic conditions of airborne scent tracking. We hope we and others can improve upon this experimental design to better recapitulate the relevant olfactory features and motor affordances of the real world.</p></body></sub-article></article>