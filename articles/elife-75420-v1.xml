<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">75420</article-id><article-id pub-id-type="doi">10.7554/eLife.75420</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Reverse engineering of metacognition</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-46724"><name><surname>Guggenmos</surname><given-names>Matthias</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0139-4123</contrib-id><email>mg.corresponding@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Health and Medical University, Institute for Mind, Brain and Behavior</institution><addr-line><named-content content-type="city">Potsdam</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/001w7jn25</institution-id><institution>Charité – Universitätsmedizin Berlin, Department of Psychiatry and Neurosciences, corporate member of Freie Universität Berlin and Humboldt-Universität zu Berlin</institution></institution-wrap><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Wyart</surname><given-names>Valentin</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>École normale supérieure, PSL University, INSERM</institution></institution-wrap><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>15</day><month>09</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e75420</elocation-id><history><date date-type="received" iso-8601-date="2021-11-09"><day>09</day><month>11</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-07-18"><day>18</day><month>07</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-10-12"><day>12</day><month>10</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.10.10.463812"/></event></pub-history><permissions><copyright-statement>© 2022, Guggenmos</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Guggenmos</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-75420-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-75420-figures-v1.pdf"/><abstract><p>The human ability to introspect on thoughts, perceptions or actions − metacognitive ability − has become a focal topic of both cognitive basic and clinical research. At the same time it has become increasingly clear that currently available quantitative tools are limited in their ability to make unconfounded inferences about metacognition. As a step forward, the present work introduces a comprehensive modeling framework of metacognition that allows for inferences about metacognitive noise and metacognitive biases during the readout of decision values or at the confidence reporting stage. The model assumes that confidence results from a continuous but noisy and potentially biased transformation of decision values, described by a confidence link function. A canonical set of metacognitive noise distributions is introduced which differ, amongst others, in their predictions about metacognitive sign flips of decision values. Successful recovery of model parameters is demonstrated, and the model is validated on an empirical data set. In particular, it is shown that metacognitive noise and bias parameters correlate with conventional behavioral measures. Crucially, in contrast to these conventional measures, metacognitive noise parameters inferred from the model are shown to be independent of performance. This work is accompanied by a toolbox (<italic>ReMeta</italic>) that allows researchers to estimate key parameters of metacognition in confidence datasets.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>Metacognition is a person’s ability to think about their own thoughts. For example, imagine you are walking in a dark forest when you see an elongated object. You think it is a stick rather than a snake, but how sure are you? Reflecting on one’s certainty about own thoughts or perceptions – confidence – is a prime example of metacognition. While our ability to think about our own thoughts in this way provides many, perhaps uniquely human, advantages, confidence judgements are prone to biases. Often, humans tend to be overconfident: we think we are right more often than we actually are. Internal noise of neural processes can also affect confidence.</p><p>Understanding these imperfections in metacognition could shed light on how humans think, but studying this phenomenon is challenging. Current methods are lacking either mechanistic insight about the sources of metacognitive biases and noise or rely on unrealistic assumptions. A better model for how metacognition works could provide a clearer picture.</p><p>Guggenmos developed a mathematical model and a computer toolbox to help researchers investigate how humans or animals estimate confidence in their own thoughts and resulting decisions . The model splits metacognition apart, allowing scientists to explore biases and sources of noise at different phases in the process. It takes two kinds of data: the decisions study participants make, and how sure they are about their decision being correct. It then recreates metacognition in three phases: the primary decision, the metacognitive readout of the evidence, and the confidence report. This allows investigators to see where and when noise and bias come into play. Guggenmos tested the model using independent data from a visual discrimination task and found that it was able to predict how confident participants reported to be in their decisions.</p><p>Metacognitive ability can change in people with mental illness. People with schizophrenia have often been found to be overconfident in their decisions, while people with depression can be underconfident. Using this model to separate the various facets of metacognition could help to explain why. It could also shed light on human thinking in general.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>metacognition</kwd><kwd>confidence</kwd><kwd>decision making</kwd><kwd>computational modeling</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>GU 1845/1-1</award-id><principal-award-recipient><name><surname>Guggenmos</surname><given-names>Matthias</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A model framework and toolbox to quantify metacognitive biases and sources of metacognitive noise in animal and human confidence data.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The human ability to judge the quality of one’s own choices, actions and percepts by means of confidence ratings has been subject to scientific inquiry since the dawn of empirical psychology (<xref ref-type="bibr" rid="bib42">Pierce and Jastrow, 1885</xref>; <xref ref-type="bibr" rid="bib16">Fullerton and Cattell, 1892</xref>), albeit it has long been limited to specific research niches. More recently, research on human confidence, and metacognition more generally, has accelerated and branched off to other domains such as mental illnesses (<xref ref-type="bibr" rid="bib46">Rouault et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">Hoven et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Moritz and Lysaker, 2019</xref>; <xref ref-type="bibr" rid="bib51">Seow et al., 2021</xref>) and education (<xref ref-type="bibr" rid="bib13">Fleur et al., 2021</xref>). Two main quantitative characteristics have emerged to describe subjective reports of confidence: <italic>metacognitive bias</italic> and <italic>metacognitive sensitivity</italic>.</p><p><xref ref-type="bibr" rid="bib16">Fullerton and Cattell, 1892</xref> already noted that ‘different individuals place very different meanings on the degree of confidence. Some observers are nearly always quite or fairly confident, while others are seldom confident.’ (p. 126). Technically, metacognitive biases describe a general propensity of observers toward lower or higher confidence ratings, holding the accuracy of the primary actions − type 1 performance − constant. From a perspective of statistical confidence, that is assuming that observers use confidence ratings to report probability correct, an observer is often considered <italic>underconfident</italic> or <italic>overconfident</italic> if confidence ratings are systematically below or above the objective proportion of correct responses.</p><p>Metacognitive biases of this type have been quite extensively studied in the judgement and decision-making literature, in which they became known under the term <italic>calibration</italic> (<xref ref-type="bibr" rid="bib30">Lichtenstein et al., 1977b</xref>). A central finding is that humans have a tendency toward overestimating their probability of being correct (<italic>overconfidence bias</italic>), particularly in general knowledge questions (<xref ref-type="bibr" rid="bib30">Lichtenstein et al., 1977b</xref>; <xref ref-type="bibr" rid="bib31">Lichtenstein et al., 1982</xref>; <xref ref-type="bibr" rid="bib23">Harvey, 1997</xref>; but see <xref ref-type="bibr" rid="bib18">Gigerenzer et al., 1991</xref>). More recently, overconfidence in decisions has been studied in psychiatric diseases, suggesting, for instance, underconfidence in individuals with depression (<xref ref-type="bibr" rid="bib14">Fu et al., 2005</xref>; <xref ref-type="bibr" rid="bib15">Fu et al., 2012</xref>; <xref ref-type="bibr" rid="bib10">Fieker et al., 2016</xref>) and overconfidence in schizophrenic patients (<xref ref-type="bibr" rid="bib36">Moritz and Woodward, 2006a</xref>; <xref ref-type="bibr" rid="bib27">Köther et al., 2012</xref>; <xref ref-type="bibr" rid="bib38">Moritz et al., 2014</xref>).</p><p>However, currently there is no established framework that allows for unbiased estimates of metacognitive biases. The validity of traditional calibration curve analyses, which is based on a comparison of the subjective and objective probability of being correct, has been debunked repeatedly (<xref ref-type="bibr" rid="bib53">Soll, 1996</xref>; <xref ref-type="bibr" rid="bib35">Merkle, 2009</xref>; <xref ref-type="bibr" rid="bib9">Drugowitsch, 2016</xref>). In particular, the classic hard-easy (<xref ref-type="bibr" rid="bib29">Lichtenstein and Fischhoff, 1977a</xref>), according to which overconfidence is particularly pronounced for difficult tasks, can be explained as a mere statistical artefact of random errors. For this reason, and in view of the potential importance in patient populations, there is a pressing need for unbiased measures of metacognitive biases.</p><p>While the measurement of metacognitive biases has received surprisingly little attention in the recent decades, the intricacies of measuring metacognitive sensitivity have been the subject of critical discussion and have spurred a number of methodological developments (<xref ref-type="bibr" rid="bib41">Nelson, 1984</xref>; <xref ref-type="bibr" rid="bib17">Galvin et al., 2003</xref>; <xref ref-type="bibr" rid="bib32">Maniscalco and Lau, 2012</xref>; <xref ref-type="bibr" rid="bib33">Maniscalco and Lau, 2014</xref>; <xref ref-type="bibr" rid="bib11">Fleming and Lau, 2014</xref>). The issue is not the measurement of sensitivity per se: defining metacognitive (or type 2) sensitivity as the ability to discriminate between one’s correct and incorrect responses, it is readily possible to compute this quantity using the logic of receiver operating curve analyses (type 2 ROC; <xref ref-type="bibr" rid="bib6">Clarke et al., 1959</xref>; <xref ref-type="bibr" rid="bib43">Pollack, 1959</xref>). The main issue is that metacognitive sensitivity, according to this definition, is strongly influenced by type 1 performance. The lower type 1 performance, the higher will be the number of guessing trials and thus the higher will also be the expected number of trials in which observers assign low confidence to accidental correct guesses. Expected metacognitive sensitivity thus strongly depends on type 1 performance. Indeed, the importance of such type 1 performance confounds has been demonstrated in a recent meta-analysis of metacognitive performance aberrancies in schizophrenia (<xref ref-type="bibr" rid="bib48">Rouy et al., 2020</xref>). The authors found that a previously claimed metacognitive deficit in schizophrenia was present only in studies that did not control for type 1 performance.</p><p>A potential solution to the problem of type 1 performance confounds was proposed by Maniscalco and colleagues through a measure called <italic>meta-d’</italic> (<xref ref-type="bibr" rid="bib47">Rounis et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Maniscalco and Lau, 2012</xref>; <xref ref-type="bibr" rid="bib33">Maniscalco and Lau, 2014</xref>). Since <italic>meta-d’</italic> is expressed in units of d’, it can be directly compared to − and normalized by − type 1 sensitivity, leading to a ratio measure termed <italic>M</italic><sub>ratio</sub> (<italic>M</italic><sub>ratio</sub> = <italic>meta-d’</italic> / <italic>d’</italic>).</p><p>Recently, however, these normalized measures have come under scrutiny. <xref ref-type="bibr" rid="bib5">Bang et al., 2019</xref> showed that the type 1 performance independence of <italic>M</italic><sub>ratio</sub> breaks down with the simple assumption of a source of metacognitive noise that is independent of sensory noise. <xref ref-type="bibr" rid="bib20">Guggenmos, 2021</xref> confirmed this diagnosis in a systematic analysis of empirical (Confidence Database; <xref ref-type="bibr" rid="bib45">Rahnev et al., 2020</xref>) and simulated data. The very same factor (metacognitive noise) that therefore plausibly introduces interindividual differences in metacognitive performance, might obviate a type-1-performance-independent measurement of metacognitive efficiency in this way. Apart from type 1 performance, a recent study has shown that in empirical data the <italic>overall level of confidence</italic> likewise affects <italic>M</italic><sub>ratio</sub> (<xref ref-type="bibr" rid="bib58">Xue et al., 2021</xref>) − a confound that may be caused by different levels of metacognitive noise when overall confidence is low or high (<xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>).</p><p>Here I argue that an unbiased estimation of latent metacognitive parameters requires a mechanistic forward model − a process model which specifies the transformation from stimulus input to the computations underlying confidence reports and which considers sources of metacognitive noise. In the current work, I introduce a model and a toolbox to realize a process model approach for typical confidence datasets. It allows researchers to make parametric inferences about metacognitive inefficiencies either during readout or during report, as well as about different types of metacognitive biases. The basic structure of the model is shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>. It comprises two distinct levels for type 1 decision making (<italic>sensory level</italic>) and type 2 metacognitive judgments (<italic>metacognitive level</italic>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Computational model.</title><p>Input to the model is the stimulus variable x, which codes the stimulus category (sign) and the intensity (absolute value). Type 1 decision-making is controlled by the sensory level. The processing of stimuli <italic>x</italic> at the sensory level is described by means of sensory noise (<italic>σ</italic><sub>s</sub>), bias (<italic>δ</italic><sub>s</sub>) and threshold (<italic>ϑ</italic><sub>s</sub>) parameters. The output of the sensory level is the decision value <italic>y</italic>, which determines type 1 decisions <italic>d</italic> and provides the input to the metacognitive level. At the metacognitive level it is assumed that the dominant source of metacognitive noise is either noise at the readout of decision values (<italic>noisy-readout model</italic>) or at the reporting stage (<italic>noisy-report model</italic>). In both cases, metacognitive judgements are based on the absolute decision value |<italic>y</italic>| (referred to as <italic>sensory evidence</italic>), leading to a representation of <italic>metacognitive evidence</italic> <inline-formula><mml:math id="inf1"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> at the metacognitive level. While the “readout” of this decision value is considered precise for the noisy-report model (<italic>z</italic> = <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>), it is subject to metacognitive readout noise <italic>z</italic> ∼ <italic>f</italic><sub>m</sub>(<italic>z; z*,σ</italic><sub>m</sub>) in the noisy-readout model, described by a metacognitive noise parameter <italic>σ</italic><sub>m</sub>. A link function transforms metacognitive evidence to internal confidence <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. In the case of a noisy-report model, the dominant metacognitive noise source is during the report of confidence, that is confidence reports <italic>c</italic> are noisy expressions of the internal confidence representation: <italic>c</italic> ∼ <italic>f</italic><sub>m</sub>(<italic>c; c*,σ</italic><sub>m</sub>). Metacognitive biases operate at the level of sensory evidence (<italic>multiplicative evidence bias φ</italic><sub>m</sub>, <italic>additive evidence bias δ</italic><sub>m</sub>) or at the level of the confidence link function (<italic>multiplicative confidence bias λ</italic><sub>m</sub>, <italic>additive confidence bias κ</italic><sub>m</sub>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig1-v1.tif"/></fig><p>A few key design choices deserve emphasis. First, the model assumes that confidence is a second-order process (<xref ref-type="bibr" rid="bib12">Fleming and Daw, 2017</xref>) which assesses the evidence that guided type 1 behavior. In the proposed nomenclature of <xref ref-type="bibr" rid="bib34">Maniscalco and Lau, 2016</xref> it corresponds to a hierarchical model and not to a single-channel model in that it considers additional sources of metacognitive noise. A consequence of the hierarchical structure is that it is essential to capture the processes underlying the decision values at the type 1 level as precisely as possible, since decision values are the input to metacognitive computations. In the present model, this includes an estimate of both a sensory bias and a sensory threshold, both of which will influence type 1 decision values.</p><p>Second, recent work has demonstrated that metacognitive judgements are not only influenced by sensory noise, but also by metacognitive noise (<xref ref-type="bibr" rid="bib5">Bang et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>). In the present model, I therefore consider sources of metacognitive noise either during the readout of type 1 decision values or during report.</p><p>Third, human confidence ratings are often subject to metacognitive biases which can lead to the diagnosis of underconfidence or overconfidence. As outlined above, there is currently no established methodology to measure under- and overconfidence, let alone measure different types of such biases. In the present model, I consider four parameters that can be interpreted as metacognitive biases either at the level of evidence or at the level of the confidence report. The interpretation of these parameters as metacognitive biases entails the assumption that observers aim at reporting probability correct with their confidence ratings (<italic>statistical confidence</italic>; <xref ref-type="bibr" rid="bib22">Hangya et al., 2016</xref>). Although I discuss link functions that deviate from this assumption, in the model outlined here, the transformation of sensory evidence to confidence therefore follows the logic of statistical confidence.</p><p>I demonstrate the issues of conventional measures of metacognitive ability and metacognitive biases, in particular their dependency on type 1 performance, and show that the process model approach can lead to unbiased inferences. Finally, I validate the model on a recently published empirical dataset (<xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>). I illustrate for this dataset how model parameters can describe different facets of metacognition and assess the relationship of these parameters to conventional measures of metacognitive ability and metacognitive bias.</p><p>This article is accompanied by a toolbox − the Reverse engineering of Metacognition (<italic>ReMeta</italic>) toolbox, which allows researchers to apply the model to standard psychophysical datasets and make inferences about the parameters of the model. It is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/m-guggenmos/remeta">https://github.com/m-guggenmos/remeta</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ce43bc78c8d5113b878408e0e2d2520c8595a802;origin=https://github.com/m-guggenmos/remeta;visit=swh:1:snp:8f7bcfafda79ee859399a1a11573d8e97f5b8b1d;anchor=swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2">swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2</ext-link>; <xref ref-type="bibr" rid="bib21">Guggenmos, 2022</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Results are structured in three parts. The first part introduces the architecture and the computational model, from stimulus input to type 1 and type 2 responses. The second part provides the mathematical basis for model inversion and parameter fitting and systematically assesses the success of parameter recovery as a function of sample size and varied ground truth parameter values. Finally, in the third part, the model is validated on an empirical dataset (<xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>).</p><sec id="s2-1"><title>Computational model</title><sec id="s2-1-1"><title>Computing decision values</title><p>For the model outlined here, the task space is restricted to two stimulus categories referred to as <italic>S</italic><sup>−</sup> and <italic>S</italic><sup>+</sup>. Stimuli are described by the stimulus variable <italic>x</italic>, the sign of which codes the stimulus category and the absolute value |<italic>x</italic>| codes the intensity of the stimulus. The sensory level computes <italic>decision values</italic> <inline-formula><mml:math id="inf4"><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> from the stimulus input <italic>x</italic> as follows:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The sensory bias parameter <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> captures systematic preferences for one response category (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) and corresponds to a horizontal shift of the resulting psychometric function. Positive (negative) values of <italic>δ</italic><sub>s</sub> lead to a propensity to choose stimulus category <italic>S</italic><sup>+</sup> (<italic>S</italic><sup>−</sup>). In addition, the sensory threshold <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mi>ϵ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> defines the minimal stimulus intensity which is necessary to drive the system, that is, above which the observer’s type 1 choices can be better than chance level (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Decision values <inline-formula><mml:math id="inf7"><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are fixed to zero below <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the absence of a sensory bias, and fixed to <italic>δ</italic><sub>s</sub> in the presence of a bias (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Note that a sensory threshold parameter should only be considered if the stimulus material includes intensity levels in a range at which participants perform close to chance. Otherwise, the parameter cannot be estimated and should be omitted, that is, <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> reduces to  <inline-formula><mml:math id="inf9"><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> = <italic>x + δ</italic><sub>s</sub>.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Psychometric functions for different settings of sensory model parameters.</title><p>Top left legends indicate the values of varied parameters, bottom right legends settings of the respective other parameters. (<bold>A</bold>) The sensory bias parameter <italic>δ</italic><sub>s</sub> horizontally shifts the psychometric function, leading to a propensity to choose stimulus category <italic>S</italic><sup>−</sup> (<italic>δ</italic><sub>s</sub> &lt; 0) or stimulus category <italic>S</italic><sup>+</sup> (<italic>δ</italic><sub>s</sub> &gt; 0). (<bold>B</bold>) Stimulus intensities below the threshold parameter <italic>ϑ</italic><sub>s</sub> lead to chance-level performance. (<bold>C</bold>) Example for simultaneous non-zero values of the bias and threshold parameter. (<bold>D</bold>) The sensory noise parameter <italic>σ</italic><sub>s</sub> changes the slope of the psychometric function.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Nonlinear transformation of the stimulus variable.</title><p>Early visual processing likely involves nonlinear transformations of stimulus signals, including processes such as contrast gain control nonlinearities or nonlinear transduction. In the toolbox, either a power transformation or an exponential transformation is considered. In both cases, the transformation includes a renormalization to 1, such that any difference in linear stimulus intensity scaling between participants is captured by the decision noise parameter <italic>σ</italic><sub>s</sub>. (<bold>A</bold>) Power transformation. (<bold>B</bold>) Exponential transformation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig2-figsupp1-v1.tif"/></fig></fig-group><p>In the model described here I assume that decision values can be linearly constructed from the stimulus variable <italic>x</italic>. In practice, this may often be too strong of an assumption, and it may thus be necessary to allow for a nonlinear transformation of <italic>x</italic> (‘nonlinear transduction’, see e.g. <xref ref-type="bibr" rid="bib8">Dosher and Lu, 1998</xref>). The toolbox therefore offers an additional nonlinear transformation parameter <italic>γ</italic><sub>s</sub> (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for an illustration).</p><p>The final decision value <italic>y</italic> is subject to sources of sensory noise <italic>σ</italic><sub>s</sub>, described by a logistic distribution <italic>f</italic><sub>s</sub>(<italic>y</italic>):<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mi>y</mml:mi><mml:mi> </mml:mi><mml:mo>~</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mi> </mml:mi><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p><xref ref-type="disp-formula" rid="equ2">Equation 2</xref> is a reparameterization of a standard logistic distribution in terms of the standard deviation <italic>σ</italic><sub>s</sub> using the fact that the standard deviation of the logistic distribution is equal to <italic>sπ</italic>/<inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula> (where <italic>s</italic> is the conventional scale parameter of the logistic distribution). <xref ref-type="fig" rid="fig2">Figure 2D</xref> shows psychometric functions with varying levels of sensory noise <italic>σ</italic><sub>s</sub>. The logistic distribution was chosen over the more conventional normal distribution due to its explicit analytic solution of the cumulative density − the logistic function. In practice, both distributions are highly similar, and which one is chosen is unlikely to matter.</p><p>Type 1 decisions <italic>d</italic> between the stimulus categories S<sup>+</sup> and <italic>S</italic><sup>−</sup> are based on the sign of <italic>y</italic>:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msup><mml:mi>S</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mtd><mml:mtd><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">y</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>S</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:mtd><mml:mtd><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">y</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s2-1-2"><title>From decision values to metacognitive evidence</title><p>The decision values computed at the sensory level constitute the input to the metacognitive level. I assume that metacognition leverages the same sensory information that also guides type 1 decisions (or a noisy version thereof). Specifically, metacognitive judgements are based on a readout of absolute decision values |<italic>y</italic>|, henceforth referred to as <italic>sensory evidence</italic>. Respecting a multiplicative (<underline><italic>φ</italic></underline><sub>m</sub> ∈ ℝ<sup>+</sup>) and an additive (<italic>δ</italic><sub>m</sub> ∈ ℝ) evidence bias, an estimate of sensory evidence is computed at the metacognitive level <italic>– metacognitive evidence</italic> <inline-formula><mml:math id="inf11"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal"> </mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>The multiplicative evidence bias <italic>φ</italic><sub>m</sub> and the additive evidence bias <italic>δ</italic><sub>m</sub> are two different types of metacognitive biases at the readout stage, which are described in more detail in ‘Metacognitive biases’. Note that the <italic>max</italic> operation is necessary to enforce positive values of metacognitive evidence.</p></sec><sec id="s2-1-3"><title>The link function: from metacognitive evidence to confidence</title><p>The transformation from metacognitive evidence to internal confidence <inline-formula><mml:math id="inf12"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is described by a <italic>link function</italic>. A suitable link function must be bounded, reflecting the fact that confidence ratings typically have lower and upper bounds, and increase monotonically.</p><p>I assume that observers aim at reporting probability correct, leading to a logistic link function in the case of the logistic sensory noise distribution (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>). Without loss of generality, I use the range [0;1] for confidence ratings, such that a confidence level of 0 indicates expected chance-level type 1 performance (probability correct = 0.5) and a confidence level of 1 the expectation of optimal type 1 performance (probability correct = 1.0). Note that I do not consider the possibility that type 1 errors can be reported at the time of the confidence report, that is, confidence cannot be negative. With these constraints and using the simple mathematical relationship between the logistic function and the tangens hyperbolicus, one arrives at the following link function (see Appendix 1, <xref ref-type="disp-formula" rid="equ1">Equation A1</xref>, for the derivation):<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">tanh</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Note that I use the variable <italic>z</italic> as opposed to <inline-formula><mml:math id="inf13"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, to indicate that the metacognitive evidence that enters the link function may be a noisy version of <inline-formula><mml:math id="inf14"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (see the description of the <italic>noisy-readout model</italic> below). <xref ref-type="fig" rid="fig3">Figure 3</xref> shows examples of evidence-confidence relationships based on the link function in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> and in dependence of several model parameters.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Effect of model parameters on the evidence-confidence relationship.</title><p>All metacognitive bias parameters and noise parameters affect the relationship between the sensory evidence |<italic>y</italic>| and confidence, assuming the link function provided in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>. (<bold>A</bold>) Effect of metacognitive bias parameters on the evidence-confidence relationship. Metacognitive noise was set to zero for simplicity. (<bold>B</bold>) Effect of metacognitive noise <italic>σ</italic><sub>m</sub> and sensory noise <italic>σ</italic><sub>s</sub> on the evidence-confidence relationship. Metacognitive noise renders confidence ratings more indifferent with respect to the level of sensory evidence. Note that, due to the absence of an analytic expression, the illustration for the effect of metacognitive noise is based on simulation. Increasing sensory noise affects the slope of the confidence-evidence relationship, reflecting changes to be expected from an ideal metacognitive observer.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Confidence link functions.</title><p>Alternative choices for link functions provided by the <italic>ReMeta</italic> toolbox describing the relationship between metacognitive evidence and confidence. Note that these link functions do not compute the subjective probability of being correct. Link functions: <italic>tanh</italic> (simple tangens hyperbolicus), <italic>linear</italic> (linear slope, no intercept), <italic>step function</italic> (criterion-based link function with three criteria placed at evidence levels 0.2, 0.4, and 0.7), <italic>piecewise</italic> (piecewise linear function with three criteria placed at evidence levels of 0.05, 0.2, and 0.5), <italic>piecewise invertible</italic> (piecewise linear function with two criteria placed at evidence levels of 0.1 and 0.3; to attain invertibility, the last piece is described by a tangens hyperbolicus with an additional parameter).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig3-figsupp1-v1.tif"/></fig></fig-group><p>Many other link functions are conceivable, which do not assume that observers aim at expressing confidence as probability correct. In particular, such link functions may not involve an estimate of sensory noise <italic>σ</italic><sub>s</sub>. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> illustrates alternative link functions provided by the <italic>ReMeta</italic> toolbox.</p><p>I refer to <inline-formula><mml:math id="inf15"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> as the <italic>internal confidence</italic>, which may be different from the ultimately <italic>reported confidence c</italic>. This distinction becomes important when metacognitive noise is considered at the level of the confidence report (see Result, ‘Metacognitive noise: noisy-report models’).</p></sec><sec id="s2-1-4"><title>Metacognitive biases</title><p>Metacognitive biases describe a systematic discrepancy between objective type 1 performance and subjective beliefs thereof (expressed via confidence ratings). Relative to an ideal metacognitive observer of stastistical confidence, overconfident observers report systematically higher levels of confidence and underconfident observers report systematically lower levels of confidence. Importantly, metacognitive biases are orthogonal to the metacognitive <italic>sensitivity</italic> of an observer. For instance, an underconfident observer who consistently chooses the second-lowest confidence rating for correct choices could have high metacognitive sensitivity nevertheless, as long as they consistently choose the lowest rating for incorrect choices. In the present model I consider metacognitive biases either at the level of evidence or at the level of confidence (<xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><p>Metacognitive evidence biases represent a biased representation of sensory evidence at the metacognitive level. These biases may be either due to a biased readout from sensory channels or due to biased processing of read-out decision values at the initial stages of the metacognitive level. In either case, evidence biases affect the metacognitive representation <italic>z</italic> of sensory evidence and may be multiplicative or additive in nature. The <italic>multiplicative evidence bias φ</italic><sub>m</sub> leads to a scaling of absolute sensory decision values, with <italic>φ</italic><sub>m</sub> &lt; 1 and <italic>φ</italic><sub>m</sub> &gt; 1 corresponding to under- and overconfident observers, respectively. The <italic>additive evidence bias δ</italic><sub>m</sub> represents an additive bias such that metacognitive evidence is systematically decreased (underconfidence) or increased (overconfidence) by a constant <italic>δ</italic><sub>m</sub>. Values <italic>δ</italic><sub>m</sub> &lt; 0 can be interpreted as a metacognitive threshold, such that the metacognitive level is only ‘aware’ of stimuli that yield sensory evidence above <italic>δ</italic><sub>m</sub>.</p><p>An alternative interpretation of metacognitive evidence biases at the readout stage is that they correspond to an under- or overestimation of one’s own sensory noise <italic>σ</italic><sub>s</sub>. Applying this view, a value of <italic>φ</italic><sub>m</sub> &gt; 1 would suggest that the observer underestimated sensory noise <italic>σ</italic><sub>s</sub> and hence shows overconfidence, whereas a value of <italic>φ</italic><sub>m</sub> &lt; 1 implies that the observer overestimated <italic>σ</italic><sub>s</sub> and thus is underconfident.</p><p>In addition, the present model considers metacognitive bias parameters loading on internal confidence representations. To this end, the confidence link function (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) is augmented by a <italic>multiplicative confidence bias λ</italic><sub>m</sub> and an <italic>additive confidence bias κ</italic><sub>m</sub>:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">tanh</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>z</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Analogous to the evidence biases, values of <italic>λ</italic><sub>m</sub> &lt; 1 and <italic>κ</italic><sub>m</sub> &lt; 0 reflect underconfidence, and values of <italic>λ</italic><sub>m</sub> &gt; 1 and <italic>κ</italic><sub>m</sub> &gt; 0 reflect overconfidence. The effects of all metacognitive evidence and confidence bias parameters are illustrated in <xref ref-type="fig" rid="fig3">Figure 3A</xref>.</p><p>To assess how evidence- and confidence-related metacognitive biases relate to conventional measures of under- and overconfidence, I computed calibration curves (<xref ref-type="bibr" rid="bib30">Lichtenstein et al., 1977b</xref>) for a range of values for each bias parameter (<xref ref-type="fig" rid="fig4">Figure 4</xref>, left panels). A first observation concerns the case in which no metacognitive biases are present (i.e. <italic>φ</italic><sub>m</sub> <italic>= λ</italic><sub>m</sub> = 1, <italic>δ</italic><sub>m</sub> <italic>= κ</italic><sub>m</sub> = 0; black lines). One could assume that calibration curves for bias-free observers are identical to the diagonal, such that objective and subjective accuracy are identical. This is not the case − the calibration curve is tilted toward overconfidence. This may seem surprising but reflects exactly what is expected for a bias-free statistical confidence observer. This is best understood for the extreme case when the subjective probability correct is arbitrarily close to 1. Even for very high ratings of subjective probability, due to sensory noise, there is a certain finite probability that associated type 1 choices have been incorrect. Hence, objective type 1 performance is expected to be below the subjective probability in these cases. Importantly, <italic>relative</italic> to this bias-free observer all metacognitive bias parameters yield calibration curves that resemble under- and overconfidence given appropriate choices of the parameter values (underconfidence: redhish lines; overconfidence: blueish lines).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Metacognitive bias parameters (<italic>φ</italic><sub>m</sub>, <italic>δ</italic><sub>m</sub>, <italic>λ</italic><sub>m</sub>, <italic>κ</italic><sub>m</sub>).</title><p>Gray shades indicate areas of true overconfidence according to the generative model. Gray stripes areas indicate additional areas that would be classified as overconfidence in conventional analyses of confidence data, i.e. when simply comparing objective und subjective probability correct. Simulations are based on a noisy-report model with a truncated normal metacognitive noise distribution. Metacognitive noise was set close to zero for simplicity. (<bold>Left panels</bold>) Calibration curves. Calibration curves compute the proportion of correct responses (objective probability correct) for each interval of subjective confidence reports. Calibration curves above and below the diagonal indicate under- and overconfident observers, respectively. For this analysis, confidence was transformed from rating space [0; 1] to probability space [0.5; 1] and divided in 100 intervals with bin size 0.01. Average type 1 performance for this simulation was around 70%. (<bold>Middle panels</bold>) Confidence bias in dependence of type 1 performance. Different levels of type 1 performance were simulated by sweeping the sensory noise parameter between 0.01 and 50. Confidence bias was computed as the difference between subjective probability correct and objective proportion correct. (<bold>Right panels</bold>) Recovery of metacognitive bias parameters in dependence of performance. Shades indicate standard deviations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig4-v1.tif"/></fig><p>As mentioned previously, metacognitive sensitivity (<italic>AUROC2</italic>, <italic>meta-d’</italic>) is strongly dependent on type 1 performance. How do metacognitive biases perform in this regard, when measured in a model-free manner from choice and confidence reports? To find out, I simulated confidence biases for a range of metacognitive bias parameter values and type 1 performance levels (by varying the sensory noise parameter). Confidence biases were computed as the difference between subjective probability correct (by linearly transforming confidence from rating space [0; 1] to probability space [0.5; 1]) and objective probability correct. As shown in the middle panels of <xref ref-type="fig" rid="fig4">Figure 4</xref>, these results showcase the limits of naively measuring confidence biases in this way. Again, the bias-free observer shows an apparent overconfidence bias. In addition, this bias increases as type 1 performance decreases, reminiscent of the classic hard-easy effect for confidence (<xref ref-type="bibr" rid="bib29">Lichtenstein and Fischhoff, 1977a</xref>; for related analyses, see <xref ref-type="bibr" rid="bib53">Soll, 1996</xref>; <xref ref-type="bibr" rid="bib35">Merkle, 2009</xref>; <xref ref-type="bibr" rid="bib9">Drugowitsch, 2016</xref>; <xref ref-type="bibr" rid="bib26">Khalvati et al., 2021</xref>). At chance level performance, the overconfidence bias is exactly 0.25.</p><p>The value of 0.25 can be understood in the context of the ‘0.75 signature’ (<xref ref-type="bibr" rid="bib22">Hangya et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Adler and Ma, 2018b</xref>). When evidence discriminability is zero, an ideal Bayesian metacognitive observer will show an average confidence of 0.75 and thus an apparent (over)confidence bias of 0.25. Intuitively this can be understood from the fact that Bayesian confidence is defined as the area under a probability density in favor of the chosen option. Even in the case of zero evidence discriminability, this area will always be at least 0.5 − otherwise the other choice option would have been selected, but often higher.</p><p>The overconfidence bias leads to another peculiar case, namely that the bias of truly underconfident observers (i.e. <italic>φ</italic><sub>m</sub> &lt; 1, <italic>δ</italic><sub>m</sub> &lt; 0, <italic>λ</italic><sub>m</sub> &lt; 1, or <italic>κ</italic><sub>m</sub> &lt; 0) can show a sign flip from over- to underconfidence as performance increases from chance level to perfect performance (redish lines in the middle panels of <xref ref-type="fig" rid="fig4">Figure 4</xref>). Overall, the simulation underscores that metacognitive biases are just as confounded by type 1 behavior as metacognitive sensitivity.</p><p>Is it possible to recover unbiased estimates for the metacognitive bias parameters by inverting the process model? To find out, I again simulated data for a range of type 1 performance levels and true values of the bias parameters. In each case, I fitted the model to the data to obtain estimates of the parameters. As shown in the right panels of <xref ref-type="fig" rid="fig4">Figure 4</xref>, parameter recovery was indeed unbiased across the type 1 performance spectrum, with certain deviations only for extremely low or high type 1 performance levels. This demonstrates that, in principle, unbiased inferences about metacognitive biases are possible in a process model approach, assuming that the fitted model is a sufficient approximation of the empirical generative model.</p><p>Finally, note that the parameter recovery shown in <xref ref-type="fig" rid="fig4">Figure 4</xref> was performed with four separate models, each of which was specified with a single metacognitive bias parameter (i.e., <italic>φ</italic><sub>m</sub>, <italic>δ</italic><sub>m</sub>, <italic>λ</italic><sub>m</sub>, or <italic>κ</italic><sub>m</sub>). Parameter recovery can become unreliable when more than two of these bias parameters are specified in parallel (see ‘Parameter recovery’). In practice, the researcher thus must make an informed decision about which bias parameters to include in a specific model. In most scenarios one or two metacognitive bias parameters are likely a good choice. While the evidence-related bias parameters <italic>φ</italic><sub>m</sub> and <italic>δ</italic><sub>m</sub> have a more principled interpretation (e.g. as an under/overestimation of sensory noise), it is not unlikely that metacognitive biases also emerge at the level of the confidence report (<italic>λ</italic><sub>m</sub>, <italic>κ</italic><sub>m</sub>). The first step thus must always be a process of model specification or a statistical comparison of candidate models to determine the final specification (see also ‘On using the model framework’).</p></sec><sec id="s2-1-5"><title>Confidence criteria</title><p>In the model outlined here, confidence results from a continuous transformation of metacognitive evidence, described by a parametric link function (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>). The model thus has no confidence criteria. However, it would be readily possible to replace the tangens hyperbolicus with a stepwise link function where each step is described by the criterion placed along the z-axis and the respective confidence level (alternatively, one can assume equidistant confidence levels, thereby saving half of the parameters). Such a link function might be particularly relevant for discrete confidence rating scales where participants associate available confidence ratings with often idiosyncratic and not easily parameterizable levels of metacognitive evidence.</p><p>Yet, even for the parametric link function of a statistical confidence observer it is worth considering two special confidence criteria: a minimum confidence criterion, below which confidence is 0, and a maximum criterion, above which confidence is 1. Indeed, the over-proportional presence of the most extreme confidence ratings that is often observed in confidence datasets (Confidence Database; <xref ref-type="bibr" rid="bib45">Rahnev et al., 2020</xref>) motivates such criteria.</p><p>My premise here is that these two specific criteria can be described as an implicit result of metacognitive biases. In general, when considering an ideal statistical confidence observer and assuming continuous confidence ratings, the presence of any criterion reflects suboptimal metacognitive behavior − including a minimum or maximum confidence criterion. According to <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>, an ideal observer’s confidence should never be exactly 1 (for finite sensory noise) and should only ever be 0 when metacognitive evidence is exactly zero, which makes a dedicated criterion for this case likewise superfluous.</p><p>Importantly, a minimum confidence criterion is implicit to the additive evidence bias <italic>δ</italic><sub>m</sub>. As explained above, a negative value of <italic>δ</italic><sub>m</sub> effectively corresponds to a metacognitive threshold, such that metacognitive evidence <italic>z</italic> (and hence confidence) is zero for decision values smaller than <italic>δ</italic><sub>m</sub>. A maximum confidence criterion can be realized by the confidence bias parameters <italic>λ</italic><sub>m</sub> and <italic>κ</italic><sub>m</sub>. Specifically, assuming <italic>λ</italic><sub>m</sub> &gt; 1 or <italic>κ</italic><sub>m</sub> &gt; 0, the maximum criterion is the point along the metacognitive evidence axis at which a link function of the form <italic>λ</italic><sub>m</sub>·tanh(..) + <italic>κ</italic><sub>m</sub> becomes exactly 1. In sum, both a minimum and a maximum confidence criterion can be implemented as a form of a metacognitive bias.</p></sec><sec id="s2-1-6"><title>Metacognitive noise: noisy-readout models</title><p>A key aspect of the current model is that the transformation from sensory decision values to confidence reports is subject to sources of metacognitive noise. In this section, I first consider a model of type <italic>noisy-readout</italic>, according to which the metacognitive noise mainly applies to the metacognitive readout of absolute sensory decision values (i.e. <inline-formula><mml:math id="inf16"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>). The final metacognitive evidence <italic>z</italic> is thus a noisy version of <inline-formula><mml:math id="inf17"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. By contrast, sources of noise involved in the report of confidence are considered negligible and the internal confidence estimate <inline-formula><mml:math id="inf18"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> resulting from the link function is equal to the reported confidence <italic>c</italic>.</p><p>Metacognitive noise is defined by a probability distribution and a metacognitive noise parameter <italic>σ</italic><sub>m</sub>. The appropriate noise distribution for such readout noise is an open empirical question. Here, I introduce a family of potential candidates. A key consideration for the choice of a noise distribution is the issue of sign flips. I distinguish two cases.</p><p>A first scenario is that the metacognitive level initially deals with signed decision values, such that metacognitive noise can cause sign flips of these decision values. For instance, while an observer may have issued a type 1 response for stimulus category <italic>S</italic><sup>+</sup>, readout noise could flip the sign of the decision value toward <italic>S<sup>−</sup></italic> at the metacognitive level. How would an observer indicate their confidence in such a case? Unless confidence rating scales include the possibility to indicate errors (which I do not consider here), the only sensible response would be to indicate a confidence of 0, since confidence ratings apply to the choice made and not to the choice one would have hypothetically made based on a subsequent metacognitive representation.</p><p>Enforcing a lower bound of 0 is a form of post-hoc censoring which leads to the concept of a <italic>censored</italic> (or <italic>rectified</italic>) distribution. If a distribution is left-censored at zero, all negative parts of the distribution are assigned to the probability mass of zero, resulting in a distribution with a discrete term at <italic>z</italic> = 0 and a continuous term for <italic>z</italic> &gt; 0 (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). In case of a normal distribution, the probability of z being exactly zero is equal to the cumulative density of the normal distribution at zero. An alternative to the normal distribution is a double exponential distribution, which allows for tail asymmetry. In particular, I here consider the Gumbel distribution which has a pronounced right tail, a property that fits recent observations regarding the skewed nature of metacognitive noise (<xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>; <xref ref-type="bibr" rid="bib58">Xue et al., 2021</xref>). Mathematical definitions of all distributions are listed in <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Metacognitive noise.</title><p>Considered noise distributions are either censored, truncated or naturally bounded. In case of censoring, protruding probability mass accumulates at the bounds (depicted as bars with a darker shade; the width of these bars was chosen such that the area corresponds to the probability mass). The parameter <italic>σ</italic><sub>m</sub> and the distributional mode was set to ⅓ in all cases (arbitrary value). (<bold>A - C</bold>) Noisy-readout models. Metacognitive noise is considered at the level of readout, affecting metacognitive evidence <italic>z</italic>. Only a lower bound at <italic>z</italic> = 0 applies. (<bold>D - F</bold>) Noisy-report models. Metacognitive noise is considered at the level of the confidence report, affecting internal confidence representations <italic>c</italic>. Confidence reports are bounded between 0 and 1.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig5-v1.tif"/></fig><p>The second scenario is that the nature of metacognitive readout noise itself makes sign flips impossible, sparing the necessity of censoring. This required noise distributions that are bounded at zero, either naturally or by means of truncation. I first consider truncated distributions, in particular the truncated normal and the truncated Gumbel distribution (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Truncating a distribution means to cut off the parts of the distribution outside the truncation points (here the range below zero) and to renormalize the remainder of the distribution to 1.</p><p>While truncated distributions behave well mathematically, compared to censored distributions it is much less clear how a natural process could lead to a truncated metacognitive noise distribution. Truncated distributions occur when values outside of the bounds are discarded, which clearly does not apply to confidence ratings. I thus consider truncated distributions as an auxiliary construct at this point that may nevertheless qualify as an approximation to an unknown natural process.</p><p>Finally, there are many candidates of probability distributions that are naturally bounded at zero, perhaps the most prominent one being the lognormal distribution. In addition, I consider the Gamma distribution (<xref ref-type="fig" rid="fig5">Figure 5C</xref>), which has a more pronounced lower tail and is also the connatural counterpart to the Beta distribution for noisy-report models (see next section).</p></sec><sec id="s2-1-7"><title>Metacognitive noise: noisy-report models</title><p>In contrast to noisy-readout models, a noisy-report model assumes that the readout noise of decision values is negligible (<italic>z</italic> = <inline-formula><mml:math id="inf19"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>) and that the dominant source of metacognitive noise occurs at the reporting stage: <italic>c</italic> ∼ f<sub>m</sub>(c). Reporting noise itself may comprise various different sources of noise, occurring for example during the mental translation to an experimental confidence scale or in the form of visuomotor noise (e.g. when using a mouse cursor to indicate a continuous confidence rating).</p><p>A hard constraint for reporting noise is the fact that confidence scales are typically bounded between a minimum and a maximum confidence rating (reflecting the bounds [0; 1] for c in the present model). Reported confidence cannot be outside these bounds, regardless of the magnitude of reporting noise. As in the case of the noisy-readout model, one may consider either censored (<xref ref-type="fig" rid="fig5">Figure 5D</xref>), truncated (<xref ref-type="fig" rid="fig5">Figure 5E</xref>) or naturally bounded distributions (Beta distribution; <xref ref-type="fig" rid="fig5">Figure 5F</xref>) to accommodate this constraint.</p></sec><sec id="s2-1-8"><title>Metacognitive noise as a measure of metacognitive ability</title><p>As outlined above, I assume that metacognitive noise can be described either as variability during readout or report. In both cases, metacognitive noise is governed by the parameter <italic>σ</italic><sub>m</sub>. Higher values of <italic>σ</italic><sub>m</sub> will lead to a flatter relationship between reported confidence and sensory evidence, that is, confidence ratings become more indifferent with regard to different levels of evidence (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>The behavior of the metacognitive noise parameter is closely related to the concept of metacognitive efficiency (<xref ref-type="bibr" rid="bib11">Fleming and Lau, 2014</xref>), a term coined for measures of metacognitive ability that aim at being invariant to type 1 performance (in particular, <italic>M</italic><sub>ratio</sub>). As outlined in the introduction, the type 1 performance independence of <italic>M</italic><sub>ratio</sub> has been contested to some degree, on the basis of empirical data and as well as in simulations that consider the presence of metacognitive noise (<xref ref-type="bibr" rid="bib5">Bang et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Guggenmos, 2021</xref>).</p><p>Here, I was interested in two main questions: can metacognitive noise <italic>σ</italic><sub>m</sub> be truthfully recovered regardless of type 1 performance? And further, to what degree are metacognitive noise <italic>σ</italic><sub>m</sub> and metacognitive efficiency correlated and thus potentially capture similar constructs?</p><p>To assess the type 1 performance dependency, I simulated data with varying levels of sensory noise <italic>σ</italic><sub>s</sub> and five different values of <italic>σ</italic><sub>m</sub>. In each case I computed <italic>M</italic><sub>ratio</sub> on the data and also fitted the model to recover the metacognitive noise parameter <italic>σ</italic><sub>m</sub>. As shown in the left panels of <xref ref-type="fig" rid="fig6">Figure 6A</xref> (noisy-report) and 6B (noisy-readout), <italic>M</italic><sub>ratio</sub> shows a nonlinear dependency with varying type 1 performance levels. While this simulation was based on multiple stimulus levels, a similar nonlinear dependency is also present for a scenario with constant stimuli (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Comparison of <italic>M</italic><sub>ratio</sub> and metacognitive noise <italic>σ</italic><sub>m</sub>.</title><p>Different performance levels were induced by varying the sensory noise of the forward model. Five different levels of metacognitive noise were simulated for a truncated normal noise distribution, covering the range between low and high metacognitive noise. While <italic>M</italic><sub>ratio</sub> showed a nonlinear dependency with varying type 1 performance levels both for (<bold>A</bold>) noisy-report models and (<bold>B</bold>) noisy-readout models, the recovered metacognitive noise parameter <italic>σ</italic><sub>m</sub> was largely independent of type 1 performance. Shaded areas indicate standard deviations across 100 simulated subjects. Right panels: Relationship between metacognitive noise and <italic>M</italic><sub>ratio</sub>. Simulated data were generated with a range of varying metacognitive noise parameters <italic>σ</italic><sub>m</sub> and constant sensory noise (<italic>σ</italic><sub>s</sub> = 0.5; proportion correct responses: 0.82). Computed <italic>M</italic><sub>ratio</sub> values show a clear negative correspondence with <italic>σ</italic><sub>m</sub>, reflecting the fact that metacognitive performance decreases with higher metacognitive noise.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Comparison of <italic>M</italic><sub>ratio</sub> and metacognitive noise <italic>σ</italic><sub>m</sub> for constant stimuli.</title><p>This simulation mirrors the simulations in <xref ref-type="fig" rid="fig6">Figure 6</xref> but is based on only a single stimulus intensity level for both stimulus categories. While parameter recovery improves for the noisy-readout model under the extreme regime of low sensory and high metacognitive noise relative to a scenario with varying stimulus levels (<xref ref-type="fig" rid="fig6">Figure 6</xref>), parameter recovery becomes somewhat more unstable at low type 1 performance levels / high sensory noise.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Type 1 dependency of <italic>M</italic><sub>ratio</sub> and metacognitive noise <italic>σ</italic><sub>m</sub> for various settings of other parameters.</title><p>This simulation mirrors the simulations in <xref ref-type="fig" rid="fig6">Figure 6</xref>, while varying settings for other parameters (as indicated in the title for each column). Changed parameters: sensory threshold <italic>ϑ</italic><sub>s</sub>, sensory bias <italic>δ</italic><sub>s</sub>, multiplicative evidence bias <italic>φ</italic><sub>m</sub>, additive evidence bias <italic>δ</italic><sub>m</sub>, multiplicative confidence bias <italic>λ</italic><sub>m</sub>, additive confidence bias <italic>κ</italic><sub>m</sub>. Note that metacognitive confidence biases are incompatible with a noisy-readout model and hence this combination was omitted.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig6-figsupp2-v1.tif"/></fig></fig-group><p>By contrast, the parameter <italic>σ</italic><sub>m</sub> is recovered without bias across a broad range of type 1 performance levels and at different levels of generative metacognitive noise (<xref ref-type="fig" rid="fig6">Figure 6</xref>, middle panels). The exception is a regime with very high metacognitive noise and low sensory noise under the noisy-readout model, in which recovery becomes biased. A likely reason is related to the inversion of the link function, which is necessary for parameter inference in noisy-readout models (‘Metacognitive level’): since the link function is dependent on sensory noise σ<sub>s</sub>, its inversion becomes increasingly imprecise as <italic>σ</italic><sub>s</sub> approaches very small or very high values. However, apart from these extremal cases under the noisy-readout model, <italic>σ</italic><sub>m</sub> is largely unbiased and is thus a promising candidate to measure metacognitive ability independent of type 1 performance. <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref> shows that this conclusion also holds for various settings of other model parameters.</p><p>Despite the fact that <italic>M</italic><sub>ratio</sub> may not be entirely independent of type 1 performance, it is likely that it captures the metacognitive ability of observers <italic>to some degree</italic>. It is thus interesting to assess the relationship between the model-based measure of metacognitive noise <italic>σ</italic><sub>m</sub> and <italic>M</italic><sub>ratio</sub>. To this aim, I performed a second simulation in which type 1 performance was kept constant (at around 82% correct) by using a fixed sensory noise parameter (<italic>σ</italic><sub>s</sub> = 0.5) while varying the generative metacognitive noise parameter <italic>σ</italic><sub>m</sub>. In addition, <italic>M</italic><sub>ratio</sub> was computed for each simulated observer. As shown in the right panels of <xref ref-type="fig" rid="fig6">Figure 6A and B</xref>, there was indeed a strong negative correlation between <italic>σ</italic><sub>m</sub> and <italic>M</italic><sub>ratio</sub> both for the noisy-report (r = −0.97) and the noisy-readout model (r = −0.91). Of note, a very similar relationship is observed for the unnormalized measure <italic>meta-d</italic>’ (noisy-report: r = −0.97; noisy-readout: r = −0.91). The negative sign of the correlation is expected since a higher degree of noise should lead to more imprecise confidence ratings and thus reduced metacognitive performance.</p></sec></sec><sec id="s2-2"><title>Model fitting</title><p>Model fitting proceeds in a two-stage process. First, parameters of the sensory level are fitted by maximizing the likelihood of the model with respect to the observed type 1 decisions. Second, using the decision values predicted by the sensory level, the parameters of the metacognitive level are fitted by maximizing the likelihood with respect to observed confidence reports. The two levels are thus fitted independently. The reason for the separation of both levels is that choice-based parameter fitting for psychometric curves at the type 1/sensory level is much more established and robust compared to the metacognitive level for which there are more unknowns (e.g. the type of link function or metacognitive noise distribution). Hence, the current model deliberately precludes the possibility that the estimates of sensory parameters are influenced by confidence ratings.</p><p>In the following, the capital letter <italic>D</italic> denotes observed type 1 decisions, and the capital letter <italic>C</italic> denotes observed confidence ratings. The set of parameters of the sensory level is denoted as <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>:=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and the set of parameters of the metacognitive level as <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>:=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><sec id="s2-2-1"><title>Sensory level</title><p>At the sensory level, sensory noise is considered to follow a logistic distribution (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>). The likelihood <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of a particular type 1 decision D for stimulus x has an analytic solution given by the logistic function:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>ϑ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf23"><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (<italic>x; ϑ</italic><sub>s</sub>, <italic>δ</italic><sub>s</sub>) is given by <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. By maximizing the (cumulative) likelihood across trials, estimates for <italic>σ</italic><sub>s</sub>, <italic>ϑ</italic><sub>s</sub>, and <italic>δ</italic><sub>s</sub> are obtained.</p></sec><sec id="s2-2-2"><title>Metacognitive level</title><p>Parameter inference at the metacognitive level requires the output of the sensory level (decision values <italic>y</italic>) and empirical confidence ratings <italic>C</italic>. In addition, if the goal is to compute confidence as probability correct (as assumed here), the estimate of sensory noise <italic>σ</italic><sub>s</sub> is required. By running the model in feed-forward mode and using the fitted sensory parameters, the likelihood of confidence ratings is evaluated either at the stage of readout (noisy-readout model) or report (noisy-report model).</p><p>Special consideration is necessary for the noisy-readout model in which the significant metacognitive noise source is assumed at the level of an unobserved variable − metacognitive evidence. For this reason, the model must be inverted from the point of the observed variable (here confidence ratings) into the space of the latent variable (metacognitive evidence). A consequence of this is that the link function that transforms metacognitive decision values to confidence ratings must be strictly monotonically increasing in the noisy-readout scenario, as model inversion would otherwise be ambiguous.</p><p>Using the link function considered for this work, the tangens hyperbolicus (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>), the inversion is as follows:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mi>π</mml:mi></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Importantly, the likelihood <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of observed confidence ratings <italic>C</italic> given parameters <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> not only depends on the uncertainty of the model prediction for metacognitive decision values <inline-formula><mml:math id="inf26"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (<italic>y</italic>), but also on the uncertainty around the decision values <italic>y</italic> themselves. Computing the likelihood <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> thus requires an integration over the probability density <italic>f</italic><sub>s</sub>(<italic>y</italic>):<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mtext>-</mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∫</mml:mo><mml:mrow/></mml:munder><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Z</mml:mi><mml:mo>∣</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The term <italic>z</italic>*(<italic>y</italic>) is given by <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>.</p><p>In case of the noisy-report model, the likelihood can be directly computed with respect to the observed confidence reports <italic>C</italic>, that is, without inversion of the link function:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mrow><mml:mtext>-</mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mtext mathvariant="fraktur"> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∫</mml:mo><mml:mrow/></mml:munder><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∣</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The term <italic>c</italic>*(<italic>y</italic>) corresponds to the link function in <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>.</p></sec><sec id="s2-2-3"><title>Parameter recovery</title><p>To ensure that the model fitting procedure works as expected and that model parameters are distinguishable, I performed a parameter recovery analysis. To this end, I systematically varied each parameter of a model with metacognitive evidence biases and generated data (see below, for a model with confidence biases). Specifically, each of the six parameters (<italic>σ</italic><sub>s</sub><italic>, ϑ</italic><sub>s</sub>, <italic>δ</italic><sub>s</sub><italic>, σ</italic><sub>m</sub><italic>,φ</italic><sub>m</sub><italic>, δ</italic><sub>m</sub>) was varied in 500 equidistant steps between a sensible lower and upper bound. The model was then fit to each dataset to obtain the recovered parameters.</p><p>To assess the relationship between fitted and generative parameters, I computed linear slopes between each generative parameter (as the independent variable) and each fitted parameter (as the dependent variable), resulting in a 6 × 6 slope matrix. Slopes instead of correlation coefficients were computed, as correlation coefficients are sample-size-dependent and approach 1 with increasing sample size even for tiny linear dependencies. Thus, as opposed to correlation coefficients, slopes quantify the strength of a relationship. To reduce the sensitivity to outliers, slopes were computed using the Theil-Sen method which is based on the median of the slopes of all lines through pairs of points (<xref ref-type="bibr" rid="bib50">Sen, 1968</xref>; <xref ref-type="bibr" rid="bib55">Theil, 1950</xref>). Comparability between the slopes of different parameters is given because (i) slopes are – like correlation coefficients – expected to be 1 if the fitted values precisely recover the true parameter values (i.e. the diagonal of the matrix) and (ii) all parameters have a similar value range which allows for a comparison of off-diagonal slopes at least to some degree.</p><p>To test whether parameter recovery was robust against different settings of the respective other parameters, I performed this analysis for a coarse parameter grid consisting of three different values for each of the six parameters except <italic>σ</italic><sub>m</sub>, for which five different values were considered. This resulted in 3<sup>5</sup>·5<sup>1</sup>=1,215 slope matrices for the entire parameter grid.</p><p><xref ref-type="fig" rid="fig7">Figure 7</xref> shows the result of this analysis both for a noisy-report and a noisy-readout model, expanded along the sensory (<italic>σ</italic><sub>s</sub>) and metacognitive (<italic>σ</italic><sub>m</sub>) noise axis of the coarse parameter grid. Overall, generative and fitted parameters show excellent correspondence, that is, nearly all slopes on the diagonal are close to 1.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Parameter recovery (500 trials per observer).</title><p>Linear dependency between generative parameters and fitted parameters for the six parameters of the noisy-report and noisy-readout model (<italic>σ</italic><sub>s</sub>, <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ϑ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <italic>δ</italic><sub>s</sub>, <italic>σ</italic><sub>m</sub>, <italic>φ</italic><sub>m</sub>, <italic>δ</italic><sub>m</sub>). Linear dependency between generative and fitted parameters was assessed through robust linear slopes. The optimal value for diagonal elements is 1 while off-diagonal elements should be close to zero. Multiple slope matrices were computed for each node of a coarse parameter grid (see text). The figure thus shows average slope matrices, expanded along the coarse parameter grid axes for sensory noise σ<sub>s</sub> and metacognitive noise σ<sub>m</sub>. The row-wise values for σ<sub>s</sub> and the column-wise values for σ<sub>m</sub> indicate the parameter values used for data generation, except when σ<sub>s</sub> or σ<sub>m</sub> where themselves varied.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>The figure mirrors the parameter recovery analysis in <xref ref-type="fig" rid="fig7">Figure 7</xref> with 10,000 instead of 500 trials.</title><p>Sensory parameters: sensory noise <italic>σ</italic><sub>s</sub>, sensory threshold <italic>ϑ</italic><sub>s</sub>, sensory bias <italic>δ</italic><sub>s</sub>. Metacognitive parameters: metacognitive noise <italic>σ</italic><sub>m</sub>, multiplicative evidence bias <italic>φ</italic><sub>m</sub>, additive evidence bias <italic>δ</italic><sub>m</sub>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>The figure mirrors the parameter recovery analysis in <xref ref-type="fig" rid="fig7">Figure 7</xref> for a model with metacognitive confidence biases (<italic>λ</italic><sub>m</sub>, <italic>κ</italic><sub>m</sub>) instead of metacognitive evidence biases and for either 500 or 10,000 trials.</title><p>Note that metacognitive confidence biases are incompatible with a noisy-readout model and hence this combination was omitted. Sensory parameters: sensory noise <italic>σ</italic><sub>s</sub>, sensory threshold <italic>ϑ</italic><sub>s</sub>, sensory bias <italic>δ</italic><sub>s</sub>. Metacognitive parameters: metacognitive noise <italic>σ</italic><sub>m</sub>, multiplicative confidence bias <italic>λ</italic><sub>m</sub>, additive confidence bias <italic>κ</italic><sub>m</sub>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig7-figsupp2-v1.tif"/></fig><fig id="fig7s3" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 3.</label><caption><title>Parameter recovery for a mix of evidence-related and confidence-related metacognitive bias parameters.</title><p>For simplicity and clarity, this figure shows only slope matrices for intermediate levels of sensory (<italic>σ</italic><sub>s</sub> = 0.7) and metacognitive (<italic>σ</italic><sub>m</sub> = 0.2) noise, and for 10,000 trials. Sensory parameters: sensory noise <italic>σ</italic><sub>s</sub>, sensory threshold <italic>ϑ</italic><sub>s</sub>, sensory bias <italic>δ</italic><sub>s</sub>. Metacognitive parameters: metacognitive noise <italic>σ</italic><sub>m</sub>, multiplicative evidence bias <italic>φ</italic><sub>m</sub>, additive evidence bias <italic>δ</italic><sub>m</sub>, multiplicative confidence bias <italic>λ</italic><sub>m</sub>, additive confidence bias <italic>κ</italic><sub>m</sub>. The title displayed over each slope matrix indicates the metacognitive bias parameters that were included in the model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig7-figsupp3-v1.tif"/></fig><fig id="fig7s4" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 4.</label><caption><title>No indication of biases in parameter recovery.</title><p>For these analyses, the sample size was fixed to 10,000 trials. Sensory parameters: sensory noise <italic>σ</italic><sub>s</sub>, sensory threshold <italic>ϑ</italic><sub>s</sub>, sensory bias <italic>δ</italic><sub>s</sub>. At the metacognitive level the model was specified either with evidence-related (middle row) or confidence-related (bottom row) metacognitive bias parameters. Metacognitive parameters: metacognitive noise <italic>σ</italic><sub>m</sub>, multiplicative evidence bias <italic>φ</italic><sub>m</sub>, additive evidence bias <italic>δ</italic><sub>m</sub>, multiplicative confidence bias <italic>λ</italic><sub>m</sub>, additive confidence bias <italic>κ</italic><sub>m</sub>. Note that confidence-based metacognitive bias parameters are incompatible with a noisy-readout model and hence this combination was omitted. Error bars represent mean ± standard deviation. Dashed lines indicate the true values of the parameters. The error bars for the model with metacognitive evidence biases were displaced horizontally by −3% (noisy-report) and +3% (noisy-readout) of the full x-range to avoid mutual occlusion.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig7-figsupp4-v1.tif"/></fig><fig id="fig7s5" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 5.</label><caption><title>Parameter recovery across a range of trial numbers (500 to 10,000).</title><p>Sensory parameters: sensory noise <italic>σ</italic><sub>s</sub>, sensory threshold <italic>ϑ</italic><sub>s</sub>, sensory bias <italic>δ</italic><sub>s</sub>. At the metacognitive level the model was specified either with evidence-related (middle row) or confidence-related (bottom row) metacognitive bias parameters. Metacognitive parameters: metacognitive noise <italic>σ</italic><sub>m</sub>, multiplicative evidence bias <italic>φ</italic><sub>m</sub>, additive evidence bias <italic>δ</italic><sub>m</sub>, multiplicative confidence bias <italic>λ</italic><sub>m</sub>, additive confidence bias <italic>κ</italic><sub>m</sub>. Note that confidence-based metacognitive bias parameters are incompatible with a noisy-readout model and hence this combination was omitted. For simplicity, all parameters of the generative models were set to 0.2. Error bars represent mean ± standard deviation, dashed lines the true parameter value.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig7-figsupp5-v1.tif"/></fig><fig id="fig7s6" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 6.</label><caption><title>Model recovery.</title><p>Data were generated for noisy-readout and noisy-report models with different settings for sensory noise (<italic>σ</italic><sub>s</sub>) and metacognitive noise (<italic>σ</italic><sub>m</sub>). Model recovery was quantified by the frequency/probability with which the data of a particular generative model were best fitted by the noisy-readout and the noisy-report model. Top panel: 10,000 trials per observer. Bottom panel: 500 trials per observer.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig7-figsupp6-v1.tif"/></fig></fig-group><p>Off-diagonal slopes indicate a potential trade-off between different parameters in the fitting procedure. In the present analysis, the only marked trade-off emerges between metacognitive noise <italic>σ</italic><sub>m</sub> and the metacognitive evidence biases (<italic>φ</italic><sub>m</sub><italic>, δ</italic><sub>m</sub>) in the noisy-readout model, under conditions of low sensory noise. In this regime, the multiplicative evidence bias <italic>φ</italic><sub>m</sub> becomes increasingly underestimated and the additive evidence bias <italic>δ</italic><sub>m</sub> overestimated with increasing metacognitive noise. Closer inspection shows that this dependency emerges only when metacognitive noise is high – up to <italic>σ</italic><sub>m</sub>≈ 0.3 no such dependency exists. It is thus a scenario in which there is little true variance in confidence ratings (due to low sensory noise many confidence ratings would be close to 1 in the absence of metacognitive noise), but a lot of measured variance due to high metacognitive noise. It is likely for this reason that parameter inference is problematic. Overall, except for this arguably rare scenario, all parameters of the model are highly identifiable and separable.</p><p>While this analysis was carried out for 500 trials per simulated subject to assess the scenario of a typical metacognition study, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> shows the same analysis with 10,000 trials to give an indication of the theoretical linear dependency structure.</p><p>I repeated the same analysis for a model with metacognitive confidence biases. The result of this analysis shows that also the parameters of a model with metacognitive confidence biases can be accurately recovered (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). In addition, I assessed models that feature a mix of metacognitive evidence and confidence biases (<xref ref-type="fig" rid="fig7s3">Figure 7—figure supplement 3</xref>). The results of these analyses indicate that models with up to three bias parameters show generally good parameter recovery. An exception are models with both confidence bias parameters (<italic>λ</italic><sub>m</sub><italic>, κ</italic><sub>m</sub>) which additionally consider one of the evidence bias parameters (<italic>φ</italic><sub>m</sub> or <italic>δ</italic><sub>m</sub>). For these models, considerable trade-offs between the bias parameters start to emerge. Finally, a model with all four considered metacognitive bias largely fails to recover its bias parameters.</p><p>While the previous analysis indicates overall excellent parameter recovery performance, there nevertheless could be certain biases in parameter recovery that escape a slope-based analysis. To test for such biases, in <xref ref-type="fig" rid="fig7s4">Figure 7—figure supplement 4</xref> I assessed the precise values of recovered parameters across a range of generative parameter values. In all instances, the model precisely recovered the input parameter values, thereby demonstrating the absence of systematic biases.</p><p>Finally, to more systematically assess the precision of parameter recovery in dependence of trial number, I set the value of each generative parameter to 0.2 (arbitrary value) and tested parameter recovery across a range of trial numbers between 500 and 10,000. The results in <xref ref-type="fig" rid="fig7s5">Figure 7—figure supplement 5</xref> provide a reference for the expected precision of parameter estimates in dependence of trial number.</p></sec><sec id="s2-2-4"><title>Model recovery</title><p>One strength of the present modeling framework is that it allows testing whether inefficiencies of metacognitive reports are better described by metacognitive noise at readout (noisy-readout model) or at report (noisy-report model). To validate this type of application, I performed an additional model recovery analysis which tested whether data simulated by either model are also best fitted by the respective model.</p><p><xref ref-type="fig" rid="fig7s6">Figure 7—figure supplement 6</xref> shows that the recovery probability was close to 1 in most cases, thus demonstrating excellent model identifiability. With fewer trials per observer, recovery probabilities decreased expectedly, but were still at a reasonable level. The only edge case with poorer recovery was a scenario with low metacognitive noise and high sensory noise. Model identification is particularly hard in this regime because low metacognitive noise reduces the relevance of the metacognitive noise source, while high sensory noise increases the general randomness of responses.</p></sec></sec><sec id="s2-3"><title>Application to empirical data</title><sec id="s2-3-1"><title>On using the model framework</title><p>The present work does not propose a single specific model of metacognition, but rather provides a flexible framework of possible models and a toolbox to engage in a metacognitive modeling project. Applying the framework to an empirical dataset thus requires a number of user decisions: which metacognitive noise type is likely more dominant? which metacognitive biases should be considered? which link function should be used? These decisions may be guided either by a priori hypotheses of the researcher or can be informed by running a set of candidate models through a statistical model comparison.</p><p>As an exemplary workflow, consider a researcher who is interested in quantifying overconfidence in a confidence dataset with a single parameter to perform a brain-behavior correlation analysis. The concept of under/overconfidence already entails the first modeling choice, as only a link function that quantifies probability correct (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>), i.e. statistical confidence, allows for a meaningful interpretation of metacognitive bias parameters. Moreover, the researcher must decide for a specific metacognitive bias parameter. The researcher may not be interested in biases at the level of the confidence report, but, due to a specific hypothesis, rather at metacognitive biases at the level of readout/evidence, thus leaving a decision between the multiplicative and the additive evidence bias parameter. Also, the researcher may have no idea whether the dominant source of metacognitive noise is at the level of the readout or report. To decide between these options, the researcher computes the evidence (e.g., AIC) for all four combinations and chooses the best-fitting model (ideally, this would be in a dataset independent from the main dataset).</p></sec><sec id="s2-3-2"><title>Application to an example dataset (Shekhar and Rahnev, 2021)</title><p>To test the proposed model on real-world empirical data, I used a data set recently published by <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref> which has a number of advantageous properties for a modeling approach. First, a high number of 2,800 trials were measured for each of the 20 participants, enabling a precise estimate of computational parameters (<xref ref-type="fig" rid="fig7s5">Figure 7—figure supplement 5</xref>). Second, the task design comprised multiple stimulus intensities, which is expected to improve the fit of a process model. And third, participants rated their confidence on a continuous scale. While the model works well with discrete confidence ratings, only continuous confidence scales harness the full expressive power of the model. In each trial, participants indicated whether a Gabor patch imposed on a noisy background was tilted counterclockwise or clockwise from a vertical reference and simultaneously rated their confidence. The average performance was 77.7% correct responses.</p><p><xref ref-type="fig" rid="fig8">Figure 8A</xref> visualizes the overall model fit at the sensory level. The posterior, defined as the probability of choosing <italic>S</italic><sup>+</sup>, closely matched the model fit. The average posterior probability showed a slight x-offset toward higher choice probabilities for <italic>S</italic><sup>+</sup> which was reflected in a positive average sensory bias <italic>δ</italic><sub>s</sub> (group mean ± SEM = 0.06 ± 0.03). Since no stimulus intensities near chance-level performance were presented to participants, a sensory threshold parameter <italic>ϑ</italic><sub>s</sub>was not fitted.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Application of the model to empirical data from <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref> (N=20).</title><p>(<bold>A</bold>) Posterior probability (choice probability for <italic>S</italic><sup>+</sup>) as a function of normalized signed stimulus intensity. Model-based predictions closely follow the empirical data. Means and standard errors across subjects were computed for the three difficulty levels of each stimulus category. The fit is based on a logistic function with a sensory bias parameter <italic>δ</italic><sub>s</sub>. (<bold>B</bold>) Comparison of noisy-readout and noisy-report models featuring different metacognitive noise distributions. Model comparison was based on the Akaike information criterion (AIC) which quantified model evidence at the metacognitive level (the sensory level is identical between models). Error bars indicate standard errors of the mean (SEM). (<bold>C</bold>) Breakdown of best-fitting models across participants. (<bold>D–G</bold>) Inspection of the metacognitive level for the winning model of the type <italic>noisy-report</italic> with a truncated Gumbel noise distribution. (<bold>D</bold>) Empirical confidence is well-fitted by model-based predictions of confidence which are based on an average of 1000 runs of the generative model. Error bars represent SEM. (<bold>E</bold>) Relationship of empirical <italic>M</italic><sub>ratio</sub> and model-based metacognitive noise <italic>σ</italic><sub>m</sub>. (<bold>F</bold>) Partial correlation of the empirical confidence bias the and model-based multiplicative evidence bias <italic>φ</italic><sub>m</sub>. The additive evidence bias was partialed out from the confidence bias. (<bold>G</bold>) Partial correlation of the empirical confidence bias and the model-based additive evidence bias <italic>δ</italic><sub>m</sub>. The multiplicative evidence bias was partialed out from the confidence bias.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig8-v1.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Empirical confidence distributions and generative models of all 20 subjects in <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>.</title><p>Empirical confidence distributions are depicted as gray histograms. Distributions of generative models are depicted as orange line plots for the winning model at the group level (noisy-report+truncated Gumbel) and as green line plots for the winning model at the single-subject level.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig8-figsupp1-v1.tif"/></fig></fig-group><p>At the metacognitive level, I compared noisy-readout and noisy-report models in combination with the metacognitive noise distributions introduced in Result, ‘Metacognitive noise: noisy-readout models’ and ‘Metacognitive noise: noisy-report models’. For this analysis, I considered metacognitive <italic>evidence</italic> biases only (i.e. multiplicative evidence bias <italic>φ</italic><sub>m</sub> and additive evidence bias <italic>δ</italic><sub>m</sub>). The model evidence was computed based on the Akaike information criterion (AIC; <xref ref-type="bibr" rid="bib4">Akaike, 1974</xref>). As shown in <xref ref-type="fig" rid="fig8">Figure 8B</xref>, with the exception of censored distributions, all models performed at a similar level. Seven of the 10 tested models were the winning model for at least one participant (<xref ref-type="fig" rid="fig8">Figure 8C</xref>).</p><p>Interestingly, there were quite clear patterns between the shapes of individual confidence distributions and the respective winning model (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). For instance, a single participant was best described by a noisy-report+Beta model, and indeed the confidence distribution of this participant is quite unique and plausibly could be generated by a Beta noise distribution (participant 7). Participants who were best fitted by noisy-readout models have quite specific confidence distributions with pronounced probability masses at the extremes and very thin coverage at intermediate confidence levels (participants 4–6, 8, 10, 13, 19) − except those, for which the lognormal readout noise distribution was optimal (participants 9 and 11). Finally, two participants were best fitted by a censored distribution (participants 14 and 16), contrary to the general tendency. These participants likewise had fairly idiosyncratic confidence distributions characterized by the combination of a probability mass centered at mid-level confidence ratings and a prominent probability mass at a confidence of 1. While a more detailed analysis of individual differences is beyond the scope of this paper, these examples may point to distinct phenotypes of metacognitive noise.</p><p>In the next step, I inspected the winning metacognitive model (noisy report +truncated Gumbel) in more detail. While the selection of this specific model is arbitrary due to the similar performance of several other models, it serves the illustrative purpose and the differences between these models were overall negligible.</p><p>I first compared confidence ratings predicted by the model with empirical confidence ratings across the range of experimental stimulus intensities. As shown in <xref ref-type="fig" rid="fig8">Figure 8D</xref>, model-predicted confidence tracked behavioral confidence quite well (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). This included a slight confidence bias toward <italic>S</italic><sup>+</sup>, which itself is likely a result of the general sensory bias toward <italic>S</italic><sup>+</sup>.</p><p>I then compared the fitted parameter values of the model with conventional behavioral measures of metacognition. In Results, ‘Metacognitive noise as a measure of metacognitive ability’, a tight inverse relationship between metacognitive efficiency (<italic>M</italic><sub>ratio</sub>) and the metacognitive noise parameter <italic>σ</italic><sub>m</sub> was demonstrated for simulated data. As shown in <xref ref-type="fig" rid="fig8">Figure 8E</xref>, for the empirical data there was likewise a negative relationship, although weaker (r<sub>Pearson</sub> = −0.48, <italic>P</italic> = 0.032). Note that this relationship is by no means self-evident, as <italic>M</italic><sub>ratio</sub> values are based on information that is not available to a process model: <italic>which specific</italic> responses are correct or incorrect. I will elaborate more on this aspect in the discussion, but assert for now that metacognitive efficiency in empirical data can, at least in part, be accounted for by modeling metacognitive noise in a process model.</p><p>As outlined above, the multiplicative evidence bias <italic>φ</italic><sub>m</sub> and the additive evidence bias <italic>δ</italic><sub>m</sub> can be interpreted as metacognitive biases. To assess the validity of these parameters, I computed individual confidence biases by subtracting the participants' objective accuracy from their subjective accuracy (based on confidence ratings). Positive and negative values of this confidence bias are often regarded as evidence for over- and underconfidence. As shown in <xref ref-type="fig" rid="fig8">Figure 8F and G</xref>, both parameters show the expected relationships: higher individual confidence biases are associated with higher values of <italic>δ</italic><sub>m</sub> when controlling for <italic>φ</italic><sub>m</sub> (<italic>r</italic><sub>Partial</sub> = 0.78, p &lt; 0.001), and with <italic>φ</italic><sub>m</sub> when controlling for <italic>δ</italic><sub>m</sub> (<italic>r</italic><sub>Partial</sub> = 0.64, p = 0.003). This analysis confirms that the metacognitive bias parameters of the model meaningfully relate to the over- and underconfidence behavior in empirical data.</p><p>In a final step, I focus on the model fit of a single participant (<xref ref-type="fig" rid="fig9">Figure 9</xref>). The selected participant has a relatively high degree of sensory noise (proportion correct = 0.74; <italic>σ</italic><sub>s</sub> = 1.04) compared to the group mean (proportion correct ± SEM = 0.78 ± 0.01; σ<sub>s</sub> ± SEM = 0.89 ± 0.04), reflected in a relatively flat psychometric curve (<xref ref-type="fig" rid="fig9">Figure 9A</xref>). Like many participants in the dataset, the participant tends to disproportionally choose clockwise/<italic>S</italic><sup>+</sup> over counterclockwise/<italic>S</italic><sup>−</sup>, reflected in a psychometric curve shifted toward <italic>S</italic><sup>+</sup> and hence a positive response bias (<italic>δ</italic><sub>s</sub> = 0.23).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Visualization of a model fit for a single participant from <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>.</title><p>The applied model was a noisy-report model with a metacognitive noise distribution of the type truncated Gumbel and metacognitive <italic>evidence</italic> biases Each stimulus category in <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref> was presented with three intensity levels, corresponding to values of ±1/3, ±2/3, and ±1 in normalized stimulus space (variable <italic>x</italic>). (<bold>A</bold>) Choice probability for <italic>S</italic><sup>+</sup> as a function of stimulus intensity. The positive sensory bias <italic>δ</italic><sub>s</sub> shifts the logistic function toward the left, thereby increasing the choice probability for <italic>S</italic><sup>+</sup>. (<bold>B</bold>) Link function, average confidence ratings and likelihood. The link function was transformed into decision value space <italic>y</italic>, for illustratory purposes. The flat range of the link function is caused by a relatively large additive evidence bias <italic>δ</italic><sub>m</sub>. Confidence ratings from empirical data (gray) and from the generative model (orange) for each stimulus levels <italic>i</italic> are indicated by their mean and standard deviation. Note that these confidence averages derive from the whole range of possible decision values and they are anchored at the most likely decision values <inline-formula><mml:math id="inf29"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> of each stimulus level <italic>i</italic> only for illustratory purposes. The likelihood for confidence ratings is shown only for the most likely decision values <inline-formula><mml:math id="inf30"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> of each stimulus level <italic>i</italic>. (<bold>C</bold>) Confidence distributions and likelihood. Empirical confidence ratings are shown as a histograms and confidence ratings obtained from the generative model as line plots. To visualize the effect of sensory uncertainty on the metacognitive level, likelihood distributions are plotted not only for the most likely values <inline-formula><mml:math id="inf31"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> of the decision value distributions, but also half a standard deviation below (dashed and lighter color) and above (solid and lighter color). The width of likelihood distributions is controlled by the metacognitive noise parameter <italic>σ</italic><sub>m</sub>. Distributions colored in red indicate that a sign flip of decision values has occurred, i.e. responses based on these decision values would be incorrect.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75420-fig9-v1.tif"/></fig><p><xref ref-type="fig" rid="fig9">Figure 9B and C</xref> visualize the results of the metacognitive level, which is again of the type noisy-report+truncated Gumbel. For this participant, the model fit indicates a negative additive evidence bias <italic>δ</italic><sub>m</sub>, thereby introducing a threshold below which stimuli are not metacognitively accessible (indicated by a flat region for the link function in <xref ref-type="fig" rid="fig9">Figure 9B</xref>). This negative additive evidence bias is compensated by a relatively high multiplicative evidence bias <italic>φ</italic><sub>m</sub> = 1.15, resulting in an average confidence of 0.488 that is close to the group average (0.477 ± 0.038).</p><p>While below average in terms of type 1 performance, this participant excels in terms of metacognitive performance. This is both indicated by a high <italic>M</italic><sub>ratio</sub> of 1.23 (group mean ± SEM = 0.88 ± 0.05) and a low metacognitive noise parameter <italic>σ</italic><sub>m</sub> of 0.06 (group mean ± SEM = 0.10 ± 0.02).</p><p>It is important to note that a low metacognitive noise parameter <italic>σ</italic><sub>m</sub> does not imply that the participants’ confidence ratings are expected to be within a narrow range for each specific stimulus intensity. This is because the uncertainty of the sensory level translates to the metacognitive level: the width of decision value distributions, as determined by sensory noise <italic>σ</italic><sub>s</sub>, also affects the expected width of downstream confidence distributions. Indeed, the behavioral confidence distributions in <xref ref-type="fig" rid="fig9">Figure 9C</xref> are spread out across the entire confidence range for all difficulty levels. In <xref ref-type="fig" rid="fig9">Figure 9C</xref> this aspect is emphasized by not only showing the confidence likelihood for the most likely decision value <inline-formula><mml:math id="inf32"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> of each stimulus level <italic>i</italic>, but also for sensory decision values 0.5 standard deviations below and above <inline-formula><mml:math id="inf33"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> .</p><p>Note that when considering decision values 0.5 standard deviations above <inline-formula><mml:math id="inf34"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> , a sign flip occurs for the two lower stimulus intensities of <italic>S</italic><sup>−</sup> (indicated with likelihood distributions shaded in red). In these cases, the participant would make an incorrect choice. Moreover, the two lower stimulus intensities of <italic>S</italic><sup>−</sup> show a well-known characteristic of statistical confidence: an increase of confidence for incorrect choices as stimulus difficulty increases (<xref ref-type="bibr" rid="bib49">Sanders et al., 2016</xref>).</p><p>To compare the empirical confidence distribution of this participant with the distribution predicted by the model, the parameters in the generative model were set to their corresponding fitted values and sampled confidence ratings. The average predicted confidence ratings (<xref ref-type="fig" rid="fig9">Figure 9B</xref>, orange error bars) and the density histograms (<xref ref-type="fig" rid="fig9">Figure 9C</xref>, orange line plots) obtained from this sampling procedure demonstrate a close fit with the participant’s confidence rating distributions. This close correspondence is not limited to this particular participant. As shown in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>, a generative model described by <italic>σ</italic><sub>m</sub>, <italic>δ</italic><sub>m</sub> and <italic>φ</italic><sub>m</sub> is able to approximate a wide range of idiosyncratic empirical confidence distributions.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The present work introduces and evaluates a process model of metacognition and the accompanying toolbox <italic>ReMeta</italic> (see Materials and methods). The model connects key concepts in metacognition research − metacognitive readout, metacognitive biases, metacognitive noise − with the goal of providing an account of human metacognitive responses. The model can be directly applied to confidence datasets of any perceptual or non-perceptual modality.</p><p>As any cognitive computational model, the model can serve several purposes such as inference about model parameters, inference about latent variables and as a means to generate artificial data. In the present work, I focused on parameter inference, in particular metacognitive parameters describing metacognitive noise (<italic>σ</italic><sub>m</sub>) and metacognitive biases (<italic>φ</italic><sub>m</sub>, <italic>δ</italic><sub>m</sub>, <italic>λ</italic><sub>m</sub>, <italic>κ</italic><sub>m</sub>). Indeed, I would argue that this use case is one of the most pressing issues in metacognition research: parametrically characterizing the latent processes underlying human confidence reports without the confound of type 1 behavior that hampers descriptive approaches.</p><p>In the context of metacognitive biases, I have shown that the conventional method of simply comparing objective and subjective performance (via confidence ratings) is flawed not only because it is biased toward overconfidence, but also because it is strongly dependent on type 1 performance. Just as in the case of metacognitive performance, unbiased inferences about metacognitive biases thus require a process model approach.</p><p>Here, I introduced four metacognitive bias parameters loading either on metacognitive evidence or the confidence report. As shown through the simulation of calibration curves, all bias parameters can yield under- or overconfidence relative to a bias-free observer. The fact that the calibration curves and the relationships between type 1 performance and confidence biases are quite distinct between the proposed metacognitive bias parameters may indicate that these are to some degree dissociable. Moreover, in an empirical dataset the multiplicative evidence bias <italic>φ</italic><sub>m</sub> and the additive evidence bias <italic>δ</italic><sub>m</sub> strongly correlated with a conventional confidence bias measure, thereby validating these parameters.</p><p>The second kind of metacognitive parameter considered in this work is metacognitive noise (<xref ref-type="bibr" rid="bib40">Mueller and Weidemann, 2008</xref>; <xref ref-type="bibr" rid="bib25">Jang et al., 2012</xref>; <xref ref-type="bibr" rid="bib7">De Martino et al., 2013</xref>; <xref ref-type="bibr" rid="bib56">van den Berg et al., 2017</xref>; <xref ref-type="bibr" rid="bib5">Bang et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref>). As with metacognitive biases, metacognitive noise may arise at different stages of the processing hierarchy and in the present work I investigated two kinds: noise at readout and report. Both parameters affect the precision of confidence ratings and as a result they showed an expected negative relationship with regular measures of metacognitive ability (<italic>meta-d’</italic>, <italic>M</italic><sub>ratio</sub>). Importantly, I show that while even <italic>M</italic><sub>ratio</sub>, a measure normalized for type 1 performance, was dependent on type 1 performance for simulated data, recovered estimates of metacognitive noise were largely invariant to type 1 performance. Thus, just as in the case of metacognitive biases, the entanglement of metacognitive and type 1 behavior can be unraveled by means of a process model approach.</p><p>While this summary so far emphasized the advantages of a process model approach to metacognition, there are a number of remaining challenges. First, it is entirely possible that a comprehensive model of metacognition is non-invertible from the point of confidence ratings. This challenge is exemplified by the noisy-readout model, for which the inversion requires a strictly monotonically increasing link function. To achieve unbiased parameter inferences, one would need additional observed measures along the processing hierarchy. For instance, reaction time could be considered an implicit proxy for confidence, which is affected by readout noise but not by reporting noise. Conditional on finding an appropriate functional relationship to metacognitive evidence, reaction times could allow for an unbiased inference of metacognitive readout noise or metacognitive evidence bias parameters.</p><p>Second, the effects of different sources of bias and noise along the processing hierarchy may be so strongly correlated that their dissociation would require unrealistic amounts of confidence data. This dissociation, however, is essential for many research questions in metacognition − whether the goal is to derive a fundamental model of human metacognition or whether one is interested in specific abberrancies in mental illness. An example for the latter is the frequent observation of overconfidence in schizophrenia which is thought to reflect a more general deficit in the ability to integrate disconfirmatory evidence (<xref ref-type="bibr" rid="bib54">Speechley et al., 2010</xref>; <xref ref-type="bibr" rid="bib59">Zawadzki et al., 2012</xref>) and may underlie the maintenance of delusional beliefs (<xref ref-type="bibr" rid="bib37">Moritz and Woodward, 2006b</xref>). To investigate this specific hypothesis, it is central to dissociate whether metacognitive biases mainly apply at the reporting stage − which may be a result of the disease − or at an earlier metacognitive processing stage, which may be involved in the development of the disease. This issue likewise could be addressed by measuring behavioral, physiological or neurobiological processes that precede the report of confidence.</p><p>Third, the demonstration of an unbiased recovery of metacognitive noise and bias parameters in a process model approach comes with a strong caveat, since the data is generated with the very same model that is used for parameter recovery. Yet, all models are wrong, starts a famous saying, and this certainly applies to current models of metacognition. The question is thus: given the unknown true model that underlies empirical confidence ratings, to what degree can parameters obtained from an approximated model be considered unbiased? The way forward here is to continuously improve computational models of metacognition in terms of model evidence, thus increasing the chances that fitted parameters are meaningful estimates of the true parameters.</p><p>With respect to previous modeling work, a recent paper by <xref ref-type="bibr" rid="bib52">Shekhar and Rahnev, 2021</xref> deserves special attention. Here too, the authors adopted a process model approach for metacognition with the specific goal of deriving a measure of metacognitive ability, quite similar to the metacognitive noise parameter <italic>σ</italic><sub>m</sub> in this work. One key difference is that Shekhar and Rahnev tailored their model to discrete confidence scales, such that each possible confidence rating (for each choice option) is associated with a separately fitted confidence criterion (as notable precursor of this idea is <xref ref-type="bibr" rid="bib1">Adler and Ma, 2018a</xref>). This introduces maximal flexibility, as essentially arbitrary mappings from internal evidence to confidence can be fitted. In addition, it requires minimal assumptions about the link functions that underlies the computation of confidence, apart from an ordering constraint applied to the criteria.</p><p>However, while this flexibility is a strength, it also comes at certain costs. One issue is the relatively large number of parameters that have to be fitted. Shekhar and Rahnev note that the MLE procedures for the fitting of confidence criteria often got stuck in local minima. Rather than via MLE, confidence criteria were thus fitted by matching the expected proportion of high confidence trials to the observed proportion for each criterion. It is thus not guaranteed that the obtained confidence criterions indeed maximize the likelihood under the data. Furthermore, to make a criterion-based model compatible with data from a continuous confidence scale, confidence reports have to be discretized. Apart from the loss of information associated with discretization, this introduces uncertainty as to how exactly the data should be binned (e.g. equinumerous versus equidistant). Another aspect worth mentioning is that a criterion-based approach effectively corresponds to a stepwise link function, which is not invertible. Making inferences about readout noise thus poses a challenge to such criterion-based models.</p><p>In the present work, I assumed a mapping between internal evidence and confidence that can be described by a parametric link function. This too comes with advantages and disadvantages. On the one hand, a parametric link function naturally imposes strong constraints on the mapping between internal evidence and confidence. In reality, this mapping might not conform to any simple function − and even if it did, different observers might apply different functions. On the other hand, imposing a specific link function can be seen as a form of regularization when statistical power is insufficient to constrain a large number of individual criteria. Further, a parametric link function does not need to worry about the discretization of confidence ratings, while still being compatible with a priori discretized ratings. Finally, a meaningful inference about metacognitive biases requires a parametric link function which computes the subjective probability of being correct (as in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>).</p><p>The process model approach deviates in an important way from standard analyses of confidence reports based on the type 2 receiver operating curve. As type 2 ROC analyses are solely based on stimulus-specific type 1 and type 2 responses, they do not consider one of the arguably most important factors in this context: stimulus intensity. This implies that such measures cannot dissociate to what degree variability in confidence ratings is based on stimulus variability or on internal noise. In contrast, since a process model specifies the exact transformation from stimulus intensity to decision variable to confidence, this source of variance is appropriately taken into account. The metacognitive noise parameter <italic>σ</italic><sub>m</sub> introduced here is thus a measure of the <italic>unexpected</italic> variability of confidence ratings, after accounting for the variability on the stimulus side. Note that such stimulus variability is typically present even in designs with intended constant stimulus difficulty, due to the involvement of randomness in the generation of unique trial-by-trial stimuli. In many cases, the <italic>effective</italic> stimulus difficulty (i.e. including this random component of stimulus variability) can likewise be quantified using appropriate feature-based energy detectors (see e.g. <xref ref-type="bibr" rid="bib19">Guggenmos et al., 2016</xref>).</p><p>The process model approach bears another important difference compared with type 2 ROC analyses, in this case a limiting factor on the side of the process model. As the area under the type 2 ROC quantifies to what degree confidence ratings discriminate between correct and incorrect responses, it is important to recognize what valuable piece of information the correctness of a <italic>specific</italic> response is. Over and above stimulus intensity, the correctness of a response will typically be influenced by negative factors such as attentional lapses, finger errors, tiredness, and positive factors such as phases of increased motivation or concentration. All of these factors not only influence type 1 performance, but they also influence the type 2 response that one would expect from an ideal metacognitive observer. Analyses of type 2 ROCs implicitly make use of this information insofar as they consider the correctness of each individual response.</p><p>In contrast, the information about the objective trial-by-trial accuracy is not available in a process model. The signal that enters the metacognitive level of the process model is based only on information that was accessible to the observer (in particular, sensory decision variables), but not based on the correctness of specific choices, which is only accessible to the experimenter. Note that this is not a limitation specific to the present model, but the nature of process models in general. Improving process models in this regard requires additional measurements that reflect knowledge of the observer, such as subjective reports of attentional lapses or finger errors.</p><p>In sum, while a type 2 ROC analysis – as a descriptive approach – does not allow any conclusions about the causes of metacognitive inefficiency, it is able to capture a more thorough picture of metacognitive sensitivity: that is, it quantifies metacognitive awareness not only about one’s own sensory noise, but also about other potential sources of error (attentional lapses, finger errors, etc.). While it cannot distinguish between these sources, it captures them all. On the other hand, only a process model approach will allow to draw specific conclusions about mechanisms – and pin down sources – of metacognitive inefficiency, which arguably is of major importance in many applications.</p><p>Finally, how does the present model relate to the recent discussion between Bayesian and Non-Bayesian models of confidence (<xref ref-type="bibr" rid="bib3">Aitchison et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Sanders et al., 2016</xref>; <xref ref-type="bibr" rid="bib1">Adler and Ma, 2018a</xref>)? A Bayesian observer of the (inner) world is one who maintains a posterior probability density over possible states of that world. In particular, computing confidence for such an observer corresponds to integrating the posterior over all possible states for which the type 1 choice would be correct. In this sense, the model proposed here with the link function provided in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> corresponds to a Bayesian observer, albeit one that can be susceptible to metacognitive biases and to additional sources of metacognitive noise. Thus, while the observer is Bayesian in nature, it may not be Bayes optimal. At the same time, the framework and the toolbox are flexible to allow for ‘non-Bayesian’ link functions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) that could represent certain idiosyncratic heuristics and shortcuts inherent to human confidence judgements. Of note, the model proposed here does not consider prior distributions over the stimulus categories (see e.g. <xref ref-type="bibr" rid="bib1">Adler and Ma, 2018a</xref>). Instead, it is assumed that the observer considers both stimulus categories equally likely which is considered a reasonable assumption if stimulus categories are balanced.</p><sec id="s3-1"><title>Conclusion</title><p>The model outlined in this paper casts confidence as a noisy and potentially biased transformation of sensory decision values. The model parameters that shape this transformation provide a rich account of human metacognitive inefficiencies and metacognitive biases. In particular, I hope that the underlying framework will allow a systematic model comparison in future confidence datasets to elucidate sources of metacognitive noise, to narrow down candidate noise distributions and to differentiate between different kinds of metacognitive biases. The accompanying toolbox <italic>ReMeta</italic> provides a platform for such investigations.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>The <italic>ReMeta</italic> toolbox</title><p>The code underlying this work has been bundled in a user-friendly Python toolbox (<italic>ReMeta</italic>) which is published alongside this paper at <ext-link ext-link-type="uri" xlink:href="https://github.com/m-guggenmos/remeta">https://github.com/m-guggenmos/remeta</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ce43bc78c8d5113b878408e0e2d2520c8595a802;origin=https://github.com/m-guggenmos/remeta;visit=swh:1:snp:8f7bcfafda79ee859399a1a11573d8e97f5b8b1d;anchor=swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2">swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2</ext-link>; <xref ref-type="bibr" rid="bib21">Guggenmos, 2022</xref>). While its core is identical to the framework outlined here, it offers a variety of additional parameters and settings. In particular, it allows fitting separate values for each parameter depending on the sign of the stimulus (for sensory parameters) or the decision value (for metacognitive parameters). Moreover, it offers various choices for noise distributions and link functions, including criterion-based link functions.</p><p>The <italic>ReMeta</italic> toolbox has a simplified interface such that in the most basic case it requires only three 1-d arrays as input: stimuli, choices and confidence. The output is a structure containing the fitted parameters, information about the goodness of fit (log-likelihood, AIC, BIC, correlation between empirical confidence ratings and ratings from a generative model) and trial-by-trial arrays of latent variables (e.g. decision values, metacognitive evidence). The toolbox is highly configurable − in particular, each parameter can be disabled, enabled, or enabled in duplex mode (i.e. sign-dependent, see above).</p><p>Parameter fitting minimizes the negative log-likelihood of type 1 choices (sensory level) or type 2 confidence ratings (metacognitive level). For the sensory level, initial guesses for the fitting procedure were found to be of minor importance and are set to reasonable default values. Data are fitted with a gradient-based optimization method (<italic>Sequential Least Squares Programming</italic>; <xref ref-type="bibr" rid="bib28">Kraft, 1988</xref>). However, if enabled, the sensory threshold parameter can introduce a discontinuity in the psychometric function, thereby violating the assumptions of gradient methods. In this case, an additional gradient-free method (<italic>Powell’s method</italic>; <xref ref-type="bibr" rid="bib44">Powell, 1964</xref>) is used and the estimate with the lower negative log-likelihood is chosen. Both parameter fitting procedures respect lower and upper bounds for each parameter.</p><p>Since parameters of the metacognitive level were found to be more variable, subject-specific initial values for the fitting procedure are of greater importance. For this reason, an initial coarse grid-search with parameter-specific grid points is performed to determine suitable initial values, which are subsequently used for a gradient-based optimization routine (<italic>Sequential Least Squares Programming</italic>). Here too, lower and upper bounds are respected for each parameter.</p><p>The toolbox has optional settings to invoke an additional fine-grained grid-search and an explicit global optimization routine (<italic>Basin-hopping</italic>; <xref ref-type="bibr" rid="bib57">Wales and Doye, 1997</xref>), both of which are computationally considerably more expensive. Exploratory tests showed that these methods were not necessary for parameter estimation on either simulated or empirical data in this work; however, this may be different for other empirical datasets.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-75420-transrepform1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data used for model validation (Shekhar and Rahnev, 2021) was made publicly available by the original authors at <ext-link ext-link-type="uri" xlink:href="https://osf.io/s8fnb/">https://osf.io/s8fnb/</ext-link>.</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Shekhar</surname><given-names>M</given-names></name><name><surname>Rahnev</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>The nature of metacognitive inefficiency in perceptual decision making</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/s8fnb/">s8fnb</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This research was funded by the German Research Foundation (grant GU 1845/1-1). I’m grateful to the lab of Elisa Filevich for helpful input and critical discussion. Computation has been performed on the HPC for Research cluster of the Berlin Institute of Health.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adler</surname><given-names>WT</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2018">2018a</year><article-title>Comparing bayesian and non-bayesian accounts of human confidence reports</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006572</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006572</pub-id><pub-id pub-id-type="pmid">30422974</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adler</surname><given-names>WT</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2018">2018b</year><article-title>Limitations of proposed signatures of bayesian confidence</article-title><source>Neural Computation</source><volume>30</volume><fpage>3327</fpage><lpage>3354</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01141</pub-id><pub-id pub-id-type="pmid">30314423</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aitchison</surname><given-names>L</given-names></name><name><surname>Bang</surname><given-names>D</given-names></name><name><surname>Bahrami</surname><given-names>B</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Doubly bayesian analysis of confidence in perceptual decision-making</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>1004519</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004519</pub-id><pub-id pub-id-type="pmid">26517475</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akaike</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>A new look at the statistical model identification</article-title><source>IEEE Transactions on Automatic Control</source><volume>19</volume><fpage>716</fpage><lpage>723</lpage><pub-id pub-id-type="doi">10.1109/TAC.1974.1100705</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bang</surname><given-names>JW</given-names></name><name><surname>Shekhar</surname><given-names>M</given-names></name><name><surname>Rahnev</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sensory noise increases metacognitive efficiency</article-title><source>Journal of Experimental Psychology. General</source><volume>148</volume><fpage>437</fpage><lpage>452</lpage><pub-id pub-id-type="doi">10.1037/xge0000511</pub-id><pub-id pub-id-type="pmid">30382720</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname><given-names>FR</given-names></name><name><surname>Birdsall</surname><given-names>TG</given-names></name><name><surname>Tanner</surname><given-names>WP</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Two types of roc curves and definitions of parameters</article-title><source>The Journal of the Acoustical Society of America</source><volume>31</volume><fpage>629</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1121/1.1907764</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname><given-names>B</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Garrett</surname><given-names>N</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Confidence in value-based choice</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>105</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/nn.3279</pub-id><pub-id pub-id-type="pmid">23222911</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosher</surname><given-names>BA</given-names></name><name><surname>Lu</surname><given-names>ZL</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Perceptual learning reflects external noise filtering and internal noise reduction through channel reweighting</article-title><source>PNAS</source><volume>95</volume><fpage>13988</fpage><lpage>13993</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.23.13988</pub-id><pub-id pub-id-type="pmid">9811913</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Becoming confident in the statistical nature of human confidence judgments</article-title><source>Neuron</source><volume>90</volume><fpage>425</fpage><lpage>427</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.023</pub-id><pub-id pub-id-type="pmid">27151633</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fieker</surname><given-names>M</given-names></name><name><surname>Moritz</surname><given-names>S</given-names></name><name><surname>Köther</surname><given-names>U</given-names></name><name><surname>Jelinek</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Emotion recognition in depression: An investigation of performance and response confidence in adult female patients with depression</article-title><source>Psychiatry Research</source><volume>242</volume><fpage>226</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1016/j.psychres.2016.05.037</pub-id><pub-id pub-id-type="pmid">27294796</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>S</given-names></name><name><surname>Lau</surname><given-names>HC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>How to measure metacognition</article-title><source>Frontiers in Human Neuroscience</source><volume>8</volume><elocation-id>443</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2014.00443</pub-id><pub-id pub-id-type="pmid">25076880</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Self-evaluation of decision-making: A general Bayesian framework for metacognitive computation</article-title><source>Psychological Review</source><volume>124</volume><fpage>91</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1037/rev0000045</pub-id><pub-id pub-id-type="pmid">28004960</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleur</surname><given-names>DS</given-names></name><name><surname>Bredeweg</surname><given-names>B</given-names></name><name><surname>van den Bos</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Metacognition: ideas and insights from neuro- and educational sciences</article-title><source>NPJ Science of Learning</source><volume>6</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1038/s41539-021-00089-5</pub-id><pub-id pub-id-type="pmid">34103531</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>T</given-names></name><name><surname>Koutstaal</surname><given-names>W</given-names></name><name><surname>Fu</surname><given-names>CHY</given-names></name><name><surname>Poon</surname><given-names>L</given-names></name><name><surname>Cleare</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Depression, confidence, and decision: Evidence against depressive realism</article-title><source>Journal of Psychopathology and Behavioral Assessment</source><volume>27</volume><fpage>243</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1007/s10862-005-2404-x</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>T</given-names></name><name><surname>Koutstaal</surname><given-names>W</given-names></name><name><surname>Poon</surname><given-names>L</given-names></name><name><surname>Cleare</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Confidence judgment in depression and dysphoria: the depressive realism vs. negativity hypotheses</article-title><source>Journal of Behavior Therapy and Experimental Psychiatry</source><volume>43</volume><fpage>699</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1016/j.jbtep.2011.09.014</pub-id><pub-id pub-id-type="pmid">22071004</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fullerton</surname><given-names>GS</given-names></name><name><surname>Cattell</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1892">1892</year><source>On the Perception of Small Differences, with Special Reference to the Extent, Force, and Time of Movement</source><publisher-name>University of Pennsylvania Press</publisher-name><pub-id pub-id-type="doi">10.1037/14119-000</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galvin</surname><given-names>SJ</given-names></name><name><surname>Podd</surname><given-names>JV</given-names></name><name><surname>Drga</surname><given-names>V</given-names></name><name><surname>Whitmore</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Type 2 tasks in the theory of signal detectability: discrimination between correct and incorrect decisions</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>10</volume><fpage>843</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.3758/bf03196546</pub-id><pub-id pub-id-type="pmid">15000533</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gigerenzer</surname><given-names>G</given-names></name><name><surname>Hoffrage</surname><given-names>U</given-names></name><name><surname>Kleinbölting</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Probabilistic mental models: A Brunswikian theory of confidence</article-title><source>Psychological Review</source><volume>98</volume><fpage>506</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.98.4.506</pub-id><pub-id pub-id-type="pmid">1961771</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guggenmos</surname><given-names>M</given-names></name><name><surname>Wilbertz</surname><given-names>G</given-names></name><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mesolimbic confidence signals guide perceptual learning in the absence of external feedback</article-title><source>eLife</source><volume>5</volume><elocation-id>e13388</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13388</pub-id><pub-id pub-id-type="pmid">27021283</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Guggenmos</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Validity and Reliability of Metacognitive Performance Measures</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/nc/niab040</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Guggenmos</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Remeta</data-title><version designator="swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2">swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ce43bc78c8d5113b878408e0e2d2520c8595a802;origin=https://github.com/m-guggenmos/remeta;visit=swh:1:snp:8f7bcfafda79ee859399a1a11573d8e97f5b8b1d;anchor=swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2">https://archive.softwareheritage.org/swh:1:dir:ce43bc78c8d5113b878408e0e2d2520c8595a802;origin=https://github.com/m-guggenmos/remeta;visit=swh:1:snp:8f7bcfafda79ee859399a1a11573d8e97f5b8b1d;anchor=swh:1:rev:43ccbf2e35b1e934dab83e156e4fbb22ac160cd2</ext-link></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Sanders</surname><given-names>JI</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A mathematical framework for statistical decision confidence</article-title><source>Neural Computation</source><volume>28</volume><fpage>1840</fpage><lpage>1858</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00864</pub-id><pub-id pub-id-type="pmid">27391683</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Confidence in judgment</article-title><source>Trends in Cognitive Sciences</source><volume>1</volume><fpage>78</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(97)01014-0</pub-id><pub-id pub-id-type="pmid">21223868</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoven</surname><given-names>M</given-names></name><name><surname>Lebreton</surname><given-names>M</given-names></name><name><surname>Engelmann</surname><given-names>JB</given-names></name><name><surname>Denys</surname><given-names>D</given-names></name><name><surname>Luigjes</surname><given-names>J</given-names></name><name><surname>van Holst</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Abnormalities of confidence in psychiatry: an overview and future perspectives</article-title><source>Translational Psychiatry</source><volume>9</volume><elocation-id>268</elocation-id><pub-id pub-id-type="doi">10.1038/s41398-019-0602-7</pub-id><pub-id pub-id-type="pmid">31636252</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jang</surname><given-names>Y</given-names></name><name><surname>Wallsten</surname><given-names>TS</given-names></name><name><surname>Huber</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A stochastic detection and retrieval model for the study of metacognition</article-title><source>Psychological Review</source><volume>119</volume><fpage>186</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1037/a0025960</pub-id><pub-id pub-id-type="pmid">22059901</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khalvati</surname><given-names>K</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Rao</surname><given-names>RPN</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Bayesian inference with incomplete knowledge explains perceptual confidence and its deviations from accuracy</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>5704</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-25419-4</pub-id><pub-id pub-id-type="pmid">34588440</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Köther</surname><given-names>U</given-names></name><name><surname>Veckenstedt</surname><given-names>R</given-names></name><name><surname>Vitzthum</surname><given-names>F</given-names></name><name><surname>Roesch-Ely</surname><given-names>D</given-names></name><name><surname>Pfueller</surname><given-names>U</given-names></name><name><surname>Scheu</surname><given-names>F</given-names></name><name><surname>Moritz</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>“Don’t give me that look” - overconfidence in false mental state perception in schizophrenia</article-title><source>Psychiatry Research</source><volume>196</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.psychres.2012.03.004</pub-id><pub-id pub-id-type="pmid">22482796</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kraft</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1988">1988</year><source>A Software Package for Sequential Quadratic Programming</source><publisher-name>German Aerospace Center</publisher-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lichtenstein</surname><given-names>S</given-names></name><name><surname>Fischhoff</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1977">1977a</year><article-title>Do those who know more also know more about how much they know?</article-title><source>Organizational Behavior and Human Performance</source><volume>20</volume><fpage>159</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1016/0030-5073(77)90001-0</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lichtenstein</surname><given-names>S</given-names></name><name><surname>Fischhoff</surname><given-names>B</given-names></name><name><surname>Phillips</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1977">1977b</year><chapter-title>Calibration of probabilities: the state of the art</chapter-title><person-group person-group-type="editor"><name><surname>Jungermann</surname><given-names>H</given-names></name><name><surname>De Zeeuw</surname><given-names>G</given-names></name></person-group><source>Decision Making and Change in Human Affairs. Theory and Decision Library</source><publisher-loc>Dordrecht</publisher-loc><publisher-name>Springer</publisher-name><fpage>275</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.1007/978-94-010-1276-8_19</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lichtenstein</surname><given-names>S</given-names></name><name><surname>Fischhoff</surname><given-names>B</given-names></name><name><surname>Phillips</surname><given-names>LD</given-names></name></person-group><year iso-8601-date="1982">1982</year><chapter-title>Calibration of probabilities: the state of the art to 1980</chapter-title><person-group person-group-type="editor"><name><surname>Kahnemann</surname><given-names>D</given-names></name><name><surname>Slovic</surname><given-names>P</given-names></name><name><surname>Tversky</surname><given-names>A</given-names></name></person-group><source>Judgment under Uncertainty</source><publisher-name>Cambridge University Press</publisher-name><fpage>306</fpage><lpage>334</lpage></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</article-title><source>Consciousness and Cognition</source><volume>21</volume><fpage>422</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2011.09.021</pub-id><pub-id pub-id-type="pmid">22071269</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><chapter-title>Signal Detection Theory Analysis of Type 1 and Type 2 Data: Meta-d0, Response- Specific Meta-d0, and the Unequal Variance SDT Model</chapter-title><person-group person-group-type="editor"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><source>The Cognitive Neuroscience of Metacognition</source><publisher-name>Springer-Verlag Publishing</publisher-name><fpage>25</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-45190-4_3</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The signal processing architecture underlying subjective reports of sensory awareness</article-title><source>Neuroscience of Consciousness</source><volume>2016</volume><elocation-id>niw002</elocation-id><pub-id pub-id-type="doi">10.1093/nc/niw002</pub-id><pub-id pub-id-type="pmid">27499929</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merkle</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The disutility of the hard-easy effect in choice confidence</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>16</volume><fpage>204</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.3758/PBR.16.1.204</pub-id><pub-id pub-id-type="pmid">19145033</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moritz</surname><given-names>S</given-names></name><name><surname>Woodward</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="2006">2006a</year><article-title>Metacognitive control over false memories: A key determinant of delusional thinking</article-title><source>Current Psychiatry Reports</source><volume>8</volume><fpage>184</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1007/s11920-006-0022-2</pub-id><pub-id pub-id-type="pmid">19817068</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moritz</surname><given-names>S</given-names></name><name><surname>Woodward</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="2006">2006b</year><article-title>The contribution of metamemory deficits to schizophrenia</article-title><source>Journal of Abnormal Psychology</source><volume>115</volume><fpage>15</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1037/0021-843X.15.1.15</pub-id><pub-id pub-id-type="pmid">16492092</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moritz</surname><given-names>S</given-names></name><name><surname>Ramdani</surname><given-names>N</given-names></name><name><surname>Klass</surname><given-names>H</given-names></name><name><surname>Andreou</surname><given-names>C</given-names></name><name><surname>Jungclaussen</surname><given-names>D</given-names></name><name><surname>Eifler</surname><given-names>S</given-names></name><name><surname>Englisch</surname><given-names>S</given-names></name><name><surname>Schirmbeck</surname><given-names>F</given-names></name><name><surname>Zink</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Overconfidence in incorrect perceptual judgments in patients with schizophrenia</article-title><source>Schizophrenia Research. Cognition</source><volume>1</volume><fpage>165</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1016/j.scog.2014.09.003</pub-id><pub-id pub-id-type="pmid">29379749</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moritz</surname><given-names>S</given-names></name><name><surname>Lysaker</surname><given-names>PH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Metacognition research in psychosis: Uncovering and adjusting the prisms that distort subjective reality</article-title><source>Schizophrenia Bulletin</source><volume>45</volume><fpage>17</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1093/schbul/sby151</pub-id><pub-id pub-id-type="pmid">30351363</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mueller</surname><given-names>ST</given-names></name><name><surname>Weidemann</surname><given-names>CT</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Decision noise: an explanation for observed violations of signal detection theory</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>15</volume><fpage>465</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.3758/pbr.15.3.465</pub-id><pub-id pub-id-type="pmid">18567246</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>TO</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>A comparison of current measures of the accuracy of feeling-of-knowing predictions</article-title><source>Psychological Bulletin</source><volume>95</volume><fpage>109</fpage><lpage>133</lpage><pub-id pub-id-type="pmid">6544431</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pierce</surname><given-names>CS</given-names></name><name><surname>Jastrow</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1885">1885</year><article-title>On small differences of sensation</article-title><source>Memoirs of the National Academy of Sciences</source><volume>3</volume><fpage>73</fpage><lpage>83</lpage></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollack</surname><given-names>I</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>On indices of signal and response discriminability</article-title><source>The Journal of the Acoustical Society of America</source><volume>31</volume><elocation-id>1031</elocation-id><pub-id pub-id-type="doi">10.1121/1.1907802</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Powell</surname><given-names>MJD</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>An efficient method for finding the minimum of a function of several variables without calculating derivatives</article-title><source>The Computer Journal</source><volume>7</volume><fpage>155</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1093/comjnl/7.2.155</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahnev</surname><given-names>D</given-names></name><name><surname>Desender</surname><given-names>K</given-names></name><name><surname>Lee</surname><given-names>ALF</given-names></name><name><surname>Adler</surname><given-names>WT</given-names></name><name><surname>Aguilar-Lleyda</surname><given-names>D</given-names></name><name><surname>Akdoğan</surname><given-names>B</given-names></name><name><surname>Arbuzova</surname><given-names>P</given-names></name><name><surname>Atlas</surname><given-names>LY</given-names></name><name><surname>Balcı</surname><given-names>F</given-names></name><name><surname>Bang</surname><given-names>JW</given-names></name><name><surname>Bègue</surname><given-names>I</given-names></name><name><surname>Birney</surname><given-names>DP</given-names></name><name><surname>Brady</surname><given-names>TF</given-names></name><name><surname>Calder-Travis</surname><given-names>J</given-names></name><name><surname>Chetverikov</surname><given-names>A</given-names></name><name><surname>Clark</surname><given-names>TK</given-names></name><name><surname>Davranche</surname><given-names>K</given-names></name><name><surname>Denison</surname><given-names>RN</given-names></name><name><surname>Dildine</surname><given-names>TC</given-names></name><name><surname>Double</surname><given-names>KS</given-names></name><name><surname>Duyan</surname><given-names>YA</given-names></name><name><surname>Faivre</surname><given-names>N</given-names></name><name><surname>Fallow</surname><given-names>K</given-names></name><name><surname>Filevich</surname><given-names>E</given-names></name><name><surname>Gajdos</surname><given-names>T</given-names></name><name><surname>Gallagher</surname><given-names>RM</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Gherman</surname><given-names>S</given-names></name><name><surname>Haddara</surname><given-names>N</given-names></name><name><surname>Hainguerlot</surname><given-names>M</given-names></name><name><surname>Hsu</surname><given-names>T-Y</given-names></name><name><surname>Hu</surname><given-names>X</given-names></name><name><surname>Iturrate</surname><given-names>I</given-names></name><name><surname>Jaquiery</surname><given-names>M</given-names></name><name><surname>Kantner</surname><given-names>J</given-names></name><name><surname>Koculak</surname><given-names>M</given-names></name><name><surname>Konishi</surname><given-names>M</given-names></name><name><surname>Koß</surname><given-names>C</given-names></name><name><surname>Kvam</surname><given-names>PD</given-names></name><name><surname>Kwok</surname><given-names>SC</given-names></name><name><surname>Lebreton</surname><given-names>M</given-names></name><name><surname>Lempert</surname><given-names>KM</given-names></name><name><surname>Ming Lo</surname><given-names>C</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name><name><surname>Massoni</surname><given-names>S</given-names></name><name><surname>Matthews</surname><given-names>J</given-names></name><name><surname>Mazancieux</surname><given-names>A</given-names></name><name><surname>Merfeld</surname><given-names>DM</given-names></name><name><surname>O’Hora</surname><given-names>D</given-names></name><name><surname>Palser</surname><given-names>ER</given-names></name><name><surname>Paulewicz</surname><given-names>B</given-names></name><name><surname>Pereira</surname><given-names>M</given-names></name><name><surname>Peters</surname><given-names>C</given-names></name><name><surname>Philiastides</surname><given-names>MG</given-names></name><name><surname>Pfuhl</surname><given-names>G</given-names></name><name><surname>Prieto</surname><given-names>F</given-names></name><name><surname>Rausch</surname><given-names>M</given-names></name><name><surname>Recht</surname><given-names>S</given-names></name><name><surname>Reyes</surname><given-names>G</given-names></name><name><surname>Rouault</surname><given-names>M</given-names></name><name><surname>Sackur</surname><given-names>J</given-names></name><name><surname>Sadeghi</surname><given-names>S</given-names></name><name><surname>Samaha</surname><given-names>J</given-names></name><name><surname>Seow</surname><given-names>TXF</given-names></name><name><surname>Shekhar</surname><given-names>M</given-names></name><name><surname>Sherman</surname><given-names>MT</given-names></name><name><surname>Siedlecka</surname><given-names>M</given-names></name><name><surname>Skóra</surname><given-names>Z</given-names></name><name><surname>Song</surname><given-names>C</given-names></name><name><surname>Soto</surname><given-names>D</given-names></name><name><surname>Sun</surname><given-names>S</given-names></name><name><surname>van Boxtel</surname><given-names>JJA</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Weidemann</surname><given-names>CT</given-names></name><name><surname>Weindel</surname><given-names>G</given-names></name><name><surname>Wierzchoń</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Ye</surname><given-names>Q</given-names></name><name><surname>Yeon</surname><given-names>J</given-names></name><name><surname>Zou</surname><given-names>F</given-names></name><name><surname>Zylberberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The Confidence Database</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>317</fpage><lpage>325</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0813-1</pub-id><pub-id pub-id-type="pmid">32015487</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouault</surname><given-names>M</given-names></name><name><surname>Seow</surname><given-names>T</given-names></name><name><surname>Gillan</surname><given-names>CM</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Psychiatric symptom dimensions are associated with dissociable shifts in metacognition but not task performance</article-title><source>Biological Psychiatry</source><volume>84</volume><fpage>443</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2017.12.017</pub-id><pub-id pub-id-type="pmid">29458997</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rounis</surname><given-names>E</given-names></name><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Rothwell</surname><given-names>JC</given-names></name><name><surname>Passingham</surname><given-names>RE</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Theta-burst transcranial magnetic stimulation to the prefrontal cortex impairs metacognitive visual awareness</article-title><source>Cognitive Neuroscience</source><volume>1</volume><fpage>165</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1080/17588921003632529</pub-id><pub-id pub-id-type="pmid">24168333</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Rouy</surname><given-names>M</given-names></name><name><surname>Saliou</surname><given-names>P</given-names></name><name><surname>Nalborczyk</surname><given-names>L</given-names></name><name><surname>Pereira</surname><given-names>M</given-names></name><name><surname>Roux</surname><given-names>P</given-names></name><name><surname>Faivre</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Systematic Review and Meta-Analysis of the Calibration of Confidence Judgments in Individuals with Schizophrenia Spectrum Disorders</article-title><source>medRxiv</source><pub-id pub-id-type="doi">10.1101/2020.12.03.20243113</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanders</surname><given-names>JI</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Signatures of a statistical computation in the human sense of confidence</article-title><source>Neuron</source><volume>90</volume><fpage>499</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.025</pub-id><pub-id pub-id-type="pmid">27151640</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sen</surname><given-names>PK</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Estimates of the regression coefficient based on kendall’s tau</article-title><source>Journal of the American Statistical Association</source><volume>63</volume><fpage>1379</fpage><lpage>1389</lpage><pub-id pub-id-type="doi">10.1080/01621459.1968.10480934</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seow</surname><given-names>TXF</given-names></name><name><surname>Rouault</surname><given-names>M</given-names></name><name><surname>Gillan</surname><given-names>CM</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>How local and global metacognition shape mental health</article-title><source>Biological Psychiatry</source><volume>90</volume><fpage>436</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2021.05.013</pub-id><pub-id pub-id-type="pmid">34334187</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shekhar</surname><given-names>M</given-names></name><name><surname>Rahnev</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The nature of metacognitive inefficiency in perceptual decision making</article-title><source>Psychological Review</source><volume>128</volume><fpage>45</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1037/rev0000249</pub-id><pub-id pub-id-type="pmid">32673034</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soll</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Determinants of overconfidence and miscalibration: The roles of random error and ecological structure</article-title><source>Organizational Behavior and Human Decision Processes</source><volume>65</volume><fpage>117</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1006/obhd.1996.0011</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Speechley</surname><given-names>WJ</given-names></name><name><surname>Whitman</surname><given-names>JC</given-names></name><name><surname>Woodward</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The contribution of hypersalience to the “jumping to conclusions” bias associated with delusions in schizophrenia</article-title><source>Journal of Psychiatry &amp; Neuroscience</source><volume>35</volume><fpage>7</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1503/jpn.090025</pub-id><pub-id pub-id-type="pmid">20040242</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Theil</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1950">1950</year><article-title>A Rank Invariant Method of Linear and Polynomial Regression Analysis, i, ii, iii</article-title><conf-name>Proceedings of the Koninklijke Nederlandse Akademie Wetenschappen, Series A Mathematical Sciences</conf-name><fpage>386</fpage><lpage>392</lpage></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Berg</surname><given-names>R</given-names></name><name><surname>Yoo</surname><given-names>AH</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fechner’s law in metacognition: A quantitative model of visual working memory confidence</article-title><source>Psychological Review</source><volume>124</volume><fpage>197</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1037/rev0000060</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wales</surname><given-names>DJ</given-names></name><name><surname>Doye</surname><given-names>JPK</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Global optimization by basin-hopping and the lowest energy structures of lennard-jones clusters containing up to 110 atoms</article-title><source>The Journal of Physical Chemistry A</source><volume>101</volume><fpage>5111</fpage><lpage>5116</lpage><pub-id pub-id-type="doi">10.1021/jp970984n</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>K</given-names></name><name><surname>Shekhar</surname><given-names>M</given-names></name><name><surname>Rahnev</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The Nature of Metacognitive Noise Confounds Metacognitive Sensitivity and Metacognitive Bias</article-title><source>PsyArXiv</source><ext-link ext-link-type="uri" xlink:href="https://osf.io/buahk">https://osf.io/buahk</ext-link></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zawadzki</surname><given-names>JA</given-names></name><name><surname>Woodward</surname><given-names>TS</given-names></name><name><surname>Sokolowski</surname><given-names>HM</given-names></name><name><surname>Boon</surname><given-names>HS</given-names></name><name><surname>Wong</surname><given-names>AHC</given-names></name><name><surname>Menon</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Cognitive factors associated with subclinical delusional ideation in the general population</article-title><source>Psychiatry Research</source><volume>197</volume><fpage>345</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1016/j.psychres.2012.01.004</pub-id><pub-id pub-id-type="pmid">22421072</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Derivation of the link function in Equation 5</title><p>The link function <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> corresponds to an observer who expresses confidence as the subjective probability of having made a correct type 1 decision. Ignoring metacognitive noise and metacognitive biases in a first step, the link function <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is defined as the (rescaled) choice probability <italic>p</italic> for the chosen option (rescaled from 0.5..1 to 0..1 using the transformation <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). Since the choice probability for the chosen option is symmetric in <italic>y</italic>, the link function can be simplified to just considering absolute decision values (i.e., <inline-formula><mml:math id="inf38"><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>)</mml:mo></mml:math></inline-formula>). Using the expression for the choice probability in <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, a logistic function, and using the relationship <inline-formula><mml:math id="inf39"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> , one arrives at the following derivation of the link function:<disp-formula id="equ11"> <label>(A1)</label><mml:math id="m11"><mml:mrow><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msup><mml:mi>c</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>S</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>;</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>⋅</mml:mo><mml:mn>0.5</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The final form of the link function in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> is based on <xref ref-type="disp-formula" rid="equ1">Equation A1</xref>, augmented with evidence-based metacognitive bias parameters (<inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>:=</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>y</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) and accounting for metacognitive readout noise (<inline-formula><mml:math id="inf41"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi>z</mml:mi></mml:math></inline-formula>).”</p></sec></app><app id="appendix-2"><title>Appendix 2</title><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Metacognitive noise distributions.</title><p>All distributions are parameterized such that <inline-formula><mml:math id="inf42"><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the mode and σ<sub>m</sub> is the standard deviation of the distribution (the only exception is the Beta distribution, for which σ<sub>m</sub> is a spread parameter that cannot be identified with a statistical quantity). For the Gumbel distribution the auxiliary parameter η<sub>m</sub> was defined as η<sub>m</sub> = π/(σ<sub>m</sub>√6), such that σ<sub>m</sub> corresponds to the standard deviation of the distribution.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom"><italic>Noisy-readout</italic></th><th align="left" valign="bottom"><italic>Noisy-report</italic></th></tr></thead><tbody><tr><td align="left" valign="top">Censored<break/>Normal</td><td align="left" valign="middle"><inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>z</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>c</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Censored<break/>Gumbel</td><td align="left" valign="middle"><inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>z</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>c</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Truncated<break/>Normal</td><td align="left" valign="middle"><inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Truncated<break/>Gumbel</td><td align="left" valign="middle"><inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Gamma/<break/>Beta</td><td align="left" valign="middle"><inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>α</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><italic>Parameterization:</italic><break/><inline-formula><mml:math id="inf52"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:msqrt><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt></mml:math></inline-formula><break/><inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msqrt><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="middle"><inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">B</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><italic>Parameterization:</italic><break/><inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Lognormal</td><td align="left" valign="middle"><inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>m</mml:mi><mml:mo>∗</mml:mo></mml:msubsup><mml:msqrt><mml:mi>π</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>m</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>Note: <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>m</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> represent an analytic parameterization such that the lognormal distribution has mode z* and standard deviation σ<sub>m</sub>. See the published code for details.</td><td align="left" valign="middle"/></tr></tbody></table></table-wrap></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75420.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wyart</surname><given-names>Valentin</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>École normale supérieure, PSL University, INSERM</institution></institution-wrap><country>France</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.10.10.463812" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.10.10.463812"/></front-stub><body><p>This paper presents a novel computational model of metacognition and a validated toolbox for fitting it to empirical data. By formalizing different sources of noise and bias that impact confidence, the proposed model aims at providing metacognition metrics that are independent of perception – a continued endeavor in the field. The framework and toolbox constitute a valuable resource for the field.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75420.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Wyart</surname><given-names>Valentin</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a0dhs15</institution-id><institution>École normale supérieure, PSL University, INSERM</institution></institution-wrap><country>France</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Fleming</surname><given-names>Steve</given-names></name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.10.10.463812">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.10.10.463812v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Reverse engineering of metacognition&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by Valentin Wyart as the Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Steve Fleming (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission. As you will see, the reviewers have found your modeling approach to the measure of metacognition to be interesting and potentially insightful, but several additional analyses and controls will need to be performed for the article to be considered as publishable in <italic>eLife</italic>. Please address all essential revisions below in a revised version of the article, together with a point-by-point response. The individual reviews from the two reviewers are appended below, but they do not formally require individual point-by-point responses at the revision stage.</p><p>Essential revisions:</p><p>1) Parameter and model recovery: separability between the two metacognitive modules. More work needs to be done to demonstrate that the proposed model can discriminate between the noisy readout module and the noisy report module. The two proposed modules have different psychological meanings, but seem to impact the confidence output similarly. Indeed, qualitatively, it seems like the only thing distinguishing them is that the noise is either applied before or after the link function, and it isn't clear whether this was sufficient to distinguish one from the other. Are these two modules mutually exclusive (as Figure 1 suggests), or could both sources of noise co-exist? It is important to show model recovery for introducing noisy readout vs. report at the metacognitive level. Both reviewers appreciate they might return differential AICs, but it is important to report a 2x2 model confusion matrix from simulated data (see Wilson and Collins, 2019 <italic>eLife</italic>) to test whether the ground-truth metacognitive module can be recovered from simulated data. The similarity between the two metacognitive modules also raises the question of how the two types of σ_m are recoverable/separable from each other. If they capture independent aspects of noise, one could imagine a model with both modules. More evidence is needed to show that these two capture separate aspects of noise.</p><p>2) Parameter and model recovery: perform analyses that capture more realistically aspects of experimental datasets. The parameter recovery demonstrated in Figure 4 is impressive, but it is critically important to know what happens when more than one parameter needs to be inferred, as in real data. The plots don't show what the other parameters are doing when one is being recovered (nor do the plots in the supplement to Figure 6). The key question is whether each parameter is independently identifiable, or whether there are correlations in parameter estimates that might limit the assignment of effects (e.g., metacognitive bias) to one parameter rather than another. For example, the slope and metacognitive noise may trade off against each other, as might the slope and δ_m. This seems particularly important to establish as a limit of what can be inferred from a ReMeta model fit. To address this concern, a proper correlation matrix between best-fitting parameters should be presented, and a parameter confusion matrix should be conducted across the parameter space, not only for certain regimes (i.e. more than Figure 6 supp 3), that is, the full grid exploration irrespective of how other parameters were set. Finally, recovery analyses should not (only) be done on 10,000 trials which is one to two orders of magnitude larger than the amount of data collected from individual subjects in experiments. 1,000 trials appear like an upper bound on typical data.</p><p>3) Trade-off between the flexibility of the model vs. the generalizability of the identified metacognitive architecture across contexts and participants. The current modeling framework proposed appears to favor flexibility (reflected, e.g., in the modularity of the metacognitive part, choice of the link functions) against the generalizability of the identified architecture. But beyond questions about model and parameter recovery that need to be taken care of, could the modeling framework be 'too flexible' in that it does not allow to draw conclusions that generalize across contexts (e.g., cognitive tasks, stimuli, etc.) and participants. This question is important, because Figure 7 and ‘Application to empirical data’ of the results explain that all models are similar, regardless of module of functions specified; Figure 7 supp shows that half of participants are best fitted by noisy readout, while the other half is best fitted by noisy report; plus, idiosyncrasies across participants are all captured. It would therefore be important to discuss in the article whether the high flexibility of the modeling architecture (that captures idiosyncrasies using its various free architectural choices and parameters) may compromise the generalizability of the modeling results at the group level and across tasks. This will be important to understand better the strengths and possible weaknesses of the proposed modeling framework for metacognition.</p><p>4) Separate fitting of type-1 and type-2 stages. The final paragraph of the discussion explains that data on empirical trial-by-trial accuracy is not used in the model fits. It is easy to see how in a process model that simulates decision and confidence data from stimulus features (from the perspective of the modeled observed), objective accuracy should not be considered as an input. But in terms of a model fit, it seems odd not to use trial by trial accuracy to constrain the fits at the metacognitive level, given that the hallmark of metacognitive sensitivity is a confidence-accuracy correlation. Is it not possible to create accuracy-conditional likelihood functions when fitting the confidence rating data (similar to how the meta-d' model fit is handled)? Psychologically, this also makes sense given that the observer typically knows their own response when giving a confidence rating. It is very important to explain more explicitly why fitting both choices and confidence at the same time is not possible in the current modeling framework. The assumption that different sources of noise are independent does not appear sufficient to explain this modeling choice.</p><p>5) Differences in the tasks required to fit the ReMeta model and the Mration model. An important nuance in comparing the present σ_m to Mratio is that the present model requires that multiple difficulty levels are tested, whereas instead, the Mratio model based on signal detection theory assumes a constant signal strength. How does this impact the (unfair?) comparison of these two metrics on empirical data that varied in difficulty level across trials? Relatedly, the Discussion paragraph that explained how the present model departs from type 2 AUROC analysis similarly omits to account for the fact that studies relying on the latter typically intend to not vary stimulus intensity at the level of the experimenter.</p><p>6) Structure of the model: variability in scale usage. Variability in scale usage appears to be forced to be set early in the model, not late. This is concerning that all the variability in scale usage is being assumed to load onto evidence-related parameters (eg δ_m) rather than being something about how subjects report or use an arbitrary confidence scale (eg the &quot;implicit biases&quot; assumed to govern the upper and lower bounds of the link function). You could have a similar notion of offset at the level of report – eg an equivalent parameter to δ_m but now applied to c and not z. Would these be distinguishable? They seem to have quite different interpretations psychologically: one is at the level of a bias in confidence formation, and the other at the level of a public report.</p><p>7) Structure of the model: integration only of choice-congruent decision evidence for confidence. In Eq8, could you explain why only the decision values consistent with the empirical choice are filtered. Is this an explicit modeling of the 'decision-congruence' phenomenon reported elsewhere (eg. Peters et al. 2017; Luu and Stocker, 2018, <italic>eLife</italic>)? What would be the implications of not keeping only the congruent decision values? It is important to motivate more clearly and explicitly this choice in the structure of the model.</p><p>8) Structure of the model: λ_m. It appears that λ_m is a meaningful part of the model. If so, it should be introduced early into the Figure 1 model, and be properly part of the parameter recovery procedure described above.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>I did not have time to check the toolbox available online but I note that it is an important strength that the authors have shared this resource for other researchers to look at or re-use for their own work.</p><p>Regarding the reasoning in paragraph 1.6, it is unclear to me why metacognitive evidence for the chosen option would become zero in case of a sign flip, rather than becoming negative evidence (just flipping sign)? I think it would be best to simply make the assumption that sign flips are impossible.</p><p>Isn't the lack of a reliable recovery of δ_m at low and high type 1 performance levels an issue, because it is exactly at the bounds that δ_m is supposed to have an effect?</p><p>We would like to see more discussion on how this model compares to other proposals of Bayesian confidence signatures (Adler and Ma, 2018, already cited). I also wondered about the possible inclusion of RTs in the model, which is then nicely addressed in the Discussion already.</p><p>Figure 4, middle panels: I think it is an assumption to simply convert confidence in 0-1 space to 0.5-1 space. Indeed, observers may treat very differently a 0.5-1 scale in which both 'I have purely guessed' and 'I am pretty sure I have made an error' would be reported around 0.5, whereas would be further apart on a 0-1 scale.</p><p>The sensory bias (bias), sensory noise (slope), and sensory threshold (random responses) all capture choice patterns in a logistic function; can you better explain how Equation 2 was developed? But parameterization of Figure 2 seems able to capture all standard effects. Similarly the reasoning leading to the generation of Equation 5 could be better motivated.</p><p>Figure 3C legend &quot;Higher metacognitive noise flattens the relationship between type 1 decision values and confidence.&quot;: this is between metacognitive evidence and confidence instead?</p><p>The behavioral effects shown in Figure 2 and 3 as a function of parameter values are useful, but also confusing because several of the parameters change value from plot to plot. Would it be possible instead to fix all but one parameter, and change the one parameter for 4-5 values instead of 2 values, for instance using a color scale? This way, the reader would be able to appreciate the effect of each parameter in isolation from the others.</p><p>Figure 6A displays an increase in Mratio as type 1 d' increases – the opposite of what is reported in the legend and in the text? at least for d' between 0 and 3, which is the case in most perceptual experiments? Likewise, there is a discrepancy with σ_m from the other module (Figure 6 supp).</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>- I found it odd that z was the noisy estimate of z-hat (and c the noisy estimate of c-hat), rather than the other way around given that the -hat operator is typically added to refer to an estimate.</p><p>- The current model is restricted to cases in which the sensory evidence is varying. This is opposite to the meta-d' model, in which sensory evidence is assumed to be fixed, or at least varying across a narrow range (eg d' is constant for stimulus repetitions). It might be worth emphasising that the two models can be chosen depending on the data available, rather than ReMeta being universally more suitable than meta-d'.</p><p>- I felt the introduction could do with some more emphatic framing, and that the author is selling himself short here. Lines 26-33 outline the rationale for the model. But there are two goals here - one is an incremental one of fixing the biases in current metacognitive efficiency estimates, which is useful, but it doesn't seem to be so debilitating (at least with the standard m-ratio estimates) as to warrant entirely new model machinery. But then later in the paragraph, the fact that this new approach could also accommodate fits of parameters governing different types of metacognitive biases is introduced. This seems much more important given that there is no current framework for modelling such biases.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75420.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>I did not have time to check the toolbox available online but I note that it is an important strength that the authors have shared this resource for other researchers to look at or re-use for their own work.</p><p>Regarding the reasoning in paragraph 1.6, it is unclear to me why metacognitive evidence for the chosen option would become zero in case of a sign flip, rather than becoming negative evidence (just flipping sign)? I think it would be best to simply make the assumption that sign flips are impossible.</p></disp-quote><p>Indeed, re-reading this paragraph I found my wording to be unnecessarily convoluted. The point I had in mind is quite straightforward: either sign flips are impossible due to the nature of metacognitive noise itself (e.g. lognormal distribution) or they are possible but are not observed because the confidence scale does not include the possibility to report errors (hence confidence=0 in such cases -&gt; censored distributions). I substantially simplified the corresponding paragraphs along these lines (‘Metacognitive noise: noisy-report models’).</p><disp-quote content-type="editor-comment"><p>Isn't the lack of a reliable recovery of δ_m at low and high type 1 performance levels an issue, because it is exactly at the bounds that δ_m is supposed to have an effect?</p></disp-quote><p>Figure 4 (second row) shows that the recovery of δ_m indeed becomes unstable at very low or very high type 1 performance levels. I don’t consider this problematic, however.</p><p>Figure 4 investigates parameter recovery in dependence of <italic>overall</italic> type 1 performance. As outlined above, if overall type 1 performance is close to chance or close to perfect, behavior is random or shows little variance, respectively, which is why parameter recovery is often hampered.</p><p>More to the reviewer’s point, in the manuscript I provide an interpretation of δ_m in terms of a confidence threshold (for δ_m &lt; 0), i.e. a minimal level of sensory evidence required to have a nonzero confidence experience. I assume this is what the reviewer was referring to with “exactly at the bounds that δ_m is supposed to have an effect”; please correct me otherwise. This interpretation, however, refers to instances of <italic>single</italic> trials in which sensory evidence is low (from the perspective of the observer, not necessarily objectively). Critically, the idea of a confidence threshold can be meaningful and impactful even if overall performance is at intermediate or high levels, as subjective sensory evidence will often nevertheless be low in a <italic>certain fraction</italic> of trials.</p><p>More importantly, however, the evidence shift induced through δ_m applies to all levels of internal evidence (after all, it is just the subtraction of a constant); the idea of a confidence threshold at very low levels of evidence is highlighted mainly because it is associated with a prominent feature in the confidence-evidence relationship.</p><disp-quote content-type="editor-comment"><p>We would like to see more discussion on how this model compares to other proposals of Bayesian confidence signatures (Adler and Ma, 2018, already cited). I also wondered about the possible inclusion of RTs in the model, which is then nicely addressed in the Discussion already.</p></disp-quote><p>As the reviewer mentions, I had cited a paper by Adler and Ma from 2018 (<italic>Neural Computation</italic>), but I now realized that there is a second Adler and Ma (2018; <italic>PLOS Comp. Biology</italic>), to which the reviewer is likely referring to. I had missed the latter one in my literature review. I now refer to this and related references in a new discussion paragraph on Bayesian confidence models (Line 807ff):</p><p>“Finally, how does the present model relate to the recent discussion between Bayesian and Non-Bayesian models of confidence (Aitchison et al., 2015; Sanders et al., 2016; Adler and Ma, 2018b)? A Bayesian observer of the (inner) world is one who maintains a posterior probability density over possible states of that world. In particular, computing confidence for such an observer corresponds to integrating the posterior over all possible states for which the type 1 choice would be correct. In this sense, the model proposed here with the link function provided in Equation 5 corresponds to a Bayesian observer, albeit one that can be susceptible to metacognitive biases and to additional sources of metacognitive noise. Thus, while the observer is Bayesian in nature, it may not be Bayes optimal. At the same time, the framework and the toolbox are flexible to allow for “non-Bayesian” link functions (Figure 3—figure supplement 1) that could represent certain idiosyncratic heuristics and shortcuts inherent to human confidence judgements. Of note, the model proposed here does not consider prior distributions over the stimulus categories (see e.g., Adler and Ma, 2018b). Instead, it is assumed that the observer considers both stimulus categories equally likely which is a reasonable assumption if stimulus categories are balanced.”</p><p>I agree that including RTs in a confidence model would be a nice feature, but in my opinion this requires a lot of groundwork that is beyond the scope of this work.</p><disp-quote content-type="editor-comment"><p>Figure 4, middle panels: I think it is an assumption to simply convert confidence in 0-1 space to 0.5-1 space. Indeed, observers may treat very differently a 0.5-1 scale in which both 'I have purely guessed' and 'I am pretty sure I have made an error' would be reported around 0.5, whereas would be further apart on a 0-1 scale.</p></disp-quote><p>In this manuscript I strictly consider confidence as ranging from ‘I have purely guessed’ to ‘I am 100% certain’, i.e. I do not consider the case of realizing errors at the time of the confidence report. This was stated e.g. on Line 330ff (“Unless confidence rating scales include the possibility to indicate errors (which I do not consider here)[.]”). The transformation from 0.5-1 to 0-1 space is thus a purely mathematical one, motivated by certain technical advantages (e.g. the Β noise distribution is naturally bounded between 0 and 1). I now also state this in the relevant paragraph concerning the transformation 0.5-1 -&gt; 0-1 (Line 183ff):</p><p>“Note that I do not consider the possibility that type 1 errors can be reported at the time of the confidence report, i.e., confidence cannot be negative.”.</p><disp-quote content-type="editor-comment"><p>The sensory bias (bias), sensory noise (slope), and sensory threshold (random responses) all capture choice patterns in a logistic function; can you better explain how Equation 2 was developed? But parameterization of Figure 2 seems able to capture all standard effects. Similarly the reasoning leading to the generation of Equation 5 could be better motivated.</p></disp-quote><p>Equation 2: The formula in Equation 2 is the logistic distribution. The only change from the standard form is that I converted the conventional parameter <italic>s</italic> to a standard deviation <italic>σ</italic> using fact that the variance of the logistic distribution is known as <italic>s</italic>²<italic>π</italic>²/3. The nature of the bias parameter in Equation 1 corresponds to a horizontal shift of the resulting psychometric function. The sensory threshold parameter is the mathematical formalization of the notion that a certain degree of sensory stimulation is necessary to drive the system, i.e., below a certain intensity level <italic>δ</italic><sub>s</sub> the resulting decision values are zero. I now provide this explanatory information interspersed in ‘Computing decision values’.</p><p>Equation 5: I have now added the derivation of the link function in Equation 5 as Appendix Equation A1 and reference to it in ‘The link function: from metacognitive evidence to confidence’.</p><disp-quote content-type="editor-comment"><p>Figure 3C legend &quot;Higher metacognitive noise flattens the relationship between type 1 decision values and confidence.&quot;: this is between metacognitive evidence and confidence instead?</p></disp-quote><p>Thanks, corrected!</p><disp-quote content-type="editor-comment"><p>The behavioral effects shown in Figure 2 and 3 as a function of parameter values are useful, but also confusing because several of the parameters change value from plot to plot. Would it be possible instead to fix all but one parameter, and change the one parameter for 4-5 values instead of 2 values, for instance using a color scale? This way, the reader would be able to appreciate the effect of each parameter in isolation from the others.</p></disp-quote><p>I liked this suggestion and implemented it for Figures 2 and 3:</p><disp-quote content-type="editor-comment"><p>Figure 6A displays an increase in Mratio as type 1 d' increases – the opposite of what is reported in the legend and in the text? at least for d' between 0 and 3, which is the case in most perceptual experiments? Likewise, there is a discrepancy with σ_m from the other module (Figure 6 supp).</p></disp-quote><p>Thanks for noting. I replaced it with a more neutral “shows a nonlinear dependency with varying type 1 performance levels” (Line 387). Note that the plots in Figure 6 changed slightly because I now plot proportion correct responses instead of d’ and I use truncated normal distributions for all plots (which is the new default of the toolbox; also, it makes the comparison between noisy-readout and noisy-report models easier).</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>- I found it odd that z was the noisy estimate of z-hat (and c the noisy estimate of c-hat), rather than the other way around given that the -hat operator is typically added to refer to an estimate.</p></disp-quote><p>I agree that the notation could be confusing. I now replaced the hat-notation with an asterisk-notation. I did not simply flip the hat and non-hat notation, since noisy versions of the variables are not really an estimate in the traditional sense either (as e.g., the sample mean).</p><disp-quote content-type="editor-comment"><p>- The current model is restricted to cases in which the sensory evidence is varying. This is opposite to the meta-d' model, in which sensory evidence is assumed to be fixed, or at least varying across a narrow range (eg d' is constant for stimulus repetitions). It might be worth emphasising that the two models can be chosen depending on the data available, rather than ReMeta being universally more suitable than meta-d'.</p></disp-quote><p>As I noted also to Reviewer #1, this restriction was unnecessarily imposed in the previous version of the manuscript. The references to this restriction are now removed from the manuscript. In other words, the model also works for constant stimuli.</p><disp-quote content-type="editor-comment"><p>- I felt the introduction could do with some more emphatic framing, and that the author is selling himself short here. Lines 26-33 outline the rationale for the model. But there are two goals here - one is an incremental one of fixing the biases in current metacognitive efficiency estimates, which is useful, but it doesn't seem to be so debilitating (at least with the standard m-ratio estimates) as to warrant entirely new model machinery. But then later in the paragraph, the fact that this new approach could also accommodate fits of parameters governing different types of metacognitive biases is introduced. This seems much more important given that there is no current framework for modelling such biases.</p></disp-quote><p>I agree with this assessment and I now put a stronger emphasis on this methodological gap in the literature (Line 53ff):</p><p>“However, currently there is no established framework that allows for unbiased estimates of metacognitive biases. The validity of traditional calibration curve analyses, which is based on a comparison of the subjective and objective probability of being correct, has been debunked repeatedly (Soll, 1996; Merkle, 2009; Drugowitsch, 2016). In particular, the classic hard-easy (Lichtenstein and Fischhoff, 1977), according to which overconfidence is particularly pronounced for difficult tasks, can be explained as a mere statistical artefact of random errors. For this reason, and in view of the potential importance in patient populations, there is a pressing need for unbiased measures of metacognitive biases.”</p><p>Towards the end of the introduction, I once again refer to this point (Line 111ff):</p><p>“[.] As outlined above, there is currently no established methodology to measure under- and overconfidence, let alone measure different types of such biases. [..]”</p><p>In return, I cut down on introductory space taken up by the issue of metacognitive efficiency, in line also with the recommendation of Reviewer #1.</p></body></sub-article></article>