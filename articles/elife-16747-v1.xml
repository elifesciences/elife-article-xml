<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">16747</article-id><article-id pub-id-type="doi">10.7554/eLife.16747</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Individual differences in selective attention predict speech identification at a cocktail party</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-54942"><name><surname>Oberfeld</surname><given-names>Daniel</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6710-3309</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-55781"><name><surname>Klöckner-Nowotny</surname><given-names>Felicitas</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Psychology, Section Experimental Psychology</institution>, <institution>Johannes Gutenberg-Universität</institution>, <addr-line><named-content content-type="city">Mainz</named-content></addr-line>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Shinn-Cunningham</surname><given-names>Barbara G</given-names></name><role>Reviewing editor</role><aff id="aff2"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>oberfeld@uni-mainz.de</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>31</day><month>08</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>5</volume><elocation-id>e16747</elocation-id><history><date date-type="received"><day>07</day><month>04</month><year>2016</year></date><date date-type="accepted"><day>08</day><month>08</month><year>2016</year></date></history><permissions><copyright-statement>© 2016, Oberfeld et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Oberfeld et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-16747-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.16747.001</object-id><p>Listeners with normal hearing show considerable individual differences in speech understanding when competing speakers are present, as in a crowded restaurant. Here, we show that one source of this variance are individual differences in the ability to focus selective attention on a target stimulus in the presence of distractors. In 50 young normal-hearing listeners, the performance in tasks measuring auditory and visual selective attention was associated with sentence identification in the presence of spatially separated competing speakers. Together, the measures of selective attention explained a similar proportion of variance as the binaural sensitivity for the acoustic temporal fine structure. Working memory span, age, and audiometric thresholds showed no significant association with speech understanding. These results suggest that a reduced ability to focus attention on a target is one reason why some listeners with normal hearing sensitivity have difficulty communicating in situations with background noise.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.001">http://dx.doi.org/10.7554/eLife.16747.001</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>speech-in-noise identification</kwd><kwd>auditory selective attention</kwd><kwd>visual attention</kwd><kwd>temporal fine structure sensitivity</kwd><kwd>individual differences</kwd><kwd>working memory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>OB 346/4-2</award-id><principal-award-recipient><name><surname>Oberfeld</surname><given-names>Daniel</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Cocktail-party listening performance in normal-hearing listeners is associated with the ability to focus attention on a target stimulus in the presence of distractors.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Imagine yourself sitting at a table in a crowded restaurant, chatting with a friend of yours. Can you follow the conversation with your friend easily, or does the high noise level in general or more specifically the conversations heard from other tables interfere with speech intelligibility? While the human auditory system has impressive abilities in structuring the mixture of sound waves arriving at the ears into different auditory objects or streams (auditory scene analysis; e.g., <xref ref-type="bibr" rid="bib9">Bregman, 1990</xref>; <xref ref-type="bibr" rid="bib18">Carlyon, 2004</xref>), listeners show considerable variation when it comes to speech understanding in adverse acoustic conditions, such as the almost proverbial '<italic>cocktail-party</italic>' situation described above (<xref ref-type="bibr" rid="bib11">Bronkhorst, 2000</xref>; <xref ref-type="bibr" rid="bib19">Cherry, 1953</xref>). Surprisingly, pronounced individual differences in speech identification in background noise are observed even in listeners with <italic>normal hearing</italic>, that is, with audiometric thresholds better than 20 dB HL within the frequency range most important for speech (100 Hz–4 kHz; <xref ref-type="bibr" rid="bib15">Byrne et al., 1994</xref>), usually taken as an indication of approximately intact processing in the inner ear. For example, <xref ref-type="bibr" rid="bib89">Ruggles and Shinn-Cunningham (2011)</xref> tested normal-hearing subjects in a simulated cocktail-party listening task with two competing speakers presented 15° to the left and right of the target speaker. Across listeners, the percentage of correct responses in reporting a sequence of digits produced by the target speaker varied between 40% and 85% in an anechoic condition. Compatible with these experimental results, in clinical settings a relevant number of patients with normal audiometric findings complain about hearing difficulties in daily life (<xref ref-type="bibr" rid="bib115">Zhao and Stephens, 2007</xref>).</p><p>Understanding speech in a cocktail-party situation with interfering speakers and other background noise requires <italic>selective attention</italic> (<xref ref-type="bibr" rid="bib12">Bronkhorst, 2015</xref>; <xref ref-type="bibr" rid="bib19">Cherry, 1953</xref>; <xref ref-type="bibr" rid="bib96">Shinn-Cunningham, 2008</xref>; <xref ref-type="bibr" rid="bib110">Xiang et al., 2010</xref>), and was even proposed to be the '<italic>best-known real life example of selective attention</italic>' (<xref ref-type="bibr" rid="bib80">Pashler, 1998</xref>). The information from the target speaker needs to be processed, while information from other sound sources should be ignored. The main hypothesis tested in the present study was that individual differences in the <italic>capability to direct auditory selective attention to the relevant stimulus in the presence of distractors</italic> explain a significant proportion of the inter-individual variance in cocktail-party listening performance. Although several aspects of speech appear to be processed outside the focus of attention (<xref ref-type="bibr" rid="bib84">Pulvermüller and Shtyrov, 2006</xref>), attention enhances the representation of speech (and other sounds) at relatively early stages (e.g., <xref ref-type="bibr" rid="bib20">Choi et al., 2014</xref>; <xref ref-type="bibr" rid="bib98">Srinivasan et al., 2012</xref>; <xref ref-type="bibr" rid="bib110">Xiang et al., 2010</xref>; <xref ref-type="bibr" rid="bib116">Zion Golumbic et al., 2013</xref>). On the behavioral level, the importance of attention is illustrated by studies that manipulated the a-priori information concerning the target speaker. For instance, in an experiment by <xref ref-type="bibr" rid="bib57">Kidd et al. (2005)</xref>; the speech identification performance was better when the listener knew in advance which of three talkers (presented at different spatial positions) would be the target speaker, compared to conditions where the target location was uncertain. Thus, for exactly identical acoustic signals, being able to direct attention to the correct location results in a large improvement in speech recognition (e.g., <xref ref-type="bibr" rid="bib5">Best et al., 2007</xref>; <xref ref-type="bibr" rid="bib60">Kitterick et al., 2010</xref>). The direction of selective attention to the target speaker can be impaired due to limitations imposed by the <italic>acoustic signal</italic> or by <italic>perceptual or cognitive characteristics of the listener</italic> (cf. <xref ref-type="bibr" rid="bib67">Mattys et al., 2012</xref>). If a listener has problems in using acoustic cues for the formation of auditory objects or streams, or on a more cognitive level is incapable of ignoring irrelevant information, then speech identification performance will be low even when fundamental frequency, timbre, and spatial location of the speakers differ.</p><p>With respect to listeners' attentional capabilities, it is important to take into consideration that attention is a multifaceted phenomenon (cf. <xref ref-type="bibr" rid="bib100">Styles, 2006</xref>). In a cocktail party situation, it is required to attend to a certain speaker (target) and to ignore the other sound sources (distractors). We were interested in whether speech understanding in a cocktail-party situation could be related to a more general ability to focus attention on a target in the presence of distractors. Surprisingly, this particular aspect of attention has not been studied very systematically in previous experiments that investigated the role of attention for speech understanding in noise (<xref ref-type="bibr" rid="bib36">Füllgrabe et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Gatehouse and Akeroyd, 2008</xref>; <xref ref-type="bibr" rid="bib48">Heinrich et al., 2015</xref>; <xref ref-type="bibr" rid="bib72">Neher et al., 2009</xref>, <xref ref-type="bibr" rid="bib73">2011</xref>, <xref ref-type="bibr" rid="bib74">2012</xref>; <xref ref-type="bibr" rid="bib95">Schoof and Rosen, 2014</xref>; <xref ref-type="bibr" rid="bib106">van Rooij et al., 1989</xref>). Most of these studies used tests developed for neuropsychological settings, like the Test of Everyday Attention (TEA; <xref ref-type="bibr" rid="bib85">Robertson et al., 1996</xref>) and the Trail Making Tests (TMT; <xref ref-type="bibr" rid="bib8">Bowie and Harvey, 2006</xref>), indexing <italic>visual search</italic> (TEA Map Search, Telephone Search), <italic>task/attentional switching</italic> (TEA Visual Elevator and Auditory Elevator with Reversal, TMT-B), <italic>sustained attention</italic> (TMT-A, TEA Lottery Test and Elevator Counting), or <italic>divided attention</italic> (TEA Telephone Search While Counting). Only one TEA subtest (&quot;Elevator counting with distraction&quot;) directly addresses the capability to ignore distractors. Here, participants have to count low pitch tones ('targets') while ignoring interspersed high pitch tones ('distractors'). We are aware of only two studies that included this subtest (<xref ref-type="bibr" rid="bib39">Gatehouse and Akeroyd, 2008</xref>; <xref ref-type="bibr" rid="bib72">Neher et al., 2009</xref>), in hearing-impaired listeners. Concerning the other tasks, while switching attention is relevant for situations where the target speaker changes dynamically, for example in a conversation involving more than two persons, there are many situations where the target speaker does not change. Visual search and sustained attention seem even less relevant for cocktail-party listening. For this reason, our study included tasks in which subjects had to <italic>identify an auditory or visual target element in the presence of distractors</italic>. In our view, this is the most important aspect of attention in cocktail-party listening.</p><p>As a measure of <italic>visual selective attention</italic>, we used a <italic>flanker task</italic> as established by <xref ref-type="bibr" rid="bib33">Eriksen and Eriksen (1974)</xref>; where a target stimulus is surrounded by task-irrelevant distractors (flankers). In the critical <italic>incompatible condition</italic>, the flankers and the target call for opposite responses. If the incompatible flankers produce only small response time (RT) costs, then the participant has a high ability to focus visual selective attention on the target stimulus. This flanker interference is defined as the difference between the average response time (RT) in the incompatible condition and in a neutral condition where the flankers are not associated with one of the responses relevant for the target.</p><p>To measure the individual ability to direct <italic>auditory selective attention</italic> to a target stimulus while ignoring distractors, we used an intensity discrimination task under backward masking. If – as in the present study – a target sound is followed by a backward masker after a silent inter-stimulus interval (ISI) of 50 ms or more, it is virtually impossible that the masker affects the representation of the target in the auditory nerve (<xref ref-type="bibr" rid="bib56">Kiang et al., 1965</xref>; <xref ref-type="bibr" rid="bib82">Plack and Viemeister, 1992</xref>). Instead, strong effects of the backward masker on intensity discrimination can be explained by a failure to selectively attend to the target sounds while ignoring the maskers (<xref ref-type="bibr" rid="bib79">Oberfeld and Stahn, 2012</xref>; <xref ref-type="bibr" rid="bib77">Oberfeld et al., 2012</xref>; <xref ref-type="bibr" rid="bib94">Schlauch et al., 1997</xref>). For example, in a study from our lab that quantified the amount of attention directed to the maskers using a behavioral reverse-correlation approach (<xref ref-type="bibr" rid="bib78">Oberfeld et al., 2014</xref>), the effect of non-simultaneous masking on the intensity difference limen (DL) was well accounted for by the attention to the maskers, explaining 72% of the variance.</p><p>Listeners with normal audiometric thresholds may differ in their sensitivity to the temporal fine structure (TFS) of sounds (e.g., <xref ref-type="bibr" rid="bib38">Füllgrabe, 2013</xref>; <xref ref-type="bibr" rid="bib87">Ruggles et al., 2011</xref>), which is necessary for using interaural time difference (ITD) cues to sound localization. These differences were proposed to be due to cochlear neuropathy, which could for instance be caused by moderate noise exposure (<xref ref-type="bibr" rid="bib6">Bharadwaj et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Kujawa and Liberman, 2009</xref>) and is sometimes described as 'hidden hearing loss' (<xref ref-type="bibr" rid="bib81">Plack et al., 2014</xref>) because it cannot be detected using standard measures of audiometric threshold. Several studies showed a correlation between TFS sensitivity and the recognition of speech in noise, for normal-hearing as well as for hearing-impaired listeners (<xref ref-type="bibr" rid="bib6">Bharadwaj et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Füllgrabe et al., 2014</xref>; <xref ref-type="bibr" rid="bib73">Neher et al., 2011</xref>, <xref ref-type="bibr" rid="bib74">2012</xref>; <xref ref-type="bibr" rid="bib87">Ruggles et al., 2011</xref>; <xref ref-type="bibr" rid="bib95">Schoof and Rosen, 2014</xref>). For this reason, our study included binaural sensitivity for the temporal fine structure as a potential predictor of speech identification in a cocktail-party situation, using a task proposed by <xref ref-type="bibr" rid="bib49">Hopkins and Moore (2010)</xref> that measures the smallest detectable interaural phase difference (IPD) of a sinusoidal carrier relative to an IPD of 0°.</p><p>As additional cognitive measures, working memory capacity (e.g., <xref ref-type="bibr" rid="bib1">Akeroyd, 2008</xref>; <xref ref-type="bibr" rid="bib37">Füllgrabe et al., 2016</xref>) measured in a sentence span test (<xref ref-type="bibr" rid="bib28">Daneman and Carpenter, 1980</xref>), and processing speed (e.g., <xref ref-type="bibr" rid="bib91">Salthouse, 1996</xref>; <xref ref-type="bibr" rid="bib105">Tun and Wingfield, 1999</xref>) measured by the RT in the neutral condition of the visual flanker task, were included as potential predictors of speech-in-noise identification. The latter was measured in a simulated cocktail-party listening situation with two competing speakers that were presented 25° to the left and right of the target speaker, who was positioned in front of the listener (azimuthal angle 0°). In addition, self-reported hearing-related problems in daily life were assessed via the Speech, Spatial and Qualities of Hearing Scale (SSQ) by <xref ref-type="bibr" rid="bib40">Gatehouse and Noble (2004)</xref>, using the German version (<xref ref-type="bibr" rid="bib58">Kießling et al., 2011</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>To which extent did speech understanding in a cocktail-party situation depend on the capability of directing selective attention to a target in the presence of distractors, binaural sensitivity for the temporal fine structure (TFS), and other factors? To answer this question, a multiple linear regression analysis was conducted (the statistical details are described in Materials and methods). The criterion variable was the speech recognition score (SRS) defined as the proportion correct in the simulated cocktail-party listening task with two interfering speakers. We used a sentence identification task based on a German matrix test (<xref ref-type="bibr" rid="bib107">Wagener et al., 1999a</xref>) and presented binaural simulations of an anechoic environment (see Materials and methods). The nine predictors were (1) the elevation of the intensity difference limen caused by the backward masker (DL<sub>elev</sub>), defined as the difference between the DL under masking and the DL in quiet, which measures the capability of directing auditory selective attention to a target (<xref ref-type="bibr" rid="bib78">Oberfeld et al., 2014</xref>), (2) the amount of flanker interference in the flanker task (Int<sub>Flanker</sub>), which indexes visual selective attention, (3) the IPD threshold in the TFS-LF (<xref ref-type="bibr" rid="bib49">Hopkins and Moore, 2010</xref>) test (TFS<sub>th</sub>), which measures binaural sensitivity for the temporal fine structure, (4) the pure-tone average threshold on the better ear (PTA<sub>BE</sub>) at octave frequencies between 125 Hz and 4 kHz, (5) the average asymmetry in the hearing thresholds between left and right ear in the same frequency range (HL<sub>diff</sub>), (6) the intensity-DL in quiet (DL<sub>quiet</sub>), which represents a suprathreshold measure of hearing ability that is not related to selective attention, (7) the response time in the neutral condition of the flanker task (RT<sub>neutral</sub>), which was included as a measure of processing speed (<xref ref-type="bibr" rid="bib92">Salthouse, 2000</xref>), and (8) the proportion of correctly recalled consonants in the sentence span task (SS<sub>Pcorr</sub>) that indexes working memory capacity. Finally, (9) the age of the participant was added as a predictor, as in previous studies (e.g., <xref ref-type="bibr" rid="bib74">Neher et al., 2012</xref>), to investigate whether the observed inter-individual differences in cocktail-party listening are determined by other factors related to age. Note that due to the relatively large sample size it was not necessary to summarize the different predictors into a small number of factors as in some previous studies (<xref ref-type="bibr" rid="bib36">Füllgrabe et al., 2014</xref>; <xref ref-type="bibr" rid="bib48">Heinrich et al., 2015</xref>; <xref ref-type="bibr" rid="bib95">Schoof and Rosen, 2014</xref>; <xref ref-type="bibr" rid="bib106">van Rooij et al., 1989</xref>).<table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.002</object-id><label>Table 1.</label><caption><p>Results of the multiple regression analysis. Criterion variable: speech recognition score (SRS; proportion correct) in the simulated cocktail-party listening task. Predictors: age, masker-induced elevation of the intensity difference limen (DL<sub>elev</sub>), the amount of flanker interference in the flanker task (Int<sub>Flanker</sub>), IPD threshold in the TFS-LF task (TFS<sub>th</sub>), pure-tone average thresholds on the better ear (PTA<sub>BE</sub>), average asymmetry in the hearing thresholds between left and right ear (HL<sub>diff</sub>), intensity-DL in quiet (DL<sub>quiet</sub>), response time in the neutral condition of the flanker task (RT<sub>neutral</sub>), and proportion of correctly recalled consonants in the working memory task (SS<sub>Pcorr</sub>). All variables were <italic>z</italic>-standardized.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.002">http://dx.doi.org/10.7554/eLife.16747.002</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="top"><p>Predictor</p></th><th align="center" valign="top"><p>β</p></th><th align="center" valign="top"><p>SE</p></th><th align="center" valign="top"><p>t</p></th><th align="center" valign="top"><p>p</p></th><th align="center" valign="top"><p>GDW</p></th><th align="center" valign="top"><p><bold>β<sub>Lasso</sub></bold></p> </th></tr></thead><tbody><tr><td align="center" valign="top"><p>Intercept</p></td><td align="center"><p>0.068</p></td><td align="center"><p>0.096</p></td><td align="center"><p>0.710</p></td><td align="center"><p>0.480</p></td><td align="center" valign="top"/><td align="center" valign="bottom"><p>0.081</p></td></tr><tr><td align="center" valign="top"><p>Age</p></td><td align="center"><p>0.194</p></td><td align="center"><p>0.110</p></td><td align="center"><p>1.760</p></td><td align="center"><p>0.086</p></td><td align="center" valign="bottom"><p>0.020</p></td><td align="center" valign="top"><p>−</p></td></tr><tr><td align="center" valign="top"><p><bold>DL<sub>elev</sub></bold></p> </td><td align="center"><p><bold>−0.347</bold></p> </td><td align="center"><p><bold>0.107</bold></p> </td><td align="center"><p><bold>3.240</bold></p> </td><td align="center"><p><bold>0.003</bold></p> </td><td align="center" valign="bottom"><p><bold>0.152</bold></p> </td><td align="center" valign="top"><p>−0.220</p></td></tr><tr><td align="center" valign="top"><p><bold>Int<sub>Flanker</sub></bold></p> </td><td align="center"><p><bold>−0.233</bold></p> </td><td align="center"><p><bold>0.103</bold></p> </td><td align="center"><p><bold>2.270</bold></p> </td><td align="center"><p><bold>0.029</bold></p> </td><td align="center" valign="bottom"><p><bold>0.052</bold></p> </td><td align="center" valign="top"><p>−0.081</p></td></tr><tr><td align="center" valign="top"><p><bold>TFS<sub>th</sub></bold></p> </td><td align="center"><p><bold>−0.383</bold></p> </td><td align="center"><p><bold>0.103</bold></p> </td><td align="center"><p><bold>3.730</bold></p> </td><td align="center"><p><bold>0.001</bold></p> </td><td align="center" valign="bottom"><p><bold>0.204</bold></p> </td><td align="center" valign="top"><p>−0.286</p></td></tr><tr><td align="center" valign="top"><p>PTA<sub>BE</sub></p></td><td align="center"><p>0.137</p></td><td align="center"><p>0.102</p></td><td align="center"><p>1.350</p></td><td align="center"><p>0.186</p></td><td align="center" valign="bottom"><p>0.016</p></td><td align="center" valign="top"><p>−</p></td></tr><tr><td align="center" valign="top"><p>HL<sub>diff</sub></p></td><td align="center"><p>−0.088</p></td><td align="center"><p>0.106</p></td><td align="center"><p>0.830</p></td><td align="center"><p>0.413</p></td><td align="center" valign="bottom"><p>0.007</p></td><td align="center" valign="top"><p>−</p></td></tr><tr><td align="center" valign="top"><p>DL<sub>quiet</sub></p></td><td align="center"><p>−0.007</p></td><td align="center"><p>0.114</p></td><td align="center"><p>0.070</p></td><td align="center"><p>0.948</p></td><td align="center" valign="bottom"><p>0.021</p></td></tr><tr><td align="center" valign="top"><p>RT<sub>neutral</sub></p></td><td align="center"><p>−0.037</p></td><td align="center"><p>0.129</p></td><td align="center"><p>0.280</p></td><td align="center"><p>0.778</p></td><td align="center" valign="bottom"><p>0.015</p></td><td align="center" valign="top"><p>−</p></td></tr><tr><td align="center" valign="top"><p>SS<sub>Pcorr</sub></p></td><td align="center"><p>0.193</p></td><td align="center"><p>0.111</p></td><td align="center"><p>1.740</p></td><td align="center"><p>0.091</p></td><td align="center" valign="bottom"><p>0.085</p></td><td align="center" valign="top"><p>0.089</p></td></tr><tr><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"/><td valign="top"><italic>R</italic><sup>2</sup> =0.57 <break/>p&lt;0.001</td><td valign="top"><italic>R</italic><sup>2</sup> =0.44</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><p>Note: <italic>N</italic> = 45. β: estimated ordinary least-squares (OLS) regression coefficient. SE: standard error of the estimate. <italic>t: t</italic>-statistic. Bold font indicates a β significantly different from 0 (p&lt;0.05). GDW: general dominance weight. β<sub>Lasso</sub>: regression coefficients for predictors selected by the Lasso procedure (model selection via four-fold cross-validation).</p></fn></table-wrap-foot></table-wrap></p><p>The regression model showed a good fit, <italic>R</italic><sup>2</sup> = 0.57, p&lt;0.001, <italic>N</italic> = 45. As can be seen in <xref ref-type="table" rid="tbl1">Table 1</xref>, the performance in the cocktail-party listening task was significantly negatively related to the intensity-DL elevation under backward masking. Thus, compatible with our hypotheses, participants who showed a better capability of focusing attention on the target sounds in the intensity discrimination task were less affected by the interfering speakers in the cocktail-party listening task. In the same line of reasoning, the significant negative regression coefficient for flanker interference shows that a high capability of directing visual selective attention corresponded to good performance on the cocktail-party listening task. The IPD threshold measured in the TFS-LF task was also significantly negatively related to the SRS. Thus, compatible with previous studies (e.g., <xref ref-type="bibr" rid="bib36">Füllgrabe et al., 2014</xref>; <xref ref-type="bibr" rid="bib73">Neher et al., 2011</xref>, <xref ref-type="bibr" rid="bib74">2012</xref>; <xref ref-type="bibr" rid="bib88">Ruggles et al., 2012</xref>), listeners who showed high sensitivity for the TFS performed better in the spatial listening task. None of the remaining predictors showed a significant association with the performance in the spatial listening task. Notably, neither for age nor for working memory capacity did the regression coefficient differ significantly from 0.<table-wrap id="tbl2" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.003</object-id><label>Table 2.</label><caption><p>Pairwise Pearson partial correlation coefficients, controlling for age. <italic>N</italic> = 50. In each row, the upper numbers are the partial correlation coefficients (ρ<sub>partial</sub>), and the lower numbers are the <italic>p</italic>-values for the test of |ρ<sub>partial</sub>| &gt; 0. The rightmost column shows Pearson correlation coefficients with age. Bold font: p&lt;0.05. Italics: p&lt;0.10.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.003">http://dx.doi.org/10.7554/eLife.16747.003</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center"/><th align="center"><p>DL<sub>elev</sub></p></th><th align="center"><p>Int<sub>Flanker</sub></p></th><th align="center"><p>TFS<sub>th</sub></p></th><th align="center"><p>PTA<sub>BE</sub></p></th><th align="center"><p>HL<sub>diff</sub></p></th><th align="center"><p>DL<sub>quiet</sub></p></th><th align="center"><p>RT<sub>neutral</sub></p></th><th align="center"><p>SS<sub>Pcorr</sub></p></th><th align="center"><p>SSQ<sub>speech</sub></p></th><th align="center"><p>SSQ<sub>spatial</sub></p></th><th align="center"><p>SSQ<sub>qualities</sub></p></th><th align="center"><p>Age</p></th></tr></thead><tbody><tr><td align="center" rowspan="2"><p>OLSA<sub>Pcorr</sub></p></td><td align="center" valign="bottom"><p><bold>−0.374</bold></p> </td><td align="center" valign="bottom"><p>−0.149</p></td><td align="center" valign="bottom"><p><bold>−0.353</bold></p> </td><td align="center" valign="bottom"><p>0.060</p></td><td align="center" valign="bottom"><p>−0.163</p></td><td align="center" valign="bottom"><p><italic>−0.244</italic></p> </td><td align="center" valign="bottom"><p>−0.232</p></td><td align="center" valign="bottom"><p><bold>0.338</bold></p> </td><td align="center" valign="bottom"><p>0.121</p></td><td align="center" valign="bottom"><p>0.083</p></td><td align="center" valign="bottom"><p>0.230</p></td><td align="center" valign="top"><p>0.033</p></td></tr><tr><td align="center" valign="bottom"><p><bold>0.008</bold></p> </td><td align="center" valign="bottom"><p>0.307</p></td><td align="center" valign="bottom"><p><bold>0.013</bold></p> </td><td align="center" valign="bottom"><p>0.683</p></td><td align="center" valign="bottom"><p>0.263</p></td><td align="center" valign="bottom"><p><italic>0.091</italic></p> </td><td align="center" valign="bottom"><p>0.109</p></td><td align="center" valign="bottom"><p><bold>0.018</bold></p> </td><td align="center" valign="bottom"><p>0.407</p></td><td align="center" valign="bottom"><p>0.570</p></td><td align="center" valign="bottom"><p>0.112</p></td><td align="center" valign="top"><p>0.819</p></td></tr><tr><td align="center" rowspan="2"><p>DL<sub>elev</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>−0.047</p></td><td align="center" valign="bottom"><p>0.038</p></td><td align="center" valign="bottom"><p>0.030</p></td><td align="center" valign="bottom"><p>−0.083</p></td><td align="center" valign="bottom"><p>−0.045</p></td><td align="center" valign="bottom"><p>0.092</p></td><td align="center" valign="bottom"><p><italic>−0.255</italic></p> </td><td align="center" valign="bottom"><p><bold>−0.302</bold></p> </td><td align="center" valign="bottom"><p>−0.049</p></td><td align="center" valign="bottom"><p>−0.178</p></td><td align="center" valign="bottom"><p>−0.045</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.748</p></td><td align="center" valign="bottom"><p>0.793</p></td><td align="center" valign="bottom"><p>0.838</p></td><td align="center" valign="bottom"><p>0.570</p></td><td align="center" valign="bottom"><p>0.759</p></td><td align="center" valign="bottom"><p>0.529</p></td><td align="center" valign="bottom"><p><italic>0.077</italic></p> </td><td align="center" valign="bottom"><p><bold>0.035</bold></p> </td><td align="center" valign="bottom"><p>0.740</p></td><td align="center" valign="bottom"><p>0.220</p></td><td align="center" valign="bottom"><p>0.754</p></td></tr><tr><td align="center" rowspan="2"><p>Int<sub>Flanker</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>−0.081</p></td><td align="center" valign="bottom"><p>−0.018</p></td><td align="center" valign="bottom"><p>−0.234</p></td><td align="center" valign="bottom"><p>−0.032</p></td><td align="center" valign="bottom"><p>−0.094</p></td><td align="center" valign="bottom"><p>−0.112</p></td><td align="center" valign="bottom"><p>−0.141</p></td><td align="center" valign="bottom"><p>−0.098</p></td><td align="center" valign="bottom"><p>−0.112</p></td><td align="center"><p>0.045</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.578</p></td><td align="center" valign="bottom"><p>0.903</p></td><td align="center" valign="bottom"><p>0.105</p></td><td align="center" valign="bottom"><p>0.826</p></td><td align="center" valign="bottom"><p>0.522</p></td><td align="center" valign="bottom"><p>0.444</p></td><td align="center" valign="bottom"><p>0.335</p></td><td align="center" valign="bottom"><p>0.501</p></td><td align="center" valign="bottom"><p>0.444</p></td><td align="center"><p>0.758</p></td></tr><tr><td align="center" rowspan="2"><p>TFS<sub>th</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.034</p></td><td align="center" valign="bottom"><p>−0.023</p></td><td align="center" valign="bottom"><p><bold>0.399</bold></p> </td><td align="center" valign="bottom"><p><bold>0.312</bold></p> </td><td align="center" valign="bottom"><p>−0.177</p></td><td align="center" valign="bottom"><p>−0.149</p></td><td align="center" valign="bottom"><p><bold>−0.314</bold></p> </td><td align="center" valign="bottom"><p><bold>−0.352</bold></p> </td><td align="center"><p>0.027</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.818</p></td><td align="center" valign="bottom"><p>0.873</p></td><td align="center" valign="bottom"><p><bold>0.005</bold></p> </td><td align="center" valign="bottom"><p><bold>0.029</bold></p> </td><td align="center" valign="bottom"><p>0.224</p></td><td align="center" valign="bottom"><p>0.306</p></td><td align="center" valign="bottom"><p><bold>0.028</bold></p> </td><td align="center" valign="bottom"><p><bold>0.013</bold></p> </td><td align="center"><p>0.852</p></td></tr><tr><td align="center" rowspan="2"><p>PTA<sub>BE</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>−0.292</bold></p> </td><td align="center" valign="bottom"><p>−0.083</p></td><td align="center" valign="bottom"><p>−0.010</p></td><td align="center" valign="bottom"><p>−0.092</p></td><td align="center" valign="bottom"><p>0.136</p></td><td align="center" valign="bottom"><p>0.082</p></td><td align="center" valign="bottom"><p>0.097</p></td><td align="center"><p><italic>−0.248</italic></p> </td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>0.042</bold></p> </td><td align="center" valign="bottom"><p>0.572</p></td><td align="center" valign="bottom"><p>0.944</p></td><td align="center" valign="bottom"><p>0.531</p></td><td align="center" valign="bottom"><p>0.353</p></td><td align="center" valign="bottom"><p>0.577</p></td><td align="center" valign="bottom"><p>0.508</p></td><td align="center"><p><italic>0.082</italic></p> </td></tr><tr><td align="center" rowspan="2"><p>HL<sub>diff</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.195</p></td><td align="center" valign="bottom"><p>0.038</p></td><td align="center" valign="bottom"><p>0.087</p></td><td align="center" valign="bottom"><p><italic>0.274</italic></p> </td><td align="center" valign="bottom"><p>0.198</p></td><td align="center" valign="bottom"><p>0.119</p></td><td align="center"><p>0.227</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.180</p></td><td align="center" valign="bottom"><p>0.795</p></td><td align="center" valign="bottom"><p>0.551</p></td><td align="center" valign="bottom"><p><italic>0.057</italic></p> </td><td align="center" valign="bottom"><p>0.174</p></td><td align="center" valign="bottom"><p>0.416</p></td><td align="center"><p>0.113</p></td></tr><tr><td align="center" rowspan="2"><p>DL<sub>quiet</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>0.383</bold></p> </td><td align="center" valign="bottom"><p>−0.115</p></td><td align="center" valign="bottom"><p>−0.008</p></td><td align="center" valign="bottom"><p>−0.118</p></td><td align="center" valign="bottom"><p>−0.130</p></td><td align="center"><p>0.082</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>0.007</bold></p> </td><td align="center" valign="bottom"><p>0.431</p></td><td align="center" valign="bottom"><p>0.959</p></td><td align="center" valign="bottom"><p>0.420</p></td><td align="center" valign="bottom"><p>0.375</p></td><td align="center"><p>0.573</p></td></tr><tr><td align="center" rowspan="2"><p>RT<sub>neutral</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>−0.198</p></td><td align="center" valign="bottom"><p>−0.087</p></td><td align="center" valign="bottom"><p>−0.135</p></td><td align="center" valign="bottom"><p>−0.011</p></td><td align="center"><p>0.217</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.172</p></td><td align="center" valign="bottom"><p>0.552</p></td><td align="center" valign="bottom"><p>0.355</p></td><td align="center" valign="bottom"><p>0.940</p></td><td align="center"><p>0.129</p></td></tr><tr><td align="center" rowspan="2"><p>SS<sub>Pcorr</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>−0.011</p></td><td align="center" valign="bottom"><p>0.081</p></td><td align="center" valign="bottom"><p>0.053</p></td><td align="center"><p><bold>−0.380</bold></p> </td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p>0.940</p></td><td align="center" valign="bottom"><p>0.580</p></td><td align="center" valign="bottom"><p>0.720</p></td><td align="center"><p><bold>0.006</bold></p> </td></tr><tr><td align="center" rowspan="2"><p>SSQ<sub>speech</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>0.707</bold></p> </td><td align="center" valign="bottom"><p><bold>0.728</bold></p> </td><td align="center"><p>0.040</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>&lt;0.0001</bold></p> </td><td align="center" valign="bottom"><p><bold>&lt;0.0001</bold></p> </td><td align="center"><p>0.784</p></td></tr><tr><td align="center" rowspan="2"><p>SSQ<sub>spatial</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>0.701</bold></p> </td><td align="center"><p>0.123</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"><p><bold>&lt;0.0001</bold></p> </td><td align="center"><p>0.393</p></td></tr><tr><td align="center" rowspan="2"><p>SSQ<sub>qualities</sub></p></td><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center"><p>0.058</p></td></tr><tr><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center" valign="bottom"/><td align="center"><p>0.692</p></td></tr></tbody></table></table-wrap></p><p>What can be concluded about the relative importance of the different psychoacoustic and cognitive predictors for explaining individual differences in cocktail-party listening? In our data, the nine predictors were partly correlated (see <xref ref-type="table" rid="tbl2">Table 2</xref>). In such a case, it can be misleading to gauge the relative importance of the predictors by considering the squared standardized regression coefficients (cf. <xref ref-type="bibr" rid="bib104">Tonidandel and LeBreton, 2011</xref>). For this reason, we used the 'dominance analysis' approach proposed by <xref ref-type="bibr" rid="bib13">Budescu (1993)</xref>; which was shown to be a useful measure of the relative importance of predictors in a regression model, both on theoretical grounds and in simulation studies (<xref ref-type="bibr" rid="bib64">LeBreton et al., 2004</xref>; <xref ref-type="bibr" rid="bib101">Thomas et al., 2014</xref>; <xref ref-type="bibr" rid="bib104">Tonidandel and LeBreton, 2011</xref>). Dominance analysis provides a quantitative measure of relative importance by examining the change in the variance-accounted-for (Δ<italic>R</italic><sup>2</sup>) resulting from adding a predictor to all possible regression models containing subsets of the predictors. For example, if there are three predictors (A, B, and C), then there are four possible subset models to which predictor C can be added (that is, models containing only the intercept term, intercept and predictor A, intercept and predictor B, and intercept and predictors A and B, respectively). A predictor’s <italic>general dominance weight</italic> (GDW; <xref ref-type="bibr" rid="bib2">Azen and Budescu, 2003</xref>) is found by averaging the squared semipartial correlations across all of the possible subset models. This measure indexes a variable's contribution to the prediction of the dependent variable, by itself and in combination with the other predictors. The sum of the GDWs is the total proportion of variance explained by the regression model, <italic>R</italic><sup>2</sup>.</p><p>As shown in <xref ref-type="table" rid="tbl1">Table 1</xref>, the general dominance weight was highest for the IPD threshold in the TFS-LF task, followed by the DL-elevation in the intensity discrimination task. According to these results, sensitivity for the binaural TFS and auditory selective attention are the most important predictors of cocktail-party listening. The contribution of flanker interference was much lower, and the GDW for the non-significant predictor sentence span was even slightly higher than the GDW for flanker interference.</p><p>To validate the conclusions based on dominance analysis, we used a second approach to variable selection. In the <italic>Lasso</italic> method proposed by <xref ref-type="bibr" rid="bib102">Tibshirani (1996)</xref>; regression coefficients for predictors with only a small explanatory value are set to 0 (<italic>shrinkage</italic>), so that the Lasso method effectively performs <italic>subset selection</italic>, that is, selects the most important predictors (<xref ref-type="bibr" rid="bib52">James et al., 2013</xref>). The Lasso approach is widely used in the field of statistical learning (<xref ref-type="bibr" rid="bib47">Hastie et al., 2009</xref>). It involves a tuning parameter λ to impose a so-called <italic>l</italic><sub>1</sub>-penalty (<xref ref-type="bibr" rid="bib103">Tibshirani, 2011</xref>) on the regression model. We used 4-fold cross-validation for selecting the best model, that is, the optimal value of λ (<xref ref-type="bibr" rid="bib52">James et al., 2013</xref>). In cross-validation, the set of observations is randomly divided into <italic>k</italic> groups of approximately equal size. The first group is treated as a validation set, and the model is fit on the remaining <italic>k</italic> − 1 groups. The mean squared error is computed on the observations in the validation set, and this procedure is repeated <italic>k</italic> times, each time selecting a different group of observations as the validation set. In this approach, first the λ value corresponding to the smallest cross-validation error is selected, and then the regression model is fit to all of the available observations using the selected value of λ. Compatible with the dominance analysis presented above, the model selected by the Lasso method contained the predictors DL<sub>elev</sub>, TFS<sub>th</sub>, and Int<sub>Flanker</sub> (see <xref ref-type="table" rid="tbl1">Table 1</xref>), and the highest regression coefficients were estimated for DL<sub>elev</sub> and TFS<sub>th</sub>. In addition, the Lasso procedure selected the predictor SS<sub>Pcorr</sub> (see <xref ref-type="table" rid="tbl1">Table 1</xref>). Thus, unlike the ordinary least-squares (OLS) multiple regression, the Lasso indicated a contribution of working memory span to speech identification in noise.</p><p>Finally, it is interesting to compare these multiple regression results to the pairwise partial correlation coefficients with the SRS, controlling for age (see <xref ref-type="table" rid="tbl2">Table 2</xref>). The predictors DL<sub>elev</sub> and TFS<sub>th</sub> showed a significantly negative partial correlation with the SRS, compatible with the results from ordinary least-squares (OLS) regression and the Lasso. As for the Lasso, the partial correlation coefficient for SS<sub>Pcorr</sub> was also significant. It appears possible that the (moderate) correlations between SS<sub>Pcorr</sub> and DL<sub>elev</sub> and age (see <xref ref-type="table" rid="tbl2">Table 2</xref>) increased the standard error of the regression coefficient for SS<sub>Pcorr</sub> in the multiple regression analysis shown in <xref ref-type="table" rid="tbl1">Table 1</xref>. The opposite pattern occurred for Int<sub>Flanker</sub>. Here, the partial correlation coefficient for Int<sub>Flanker</sub> was not significant, unlike in the multiple regressions.</p><p>The relation between the scores on the SSQ questionnaire (<xref ref-type="bibr" rid="bib40">Gatehouse and Noble, 2004</xref>), representing self-reported hearing abilities in daily life, and the performance in the cocktail-party listening task was analyzed via linear multiple regression. The SRS was the criterion variable, and age and the three SSQ subscales (speech hearing: SSQ<sub>speech</sub>; spatial hearing: SSQ<sub>spatial</sub>; other qualities: SSQ<sub>qualities</sub>) were entered as predictors. Using the same criteria as for the regression analysis presented in <xref ref-type="table" rid="tbl1">Table 1</xref> (see Materials and methods), three participants were excluded as outliers. The model explained only a small, non-significant portion of the variance, <italic>R</italic><sup>2</sup> = 0.137, <italic>p</italic>=0.17, <italic>N</italic> = 47. Only the regression coefficient for the 'Other qualities' scale was significant, showing a positive relation between this SSQ subscore and the SRS (see <xref ref-type="table" rid="tbl3">Table 3</xref>). Thus, persons reporting better hearing abilities on the SSQ 'Other qualities' scale tended to perform better in the spatial listening task. As seen in <xref ref-type="table" rid="tbl2">Table 2</xref>, the partial correlations controlling for age indicated a significant negative relation between the DL-elevation and SSQ<sub>speech</sub>, and between the IPD threshold in the TFS-LF test and SSQ<sub>spatial</sub> and SSQ<sub>qualities</sub>.<table-wrap id="tbl3" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.004</object-id><label>Table 3.</label><caption><p>Multiple regression analysis of the relation between the SSQ scores (<xref ref-type="bibr" rid="bib40">Gatehouse and Noble, 2004</xref>) representing self-reported hearing abilities (predictors) and the speech recognition score in the simulated cocktail-party listening task (criterion). <italic>N</italic> = 47.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.004">http://dx.doi.org/10.7554/eLife.16747.004</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center"><p>Predictor</p></th><th align="center"><p>β</p></th><th align="center"><p>SE</p></th><th align="center"><p>t</p></th><th align="center"><p>p</p></th></tr></thead><tbody><tr><td align="center"><p>Intercept</p></td><td align="center" valign="bottom"><p>−1.150</p></td><td align="center" valign="bottom"><p>0.988</p></td><td align="center" valign="bottom"><p>1.160</p></td><td align="center" valign="bottom"><p>0.251</p></td></tr><tr><td align="center"><p>Age</p></td><td align="center" valign="bottom"><p>−0.006</p></td><td align="center" valign="bottom"><p>0.034</p></td><td align="center" valign="bottom"><p>0.170</p></td><td align="center" valign="bottom"><p>0.864</p></td></tr><tr><td align="center"><p>SSQ<sub>speech</sub></p></td><td align="center" valign="bottom"><p>0.006</p></td><td align="center" valign="bottom"><p>0.116</p></td><td align="center" valign="bottom"><p>0.050</p></td><td align="center" valign="bottom"><p>0.958</p></td></tr><tr><td align="center"><p>SSQ<sub>spatial</sub></p></td><td align="center" valign="bottom"><p>−0.160</p></td><td align="center" valign="bottom"><p>0.117</p></td><td align="center" valign="bottom"><p>1.360</p></td><td align="center" valign="bottom"><p>0.181</p></td></tr><tr><td align="center"><p><bold>SSQ<sub>qualities</sub></bold></p> </td><td align="center" valign="bottom"><p><bold>0.321</bold></p> </td><td align="center" valign="bottom"><p><bold>0.142</bold></p> </td><td align="center" valign="bottom"><p><bold>2.250</bold></p> </td><td align="center" valign="bottom"><p><bold>0.030</bold></p> </td></tr></tbody></table></table-wrap></p></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In a relatively large sample of young, normal-hearing participants (<italic>N</italic> = 50; age range 18–30 years), we studied the role of perceptual and cognitive factors for speech understanding in a cocktail-party situation with spatially separated interfering speakers. Our main hypothesis was that individual differences in the ability to direct auditory selective attention to the relevant stimulus, while ignoring distractors, explain a significant proportion of the inter-individual variance in cocktail-party listening performance. To test this hypothesis, we included tasks that assessed auditory and visual selective attention in the presence of distractors, using non-speech stimuli. Among the many different aspects of attention (cf. <xref ref-type="bibr" rid="bib100">Styles, 2006</xref>), this ability seems particularly relevant in a cocktail-party situation where it is necessary to selectively attend to the target speaker and to ignore the interfering speakers and other background noise (<xref ref-type="bibr" rid="bib12">Bronkhorst, 2015</xref>; <xref ref-type="bibr" rid="bib96">Shinn-Cunningham, 2008</xref>).</p><p>In our experiment, the individual ability to selectively attend to an auditory target stimulus in the presence of distractors (measured in an intensity discrimination task under backward masking; <xref ref-type="bibr" rid="bib78">Oberfeld et al., 2014</xref>) as well as the ability to attend to a visual target stimulus (measured in a Flanker task; <xref ref-type="bibr" rid="bib61">Kramer and Jacobson, 1991</xref>) explained a significant portion of the variance in sentence identification performance with two interfering talkers. Together, the two measures of selective attention explained approximately the same proportion of variance as the binaural TFS sensitivity, which was the predictor with the highest relative importance (see <xref ref-type="table" rid="tbl1">Table 1</xref>). These results are compatible with our hypothesis that not only rather basic auditory factors like spatial hearing abilities contribute to individual differences in cocktail-party listening, but that in the cognitive domain a general ability of focusing attention on a relevant target stimulus represents an additional important predictor. One of the few previous studies that measured selective attention in the presence of distractors (<xref ref-type="bibr" rid="bib39">Gatehouse and Akeroyd, 2008</xref>) found that in unaided hearing-impaired listeners (mean age about 66 years) the word recognition performance in static background noise was positively related to performance in the 'Elevator counting with distraction' subtest of the Tests of Everyday Attention. However, the analysis did not control for effects of age. In a recent study (<xref ref-type="bibr" rid="bib17">Cahana-Amitay et al., 2016</xref>), a composite score for 'inhibition' that included the error rate in an incongruent condition of the Stroop color-word test (<xref ref-type="bibr" rid="bib99">Stroop, 1935</xref>) was negatively correlated with sentence-final word recognition (controlling for age) in a group of subjects ranging in age between 55 and 84 years.</p><p>Our data also illustrate that it is only of limited value to use a broad, unspecific concept of 'attention' and to study associations between speech-in-noise understanding and aspects of attention that are not necessarily related to the requirements of cocktail-party listening. Thus, it seems more appropriate to recognize that attention has many facets (<xref ref-type="bibr" rid="bib100">Styles, 2006</xref>), to not aggregate across the performance on tasks measuring very different aspects of attention in order to define a general 'attention' factor, and to formulate hypotheses concerning the potential importance of a particular aspect of attention for speech identification in noise. In this line of thinking, we note that in the simulated cocktail-party listening task as well as in the two tasks measuring auditory and visual selective attention, the participants had a-priori knowledge of the spatial or temporal position of the target. For this reason, the direction of attention to the target could be viewed as being endogenous (top-down) rather than exogenous (bottom up) (<xref ref-type="bibr" rid="bib83">Posner, 1980</xref>). Limitations in the ability to focus attention while performing these tasks should thus be related to the dorsal fronto-parietal attentional system in the cortex rather than to the ventral network (cf. <xref ref-type="bibr" rid="bib14">Buschman and Miller, 2007</xref>; <xref ref-type="bibr" rid="bib24">Corbetta and Shulman, 2002</xref>). To test this hypothesis, future experiments on attentional factors influencing cocktail-party listening could include tasks measuring both the endogenous and exogenous orienting of attention, using for instance temporal or spatial cueing (e.g., <xref ref-type="bibr" rid="bib25">Coull and Nobre, 1998</xref>; <xref ref-type="bibr" rid="bib83">Posner, 1980</xref>). Alternatively, one could argue that in the intensity discrimination task, the onset of the backward masker elicits a capture of attention away from the target tones (e.g., <xref ref-type="bibr" rid="bib31">Desimone and Duncan, 1995</xref>; <xref ref-type="bibr" rid="bib53">Jonides and Yantis, 1988</xref>; <xref ref-type="bibr" rid="bib111">Yantis and Jonides, 1990</xref>). Thus, it might even be necessary to further qualify the description of the particular aspect of attention that is indexed by the intensity discrimination task under backward masking and say that is measures the ability to suppress salient, but task-irrelevant auditory events.</p><p>The working memory span did not show a strong relation to cocktail-party listening. Thus, although the sentence identification task we presented requires working memory for storing the sequence of five words, the performance on this task appeared to be more strongly limited by failures of selective attention than by memory aspects. This result is compatible with previous data indicating that working memory capacity and speech identification in noise are associated in older, hearing-impaired participants (see <xref ref-type="bibr" rid="bib1">Akeroyd, 2008</xref>), while in normal hearing subjects this correlation is weaker or even absent (<xref ref-type="bibr" rid="bib37">Füllgrabe et al., 2016</xref>). Thus, measures of selective attention should be included in future studies instead of focusing only on working memory capacity. In general, working memory and attention are not independent (<xref ref-type="bibr" rid="bib26">Cowan et al., 2005</xref>). For instance, <xref ref-type="bibr" rid="bib22">Conway et al. (2001)</xref> studied the probability that in a dichotic listening task participants recognize their own name on the ignored channel (<xref ref-type="bibr" rid="bib71">Moray, 1959</xref>), and found that this probability was higher in participants with a low WM span. Also, the working memory load affects speech understanding in a cocktail-party setting (<xref ref-type="bibr" rid="bib35">Francis, 2010</xref>). In line with these results, in our data the working memory span showed a marginally significant negative correlation (controlling for age) with the DL-elevation (auditory selective attention), see <xref ref-type="table" rid="tbl2">Table 2</xref>.</p><p>Our results confirm the association between binaural TFS sensitivity for speech identification in a spatial listening task, compatible with earlier studies (<xref ref-type="bibr" rid="bib36">Füllgrabe et al., 2014</xref>; <xref ref-type="bibr" rid="bib73">Neher et al., 2011</xref>; <xref ref-type="bibr" rid="bib74">Neher et al., 2012</xref>; <xref ref-type="bibr" rid="bib87">Ruggles et al., 2011</xref>; <xref ref-type="bibr" rid="bib95">Schoof and Rosen, 2014</xref>). The significant negative association between the IPD threshold and the SRS could be attributed to a reduced benefit from ITD cues in listeners with impaired binaural TFS sensitivity, although a reduction in TFS sensitivity could be also associated with other perceptual impairments beyond sound source localization (<xref ref-type="bibr" rid="bib70">Moore, 2008</xref>). Spatial cues facilitate auditory streaming/grouping (e.g., <xref ref-type="bibr" rid="bib29">Darwin and Hukin, 1999</xref>; <xref ref-type="bibr" rid="bib30">David et al., 2015</xref>), selective attention (e.g., <xref ref-type="bibr" rid="bib51">Ihlefeld and Shinn-Cunningham, 2008</xref>), and speech recognition (e.g., <xref ref-type="bibr" rid="bib27">Culling et al., 2004</xref>). The importance of spatial cues was reported to increase with the number of interfering sound sources (<xref ref-type="bibr" rid="bib112">Yost et al., 1996</xref>). Thus, one should expect a smaller influence of TFS sensitivity in situations with only one interfering speaker (compared to two as in the present study). Also, the simulated anechoic environment might have caused an overestimation of the importance of ITD cues. In a typical reverberant environment, spatial cues to sound source segregation are reduced (e.g., <xref ref-type="bibr" rid="bib63">Lavandier and Culling, 2010</xref>). It remains to be shown whether the ability to attend to a target in the presence of distractors plays a stronger role than binaural TFS sensitivity in a reverberant setting. On the other hand, the spatial separation of 25° between target and distractor speakers was larger than in some previous studies that used a separation of only 15° (<xref ref-type="bibr" rid="bib87">Ruggles et al., 2011</xref>, <xref ref-type="bibr" rid="bib88">2012</xref>, <xref ref-type="bibr" rid="bib89">Ruggles and Shinn-Cunningham, 2011</xref>). The corresponding stronger ITD cues in our study might have reduced the importance of the sensory representation of the acoustic stimulus for task performance, which would emphasize the relative importance of central factors. Note that in cocktail-party situations in daily life, the spatial separation between the target speakers and competing speakers will often be even larger than 25°.</p><p>The self-report measures of hearing abilities (SSQ scores) showed only weak associations with performance in the cocktail-party listening task (controlling for age). In hearing-impaired listeners, some earlier studies (<xref ref-type="bibr" rid="bib39">Gatehouse and Akeroyd, 2008</xref>; <xref ref-type="bibr" rid="bib48">Heinrich et al., 2015</xref>) also reported rather small correlations between SSQ scores and speech identification in static or amplitude-modulated background noise, even without controlling for age. <xref ref-type="bibr" rid="bib36">Füllgrabe et al. (2014)</xref> found no correlation between SSQ scores and speech-in-noise perception in audiometrically normal-hearing listeners.</p><p>Compared to previous studies on predictors of cocktail-party listening, our experiments introduced several methodological improvements. The sample size in our study was larger than in some previous experiments, so that it was possible to measure the influence of several variables on sentence identification in noise, without first combining predictors into a small number of factors. We also used multiple linear regression analyses, rather than pairwise correlations as in some previous experiments. Predictors like hearing thresholds, age, working memory span and TFS sensitivity are partly correlated (see <xref ref-type="table" rid="tbl2">Table 2</xref>). Multiple linear regression accounts for correlations among the predictors (<xref ref-type="bibr" rid="bib41">Gauss, 1821</xref>), while interpreting pairwise correlations is extremely difficult for a large set of intercorrelated predictors. Unlike most previous studies, we also report the reliability of the measured variables, which in most cases was acceptable to high. Finally, we used two established approaches for assessing the relative importance of predictors, dominance analysis (<xref ref-type="bibr" rid="bib13">Budescu, 1993</xref>) and Lasso (<xref ref-type="bibr" rid="bib102">Tibshirani, 1996</xref>). The Lasso method was proposed to avoid some of the problems of forward or backward selection in stepwise regression (<xref ref-type="bibr" rid="bib45">Harrell, 2015</xref>; <xref ref-type="bibr" rid="bib52">James et al., 2013</xref>).</p><p>Despite the new findings concerning the role of the ability to direct selective attention to a target stimulus for speech identification in noise and the methodological features of our study, there are of course several limitations. First, we included only a single measure each for auditory and selective attention in the presence of distractors. From a psychometric point of view, it would be desirable to include different paradigms, in order to test whether the results generalize to different tasks indexing selective attention, and to increase the reliability of the measures of selective attention. In the auditory modality, we used intensity discrimination under backward masking as an index of selective attention. In this task, the target sounds have to be selected on the basis of their temporal position within a trial. We had decided against a task measuring the <italic>spatial</italic> direction of attention (e.g., <xref ref-type="bibr" rid="bib90">Sach et al., 2000</xref>; <xref ref-type="bibr" rid="bib97">Spence and Driver, 1994</xref>) because the performance on such a task depends on abilities of spatial hearing, which we assessed separately in terms of the binaural TFS sensitivity. Also, the precise perception of the temporal structure of speech is important for intelligibility (<xref ref-type="bibr" rid="bib117">Zion Golumbic et al., 2012</xref>), and non-simultaneous masking can negatively affect speech identification (<xref ref-type="bibr" rid="bib32">Dirks and Bower, 1970</xref>). Still, it would be interesting to study whether the spatial direction of attention shows a similar relation to cocktail-party listening as the temporal direction of attention. Spatial and temporal attention were reported to involve different brain areas (e.g., <xref ref-type="bibr" rid="bib69">Michalka et al., 2015</xref>).</p><p>Second, we studied a relatively young group of listeners. It remains to be shown whether attentional abilities play a similar role in normal-hearing older subjects, or in hearing-impaired listeners. Age-related changes in selective attention have been reported (<xref ref-type="bibr" rid="bib113">Zanto and Gazzaley, 2014</xref>), just as for other cognitive skills (e.g., <xref ref-type="bibr" rid="bib91">Salthouse, 1996</xref>; <xref ref-type="bibr" rid="bib93">Sander et al., 2012</xref>). At the same time, the probability of audiometrically relevant hearing losses as well as of 'hidden hearing losses' (<xref ref-type="bibr" rid="bib81">Plack et al., 2014</xref>) increases with age, partly due to noise exposure across the life span. In fact, the TFS sensitivity shows a gradual deterioration with age in normal-hearing listeners (<xref ref-type="bibr" rid="bib38">Füllgrabe, 2013</xref>; <xref ref-type="bibr" rid="bib43">Grose and Mamo, 2010</xref>; <xref ref-type="bibr" rid="bib59">King et al., 2014</xref>; <xref ref-type="bibr" rid="bib86">Ross et al., 2007</xref>). Thus, the relative importance of psychoacoustic and cognitive predictors of speech understanding in a cocktail-party situation might differ between young, middle-aged and older groups, and future research should address this aspect.</p><p>Third, our participants were rather homogeneous in terms of education and (being university students) very likely also in terms of socioeconomic status and cognitive aptitude. Thus, it would be desirable to study potential psychoacoustic and cognitive predictors in a less homogeneous and more representative sample.</p><p>Fourth, our simulated cocktail-party listening task presented two spatially separated interfering speakers with the same voice as the target speaker, producing sentences with a fixed syntactical structure, and presented with a spatial separation of only 25° from the target speaker. These characteristics likely rendered the task more difficult than a realistic cocktail-party listening situation. On the other hand, communication situations in daily life often include some relatively static background noise in addition to competing speakers, while in our experiment no background noise was presented. Taken together, we assume realistic communication situations to be somewhat, but not dramatically, less difficult than the simulated cocktail-party listening task we presented. For this reason, although the average speech identification performance should be somewhat better in many realistic situations, we do not assume the latter situations to be so easy that individual differences are strongly reduced. Thus, the association between for selective attention in the presence of distractors or binaural TFS-sensitivity and speech-in-noise identification should apply to other cocktail-party situations, although ultimately this is an empirical question that should be tested in future experiments.</p><p>In conclusion, the individual ability to focus attention on a target stimulus in the presence of distractors explained a significant portion of the inter-individual variance in cocktail-party listening performance in a relatively young sample of normal-hearing listeners. Previous studies had reported that speech identification in multitalker situations is associated not only to auditory abilities such as binaural TFS sensitivity, but also to cognitive factors, predominantly in older and often hearing-impaired listeners (e.g., <xref ref-type="bibr" rid="bib1">Akeroyd, 2008</xref>) but also in young normal-hearing listeners (<xref ref-type="bibr" rid="bib114">Zekveld et al., 2013</xref>). Our results highlight the importance of studying aspects of attention directly relevant for speech identification in noise, rather than measuring associations with less relevant facets of attention such as visual search or to aggregate across very different aspects of attention in order to define a general 'attention' factor.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Fifty listeners with normal hearing participated in the experiment voluntarily. All listeners reported normal hearing and no history of hearing disorders, and normal or corrected-to-normal visually acuity. They had hearing thresholds better than 20 dB HL at octave frequencies between 125 Hz and 4 kHz (that is, in the frequency region most important for speech; <xref ref-type="bibr" rid="bib15">Byrne et al., 1994</xref>), calculated on the basis of equivalent threshold sound pressure levels for the Sennheiser HDA 200 earphones (<xref ref-type="bibr" rid="bib44">Han and Poulsen, 1998</xref>). The maximal asymmetry between left and right ear was 15 dB in the frequency range between 125 Hz and 4 kHz. In the high-frequency range, for all but one listener the hearing thresholds were also better than 20 dB HL at 6 and 8 kHz.</p><p>The sample size of <italic>N</italic> = 50 was selected so that in the multiple regression analysis containing nine predictors the power to detect a moderate deviation of a single linear regression coefficient from 0 (partial <italic>R</italic><sup>2</sup> = 0.15) was 1 − β = 0.8 (two-tailed test), with α set to 0.05. According to G*Power (<xref ref-type="bibr" rid="bib34">Faul et al., 2009</xref>), the required minimum sample size is 47.</p><p>All participants were native speakers of German. Most of them were psychology students at the Johannes Gutenberg – Universität Mainz, they received partial course credit or were paid for their participation. The experiment was conducted according to the principles expressed in the Declaration of Helsinki. All listeners participated voluntarily after providing informed written consent, after the topic of the study and potential risks had been explained to them. They were uninformed about the experimental hypotheses. The study was approved by the ethics committee of the Department of Psychology, Johannes Gutenberg-Universität Mainz.</p><p>The participants (39 female, 11 male) ranged in age between 18 and 30 years (mean age 21.5 y, SD = 3.1 y). All held the German general qualification for university entrance (Abitur), and 44 of them were psychology students. Since very good grades in secondary school are required for admission in psychology at German universities, the group can be assumed to have relatively high test intelligence, although we did not conduct an intelligence test (<xref ref-type="bibr" rid="bib36">Füllgrabe et al., 2014</xref>).</p></sec><sec id="s4-2"><title>Apparatus</title><p>The auditory stimuli were generated digitally, played back via an RME (Haimhausen, Germany) ADI/S digital-to-analog converter (<italic>f</italic><sub>s</sub> = 44.1 kHz, 24-bit resolution), attenuated by a TDT (Alachua, FL) PA5 programmable attenuator, buffered by a TDT HB7 headphone buffer, and presented via Sennheiser (Wedemark, Germany) HDA 200 circumaural headphones calibrated according to <xref ref-type="bibr" rid="bib50">IEC 318 (1970)</xref>. The visual stimuli and task instructions were presented on a 17'' TFT computer monitor. The experiment was conducted in a double-walled sound-insulated chamber (IAC Acoustics Germany, Niederkrüchten). Responses were collected via a numeric keypad, a computer keyboard, or a mouse, depending on the task.</p></sec><sec id="s4-3"><title>Tasks</title><sec id="s4-3-1"><title>Audiometric thresholds</title><p>Detection thresholds were measured bilaterally using Békésy tracking (<xref ref-type="bibr" rid="bib16">Békésy, 1947</xref>; <xref ref-type="bibr" rid="bib46">Hartmann, 2005</xref>) with pulsed 270-ms pure tones including 10-ms cos<sup>2</sup> on- and off-ramps. The starting frequency was 100 Hz. The frequency increased exponentially from tone to tone, at a rate of 1.4 octaves/minute. For each listener and ear, thresholds were computed as the average sound pressure level in a third-octave band around octave frequencies between 125 Hz and 4 kHz. The average hearing levels are shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>. The individual better-ear pure tone average threshold (PTA<sub>BE</sub>) at octave frequencies between 125 Hz and 4 kHz was entered as a predictor of cocktail-party listening in the regression analyses. In addition, the individual average bilateral asymmetry of the thresholds at the same octave frequencies (HL<sub>diff</sub>) was included as a predictor, because asymmetric thresholds can affect binaural unmasking on the basis of ITD cues (<xref ref-type="bibr" rid="bib10">Bronkhorst and Plomp, 1989</xref>).<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.005</object-id><label>Figure 1.</label><caption><title>Average audiometric hearing thresholds (in dB HL), at octave frequencies between 125 Hz and 4 kHz (<italic>N =</italic> 50).</title><p>Left panel: left ear. Right panel: right ear. Error bars represent 95% confidence intervals.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.005">http://dx.doi.org/10.7554/eLife.16747.005</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16747-fig1-v1"/></fig></p></sec><sec id="s4-3-2"><title>Cocktail-party listening task</title><p>As a measure of speech understanding in adverse listening conditions, we used a simulated cocktail-party listening task with two interfering speakers. The listeners performed a sentence identification task with the speech material of the Oldenburger Satztest (OLSA; HörTech gGmbH, Oldenburg), which is a German matrix test (<xref ref-type="bibr" rid="bib107">Wagener et al., 1999a</xref>). The speech material consists of sentences with the syntactic structure <italic>name-verb-numeral-adjective-object</italic> (e.g., 'Peter kauft vier kleine Messer' – 'Peter buys four small knives'). The sentences were constructed by pseudo-randomly selecting one of ten alternatives for each word position. This results in syntactically correct but semantically unpredictable sentences, which makes it possible to use each sentence several times for the same listener. In total, 100 different sentences are available in the OLSA test. The sentences are produced by an adult male speaker and are optimized for similar intelligibility (<xref ref-type="bibr" rid="bib108">Wagener et al., 1999b</xref>). The task was to identify the sentence produced by the target speaker. The matrix of 5 (word position) × 10 (alternatives) words constituting the sentence test was displayed on a computer monitor. On each trial, subjects were asked to select the five words they had just heard using a computer mouse. The selected words were displayed in a row below the matrix of test words. Initially, the selected words were displayed in black ink. After confirming their selection by clicking on an 'Accept' button, the participants received immediate feedback concerning the correctness of their selection of words. Correctly identified words were colored in green, and incorrect words were colored in red. This visual feedback was presented for 500 ms. The next trial then started automatically after a pause of 500 ms.</p><p>The target speaker and the two interfering speakers were presented binaurally via headphones, using head related impulse responses (HRIRs) to simulate the different spatial position of the sound sources. The target speaker was presented from the front (0° azimuthal angle). The interfering speakers were presented 25° to the left and 25° to the right of the target speaker. HRIRs from an anechoic room were used because a previous study showed higher inter-individual differences in speech understanding in an anechoic condition, compared to conditions with reverberation (<xref ref-type="bibr" rid="bib89">Ruggles and Shinn-Cunningham, 2011</xref>). They had been recorded with a head-and-torso simulator Brüel &amp; Kjær Type 4128C at a distance of 80 cm between loudspeaker and microphones and an elevation of 0° (<xref ref-type="bibr" rid="bib55">Kayser et al., 2009</xref>). In the experiment, the target speaker was presented at an average sound pressure level of 58 dB SPL, while each interfering speaker was presented at 60 dB SPL.</p><p>Each participant first received five trials without interfering speakers, to become familiar with the task and the response interface. Next, five trials were presented with a single interfering speaker, positioned 25° to the right of the listener. After these brief practice blocks, each listener received three experimental blocks with two interfering speakers (25° left and right), containing 50 trials each. On each trial, the sentences produced by the target speaker and the two interfering speakers were selected at random from the set of 100 test sentences, of course with the restriction that none of the three speakers produced an identical word. Note that the same male voice was used for the target speaker and the two interfering speakers, which made the task relatively difficult (<xref ref-type="bibr" rid="bib19">Cherry, 1953</xref>).</p><p>For each listener and each block of 50 trials collected in the sentence identification task with two interfering speakers, the proportion of correctly identified words for the target speaker was computed (speech recognition score; SRS). Because non-normally distributed measures can cause problems in regression/correlation analyses (e.g., <xref ref-type="bibr" rid="bib7">Bishara and Hittner, 2012</xref>) and repeated-measures ANOVAs (e.g., <xref ref-type="bibr" rid="bib75">Oberfeld and Franke, 2013</xref>), the proportions were arcsin-square-root transformed (<xref ref-type="bibr" rid="bib3">Bartlett, 1936</xref>) to obtain a closer approximation to the normal distribution. The data were analyzed with a repeated-measures analysis of variance (rmANOVA), using the multivariate approach. Partial η<sup>2</sup> is reported as a measure of association strength. The same type of rmANOVAs is used in all following analyses. An rmANOVA showed a significant effect of block, <italic>F</italic>(2, 48) = 47.34, p&lt;0.001. The mean proportion of correct responses was considerably lower in the first block than in the two following blocks, compatible with data by <xref ref-type="bibr" rid="bib109">Wagener et al. (1999c)</xref> who reported a sizeable practice effect in steady background noise. For this reason, the data from the first block were excluded from further analyses. An rmANOVA conducted on the data from blocks 2 and 3 still showed a significant while rather weak effect of block on the SRS, <italic>F</italic>(1, 49) = 4.54, <italic>p</italic>=0.038, <xref ref-type="bibr" rid="bib21">Cohen (1988)</xref> <italic>d<sub>z</sub></italic> = 0.30. The degree of agreement between the two measurements of the SRS (blocks 2 and 3) represents test-retest reliability and was assessed by an absolute agreement definition of the intraclass correlation in a two-way mixed-model (ICC(A,2) in the nomenclature of <xref ref-type="bibr" rid="bib68">McGraw and Wong, 1996</xref>). The reliability was high, ICC(A,2) =0.934.</p><p><xref ref-type="fig" rid="fig2">Figure 2</xref> shows a histogram of the average individual speech recognition score (proportion correct) in the simulated cocktail-party listening task (blocks 2 and 3). As expected, the listeners showed considerable variation in the SRS. The arcsin-sqrt transformed average individual proportion correct on blocks 2 and 3 (SRS) served as the measure of cocktail-party listening, and was used as the <italic>criterion variable</italic> in the regression analyses.<fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.006</object-id><label>Figure 2.</label><caption><title>Average individual proportion correct (speech recognition score; SRS) in the simulated cocktail-party listening task with two spatially separated interfering speakers (<italic>N =</italic> 50).</title><p>This measure served as the criterion variable in the regression analyses. The mean (<italic>M</italic>) and the standard deviation (SD) are displayed.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.006">http://dx.doi.org/10.7554/eLife.16747.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-16747-fig2-v1"/></fig></p></sec><sec id="s4-3-3"><title>Auditory intensity discrimination under backward masking (auditory selective attention)</title><p>Intensity difference limens (DLs) in quiet and under backward masking were measured using a two-interval, two alternative forced-choice task and an adaptive procedure with a three down, one up rule (<xref ref-type="bibr" rid="bib65">Levitt, 1971</xref>). The targets and the maskers were 1-kHz pure tones with a steady-state duration of 20 ms, presented to the right ear. The tones were gated on and off with 5-ms cosine-squared ramps. The standard level was 60 dB SPL. An intensity increment – that is, a pure tone of the same frequency, duration and temporal envelope – was added in-phase to the standard in one of the observation intervals (selected randomly). The level of the backward masker was 90 dB SPL. The silent interval between standard offset and masker onset was 50 ms (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). This ISI value is in the range where the effects of backward and forward masking on speech identification were observed (<xref ref-type="bibr" rid="bib32">Dirks and Bower, 1970</xref>). The temporal interval between the onsets of the two target tones (standard and standard-plus-increment) was 800 ms. The task was to select the interval containing the louder target tone (that is, the standard-plus-increment), and to ignore the maskers. Visual trial-by-trial feedback was provided. In the adaptive procedure, the initial level of the intensity increment, expressed in terms of 10 log<sub>10</sub>(△<italic>I</italic>/<italic>I</italic>), where △<italic>I</italic> is the intensity difference between the standard-plus-increment and the standard and <italic>I</italic> is the intensity of the standard, was 8 dB. For the in-quiet condition, the step size was 5 dB until the third reversal, and 2 dB for the remaining six reversals. In the backward-masking condition, four reversals were collected with the larger and eight reversals with the smaller step size. The arithmetic mean of 10 log<sub>10</sub>(△<italic>I</italic>/<italic>I</italic>) from the fourth (in quiet) or fifth reversal (backward masking) up to the last even-numbered reversal was taken as the difference limen corresponding to 79.4% correct. Adaptive tracks where the standard deviation of 10 log<sub>10</sub>(△<italic>I</italic>/<italic>I</italic>) at the counting reversals exceeded 7 dB were excluded from the data analysis, which affected 5 tracks (1% of the total of 470 tracks). After a brief practice block, two blocks were obtained in quiet, followed by three blocks under backward masking.<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.007</object-id><label>Figure 3.</label><caption><title>Schematic depiction of the two-interval intensity discrimination task used to measure auditory selective attention.</title><p>Green: target tones. Red: backward maskers ('distractors'). The standard (<italic>S</italic>) was a 1 kHz tone presented at 60 dB SPL. An intensity increment (<italic>I</italic>) was presented in either the first or the second interval, with equal a-priori probability. The task was to select the interval containing the louder target (that is, standard-plus-increment). The maskers were 1 kHz tones presented at 90 dB SPL. The same temporal configuration was used in the in-quiet condition, except that the maskers were not presented.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.007">http://dx.doi.org/10.7554/eLife.16747.007</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16747-fig3-v1"/></fig></p><p>An rmANOVA with the within-subjects factor block (1, 2, 3) showed no significant effect of block on the DL under backward masking, <italic>F</italic>(2, 44) = 1.03, <italic>p</italic>=0.90. Thus, there was no significant practice effect, and therefore the average individual DL under backward masking (DL<sub>masked</sub>) across the three blocks was computed. The reliability of the masked DL across the three measurements (blocks) was moderate, ICC(A,3) = 0.871.</p><p>The average DL in quiet (DL<sub>quiet</sub>) was included as a predictor in the regression analyses, representing a suprathreshold measure of hearing ability that is not related to selective attention. The reliability of DL<sub>quiet </sub>across the two measurements (blocks) was ICC(A,2) = 0.660.</p><p>We used the elevation of the intensity-DL caused by the backward masker as a measure of auditory selective attention, as in previous studies (<xref ref-type="bibr" rid="bib78">Oberfeld et al., 2014</xref>). The DL-elevation denotes the difference between the DL under masking and the DL in quiet, DL<sub>elev</sub> = DL<sub>masked</sub> − DL<sub>quiet</sub>. As <xref ref-type="fig" rid="fig4">Figure 4</xref> shows, there was considerable variation in the individual DL-elevations under masking, as expected.<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.008</object-id><label>Figure 4.</label><caption><title>Individual elevation of the intensity difference limen caused by the backward maskers (DL<sub>elev</sub>), defined as the difference between the DL under masking and the DL in quiet.</title><p>Lower values represent a better capability of directing auditory selective attention to the target tones. <italic>N =</italic> 50.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.008">http://dx.doi.org/10.7554/eLife.16747.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-16747-fig4-v1"/></fig></p></sec><sec id="s4-3-4"><title>Binaural sensitivity for the temporal fine structure</title><p>The binaural sensitivity to temporal fine structure information was measured as the smallest detectable interaural phase difference (IPD) of a sinusoidal carrier relative to an IPD of 0°, using the TFS-LF test proposed by <xref ref-type="bibr" rid="bib49">Hopkins and Moore (2010)</xref>. In a two-interval task, four pure tones (500 Hz) were presented binaurally in each interval. In one of the intervals (selected randomly), the second and fourth tone were presented with an IPD greater than 0° between the right and left ear, while the IPD was 0° for the first and the third tone. If the listener is sensitive to the change in IPD, then the four tones are perceived as changing in lateralization. In the other interval, all tones were presented with an interaural phase difference of IPD = 0°, corresponding to no change in lateralization from tone to tone. All tones were presented at 30 dB SL with a steady-state duration of 300 ms and 50 ms cosine-squared on- and offset ramps, 20 ms pauses between the tones within an interval, and 200 ms silence between the two intervals. The task was to identify the interval which contained the tones with the phase shift and thus elicited the perception of a location change. Visual trial-by-trial feedback was provided. The initial phase shift was IPD =180° and was divided by <italic>a</italic> = (1.25)<sup>2</sup> in case of three consecutive correct responses, or multiplied by <italic>a</italic> after an incorrect response (three down, one up rule). After the third reversal, the step size was reduced to <italic>a</italic> = 1.25. The experimental block ended when nine reversals had been collected or 70 trials had been presented. The geometric mean of the IPD at the last six reversals was taken as the IPD threshold. After a brief practice block, two threshold estimates were obtained. Adaptive tracks in which the SD of the log<sub>10</sub>- transformed values of the IPD at the counting reversals was higher than 0.3 or where less than 4 reversals had been collected were excluded from the analysis, which affected only 2 of the 100 tracks. The arithmetic mean of the IPD threshold obtained in the two blocks presenting the TFS-LF test was used as a predictor in the regression analyses (TFS<sub>th</sub>), representing <italic>sensitivity for the temporal fine structure</italic>. The reliability of TFS<sub>th</sub> across the two measurements (blocks) was ICC(A,2) = 0.682. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows the distribution of TFS<sub>th</sub>. As expected, there was considerable inter-individual variation of the binaural TFS sensitivity, compatible with previous reports of both monaural (<xref ref-type="bibr" rid="bib87">Ruggles et al., 2011</xref>) and binaural TFS sensitivity (<xref ref-type="bibr" rid="bib38">Füllgrabe, 2013</xref>; <xref ref-type="bibr" rid="bib86">Ross et al., 2007</xref>).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.009</object-id><label>Figure 5.</label><caption><title>Individual IPD thresholds in the TFS-LF test (TFS<sub>th</sub>).</title><p>Lower values represent better binaural sensitivity for the temporal fine structure. <italic>N =</italic> 50.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.009">http://dx.doi.org/10.7554/eLife.16747.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-16747-fig5-v1"/></fig></p></sec><sec id="s4-3-5"><title>Flanker task (visual selective attention)</title><p>To measure spatial visual selective attention, a flanker task as established by <xref ref-type="bibr" rid="bib33">Eriksen and Eriksen (1974)</xref> was used, in a variant proposed by <xref ref-type="bibr" rid="bib61">Kramer and Jacobson (1991)</xref>. The participants' task was to decide whether a target line presented on a computer screen was dotted or dashed. The target line was presented in vertical orientation, on the center of the display. It was surrounded by other lines, the so-called flankers. In one condition (<xref ref-type="fig" rid="fig6">Figure 6</xref>, right column), the two vertical lines adjacent to the target line were associated with the <italic>incompatible</italic> response. If the target line was dashed, the distractor lines were dotted, and vice versa. In a control condition (<xref ref-type="fig" rid="fig6">Figure 6</xref>, left column), the adjacent distractor lines were solid, and thus not associated with one of the responses relevant for the target line, this is the <italic>neutral condition</italic>. The two flanker lines adjacent to the target line were either connected with the target line with horizontal solid lines (<xref ref-type="fig" rid="fig6">Figure 6</xref>, upper row), or they were connected with two additional, vertically oriented solid lines (<xref ref-type="fig" rid="fig6">Figure 6</xref>, lower row). In the former condition ('same object'), the target line and the distractor lines can be expected to be perceived as belonging to the same visual object (<xref ref-type="bibr" rid="bib61">Kramer and Jacobson, 1991</xref>). In the latter condition ('different object'), the target line and the distractors should be grouped into separate objects. According to the concept of object-based attention (e.g., <xref ref-type="bibr" rid="bib54">Kahneman et al., 1981</xref>), ignoring the flankers should be more difficult if the flankers and the target are perceived as belonging to the same object. To further emphasize the grouping, the target line and the adjacent flankers were presented in the same color in the same-object condition, and in different colors in the different-object condition. The colors blue and green were used, and the target line was equally often presented in blue and in green.<fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.010</object-id><label>Figure 6.</label><caption><title>Example stimuli from the flanker task (<xref ref-type="bibr" rid="bib61">Kramer and Jacobson, 1991</xref>) used to measure spatial visual selective attention.</title><p>The participants' task was to decide whether the central <italic>target line</italic> was dotted or dashed. In the <italic>neutral condition</italic> (left column), the neighboring flanker lines were solid and therefore not associated with a response. In the <italic>incompatible condition</italic> (right column), the flanker lines were associated with the incompatible response. The horizontal lines and the colors promoted the perceptual grouping of the target line and the flankers as either belonging to the <italic>same object</italic> (upper row), or into <italic>different objects</italic> (lower row).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.010">http://dx.doi.org/10.7554/eLife.16747.010</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-16747-fig6-v1"/></fig></p><p>The stimuli were presented on a CRT display (frame rate 85 Hz), with a viewing distance of 100 cm. The size of the vertical lines was 0.9° of visual angle (vertical) by 0.04° (horizontal). The horizontal separation between the lines was 0.25°. The trial started with a blank gray screen presented for 500 ms, followed by a fixation cross presented for 200 ms, after which the stimulus was presented. Participants responded by pressing two designated buttons on a numeric keypad, and received immediate visual feedback concerning the correctness of the response. They first received a practice block containing all of the 16 combinations of target type (dotted, dashed), distractor type (neutral, incompatible), object condition (same object, different object), and target color (blue, green). Then, three experimental blocks were presented. In each block, all of the 16 conditions were presented four times (64 trials/block), in random order.</p><p>Response times (RTs) below 200 ms or above 3000 ms were excluded from the analysis, which affected less than 0.1% of the trials. For each subject, the average correct RT on neutral trials (RT<sub>neutral</sub>) was computed as a measure of <italic>processing speed</italic> (e.g., <xref ref-type="bibr" rid="bib91">Salthouse, 1996</xref>). Because the asymmetric distribution of RTs can cause problems in regression/correlation analyses (e.g., <xref ref-type="bibr" rid="bib7">Bishara and Hittner, 2012</xref>) and repeated-measures ANOVAs (e.g., <xref ref-type="bibr" rid="bib75">Oberfeld and Franke, 2013</xref>), the RTs were log-transformed prior to all analyses. An rmANOVA on the RTs in the neutral condition showed marginally significant effect of block, <italic>F</italic>(2, 98) = 2.39, <italic>p</italic>=0.097. The mean RT was significantly higher in the first block than in blocks 2 and 3, representing a practice effect. For this reason, the data from block 1 were excluded from further analyses. The reliability across the two remaining blocks was high, ICC(A,2) = 0.920. The average RT on neutral trials in blocks 2 and 3 was used as a predictor (RT<sub>neutral</sub>).</p><p>As a measure of <italic>visual selective attention</italic>, we used the flanker interference, defined as the difference between (log-transformed) correct RTs in the incompatible condition and the neutral condition (Int<sub>Flanker</sub> = RT<sub>incompatible</sub> − RT<sub>neutral</sub>), averaged across the same-object and different-object condition and the two blocks (2 and 3). Lower values represent a better capability of directing visual selective attention to the target line (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). The reliability of Int<sub>Flanker</sub> across the two measurements (blocks 2 and 3) was lower than desirable, ICC(A,2) = 0.596.<fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.16747.011</object-id><label>Figure 7.</label><caption><title>Individual flanker interference (Int<sub>Flanker</sub>) in the visual attention task.</title><p>Lower values represent a better capability of directing visual selective attention to the target line. <italic>N =</italic> 50.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.16747.011">http://dx.doi.org/10.7554/eLife.16747.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-16747-fig7-v1"/></fig></p></sec><sec id="s4-3-6"><title>Sentence span task (working memory capacity)</title><p>Working memory (WM) capacity was measured with a reading span test, originally proposed by <xref ref-type="bibr" rid="bib28">Daneman and Carpenter (1980)</xref>, which is one of the most established working memory span tasks (<xref ref-type="bibr" rid="bib23">Conway et al., 2005</xref>). A computer version was used (<xref ref-type="bibr" rid="bib66">Lewandowsky et al., 2010</xref>). On each trial, the participants saw an alternating sequence of sentences and consonants. The task was to judge the correctness of each sentence and to remember the following consonant for later serial recall. The sentences were taken from the 'easy' variant of the German version (WMC Multilingual, downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.psychologie.uzh.ch/fachrichtungen/allgpsy/Software.html">http://www.psychologie.uzh.ch/fachrichtungen/allgpsy/Software.html</ext-link>). After a 1.5 s fixation cross, the first semantically correct (e.g., 'Every rabbit has fur.') or incorrect (e.g., 'Tomorrow is in the past.') sentence appeared centrally on the screen. The participants pressed one of two designated buttons on a computer keyboard to classify the sentence as correct or incorrect. On button press, the sentence disappeared and a single consonant was presented centrally for 1 s. After a 100-ms blank interval, the next sentence appeared. Depending on the list length, three to seven of these sentence-consonant sequences were presented. After the complete list had been presented, the participant was asked to type the remembered series of consonants into a response box displayed on the computer screen. The participants were required to type as many letters as were actually presented in the trial. They were informed that the order of letters mattered and were hence instructed to guess if necessary, rather than skip letters that they could not remember. No feedback was provided.</p><p>Each participant received two trials for each of the five list lengths (3, 4, 5, 6, and 7), in random order. The proportion of consonants recalled correctly (that is, reproduced in the correct list position), averaged across the 10 lists, was computed for each subject (partial credit scoring; <xref ref-type="bibr" rid="bib23">Conway et al., 2005</xref>). The reliability across the two presentations of each list length was acceptable, ICC(A,2) = 0.759. The arcsin-sqrt transformed proportion correct on the sentence span task (SS<sub>pcorr</sub>) was included as a predictor of cocktail-party listening in the regression analyses.</p></sec><sec id="s4-3-7"><title>Self-reported hearing problems</title><p>Self-reported hearing-related problems in daily life were assessed via the Speech, Spatial and Qualities of Hearing Scale (SSQ) by <xref ref-type="bibr" rid="bib40">Gatehouse and Noble (2004)</xref>; using the German version (<xref ref-type="bibr" rid="bib58">Kießling et al., 2011</xref>). The <italic>Speech hearing</italic> subscale covers speech understanding in the presence of additional speakers (e.g., 'You are in conversation with one person in a room where there are many other people talking. Can you follow what the person you are talking to is saying?'), and is therefore directly relevant for our research question. The <italic>Spatial hearing</italic> subscale indexes the capability of locating static or moving sound sources (e.g., 'You are sitting around a table or at a meeting with several people. You can’t see everyone. Can you tell where any person is as soon as they start speaking?'). The <italic>Other qualities</italic> subscale addresses aspects of segregation of sounds, recognition, clarity/naturalness, and listening effort. The SSQ response scales range from 0 to 10, and 10 represents the highest self-rated hearing ability. The mean ratings (with SDs in parentheses) on the Speech hearing, Spatial hearing, and Other qualities scale were 7.16 (1.43), 6.95 (1.39), and 7.82 (1.18), respectively. The SSQ total score, which can range between 0 and 30, varied between 12.5 and 29.4 (<italic>M</italic> = 21.9, SD = 3.6). Thus, the participants showed considerable variation in their self-reported hearing abilities.</p></sec></sec><sec id="s4-4"><title>Procedure</title><p>Each participant was tested on all tasks. To minimize inter-individual variation due to different task orders, a fixed sequence of tasks was presented. After informed written consent and basic instructions, the experiment started with the measurement of audiometric thresholds, followed by intensity discrimination in quiet, intensity discrimination under backward masking, the cocktail-party listing task, the TFS-LF test, a questionnaire concerning demographic information, the flanker task, the sentence span task, and the SSQ questionnaire. Each task was preceded by detailed instructions and practice trials. The duration of the experimental session was approximately 3 hr, including several short breaks.</p></sec><sec id="s4-5"><title>Regression analysis</title><p>Multiple linear regression was used to analyze the association between the psychoacoustic and cognitive predictors and the speech recognition score (SRS) in the cocktail-party listening task. As explained above, proportions (SRS and SS<sub>Pcorr</sub>) were arcsin-sqrt transformed, and the response-time measures (RT<sub>neutral</sub>, Int<sub>Flanker</sub>) were based on log-transformed RTs. All variables were <italic>z</italic>-standardized. The nine predictors were entered simultaneously. Following the recommendations by <xref ref-type="bibr" rid="bib4">Belsley et al. (1980)</xref>; we analyzed the externally studentized residuals, and the DFFITS index proposed by <xref ref-type="bibr" rid="bib4">Belsley et al. (1980)</xref> as a measure of the influence of an observation. Observations for which the absolute value of the externally studentized residual exceeded 1.96 or with an absolute DFFITS value exceeding <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mi>p</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula> (where <italic>N</italic> = 50 is the number of subjects, and <italic>p</italic>=9 is the number of predictors) were defined as outliers. This resulted in the exclusion of 5 of the 50 subjects from the regression analysis. The maximum condition index (<xref ref-type="bibr" rid="bib4">Belsley et al., 1980</xref>) was 2.49. <xref ref-type="bibr" rid="bib4">Belsley et al. (1980)</xref> suggested that only condition indices of at least 30 indicate potential problems with multicollinearity. It should be noted that according to the Gauß-Markov theorem (<xref ref-type="bibr" rid="bib41">Gauss, 1821</xref>) the estimates provided by the multiple regression analysis will remain unbiased in the presence of correlated predictors. However, multicollinearity could inflate the variance of the estimated regression coefficients (e.g., <xref ref-type="bibr" rid="bib42">Greene, 2008</xref>), resulting in non-significant regression coefficients.</p><p>Q-Q plots of the residuals showed no systematic deviations from normality, and plots of the SRS as a function of the predictors showed no severe deviations from linearity. Thus, linear multiple regression was an appropriate method to assess the influence of the nine predictors on the speech recognition score, and to gauge their relative importance. Note that unlike most previous studies on factors influencing cocktail-party listening, our analyses did not focus on pairwise correlations, because only multiple regression provides valid information about the effects of multiple, partly correlated predictors (see <xref ref-type="table" rid="tbl2">Table 2</xref>).</p><p>Data are available from the Dryad Digital Repository (<xref ref-type="bibr" rid="bib76">Oberfeld and Klöckner-Nowotny, 2016</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by a grant from Deutsche Forschungsgemeinschaft (<ext-link ext-link-type="uri" xlink:href="http://www.dfg.de">www.dfg.de</ext-link>) to Daniel Oberfeld (OB 346/4-2: &quot;Temporal aspects of auditory intensity processing&quot;). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. The authors have no financial relationship with the organization that sponsored the research. No additional external funding received. The authors declare that they have no conflict of interest. We are grateful to Marius Frenken for his assistance in preparing the figures, and to Annika Grotjohann, Marius Frenken, Julia Pfeiff, and Jannis Renner for their help with data collection. We thank Eve Marder, Barbara Shinn-Cunningham, Hari Bharadwaj and an anonymous reviewer for helpful comments on a previous version of this paper.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>DO, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>FK-N, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The experiment was conducted according to the principles expressed in the Declaration of Helsinki. All listeners participated voluntarily after providing informed written consent, after the topic of the study and potential risks had been explained to them. They were uninformed about the experimental hypotheses. The study was approved by the ethics committee of the Department of Psychology, Johannes Gutenberg-Universitaet Mainz.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><sec id="s7" sec-type="datasets"><title>Major datasets</title><p>The following dataset was generated:</p><p><related-object content-type="generated-dataset" id="data-ro1" source-id="http://dx.doi.org/10.5061/dryad.f96cr" source-id-type="uri"><collab>Oberfeld D</collab><x>,</x> <collab>Klöckner- Nowotny F</collab><x>,</x> <year>2016</year><x>,</x><source>Experimental data on psychoacoustic and cognitive predictors of cocktail-party listening</source><x>,</x> <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5061/dryad.f96cr">http://dx.doi.org/10.5061/dryad.f96cr</ext-link><x>,</x> <comment>Available at Dryad Digital Repository under a CC0 Public Domain Dedication</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akeroyd</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Are individual differences in speech reception related to individual differences in cognitive ability? A survey of twenty experimental studies with normal and hearing-impaired adults</article-title><source>International Journal of Audiology</source><volume>47</volume><fpage>S53</fpage><lpage>S71</lpage><pub-id pub-id-type="doi">10.1080/14992020802301142</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azen</surname><given-names>R</given-names></name><name><surname>Budescu</surname><given-names>DV</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The dominance analysis approach for comparing predictors in multiple regression</article-title><source>Psychological Methods</source><volume>8</volume><fpage>129</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1037/1082-989X.8.2.129</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartlett</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="1936">1936</year><article-title>The square root transformation in analysis of variance</article-title><source>Supplement to the Journal of the Royal Statistical Society</source><volume>3</volume><fpage>68</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.2307/2983678</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Belsley</surname><given-names>DA</given-names></name><name><surname>Kuh</surname><given-names>E</given-names></name><name><surname>Welsch</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1980">1980</year><chapter-title>Regression diagnostics: Identifying influential data and sources of collinearity</chapter-title><source>Wiley Series in Probability and Statistics</source><publisher-loc>Hoboken, N.J</publisher-loc><publisher-name>Wiley</publisher-name><pub-id pub-id-type="doi">10.1002/0471725153</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Best</surname><given-names>V</given-names></name><name><surname>Ozmeral</surname><given-names>EJ</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Visually-guided attention enhances target identification in a complex auditory scene</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>8</volume><fpage>294</fpage><lpage>304</lpage><pub-id pub-id-type="doi">10.1007/s10162-007-0073-z</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bharadwaj</surname><given-names>HM</given-names></name><name><surname>Masud</surname><given-names>S</given-names></name><name><surname>Mehraei</surname><given-names>G</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Individual differences reveal correlates of hidden hearing deficits</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>2161</fpage><lpage>2172</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3915-14.2015</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bishara</surname><given-names>AJ</given-names></name><name><surname>Hittner</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Testing the significance of a correlation with nonnormal data: comparison of Pearson, Spearman, transformation, and resampling approaches</article-title><source>Psychological Methods</source><volume>17</volume><fpage>399</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1037/a0028087</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowie</surname><given-names>CR</given-names></name><name><surname>Harvey</surname><given-names>PD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Administration and interpretation of the Trail Making Test</article-title><source>Nature Protocols</source><volume>1</volume><fpage>2277</fpage><lpage>2281</lpage><pub-id pub-id-type="doi">10.1038/nprot.2006.390</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bregman</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="1990">1990</year><source>Auditory Scene Analysis: The Perceptual Organization of Sound</source><publisher-loc>Cambridge, Mass</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bronkhorst</surname><given-names>AW</given-names></name><name><surname>Plomp</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Binaural speech intelligibility in noise for hearing-impaired listeners</article-title><source>The Journal of the Acoustical Society of America</source><volume>86</volume><fpage>1374</fpage><lpage>1383</lpage><pub-id pub-id-type="doi">10.1121/1.398697</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bronkhorst</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The cocktail party phenomenon: A review of research on speech intelligibility in multiple-talker conditions</article-title><source>Acustica</source><volume>86</volume><fpage>117</fpage><lpage>128</lpage></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bronkhorst</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cocktail-party problem revisited: early processing and selection of multi-talker speech</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>77</volume><fpage>1465</fpage><lpage>1487</lpage><pub-id pub-id-type="doi">10.3758/s13414-015-0882-9</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Budescu</surname><given-names>DV</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Dominance analysis: A new approach to the problem of relative importance of predictors in multiple regression</article-title><source>Psychological Bulletin</source><volume>114</volume><fpage>542</fpage><lpage>551</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.114.3.542</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Top-down versus bottom-up control of attention in the prefrontal and posterior parietal cortices</article-title><source>Science</source><volume>315</volume><fpage>1860</fpage><lpage>1862</lpage><pub-id pub-id-type="doi">10.1126/science.1138071</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Byrne</surname><given-names>D</given-names></name><name><surname>Dillon</surname><given-names>H</given-names></name><name><surname>Tran</surname><given-names>K</given-names></name><name><surname>Arlinger</surname><given-names>S</given-names></name><name><surname>Wilbraham</surname><given-names>K</given-names></name><name><surname>Cox</surname><given-names>R</given-names></name><name><surname>Hagerman</surname><given-names>B</given-names></name><name><surname>Hetu</surname><given-names>R</given-names></name><name><surname>Kei</surname><given-names>J</given-names></name><name><surname>Lui</surname><given-names>C</given-names></name><name><surname>Kiessling</surname><given-names>J</given-names></name><name><surname>Kotby</surname><given-names>MN</given-names></name><name><surname>Nasser</surname><given-names>NHA</given-names></name><name><surname>El Kholy</surname><given-names>WAH</given-names></name><name><surname>Nakanishi</surname><given-names>Y</given-names></name><name><surname>Oyer</surname><given-names>H</given-names></name><name><surname>Powell</surname><given-names>R</given-names></name><name><surname>Stephens</surname><given-names>D</given-names></name><name><surname>Meredith</surname><given-names>R</given-names></name><name><surname>Sirimanna</surname><given-names>T</given-names></name><name><surname>Tavartkiladze</surname><given-names>G</given-names></name><name><surname>Frolenkov</surname><given-names>GI</given-names></name><name><surname>Westerman</surname><given-names>S</given-names></name><name><surname>Ludvigsen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>An international comparison of long-term average speech spectra</article-title><source>The Journal of the Acoustical Society of America</source><volume>96</volume><fpage>2108</fpage><lpage>2120</lpage><pub-id pub-id-type="doi">10.1121/1.410152</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Békésy</surname><given-names>Gv</given-names></name></person-group><year iso-8601-date="1947">1947</year><article-title>A new audiometer</article-title><source>Acta Oto-Laryngologica</source><volume>35</volume><fpage>411</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.3109/00016484709123756</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cahana-Amitay</surname><given-names>D</given-names></name><name><surname>Spiro</surname><given-names>A</given-names></name><name><surname>Sayers</surname><given-names>JT</given-names></name><name><surname>Oveis</surname><given-names>AC</given-names></name><name><surname>Higby</surname><given-names>E</given-names></name><name><surname>Ojo</surname><given-names>EA</given-names></name><name><surname>Duncan</surname><given-names>S</given-names></name><name><surname>Goral</surname><given-names>M</given-names></name><name><surname>Hyun</surname><given-names>J</given-names></name><name><surname>Albert</surname><given-names>ML</given-names></name><name><surname>Obler</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How older adults use cognition in sentence-final word recognition</article-title><source>Aging, Neuropsychology, and Cognition</source><volume>23</volume><fpage>418</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1080/13825585.2015.1111291</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlyon</surname><given-names>RP</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>How the brain separates sounds</article-title><source>Trends in Cognitive Sciences</source><volume>8</volume><fpage>465</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.08.008</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cherry</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="1953">1953</year><article-title>Some experiments on the recognition of speech, with one and with two ears</article-title><source>The Journal of the Acoustical Society of America</source><volume>25</volume><fpage>975</fpage><lpage>979</lpage><pub-id pub-id-type="doi">10.1121/1.1907229</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>I</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Bharadwaj</surname><given-names>H</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Individual differences in attentional modulation of cortical responses correlate with selective attention performance</article-title><source>Hearing Research</source><volume>314</volume><fpage>10</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2014.04.008</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1988">1988</year><source>Statistical Power Analysis for the Behavioral Sciences</source><edition>2nd edn</edition><publisher-loc>Hillsdale, N.J</publisher-loc><publisher-name>Lawrence Erlbaum Associates</publisher-name><pub-id pub-id-type="doi">10.4324/9780203771587</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>AR</given-names></name><name><surname>Cowan</surname><given-names>N</given-names></name><name><surname>Bunting</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The cocktail party phenomenon revisited: the importance of working memory capacity</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>8</volume><fpage>331</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.3758/BF03196169</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>ARA</given-names></name><name><surname>Kane</surname><given-names>MJ</given-names></name><name><surname>Bunting</surname><given-names>MF</given-names></name><name><surname>Hambrick</surname><given-names>DZ</given-names></name><name><surname>Wilhelm</surname><given-names>O</given-names></name><name><surname>Engle</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Working memory span tasks: A methodological review and user’s guide</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>12</volume><fpage>769</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.3758/BF03196772</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title><source>Nature Reviews Neuroscience</source><volume>3</volume><fpage>201</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1038/nrn755</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coull</surname><given-names>JT</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Where and when to pay attention: the neural systems for directing attention to spatial locations and to time intervals as revealed by both PET and fMRI</article-title><source>Journal of Neuroscience</source><volume>18</volume><fpage>7426</fpage><lpage>7435</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N</given-names></name><name><surname>Elliott</surname><given-names>EM</given-names></name><name><surname>Scott Saults</surname><given-names>J</given-names></name><name><surname>Morey</surname><given-names>CC</given-names></name><name><surname>Mattox</surname><given-names>S</given-names></name><name><surname>Hismjatullina</surname><given-names>A</given-names></name><name><surname>Conway</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>On the capacity of attention: its estimation and its role in working memory and cognitive aptitudes</article-title><source>Cognitive Psychology</source><volume>51</volume><fpage>42</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2004.12.001</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Culling</surname><given-names>JF</given-names></name><name><surname>Hawley</surname><given-names>ML</given-names></name><name><surname>Litovsky</surname><given-names>RY</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The role of head-induced interaural time and level differences in the speech reception threshold for multiple interfering sound sources</article-title><source>The Journal of the Acoustical Society of America</source><volume>116</volume><fpage>1057</fpage><lpage>1065</lpage><pub-id pub-id-type="doi">10.1121/1.1772396</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daneman</surname><given-names>M</given-names></name><name><surname>Carpenter</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Individual differences in working memory and reading</article-title><source>Journal of Verbal Learning and Verbal Behavior</source><volume>19</volume><fpage>450</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1016/S0022-5371(80)90312-6</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Darwin</surname><given-names>CJ</given-names></name><name><surname>Hukin</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Auditory objects of attention: the role of interaural time differences</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>25</volume><fpage>617</fpage><lpage>629</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.25.3.617</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David</surname><given-names>M</given-names></name><name><surname>Lavandier</surname><given-names>M</given-names></name><name><surname>Grimault</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sequential streaming, binaural cues and lateralization</article-title><source>The Journal of the Acoustical Society of America</source><volume>138</volume><fpage>3500</fpage><lpage>3512</lpage><pub-id pub-id-type="doi">10.1121/1.4936902</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname><given-names>R</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Neural mechanisms of selective visual attention</article-title><source>Annual Review of Neuroscience</source><volume>18</volume><fpage>193</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.18.030195.001205</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dirks</surname><given-names>DD</given-names></name><name><surname>Bower</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Effect of forward and backward masking on speech intelligibility</article-title><source>Journal of the Acoustical Society of America</source><volume>47</volume><fpage>1003</fpage><pub-id pub-id-type="doi">10.1121/1.1911998</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eriksen</surname><given-names>BA</given-names></name><name><surname>Eriksen</surname><given-names>CW</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Effects of noise letters upon the identification of a target letter in a nonsearch task</article-title><source>Perception &amp; Psychophysics</source><volume>16</volume><fpage>143</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.3758/BF03203267</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faul</surname><given-names>F</given-names></name><name><surname>Erdfelder</surname><given-names>E</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name><name><surname>Lang</surname><given-names>A-G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses</article-title><source>Behavior Research Methods</source><volume>41</volume><fpage>1149</fpage><lpage>1160</lpage><pub-id pub-id-type="doi">10.3758/BRM.41.4.1149</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francis</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Improved segregation of simultaneous talkers differentially affects perceptual and cognitive capacity demands for recognizing speech in competing speech</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>72</volume><fpage>501</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.3758/APP.72.2.501</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Füllgrabe</surname><given-names>C</given-names></name><name><surname>Moore</surname><given-names>BC</given-names></name><name><surname>Stone</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Age-group differences in speech identification despite matched audiometrically normal hearing: contributions from auditory temporal processing and cognition</article-title><source>Frontiers in Aging Neuroscience</source><volume>6</volume><elocation-id>347</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2014.00347</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Füllgrabe</surname><given-names>C</given-names></name><name><surname>Rosen</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><chapter-title>Investigating the role of working memory in speech-in-noise identification for listeners with normal hearing</chapter-title><person-group person-group-type="editor"><name><surname>van Dijk</surname> <given-names>P</given-names></name><name><surname>Başkent</surname> <given-names>D</given-names></name><name><surname>Gaudrain</surname> <given-names>E</given-names></name><name><surname>de Kleine</surname> <given-names>E</given-names></name><name><surname>Wagner</surname> <given-names>A</given-names></name><name><surname>Lanting</surname> <given-names>C</given-names></name></person-group><span class="RefunTagged">(eds).</span><source>Physiology, Psychoacoustics and Cognition in Normal and Impaired Hearing</source><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Füllgrabe</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Age-dependent changes in temporal-fine-structure processing in the absence of peripheral hearing loss</article-title><source>American Journal of Audiology</source><volume>22</volume><fpage>313</fpage><lpage>315</lpage><pub-id pub-id-type="doi">10.1044/1059-0889(2013/12-0070)</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatehouse</surname><given-names>S</given-names></name><name><surname>Akeroyd</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The effects of cueing temporal and spatial attention on word recognition in a complex listening task in hearing-impaired listeners</article-title><source>Trends in Amplification</source><volume>12</volume><fpage>145</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1177/1084713808317395</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatehouse</surname><given-names>S</given-names></name><name><surname>Noble</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The Speech, Spatial and Qualities of Hearing Scale (SSQ)</article-title><source>International Journal of Audiology</source><volume>43</volume><fpage>85</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1080/14992020400050014</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauss</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="1821">1821</year><article-title>Theoria combinationis observationum erroribus minimis obnoxiae</article-title><source>Commentationes Societatis Regiae Scientiarum Gottingensis Recentiores</source><fpage>33</fpage><lpage>90</lpage></element-citation></ref><ref id="bib42"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Greene</surname><given-names>WH</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Econometric Analysis</source><edition>6 edn</edition><publisher-loc>Upper Saddle River, NJ</publisher-loc><publisher-name>Pearson</publisher-name></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grose</surname><given-names>JH</given-names></name><name><surname>Mamo</surname><given-names>SK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Processing of temporal fine structure as a function of age</article-title><source>Ear and Hearing</source><volume>31</volume><fpage>755</fpage><lpage>760</lpage><pub-id pub-id-type="doi">10.1097/AUD.0b013e3181e627e7</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>LA</given-names></name><name><surname>Poulsen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Equivalent threshold sound pressure levels for Sennheiser HDA 200 earphone and Etymotic Research ER-2 insert earphone in the frequency range 125 Hz to 16 kHz</article-title><source>Scandinavian Audiology</source><volume>27</volume><fpage>105</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1080/010503998420342</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Harrell</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2015">2015</year><source>Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-319-19425-7</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hartmann</surname><given-names>WM</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>Signals, sound, and sensation</chapter-title><source>Modern Acoustics And. Signal Processing</source><edition>5th edn</edition><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><chapter-title>The elements of statistical learning</chapter-title><source>Data Mining, Inference, and Prediction</source><edition>Second Edn</edition><publisher-loc>Berlin, New York</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinrich</surname><given-names>A</given-names></name><name><surname>Henshaw</surname><given-names>H</given-names></name><name><surname>Ferguson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The relationship of speech intelligibility with hearing sensitivity, cognition, and perceived hearing difficulties varies for different speech perception tests</article-title><source>Frontiers in Psychology</source><volume>6</volume><elocation-id>782</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2015.00782</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopkins</surname><given-names>K</given-names></name><name><surname>Moore</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Development of a fast method for measuring sensitivity to temporal fine structure information at low frequencies</article-title><source>International Journal of Audiology</source><volume>49</volume><fpage>940</fpage><lpage>946</lpage><pub-id pub-id-type="doi">10.3109/14992027.2010.512613</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><collab>IEC 318</collab></person-group><year iso-8601-date="1970">1970</year><source>An IEC Artificial Ear, of the Wide Band Type, for the Calibration of Earphones Used in Audiometry</source><publisher-loc>Geneva</publisher-loc><publisher-name>International Electrotechnical Commission</publisher-name></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ihlefeld</surname><given-names>A</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Disentangling the effects of spatial cues on selection and formation of auditory objects</article-title><source>Journal of the Acoustical Society of America</source><volume>124</volume><fpage>2224</fpage><lpage>2235</lpage><pub-id pub-id-type="doi">10.1121/1.2973185</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname><given-names>G</given-names></name><name><surname>Witten</surname><given-names>G</given-names></name><name><surname>Hastie</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>An Introduction to Statistical Learning</source><edition>Vol 103</edition><publisher-loc>New York</publisher-loc><publisher-name>Springer Science+Business Media</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4614-7138-7</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jonides</surname><given-names>J</given-names></name><name><surname>Yantis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Uniqueness of abrupt visual onset in capturing attention</article-title><source>Perception &amp; Psychophysics</source><volume>43</volume><fpage>346</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.3758/BF03208805</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name><name><surname>Henik</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1981">1981</year><chapter-title>Perceptual organization and attention</chapter-title><person-group person-group-type="editor"><name><surname>Kubovy</surname> <given-names>M</given-names></name><name><surname>Pomerantz</surname> <given-names>J. R</given-names></name></person-group><source>Perceptual Organization</source><publisher-loc>Hillsdale, NJ</publisher-loc><publisher-name>Erlbaum</publisher-name><fpage>181</fpage><lpage>211</lpage></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname><given-names>H</given-names></name><name><surname>Ewert</surname><given-names>SD</given-names></name><name><surname>Anemüller</surname><given-names>J</given-names></name><name><surname>Rohdenburg</surname><given-names>T</given-names></name><name><surname>Hohmann</surname><given-names>V</given-names></name><name><surname>Kollmeier</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Database of multichannel in-ear and behind-the-ear head-related and binaural room impulse responses</article-title><source>EURASIP Journal on Advances in Signal Processing</source><volume>2009</volume><elocation-id>298605</elocation-id><pub-id pub-id-type="doi">10.1155/2009/298605</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kiang</surname><given-names>NYS</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name><name><surname>Thomas</surname><given-names>EC</given-names></name><name><surname>Clark</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="1965">1965</year><source>Discharge Patterns of Single Fibers in the Cat's Auditory Nerve</source><publisher-loc>Cambridge, Mass</publisher-loc><publisher-name>M.I.T. Press</publisher-name></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kidd</surname><given-names>G</given-names></name><name><surname>Arbogast</surname><given-names>TL</given-names></name><name><surname>Mason</surname><given-names>CR</given-names></name><name><surname>Gallun</surname><given-names>FJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The advantage of knowing where to listen</article-title><source>The Journal of the Acoustical Society of America</source><volume>118</volume><fpage>3804</fpage><lpage>3815</lpage><pub-id pub-id-type="doi">10.1121/1.2109187</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kießling</surname><given-names>J</given-names></name><name><surname>Grugel</surname><given-names>L</given-names></name><name><surname>Meister</surname><given-names>H</given-names></name><name><surname>Meis</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>German translations of the questionnaires SADL, ECHO and SSQ and their evaluation</article-title><source>Zeitschrift Für Audiologie/Audiological Acoustics</source><volume>50</volume><fpage>6</fpage><lpage>16</lpage></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>A</given-names></name><name><surname>Hopkins</surname><given-names>K</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The effects of age and hearing loss on interaural phase difference discrimination</article-title><source>The Journal of the Acoustical Society of America</source><volume>135</volume><fpage>342</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1121/1.4838995</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitterick</surname><given-names>PT</given-names></name><name><surname>Bailey</surname><given-names>PJ</given-names></name><name><surname>Summerfield</surname><given-names>AQ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Benefits of knowing who, where, and when in multi-talker listening</article-title><source>The Journal of the Acoustical Society of America</source><volume>127</volume><fpage>2498</fpage><lpage>2508</lpage><pub-id pub-id-type="doi">10.1121/1.3327507</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kramer</surname><given-names>AF</given-names></name><name><surname>Jacobson</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Perceptual organization and focused attention: the role of objects and proximity in visual processing</article-title><source>Perception &amp; Psychophysics</source><volume>50</volume><fpage>267</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.3758/BF03206750</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kujawa</surname><given-names>SG</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Adding insult to injury: cochlear nerve degeneration after &quot;temporary&quot; noise-induced hearing loss</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>14077</fpage><lpage>14085</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2845-09.2009</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lavandier</surname><given-names>M</given-names></name><name><surname>Culling</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Prediction of binaural speech intelligibility against noise in rooms</article-title><source>The Journal of the Acoustical Society of America</source><volume>127</volume><fpage>387</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1121/1.3268612</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname><given-names>JM</given-names></name><name><surname>Ployhart</surname><given-names>RE</given-names></name><name><surname>Ladd</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A monte carlo comparison of relative importance methodologies</article-title><source>Organizational Research Methods</source><volume>7</volume><fpage>258</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1177/1094428104266017</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Transformed up-down methods in psychoacoustics</article-title><source>The Journal of the Acoustical Society of America</source><volume>49</volume><fpage>467</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1121/1.1912375</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewandowsky</surname><given-names>S</given-names></name><name><surname>Oberauer</surname><given-names>K</given-names></name><name><surname>Yang</surname><given-names>LX</given-names></name><name><surname>Ecker</surname><given-names>UK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A working memory test battery for MATLAB</article-title><source>Behavior Research Methods</source><volume>42</volume><fpage>571</fpage><lpage>585</lpage><pub-id pub-id-type="doi">10.3758/BRM.42.2.571</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattys</surname><given-names>SL</given-names></name><name><surname>Davis</surname><given-names>MH</given-names></name><name><surname>Bradlow</surname><given-names>AR</given-names></name><name><surname>Scott</surname><given-names>SK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Speech recognition in adverse conditions: A review</article-title><source>Language and Cognitive Processes</source><volume>27</volume><fpage>953</fpage><lpage>978</lpage><pub-id pub-id-type="doi">10.1080/01690965.2012.705006</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGraw</surname><given-names>KO</given-names></name><name><surname>Wong</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Forming inferences about some intraclass correlation coefficients</article-title><source>Psychological Methods</source><volume>1</volume><fpage>30</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1037/1082-989X.1.1.30</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michalka</surname><given-names>SW</given-names></name><name><surname>Kong</surname><given-names>L</given-names></name><name><surname>Rosen</surname><given-names>ML</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name><name><surname>Somers</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Short-term memory for space and time flexibly recruit complementary sensory-biased frontal lobe attention networks</article-title><source>Neuron</source><volume>87</volume><fpage>882</fpage><lpage>892</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.028</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The role of temporal fine structure processing in pitch perception, masking, and speech perception for normal-hearing and hearing-impaired people</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>9</volume><fpage>399</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1007/s10162-008-0143-x</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moray</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Attention in dichotic listening: Affective cues and the influence of instructions</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>11</volume><fpage>56</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1080/17470215908416289</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neher</surname><given-names>T</given-names></name><name><surname>Behrens</surname><given-names>T</given-names></name><name><surname>Carlile</surname><given-names>S</given-names></name><name><surname>Jin</surname><given-names>C</given-names></name><name><surname>Kragelund</surname><given-names>L</given-names></name><name><surname>Petersen</surname><given-names>AS</given-names></name><name><surname>Schaik</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Benefit from spatial separation of multiple talkers in bilateral hearing-aid users: Effects of hearing loss, age, and cognition</article-title><source>International Journal of Audiology</source><volume>48</volume><fpage>758</fpage><lpage>774</lpage><pub-id pub-id-type="doi">10.3109/14992020903079332</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neher</surname><given-names>T</given-names></name><name><surname>Laugesen</surname><given-names>S</given-names></name><name><surname>Jensen</surname><given-names>NS</given-names></name><name><surname>Kragelund</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Can basic auditory and cognitive measures predict hearing-impaired listeners' localization and spatial speech recognition abilities?</article-title><source>The Journal of the Acoustical Society of America</source><volume>130</volume><fpage>1542</fpage><lpage>1558</lpage><pub-id pub-id-type="doi">10.1121/1.3608122</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neher</surname><given-names>T</given-names></name><name><surname>Lunner</surname><given-names>T</given-names></name><name><surname>Hopkins</surname><given-names>K</given-names></name><name><surname>Moore</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Binaural temporal fine structure sensitivity, cognitive function, and spatial speech recognition of hearing-impaired listeners (L)</article-title><source>The Journal of the Acoustical Society of America</source><volume>131</volume><fpage>2561</fpage><lpage>2564</lpage><pub-id pub-id-type="doi">10.1121/1.3689850</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberfeld</surname><given-names>D</given-names></name><name><surname>Franke</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Evaluating the robustness of repeated measures analyses: The case of small sample sizes and nonnormal data</article-title><source>Behavior Research Methods</source><volume>45</volume><fpage>792</fpage><lpage>812</lpage><pub-id pub-id-type="doi">10.3758/s13428-012-0281-2</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Oberfeld</surname><given-names>D</given-names></name><name><surname>Klöckner-Nowotny</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Experimental data on psychoacoustic and cognitive predictors of cocktail-party listening</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.f96cr</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberfeld</surname><given-names>D</given-names></name><name><surname>Stahn</surname><given-names>P</given-names></name><name><surname>Kuta</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Binaural release from masking in forward-masked intensity discrimination: evidence for effects of selective attention</article-title><source>Hearing Research</source><volume>294</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2012.09.004</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberfeld</surname><given-names>D</given-names></name><name><surname>Stahn</surname><given-names>P</given-names></name><name><surname>Kuta</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Why do forward maskers affect auditory intensity discrimination? Evidence from &quot;molecular psychophysics&quot;</article-title><source>PLoS One</source><volume>9</volume><pub-id pub-id-type="doi">10.1371/journal.pone.0099745</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberfeld</surname><given-names>D</given-names></name><name><surname>Stahn</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sequential grouping modulates the effect of non-simultaneous masking on auditory intensity resolution</article-title><source>PloS One</source><volume>7</volume><elocation-id>e48054</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0048054</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pashler</surname><given-names>HE</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>The Psychology of Attention</source><publisher-loc>Cambridge, Mass</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>Barker</surname><given-names>D</given-names></name><name><surname>Prendergast</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Perceptual consequences of &quot;hidden&quot; hearing loss</article-title><source>Trends in Hearing</source><volume>18</volume><elocation-id>2331216514550621</elocation-id><pub-id pub-id-type="doi">10.1177/2331216514550621</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>Viemeister</surname><given-names>NF</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Intensity discrimination under backward masking</article-title><source>The Journal of the Acoustical Society of America</source><volume>92</volume><fpage>3097</fpage><lpage>3101</lpage><pub-id pub-id-type="doi">10.1121/1.404205</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Orienting of attention</article-title><source>The Quarterly Journal of Experimental Psychology</source><volume>32</volume><fpage>3</fpage><lpage>25</lpage></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulvermüller</surname><given-names>F</given-names></name><name><surname>Shtyrov</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Language outside the focus of attention: the mismatch negativity as a tool for studying higher cognitive processes</article-title><source>Progress in Neurobiology</source><volume>79</volume><fpage>49</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2006.04.004</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Ward</surname><given-names>T</given-names></name><name><surname>Ridgeway</surname><given-names>V</given-names></name><name><surname>Nimmo-Smith</surname><given-names>I</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The structure of normal human attention: The Test of Everyday Attention</article-title><source>Journal of the International Neuropsychological Society</source><volume>2</volume><fpage>525</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1017/S1355617700001697</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>B</given-names></name><name><surname>Fujioka</surname><given-names>T</given-names></name><name><surname>Tremblay</surname><given-names>KL</given-names></name><name><surname>Picton</surname><given-names>TW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Aging in binaural hearing begins in mid-life: evidence from cortical auditory-evoked responses to changes in interaural phase</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>11172</fpage><lpage>11178</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1813-07.2007</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruggles</surname><given-names>D</given-names></name><name><surname>Bharadwaj</surname><given-names>H</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Normal hearing is not enough to guarantee robust encoding of suprathreshold features important in everyday communication</article-title><source>PNAS</source><volume>108</volume><fpage>15516</fpage><lpage>15521</lpage><pub-id pub-id-type="doi">10.1073/pnas.1108912108</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruggles</surname><given-names>D</given-names></name><name><surname>Bharadwaj</surname><given-names>H</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Why middle-aged listeners have trouble hearing in everyday settings</article-title><source>Current Biology</source><volume>22</volume><fpage>1417</fpage><lpage>1422</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.05.025</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruggles</surname><given-names>D</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spatial selective auditory attention in the presence of reverberant energy: individual differences in normal-hearing listeners</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>12</volume><fpage>395</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1007/s10162-010-0254-z</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sach</surname><given-names>AJ</given-names></name><name><surname>Hill</surname><given-names>NI</given-names></name><name><surname>Bailey</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Auditory spatial attention using interaural time differences</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>26</volume><fpage>717</fpage><lpage>729</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.26.2.717</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salthouse</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The processing-speed theory of adult age differences in cognition</article-title><source>Psychological Review</source><volume>103</volume><fpage>403</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.103.3.403</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salthouse</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Aging and measures of processing speed</article-title><source>Biological Psychology</source><volume>54</volume><fpage>35</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/S0301-0511(00)00052-1</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sander</surname><given-names>MC</given-names></name><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>Werkle-Bergner</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Lifespan age differences in working memory: a two-component framework</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>36</volume><fpage>2007</fpage><lpage>2033</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2012.06.004</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlauch</surname><given-names>RS</given-names></name><name><surname>Lanthier</surname><given-names>N</given-names></name><name><surname>Neve</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Forward-masked intensity discrimination: duration effects and spectral effects</article-title><source>The Journal of the Acoustical Society of America</source><volume>102</volume><fpage>461</fpage><lpage>467</lpage><pub-id pub-id-type="doi">10.1121/1.419610</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoof</surname><given-names>T</given-names></name><name><surname>Rosen</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The role of auditory and cognitive factors in understanding speech in noise by normal-hearing older listeners</article-title><source>Frontiers in Aging Neuroscience</source><volume>6</volume><elocation-id>307</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2014.00307</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Object-based auditory and visual attention</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>182</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.02.003</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spence</surname><given-names>CJ</given-names></name><name><surname>Driver</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Covert spatial orienting in audition: Exogenous and endogenous mechanisms</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>20</volume><fpage>555</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.20.3.555</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>S</given-names></name><name><surname>Keil</surname><given-names>A</given-names></name><name><surname>Stratis</surname><given-names>K</given-names></name><name><surname>Woodruff Carr</surname><given-names>KL</given-names></name><name><surname>Smith</surname><given-names>DW</given-names></name><name><surname>Carr</surname><given-names>KLW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Effects of cross-modal selective attention on the sensory periphery: cochlear sensitivity is altered by selective attention</article-title><source>Neuroscience</source><volume>223</volume><fpage>325</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2012.07.062</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroop</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1935">1935</year><article-title>Studies of interference in serial verbal reactions</article-title><source>Journal of Experimental Psychology</source><volume>18</volume><fpage>643</fpage><lpage>662</lpage><pub-id pub-id-type="doi">10.1037/h0054651</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Styles</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>The Psychology of Attention (2nd ed)</source><publisher-loc>Hove, UK</publisher-loc><publisher-name>Psychology Press</publisher-name></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>DR</given-names></name><name><surname>Zumbo</surname><given-names>BD</given-names></name><name><surname>Kwan</surname><given-names>E</given-names></name><name><surname>Schweitzer</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>On Johnson's (2000) relative weights method for assessing variable importance: A reanalysis</article-title><source>Multivariate Behavioral Research</source><volume>49</volume><fpage>329</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1080/00273171.2014.905766</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Regression shrinkage and selection via the Lasso</article-title><source>Journal of the Royal Statistical Society Series B-Methodological</source><volume>58</volume><fpage>267</fpage><lpage>288</lpage></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Regression shrinkage and selection via the lasso: a retrospective</article-title><source>Journal of the Royal Statistical Society: Series B</source><volume>73</volume><fpage>273</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2011.00771.x</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tonidandel</surname><given-names>S</given-names></name><name><surname>LeBreton</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Relative importance analysis: A useful supplement to regression analysis</article-title><source>Journal of Business and Psychology</source><volume>26</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1007/s10869-010-9204-3</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tun</surname><given-names>PA</given-names></name><name><surname>Wingfield</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>One voice too many: Adult age differences in language processing with different types of distracting sounds</article-title><source>The Journals of Gerontology Series B: Psychological Sciences and Social Sciences</source><volume>54B</volume><fpage>P317</fpage><lpage>P327</lpage><pub-id pub-id-type="doi">10.1093/geronb/54B.5.P317</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Rooij</surname><given-names>JC</given-names></name><name><surname>Plomp</surname><given-names>R</given-names></name><name><surname>Orlebeke</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Auditive and cognitive factors in speech perception by elderly listeners. I: Development of test battery</article-title><source>The Journal of the Acoustical Society of America</source><volume>86</volume><fpage>1294</fpage><lpage>1309</lpage><pub-id pub-id-type="doi">10.1121/1.398744</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagener</surname><given-names>K</given-names></name><name><surname>Kühnel</surname><given-names>V</given-names></name><name><surname>Kollmeier</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1999">1999a</year><article-title>Entwicklung und Evaluation eines Satztests für die deutsche Sprache. I: Design des Oldenburger Satztests</article-title><source>Zeitschrift Für Audiologie</source><volume>38</volume><fpage>4</fpage><lpage>15</lpage></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagener</surname><given-names>K</given-names></name><name><surname>Kühnel</surname><given-names>V</given-names></name><name><surname>Kollmeier</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1999">1999b</year><article-title>Entwicklung und Evaluation eines Satztests für die deutsche Sprache. II: Optimierung des Oldenburger Satztests</article-title><source>Zeitschrift Für Audiologie</source><volume>38</volume><fpage>44</fpage><lpage>56</lpage></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagener</surname><given-names>K</given-names></name><name><surname>Kühnel</surname><given-names>V</given-names></name><name><surname>Kollmeier</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1999">1999c</year><article-title>Entwicklung und Evaluation eines Satztests für die deutsche Sprache, III: Evaluation des Oldenburger Satztests</article-title><source>Zeitschrift Für Audiologie</source><volume>38</volume><fpage>86</fpage><lpage>95</lpage></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiang</surname><given-names>J</given-names></name><name><surname>Simon</surname><given-names>J</given-names></name><name><surname>Elhilali</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Competing streams at the cocktail party: exploring the mechanisms of attention and temporal integration</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>12084</fpage><lpage>12093</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0827-10.2010</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yantis</surname><given-names>S</given-names></name><name><surname>Jonides</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Abrupt visual onsets and selective attention: voluntary versus automatic allocation</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>16</volume><fpage>121</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.16.1.121</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yost</surname><given-names>WA</given-names></name><name><surname>Dye</surname><given-names>RH</given-names></name><name><surname>Sheft</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A simulated &quot;cocktail party&quot; with up to three sound sources</article-title><source>Perception &amp; Psychophysics</source><volume>58</volume><fpage>1026</fpage><lpage>1036</lpage><pub-id pub-id-type="doi">10.3758/BF03206830</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zanto</surname><given-names>TP</given-names></name><name><surname>Gazzaley</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><chapter-title>Attention and ageing</chapter-title><person-group person-group-type="editor"><name><surname>Nobre</surname> <given-names>A. C</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><span class="RefunTagged">(eds)</span><source>The Oxford Handbook of Attention</source><publisher-loc>Oxford</publisher-loc><publisher-name>Oxford University Press</publisher-name><fpage>927</fpage><lpage>971</lpage></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zekveld</surname><given-names>AA</given-names></name><name><surname>Rudner</surname><given-names>M</given-names></name><name><surname>Johnsrude</surname><given-names>IS</given-names></name><name><surname>Rönnberg</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The effects of working memory capacity and semantic cues on the intelligibility of speech in noise</article-title><source>The Journal of the Acoustical Society of America</source><volume>134</volume><fpage>2225</fpage><lpage>2234</lpage><pub-id pub-id-type="doi">10.1121/1.4817926</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>F</given-names></name><name><surname>Stephens</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A critical review of King-Kopetzky syndrome: Hearing difficulties, but normal hearing?</article-title><source>Audiological Medicine</source><volume>5</volume><fpage>119</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1080/16513860701296421</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zion Golumbic</surname><given-names>EM</given-names></name><name><surname>Ding</surname><given-names>N</given-names></name><name><surname>Bickel</surname><given-names>S</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Schevon</surname><given-names>CA</given-names></name><name><surname>McKhann</surname><given-names>GM</given-names></name><name><surname>Goodman</surname><given-names>RR</given-names></name><name><surname>Emerson</surname><given-names>R</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Simon</surname><given-names>JZ</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Mechanisms underlying selective neuronal tracking of attended speech at a &quot;cocktail party&quot;</article-title><source>Neuron</source><volume>77</volume><fpage>980</fpage><lpage>991</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.037</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zion Golumbic</surname><given-names>EM</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Temporal context in speech processing and attentional stream selection: a behavioral and neural perspective</article-title><source>Brain and Language</source><volume>122</volume><fpage>151</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2011.12.010</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.16747.014</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Shinn-Cunningham</surname><given-names>Barbara G</given-names></name><role>Reviewing editor</role><aff id="aff3"><institution>Boston University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Individual differences in selective attention predict speech identification at a cocktail party&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Barbara G Shinn-Cunningham (Reviewing editor and Reviewer #1) and Hari Bharadwaj (Reviewer #2), and the evaluation has been overseen by Eve Marder as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission. We hope you will be able to submit the revised version within two months, so please let us know if you have any questions first.</p><p>Summary:</p><p>This investigation tests the hypothesis that individual differences in the ability to identify target speech in the presence of spatially separated speech distractors is related to cross-subject differences in both supra-threshold auditory temporal processing abilities and cognitive function. More specifically, the authors assess binaural sensitivity to temporal-fine-structure (TFS) information and the ability to focus attention in a large group of young audiometrically normal-hearing listeners, thereby extending and complementing previous work. Overall, this is a nice study in distinguishing between sensory and central contributions to individual differences that may affect everyday communication. The study is clear, well written, and of interest to the hearing-research community. We have three major issues that need to be addressed, along with some suggestions that might strengthen your presentation.</p><p>Essential revisions:</p><p>1) The statistical tests you performed do not disprove a sensory contribution to the observed individual differences that you argue reflect top-down attention.</p><p>You have shown that the intensity difference limen (DL) measured using backward masking correlates strongly with DL in quiet (<xref ref-type="table" rid="tbl2">Table 2</xref>). Given that DL<sub>masked</sub> and DL<sub>quiet</sub> are strongly correlated, using them both as predictors in the multiple regression analysis makes the assignment of coefficients (and subsequent t-scores) dependent on the exact algorithm used for fitting, and essentially arbitrary.</p><p>If DL<sub>masked</sub> was not included, was DL<sub>quiet</sub> a significant predictor? Is DL<sub>masked</sub> a significant predictor when DL<sub>quiet</sub> has already been partialed out?</p><p>The Lasso fitting procedure penalizes the L1-norm of the set of coefficients, thereby favoring sparse solutions. Thus, it would pick the better of the two predictors: that is, DL<sub>masked</sub> might be picked over DL<sub>quiet</sub> or over both together. However, the fact that the procedure does not pick DL<sub>quiet</sub> is not in itself evidence that DL<sub>masked</sub> does not include differences from sensory factors. All this proves is that the DL<sub>masked</sub> is the better of the two predictors overall and effectively encompasses the other.</p><p>Also, you use an eigenvalue ratio criterion (First paragraph of Regression analysis section) to say that there isn't a multicollinearity problem here. This index is of limited utility when many noisy predictors are used. Indeed the correlation between DL<sub>masked</sub> and DL<sub>quiet</sub> is already evidence for some multi collinearity.</p><p>The language you use to describe your results needs to reflect these subtleties, and/or you need to include more extensive statistical testing to rule out sensory contributions that are correlated with/included in DL<sub>masked</sub>. All you can currently conclude is that the perceptual weight given to the masker accounts for the behavior, not that this factor reflects only top-down selection.</p><p>2) Isn't a differential measure of auditory masking effects more in line with your other metrics?</p><p>If the differences in DL under masking reflect top-down selection, it seems to make more sense to quantify the differential effect of masker on DL as a correlate rather than the overall threshold under masking (e.g., DL<sub>masked</sub> minus DL<sub>quiet</sub>). This would better parallel the visual measure you use (the differential effect of the flanker on the reaction time) as a measure of top-down selection (as opposed to the overall RT with an incongruent flanker).</p><p>3) The &quot;cognitive&quot; component you measure seems more specific than your discussion/presentation concedes.</p><p>The backward masking task you used to isolate auditory &quot;attention&quot; requires listeners to attend to a signal and ignore a later event that draws attention exogenously. This task no doubt indexes the ability to suppress an exogenous draw of attention, and your results show that this ability differs across listeners in a way that is reflected in &quot;cocktail party&quot; listening. However, this may be very different from the ability to sustain focused attention. Indeed, different attentional control subnetworks are thought to control exogenous vs. endogenous attention; a whole host of processes (e.g., precise sensory coding, scene analysis, top-down selection, exogenous attention.) allow us to selectively understand a target and ignore maskers.</p><p>In the first paragraph of discussion, you claim that &quot;the ability to direct auditory selective attention&quot; differs in consistent ways across listeners; however, it seems more appropriate to argue that there are differences in &quot;the ability to suppress exogenously salient, but task-irrelevant auditory events.&quot; See also the second paragraph, and eighth paragraph of Discussion section where you write, &quot;future experiments on attentional factors influencing cocktail-party listening could include tasks measuring both the endogenous and exogenous orienting of attention.&quot; We agree; but we suspect you have just isolated one particular aspect of attention, already.</p><p>This does not diminish the importance of your study, but changes the language you might use to discuss your results. Please consider integrating this idea into the way you describe your study. Rather than arguing that you are measuring &quot;attention&quot; (and leaving it at that), taking a more sophisticated, nuanced view that distinguishes amongst different aspects of attention, and that doesn't over-simplify, would enhance the impact of your work.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.16747.015</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p> <italic>Essential revisions:</italic> </p><p> <italic>1) The statistical tests you performed do not disprove a sensory contribution to the observed individual differences that you argue reflect top-down attention.</italic> </p><p><italic>2) Isn't a differential measure of auditory masking effects more in line with your other metrics?</italic></p><p>The problems that were correctly identified under point 1 are now solved in the revised manuscript by addressing point 2. For this reason, we respond to the detailed comments that were listed under point 1 and point 2 in a slightly non-chronological order.</p><p> <italic>If the differences in DL under masking reflect top-down selection, it seems to make more sense to quantify the differential effect of masker on DL as a correlate rather than the overall threshold under masking (e.g., DL<sub>masked</sub> minus DL<sub>quiet</sub>). This would better parallel the visual measure you use (the differential effect of the flanker on the reaction time) as a measure of top-down selection (as opposed to the overall RT with an incongruent flanker).</italic> </p><p>We agree and are grateful for this suggestion. We now used the elevation in the intensity DL caused by the backward maskers as a measure of auditory selective attention, defined as DL<sub>elev</sub> = DL<sub>masked</sub> − DL<sub>quiet</sub> as in several of our previous studies (e.g., Oberfeld &amp; Stahn, 2012, PLOS One). This separates the basic sensory sensitivity (DL<sub>quiet</sub>) in the intensity discrimination task from the detrimental effects of the distractors/maskers.</p><p><italic>You have shown that the intensity difference limen (DL) measured using backward masking correlates strongly with DL in quiet (<xref ref-type="table" rid="tbl2">Table 2</xref>). Given that DL<sub>masked</sub> and DL<sub>quiet</sub> are strongly correlated, using them both as predictors in the multiple regression analysis makes the assignment of coefficients (and subsequent t-scores) dependent on the exact algorithm used for fitting, and essentially arbitrary.</italic> </p><p>As can be seen in <xref ref-type="table" rid="tbl2">Table 2</xref> of the revised paper, using the DL-elevation instead of DL<sub>masked</sub> as predictor solves this problem. The partial correlation (controlling for age) between DL<sub>elev</sub> and DL<sub>quiet</sub> is close to 0. The same applies to the &quot;raw&quot; pairwise correlations (not controlling for age), as shown in the table included below. Also, DL<sub>elev</sub> shows no substantial correlations with any other predictor (see <xref ref-type="table" rid="tbl2">Table 2</xref> of the revised paper and the table below), except probably the sentence span measure (SS<sub>PCorr</sub>; ρpartial = −0.255, p =.077), which clearly represents a cognitive rather than sensory aspect.</p><p> <italic>If DL<sub>masked</sub> was not included, was DL<sub>quiet</sub> a significant predictor? Is DL<sub>masked</sub> a significant predictor when DL<sub>quiet</sub> has already been partialed out?</italic> </p><p> <italic>The Lasso fitting procedure penalizes the L1-norm of the set of coefficients, thereby favoring sparse solutions. Thus, it would pick the better of the two predictors: that is, DL<sub>masked</sub> might be picked over DL<sub>quiet</sub> or over both together. However, the fact that the procedure does not pick DL<sub>quiet</sub> is not in itself evidence that DL<sub>masked</sub> does not include differences from sensory factors. All this proves is that the DL<sub>masked</sub> is the better of the two predictors overall and effectively encompasses the other.</italic> </p><p><italic>The language you use to describe your results needs to reflect these subtleties, and/or you need to include more extensive statistical testing to rule out sensory contributions that are correlated with/included in DL<sub>masked</sub>. All you can currently conclude is that the perceptual weight given to the masker accounts for the behavior, not that this factor reflects only top-down selection.</italic> </p><p>These issues are solved by using DL<sub>elev</sub> instead of DL<sub>masked</sub>, because DL<sub>elev</sub> and DL<sub>quiet</sub> are virtually uncorrelated.</p><p> <italic>Also, you use an eigenvalue ratio criterion (First paragraph of Regression analysis section) to say that there isn't a multicollinearity problem here. This index is of limited utility when many noisy predictors are used. Indeed the correlation between DL<sub>masked</sub> and DL<sub>quiet</sub> is already evidence for some multi collinearity.</italic> </p><p>We agree that there is no general consensus concerning the optimal criterion for detecting multicollinearity, although the condition index is widely used in the literature. Concerning the two measures derived from the intensity discrimination task, these issues are solved because DL<sub>elev</sub> and DL<sub>quiet</sub> are virtually uncorrelated. On a more general level, the Gauß- Markov theorem states that the regression coefficients are unbiased even if there are correlations between predictors. However, multicollinearity could result in non-significant regression coefficients due to an increase in the standard error of the estimated regression coefficients. We consider it unlikely that this was a serious problem in our analyses, however, because there were only a few substantial pairwise correlations between predictors (<xref ref-type="table" rid="tbl2">Table 2</xref>), and because the pairwise partial correlations (where multicollinearity cannot have affected the results) between the SRS and the predictors showed a significant correlation for only one predictor (SS<sub>Pcorr</sub>) for which the regression coefficient in the multiple regression was non-significant. On a more general level, we believe that multiple regression provides a more informative view of the associations than the pairwise partial correlations, and that correlations between predictors are not argument against but for using multiple regression. These aspects are discussed in the revised paper:</p><p>Results: &quot;It appears possible that the (moderate) correlations between SS<sub>Pcorr</sub> and DL<sub>elev</sub> and age (see <xref ref-type="table" rid="tbl2">Table 2</xref>) increased the standard error of the regression coefficient for SS<sub>Pcorr</sub> in the multiple regression analysis shown in <xref ref-type="table" rid="tbl1">Table 1</xref>.&quot;</p><p>Materials and methods: &quot;The maximum condition index (Belsley et al. 1980) was 2.49. Belsley et al. (1980) suggested that only condition indices of at least 30 indicate potential problems with multicollinearity. […] However, multicollinearity could inflate the variance of the estimated regression coefficients (e.g., Greene 2008), resulting in non-significant regression coefficients.&quot;</p><p> <italic>3) The &quot;cognitive&quot; component you measure seems more specific than your discussion/presentation concedes.</italic> </p><p> <italic>The backward masking task you used to isolate auditory &quot;attention&quot; requires listeners to attend to a signal and ignore a later event that draws attention exogenously. This task no doubt indexes the ability to suppress an exogenous draw of attention, and your results show that this ability differs across listeners in a way that is reflected in &quot;cocktail party&quot; listening. However, this may be very different from the ability to sustain focused attention. Indeed, different attentional control subnetworks are thought to control exogenous vs. endogenous attention; a whole host of processes (e.g., precise sensory coding, scene analysis, top-down selection, exogenous attention.) allow us to selectively understand a target and ignore maskers.</italic> </p><p> <italic>In the first paragraph of discussion, you claim that &quot;the ability to direct auditory selective attention&quot; differs in consistent ways across listeners; however, it seems more appropriate to argue that there are differences in &quot;the ability to suppress exogenously salient, but task-irrelevant auditory events.&quot; See also the second paragraph, and eighth paragraph of Discussion section where you write, &quot;future experiments on attentional factors influencing cocktail-party listening could include tasks measuring both the endogenous and exogenous orienting of attention.&quot; We agree; but we suspect you have just isolated one particular aspect of attention, already.</italic> </p><p> <italic>This does not diminish the importance of your study, but changes the language you might use to discuss your results. Please consider integrating this idea into the way you describe your study. Rather than arguing that you are measuring &quot;attention&quot; (and leaving it at that), taking a more sophisticated, nuanced view that distinguishes amongst different aspects of attention, and that doesn't over-simplify, would enhance the impact of your work.</italic> </p><p>We agree, and this was exactly why in the manuscript we say early on that we are interested in &quot;selectively attending to a target in the presence of distractors&quot; rather than speaking about &quot;attention&quot; per se. We now double-checked the text for 5 passages where our wording was too unspecific, and now use this more specific description throughout the text. Also, the differences between endogenous and exogenous attention were already discussed in the original manuscript. However, we reached a different conclusion and believe that because the spatial position of the target speaker in the cocktail-party listening task and the temporal position of the target tones in the intensity discrimination task were fixed and known, these tasks involved an endogenous rather than exogenous direction of attention. In the revised paper, we introduce this aspect earlier in the Discussion section, discuss that capture of attention by the backward maskers is an alternative &quot;exogenous attention&quot; view of our task, and added the qualification that the intensity discrimination task might even more specifically address &quot;the ability to suppress salient, but task-irrelevant auditory events.&quot;:</p><p>&quot;To test this hypothesis, future experiments on attentional factors influencing cocktail-party listening could include tasks measuring both the endogenous and exogenous orienting of attention, using for instance temporal or spatial cueing (e.g., Coull and Nobre 1998; Posner 1980). Alternatively, one could argue that the onset of the backward masker elicits a capture of attention away from the target tones (e.g., Desimone and Duncan 1995; Jonides and Yantis 1988; Yantis and Jonides 1990). Thus, it might even be necessary to further qualify the description of the particular aspect of attention that is indexed by the intensity discrimination task under backward masking and say that is measures the ability to suppress salient, but task-irrelevant auditory events.&quot;</p></body></sub-article></article>