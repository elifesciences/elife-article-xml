<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">80990</article-id><article-id pub-id-type="doi">10.7554/eLife.80990</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A visual sense of number emerges from divisive normalization in a simple center-surround convolutional network</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-62579"><name><surname>Park</surname><given-names>Joonkoo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6703-3961</contrib-id><email>joonkoo@umass.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-283953"><name><surname>Huber</surname><given-names>David E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7709-7993</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0072zz521</institution-id><institution>Department of Psychological and Brain Sciences, University of Massachusetts Amherst</institution></institution-wrap><addr-line><named-content content-type="city">Amherst</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0072zz521</institution-id><institution>Commonwealth Honors College, University of Massachusetts Amherst</institution></institution-wrap><addr-line><named-content content-type="city">Amherst</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Serences</surname><given-names>John T</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0168r3w48</institution-id><institution>University of California, San Diego</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>03</day><month>10</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e80990</elocation-id><history><date date-type="received" iso-8601-date="2022-06-11"><day>11</day><month>06</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-10-02"><day>02</day><month>10</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-06-01"><day>01</day><month>06</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.06.01.494401"/></event></pub-history><permissions><copyright-statement>Â© 2022, Park and Huber</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Park and Huber</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-80990-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-80990-figures-v2.pdf"/><abstract><p>Many species of animals exhibit an intuitive sense of number, suggesting a fundamental neural mechanism for representing numerosity in a visual scene. Recent empirical studies demonstrate that early feedforward visual responses are sensitive to numerosity of a dot array but substantially less so to continuous dimensions orthogonal to numerosity, such as size and spacing of the dots. However, the mechanisms that extract numerosity are unknown. Here, we identified the core neurocomputational principles underlying these effects: (1) center-surround contrast filters; (2) at different spatial scales; with (3) divisive normalization across network units. In an untrained computational model, these principles eliminated sensitivity to size and spacing, making numerosity the main determinant of the neuronal response magnitude. Moreover, a model implementation of these principles explained both well-known and relatively novel illusions of numerosity perception across space and time. This supports the conclusion that the neural structures and feedforward processes that encode numerosity naturally produce visual illusions of numerosity. Taken together, these results identify a set of neurocomputational properties that gives rise to the ubiquity of the number sense in the animal kingdom.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>numerosity perception</kwd><kwd>computational modeling</kwd><kwd>divisive normalization</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>BCS 1654089</award-id><principal-award-recipient><name><surname>Park</surname><given-names>Joonkoo</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>RF1MH114277</award-id><principal-award-recipient><name><surname>Huber</surname><given-names>David E</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A set of canonical computational principles implemented in a simple feedforward neural network naturally gives rise to the network's sensitivity to numerosity and its illusory effects, providing an explanation for the ubiquity of the number sense in the animal kingdom.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Humans have an intuitive sense of number that allows numerosity estimation without counting (<xref ref-type="bibr" rid="bib12">Dehaene, 2011</xref>). The prevalence of number sense across phylogeny and ontogeny (<xref ref-type="bibr" rid="bib16">Feigenson et al., 2004</xref>) suggests common neural mechanisms that allow the extraction of numerosity information from a visual scene. While earlier empirical work highlighted the parietal cortex for numerosity representation (<xref ref-type="bibr" rid="bib34">Nieder, 2016</xref>), growing evidence suggests that numerosity is processed at a much earlier stage. A recent study, using high-temporal resolution electroencephalography together with a novel stimulus design, demonstrated that early visual cortical activity is uniquely sensitive to the number (abbreviated as <italic>N</italic>) of a dot array in the absence of any behavioral response, but much less so to nonnumerical dimensions that are orthogonal to number (i.e., size and spacing, abbreviated as <italic>Sz</italic> and <italic>Sp</italic>, respectively; see <xref ref-type="fig" rid="fig1">Figure 1A</xref>; <xref ref-type="bibr" rid="bib35">Park et al., 2016</xref>). Subsequent behavioral and neural studies showed that this early cortical sensitivity to numerosity indicates feedforward activity in visual areas <italic>V</italic>1, <italic>V</italic>2, and <italic>V</italic>3 (<xref ref-type="bibr" rid="bib17">Fornaciai et al., 2017</xref>; <xref ref-type="bibr" rid="bib19">Fornaciai and Park, 2021</xref>; <xref ref-type="bibr" rid="bib18">Fornaciai and Park, 2018</xref>). These results suggest that numerosity is a basic currency of perceived magnitude early in the visual stream.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Stimulus design and computational methods.</title><p>(<bold>A</bold>) Properties of magnitude dimensions represented in three orthogonal axes defined by log-scaled number (<italic>N</italic>), size (<italic>Sz</italic>), and spacing (<italic>Sp</italic>) (<xref ref-type="table" rid="table1">Table 1</xref>). (<bold>B</bold>) Schematic illustration of the computational process from a dot-array image to the driving input (i.e., the model without divisive normalization), <italic>D</italic>, of the simulated neurons, versus the normalized response (i.e., the model with divisive normalization), <italic>R</italic>. A bitmap image of a dot array was fed into a convolutional layer with DoG filters in six different sizes (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). The resulting values, after half wave rectification, represented the driving input. Neighborhood weight, defined by Î·, was multiplied by the driving input across all the neurons across all the filter sizes, the summation of which served as the normalization factor (see <xref ref-type="disp-formula" rid="equ2 equ3">Equations 2 and 3</xref>). This illustration of Î· is showing the case where <italic>r</italic> is defined by twice the size of the sigma for the DoG kernel. DOG, difference-of-Gaussians.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig1-v2.tif"/></fig><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Mathematical relationship between various magnitude dimensions.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Dimension</th><th align="left" valign="bottom">As a function of <italic>n</italic>, <italic>r</italic><sub><italic>d</italic></sub>, <italic>r</italic><sub><italic>f</italic></sub></th><th align="left" valign="bottom">As a function of <italic>N</italic>, <italic>Sz</italic>, <italic>Sp</italic></th></tr></thead><tbody><tr><td align="left" valign="bottom">Individual area (IA)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Ï</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Total area (TA)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi><mml:mo>Ã</mml:mo><mml:mi>Ï</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Field area (FA)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Ï</mml:mi><mml:mi>r</mml:mi><mml:msup><mml:mrow><mml:msub><mml:mi/><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>F</mml:mi><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Sparsity (Spar)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Ï</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Individual perimeter (IP)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mi>Ï</mml:mi></mml:msqrt><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Total perimeter (TP)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi><mml:mo>Ã</mml:mo><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mi>Ï</mml:mi></mml:msqrt><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Coverage (Cov)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi><mml:mo>Ã</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Closeness (Close)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>Ï</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>Ã</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>Ã</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table><table-wrap-foot><fn><p>Note: n=number; r<sub>d</sub>=radius of individual dot; r<sub>f</sub>=radius of the invisible circular field in which the dots are drawn.</p></fn></table-wrap-foot></table-wrap><p>Nevertheless, it is unclear how feedforward neural activity creates a representation of numerosity within these brain regions. Specifically, the view of numerosity as a <italic>discrete number</italic> of items seems incompatible with the primary modes of information processing in the brain, such as firing rates and population codes, which are <italic>continuous</italic>. Indeed, some authors assume that continuous nonnumerical magnitude information is encoded first and integrated to produce the representation of numerosity (<xref ref-type="bibr" rid="bib10">Dakin et al., 2011</xref>; <xref ref-type="bibr" rid="bib22">Gebuis et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Leibovich et al., 2017</xref>). In contradiction, however, recent empirical studies demonstrate that the magnitude of visual cortical activity is most sensitive to number and is relatively insensitive to other continuous dimensions such as size and spacing of a dot array (<xref ref-type="bibr" rid="bib14">DeWind et al., 2019</xref>; <xref ref-type="bibr" rid="bib36">Park, 2018</xref>; <xref ref-type="bibr" rid="bib38">Paul et al., 2022</xref>; <xref ref-type="bibr" rid="bib45">Van Rinsveld et al., 2020</xref>).</p><p>What explains this insensitivity to spacing and size effects, despite robust sensitivity to number? Previous computational modeling studies offer some hints to this question. The computational model of <xref ref-type="bibr" rid="bib11">Dehaene and Changeux, 1993</xref> explains numerosity detection based on several neurocomputational principles. That model (hereafter D&amp;C) assumes a one-dimensional linear retina (each dot is a line segment), and responses are normalized across dot size via a convolution layer that represents combinations of two attributes: (1) dot size, as captured by difference-of-Gaussians contrast filters of different widths; and (2) location, by centering filters at different positions. In the convolution layer, the filter that matches the size of each dot dominates the neuronal activity at the location of the dot owing to a winner-take-all lateral inhibition process. To indicate numerosity, a summation layer pools the total activity over all the units in the convolution layer. While the D&amp;C model provided a proof of concept for numerosity detection, it has several limitations as outlined in the discussion. Of these, the most notable is that strong winner-take-all in the convolution layer discretizes visual information (e.g., discrete locations and discrete sizes yielding a literal count of dots), which is implausible for early vision. As a result, the output of the model is completely insensitive to anything other than number in all situations, which is inconsistent with empirical data (<xref ref-type="bibr" rid="bib37">Park et al., 2021</xref>).</p><p>Recently, several deep-network-based models have been applied to numerosity perception (<xref ref-type="bibr" rid="bib9">Creatore et al., 2021</xref>; <xref ref-type="bibr" rid="bib27">Kim et al., 2021</xref>; <xref ref-type="bibr" rid="bib33">Nasr et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Stoianov and Zorzi, 2012</xref>; <xref ref-type="bibr" rid="bib42">Testolin et al., 2020</xref>). <xref ref-type="bibr" rid="bib41">Stoianov and Zorzi, 2012</xref> developed a hierarchical generative model of the sensory input (images of object arrays) and demonstrated that after learning to generate its own sensory input, some units in the hidden layer were sensitive to numerosity irrespective of total area while other units were sensitive to total area irrespective of numerosity. This suggests an unsupervised learning mechanism for efficient coding of the sensory data that can extract statistical regularities of the input images. The authors provided some suggestions as to the specific neurocomputational principle(s) underlying the success of this model. For example, the first hidden layer developed center-surround representations of different sizes and the second layer developed a pattern of inhibitory connections to units in the first layer that encoded cumulative area. However, the development of center-surround detectors based on unsupervised learning is a common observation (<xref ref-type="bibr" rid="bib4">Bell and Sejnowski, 1997</xref>), indicating that such results are not unique to displays of dot arrays, and are instead a natural byproduct of learning in the visual system. In a more recent study, <xref ref-type="bibr" rid="bib27">Kim et al., 2021</xref> found that sensitivity and selectivity to numerosity were well captured in a completely untrained convolutional neural network (AlexNet) (<xref ref-type="bibr" rid="bib28">Krizhevsky et al., 2012</xref>), suggesting that a repeated process of convolution and pooling is capable of normalizing continuous dimensions and extracting numerosity information as a statistical regularity of an image. However, these are âblack boxâ models, and it is not always clear <italic>how</italic> these models work; these models contain many mechanisms, and it is not clear which mechanisms are crucial for producing numerosity-sensitive units.</p><p>Rather than applying a complex multilayer learning model, we distill the neurocomputational principles that enable the visual system to be sensitive to numerosity while remaining relatively insensitive to nonnumerical visual features. These principles are simulated in a single-layer model that does not need to be trained. Consistent with prior work, we hypothesize that center-surround contrast filters at different spatial scales play an important role in numerosity perception. In addition to this âconvolutionâ of the input, most prior proposals entail some form of pooling or normalization (e.g., normalization between center-surround units). This can emerge across layers of visual processing, as often assumed in âmax poolingâ layers of a convolutional neural network (<xref ref-type="bibr" rid="bib40">Scherer et al., 2010</xref>), or it can occur within a layer, as in the strong winner-take-all lateral inhibition used in the <xref ref-type="bibr" rid="bib11">Dehaene and Changeux, 1993</xref> model. Furthermore, some models contain both within-layer normalization and between-layer max pooling (<xref ref-type="bibr" rid="bib28">Krizhevsky et al., 2012</xref>). Although the functional form of within-layer normalization is similar to between-layer max pooling, it differs anatomically, placing the normalized response earlier in visual processing. In determining the neural mechanisms that are core to numerosity, we note that a moderate level of within-layer normalization is consistent with âdivisive normalizationâ (<xref ref-type="bibr" rid="bib6">Carandini and Heeger, 2011</xref>), in which the response of each neuron reflects its driving input divided by the summation of responses from anatomically surrounding neurons (i.e., a normalization pool). This normalization is not as extreme as winner-take-all normalization and tends to preserve visual precision through graded activation responses. In the case of early vision, the normalization pool is spatially determined by retinotopic positions. Divisive normalization is known to exist throughout the cortex, reflecting the shunting inhibition of inhibitory interneurons that limit neural activation within a patch of cortex (<xref ref-type="bibr" rid="bib6">Carandini and Heeger, 2011</xref>). A wealth of evidence indicates that divisive normalization is ubiquitous across species and brain systems and hence thought to be a fundamental computation of many neural circuits. Thus, any theory of numerosity perception would be remiss not to include the effect of within-layer divisive normalization.</p><p>To determine the contribution of divisive normalization to numerosity encoding, we implemented an untrained neural network with versus without divisive normalization as applied to center-surround filters at different spatial scales (e.g., as in <italic>V</italic>1) (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The output simulates the summation of synchronized postsynaptic activity of a large population of neurons at a pre-decisional stage, consistent with previous work (<xref ref-type="bibr" rid="bib17">Fornaciai et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Park et al., 2016</xref>). Our results show that (1) hierarchically organized multiple center-surround filters of varying size make the network insensitive to spacing and that (2) divisive normalization implemented across network units makes the network additionally insensitive to size. Divisive normalization not only occurs over space but also over time (<xref ref-type="bibr" rid="bib26">Huber and OâReilly, 2003</xref>). Thus, we additionally implemented temporal divisive normalization to test if it explains the contextual effects of numerosity perception (<xref ref-type="bibr" rid="bib5">Burr and Ross, 2008</xref>; <xref ref-type="bibr" rid="bib37">Park et al., 2021</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Center-surround convolution captures total pixel intensities and eliminates the effect of spacing</title><p>Images of dot arrays that varied systematically across number, size, and spacing (see Materials and methods) were fed into a convolutional layer with difference-of-Gaussians (DoG) filters in six different sizes. The driving input, <italic>D</italic>, for each filter was the convolution of a DoG with the display image, in other words a weighted sum of local pixel intensities (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The summed driving input in each filter size showed different effects as a function of number, size, and spacing (<xref ref-type="fig" rid="fig2">Figure 2A</xref>), but when the driving input was summed across all filter sizes it was most strongly modulated by both number and size equally but not by spacing (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), suggesting that the neural activity tracks total area (<italic>TA</italic>; see <xref ref-type="table" rid="table1">Table 1</xref>; <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>). The effect of spacing existed in the fourth and sixth largest filter sizes, largely indicating effects of field area and density, respectively (<xref ref-type="fig" rid="fig2">Figure 2A</xref>); however, the effects in these two filter sizes were in opposite directions, which made the overall effect very small. These results illustrate that having multiple filter sizes is key to normalizing the spacing dimension. In sum, the driving input of the convolutional layer primarily captured total pixel intensity of the image regardless of the spatial configuration of dots.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Simulation results showing the effects of number (<italic>N</italic>), size (<italic>Sz</italic>), and spacing (<italic>Sp</italic>) on the driving input and normalized response of the network units.</title><p>(<bold>A</bold>) Summed driving input (Î£<italic>D</italic>) separately for each of the six filter sizes as a function of <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> (see Materials and methods for the specific values of s). (<bold>B</bold>) Î£<italic>D</italic> across all filters is modulated by both number and size but not by spacing. (<bold>C</bold>) Summed normalized response (Î£<italic>R</italic>) showed a near elimination of the <italic>Sz</italic> effect leaving only the effect of <italic>N</italic>. The results were simulated using <italic>r</italic>=2Ï and <italic>Î³</italic>=2, but effects of <italic>Sz</italic> and <italic>Sp</italic> were negligible across all the tested model parameters (<xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref>). The value <italic>s</italic> on the horizontal axis indicates a median value for each dimension (see Materials and methods).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 1.</label><caption><title>Additional illustration concerning the driving input.</title><p>Correlation between summed driving input, Î£<italic>D</italic>, and log-scaled total area (<italic>TA</italic>), total perimeter (<italic>TP</italic>), and number (<italic>N</italic>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 2.</label><caption><title>Simulation results showing the effects of number (<italic>N</italic>), size (<italic>Sz</italic>), and spacing (<italic>Sp</italic>) on the normalized response (i.e., the model with divisive normalization) of the network units as a function of neighborhood size (<italic>r</italic>) and amplification factor (Î³).</title><p>Greater <italic>r</italic> resulted in a flatter curve for the size effect, and this flattening became more pronounced as Î³ increased, with the combination of high values for both parameters producing a modest negative effect of size as well as a modest positive effect of spacing. More specifically, the combination of high <italic>r</italic> and Î³ values produces a winner-take-all process across large regions of the display. Greater size, in these cases, thus leads to greater normalization factor (denominator) which results in reduced normalization activity, although the extent of this normalization depends on how far away the other dots are located (e.g., less normalization with spacing). Although this is an interesting phenomenon, empirical neural and behavioral studies show a positive effect of size, if any. Hence, larger values of <italic>r</italic> and Î³ in this model do not seem to be plausible in the case of numerosity perception. Therefore, we chose moderate values of <italic>r</italic> (=2) and Î³ (=2) for subsequent simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 3.</label><caption><title>Simulation results from images of densely packed dot arrays with extremely high numerosity.</title><p>(<bold>A</bold>) The dots arrays were systematically constructed ranging equally across the dimensions of <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic>, which was achieved by using the following parameters: number (<italic>n</italic>)=from 90 to 360, dot radius (<italic>r<sub>d</sub></italic>)=from 1 to 2 pixels, field radius (<italic>r<sub>f</sub></italic>)=from 45 to 90 pixels. For each point in the 2Ã2Ã2 parameters space, 16 unique arrays were created. (<bold>B</bold>) Examples of dot array images are shown. These images were submitted to the current computational model with the same parameters used in our original analysis (<italic>r</italic>=2Ï and <italic>Î³</italic>=2). (<bold>C</bold>) Summed driving input (Î£D) was modulated primarily by <italic>N</italic> and <italic>Sz</italic>. Summed normalized response (Î£<italic>R</italic>) was most modulated by <italic>N</italic> but also by <italic>Sz</italic> and <italic>Sp</italic> to some degree. The slope of the linear fit to <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> adjusted by the baseline (the slope estimate divided by the intercept estimate in the simple regression) was 0.4086, 0.1958, and 0.1488, respectively. Note that this baseline-adjusted slope allows comparison of relative change in the response driven by <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic>, despite differences in the baseline activity across different sets of images. In our original simulation, the baseline-adjusted slopes for <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> were 0.5771, 0.0646, and 0.0321, respectively. Thus, the same computational network when representing much more densely packed dot arrays seems to show relatively decreased sensitivity to numerosity. These results indicate that neural sensitivity to various magnitude dimensions and the degree of that sensitivity differ based on the assumptions about the distribution of filters and filter sizes.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig2-figsupp3-v2.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Divisive normalization nearly eliminates the effect of size</title><p>We next added divisive normalization to the center-surround model, with different parameter values (neighborhood size and amplification factor) to determine the conditions under which divisive normalization might reduce or eliminate the effect of size and whether it might alter the absence of spacing effects in the driving input. Driving input was normalized by the normalization factor defined by a weighted summation of neighboring neurons and filter sizes (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>). The summed normalized responses, Î£<italic>R</italic>, were strongly modulated by number but much less so, if any, by size and spacing (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). The pattern of results was largely consistent across different parameter values for neighborhood size (<italic>r</italic>) and amplification factor (Î³) of the normalization model (<xref ref-type="fig" rid="fig2s2">Figure 2âfigure supplement 2</xref>); therefore, we chose moderate values of <italic>r</italic> (=2) and Î³ (=2) for subsequent simulations. As one way to quantify these modulatory effects, a simple linear regression with Î£<italic>R</italic> as the dependent variable with mean-centered values of <italic>N</italic> as the independent variable (as well as <italic>Sz</italic> and <italic>Sp</italic> in separate regression models) was performed. Then, the slope estimate was divided by the intercept estimate, so that these effects could be easily compared across different sets of images (see <xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplement 3</xref>). This baseline-adjusted regression slope for <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> was 0.5771, 0.0646, and 0.0321, respectively. A multiple regression model with summed normalized responses as the dependent measure and the three orthogonal dimensions (<italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic>) as the independent variables revealed a much larger coefficient estimate for <italic>N</italic> (<italic>b</italic>=13.68) than for <italic>Sz</italic> (<italic>b</italic>=1.541) and for <italic>Sp</italic> (<italic>b</italic>=0.7809). In sum, a modest degree of divisive normalization eliminated the effect of size and, at the same time, did not alter the absence of spacing effects.</p></sec><sec id="s2-3"><title>Divisive normalization across space explains various visual illusions</title><p>Next, we considered if the center-surround model with divisive normalization also explains some of the most well-known visual illusions of numerosity perception. If so, this would support the hypothesis that these visual illusions reflect early visual processing at the level of numerosity encoding, without requiring any downstream processing. In other words, early vision may be the root cause of both numerosity encoding and numerosity visual illusions.</p><p>Empirical studies have long shown that irregularly spaced arrays (compared with regularly spaced arrays) and arrays with spatially grouped items (compared with ungrouped items) are all underestimated (<xref ref-type="bibr" rid="bib21">Frith and Frit, 1972</xref>; <xref ref-type="bibr" rid="bib23">Ginsburg, 1976</xref>; <xref ref-type="bibr" rid="bib44">van Oeffelen and Vos, 1982</xref>). These illusions were indeed captured by the inclusion of divisive normalization. Irregular arrays yielded a 5.98% reduction (Cohenâs <italic>d</italic>=4.23) and grouped arrays yielded a 2.99% reduction (<italic>d</italic>=10.02) of normalized response (<xref ref-type="fig" rid="fig3">Figure 3AâB</xref>). Note that, in the absence of divisive normalization, there was either no effect or an effect in the opposite direction (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>). The underestimation effects in the normalized response can be explained by greater normalization when neurons with overlapping normalization neighborhoods are activated, with this greater overlap occurring in subregions of the images for irregular or grouped dots. This explanation is functionally similar to one provided by the âoccupancy modelâ (<xref ref-type="bibr" rid="bib2">Allik and Tuulmets, 1991</xref>), but our results demonstrate that these effects emerge naturally within early visual processing.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Simulation of numerosity illusions.</title><p>Normalized response of the network units influenced by the (<bold>A</bold>) regularity, (<bold>B</bold>) grouping, and (<bold>C</bold>) heterogeneity of dot arrays, as well as by (<bold>D</bold>) adaptation and (<bold>E</bold>) context. Error bars represent one standard deviation of the normalized response across simulations; however, the error bars in most cases were too small to be visualized. Spatial normalization effects (<bold>A</bold>, <bold>B</bold>, and <bold>C</bold>) were simulated with <italic>r</italic>=2 and <italic>Î³</italic>=2. Temporal normalization effects (<bold>D, E</bold>) used these same parameters values in combination with <italic>Ï</italic>=8 and <italic>Î´</italic>=1.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>Simulation of visual illusions considering the driving input (i.e., the model without divisive normalization).</title><p>No underestimation was observed in any of these cases. If any, irregularly spaced arrays (by 2.19%), grouped arrays (by 1.98%), and more heterogeneous arrays (by 3.06%) were overestimated based on their driving input. In sum, without divisive normalization, the model failed to explain the typically observed visual illusions. Error bars indicate one standard deviation of the normalized response across 16 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 2.</label><caption><title>Effects of single dots.</title><p>(<bold>A</bold>) Images of small (radius=3.5), medium (radius=5), and large (radius=7) singly presented dots were fed into the computational model, and the driving input and the normalized response of the units with the receptive fields (RFs) targeting the dots were computed. As expected, driving input was nearly perfectly correlated with area of the dots (<italic>r</italic>=0.9983). In contrast, normalized response showed a linear relationship with the radius, which meant a logarithmic relationship with area. This occurs because a larger dot involves a greater number of filters overlapping with the dot (i.e., greater driving input), but this greater number of filters leads to a greater normalization factor (increase in the denominator of divisive normalization). In other words, the normalized response becomes tempered in a non-linear way, producing a saturating normalized response as a function of increasing dot area. (<bold>B</bold>) Schematic illustration of the saturating effect of normalized response for a single dot (within a hypothetical dot array) as a function of the area of the dot. Heterogeneous arrays are created by holding the total area and numerosity constant while changing individual dot size. Therefore, when medium-sized dots (M) are replaced with large dots (L), the same number of replacements must be done to go from medium-size dots (M) to small dots (S). However, because of the saturating effect, there is a greater decrease in normalized response than an increase in normalized response. Thus, the overall normalized response becomes necessarily smaller in a heterogeneous array compared to a homogeneous array.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 3.</label><caption><title>Adaptation effects as a function of model parameters.</title><p>In this simulation, the target of 10 dots was preceded by an adaptor of 5, 10, or 20 dots. Temporal normalization could be understood in terms of a sigmoid response curve with the amplification factor (<italic>Î´</italic>) determining the slope of the curve and the recency weighting factor (<italic>Ï</italic>) determining the horizontal position of the curve. Smaller <italic>Ï</italic> values resulted in a relative overestimation of the normalized response to the target, which can be explained by the relative leftward horizontal shift of the sigmoid response curve and hence relative increase in normalized activity (nonlinearly as a function of driving input). Larger <italic>Î´</italic> values resulted in greater under- and overestimation effects, which can be explained by the sharpening of the sigmoid response curve. Error bars indicate one standard deviation of the normalized response across 32 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 4.</label><caption><title>Adaptation effects along the size dimension.</title><p>The target of medium-sized array was preceded by an adaptor of small-, medium-, or large-sized array. No systematic pattern of adaptation was observed in these simulations. Error bars indicate one standard deviation of the normalized response across 32 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 5.</label><caption><title>Adaptation effects along the spacing dimension.</title><p>The target of medium-spaced array was preceded by an adaptor of small-, medium-, or large-spaced array. No systematic pattern of adaptation was observed in these simulations. Error bars indicate one standard deviation of the normalized response across 32 simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-figsupp5-v2.tif"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 6.</label><caption><title>Context effects as a function of model parameters.</title><p>When the model saw 400 dot arrays that varied randomly across number, size, and spacing, the normalized responses to images corresponding to small, medium, and large sizes (<italic>Sz</italic>) showed no association with size. When then model saw 400 dot arrays that differed only in size, the normalized responses were strongly associated with size. Such a pattern was consistent across all the simulations over various amplification factors (<italic>Î´</italic>) and recency weighting factors (<italic>Ï</italic>) tested. Error bars represent one standard deviation of the normalized response across 128 simulations. Note that the error bars in the exclusive change in size conditions are extremely small.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-figsupp6-v2.tif"/></fig><fig id="fig3s7" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 7.</label><caption><title>Simulation of the connectedness illusion.</title><p>In order to simulate the connectedness illusion, one set of âconnectedâ dot arrays and another set of âunconnectedâ dot arrays were constructed. First, a large number of dot arrays with <italic>n</italic>=10, <italic>r<sub>d</sub></italic>=6.5 pixels, and <italic>r<sub>f</sub></italic>=64 pixels were created. Then, connected dot arrays were constructed by connecting the centers of two dots with a thin white line that was 2 pixels in width. The resulting images were visually checked, and all the images in which the lines cross or touch other lines or dots were removed from the set. Then, unconnected dot arrays were constructed from those connected dot arrays by breaking the midpoints of the interconnecting lines and rotating those broken lines about the center of each dot by Â±30Â° in either direction randomly determined. The resulting images were checked again for any cross over of lines, in which case both that image and the corresponding connected image were removed. A total of 16 connected and 16 unconnected arrays entered the simulation. The connected arrays were underestimated by over 6% (Cohenâs <italic>d</italic>=5.72). Such an underestimation was not observed when considering the driving input (i.e., the model without divisive normalization). Error bars represent one standard deviation of the normalized response across simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig3-figsupp7-v2.tif"/></fig></fig-group><p>A relatively understudied visual illusion is the effect of heterogeneity of dot size on numerosity perception. A recent behavioral study demonstrated that the point of subjective equality was about 5.5% lower in dot arrays with heterogeneous sizes compared with dot arrays with homogeneous sizes (<xref ref-type="bibr" rid="bib29">Lee et al., 2016</xref>). Consistent with this behavioral phenomenon, our simulations revealed that greater heterogeneity leads to greater underestimation (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). As compared to the homogeneous array, a moderately heterogeneous array (labeled âless heterogeneousâ) yielded a 1.14% reduction (<italic>d</italic>=2.43) and the more heterogeneous array yielded a 5.87% reduction (<italic>d</italic>=8.11) in the magnitude of the normalized response. This occurs because the summed normalized response of a single dot saturates as dot area increases (<xref ref-type="fig" rid="fig3s2">Figure 3âfigure supplement 2</xref>), which interacts with the heterogeneity of the dot array. As heterogeneity is manipulated by making some dots larger and other dots smaller while keeping total area and numerosity constant, this saturating effect makes the overall normalized response smaller as a greater number of dots deviates from the average size (the gains from making some dots larger is not as great as the losses from making some dots smaller). As in the case of other illusions, the same analysis in the absence of divisive normalization fails to produce this illusion (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>).</p></sec><sec id="s2-4"><title>Divisive normalization across time explains numerosity adaptation and context effects</title><p>One of the most well-known visual illusions in numerosity perception is the adaptation effect (<xref ref-type="bibr" rid="bib5">Burr and Ross, 2008</xref>). We reasoned that numerosity adaptation might reflect divisive normalization across time, similar to adaptation with light or odor (<xref ref-type="bibr" rid="bib6">Carandini and Heeger, 2011</xref>), which shifts the response curve and produces a contrast aftereffect. Closely related to temporal adaptation, the recently discovered temporal contextual effect of numerosity perception is an amplified neural response to changes in one dimension (e.g., changes in dot size) when observers experience a trial sequence with only changes in that dimension (<xref ref-type="bibr" rid="bib37">Park et al., 2021</xref>). Therefore, we also applied the model with temporal normalization to the context effect.</p><p>We modeled temporal divisive normalization for a readout neuron that is driven by the sum of the normalized responses across all units, Î£<italic>R</italic>. This summed total response (now referred to as <italic>M</italic>) was temporally normalized (<italic>M<sup>*</sup></italic>) by the recency weighted average of the driving input (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). Temporal normalization shifts the sigmoid response curve horizontally along the dimension of <italic>M</italic> to maximize the sensitivity of <italic>M<sup>*</sup></italic> based on the recent history of stimulation. Provided that the constant in the denominator is approximately equal to the current trialâs response, the results of spatial normalization reported above would not change by also introducing temporal normalization. Temporal normalization was assessed for cases of a target array of 10 dots after observing an array of 5, 10, or 20 dots with the model parameters of <italic>Ï</italic>=8 and <italic>Î´</italic>=1 (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) in 32 simulations. Similar to behavioral results (<xref ref-type="bibr" rid="bib1">Aagten-Murphy and Burr, 2016</xref>), the target of 10 dots was underestimated by 28.9% (<italic>d</italic>=18.04) when the adaptor was more numerous than the target and was overestimated by 26.6% (<italic>d</italic>=14.06) when the adaptor was less numerous than the target. This pattern held across all tested model parameters (<xref ref-type="fig" rid="fig3s3">Figure 3âfigure supplement 3</xref>). It is important to note that the model does not âknowâ the number of dots in the adaptor image. Instead, temporal divisive normalization compares the spatially normalized response of the current image to that of the adaptor image and because the spatially normalized response is primarily sensitive to variation in number, there is a contrast effect (e.g., âadapt highâ reduces the response to the current image). Indeed, because the normalized response is less sensitive to variation in size or spacing, no adaptation effect emerges for those variables (<xref ref-type="fig" rid="fig3s4">Figure 3âfigure supplement 4</xref> and <xref ref-type="fig" rid="fig3s5">Figure 3âfigure supplement 5</xref>). These results confirm that divisive normalization across space and time naturally produces numerosity adaptation.</p><p>Using the same model and parameters of temporal normalization (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), we tested if it can also explain longer-sequence context effects. Studies show that the effect of size is negligible in the context of a trial sequence that varies size, spacing, and number (<xref ref-type="bibr" rid="bib35">Park et al., 2016</xref>), but that the effect of size becomes apparent when number and spacing are held constant while varying only size (<xref ref-type="bibr" rid="bib37">Park et al., 2021</xref>). We simulated each of these contexts: the model saw a total of 400 dot arrays that varied across number, size, and spacing or else it saw 400 dot arrays that differed only in size (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). A total of 128 simulations were run for each context. In the context where all dimensions varied, the three levels of <italic>Sz</italic> had no linear association with <italic>M<sup>*</sup></italic>; the 95th percentile confidence interval of the ordinary-least-square linear slope of <italic>M<sup>*</sup></italic> as a function of <italic>Sz</italic> was [â0.0243, 0.0182], which includes 0. In contrast, in the context where only size varied, <italic>M<sup>*</sup></italic> was positively correlated with <italic>Sz</italic>; slope confidence interval of [0.00315, 0.00359], which excludes 0. This pattern held across all tested model parameters (<xref ref-type="fig" rid="fig3s6">Figure 3âfigure supplement 6</xref>). This phenomenon can be explained by the adaptive shifting of the sigmoid response curve across trials. In the former case, because recent trials are often of larger or smaller total response as compared to the current trial, the normalization for the current trial is more often pushed to the nonlinear parts of the normalization curve (e.g., closer to ceiling and floor effects). Thus, the temporally normalized response is relatively insensitive to the small effect of size (keeping in mind that the effect of size is made small by spatial divisive normalization). In contrast, when only size varies across trials, the total response of recent trials is more likely to be well-matched to the total response of the current trial. As a result, the small effect of size is magnified in light of this temporal stability.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Despite the ubiquity of number sense across animal species, it was previously unclear how unadulterated perceptual responses produce the full variety of numerosity perception effects. Recent empirical studies demonstrate that feedforward neural activity in early visual areas is uniquely sensitive to the numerosity but much less so, if any, to the dimension of size and spacing, which are continuous nonnumerical dimensions that are orthogonal to numerosity. Despite recent advances showing that numerosity information <italic>can</italic> be extracted from a deep neural network (<xref ref-type="bibr" rid="bib27">Kim et al., 2021</xref>; <xref ref-type="bibr" rid="bib33">Nasr et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Stoianov and Zorzi, 2012</xref>), precisely <italic>how</italic> early visual areas normalize the effects of size and spacing was unclear.</p><p>The current study identified the key neurocomputational principles involved in this process. First, the implementation of hierarchically organized multiple sizes of center-surround filters effectively normalizes spacing owing to offsetting factors (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). On the one hand, relatively smaller filters that roughly match or are slightly bigger than each dot produce a greater response when the dots are farther apart because their off-surround receptive fields (RFs) do not overlap. On the other hand, relatively larger filters that cover most of the array produce a greater response when the dots are closer together because stimulation at the center of the on-surround RFs is maximized. When summing these opposing effects, which occur at different center-surround filter sizes, the overall neural activity is relatively invariant to spacing. Second, the implementation of divisive normalization reduces the effect of size by reducing activity at larger filter sizes that have overlapping normalization neighborhoods (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). More specifically, increase in size produces greater overall unnormalized activity because more filters (e.g., both larger and smaller) are involved in responding to larger dots whereas only smaller filters respond to small dots (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). However, normalization dampens this increase. Critically, divisive normalization is a within-layer effect, reflecting recurrent inhibition between center-surround filters owing to inhibitory interneurons. Thus, the effect of dot size is eliminated in early visual responses. In sum, contrast filters at different spatial scales and divisive normalization naturally increases sensitivity to the number of items in a visual scene. Because these neurocomputational principles are commonly found in visual animals, this suggests that visual perception of numerosity is a natural, emergent phenomenon.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Simplified schematics explaining the mechanisms underlying the normalization of size and spacing.</title><p>(<bold>A</bold>) As spacing increases (from top to middle row) the response of small size center-surround filters increases (red and blue) whereas the response of large size center-surround filters decreases (green), with these effects counteracting each other in the total response. (<bold>B</bold>) As dot size increases (from top to middle row), more filters are involved in responding to the dots thereby increasing the unnormalized response (red and blue), but this results in a greater overlap in the neighborhoods and increases the normalization factor (yellow). These counteracting effects eliminate the size effect.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80990-fig4-v2.tif"/></fig><p>A key result from the current model is that the summed normalized output of the neuronal activity is sensitive to numerosity but shows little variation with size and spacing. This pattern is consistent with neural studies finding similar results for the summed response of <italic>V</italic>1, <italic>V</italic>2, and <italic>V</italic>3 in the absence of any behavioral judgment (<xref ref-type="bibr" rid="bib17">Fornaciai et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Fornaciai and Park, 2018</xref>; <xref ref-type="bibr" rid="bib38">Paul et al., 2022</xref>). However, this pattern is different than the behavior of prior deep neural network-based models of numerosity perception, which revealed many units in the deep layers that were sensitive to nonnumerical dimensions, along with a few that were numerosity sensitive (or selective). Although the few units that were sensitive to numerosity could explain behavior, the abundance of simulated neurons sensitive to nonnumerical dimensions is inconsistent with population-level neural activity, which fails to show sensitivity to these nonnumerical dimensions in early visual cortex (<xref ref-type="bibr" rid="bib14">DeWind et al., 2019</xref>; <xref ref-type="bibr" rid="bib36">Park, 2018</xref>; <xref ref-type="bibr" rid="bib45">Van Rinsveld et al., 2020</xref>). A key difference between the current model and previous computational models is the inclusion of divisive normalization in the center-surround convolution layer. Unlike prior models, this eliminated the effect of size in the early visual response, without requiring subsequent pooling layers (<xref ref-type="bibr" rid="bib9">Creatore et al., 2021</xref>; <xref ref-type="bibr" rid="bib27">Kim et al., 2021</xref>; <xref ref-type="bibr" rid="bib33">Nasr et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Stoianov and Zorzi, 2012</xref>; <xref ref-type="bibr" rid="bib42">Testolin et al., 2020</xref>) or a decision making process that compares high versus low spatial frequency responses (<xref ref-type="bibr" rid="bib10">Dakin et al., 2011</xref>).</p><p>At first blush, the current model might be considered an extension of <xref ref-type="bibr" rid="bib11">Dehaene and Changeux, 1993</xref>. However, there are four ways in which the current model differs qualitatively from the D&amp;C model. First, the D&amp;C model is one-dimensional, simulating a linear retina, whereas we model a two-dimensional retina feeding into center-surround filters, allowing application to the two-dimensional images used in numerosity experiments (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Second, extreme winner-take-all normalization in the convolution layer of the D&amp;C model implausibly limits visual precision by discretizing the visual response. For example, the convolution layer in the D&amp;C model only knows which of 9 possible sizes and 50 possible locations occurred. In contrast, by using divisive normalization in the current model, each dot produces activity at many locations and many filter sizes despite normalization, and a population could be used to determine exact location and size. Third, extreme winner-take-all normalization also eliminates all information other than dot size and location. By using divisive normalization, the current model represents other attributes such as edges and groupings of dots (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) and these other attributes provide a different explanation of numerosity sensitivity as compared to D&amp;C. For example, the D&amp;C model as applied to the spacing effect between two small dots (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) would represent the dots as existing discretely at two close locations versus two far locations, with the total summed response being two in either case. In contrast, the current model gives the same total response for a different reason. Although the small filters are less active for closely spaced dots, the closely spaced dots <italic>look like a group</italic> as captured by a larger filter, with this addition for the larger filter offsetting the loss for the smaller filter. Similarly, as applied to the dot size effect (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), the D&amp;C model would only represent the larger dots using larger filters. In contrast, the current model represents larger dots with larger filters and with smaller filters that capture the edges of the larger dots, and yet the summed response remains the same in each case owing to divisive normalization (again, there are offsetting factors across different filter sizes). The final difference is that the D&amp;C model does not include temporal normalization, which we show to be critical for explaining adaptation and context effects.</p><p>Finally, a recent fMRI study reported that neural activity in <italic>V</italic>1 increases monotonically with numerosity (<xref ref-type="bibr" rid="bib38">Paul et al., 2022</xref>), which is consistent with the current model at a surface level. The authors, however, concluded that this monotonic increase was better explained by aggregate Fourier power than by numerosity. This explanation is qualitatively different than the center-surround and divisive normalization explanation entailed in the current model. While further investigation may be necessary to distinguish these hypotheses, there are two caveats to consider in relation to the conclusions made by <xref ref-type="bibr" rid="bib38">Paul et al., 2022</xref>. First, Fourier power uses spatially unbounded sine waves that have little biological plausibility (unlike center-surround or Gabor filters, which are spatially limited). Second, more critically, the aggregate Fourier power metric used by <xref ref-type="bibr" rid="bib38">Paul et al., 2022</xref> aggregated only up through the first (or an <italic>n</italic>th) harmonic, but the value of the harmonic on the frequency spectrum is dictated by dot size and dot groupings. In other words, the Fourier metric required a priori knowledge about each image, and it is unclear how the visual system could know in advance an appropriate cutoff for a harmonic. Including all frequencies to compute the aggregate Fourier power would likely produce a different conclusion.</p><p>Our conclusions are primarily in terms of the qualitative effects of center-surround filtering and divisive normalization, which collectively produce sensitivity to numerosity. However, specific quantitative predictions will change depending on specific model assumptions. For instance, our simulations assumed a distribution of filter sizes that ranged from much smaller to much larger than the presented dots. The responses from filters small enough to capture edges of dots tend to offset the responses from filters large enough to capture local groups of dots, producing relative insensitivity to dot spacing and size (see <xref ref-type="fig" rid="fig4">Figure 4</xref>). However, there may be extreme cases where this balancing act breaks down. For instance, studies found that when dots are presented in the periphery where RF sizes are larger (<xref ref-type="bibr" rid="bib31">Li et al., 2021</xref>; <xref ref-type="bibr" rid="bib43">Valsecchi et al., 2013</xref>) or if the dots are crowded and hard to individuate (<xref ref-type="bibr" rid="bib3">Anobile et al., 2014</xref>), numerosity perception exhibits different behavioral characteristics. We simulated one extreme by submitting to the model images that contained very small dots (too small to allow edge responses) densely packed in a circular aperture. For this extreme, the summation of normalized responses was still primarily sensitive to number, but that sensitivity was smaller compared to our original simulation, and there was also some moderate sensitivity to size and spacing (<xref ref-type="fig" rid="fig2s3">Figure 2âfigure supplement 3</xref>). Our simulation also assumed an equal number of small and large center-surround filters although in reality there are likely fewer large filters. This assumption was made out of computational convenience, although we note that similar results would emerge with an unequal distribution of filters if the divisive normalization amplification factor scaled with filter size (e.g., if the larger number of small filters more strongly inhibited each other) or if the neighborhood size of divisive normalization scaled with filter size in a nonlinear manner. By investigating how these assumptions relate to behavior and physiology, future studies may provide additional mechanistic insights into magnitude perception in general.</p><p>The success of this model does not necessarily imply that neuronal responses in early visual regions directly determine behavioral responses (see <xref ref-type="bibr" rid="bib18">Fornaciai and Park, 2018</xref>). Prior to behavior, there are many downstream processing steps that incorporate other sources of information, such as response bias and decisional uncertainty. Instead, these results, together with previous electrophysiology results, suggest that normalized response magnitude in early visual regions may be the basic currency from which numerosity judgments are made. Future work should explore the link between the neuronal response layer in the current model and various behavioral judgments. For instance, if decisional uncertainty is modeled by assuming a constant level of decisional noise, regardless of the visual information, then the model will naturally produce Weberâs scaling law of just noticeable differences considering that the normalized response follows a log-linear pattern as a function of numerosity (see <xref ref-type="fig" rid="fig2">Figure 2C</xref>). More complex decisional assumptions could be introduced in an attempt to model the effects of task instructions that are known to bias decisions on magnitude judgment (<xref ref-type="bibr" rid="bib7">Castaldi et al., 2019</xref>; <xref ref-type="bibr" rid="bib8">Cicchini et al., 2016</xref>). More assumptions about top-down semantic influences may also explain recent coherence illusion results in orientation or color (<xref ref-type="bibr" rid="bib15">DeWind et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Qu et al., 2022</xref>), for instance, if observers are drawn to focus on a particular feature of the stimulus when comparing two dot arrays.</p><p>Another line of possible future work concerns divisive normalization in higher cortical levels involving neurons with more complex RFs. While the current normalization model with center-surround filters successfully explained visual illusions caused by regularity, grouping, and heterogeneity, other numerosity phenomena such as topological invariants and statistical pairing (<xref ref-type="bibr" rid="bib24">He et al., 2015</xref>; <xref ref-type="bibr" rid="bib46">Zhao and Yu, 2016</xref>) may require the action of neurons with RFs that are more complex than center-surround filters. For example, another well-known visual illusion is the effect of connectedness, whereby an array with dots connected pairwise with thin lines is underestimated (by up to 20%) compared to the same array without the lines connected (<xref ref-type="bibr" rid="bib20">Franconeri et al., 2009</xref>). This underestimation effect likely arises from barbell-shaped pairwise groupings of dots, rather than the circularly symmetric groupings of dots that are captured with center-surround filters. Nonetheless, a small magnitude (6%) connectedness illusion emerges with center-surround filters (<xref ref-type="fig" rid="fig3s7">Figure 3âfigure supplement 7</xref>). Augmenting the current model with a subsequent convolution layer containing oriented line filters and oriented normalization neighborhoods of different sizes might increase the predicted magnitude of the illusion.</p><p>In conclusion, our results indicate that divisive normalization in a single convolutional layer with hierarchically organized center-surround filters naturally enhances sensitivity to the discrete number of items in a visual scene by reducing the effects of size and spacing, consistent with recent empirical studies demonstrating direct and rapid encoding of numerosity (<xref ref-type="bibr" rid="bib35">Park et al., 2016</xref>). This account predicts that various well-known numerosity illusions across space and time arise naturally within the same neural responses that encode numerosity, rather than reflecting later stage processes. These results identify the key neurocomputational principles underlying the ubiquity of the number sense in the animal kingdom.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Stimulus sets</title><sec id="s4-1-1"><title>Dot arrays spanning across number, size, and spacing</title><p>Inputs to the neural network were visual stimuli of white dot arrays on a black background (200Ã200 pixels). Dots were homogeneous in size within an array and were drawn within an invisible circular field. Any two dots in an array were at least a diameter apart from edge to edge. The number of dots in an array is referred to as <italic>n</italic>, the radius of each dot is referred to as <italic>r<sub>d</sub></italic>, and the radius of the invisible circular field is referred to as <italic>r<sub>f</sub></italic>. <xref ref-type="table" rid="table1">Table 1</xref> provides mathematical definitions of other nonnumerical dimensions based on these terms.</p><p>Following the previously developed framework for systematic dot array construction (<xref ref-type="bibr" rid="bib13">DeWind et al., 2015</xref>; <xref ref-type="bibr" rid="bib35">Park et al., 2016</xref>), stimulus parameters of the dot arrays were distributed systematically within a parameter space defined by three orthogonal dimensions: log-scaled dimensions of number (<italic>N</italic>), size (<italic>Sz</italic>), and spacing (<italic>Sp</italic>) (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). <italic>N</italic> simply represents the number of dots. <italic>Sz</italic> is defined as the dimension that varies with individual area (<italic>IA</italic>) while holding <italic>N</italic> constant, hence simultaneously varying in total area (<italic>TA</italic>). <italic>Sp</italic> is defined as the dimension that varies with sparsity (<italic>Spar</italic>) while holding <italic>N</italic> constant, hence simultaneously varying in field area (<italic>FA</italic>). Log-scaling these dimensions allows <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> to be orthogonal to each other and represent all of the nonnumerical dimensions of interest to be represented as a linear combination of those three dimensions (see <xref ref-type="table" rid="table1">Table 1</xref>). Thus, this stimulus construction framework makes is easy to visualize the stimulus parameters and analyze choice behavior or neural data using a linear statistical model. For an implementation of this framework, see the MATLAB code published in the following public repository: <ext-link ext-link-type="uri" xlink:href="https://osf.io/s7xer/">https://osf.io/s7xer/</ext-link>.</p><p>Across all the dot arrays, number (<italic>n</italic>) ranged between 5 and 20 dots, dot diameter (2Ã<italic>r<sub>d</sub></italic>) ranged between 9 and 18 pixels, field radius (<italic>r<sub>f</sub></italic>) ranged between 45 and 90 pixels, all having five levels in logarithmic scale. log(<italic>N</italic>) ranged from 2.322 to 4.322 with the median of 3.322; log(<italic>Sz</italic>) ranged from 16.305 to 18.305 with the median of 17.305; log(<italic>Sp</italic>) ranged from 19.646 to 21.646 with the median of 20.646. This approach resulted in 35 unique points in the three-dimensional parameter space (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>). For each of the 35 unique points, a total of 100 dot arrays were randomly constructed for the simulation conducted in this study.</p></sec><sec id="s4-1-2"><title>Dot arrays for testing regularity effects</title><p>The âregularâ dot array was constructed following the previous study that first demonstrated the regularity effect (<xref ref-type="bibr" rid="bib23">Ginsburg, 1976</xref>). This array contained 37 dots with <italic>r<sub>d</sub></italic>=3 pixels, one of which at the center of the image and the rest distributed in three concentric circles with the radii of 20, 40, and 60 pixels. The âirregularâ arrays were constructed with the same number of and same sized dots randomly placed with <italic>r<sub>f</sub></italic>=72.5 pixels. This radius for the field area was empirically calculated so that the convex hull of the regular array and the mean convex hull of the irregular arrays were matched. Sixteen irregular arrays were used in the simulation.</p></sec><sec id="s4-1-3"><title>Dot arrays for testing grouping effects</title><p>One set of âungroupedâ dot arrays and another set of âgroupedâ dot arrays were constructed. Both ungrouped and grouped arrays contained 12 dots, each of which with <italic>r<sub>d</sub></italic>=4.5 pixels. However, in the ungrouped arrays the dots were randomly dispersed, while in the grouped arrays the dots were spatially grouped in pairs. The edge-to-edge distance between the two dots in each pair was approximately equal to <italic>r<sub>d</sub></italic>. A large number of unique dot arrays were constructed using these criteria for each of the two sets. Then, a subset of unique arrays from each set was chosen so that the convex hull of the arrays between the two sets were numerically matched. A total of 16 grouped and 16 ungrouped arrays entered the simulation.</p></sec><sec id="s4-1-4"><title>Dot arrays for testing heterogeneity effects</title><p>Three sets of dot arrays equated in the total area (<italic>TA</italic>) were created. The first set of âhomogeneousâ (or zero level of heterogeneity) dot arrays contained <italic>n</italic>=15 with <italic>r<sub>d</sub></italic>=5 pixels within a circular field defined by <italic>r<sub>f</sub></italic>=75 pixels. The second set of âless heterogeneousâ dot arrays contained six dots with <italic>r<sub>d</sub></italic>=3 pixels, six dots with <italic>r<sub>d</sub></italic>=5 pixels, and three dots with <italic>r<sub>d</sub></italic>=7.5 pixels. The last set of âmore heterogeneousâ dot arrays contained 12 dots with <italic>r<sub>d</sub></italic>=2.5 pixels and 3 dots with <italic>r<sub>d</sub></italic>=10 pixels. Hence, the total area (<italic>TA</italic>) of all the arrays were approximately identical to each other while the variability of individual area (<italic>IA</italic>) differed across the sets. Rounding errors due to pixelation and anti-aliasing, however, caused differences in the actual cumulative intensity measure of the bitmap images. On average, the cumulative intensity values (0 being black and 1 being white in the bitmap image) were comparable between the three sets of arrays: 1209 in the homogeneous arrays, 1194 in the less heterogeneous arrays, and 1204 in the more heterogeneous arrays. Sixteen arrays in each of the three sets entered the simulation.</p></sec></sec><sec id="s4-2"><title>Neural network model with divisive normalization</title><sec id="s4-2-1"><title>Convolution with DOG filters</title><p>The model consisted of a convolutional layer with DoG filters of six different sizes, that convolved input values of the aforementioned bitmap images displaying dot arrays. This architecture hence provided a structure for 200Ã200Ã6 network units (or simulated neurons) activated by images of dot arrays (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The DoG filters are formally defined as:<disp-formula id="equ1"> ,<label> (1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Î</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>â</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:msup><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>â</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>â</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>Ï</mml:mi><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>â</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <italic>I</italic> is the input image, Ï<sup>2</sup> is the spatial variance of the narrower Gaussian, and <italic>K</italic> is the scaling factor between the two variances. As recommended by <xref ref-type="bibr" rid="bib32">Marr and Hildreth, 1980</xref>, <italic>K</italic>=1.6 was used to achieve balanced bandwidth and sensitivity of the filters. Considering that the input values range [0 1], the DoG filters were reweighted so that the sum of the positive portion equals to 1 and the sum of the negative portion equals to â1, making the summation across all domains 0. This reweighting ensured that the response is maximized when the input matches the DoG filter regardless of filter size and that the filter produces a response of value 0 if the input is constant across a region regardless of filter size. Finally, the output of this convolution process was followed by half-wave rectification at each simulated neuron (<xref ref-type="bibr" rid="bib25">Heeger, 1991</xref>), where negative responses were replaced by zero. This stipulation sets the âfiring thresholdâ of the network such that the simulated neurons would not fire if the input does not match its DoG filter.</p><p>Six different Ï values were used (Ï<italic><sub>k</sub></italic>=1, 2, 4, 8, 16, and 32 for filter size <italic>k</italic>, respectively) which together were sensitive enough to represent various visual features of the input images, from the edge of the smallest dots to the overall landscape of the entire array. The activity of each stimulated neuron, <italic>i</italic>, in filter size <italic>k</italic> following this convolution procedure is referred to as <italic>D<sub>i,k</sub></italic>.</p></sec><sec id="s4-2-2"><title>Divisive normalization</title><p>Following <xref ref-type="bibr" rid="bib6">Carandini and Heeger, 2011</xref>, the normalization model was defined as:<disp-formula id="equ2"> ,<label> (2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>Î³</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:munder><mml:mo>â</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>Î·</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>Î³</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where distance similarity <italic>Î·</italic><sub>(<italic>i</italic>,<italic>j</italic>)</sub> is defined as:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>Î·</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>â</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p><italic>D</italic><sub><italic>i</italic></sub> is the driving input of neuron <italic>i</italic> (i.e., the output of the convolution procedure described above), <italic>d<sub>(i,j)</sub></italic> is the Euclidean distance between neuron <italic>i</italic> and neuron <italic>j</italic> in any filter size, <italic>c</italic> is a constant that prevents division by zero. The denominator minus this constant, which was set to 1, is referred to as the normalization factor. The parameter <italic>r<sub>k</sub></italic>, defined for each filter size, serves to scale between local and global normalization. As <italic>r<sub>k</sub></italic> gets larger, activities from broader set of neurons constitute the normalization factor. In our model, <italic>r<sub>k</sub></italic> was defined as a scaling factor of Ï<italic><sub>k</sub></italic> (e.g., <italic>r<sub>k</sub></italic>=Ï<italic><sub>k</sub></italic>, <italic>r<sub>k</sub></italic>=2Ï<italic><sub>k</sub></italic>, or <italic>r<sub>k</sub></italic>=4Ï<italic><sub>k</sub></italic>), so that neurons with larger filter sizes have their normalization factor computed from broader pool of neighboring neurons. The parameter Î³ determines the degree of amplification of individual inputs and serves to scale between winner-take-all and linear normalization. <italic>R<sub>i,k</sub></italic> represents the normalized response of neuron <italic>i</italic> in filter size <italic>k</italic>.</p></sec><sec id="s4-2-3"><title>Modeling temporal modulation of network units</title><p>Normalized responses of simulated neurons were further modeled to capture temporal modulations, with another normalization process this time working across time. First, a read-out neuron was assumed that summed up the normalized responses across all the neurons, Î£<italic>R<sub>i,k</sub></italic>. This single firing activity, now referred to as <italic>M</italic>, underwent the following temporal normalization process that resulted in the normalized activity <italic>M<sup>*</sup></italic>:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo>â</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>Î´</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>Î·</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>Î´</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>The temporal distance <italic>Î·</italic> is defined as:<disp-formula id="equ5"> ,<label> (5)</label><mml:math id="m5"><mml:mrow><mml:msub><mml:mi>Î·</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>â</mml:mo><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>Ï</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where <italic>d</italic> is the distance between time point <italic>t</italic> and <italic>T</italic>. As in <xref ref-type="disp-formula" rid="equ2 equ3">Equations 2 and 3</xref>, <italic>c</italic> is a constant that prevents division by zero, which was set to 1 for convenience. The parameter Ï determines the amount of recent history contributing to the normalization factor, and the parameter Î´ determines the degree of amplification of <italic>M<sub>t</sub></italic>.</p><p>The MATLAB code used to implement the model can be found in the following public repository: <ext-link ext-link-type="uri" xlink:href="https://osf.io/4rwjs/">https://osf.io/4rwjs/</ext-link>.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Funding acquisition, Methodology, Writing â original draft, Writing â review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Methodology, Writing â original draft, Writing â review and editing, Conceptualization</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-80990-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>No empirical datasets were generated during the current study. The source code for the computational model presented in this article are available in the following public repository: <ext-link ext-link-type="uri" xlink:href="https://osf.io/4rwjs/">https://osf.io/4rwjs/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>A divisive normalization model of numerosity perception</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/4rwjs/">4rwjs</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>The authors thank Dr. Michele Fornaciai for inspiring discussions. This study was supported by the National Science Foundation CAREER Award (BCS1654089) to JP and by the National Institute of Mental Health (RF1MH114277) to DEH.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aagten-Murphy</surname><given-names>D</given-names></name><name><surname>Burr</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Adaptation to numerosity requires only brief exposures, and is determined by number of events, not exposure duration</article-title><source>Journal of Vision</source><volume>16</volume><elocation-id>22</elocation-id><pub-id pub-id-type="doi">10.1167/16.10.22</pub-id><pub-id pub-id-type="pmid">27580042</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allik</surname><given-names>J</given-names></name><name><surname>Tuulmets</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Occupancy model of perceived numerosity</article-title><source>Perception &amp; Psychophysics</source><volume>49</volume><fpage>303</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.3758/bf03205986</pub-id><pub-id pub-id-type="pmid">2030927</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Separate mechanisms for perception of numerosity and density</article-title><source>Psychological Science</source><volume>25</volume><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1177/0956797613501520</pub-id><pub-id pub-id-type="pmid">24270462</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>AJ</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The âindependent componentsâ of natural scenes are edge filters</article-title><source>Vision Research</source><volume>37</volume><fpage>3327</fpage><lpage>3338</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(97)00121-1</pub-id><pub-id pub-id-type="pmid">9425547</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burr</surname><given-names>D</given-names></name><name><surname>Ross</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A visual sense of number</article-title><source>Current Biology</source><volume>18</volume><fpage>425</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.02.052</pub-id><pub-id pub-id-type="pmid">18342507</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Normalization as a canonical neural computation</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>51</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/nrn3136</pub-id><pub-id pub-id-type="pmid">22108672</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castaldi</surname><given-names>E</given-names></name><name><surname>Piazza</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Vignaud</surname><given-names>A</given-names></name><name><surname>Eger</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Attentional amplification of neural codes for number independent of other quantities along the dorsal visual stream</article-title><source>eLife</source><volume>8</volume><elocation-id>e45160</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.45160</pub-id><pub-id pub-id-type="pmid">31339490</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Anobile</surname><given-names>G</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spontaneous perception of numerosity in humans</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12536</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12536</pub-id><pub-id pub-id-type="pmid">27555562</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Creatore</surname><given-names>C</given-names></name><name><surname>Sabathiel</surname><given-names>S</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning exact enumeration and approximate estimation in deep neural network models</article-title><source>Cognition</source><volume>215</volume><elocation-id>104815</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2021.104815</pub-id><pub-id pub-id-type="pmid">34182145</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dakin</surname><given-names>SC</given-names></name><name><surname>Tibber</surname><given-names>MS</given-names></name><name><surname>Greenwood</surname><given-names>JA</given-names></name><name><surname>Kingdom</surname><given-names>FAA</given-names></name><name><surname>Morgan</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A common visual metric for approximate number and density</article-title><source>PNAS</source><volume>108</volume><fpage>19552</fpage><lpage>19557</lpage><pub-id pub-id-type="doi">10.1073/pnas.1113195108</pub-id><pub-id pub-id-type="pmid">22106276</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Changeux</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Development of elementary numerical abilities: a neuronal model</article-title><source>Journal of Cognitive Neuroscience</source><volume>5</volume><fpage>390</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.1162/jocn.1993.5.4.390</pub-id><pub-id pub-id-type="pmid">23964915</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>The Number Sense: How the Mind Creates Mathematics</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeWind</surname><given-names>NK</given-names></name><name><surname>Adams</surname><given-names>GK</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Modeling the approximate number system to quantify the contribution of visual stimulus features</article-title><source>Cognition</source><volume>142</volume><fpage>247</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2015.05.016</pub-id><pub-id pub-id-type="pmid">26056747</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeWind</surname><given-names>NK</given-names></name><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Woldorff</surname><given-names>MG</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Numerical encoding in early visual cortex</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>114</volume><fpage>76</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2018.03.027</pub-id><pub-id pub-id-type="pmid">29983159</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeWind</surname><given-names>NK</given-names></name><name><surname>Bonner</surname><given-names>MF</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Similarly oriented objects appear more numerous</article-title><source>Journal of Vision</source><volume>20</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/jov.20.4.4</pub-id><pub-id pub-id-type="pmid">32271896</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feigenson</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Spelke</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Core systems of number</article-title><source>Trends in Cognitive Sciences</source><volume>8</volume><fpage>307</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.05.002</pub-id><pub-id pub-id-type="pmid">15242690</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name><name><surname>Woldorff</surname><given-names>MG</given-names></name><name><surname>Park</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Numerosity processing in early visual cortex</article-title><source>NeuroImage</source><volume>157</volume><fpage>429</fpage><lpage>438</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.05.069</pub-id><pub-id pub-id-type="pmid">28583882</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Park</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Early numerosity encoding in visual cortex is not sufficient for the representation of numerical magnitude</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>1788</fpage><lpage>1802</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01320</pub-id><pub-id pub-id-type="pmid">30063175</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fornaciai</surname><given-names>M</given-names></name><name><surname>Park</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Disentangling feedforward versus feedback processing in numerosity representation</article-title><source>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</source><volume>135</volume><fpage>255</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2020.11.013</pub-id><pub-id pub-id-type="pmid">33412370</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franconeri</surname><given-names>SL</given-names></name><name><surname>Bemis</surname><given-names>DK</given-names></name><name><surname>Alvarez</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Number estimation relies on a set of segmented objects</article-title><source>Cognition</source><volume>113</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2009.07.002</pub-id><pub-id pub-id-type="pmid">19647817</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frith</surname><given-names>CD</given-names></name><name><surname>Frit</surname><given-names>U</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>The solitaire illusion: an illusion of numerosity</article-title><source>Perception &amp; Psychophysics</source><volume>11</volume><fpage>409</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.3758/BF03206279</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gebuis</surname><given-names>T</given-names></name><name><surname>Cohen Kadosh</surname><given-names>R</given-names></name><name><surname>Gevers</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sensory-integration system rather than approximate number system underlies numerosity processing: a critical review</article-title><source>Acta Psychologica</source><volume>171</volume><fpage>17</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/j.actpsy.2016.09.003</pub-id><pub-id pub-id-type="pmid">27640140</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ginsburg</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Effect of item arrangement on perceived numerosity: randomness vs regularity</article-title><source>Perceptual and Motor Skills</source><volume>43</volume><fpage>663</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.2466/pms.1976.43.2.663</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>L</given-names></name><name><surname>Zhou</surname><given-names>K</given-names></name><name><surname>Zhou</surname><given-names>T</given-names></name><name><surname>He</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Topology-defined units in numerosity perception</article-title><source>PNAS</source><volume>112</volume><fpage>E5647</fpage><lpage>E5655</lpage><pub-id pub-id-type="doi">10.1073/pnas.1512408112</pub-id><pub-id pub-id-type="pmid">26417075</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1991">1991</year><chapter-title>Nonlinear model of neural responses in cat visual cortex</chapter-title><person-group person-group-type="editor"><name><surname>Landy</surname><given-names>MS</given-names></name><name><surname>Movshon</surname><given-names>J</given-names></name></person-group><source>Computational Models of Visual Processing</source><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT Press</publisher-name><fpage>119</fpage><lpage>133</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huber</surname><given-names>DE</given-names></name><name><surname>OâReilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Persistence and accommodation in short-term priming and other perceptual paradigms: temporal segregation through synaptic depression</article-title><source>Cognitive Science</source><volume>27</volume><fpage>403</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog2703_4</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>G</given-names></name><name><surname>Jang</surname><given-names>J</given-names></name><name><surname>Baek</surname><given-names>S</given-names></name><name><surname>Song</surname><given-names>M</given-names></name><name><surname>Paik</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Visual number sense in untrained deep neural networks</article-title><source>Science Advances</source><volume>7</volume><elocation-id>eabd6127</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abd6127</pub-id><pub-id pub-id-type="pmid">33523851</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>ImageNet classification with deep convolutional neural networks</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>1106</fpage><lpage>1114</lpage></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Baek</surname><given-names>J</given-names></name><name><surname>Chong</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Perceived magnitude of visual displays: area, numerosity, and mean size</article-title><source>Journal of Vision</source><volume>16</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.1167/16.3.12</pub-id><pub-id pub-id-type="pmid">26873776</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leibovich</surname><given-names>T</given-names></name><name><surname>Katzin</surname><given-names>N</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Henik</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>From âsense of numberâ to âsense of magnitudeâ: the role of continuous magnitudes in numerical cognition</article-title><source>The Behavioral and Brain Sciences</source><volume>40</volume><elocation-id>e164</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X16000960</pub-id><pub-id pub-id-type="pmid">27530053</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>MS</given-names></name><name><surname>Abbatecola</surname><given-names>C</given-names></name><name><surname>Petro</surname><given-names>LS</given-names></name><name><surname>Muckli</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Numerosity perception in peripheral vision</article-title><source>Frontiers in Human Neuroscience</source><volume>15</volume><elocation-id>750417</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2021.750417</pub-id><pub-id pub-id-type="pmid">34803635</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name><name><surname>Hildreth</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Theory of edge detection</article-title><source>Proceedings of the Royal Society of London. Series B, Biological Sciences</source><volume>207</volume><fpage>187</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1098/rspb.1980.0020</pub-id><pub-id pub-id-type="pmid">6102765</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nasr</surname><given-names>K</given-names></name><name><surname>Viswanathan</surname><given-names>P</given-names></name><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Number detectors spontaneously emerge in a deep neural network designed for visual object recognition</article-title><source>Science Advances</source><volume>5</volume><elocation-id>eaav7903</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aav7903</pub-id><pub-id pub-id-type="pmid">31086820</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieder</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The neuronal code for number</article-title><source>Nature Reviews. Neuroscience</source><volume>17</volume><fpage>366</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.40</pub-id><pub-id pub-id-type="pmid">27150407</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J</given-names></name><name><surname>DeWind</surname><given-names>NK</given-names></name><name><surname>Woldorff</surname><given-names>MG</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rapid and direct encoding of numerosity in the visual stream</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>748</fpage><lpage>763</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv017</pub-id><pub-id pub-id-type="pmid">25715283</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A neural basis for the visual sense of number and its development: A steady-state visual evoked potential study in children and adults</article-title><source>Developmental Cognitive Neuroscience</source><volume>30</volume><fpage>333</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2017.02.011</pub-id><pub-id pub-id-type="pmid">28342780</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Godbole</surname><given-names>S</given-names></name><name><surname>Woldorff</surname><given-names>MG</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Context-dependent modulation of early visual cortical responses to numerical and nonnumerical magnitudes</article-title><source>Journal of Cognitive Neuroscience</source><volume>33</volume><fpage>2536</fpage><lpage>2547</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01774</pub-id><pub-id pub-id-type="pmid">34407187</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paul</surname><given-names>JM</given-names></name><name><surname>van Ackooij</surname><given-names>M</given-names></name><name><surname>Ten Cate</surname><given-names>TC</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Numerosity tuning in human association cortices and local image contrast representations in early visual cortex</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>1340</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-29030-z</pub-id><pub-id pub-id-type="pmid">35292648</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qu</surname><given-names>C</given-names></name><name><surname>DeWind</surname><given-names>NK</given-names></name><name><surname>Brannon</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Increasing entropy reduces perceived numerosity throughout the lifespan</article-title><source>Cognition</source><volume>225</volume><elocation-id>105096</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2022.105096</pub-id><pub-id pub-id-type="pmid">35316670</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Scherer</surname><given-names>D</given-names></name><name><surname>MÃ¼ller</surname><given-names>A</given-names></name><name><surname>Behnke</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition</article-title><conf-name>International Conference on Artificial Neural Networks</conf-name><fpage>92</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-15825-4</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stoianov</surname><given-names>I</given-names></name><name><surname>Zorzi</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Emergence of a âvisual number senseâ in hierarchical generative models</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>194</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1038/nn.2996</pub-id><pub-id pub-id-type="pmid">22231428</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Testolin</surname><given-names>A</given-names></name><name><surname>Zou</surname><given-names>WY</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Numerosity discrimination in deep neural networks: initial competence, developmental refinement and experience statistics</article-title><source>Developmental Science</source><volume>23</volume><elocation-id>e12940</elocation-id><pub-id pub-id-type="doi">10.1111/desc.12940</pub-id><pub-id pub-id-type="pmid">31977137</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valsecchi</surname><given-names>M</given-names></name><name><surname>Toscani</surname><given-names>M</given-names></name><name><surname>Gegenfurtner</surname><given-names>KR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Perceived numerosity is reduced in peripheral vision</article-title><source>Journal of Vision</source><volume>13</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/13.13.7</pub-id><pub-id pub-id-type="pmid">24198398</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Oeffelen</surname><given-names>MP</given-names></name><name><surname>Vos</surname><given-names>PG</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Configurational effects on the enumeration of dots: counting by groups</article-title><source>Memory &amp; Cognition</source><volume>10</volume><fpage>396</fpage><lpage>404</lpage><pub-id pub-id-type="doi">10.3758/bf03202432</pub-id><pub-id pub-id-type="pmid">7132717</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Rinsveld</surname><given-names>A</given-names></name><name><surname>Guillaume</surname><given-names>M</given-names></name><name><surname>Kohler</surname><given-names>PJ</given-names></name><name><surname>Schiltz</surname><given-names>C</given-names></name><name><surname>Gevers</surname><given-names>W</given-names></name><name><surname>Content</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The neural signature of numerosity by separating numerical and continuous magnitude extraction in visual cortex with frequency-tagged EEG</article-title><source>PNAS</source><volume>117</volume><fpage>5726</fpage><lpage>5732</lpage><pub-id pub-id-type="doi">10.1073/pnas.1917849117</pub-id><pub-id pub-id-type="pmid">32123113</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>RQ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistical regularities reduce perceived numerosity</article-title><source>Cognition</source><volume>146</volume><fpage>217</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2015.09.018</pub-id><pub-id pub-id-type="pmid">26451701</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80990.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Serences</surname><given-names>John T</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0168r3w48</institution-id><institution>University of California, San Diego</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.06.01.494401" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.06.01.494401"/></front-stub><body><p>The current manuscript presents a computational model of numerosity estimation. The model relies on center-surround contrast filters at different spatial scales with divisive normalization between their responses. Using dot arrays as visual stimuli, the summed normalized responses of the filters are sensitive to numerosity and insensitive to the low-level visual features of dot size and spacing. Importantly, the model provides an explanation of various spatial and temporal illusions in visual numerosity perception.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80990.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Serences</surname><given-names>John T</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0168r3w48</institution-id><institution>University of California, San Diego</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Burr</surname><given-names>David Charles</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04jr1s763</institution-id><institution>University of Florence</institution></institution-wrap><country>Italy</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.06.01.494401">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.06.01.494401v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Neurocomputational principles underlying the number sense&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: David Charles Burr (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>There was general enthusiasm for the topic. However, we all agreed that the paper lacked a clear differentiation from earlier work by Dehaene and Changeux (1993). Those authors used a slightly different architecture, but there are many similarities and the present paper did not clearly articulate what novel insights/predictions the current model brings to the table. The authors will need to clarify these novel insights â to the extent possible â and will likely need to make some direct comparisons between the current model and older models. If the authors opt to revise and resubmit, the paper will be sent back to the original two reviewers to evaluate in the context of older work.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>1. &quot;As applied to early vision, this strong winner-take-all mechanism is implausible, as the model would suggest that visual cortex only knows that dots exist, without knowing the size or the location of the dots&quot; (page 3; 3rd paragraph) - this is not true. In the Dehaene and Changeux model, the lateral inhibition in the DoG layer does implement a strong winner-take-all mechanism, however, the size and locations of the dots are still encoded in its output. The locations are topographically encoded, and the locus of activity within the DoG layer encodes (i.e., which filters are activated) encodes dot size. Therefore, the model does not imply that the visual cortex is agnostic to dot size and location. Subsequent stages of the model are indeed primarily concerned with numerosity and not affected by dot size or location, just as is the case for the model in the current manuscript.</p><p>2. &quot;Critically, unlike connections between layers, such as with the pooling layers of AlexNet, divisive normalization occurs within a layer (e.g., between center-surround units) through recurrent activation&quot; (page 4; 2nd paragraph) - AlexNet also uses a very similar form of divisive normalization within the convolutional layers (local response normalization). This form of divisive normalization has also been used before in a number of models.</p><p>3. The findings in Fig. 3 and Fig. S3 concerning the changes in the model response under different conditions should be backed by appropriate statistical tests.</p><p>4. Using the term &quot;driving input&quot; to refer to the rectified output of the convolutional layer is somewhat confusing. Perhaps it would be clearer to use the term &quot;unnormalized response&quot; or something similar.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I would very much like to see this published and make a few suggestions.</p><p>I would drop the paragraph about Paul et al. It is misleading, and not very relevant (as you indeed point out).</p><p>They cite the fact that numerosity modulates the pupil response as an example of low-level interaction. I think this is misleading. Although the pupil response is indeed a very basic reflex, it is modulated by high-level processes. It does not imply early computation of numerosity. I think the Collins reference is equally shakey.</p><p>Also, it would be useful to test the extremes of a model. For example, we know at very high densities that the rules of numerosity estimation change: what happens to the model there?</p><p>Finally, abbreviations should be defined: Sz, Sp, and N are not defined until methods, which makes the text difficult to follow. These should be defined on first use, and probably also in the caption to figure 2.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80990.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>There was general enthusiasm for the topic. However, we all agreed that the paper lacked a clear differentiation from earlier work by Dehaene and Changeux (1993). Those authors used a slightly different architecture, but there are many similarities and the present paper did not clearly articulate what novel insights/predictions the current model brings to the table. The authors will need to clarify these novel insights â to the extent possible â and will likely need to make some direct comparisons between the current model and older models. If the authors opt to revise and resubmit, the paper will be sent back to the original two reviewers to evaluate in the context of older work.</p></disp-quote><p>Thanks for the positive appraisal of our paper. We appreciate the reviewers and the editors for constructive feedback. We believe our response, with new analyses and revised text, addresses all the concerns raised</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>1. &quot;As applied to early vision, this strong winner-take-all mechanism is implausible, as the model would suggest that visual cortex only knows that dots exist, without knowing the size or the location of the dots&quot; (page 3; 3rd paragraph) - this is not true. In the Dehaene and Changeux model, the lateral inhibition in the DoG layer does implement a strong winner-take-all mechanism, however, the size and locations of the dots are still encoded in its output. The locations are topographically encoded, and the locus of activity within the DoG layer encodes (i.e., which filters are activated) encodes dot size. Therefore, the model does not imply that the visual cortex is agnostic to dot size and location. Subsequent stages of the model are indeed primarily concerned with numerosity and not affected by dot size or location, just as is the case for the model in the current manuscript.</p></disp-quote><p>Thank you for pointing out this important issue, which we addressed in the revisions listed above. We were incorrect in stating that the D&amp;C model does not know location or size. Instead, it only knows these properties in a discrete imprecise manner, and it has no information about other attributes such as edges or groupings of dots, which play an important role in the current modelâs explanation of numerosity. The quoted text has been removed and the revised paragraph appears in full above.</p><disp-quote content-type="editor-comment"><p>2. &quot;Critically, unlike connections between layers, such as with the pooling layers of AlexNet, divisive normalization occurs within a layer (e.g., between center-surround units) through recurrent activation&quot; (page 4; 2nd paragraph) - AlexNet also uses a very similar form of divisive normalization within the convolutional layers (local response normalization). This form of divisive normalization has also been used before in a number of models.</p></disp-quote><p>This is a good point and weâve used it to revise the manuscript to make clear the distinction between within-layer normalization (as in this model and as in some aspects of AlexNet) versus between-layer normalization (as in the max pooling layers that are often used in CNNs). These two kinds of normalization/pooling are functionally similar, but make different predictions as to where normalization occurs, and about the strength of normalization. More specifically, âdivisive normalizationâ predicts that sensitivity to number will occur in early visual processing (i.e., within layer) and will be of a moderate strength. The critical paragraph in the introduction now reads:</p><p>âRather than applying a complex multilayer learning model, we distill the neurocomputational principles that enable the visual system to be sensitive to numerosity while remaining relatively insensitive to non-numerical visual features. [â¦] A wealth of evidence indicates that divisive normalization is ubiquitous across species and brain systems and hence thought to be a fundamental computation of many neural circuits. Thus, any theory of numerosity perception would be remiss not to include the effect of within-layer divisive normalization.â</p><disp-quote content-type="editor-comment"><p>3. The findings in Fig. 3 and Fig. S3 concerning the changes in the model response under different conditions should be backed by appropriate statistical tests.</p></disp-quote><p>We believe what the reviewer is asking is whether we've run the model on a sufficient number of different images as to know that our simulation results are not some artifact of specific images. This is a legitimate question. However, we do not believe providing inferential test statistics is useful here because, in such simulations, the statistical significance can always be reached by generating more images to test (provided that there is in fact a real effect that generally occurs for most simulations). The question asked with an inferential test of behavior might be whether the results generalize to a larger population of subjects. With a simulation it would be whether the results generalize to additional not-yet-run simulations, although in this case this is easily achieved by simply running more simulations (with enough simulations, the entire population is sampled and there is no need for inferential statistics). Thus, perhaps a better way to quantify and compare the size of the effects across different conditions is to use an effect size measure, such as Cohenâs d, which tells us how many standard deviations lie between the two means of interest. In addition to the magnitude of the effects (e.g., 5.87% reduction) we reported in the original manuscript, we now report the effect size (e.g., d = 8.11) of all the major comparisons we make in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>4. Using the term &quot;driving input&quot; to refer to the rectified output of the convolutional layer is somewhat confusing. Perhaps it would be clearer to use the term &quot;unnormalized response&quot; or something similar.</p></disp-quote><p>We agree that this is somewhat confusing, but this is the terminology adopted by Carandini &amp; Heeger (2012), and it is commonly used in the literature. Therefore, we are worried that using different terminology might be even more confusing.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>I would very much like to see this published and make a few suggestions.</p><p>I would drop the paragraph about Paul et al. It is misleading, and not very relevant (as you indeed point out).</p></disp-quote><p>We understand the reviewerâs motivation for this suggestion; discussion of Paul et al., (2022) could be seen as a distraction. However, when we shared drafts of the manuscript with colleagues, we faced pushback and criticism for failing to explain how the current model goes beyond or is different from previous computational models and proposals regarding the basis of numerosity perception in early vision. This is also evident from reviewer #1âs request for more information about how the current model differs from the model of Dehaene and Changeux (1993). After addressing reviewer 1âs comments, the revised manuscript now contains three paragraphs in Discussion (p. 11-12) that provide detailed explanations for how the current model differs from previous well-known models of numerosity perception and discussion of Paul et al., no longer seems like a distraction within the context of this comparison to other models. We felt it important to retain the discussion of Paul et al., because we also received request of comparison to that study. More specifically, we were asked what makes our proposal a reasonable model when one of the most recent findings indicates that response in early visual processing reflects spatial frequency analysis, not numerosity (Paul et al., 2022). We suspect that readers of our study will ask the same question and so we would like to retain some version of this paragraph to address this issue.</p><p>If the reviewer and editor still think that this paragraph is irrelevant, we would be happy to take specific recommendations to achieve our goal in other ways (i.e., other ways to differentiate our work from previous models, including the âspatial frequencyâ model proposed in Paul et al.).</p><disp-quote content-type="editor-comment"><p>They cite the fact that numerosity modulates the pupil response as an example of low-level interaction. I think this is misleading. Although the pupil response is indeed a very basic reflex, it is modulated by high-level processes. It does not imply early computation of numerosity. I think the Collins reference is equally shakey.</p></disp-quote><p>We agree that this was somewhat misleading/inaccurate and we have removed this part in the discussion.</p><disp-quote content-type="editor-comment"><p>Also, it would be useful to test the extremes of a model. For example, we know at very high densities that the rules of numerosity estimation change: what happens to the model there?</p></disp-quote><p>This is a good question. We now report this simulation in Figure S9, as mentioned in the discussion with the following text:</p><p>âFor instance, our simulations assumed a distribution of filter sizes that ranged from much smaller to much larger than the presented dots. The responses from filters small enough to capture edges of dots tends to offset the responses from filters large enough to capture local groups of dots, producing relative insensitivity to dot spacing and size (see Figure 4). However, there may be extreme cases where this balancing act breaks down. For instance, studies found that when dots are presented in the periphery where receptive field sizes are larger (Li et al., 2021; Valsecchi et al., 2013) or if the dots are crowded and hard to individuate (Anobile et al., 2014), numerosity perception exhibits different behavioral characteristics. We simulated one extreme by submitting to the model images that contained very small dots (too small to allow edge responses) densely packed in a circular aperture. For this extreme, the summation of normalized responses was still primarily sensitive to number, but that sensitivity was smaller compared to our original simulation, and there was also some moderate sensitivity to size and spacing (Figure S9).â</p><p>In order to compare the effects of <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> from large numerosities (N = 90 to 360) with the same effects from the original images (N = 5 to 20), regression slope adjusted by the baseline (i.e., slope divided by the intercept from linear regression) was computed. This adjusted slope allows comparison of relative change across the two different sets of images. The caption to Figure S9 reads:</p><p>âFigure S9. Simulation results from images of densely packed dot arrays with extremely high numerosity. (A) The dots arrays were systematically constructed ranging equally across the dimensions of <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic>, which was achieved by using the following parameters: number (<italic>n</italic>) = from 90 to 360, dot radius (<italic>r<sub>d</sub></italic>) = from 1 to 2 pixels, field radius (<italic>r<sub>f</sub></italic>) = from 45 to 90 pixels. For each point in the 2Ã2Ã2 parameters space, 16 unique arrays were created. (B) Examples of dot array images are shown. These images were submitted to the current computational model with the same parameters used in our original analysis (r = 2Ï and Î³ = 2). (C) Summed driving input (Î£D) was modulated primarily by <italic>N</italic> and <italic>Sz</italic>. Summed normalized response (Î£R) was most modulated by <italic>N</italic> but also by <italic>Sz</italic> and <italic>Sp</italic> to some degree. The slope of the linear fit to <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> adjusted by the baseline (the slope estimate divided by the intercept estimate in the simple regression) was 0.4086, 0.1958, and 0.1488, respectively. Note that this adjusted slope allows comparison of relative change in the response driven by <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic>, despite differences in the overall activity across different sets of images. In our original simulation, the adjusted slopes for <italic>N</italic>, <italic>Sz</italic>, and <italic>Sp</italic> were 0.5771, 0.0646, and 0.0321, respectively. Thus, the same computational network when representing much more densely packed dot arrays seems to show relatively decreased sensitivity to numerosity. These results indicate that neural sensitivity to various magnitude dimensions and the degree of that sensitivity differ based on the assumptions about the distribution of filters and filter sizes.â</p><disp-quote content-type="editor-comment"><p>Finally, abbreviations should be defined: Sz, Sp, and N are not defined until methods, which makes the text difficult to follow. These should be defined on first use, and probably also in the caption to figure 2.</p></disp-quote><p>Done. Thanks for the suggestion.</p></body></sub-article></article>