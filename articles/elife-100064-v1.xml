<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">100064</article-id><article-id pub-id-type="doi">10.7554/eLife.100064</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100064.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural geometry from mixed sensorimotor selectivity for predictive sensorimotor control</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Zhang</surname><given-names>Yiheng</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5370-1316</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Chen</surname><given-names>Yun</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0817-2160</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Tianwei</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5192-5594</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Cui</surname><given-names>He</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6277-9804</contrib-id><email>hecui@cibr.ac.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00vpwhm04</institution-id><institution>Center for Excellence in Brain Science and Intelligence Technology, Institute of Neuroscience, Chinese Academy of Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/029819q61</institution-id><institution>Chinese Institute for Brain Research</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qbk4x57</institution-id><institution>University of Chinese Academy of Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Makin</surname><given-names>Tamar R</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>01</day><month>05</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP100064</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-06-18"><day>18</day><month>06</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-06-07"><day>07</day><month>06</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.06.535795"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-08-07"><day>07</day><month>08</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100064.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-04-15"><day>15</day><month>04</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100064.2"/></event></pub-history><permissions><copyright-statement>© 2024, Zhang, Chen et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Zhang, Chen et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-100064-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-100064-figures-v1.pdf"/><abstract><p>Although recent studies suggest that activity in the motor cortex, in addition to generating motor outputs, receives substantial information regarding sensory inputs, it is still unclear how sensory context adjusts the motor commands. Here, we recorded population neural activity in the motor cortex via microelectrode arrays while monkeys performed flexible manual interceptions of moving targets. During this task, which requires predictive sensorimotor control, the activity of most neurons in the motor cortex encoding upcoming movements was influenced by ongoing target motion. Single-trial neural states at the movement onset formed staggered orbital geometries, suggesting that target motion modulates peri-movement activity in an orthogonal manner. This neural geometry was further evaluated with a representational model and recurrent neural networks (RNNs) with task-specific input-output mapping. We propose that the sensorimotor dynamics can be derived from neuronal mixed sensorimotor selectivity and dynamic interaction between modulations.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural coding</kwd><kwd>manual interception</kwd><kwd>multi-channel recording</kwd><kwd>monkey</kwd><kwd>reach</kwd><kwd>neural dynamics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012166</institution-id><institution>National Key Research and Development Program of China</institution></institution-wrap></funding-source><award-id>2020YFB1313400</award-id><principal-award-recipient><name><surname>Cui</surname><given-names>He</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012166</institution-id><institution>National Key Research and Development Program of China</institution></institution-wrap></funding-source><award-id>2017YFA0701102</award-id><principal-award-recipient><name><surname>Cui</surname><given-names>He</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31871047</award-id><principal-award-recipient><name><surname>Cui</surname><given-names>He</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31671075</award-id><principal-award-recipient><name><surname>Cui</surname><given-names>He</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002367</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap></funding-source><award-id>Strategic Priority Research Program of Chinese Academy of Sciences XDB32040103</award-id><principal-award-recipient><name><surname>Cui</surname><given-names>He</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Target motion modulates monkey M1 neural dynamics during reaching, characterized by an orbital neural geometry composed of target-velocity-dependent tilting rings, suggesting that sensory information can be independently incorporated during motor generation.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The motor cortex, a central brain region generating motor commands, is widely known for its relation to movement kinetics (<xref ref-type="bibr" rid="bib20">Evarts, 1968</xref>; <xref ref-type="bibr" rid="bib28">Kalaska et al., 1989</xref>) and kinematics (<xref ref-type="bibr" rid="bib21">Georgopoulos et al., 1982</xref>; <xref ref-type="bibr" rid="bib72">Wang et al., 2022</xref>). More than this, the motor cortex also carries substantial sensory information and is significantly involved in a variety of sensorimotor processes. Many studies have reported that the motor cortex reveals early visuomotor responses for action selection (<xref ref-type="bibr" rid="bib16">Cisek and Kalaska, 2005</xref>; <xref ref-type="bibr" rid="bib71">Wang et al., 2019</xref>) and motor planning (<xref ref-type="bibr" rid="bib23">Hatsopoulos and Amit, 2012</xref>; <xref ref-type="bibr" rid="bib50">Pesaran et al., 2006</xref>; <xref ref-type="bibr" rid="bib56">Rao and Donoghue, 2014</xref>), anticipative activity for complex rules and sequences (<xref ref-type="bibr" rid="bib38">Lu and Ashe, 2005</xref>; <xref ref-type="bibr" rid="bib73">Wang et al., 2024</xref>; <xref ref-type="bibr" rid="bib74">Zimnik and Churchland, 2021</xref>), as well as fast closed-loop modulation for somatosensory and visual feedback control (<xref ref-type="bibr" rid="bib47">Omrani et al., 2016</xref>; <xref ref-type="bibr" rid="bib64">Sobinov and Bensmaia, 2021</xref>; <xref ref-type="bibr" rid="bib65">Stavisky et al., 2017</xref>; <xref ref-type="bibr" rid="bib68">Suway and Schwartz, 2019</xref>; <xref ref-type="bibr" rid="bib69">Tkach et al., 2007</xref>). However, it is still unclear how moving targets requiring forward control affect peri-movement activity in the motor cortex.</p><p>Nowadays, the dynamical systems perspective provides a population view to interpret mixed coding for task variables and rules (<xref ref-type="bibr" rid="bib40">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Rigotti et al., 2013</xref>). With respect to motor control, the preparatory population activity not only sets initial states to seed the motor generation (<xref ref-type="bibr" rid="bib14">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib15">Churchland and Shenoy, 2024</xref>; <xref ref-type="bibr" rid="bib70">Vyas et al., 2020</xref>), but also presumably contains redundant information – that should be ‘held’ rather than ‘released’ to trigger muscles – in an output-null space (<xref ref-type="bibr" rid="bib30">Kaufman et al., 2014</xref>). Therefore, we hypothesize that the potential sensory modulation, which results from target motion and does not intervene the motor output, functions in orthogonal dimensions of output-potent neural states.</p><p>To investigate the mixed selectivity and neural dynamics shaped by concurrent sensorimotor signals, we recorded population activity in the primary motor cortex (M1) from monkeys performing a flexible manual interception task. Unlike previous studies constraining interception at a fixed location (<xref ref-type="bibr" rid="bib43">Merchant et al., 2004a</xref>; <xref ref-type="bibr" rid="bib44">Merchant et al., 2004b</xref>), our task demands predictive spatiotemporal mappings to displace a body effector to a trial-varying location. We found that the activity of most neurons was jointly tuned to both reach direction and target motion via directional selectivity shifts, gain modulations, offset adjustments, or their combinations. Strikingly, such mixed sensorimotor selectivity exists throughout the entire trial, in contrast to the gradient of sensory-to-motor tuning from cue to movement epochs in posterior parietal cortex (PPC) that we recently reported (<xref ref-type="bibr" rid="bib37">Li et al., 2022</xref>; <xref ref-type="bibr" rid="bib36">Li et al., 2018</xref>). Principal component analysis (PCA) on the neural population revealed a clear orbital neural geometry in low-dimensional space at the movement onset: The neural states were distributed in reach-direction order and formed ring-like structures whose slopes were determined by target-motion conditions. This target-motion effect is maintained independently of hand speed. Neuronal simulation indicates that these characteristics of neural population dynamics could be derived from the mixed sensorimotor selectivity of single neurons. Recurrent neural networks (RNNs) trained with proper input-output mappings offer insights into the relationship between neuronal modulation and neural geometry in a dynamical system. We propose that this sensory modulation occurs at both single-neuron and population levels as a general element of neural computations for predictive sensorimotor control.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Mixed tuning of M1 single neurons during flexible manual interception task</title><p>Three monkeys (<italic>Macaca mulatta,</italic> C, G, and D, male, weight 7–10 kg) were trained to perform a delayed manual interception task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), which was modified from the task utilized in our recent studies (<xref ref-type="bibr" rid="bib37">Li et al., 2022</xref>; <xref ref-type="bibr" rid="bib36">Li et al., 2018</xref>). To initiate a trial, the monkey needed to hold the center dot of a standing touch screen for 600 ms. Then, a peripheral target appeared, either stationary or rotating around the center dot at a constant angular velocity. The monkey was required to wait during a randomized delay (400–800 ms) until the central dot turned dark (GO signal) and then to immediately reach to the target. Once the monkey touched the screen (Touch) again, the target stopped and another dot showed the touched location, in red for a successful interception or in blue for a failure. The error tolerance between the target and the touched location (reach endpoint) was 3 cm. There were five target-motion conditions, consisting of clockwise (CW) conditions - 240 °/s and –120 °/s, counterclockwise (CCW) conditions 120 °/s and 240 °/s, along with 0 °/s (static) condition. We define the magnitude and direction of the target’s velocity as TV<sub>mag</sub> (e.g. 0 °/s, 120 °/s, and 240 °/s) and TV<sub>dir</sub> (namely CCW and CW), respectively. These target-motion conditions were interleaved trial by trial, and the initial location of the target was random. The reach endpoints of a well-trained monkey distributed uniformly around the circle (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, Rayleigh’s test: p=0.36; data from monkey C, 772 correct trials in one session). Because the reach direction was defined as the angle of the reach endpoint, for simplicity, we divided the circular space equally into eight sectors (45° per each) and grouped trials according to the eight reach directions and five target-motion conditions.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The flexible manual interception task and example neurons.</title><p>(<bold>A</bold>) Task diagram. In each trial, the monkey first holds the center dot for 600ms (Hold), then a target appears (Target on), after 400–800ms delay the center dot turns dark (GO), immediately the monkey moves its hand to reach to the target (Touch). The movement time (from GO to Touch) is required to be within 800ms, otherwise the trial will be aborted. The feedback dot, which is presented at the touched location of the screen, will be in red for success or in blue for failure. (<bold>B</bold>) Distribution of touch endpoints. Left panel shows fifteen reaching-up example trials in five target-motion conditions, three trials in each condition. The squares mark the touch endpoints, while the circles and triangles are the target onset and stop location. The five target-motion conditions (–240°/s, - 120°/s, 0°/s, 120°/s, and 240°/s) are indicated in five colors (purple, blue, green, yellow, and red). Target onset location is randomly distributed. Right panel shows the touch endpoints of all trials, each point represents a trial, colored according to target-motion conditions. The distribution was uniform around the circle (monkey C 772 trials, Rayleigh’s test, p=0.36). (<bold>C</bold>) Implanted locations of microelectrode array in the motor cortex of the three well-trained monkeys. Neural data were recorded from the cortical regions contralateral to the used hand. AS, arcuate sulcus; CS, central sulcus. (<bold>D</bold>) Three example neurons with PD shift, gain modulation, and offset addition. The peri-stimulus time histograms (PSTH) show the activity of example neurons when monkeys reached to upper areas in five target-motion conditions. The solid lines represent the trial-averaged firing rates, the colored shadow represents the standard error. The gray shadow indicates the time window between MO-100 ms and MO +100ms. (<bold>E</bold>) The directional tuning curves of the three example neurons with PD shift, gain, and addition modulation around movement onset (MO ±100ms, adjusted R<sup>2</sup>: 0.70, 0.84, and 0.60). Dots and bars denote the average and standard error of firing rates, colored according to target-motion conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Flexible manual interception task and behavioral performance.</title><p>(<bold>A</bold>) The condition-averaged hand trajectory and touch endpoint distribution was averaged in five target-speed and eight reach-direction conditions (five colors) referred to target stopped location, including monkey C 2994 successful trials from four sessions. Hand trajectory was collected by optical camera (VICON Inc) with an infrared marker on the fingertip from GO to touching, and touch endpoint was collected by touchscreen. (<bold>B</bold>) The condition-averaged hand velocity was calculated from hand trajectory data (same in a), aligning to GO signal, with dots labelling GO (black), average movement onset (MO) and touch time (five color). Single-trial movement onset is defined as the moment of the first time rising to 5% of maximum hand velocity. The correlation coefficient of hand velocity profiles is 0.97±0.05, mean ± sd. of 40 conditions. (<bold>C</bold>) The trials distribution of peak hand velocity in five target-speed conditions (same in b). The peak hand velocity of static-speed condition were smaller than 120°/s and 240°/s conditions (ANOVA p-value of 0°/s vs. 120°/s, 120°/s vs. 240°/s were &lt;10<sup>–6</sup>,&lt;10<sup>–20</sup>). The hand velocity between CCW and CW had little difference (ANOVA p-value of CCW vs. CW was 0.45 within 120°/s and 10<sup>–4</sup> within 240°/s). (<bold>D, E</bold>) The trials distribution in five target-speed conditions of reaction time and movement time (RT and MT, same sessions from monkey C). The temporal duration of static-speed condition were larger than 120°/s and 240°/s conditions (ANOVA p-value of 0°/s vs. 120°/s, 120°/s vs. 240°/s were &lt;10<sup>–8</sup> and&lt;10<sup>–9</sup> for RT, and &lt;10<sup>–4</sup> and&lt;10<sup>–12</sup> for MT). The duration between CCW and CW had little difference (ANOVA test). (<bold>F - G</bold>) The condition-averaged hand trajectory and velocity of monkey G 2559 successful trials from four sessions. (<bold>H - J</bold>) The trials distribution of peak hand velocity in five target-speed conditions, RT and MT (same sessions from monkey G, three starts mean ANOVA test p&lt;0.01).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Three example neurons of monkey C.</title><p>Each column respectively showed threes example neurons with PD shift, gain modulation and offset modulation from monkey C (this figure), monkey G (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>), and monkey D (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>). The radar subplots in the first row showed the neuronal reach-direction tuning curves in five target-speed conditions (red, yellow, green, blue, and purple, for CCW 120, 240°/s, static, CCW 120, and 240°/s) at movement onset (MO ± 0.1 s), and short lines outside of the tuning curves labeled preferred directions. The next eight rows showed raters and peristimulus time histograms (PSTH) of example neuron activity to eight reaching areas (labeling in left, collecting the trials with touch endpoints in 45°) in five-target-speed conditions aligned to MO.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Three example neurons of monkey G.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig1-figsupp3-v1.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 4.</label><caption><title>Three example neurons of monkey D.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig1-figsupp4-v1.tif"/></fig><fig id="fig1s5" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 5.</label><caption><title>Single-neuron fitting results.</title><p>(<bold>A</bold>) The example condition-averaged neuronal activity with eight reach directions and five target speeds, fitted by PD shift, gain, offset, and full models. Dots and bars showed the condition average neuronal activity. Tuning curves were fitting results labeled with adjusted R-square at the top right. (<bold>B</bold>) The comparison of fitting goodness among five models (above four and simple model only fits reach direction with cosine function). Each dot shows the adjusted R-square of a single neuron (monkey C, N=594; monkey D, N=178; monkey G, N=390; in blue, red and yellow, respectively). Black bars are the mean of adjusted R-square (N=1162, simple model: 0.34±0.25, gain model: 0.46±0.22, PD shift model: 0.47±0.24, Addition model: 0.41±0.26, full model: 0.55±0.24, mean ± sd.). The adjusted R-squares of the full model are obviously larger than other models (Wilcoxon signed rank test, one-tailed, p&lt;0.01).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig1-figsupp5-v1.tif"/></fig></fig-group><p>We recorded neural data with Utah arrays from monkeys C, G, and D (implanted sites are shown in <xref ref-type="fig" rid="fig1">Figure 1C</xref>, and all datasets are listed in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) and hand trajectories from monkeys C and G (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), during the interception task. The hand trajectory was launched to the final interception location. The temporal profiles of hand speed were unimodal bell-like curves and similar across target-motion conditions (correlation coefficients is 0.97±0.05 for monkey C and 0.99±0.02 for monkey G, mean ± sd).</p><p>Notably, we found that neuronal directional tuning during peri-movement period (MO ± 100ms, MO for movement onset) was modulated by target motion, according to our statistical criteria, mainly in three ways: preferred direction (PD) shift, gain modulation, and offset addition (<xref ref-type="table" rid="table1">Table 1</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplements 2</xref>–<xref ref-type="fig" rid="fig1s4">4</xref>; see Materials and methods). We determined these modulations on the basis of the classical cosine tuning model (<xref ref-type="bibr" rid="bib21">Georgopoulos et al., 1982</xref>) and several previous studies (<xref ref-type="bibr" rid="bib8">Bremner and Andersen, 2012</xref>; <xref ref-type="bibr" rid="bib51">Pesaran et al., 2010</xref>; <xref ref-type="bibr" rid="bib63">Sergio et al., 2005</xref>). Specifically, PD-shift neurons had their PDs shifted in moving-target conditions compared to the static-target condition. As illustrated by the example neuron (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, <italic>PD shift</italic>), whose PDs corresponding to CCW conditions (red and yellow) and CW conditions (blue and purple) exhibited obvious differences, TV<sub>dir</sub> rather than TV<sub>mag</sub> dominated this modulation. Gain-modulation neurons exhibited reach-direction tuning multiplied by target velocity: while their directionality remained invariant, the neuronal responses at PD differed across target-motion conditions. This modulation was dominated by TV<sub>dir</sub> as well. The turning curves of the example neuron (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, <italic>Gain</italic>) had higher responses at PD in CW conditions (blue and purple) than in the others (green, yellow, and red), indicating a varying tuning depth for reach direction. Neurons with addition modulation underwent changes of offset activity induced by target velocity (both TV<sub>dir</sub> and TV<sub>mag</sub>). As shown by the example neuron (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, <italic>Addition</italic>), this effect was roughly the same in all reach directions.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Ratio of mixed selectivity neurons around movement onset.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Units across sessions</th><th align="left" valign="bottom">Gain (G)</th><th align="left" valign="bottom">PD shift (S)</th><th align="left" valign="bottom">Addition (A)</th><th align="left" valign="bottom">None</th></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>Monkey C,</bold><break/><bold>7 sessions, N=84.9 ± 15.9</bold></td><td align="left" valign="bottom">46.9 ± 15.9%</td><td align="left" valign="bottom">79.0 ± 8.9%</td><td align="left" valign="bottom">61.9 ± 14.5%</td><td align="left" valign="bottom">6.5 ± 6.2%</td></tr><tr><td align="left" valign="bottom"><bold>Monkey G,</bold><break/><bold>4 sessions, N=97.5 ± 17.7</bold></td><td align="left" valign="bottom">29.3 ± 4.9%</td><td align="left" valign="bottom">51.6 ± 29.1%</td><td align="left" valign="bottom">25.9 ± 8.3%</td><td align="left" valign="bottom">25.5 ± 15.8%</td></tr><tr><td align="left" valign="bottom"><bold>Monkey D,</bold><break/><bold>4 sessions, N=44.5 ± 7.5,</bold></td><td align="left" valign="bottom">45.6 ± 13.8%</td><td align="left" valign="bottom">74.4 ± 8.8%</td><td align="left" valign="bottom">49.1 ± 9.1%</td><td align="left" valign="bottom">10.8 ± 5.4%</td></tr><tr><td align="left" valign="bottom"><bold>RNN,</bold><break/><bold>N=200, 100 models</bold></td><td align="left" valign="bottom">46.5 ± 4.6%</td><td align="left" valign="bottom">40.7 ± 4.2%</td><td align="left" valign="bottom">57.9 ± 8.9%</td><td align="left" valign="bottom">14.2 ± 4.2%</td></tr></tbody></table><table-wrap-foot><fn><p>Single neurons were classified by modulation patterns (more details in Materials and methods). The first column shows the subject, the number of recording sessions, and the number of isolated units (mean ± sd.). Other columns show the ratio of units with any target-velocity modulations in all active units. ‘None’ means the units were not specifically tuned by either reach direction nor target velocity.</p></fn></table-wrap-foot></table-wrap><p>The activity of these example neurons could be well described by PD shift, gain, and additive models (<xref ref-type="fig" rid="fig1">Figure 1E</xref>; see Materials and methods), respectively. Nevertheless, it was difficult to classify all neurons with mixed sensorimotor selectivity into one of these three groups exclusively, because many of them experienced a mixture of two or three of above modulations. We found that the adjusted R<sup>2</sup> of a full model (0.55±0.24, mean ± sd.) can be higher than that of the PD shift (0.47±0.24), gain (0.46±0.22), additive (0.41±0.26), and simple models (only reach direction, 0.34±0.25) for three monkeys (1162 neurons, rank-sum test, one-tailed, p&lt;0.01, <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplement 5</xref>). These target-motion modulations on neuronal directionality suggested the participation of sensory signals in shaping neural dynamics during interception execution.</p></sec><sec id="s2-2"><title>Coding of sensory and motor information in neural populations</title><p>To quantify target motion information embodied in neural response of the motor cortex, we performed a series of decoding analyses on the neural data from monkey C (n=95, 772 correct trials). To begin with, we trained a support vector machine (SVM) classifier for target-motion conditions (chance level: one in five) and another for reach directions (chance level: one in eight; see Materials and methods) on neural data. As <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows, the decoding accuracy of target-motion condition increased quickly and peaked at over 70% around GO, while the decoding accuracy of reach direction climbed in an approximately linear manner and reached a plateau of about 80% before MO. These results were stable on the data of the other two monkeys and the pseudo-population of all three monkeys (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) and reconfirmed by the continuous decoding results with support vector regressions (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), suggesting that target motion information existed in M1 throughout almost the entire trial. According to the demixed PCA (dPCA; <xref ref-type="bibr" rid="bib31">Kobak et al., 2016</xref>) results, the reach-direction components occupied high ranks; although the target-velocity components explained few variance, the interaction components were non-negligible (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). This implies that the target motion information was intertwined with reach-direction information, rather than being processed independently and in parallel.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Features of the encoding pattern at population level.</title><p>(<bold>A</bold>) The decoding accuracy (SVM with 10-fold cross-validation) of reach direction (black line) and target velocity (blue line) by population activity (monkey C, n=95, 772 trials), is aligned to target on (TO), GO, and movement onset (MO). The dash-dotted lines are chance level of decoding reach direction (black, one in eight) and target velocity (blue, one in five). The shaded area is the standard deviation of the decoding accuracy for 10 permutations. (<bold>B</bold>) The left panel shows the performance of reach-direction decoder (chance level: one in eight) transferred between different target-motion conditions. The SVM decoder was built on randomly selected 100 trials in training dataset and tested in another 100 trials from a dataset of different conditions (CCW <italic>vs</italic>. CW, 120 <italic>vs</italic> 240, static <italic>vs</italic>. motion). The distributions of decoding accuracy were from 1000 repetitions and compared with one tailed t-test (p&lt;0.01, with three stars). The right panel shows the performance of target-velocity decoder (chance level: one in five) in different reach-direction conditions. The accuracy distribution was also obtained from 1000 repetitions. (<bold>C</bold>) The explained variance and representation of the principal components (PCs). The first row shows the explained variance of each PC (cumulatively over 70%). The second row shows the PCs’ fitting goodness (R<sup>2</sup><sub>PCs</sub>) of reach direction and target velocity in four epochs. (<bold>D</bold>) Directional tuning curves of the PCs. Each row shows the directional tuning of one PC (the first three PCs in C) in four epochs. Each dot represents a trial, tuning curves are averaged in eight reach directions, and PDs of PCs are indicated by the short lines in the top of subplot by a weighted sum of response. The colors of the lines and dots mean the target-motion conditions, as the same as the legend on the left. The goodness of fitting reach direction (R<sup>2</sup><sub>DirVel</sub>) for the single-trial PCs under single target-motion conditions is shown by mean ± sd. across conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Decoding results of extended datasets.</title><p>(<bold>A–D</bold>) The temporal decoding accuracy (SVM with 10-fold cross-validation) of reach direction (black line) and target speed (blue line) by pseudo-population activity (merged Monkey C, D, G, and all monkeys), is aligned to target on (TO), GO, and movement onset (MO). The dash-dotted lines are chance level of decoding reach direction (black, one in eight) and target speed (blue, one in five). The shaded area is the standard deviation of the decoding accuracy for 10 repetitions. (<bold>E–H</bold>) The left panel shows the performance of reach-direction decoder (one in eight) transferred between different target-motion conditions. The SVM decoder was built on randomly selected 100 trials in training dataset and tested in another 100 trials from a dataset of different conditions (CCW vs. CW, static vs. motion, 120 vs 240). The distributions of decoding accuracy were from 1000 repetitions and compared with one tailed t-test (p&lt;0.01, with three stars). The right panel shows the performance of target-speed decoder (one in five) in different reach-direction conditions. In this case, reach direction is grouped by eight equal sectors (each 45°), and for each condition 60 trials were randomly selected for training and testing. The accuracy distribution was also obtained by 1000 repetitions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Decoding results and neural states across epochs.</title><p>(<bold>A</bold>) The decoding accuracy (support vector regression, SVR with 10-fold cross-validation) of reach direction (black line) and simultaneous target direction (blue line) on population activity (monkey C, n=95, 772 trials), is aligned to target on (TO), GO, and movement onset (MO). The dotted lines represent the chance level of decoding reach direction (black) and target direction (blue) using data with shuffled trial labels. The line and shaded area indicate the mean and standard error of the decoding accuracy for trials. (<bold>B</bold>) Results of unsupervised dimensionality reduction on the example dataset. Each subplot shows the directional tuning of one component at movement onset (PCAs are the same with <xref ref-type="fig" rid="fig2">Figure 2D</xref>). Each dot represents a trial, and tuning curves are averaged by eight reach directions and colored by target-motion conditions. The short lines at the top of the subplot show corresponding PDs by a weighted sum of response. (<bold>C</bold>) Decoders generalize between conditions in several epochs. The first row shows the performance of reach-direction decoder (chance level: one in eight) transferred between different target-motion conditions. The SVM decoder was built on randomly selected 100 trials in training dataset and tested in another 100 trials from a dataset of different conditions (CCW <italic>vs</italic>. CW, 120 <italic>vs</italic> 240, static <italic>vs</italic>. motion). The distributions of decoding accuracy were from 1000 repetitions and compared with one tailed t-test (p&lt;0.01, with three stars). The second row shows the performance of target-speed decoder (chance level: one in five) in different reach-direction conditions. In this case, reach directions are grouped by eight equal sectors (each 45°), and for each condition 60 trials were randomly selected for training and another 60 (?) for testing. The accuracy distribution was also obtained from 1000 repetitions. (<bold>D</bold>) The neural states across epochs. In this plane spanned by the first two PCs, the dots represent the single-trial neural states in color corresponding to reach directions (first row) or target speed (second row). The explained variance is marked on the corresponding axes. The goodness of fitting ellipses (R<sup>2</sup><sub>Ellipse</sub>) for the state dots is shown as mean ± sd across single target-motion conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>dPCA and subspace projection.</title><p>(<bold>A</bold>) Neural data were merged by target-speed modulated units (N=480, K=600 trials, T=8, bin = 50 ms, from 6 sessions of monkey C) and were averaged into 40 conditions (NKT = [480,40,8]) to do dPCA (<xref ref-type="bibr" rid="bib31">Kobak et al., 2016</xref>). The condition independent components are colored as reach direction, and the interaction components are colored as target-motion conditions. (<bold>B</bold>) Summary dPCA components variance for three monkeys merged datasets. (<bold>C</bold>) Neural states in ‘reach-direction subspace’, ‘target-velocity subspace’, and ‘interception subspace’. We used dPCA components with different features to construct three subspaces (same data in <bold>A</bold>, reach-direction space #3, #4, #5; target-velocity space #10, #15, #17; interaction space #6, #11, #12), and we projected trial-averaged data into these orthogonal subspaces using different colormaps. This approach allowed us to obtain a ‘potent subspace’ coding reach direction and a ‘null space’ for target velocity. The results showed that the reach-direction subspace effectively represented the reach direction. However, while the target-velocity subspace encoded the target velocity information, it still contained reach-direction clusters within each target-velocity condition, corroborating the results of the addition model in the main text (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The interaction subspace revealed that multiple reach-direction rings were nested within each other, similar to the findings from the gain model (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref>). The interaction subspace also captured more variance than target-velocity subspace, consistent with our PCA results, suggesting the target-velocity modulation primarily coexists with reach-direction coding. Furthermore, we explored alternative methods to verify whether orthogonal subspaces could effectively separate the reach direction and target velocity. We could easily identify the reach-direction subspace, but its orthogonal subspace was relatively large, and the target-velocity information exhibited only small variance, making it difficult to isolate a subspace that purely encodes target velocity.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Neural trajectory during preparatory and peri-movement periods.</title><p>(<bold>A</bold>) The first three dimension of the condition-averaged neural trajectory (Monkey C, n=95, 40 conditions) in two periods. The neural data was N*KT (N for 95 neurons, K for 40 conditions combined with T=10 bins, bin length 50 ms, 40 conditions contain a combination of five target speeds and eight reach directions), and reduced neural dimension N to explain KT with PCA (explained variance of PC labeling in parentheses). Left column is delay period (TO to TO +500 ms, TO means target onset), with triangles and circles labeling condition-averaged TO and GO. Right column is peri-movement period (GO to GO +500 ms), with circles and squares labeling GO and movement onset (MO). The same neural trajectory is plotted in two colormaps with target-motion conditions (up row) and reach directions (down row). Black arrows mark the direction of temporal evolution. (<bold>B</bold>) The mean neural trajectory Euclidian distance of target-motion and reach-direction conditions, aligned to TO (left) and GO (right), respectively, with selected 8 PCs and 14 PCs respectively covering 90% of delay period and movement period data variance. The black bar above the subplot labels the obvious difference temporal bin between two distances (Kruskal-Wallis test, p&lt;0.05). The shadow means the standard error. The black square is the condition-averaged MO. (<bold>C</bold>) The mean neural trajectory Euclidian distance with same data in <bold>B</bold>, comparing CCW <italic>vs</italic>. CW and 120 <italic>vs</italic> 240 conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig2-figsupp4-v1.tif"/></fig></fig-group><p>Then, we performed another decoding analysis to probe the potential interaction between reach direction and target velocity during execution period. We trained a reach-direction decoder (chance level: one in eight) to check if the decoder of one certain target-motion condition could be transferred to other conditions (<xref ref-type="fig" rid="fig2">Figure 2B</xref> left). It turned out that the performance of the transferred decoder deteriorated more significantly for TV<sub>dir.</sub> (CCW <italic>vs</italic>. CW, mean ± sd. of accuracy 0.26±0.06), compared with that for TV<sub>mag</sub> (120 <italic>vs</italic> 240, 0.50±0.06, paired t-test, p&lt;0.01) and for target’s state (static <italic>vs</italic>. motion 0.55±0.06, paired t-test, p&lt;0.01). This result suggests that the coding of reach direction was rather sensitive to TV<sub>dir,</sub> but contained similarities for static and moving targets. We also compared the neural coding rules across different reach-direction conditions. We trained a target-velocity decoder (chance level: one in five), and similarly checked the transferred decoding accuracy (<xref ref-type="fig" rid="fig2">Figure 2B</xref> right). We observed that the target-velocity decoder was locked with reach direction, as the transferred decoding accuracy diminished with increasing difference of reach direction. These results qualitatively imply the interaction as that target velocities affected the reach-directional tuning, especially by TV<sub>dir.</sub> This target-motion effect was most obvious at the MO (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2C</xref>).</p><p>To explore how sensory information influences neural dynamics while preserving motor output, we performed PCA on the normalized population activity. We obtained the trial-averaged neural trajectories (five target velocities by eight reach directions, totally 40 conditions) after TO or after GO (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4A</xref>). The distance between neural trajectories grouped by reach-direction conditions was larger than the distance grouped by target-motion conditions, especially after GO (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4B</xref>), consistent with the dPCA results that M1 primarily encoded reach direction rather than target velocity. In addition, the distance of neural trajectories between CCW and CW was much larger than the distance between 120°/s and 240 °/s conditions, indicating that TV<sub>dir</sub> dominated the target-motion effect, agreeing with the decoding results (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4C</xref>).</p><p>However, these neural trajectories were not yet the ideal description, because they were shaped mostly by time. Therefore, to highlight the proposed target-motion effect on reach direction, we focused on four key time windows and snapshotted the neural trajectory as neural state to extract the coding rule at single-trial level and from a geometric view. Here, we define the ‘neural states’ as the projection of single-trial data during a specific time bin on principal components (PCs; <xref ref-type="bibr" rid="bib40">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib49">Parthasarathy et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Sun et al., 2022</xref>). At the MO, the first two PCs of the neural states explained the most variance ([24.8%, 13.8%]) and were most related to reach direction (the goodness of fitting reach direction, [<inline-formula><mml:math id="inf1"><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf2"><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula>] = [0.82, 0.81], <xref ref-type="fig" rid="fig2">Figure 2C</xref>). While reach direction was represented by the first two PCs at GO and during movement execution, target velocity influenced the tuning pattern of the first three PCs in various ways (<xref ref-type="fig" rid="fig2">Figure 2D</xref>).</p></sec><sec id="s2-3"><title>Orbital neural geometry in latent space</title><p>We visualized the neural states in the low-dimensional space spanned by the above three PCs (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2D</xref>). At the MO, the projections of the single-trial neural states onto the PC1-PC2 subspace distributed in reach-direction order, as reach direction was divided into eight sectors, there appeared to be eight reach-direction clusters (<xref ref-type="fig" rid="fig3">Figure 3A</xref> top and <xref ref-type="fig" rid="fig3">Figure 3B</xref> left). Interestingly, the neural states under each single target-motion condition formed ring-like structures and the fitted ellipses exhibited concentric shapes (the fitting goodness of ellipses, R<sup>2</sup>=0.92 ± 0.01, mean ± sd. across target-motion conditions; see Materials and methods). Moreover, these ellipses tilted in condition-dependent angles, which is particularly evident in the PC2-PC3 subspace (<xref ref-type="fig" rid="fig3">Figure 3A</xref> bottom and <xref ref-type="fig" rid="fig3">Figure 3B</xref> right). Note that here we performed a linear transformation on all resulting neural state points to make the ellipse of the static condition orthogonal to the z-axis for better visualization.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The orbital neural geometry in latent dynamics.</title><p>(<bold>A</bold>) Three-dimensional neural state of M1 population activity obtained by PCA. Each point represents a single trial. The upper subplot is colored according to five target-motion conditions, while the bottom is in colors corresponding to eight reach directions. The explained variances of the first three PCs were 17.7%, 11.3%, and 5.9%. Neural data were from monkey C (N=480, merged six sessions), for each of the total 40 conditions, 15 trials were randomly sampled. (<bold>B</bold>) Fitted ellipses of neural states. The ellipses fitted in (<bold>A</bold>) are projected onto three two-dimensional subspaces, colored by target velocities (left column) or reach directions (right column). (<bold>C</bold>) The relation between the tiling angle and target velocity. The tilting angle is calculated between ellipses of the moving-target conditions and the static-target condition (0 °/s) in the range from –90° to 90°, CCW is defined as positive. Circles, squares, and triangles correspond to monkeys C (7 sessions), G (4 sessions), and D (4 sessions), respectively. The lines indicate the linear fitting between the tilting angle (θ) and target velocity (vel.), with solid line for monkey C (<italic>θ</italic>=0.23*vel.+4.2, R<sup>2</sup>=0.91), dashed line for monkey D (<italic>θ</italic>=0.26*vel.+4.3, R<sup>2</sup>=0.81), and dotted line for monkey G (<italic>θ</italic>=0.15*vel.-1.4, R<sup>2</sup>=0.89).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Neural state of target-motion modulated M1 neurons from three monkeys.</title><p>The neural state of movement onset (MO ± 50ms) from three-monkey selected neurons. Neural data was collected with target-speed modulated units (<bold>N</bold>) and random 15 trials in 40 conditions (K=600 trials) from each monkey several sessions (<bold>A–C</bold>) and all monkeys’ sessions (<bold>D</bold>). Merged neural data was to do PCA to get neural state. Each point represented the neural state of single trial projected in static condition subspace. Ellipses were fitted by neural states in five target-speed conditions. (<bold>E–H</bold>) The relative titling angle of ellipses from static condition (merged datasets), had a linear relationship with target speed. Five color dots were tilting angles of five-target-speed condition. (<bold>I–L</bold>) We calculated the titling angle for separative sessions, and got the consistent linear relationship between tilting angle and target speed. The titling angle of three monkeys also showed in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Target-motion modulation on hand-speed-filtered trials.</title><p>(<bold>A</bold>) The peak hand velocity distribution with selected trials. We used 10~90% of peak hand velocity in static-speed condition as threshold to select trials. Solid lines are remaining-trial distribution (monkey C 2260/4132 trials) and dash lines are raw distribution in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. After filtering, there is no difference between five-speed conditions (ANOVA p-value of 0°/s vs. 120°/s, 0°/s vs. 240°/s, and 120°/s vs. 240°/s were 0.56, 0.14, and 0.26). (<bold>B</bold>) Adjusted neural state with filtered trials. We performed PCA to neural data of one example session with filter trials (random chose 100 trials for each target-speed condition by a filter of 10~90% of peak hand velocity in static-speed condition, K=500 trials) and selected units (target-speed modulated neuron, N=91), to get neural state. We repeated in each sessions of two monkeys, then neural states of target-speed conditions were fitted ellipses and calculated the tilting angles of ellipses. (<bold>C</bold>) Tilting angle between ellipses of adjusted neural state. The titling angles were highly correlated with target speed (black circles and blue triangle are four sessions of monkey C, and three sessions of monkey G). (<bold>D</bold>) The filtered hand-velocity distribution compared with raw distribution (dashed line, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1H</xref>). (<bold>E</bold>) Adjusted neural state of one example session from monkey G. (<bold>F</bold>) The R2 distribution of single-unit gain model. The gain of target speed performed better than hand velocity, with fr = c0+a*(y+c1)*cos(x-b)+c2*y, fr was mean firing rate of MO ± 50ms, x for reach direction, y for target speed or hand velocity. The triangles labeled the mean R2 of two models.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig3-figsupp2-v1.tif"/></fig></fig-group><p>Next, we quantified the spatial features of these ellipses by calculating the tilting angles, which were defined as the angles between the normal vectors of the moving-target and static-target conditions. Strikingly, these tilting angles were linearly correlated with target velocity (both TV<sub>mag</sub> and TV<sub>dir</sub>), and the relationship was robust in nine datasets from three monkeys (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>To eliminate hand-speed effect, we resampled trials to construct a new dataset with similar distributions of hand speed in each target-motion condition and found similar orbital neural geometry. Moreover, the target-motion gain model provided a better explanation compared to the hand-speed gain model (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>Given these results, we propose that this orbital neural geometry epitomizes the sensorimotor dynamics of M1 at the population level. The sensory input can regularly modulate neural states in an orthogonal dimension (PC3), without interfering with motor generation (in PC1 and PC2).</p></sec><sec id="s2-4"><title>Population neural geometry relies on neuronal tuning</title><p>To test whether a group of single neurons with a certain type of mixed sensorimotor selectivity could exhibit the orbit neural geometry, three neuronal models were constructed based on the three fitting models described above (PD shift, gain, and addition, see <xref ref-type="fig" rid="fig1">Figure 1D</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplements 2</xref>–<xref ref-type="fig" rid="fig1s4">4</xref>). We ran a simulation with these representational neuronal models (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Here, each group consisted of 300 model neurons with their PDs uniformly distributed, and was solely modulated as PD-shift, gain, or addition (see Materials and methods). The resulting neural geometry of the three simulation groups showed distinct features (<xref ref-type="fig" rid="fig4">Figure 4B</xref>): The single-condition ellipses were inclined with target-motion-dependent angles in the PD-shift and gain groups, similar to the real neural data, but the ellipses in the addition group were layered in parallel. The reach-direction clusters in the first two PCs were conservative in the gain and addition group, but not in the PD-shift group. These results indicate that the neural states of the real data mainly resembled the geometry feature of the gain modulation group. Nonetheless, we found that a population with a uniform mixture of all three modulations was able to simulate the neural geometry as well (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>The shape of neural dynamics relies on neuronal mixed selectivity.</title><p>(<bold>A</bold>) The tuning curves of three ideal neurons in five target-motion conditions. From up to down, they are PD shift, gain modulation, and addition. (<bold>B</bold>) The simulated neural states from three groups of ideal neurons, colored according to target-motion conditions (first row) and reach directions (second row). For each simulation, the neural states were obtained from 300 model neurons by PCA. The neural state in 180° reach direction is marked with a red dot. The first two principal components (PCs) can explain more than 95% of the variance in the data (the explained variance of the first three PCs, Gain: 49.5%, 46.6%, and 2.0%; PD shift: 50.1%, 47.1%, and 1.6%; Addition:50.8%, 47.9%, and 1.4%). (<bold>C</bold>) The neural states of a mixed group of 100*3 model neurons, as in (<bold>B</bold>). The explained variance of the first three PCs were 48.4%, 44.2%, and 3.1%. (<bold>D</bold>) Quantification of the difference between neural-state ellipses in four simulated groups and a real dataset (monkey C, n=95). Rotational angle is the angular differences in the first two neural state. Tilting angle is the relative angle of the normal vector of ellipses. State shift is the root of mean squared distance between two ellipses.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig4-v1.tif"/></fig><p>Comparing with the static-target condition, we calculated relative rotation angle and tilting angle between ellipses along with the vertical shift of neural states, in order to quantify the simulated structure (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). The results show that the real data yielded a smaller rotation angle than the PD-shift group, a smaller vertical shift than the additive group, but larger tilting angles than all models. The mixed group had the most similar tilting angle, although with moderate performance in rotation angle and state shift.</p><p>These simulations suggest that the existence of PD-shift and additive modulation would not disrupt the neural geometry which is primarily driven by gain modulation; rather, it is possible that these three modulations support each other in a mixed population.</p></sec><sec id="s2-5"><title>The recurrent neural network provides dynamic insights</title><p>To infer how such modulated subpopulations would interact with each other in a dynamical system, we trained 100 RNN models with random weight initialization (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; see Methods). The inputs included motor intention, target location, and a GO signal. Motor intention was defined as an abstract motor command predicted to compensate for sensorimotor delays (<xref ref-type="bibr" rid="bib18">Cui, 2016</xref>), and could be provided by the PPC (<xref ref-type="bibr" rid="bib4">Andersen and Buneo, 2002</xref>; <xref ref-type="bibr" rid="bib5">Andersen and Cui, 2009</xref>), here simplified as the interception location. The network was to generate hand velocity after MO. For a fixed validation set of 500 trials, these trained network models performed well (distance between the reach endpoint and the target was 0.0046±0.0027, a. u., mean ± sd., while the radius of target motion was 0.15).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>The neural geometry in RNNs.</title><p>(<bold>A</bold>) Network architecture. The network inputs consist of motor intention, target location, and GO signal. The motor intention is the two-dimensional Cartesian coordinate of the interception location, and exists fixed during MO-50ms to MO; the target location is the two-dimensional Cartesian coordinate of the moving target, and appears time-varying during the whole trial; the GO-signal is a step function, jumping from 0 to 1 at GO. The RNN with 200 hidden units is expected to output hand velocity in two-dimensional Cartesian coordinates for accurate interception. (<bold>B</bold>) Three example nodes with PD-shift modulation, gain modulation, and additive modulation. Similar to <xref ref-type="fig" rid="fig1">Figure 1D</xref>. (<bold>C</bold>) Three-dimensional neural state of node activity obtained by PCA, colored according to target-motion conditions (top) and reach-direction conditions (Bottom). Similar to <xref ref-type="fig" rid="fig3">Figure 3A</xref>. (<bold>D</bold>) The tilting angle of ellipses. Similar to <xref ref-type="fig" rid="fig3">Figure 3D</xref>. The fitted line is <italic>θ</italic>=0.15*vel.+0.11, R<sup>2</sup>=0.96, across five target velocities. (<bold>E</bold>) The connectivity between different types of modulations. On the left is a boxplot representing the averaged absolute connection weight, across 100 models. S for PD-shift nodes, G for gain nodes, and A for additive nodes. On the right is a diagram of the connectivity, with linewidth representing the relative connection strength.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Decoding results and weight distributions of RNNs.</title><p>(<bold>A</bold>) The decoding accuracy (SVM with 10-fold cross-validation) of reach direction (black line) and target speed (blue line) across 100 network models, is aligned to TO, GO, MO. The dash-dotted lines are chance level of decoding reach direction (black, one in eight) and target speed (blue, one in five). While the lines are the mean of the mean decoding accuracy across models, the shaded area is the standard deviation of the mean decoding accuracy across models. (<bold>B</bold>) The input weights. The weights from motor intention-x and motor intention-y were averaged as motor intention, so as target location-x and target location-y to target location. To get a relative tendency, we selected the only modulated nodes and normalized the weight by dividing the maximum (the max absolute weight from motor intention, target location, and GO-signal, respectively), for each model. For motor intention (weight &gt;0), S&gt;G = A; for target location, S&lt;G = A (weight &gt;0), S&lt;A &lt; G (weight &lt;0); for GO-signal (weight &lt;0), S&gt;G = A. ‘=’ here defines no significance while ‘&lt;’ means p&lt;0.01. (<bold>C</bold>) The output weights. The outputs to x and y were averaged. Similar with <bold>B</bold>, we selected the only modulated nodes and normalized the weight by dividing the max absolute output weights, for each model. No matter whether weight &gt;0, S&lt;G = A (p&lt;0.001).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100064-fig5-figsupp1-v1.tif"/></fig></fig-group><p>In these network models, we found three comparable features. First, from the decoding result, target motion information existed in nodes’ population dynamics shortly after TO (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>). Second, most of the activated nodes (for example, <xref ref-type="fig" rid="fig5">Figure 5B</xref>) could be classified into the above-mentioned three modulations by the same statistical standard as for the real neural data (<xref ref-type="table" rid="table1">Table 1</xref>). Third, the states reduced from node population activity were arranged in a way resembling the actual neural geometry at the MO (the fitting goodness of ellipses, R<sup>2</sup>=0.98 ± 0.05, mean ± sd.; <xref ref-type="fig" rid="fig5">Figure 5C</xref>). The tilting angles followed the same pattern as suggested by the actual results (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). We then performed canonical component analysis (CCA) and Procrustes analysis (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>; see Materials and methods), the results also indicated the similarity between network dynamics and neural dynamics.</p><p>With these RNN models, we tried perturbations to investigate the function of certain modulation groups and their connection. The ablation experiments showed that losing any kind of modulation nodes would largely deteriorate the performance, and those nodes merely with PD-shift modulation could mostly impact the neural state structure (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). The connections within and between gain modulation nodes and additive modulation nodes were stronger than the others (p&lt;0.01, K-W Test) but comparable to each other (p=1.00, K-W Test; <xref ref-type="fig" rid="fig5">Figure 5E</xref>). However, further strengthening the connection from gain to additive nodes or within additive nodes would impair the orbital structure more significantly (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). We speculate that the influence, and perhaps the formation, of modulations both relate to the robust input and output weight pattern across models (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B–C</xref>). From these results, all the three modulations are necessary for anticipative performance and their interactions likely mold the ring-like structure, though their specific roles are not yet elucidative.</p><p>We also tested three alternative network models: (1) only receives motor intention and a GO-signal; (2) only receives target location and a GO-signal; (3) initialized with sparse connection (sparsity = 0.1); the unmentioned settings and training strategies were as the same as those for original models (<xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref>; see Materials and methods). The results showed that the three modulations could emerge in these models as well, but with obviously distinctive distributions. In (1), the ring-like structure became overlapped rings parallel to the PC1-PC2 plane or barrel-like structure instead; in (2), the target-motion related tilting tendency of the neural states remained, but the projection of the neural states on the PC1-PC2 plane was distorted and the reach-direction clusters dispersed. These implies that both motor intention and target location seem to be needed for the proposed ring-like structure. The initialization of connection weights of the hidden layer can influence the network’s performance and neural state structure, even so, the ring-like structure and especially the target-velocity dependent tilting remained in a degree. However, we did not find specific connection patterns in these sparsely-initialized networks (p=0.73, K-W Test).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Mixed selectivity in M1 has been widely reported; but to our knowledge, sensory modulation on anticipatory motor control, as examined in this study, has been scarcely studied. To reveal how sensory context influence neural dynamics during movement, we recorded M1 population activity from monkeys performing a flexible manual interception that is highly dependent on predictive sensorimotor transformations. Single-neuron activity showed that the movement tuning of M1 neurons varied with target-motion conditions in complicated ways, including PD shift, gain modulation, addition, or their mixtures. Unsupervised dimensionality reduction (PCA) on population activity revealed an orbital neural geometry, where neural states of single trials spontaneously formed ellipses and were tilted according to target-motion conditions. Such a neural geometry, which could be simulated with a group of representational neurons for gain modulation alone, also emerged in the RNNs with appropriate input-output mappings. As suggested by the dynamic and connected population of the RNNs, the interactions between modulations were sophisticated in preserving the encoding of motor output. These results reveal sensory modulation of peri-movement neural dynamics at the single-neuron and population levels, and bridge the neuronal mixed sensorimotor selectivity and a low-dimensional neural geometry.</p><p>A main concern about our finding is that the observed modulation would actually be attributed to interactions between kinematic variables, such as reach direction and hand speed (<xref ref-type="bibr" rid="bib25">Inoue et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Moran and Schwartz, 1999</xref>; <xref ref-type="bibr" rid="bib48">Paninski et al., 2004</xref>). However, we can eliminate the hand-speed effect for at least two reasons: First, the hand speed pattern and neural activity pattern were not consistent. We found hand speed vary with TV<sub>mag</sub>, but the largest gap in neuronal activity related to TV<sub>dir</sub> (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>); Second, the neural geometry was not contingent upon hand speed distribution, as similar hand-speed distribution across target-motion conditions did not change the phenomenon (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). It is a pity that we did not record sufficient muscle data during interception to rule out the motor cortical representation for kinetic variables such as force (<xref ref-type="bibr" rid="bib20">Evarts, 1968</xref>; <xref ref-type="bibr" rid="bib62">Scott and Kalaska, 1997</xref>; <xref ref-type="bibr" rid="bib66">Sun et al., 2022</xref>), but we believe that this would not invalidate our main conclusions.</p><p>Another concern is whether the neural geometry was representing sensory information. Previous studies have showed that M1 has transient responses to behaviorally relevant visual cues (<xref ref-type="bibr" rid="bib1">Alexander and Crutcher, 1990</xref>; <xref ref-type="bibr" rid="bib34">Lamarre et al., 1983</xref>; <xref ref-type="bibr" rid="bib39">Lurito et al., 1991</xref>; <xref ref-type="bibr" rid="bib52">Port et al., 2001</xref>; <xref ref-type="bibr" rid="bib56">Rao and Donoghue, 2014</xref>; <xref ref-type="bibr" rid="bib58">Rizzolatti et al., 1981</xref>), but it is seldom evoked by purely visual stimuli, only weakly tuned (<xref ref-type="bibr" rid="bib32">Kruse et al., 2002</xref>; <xref ref-type="bibr" rid="bib33">Kwan et al., 1985</xref>; <xref ref-type="bibr" rid="bib42">Merchant et al., 2001</xref>). Here, the modulated neural dynamics, though distinguished according to target-motion conditions, are ultimately shaped for motor generation rather than sensory representation. To further clarify, the discussing target-motion effect is different from the sensory modulation in action selection (<xref ref-type="bibr" rid="bib16">Cisek and Kalaska, 2005</xref>), motor planning (<xref ref-type="bibr" rid="bib50">Pesaran et al., 2006</xref>), visual replay and somatosensory feedback (<xref ref-type="bibr" rid="bib54">Pruszynski et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Stavisky et al., 2017</xref>; <xref ref-type="bibr" rid="bib68">Suway and Schwartz, 2019</xref>; <xref ref-type="bibr" rid="bib69">Tkach et al., 2007</xref>), because it occurred around movement onset and in predictive control trial-by-trial.</p><p>In the present study, we focused on the orbital neural geometry by taking ‘snapshots’ of neural activities with PCA. In addition to this unsupervised dimensionality reduction method, we also tried another supervised one – dPCA (<xref ref-type="bibr" rid="bib31">Kobak et al., 2016</xref>). However, the dPCA results (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>) showed that the condition-independent temporal component explained the largest variance, followed by the component of reach direction, whereas the interactive and target-velocity components only covered very small proportions. The dPCA did not distinguish an independent subspace coding target-velocity (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3C</xref>), suggesting the target-velocity information persisted in the shared subspace with reach direction.</p><p>It would be interesting to explore whether other motor areas also allow sensory modulation during flexible interception. The functional differences between M1 and other areas lead to uncertain speculations. Although M1 has pre-movement activity, it is more related to task variables and motor outputs. Recently, a cycling task sets a good example that the supplementary motor area (SMA) encodes context information and the entire movement (<xref ref-type="bibr" rid="bib59">Russo et al., 2020</xref>), while M1 preferably relates to cycling velocity (<xref ref-type="bibr" rid="bib60">Saxena et al., 2022</xref>). The dorsal premotor area (PMd) has been reported to capture potential action selection and task probability, while M1 not (<xref ref-type="bibr" rid="bib16">Cisek and Kalaska, 2005</xref>; <xref ref-type="bibr" rid="bib22">Glaser et al., 2018</xref>; <xref ref-type="bibr" rid="bib71">Wang et al., 2019</xref>). If the neural dynamics of other frontal motor areas are revealed, we might be able to tell whether the orbital neural geometry of mixed selectivity is unique in M1, or it is just inherited from upstream areas like PMd. Either outcome would provide us some insights into understanding the interaction between M1 and other frontal motor areas in motor planning.</p><p>From a bigger view, how could the motor cortex cooperate with other brain regions during flexible interception? It could be true that the communication and collaboration of PPC-motor cortex circuity translate abstract motor intention to executable motor command: PPC transforms sensory modulation to the motor cortex, while the motor cortex sends potential movement direction to PPC, and then their recurrent interaction generates mature motor intention and command. Our simulations with neuronal models and RNNs demonstrate that differences in modulations and the interaction between them can be essential. In fact, modulations in the form of PD shift and gain have been widely found in the motor cortex and PPC. For example, motor cortex neurons experience gain and PD shift modulation by arm posture (<xref ref-type="bibr" rid="bib27">Kakei et al., 2001</xref>; <xref ref-type="bibr" rid="bib26">Kakei et al., 1999</xref>; <xref ref-type="bibr" rid="bib62">Scott and Kalaska, 1997</xref>). Neurons in PPC have eye and hand gain fields for a visually-guided reach plan (<xref ref-type="bibr" rid="bib6">Batista et al., 1999</xref>; <xref ref-type="bibr" rid="bib10">Buneo et al., 2002</xref>; <xref ref-type="bibr" rid="bib11">Chang et al., 2009</xref>), integrating target position related to gaze and hand position to form motor intention (<xref ref-type="bibr" rid="bib3">Andersen et al., 1997</xref>; <xref ref-type="bibr" rid="bib4">Andersen and Buneo, 2002</xref>; <xref ref-type="bibr" rid="bib17">Cohen and Andersen, 2002</xref>). Therefore, we posit that the three types of modulations should all be involved in sensorimotor computation in predictive motor control. Furthermore, recent studies show that interactions of PPC-motor cortex circuity are involved in motor planning, spatial transformation and motor selection (<xref ref-type="bibr" rid="bib19">Dann et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Martínez-Vázquez and Gail, 2018</xref>; <xref ref-type="bibr" rid="bib61">Schaffelhofer and Scherberger, 2016</xref>). The PPC-M1 circuit, as a key part of cortico-subcortical networks for the predictive sensorimotor control (<xref ref-type="bibr" rid="bib9">Brozović et al., 2007</xref>), will be a topic for future studies.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experimental model and subject details</title><p>All procedures have been approved by the Biomedical Research Ethics Committee of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences, under permit number ER-SlBS-221603P. They comply with national and local laws and regulations in China and are in accordance with the Guide for Care and Use of Laboratory Animals of the Institute for Laboratory Animal Research (version 20160310). All surgery was performed under anesthesia, and every effort was made to minimize suffering. The details of the experimental procedures are as follows. Three adult male rhesus macaques (monkey C, D, and G, <italic>Macaca mulatta</italic>, 7–10 kg) were recruited in this study.</p></sec><sec id="s4-2"><title>Task and behavior</title><p>The monkeys sat in primate chairs to perform the task. The stimuli were back-projected onto a vertical touch screen (Elo Touch system; sampling at 100 Hz, spatial resolution &lt;0.1 mm) about 30 cm in front of the monkeys. The monkeys were trained to perform a flexible manual interception task in a dark room. The task paradigm was modified based on the visually guided reaching interception task in a previous study (<xref ref-type="bibr" rid="bib36">Li et al., 2018</xref>). In the beginning, the monkey held the green central dot of a touch screen for 600ms to initiate a trial (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Then, a green target dot appeared at a random location, moving along a circular path with a radius of 15 cm around the central dot. The central dot turned dark as a GO cue after a random delay (400–800ms); then the monkey could intercept the target at any moment within 150–800ms after the GO cue. Once any peripheral location was touched, the target stopped. The tolerance range of the touch endpoint for correct trials was within 3 cm of the target. The monkey would be rewarded with juice after each correct trial. Conditions where targets moved clockwise (CW; –240 °/s, –120 °/s) or counterclockwise (CCW; 120 °/s, 240 °/s), as well as targets stayed stationary (0°/s), were pseudo-randomly interleaved trial by trial. Additional target velocities (–360 °/s, –180 °/s, 180 °/s, 360 °/s added) were introduced in subsequent sessions (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). The single-trial MO is defined as the moment when hand velocity first rose to 5% of the maximum. Task control and behavior data acquisition were managed via MonkeyLogic v2.0 [<ext-link ext-link-type="uri" xlink:href="https://monkeylogic.nimh.nih.gov/index.html">https://monkeylogic.nimh.nih.gov/index.html</ext-link>] (<xref ref-type="bibr" rid="bib24">Hwang et al., 2019</xref>).</p></sec><sec id="s4-3"><title>Data collection</title><p>After the monkeys were adequately trained for the task (successful rate &gt;90%), head-posts were implanted stereotaxically under anesthesia (induced by 10 mg/kg ketamine, then sustained by 2% Isoflurane). After a few weeks of recovery and adaptation, the monkeys were implanted with Utah microelectrode arrays (Blackrock Microsystems, Salt Lake City, UT) in M1 of the hemisphere contralateral to the handedness (<xref ref-type="fig" rid="fig1">Figure 1C and a</xref> 128-channel array for monkey C, 96-channel arrays for monkey G and D). The recording areas were identified by Magnetic Resonance Imaging (MRI) and cortical sulcus features. Neuronal activity was recorded via a Cerebus acquisition system (256-channel recording system Blackrock Microsystems), sampled at 30 kHz. We collected 85±16, 45±8, 98±18 well-isolated units from monkey C, G, and D across sessions, respectively (mean ± sd., more details in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Array-recorded raw data were sorted offline by Wave_clus (<xref ref-type="bibr" rid="bib55">Quiroga et al., 2004</xref>). Hand trajectory was collected by optical camera (VICON Inc 100 Hz) with an infrared marker on the fingertip from GO to Touch, and touch endpoint was collected by touchscreen.</p></sec><sec id="s4-4"><title>Peri-stimulus time histograms (PSTHs)</title><p>The PSTHs and spike rasters of single neurons are shown in <xref ref-type="fig" rid="fig1">Figure 1D</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplements 2</xref>–<xref ref-type="fig" rid="fig1s4">4</xref>. All trials were classified into 40 conditions, eight reach-endpoint sectors by five target-motion conditions. Condition-averaged firing rates were calculated with 50 ms bins and smoothed with a Gaussian kernel (standard deviation = 20ms). The standard error of firing rates was estimated from the 10 bootstrap samples in the trials of corresponding condition.</p></sec><sec id="s4-5"><title>Classification of neuronal tuning properties</title><p>To depict target-motion modulation for single-neuron reach-direction tuning, we applied a series of statistical analyses for classification.</p><p>We first calculated three indices of each neuron for each target-motion conditions, using the trial-averaged firing rate around movement onset (MO ± 100ms). These indices were preferred direction (PD), tuning depth, and offset activity. The PD of each neuron for a certain target-motion condition was calculated by the weighted sum of neuronal firing rates averaged by eight reach-direction sectors. The tuning depth of each neuron was determined by the range (max - min) of firing rates in corresponding target-motion conditions. The offset activity of each neuron was calculated by the mean firing rate (MO ± 100ms) of each target-motion condition.</p><p>Then, we classified PD shift, gain, and addition groups (in <xref ref-type="table" rid="table1">Table 1</xref>). A neuron was classified as ‘PD shift’, if its PDs were significantly different between the moving-target conditions and the static-target condition Watson-Williams test in circular data, CircStat by <xref ref-type="bibr" rid="bib7">Berens, 2009</xref>; as ‘gain’, if its tuning depths were significantly different between the moving-target conditions and the static-target condition (two-tailed Wilcoxon signed-rank test, p&lt;0.05); as ‘offset’, if its offset activities were significantly different between the moving-target conditions and the static-target condition (two-tailed Wilcoxon signed-rank test, p&lt;0.05).</p></sec><sec id="s4-6"><title>Population decoding</title><p>The population activity of the motor cortex was used to decode target motion and reach direction by SVM. Neuronal firing rate was soft-normalized as<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where raw firing rates were divided by the range of firing rates plus five (<xref ref-type="bibr" rid="bib14">Churchland et al., 2012</xref>). We trained two SVM classifiers (MATLAB function ‘fitcecoc’, 10-fold cross-validation) to decode reach direction (chance level: one in eight) and target motion (chance level: one in five) of single trials in 100 ms window sliding with 50 ms step (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The temporal decoding was repeated ten times to obtain the mean and standard deviation of decoding accuracy.</p><p>We tested the generalization of reach-direction and target-motion decoders (SVM, MATLAB function ‘fitcecoc’) in different conditions during execution period (MO ± 100ms, <xref ref-type="fig" rid="fig2">Figure 2B</xref>). The decoder predicted single-trial reach direction (one of the eight 45° sectors) or target motion (one of the five ones) across conditions based on normalized population activity. The reach-direction decoder (<xref ref-type="fig" rid="fig2">Figure 2B</xref> left), which was trained by trials in a certain set of target-motion conditions, was tested with trials from another set of target-motion conditions (CCW vs. CW, or 120 vs 240, or static vs. motion, 100 trials randomly selected without replacement from corresponding training-test datasets), and the training-test decoding was repeated 1000 times to compare the distribution of accuracy with paired t-test. The target-velocity decoder (<xref ref-type="fig" rid="fig2">Figure 2B</xref> right), which was trained by trials in a given reach-direction condition within 45°, was tested with trials from other reach-direction conditions.</p></sec><sec id="s4-7"><title>Unsupervised dimensionality reduction</title><p>The population activity was stored in NKT datasets, where N, K, and T denote the neurons, trials, and time bins, respectively. For neural state, we averaged T dimension of neural activity in a 100 ms bin (for example, the two 50 ms bins around MO), and normalized neuronal firing rates by Z-score (MATLAB function ‘zscore’) to get a K x N dataset. After preprocessing, we used PCA (MATLAB function ‘pca’) to reduce the dimension from K x N to K x P (P is the number of PCs), and we fitted the PCs with reach direction (<inline-formula><mml:math id="inf3"><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:math></inline-formula>) and target velocity (<inline-formula><mml:math id="inf4"><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:math></inline-formula>) in <xref ref-type="fig" rid="fig2">Figure 2</xref>. We also tried independent component analysis (ICA, MATLAB function ‘rica’), with similar results in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2B</xref>. Neural states of single trials were colored according to target velocity or reach direction and fitted as three-dimensional (first three PCs, <xref ref-type="fig" rid="fig3">Figure 3</xref>) ellipses by MATLAB package ‘MatGeom’ (<xref ref-type="bibr" rid="bib35">Legland, 2025</xref>). To show the relative position of ellipses in the best viewing angle, we used an isometric affine transformation to globally map all neural state points on new axes, while preserving the proportional relationships between points. After this linear transformation, the azimuth and elevation of ellipses changed slightly, but the tilting angle between ellipses remained constant (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The tilting angles, rotation angles, and state shift were calculated between ellipses of the moving-target conditions and the static-target condition in each session, with CW defined as negative angles and CCW as positive angles. A set of tilting angles were obtained from corresponding conditions in one dataset, and a linear regression model was used to fit all ellipses angles (θ) and target velocities (vel.) in nine sessions. For neural trajectory, we averaged NKT to NCT (40 condition, five target velocities by eight reach directions) and reduced neural dimension N to explain concatenated C x T (40 conditions * 10 bins) with PCA. The neural trajectories of preparatory and peri-movement period (TO~+500ms, GO~+500ms) were shown in <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref> with Euclidian distance across conditions.</p></sec><sec id="s4-8"><title>Fitting and simulating single-neuron activity</title><p>We used PD shift, gain, offset, and full models to fit neuronal activity. Neurons are fitted by single-trial data. We introduced a special sigmoid function to fit the nonlinear target-motion effects because target-velocity direction (CCW vs. CW) has a stronger effect than target-velocity magnitude (120 vs 240; <xref ref-type="bibr" rid="bib13">Churchland and Lisberger, 2001</xref>; <xref ref-type="bibr" rid="bib53">Pouget and Sejnowski, 1997</xref>). The gain and additive models refer to hand-velocity gain studies (<xref ref-type="bibr" rid="bib2">Amirikian and Georgopoulos, 2000</xref>; <xref ref-type="bibr" rid="bib25">Inoue et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Moran and Schwartz, 1999</xref>).</p><p>In the gain model, the target-motion effect on the amplitude of cosine tuning is denoted as:<disp-formula id="equ2"><mml:math id="m2"><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf5"><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:math></inline-formula> is the firing rate at the movement onset (MO ± 100ms). <inline-formula><mml:math id="inf6"><mml:mi>θ</mml:mi></mml:math></inline-formula> and <italic>vel</italic>. are the reach direction and target velocity, respectively; <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the fitted preferred direction of the neuron; <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are constants to be fitted.</p><p>In the additive model, the target velocity adjusts the offset activity, as:<disp-formula id="equ3"><mml:math id="m3"><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p><p>with similar symbols to the gain models, plus the new constant <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p>In the PD shift model, the target-motion effect on PDs is represented as:<disp-formula id="equ4"><mml:math id="m4"><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p><p>with the similar symbols to the above models.</p><p>The full model integrates all the three of the above effects:<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>with constants <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p>We fitted neuronal activity with these four models (MATLAB ‘fit’ function), and compared the fitting goodness with adjusted R-squares (<inline-formula><mml:math id="inf11"><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>j</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula>, where <inline-formula><mml:math id="inf12"><mml:mi>r</mml:mi></mml:math></inline-formula> is the original R-square, <inline-formula><mml:math id="inf13"><mml:mi>n</mml:mi></mml:math></inline-formula> is the trial number, and <inline-formula><mml:math id="inf14"><mml:mi>p</mml:mi></mml:math></inline-formula> is the degree of the polynomial).</p><p>Simulations with model neurons were based on three models to investigate the relationship between neuronal tuning (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) and population neural geometry (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). We first built three model neuron groups (each n=300) and performed PCA to obtain the neural state. Then, we repeated this in a mixed group, including 100 neurons in each of PD shift, gain and additive model (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Model neurons had three components: cosine-tuning for reach direction (<inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, PD uniformly distributed around the circle for each neuron <inline-formula><mml:math id="inf16"><mml:mi>n</mml:mi></mml:math></inline-formula>), Gaussian temporal profiles (<inline-formula><mml:math id="inf17"><mml:mi>t</mml:mi></mml:math></inline-formula>=1:200, σ=30, peak time <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>, the 100-th bin is the MO, random distribution for <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of neurons), and distinct target-motion modulation for each group. We designed five target velocity values (<inline-formula><mml:math id="inf20"><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1,2</mml:mn><mml:mo>,</mml:mo><mml:mn>3,4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>) and 64 reach directions (<inline-formula><mml:math id="inf21"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>360</mml:mn><mml:mo>∗</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>64</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula>), for 320 trials in total (<xref ref-type="bibr" rid="bib45">Michaels et al., 2016</xref>). The concrete expression of model neurons follows as below:</p><p>The gain-model neuron:<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>∗</mml:mo><mml:msup><mml:mn>30</mml:mn><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>∗</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>here, <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is randomized within [0, 1] for different neurons, modulating the target-motion gain in a sigmoidal function.</p><p>The PD-shift model neuron:<disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>∗</mml:mo><mml:msup><mml:mn>30</mml:mn><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>90</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>here,<inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a random value within [0, 1.5] for different neurons, and contributes to a sigmoidal function with target-motion shift on neuronal PD (<inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>).</p><p>The additive model:<disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:mi>F</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>∗</mml:mo><mml:msup><mml:mn>30</mml:mn><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>here, <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is also a random value within [0, 1] for different neurons, and adjusts the offset activity in a sigmoidal function with target-motion.</p><p>The firing rates of three groups of model neurons (K x N x T, 320x300 x 200) were averaged at the MO (mean T = [50:150]) to get the K x N (320x200) dataset for PCA. As with the real neural data, we selected the first three PCs (K x C, 320x3) to derive the simulated neural state shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></sec><sec id="s4-9"><title>RNNs training</title><p>For the inputs of RNNs, motor intention appears from MO-50 ms to MO, and is represented as constant variables in the form of two-dimensional Cartesian coordinates; target location is designed as time-varying two-dimensional Cartesian coordinates of the target throughout the entire trial; the GO-signal is a step function jumping from 0 to 1 at GO. Each RNN consists of 200 hidden units, and outputs hand velocity for accurate interception after the MO.</p><p>The RNN nodes evolve according to a standard dynamic differential equation:<disp-formula id="equ9"><mml:math id="m9"><mml:mi>τ</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>J</mml:mi><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>u</mml:mi></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf26"><mml:mi>τ</mml:mi></mml:math></inline-formula> is a time constant (here 50 ms), <italic>x</italic> is the activity, <inline-formula><mml:math id="inf27"><mml:mi>r</mml:mi></mml:math></inline-formula> is the firing rate, and <inline-formula><mml:math id="inf28"><mml:mi>u</mml:mi></mml:math></inline-formula> denotes the combined inputs. <inline-formula><mml:math id="inf29"><mml:mi>r</mml:mi></mml:math></inline-formula> can be calculated from <inline-formula><mml:math id="inf30"><mml:mi>x</mml:mi></mml:math></inline-formula> following:<disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The connection matrix <inline-formula><mml:math id="inf31"><mml:mi>J</mml:mi></mml:math></inline-formula> of hidden layer was randomly initialized with a normal distribution (mean = 0, sigma = <inline-formula><mml:math id="inf32"><mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>, g=1.5, N=200), and the connection between inputs and hidden units, the matrix <inline-formula><mml:math id="inf33"><mml:mi>B</mml:mi></mml:math></inline-formula>, was initialized as all zero. The initial states were zero vectors. The output <inline-formula><mml:math id="inf34"><mml:mi>z</mml:mi></mml:math></inline-formula> is obtained by<disp-formula id="equ11"><mml:math id="m11"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mi>r</mml:mi></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf35"><mml:mi>W</mml:mi></mml:math></inline-formula> is the read-out weight, and is expected to reproduce the desired hand velocity generated by bell-shaped physical equation (<xref ref-type="bibr" rid="bib29">Kao et al., 2021</xref>). <inline-formula><mml:math id="inf36"><mml:mi>W</mml:mi></mml:math></inline-formula> was also initiated as zero matrix. The loss function is:<disp-formula id="equ12"><mml:math id="m12"><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf37"><mml:mi>e</mml:mi></mml:math></inline-formula> is the mean squared error of <inline-formula><mml:math id="inf38"><mml:mi>z</mml:mi></mml:math></inline-formula> and training target. <inline-formula><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is a regularity (<xref ref-type="bibr" rid="bib67">Sussillo et al., 2015</xref>), denoting the magnitude of the nodes’ activity and calculated as activity squared summed across time. <inline-formula><mml:math id="inf40"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi>e</mml:mi><mml:mo>-</mml:mo><mml:mn>7</mml:mn></mml:math></inline-formula>. The optimization was realized with optim.Adam() based on PyTorch, the learning rate was 0.001.</p></sec><sec id="s4-10"><title>RNNs analyses</title><p>The classification of modulation type on network nodes was finished with the same procedure for real data as above. The firing rates of nodes ([0, 1]) were used for all analyses.</p><p>For decoding, similar to <italic>Population decoding</italic>, two SVM classifiers (Python, SVC from sklearn.svm, 10-fold cross-validation) were trained to decode reach direction and target motion of single trials in 100 ms window sliding with 50 ms step. It should be noted that, instead of original firing rates, the first 100 PCs were used for decoding, in order to decrease the influence of inactivated nodes. The decoding results were first averaged cross 10 cross-validation repetitions and then the resulting means were averaged across 100 models to obtain mean ± sd.</p><p>We performed Canonical Component Analysis (CCA) and Procrustes analysis to validate the similarity between data and network dynamics. The data were around the TO or around the MO each in 2 seconds (±1 s, 50 ms x 40 bins). The RNN activity were collected between MO-200 ms and MO +120ms, considering the shortest movement time, and then averaged into 40 bins for comparison. First, we performed PCA (Python, PCA from sklearn.decomposition) on actual and model data to get the first 30 PCs (KT x N → KT x 30), respectively. Then, we used these two-dimensional matrices to compute their first ten canonical components with CCA (Python, CCA from sklearn.cross_decomposition). The Pearson correlation coefficients (Python, pearsonr from scipy.stats) were calculated between paired canonical components. The Procrustes disparity (Python, procrustes from scipy.spatial) were computed between pairs of data and network first 30 PCs.</p></sec><sec id="s4-11"><title>RNNs experiments</title><p>We performed ablation of nodes and manipulation of connection weights. In former, we selected the nodes from a certain type of modulation, and set all its connection weights to zero to simulate ‘ablation’. When manipulating the connection between certain types of modulations, the selected connection weight was adjusted to be 1.5 times the original. Both above perturbations were retained for the entire trial. The perturbed network was tested with the same validation set of 500 trials as for the intact network.</p><p>We also constructed three alternative models to check the influence of input and weight initialization. The first one only receives motor intention and a GO-signal (GM); the second only receives target location and a Go-signal (GT); these two were initialized and trained as the main model. The third one was initialized with sparse connection (sparsity = 0.1); except for this, the input and the training were as the same as the main model. All involved modes shared the same validation set.</p></sec><sec id="s4-12"><title>Software</title><p>We used the Python 3.11 (<ext-link ext-link-type="uri" xlink:href="https://www.python.org/">python.org</ext-link>) and MATLAB 2018b (The MathWorks, Inc).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Data curation, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All procedures have been approved by the Biomedical Research Ethics Committee of Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences, under permit number ER-SlBS-221603P. They comply with national and local laws and regulations in China and are in accordance with the Guide for Care and Use of Laboratory Animals of the Institute for Laboratory Animal Research (version 20160310). All surgery was performed under anesthesia, and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Neural datasets.</title></caption><media xlink:href="elife-100064-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Neural dynamics similarity.</title></caption><media xlink:href="elife-100064-supp2-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>RNN perturbation results.</title></caption><media xlink:href="elife-100064-supp3-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp4"><label>Supplementary file 4.</label><caption><title>Alternative models.</title></caption><media xlink:href="elife-100064-supp4-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-100064-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The example experimental datasets and relevant analysis code have been deposited in <ext-link ext-link-type="uri" xlink:href="https://data.mendeley.com/datasets/8gngr6tphf">Mendeley Data</ext-link>. The RNN relevant code and example model datasets are available on <ext-link ext-link-type="uri" xlink:href="https://github.com/yunchenyc/RNN_ringlike_structure">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib12">Chen, 2025</xref>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Cui</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Neural Geometry from Mixed Sensorimotor Selectivity for Predictive Sensorimotor Control</data-title><source>Mendeley Data</source><pub-id pub-id-type="doi">10.17632/8gngr6tphf.2</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank C Li, J Malpeli, C Zheng, and R Zheng for helpful comments and discussions; C Guan for veterinary assistance; and P Ding, L Du, and Z Xiao for administrative support.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander</surname><given-names>GE</given-names></name><name><surname>Crutcher</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Neural representations of the target (goal) of visually guided arm movements in three motor areas of the monkey</article-title><source>Journal of Neurophysiology</source><volume>64</volume><fpage>164</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1152/jn.1990.64.1.164</pub-id><pub-id pub-id-type="pmid">2388063</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amirikian</surname><given-names>B</given-names></name><name><surname>Georgopoulos</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Directional tuning profiles of motor cortical cells</article-title><source>Neuroscience Research</source><volume>36</volume><fpage>73</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/s0168-0102(99)00112-1</pub-id><pub-id pub-id-type="pmid">10678534</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name><name><surname>Xing</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Multimodal representation of space in the posterior parietal cortex and its use in planning movements</article-title><source>Annual Review of Neuroscience</source><volume>20</volume><fpage>303</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.20.1.303</pub-id><pub-id pub-id-type="pmid">9056716</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Buneo</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Intentional maps in posterior parietal cortex</article-title><source>Annual Review of Neuroscience</source><volume>25</volume><fpage>189</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.25.112701.142922</pub-id><pub-id pub-id-type="pmid">12052908</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Cui</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Intention, action planning, and decision making in parietal-frontal circuits</article-title><source>Neuron</source><volume>63</volume><fpage>568</fpage><lpage>583</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.028</pub-id><pub-id pub-id-type="pmid">19755101</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Buneo</surname><given-names>CA</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Reach plans in eye-centered coordinates</article-title><source>Science</source><volume>285</volume><fpage>257</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1126/science.285.5425.257</pub-id><pub-id pub-id-type="pmid">10398603</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CircStat: a MATLAB toolbox for circular statistics</article-title><source>Journal of Statistical Software</source><volume>31</volume><fpage>128</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.18637/jss.v031.i10</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bremner</surname><given-names>LR</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Coding of the reach vector in parietal area 5d</article-title><source>Neuron</source><volume>75</volume><fpage>342</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.041</pub-id><pub-id pub-id-type="pmid">22841318</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brozović</surname><given-names>M</given-names></name><name><surname>Gail</surname><given-names>A</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Gain mechanisms for contextually guided visuomotor transformations</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>10588</fpage><lpage>10596</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2685-07.2007</pub-id><pub-id pub-id-type="pmid">17898230</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buneo</surname><given-names>CA</given-names></name><name><surname>Jarvis</surname><given-names>MR</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Direct visuomotor transformations for reaching</article-title><source>Nature</source><volume>416</volume><fpage>632</fpage><lpage>636</lpage><pub-id pub-id-type="doi">10.1038/416632a</pub-id><pub-id pub-id-type="pmid">11948351</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>SWC</given-names></name><name><surname>Papadimitriou</surname><given-names>C</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Using a compound gain field to compute a reach plan</article-title><source>Neuron</source><volume>64</volume><fpage>744</fpage><lpage>755</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.005</pub-id><pub-id pub-id-type="pmid">20005829</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>RNN_ringlike_structure</data-title><version designator="swh:1:rev:db463ea290461e6859abc504bf5a5cb11ecc77d3">swh:1:rev:db463ea290461e6859abc504bf5a5cb11ecc77d3</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:7dc1e099c4f175ff19a595096f3471bfb45e5149;origin=https://github.com/yunchenyc/RNN_ringlike_structure;visit=swh:1:snp:9c067dafa2fd1d4d0874ea1e0021783ca3f423fd;anchor=swh:1:rev:db463ea290461e6859abc504bf5a5cb11ecc77d3">https://archive.softwareheritage.org/swh:1:dir:7dc1e099c4f175ff19a595096f3471bfb45e5149;origin=https://github.com/yunchenyc/RNN_ringlike_structure;visit=swh:1:snp:9c067dafa2fd1d4d0874ea1e0021783ca3f423fd;anchor=swh:1:rev:db463ea290461e6859abc504bf5a5cb11ecc77d3</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Shifts in the population response in the middle temporal visual area parallel perceptual and motor illusions produced by apparent motion</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>9387</fpage><lpage>9402</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-23-09387.2001</pub-id><pub-id pub-id-type="pmid">11717372</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Foster</surname><given-names>JD</given-names></name><name><surname>Nuyujukian</surname><given-names>P</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Preparatory activity and the expansive null-space</article-title><source>Nature Reviews. Neuroscience</source><volume>25</volume><fpage>213</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/s41583-024-00796-z</pub-id><pub-id pub-id-type="pmid">38443626</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neural correlates of reaching decisions in dorsal premotor cortex: specification of multiple direction choices and final selection of action</article-title><source>Neuron</source><volume>45</volume><fpage>801</fpage><lpage>814</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.01.027</pub-id><pub-id pub-id-type="pmid">15748854</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>YE</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A common reference frame for movement plans in the posterior parietal cortex</article-title><source>Nature Reviews. Neuroscience</source><volume>3</volume><fpage>553</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1038/nrn873</pub-id><pub-id pub-id-type="pmid">12094211</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Forward prediction in the posterior parietal cortex and dynamic brain-machine interface</article-title><source>Frontiers in Integrative Neuroscience</source><volume>10</volume><elocation-id>35</elocation-id><pub-id pub-id-type="doi">10.3389/fnint.2016.00035</pub-id><pub-id pub-id-type="pmid">27833537</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dann</surname><given-names>B</given-names></name><name><surname>Michaels</surname><given-names>JA</given-names></name><name><surname>Schaffelhofer</surname><given-names>S</given-names></name><name><surname>Scherberger</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Uniting functional network topology and oscillations in the fronto-parietal single unit network of behaving primates</article-title><source>eLife</source><volume>5</volume><elocation-id>e15719</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.15719</pub-id><pub-id pub-id-type="pmid">27525488</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evarts</surname><given-names>EV</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Relation of pyramidal tract activity to force exerted during voluntary movement</article-title><source>Journal of Neurophysiology</source><volume>31</volume><fpage>14</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1152/jn.1968.31.1.14</pub-id><pub-id pub-id-type="pmid">4966614</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>AP</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name><name><surname>Caminiti</surname><given-names>R</given-names></name><name><surname>Massey</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex</article-title><source>The Journal of Neuroscience</source><volume>2</volume><fpage>1527</fpage><lpage>1537</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.02-11-01527.1982</pub-id><pub-id pub-id-type="pmid">7143039</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaser</surname><given-names>JI</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Ramkumar</surname><given-names>P</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Population coding of conditional probability distributions in dorsal premotor cortex</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1788</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04062-6</pub-id><pub-id pub-id-type="pmid">29725023</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hatsopoulos</surname><given-names>NG</given-names></name><name><surname>Amit</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Synthesizing complex movement fragment representations from motor cortical ensembles</article-title><source>Journal of Physiology, Paris</source><volume>106</volume><fpage>112</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2011.09.003</pub-id><pub-id pub-id-type="pmid">21939762</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hwang</surname><given-names>J</given-names></name><name><surname>Mitz</surname><given-names>AR</given-names></name><name><surname>Murray</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>NIMH MonkeyLogic: Behavioral control and data acquisition in MATLAB</article-title><source>Journal of Neuroscience Methods</source><volume>323</volume><fpage>13</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2019.05.002</pub-id><pub-id pub-id-type="pmid">31071345</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Inoue</surname><given-names>Y</given-names></name><name><surname>Mao</surname><given-names>H</given-names></name><name><surname>Suway</surname><given-names>SB</given-names></name><name><surname>Orellana</surname><given-names>J</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Decoding arm speed during reaching</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>5243</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-07647-3</pub-id><pub-id pub-id-type="pmid">30531921</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakei</surname><given-names>S</given-names></name><name><surname>Hoffman</surname><given-names>DS</given-names></name><name><surname>Strick</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Muscle and movement representations in the primary motor cortex</article-title><source>Science</source><volume>285</volume><fpage>2136</fpage><lpage>2139</lpage><pub-id pub-id-type="doi">10.1126/science.285.5436.2136</pub-id><pub-id pub-id-type="pmid">10497133</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakei</surname><given-names>S</given-names></name><name><surname>Hoffman</surname><given-names>DS</given-names></name><name><surname>Strick</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Direction of action is represented in the ventral premotor cortex</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>1020</fpage><lpage>1025</lpage><pub-id pub-id-type="doi">10.1038/nn726</pub-id><pub-id pub-id-type="pmid">11547338</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalaska</surname><given-names>JF</given-names></name><name><surname>Cohen</surname><given-names>DA</given-names></name><name><surname>Hyde</surname><given-names>ML</given-names></name><name><surname>Prud’homme</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>A comparison of movement direction-related versus load direction-related activity in primate motor cortex, using A two-dimensional reaching task</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>2080</fpage><lpage>2102</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-06-02080.1989</pub-id><pub-id pub-id-type="pmid">2723767</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname><given-names>TC</given-names></name><name><surname>Sadabadi</surname><given-names>MS</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Optimal anticipatory control as A theory of motor preparation: A thalamo-cortical circuit model</article-title><source>Neuron</source><volume>109</volume><fpage>1567</fpage><lpage>1581</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.03.009</pub-id><pub-id pub-id-type="pmid">33789082</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical activity in the null space: permitting preparation without movement</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/nn.3643</pub-id><pub-id pub-id-type="pmid">24487233</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Feierstein</surname><given-names>CE</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Qi</surname><given-names>XL</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Demixed principal component analysis of neural population data</article-title><source>eLife</source><volume>5</volume><elocation-id>10989</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id><pub-id pub-id-type="pmid">27067378</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruse</surname><given-names>W</given-names></name><name><surname>Dannenberg</surname><given-names>S</given-names></name><name><surname>Kleiser</surname><given-names>R</given-names></name><name><surname>Hoffmann</surname><given-names>K-P</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Temporal relation of population activity in visual areas MT/MST and in primary motor cortex during visually guided tracking movements</article-title><source>Cerebral Cortex</source><volume>12</volume><fpage>466</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1093/cercor/12.5.466</pub-id><pub-id pub-id-type="pmid">11950764</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwan</surname><given-names>HC</given-names></name><name><surname>MacKay</surname><given-names>WA</given-names></name><name><surname>Murphy</surname><given-names>JT</given-names></name><name><surname>Wong</surname><given-names>YC</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Properties of visual cue responses in primate precentral cortex</article-title><source>Brain Research</source><volume>343</volume><fpage>24</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(85)91154-0</pub-id><pub-id pub-id-type="pmid">3929999</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamarre</surname><given-names>Y</given-names></name><name><surname>Busby</surname><given-names>L</given-names></name><name><surname>Spidalieri</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Fast ballistic arm movements triggered by visual, auditory, and somesthetic stimuli in the monkey. I. Activity of precentral cortical neurons</article-title><source>Journal of Neurophysiology</source><volume>50</volume><fpage>1343</fpage><lpage>1358</lpage><pub-id pub-id-type="doi">10.1152/jn.1983.50.6.1343</pub-id><pub-id pub-id-type="pmid">6663331</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legland</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>MatGeom: a toolbox for geometry processing with MATLAB</article-title><source>SoftwareX</source><volume>29</volume><elocation-id>101984</elocation-id><pub-id pub-id-type="doi">10.1016/j.softx.2024.101984</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Cui</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Eye-hand coordination during flexible manual interception of an abruptly appearing, moving target</article-title><source>Journal of Neurophysiology</source><volume>119</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1152/jn.00476.2017</pub-id><pub-id pub-id-type="pmid">29021390</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Cui</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Posterior parietal cortex predicts upcoming movement in dynamic sensorimotor control</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2118903119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2118903119</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>X</given-names></name><name><surname>Ashe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Anticipatory activity in primary motor cortex codes memorized movement sequences</article-title><source>Neuron</source><volume>45</volume><fpage>967</fpage><lpage>973</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.01.036</pub-id><pub-id pub-id-type="pmid">15797556</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lurito</surname><given-names>JT</given-names></name><name><surname>Georgakopoulos</surname><given-names>T</given-names></name><name><surname>Georgopoulos</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Cognitive spatial-motor processes. 7. The making of movements at an angle from a stimulus direction: studies of motor cortical activity at the single cell and population levels</article-title><source>Experimental Brain Research</source><volume>87</volume><fpage>562</fpage><lpage>580</lpage><pub-id pub-id-type="doi">10.1007/BF00227082</pub-id><pub-id pub-id-type="pmid">1783027</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martínez-Vázquez</surname><given-names>P</given-names></name><name><surname>Gail</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Directed interaction between monkey premotor and posterior parietal cortex during motor-goal retrieval from working memory</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>1866</fpage><lpage>1881</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy035</pub-id><pub-id pub-id-type="pmid">29481586</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchant</surname><given-names>H</given-names></name><name><surname>Battaglia-Mayer</surname><given-names>A</given-names></name><name><surname>Georgopoulos</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Effects of optic flow in motor cortex and area 7a</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>1937</fpage><lpage>1954</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.4.1937</pub-id><pub-id pub-id-type="pmid">11600652</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchant</surname><given-names>H</given-names></name><name><surname>Battaglia-Mayer</surname><given-names>A</given-names></name><name><surname>Georgopoulos</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2004">2004a</year><article-title>Neural responses during interception of real and apparent circularly moving stimuli in motor cortex and area 7a</article-title><source>Cerebral Cortex</source><volume>14</volume><fpage>314</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhg130</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchant</surname><given-names>H</given-names></name><name><surname>Battaglia-Mayer</surname><given-names>A</given-names></name><name><surname>Georgopoulos</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2004">2004b</year><article-title>Neural responses in motor cortex and area 7a to real and apparent motion</article-title><source>Experimental Brain Research</source><volume>154</volume><fpage>291</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1007/s00221-003-1664-5</pub-id><pub-id pub-id-type="pmid">14579000</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaels</surname><given-names>JA</given-names></name><name><surname>Dann</surname><given-names>B</given-names></name><name><surname>Scherberger</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural population dynamics during reaching are better explained by a dynamical system than representational tuning</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005175</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005175</pub-id><pub-id pub-id-type="pmid">27814352</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moran</surname><given-names>DW</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Motor cortical representation of speed and direction during reaching</article-title><source>Journal of Neurophysiology</source><volume>82</volume><fpage>2676</fpage><lpage>2692</lpage><pub-id pub-id-type="doi">10.1152/jn.1999.82.5.2676</pub-id><pub-id pub-id-type="pmid">10561437</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Omrani</surname><given-names>M</given-names></name><name><surname>Murnaghan</surname><given-names>CD</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Scott</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distributed task-specific processing of somatosensory feedback for voluntary motor control</article-title><source>eLife</source><volume>5</volume><elocation-id>13141</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13141</pub-id><pub-id pub-id-type="pmid">27077949</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paninski</surname><given-names>L</given-names></name><name><surname>Fellows</surname><given-names>MR</given-names></name><name><surname>Hatsopoulos</surname><given-names>NG</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Spatiotemporal tuning of motor cortical neurons for hand position and velocity</article-title><source>Journal of Neurophysiology</source><volume>91</volume><fpage>515</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1152/jn.00587.2002</pub-id><pub-id pub-id-type="pmid">13679402</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Herikstad</surname><given-names>R</given-names></name><name><surname>Bong</surname><given-names>JH</given-names></name><name><surname>Medina</surname><given-names>FS</given-names></name><name><surname>Libedinsky</surname><given-names>C</given-names></name><name><surname>Yen</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mixed selectivity morphs population codes in prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1770</fpage><lpage>1779</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0003-2</pub-id><pub-id pub-id-type="pmid">29184197</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pesaran</surname><given-names>B</given-names></name><name><surname>Nelson</surname><given-names>MJ</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Dorsal premotor neurons encode the relative position of the hand, eye, and goal during reach planning</article-title><source>Neuron</source><volume>51</volume><fpage>125</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.05.025</pub-id><pub-id pub-id-type="pmid">16815337</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pesaran</surname><given-names>B</given-names></name><name><surname>Nelson</surname><given-names>MJ</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A relative position code for saccades in dorsal premotor cortex</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>6527</fpage><lpage>6537</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1625-09.2010</pub-id><pub-id pub-id-type="pmid">20463216</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Port</surname><given-names>NL</given-names></name><name><surname>Kruse</surname><given-names>W</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Georgopoulos</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Motor cortical activity during interception of moving targets</article-title><source>Journal of Cognitive Neuroscience</source><volume>13</volume><fpage>306</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1162/08989290151137368</pub-id><pub-id pub-id-type="pmid">11371309</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Spatial transformations in the parietal cortex using basis functions</article-title><source>Journal of Cognitive Neuroscience</source><volume>9</volume><fpage>222</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1162/jocn.1997.9.2.222</pub-id><pub-id pub-id-type="pmid">23962013</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Kurtzer</surname><given-names>I</given-names></name><name><surname>Nashed</surname><given-names>JY</given-names></name><name><surname>Omrani</surname><given-names>M</given-names></name><name><surname>Brouwer</surname><given-names>B</given-names></name><name><surname>Scott</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Primary motor cortex underlies multi-joint integration for fast feedback control</article-title><source>Nature</source><volume>478</volume><fpage>387</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1038/nature10436</pub-id><pub-id pub-id-type="pmid">21964335</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Nadasdy</surname><given-names>Z</given-names></name><name><surname>Ben-Shaul</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Unsupervised spike detection and sorting with wavelets and superparamagnetic clustering</article-title><source>Neural Computation</source><volume>16</volume><fpage>1661</fpage><lpage>1687</lpage><pub-id pub-id-type="doi">10.1162/089976604774201631</pub-id><pub-id pub-id-type="pmid">15228749</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>NG</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cue to action processing in motor cortex populations</article-title><source>Journal of Neurophysiology</source><volume>111</volume><fpage>441</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1152/jn.00274.2013</pub-id><pub-id pub-id-type="pmid">24174650</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Scandolara</surname><given-names>C</given-names></name><name><surname>Matelli</surname><given-names>M</given-names></name><name><surname>Gentilucci</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Afferent properties of periarcuate neurons in macaque monkeys. II. Visual responses</article-title><source>Behavioural Brain Research</source><volume>2</volume><fpage>147</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1016/0166-4328(81)90053-x</pub-id><pub-id pub-id-type="pmid">7248055</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russo</surname><given-names>AA</given-names></name><name><surname>Khajeh</surname><given-names>R</given-names></name><name><surname>Bittner</surname><given-names>SR</given-names></name><name><surname>Perkins</surname><given-names>SM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural trajectories in the supplementary motor area and motor cortex exhibit distinct geometries, compatible with different classes of computation</article-title><source>Neuron</source><volume>107</volume><fpage>745</fpage><lpage>758</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.05.020</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxena</surname><given-names>S</given-names></name><name><surname>Russo</surname><given-names>AA</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Motor cortex activity across movement speeds is predicted by network-level strategies for generating muscle activity</article-title><source>eLife</source><volume>11</volume><elocation-id>e67620</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.67620</pub-id><pub-id pub-id-type="pmid">35621264</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaffelhofer</surname><given-names>S</given-names></name><name><surname>Scherberger</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Object vision to hand action in macaque parietal, premotor, and motor cortices</article-title><source>eLife</source><volume>5</volume><elocation-id>e15278</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.15278</pub-id><pub-id pub-id-type="pmid">27458796</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>SH</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Reaching movements with similar hand paths but different arm orientations</article-title><source>I. Activity of Individual Cells in Motor Cortex. J Neurophysiol</source><volume>77</volume><fpage>826</fpage><lpage>852</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.2.826</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sergio</surname><given-names>LE</given-names></name><name><surname>Hamel-Pâquet</surname><given-names>C</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Motor cortex neural correlates of output kinematics and kinetics during isometric-force and arm-reaching tasks</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>2353</fpage><lpage>2378</lpage><pub-id pub-id-type="doi">10.1152/jn.00989.2004</pub-id><pub-id pub-id-type="pmid">15888522</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sobinov</surname><given-names>AR</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The neural mechanisms of manual dexterity</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>741</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00528-7</pub-id><pub-id pub-id-type="pmid">34711956</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stavisky</surname><given-names>SD</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Motor cortical visuomotor feedback activity is initially isolated from downstream targets in output-null neural state space dimensions</article-title><source>Neuron</source><volume>95</volume><fpage>195</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.023</pub-id><pub-id pub-id-type="pmid">28625485</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>O’Shea</surname><given-names>DJ</given-names></name><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Trautmann</surname><given-names>EM</given-names></name><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Cortical preparatory activity indexes learned motor memories</article-title><source>Nature</source><volume>602</volume><fpage>274</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-04329-x</pub-id><pub-id pub-id-type="pmid">35082444</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A neural network that finds A naturalistic solution for the production of muscle activity</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1025</fpage><lpage>1033</lpage><pub-id pub-id-type="doi">10.1038/nn.4042</pub-id><pub-id pub-id-type="pmid">26075643</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suway</surname><given-names>SB</given-names></name><name><surname>Schwartz</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Activity in primary motor cortex related to visual feedback</article-title><source>Cell Reports</source><volume>29</volume><fpage>3872</fpage><lpage>3884</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2019.11.069</pub-id><pub-id pub-id-type="pmid">31851920</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tkach</surname><given-names>D</given-names></name><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Hatsopoulos</surname><given-names>NG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Congruent activity during action and action observation in motor cortex</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>13241</fpage><lpage>13250</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2895-07.2007</pub-id><pub-id pub-id-type="pmid">18045918</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>O’Shea</surname><given-names>DJ</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Causal role of motor preparation during error-driven learning</article-title><source>Neuron</source><volume>106</volume><fpage>329</fpage><lpage>339</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.01.019</pub-id><pub-id pub-id-type="pmid">32053768</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Montanède</surname><given-names>C</given-names></name><name><surname>Chandrasekaran</surname><given-names>C</given-names></name><name><surname>Peixoto</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Macaque dorsal premotor cortex exhibits decision-related activity only when specific stimulus–response associations are known</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>09460-y</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-09460-y</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Cui</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>From parametric representation to dynamical system: shifting views of the motor cortex in motor control</article-title><source>Neuroscience Bulletin</source><volume>38</volume><fpage>796</fpage><lpage>808</lpage><pub-id pub-id-type="doi">10.1007/s12264-022-00832-x</pub-id><pub-id pub-id-type="pmid">35298779</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Cui</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Multiplicative joint coding in preparatory activity for reaching sequence in macaque motor cortex</article-title><source>Nature Communications</source><volume>15</volume><elocation-id>3153</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-024-47511-1</pub-id><pub-id pub-id-type="pmid">38605030</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimnik</surname><given-names>AJ</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Independent generation of sequence elements by motor cortex</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>412</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00798-5</pub-id><pub-id pub-id-type="pmid">33619403</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100064.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Imperial College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Useful</kwd></kwd-group></front-stub><body><p>This <bold>useful</bold> study examines the neural activity in the motor cortex as a monkey reaches to intercept moving targets, focusing on how tuned single neurons contribute to an interesting overall population geometry. The presented results and analyses are <bold>solid</bold>, though the investigation of this novel task could be strengthened by clarifying the assumptions behind the single neuron analyses, and further analyses of the neural population activity and its relation to different features of behaviour.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100064.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This study addresses the question of how task-relevant sensory information affects activity in motor cortex. The authors use various approaches to address this question, looking at single units and population activity. They find that there are three subtypes of modulation by sensory information at the single unit level. Population analyses reveal that sensory information affects the neural activity orthogonally to motor output. The authors then compare both single unit and population activity to computational models to investigate how encoding of sensory information at the single-unit level is coordinated in a network. They find that an RNN that displays similar orbital dynamics and sensory modulation to motor cortex also contains nodes that are modulated similarly to the three subtypes identified by the single unit analysis.</p><p>Strengths:</p><p>The strengths of this study lie in the population analyses and the approach of comparing single-unit encoding to population dynamics. In particular, the analysis in Figure 3 is very elegant and informative about the effect of sensory information on motor cortical activity. The task is also well designed to suit the questions being asked and well controlled.</p><p>It is commendable that the authors compare single-unit to population modulation. The addition of the RNN model and perturbations strengthen the conclusion that the subtypes of individual units all contribute to the population dynamics.</p><p>Weaknesses:</p><p>The main weaknesses of the study lie in the categorization of the single units into PD shift, gain and addition types. The single units exhibit clear mixed selectivity, as the authors highlight. Therefore, the subsequent analyses looking only at the individual classes in the RNN are a little limited. Another weakness of the paper is that the choice of windows for analyses is not properly justified and the dependence of the results on the time windows chosen for single unit analyses is not assessed. This is particularly pertinent because tuning curves are known to rotate during movements (Sergio et al. 2005 Journal of Neurophysiology).</p><p>This study uses insights from single-unit analysis to inform mechanistic models of these population dynamics, which is a powerful approach, but is dependent on the validity of the single-cell analysis, which I have expanded on below.</p><p>I have clarified some of the areas that would benefit from further analysis below:</p><p>Task:</p><p>The task is well designed, although it would have benefited from perhaps one more target speed (for each direction). One monkey appears to have experienced one more target speed than the others (seen in Figure 3C). It would have been nice to have this data for all monkeys, although, of course, unfeasible given that the study has been concluded.</p><p>Single unit analyses:</p><p>The choice of the three categories (PD shift, gain addition) is not completely justified in a satisfactory way. It would be nice to see whether these three main categories are confirmed by unsupervised methods.</p><p>The decoder analyses in Figure 2 provide evidence that target speed modulation may change over the trial. Therefore, it is important to see how the window considered for the firing rate in Figure 1 (currently 100ms pre - 100ms post movement onset) affects the results. Whilst it is of course understandable that a window must be chosen and will always be slightly arbitrary, using different windows and comparing the results of two or three different sizes or timed windows would be more convincing that the results are not dependent on this particular window.</p><p>RNN:</p><p>Mixed selectivity is not analysed in the RNN, which would help to compare the model to the real data where mixed selectivity is common. The CCA and Procrustes analysis are a good start to validate the claim of similarity between RNN and neural dynamics, rather than allowing comparisons to be dominated by geometric similarities that may be features of the task. However, some of the disparity values for the Procrustes analysis are quite high, albeit below that of the shuffle. Maybe a comment about this in the text should be included. There is also an absence of alternate models to compare the perturbation model results to.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100064.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this manuscript, Zhang et al. examine neural activity in motor cortex as monkeys make reaches in a novel target interception task. Zhang et al. begin by examining the single neuron tuning properties across different moving target conditions, finding several classes of neurons: those that shift their preferred direction, those that change their modulation gain, and those that shift their baseline firing rates. The authors go on to find an interesting, tilted ring structure of the neural population activity, depending on the target speed, and find that (1) the reach direction has consistent positioning around the ring, and (2) the tilt of the ring is highly predictive of the target movement speed. The authors then model the neural activity with a single neuron representational model and a recurrent neural network model, concluding that this population structure requires a mixture of the three types of single neurons described at the beginning of the manuscript.</p><p>Strengths:</p><p>I find the task the authors present here to be novel and exciting. It slots nicely into an overall trend to break away from a simple reach-to-static-target tasks to better characterize the breadth of how motor cortex generates movements. I also appreciate the movement from single neuron characterization to population activity exploration, which generally serves to anchor the results and make them concrete. Further, the orbital ring structure of population activity is fascinating, and the modeling work at the end serves as a useful baseline control to see how it might arise.</p><p>Weaknesses:</p><p>While I find the behavioral task presented here to be excitingly novel, I find the presented analyses and results to be far less interesting than they could be. Key to this, I think, is that the authors are examining this task and related neural activity primarily with a single-neuron representational lens. This would be fine as an initial analysis, since the population activity is of course composed of individual neurons, but the field seems to have largely moved towards a more abstract &quot;computation through dynamics&quot; framework that has, in the last several years, provided much more understanding of motor control than the representational framework has. As the manuscript stands now, I'm not entirely sure what interpretation to take away from the representational conclusions the authors made (i.e. the fact that the orbital population geometry arises from a mixture of different tuning types). As such, by the end of the manuscript, I'm not sure I understand any better how motor cortex or its neural geometry might be contributing to the execution of this novel task.</p><p>Main Comments:</p><p>My main suggestions to the authors revolve around bringing in the computation through a dynamics framework to strengthen their population results. The authors cite the Vyas et al. review paper on the subject, so I believe they are aware of this framework. I have three suggestions for improving or adding to the population results:</p><p>(1) Examination of delay period activity: one of the most interesting aspects of the task was the fact that the monkey had a random-length delay period before he could move to intercept the target. Presumably, the monkey had to prepare to intercept at any time between 400 and 800 ms, which means that there may be some interesting preparatory activity dynamics during this period. For example, after 400ms, does the preparatory activity rotate with the target such that once the go cue happens, the correct interception can be executed? There is some analysis of the delay period population activity in the supplement, but it doesn't quite get at the question of how the interception movement is prepared. This is perhaps the most interesting question that can be asked with this experiment, and it's one that I think may be quite novel for the field--it is a shame that it isn't discussed.</p><p>(2) Supervised examination of population structure via potent and null spaces: simply examining the first three principal components revealed an orbital structure, with a seemingly conserved motor output space and a dimension orthogonal to it that relates to the visual input. However, the authors don't push this insight any further. One way to do that would be to find the &quot;potent space&quot; of motor cortical activity by regression to the arm movement and examine how the tilted rings look in that space. Presumably, then, the null space should contain information about the target movement. The ring tilt will likely be evident if the authors look at the highest variance neural dimension orthogonal to the potent space (the &quot;null space&quot;)--this is akin to PC3 in the current figures, but it would be nice to see what comes out when you look in the data for it.</p><p>The authors attempt this sort of analysis in the supplement, alongside their dPCA results, but the results seem misinterpreted. The authors do identify one kind of output-potent space using the reach direction components of dPCA, and the reach directions are indeed aligned here. However, they then go on to interpret the target-velocity space as the output-null space, orthogonal to the potent space. There are two problems with this. (1) The target-velocity space is not necessarily orthogonal to the reach-direction space. This is a key aspect of dPCA--while the individual components within a particular marginalization space are orthogonal, the marginalization spaces themselves are not necessarily orthogonal unless they are forced to be (which the authors don't mention doing). (2) Even if the target-velocity space were orthogonal to the reach-direction space, it would not comprise the whole output-null space--such a null space would also include dimensions of neural population activity that have target-velocity/reach-direction interaction, which the authors show is a major component of neural population variance. Incidentally, the dPCA analysis the authors present shows what I would expect from their unsupervised results, but as it is written, the dPCA results are interpreted in a strange or potentially misleading way.</p><p>(3) RNN perturbations: as it's currently written, the RNN modeling has promise, but the perturbations performed don't provide me with much insight. I think this is because the authors are trying to use the RNN to interpret the single neuron tuning, but it's unclear to me what was learned from perturbing the connectivity between what seems to me almost arbitrary groups of neurons. It seems to me that a better perturbation might be to move the neural state before the movement onset to see how it changes the output. For example, the authors could move the neural state from one tilted ring to another to see if the virtual hand then reaches a completely different (yet predictable) target. Moreover, if the authors can more clearly characterize the preparatory movement, perhaps perturbations in the delay period would provide even more insight into how the interception might be prepared.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100064.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This experimental study investigates the influence of sensory information on neural population activity in M1 during a delayed reaching task. In the experiment, monkeys are trained to perform a delayed interception reach task, in which the goal is to intercept a potentially moving target.</p><p>This paradigm allows the authors to investigate how, given a fixed reach end point (which is assumed to correspond to a fixed motor output), the sensory information regarding the target motion is encoded in neural activity.</p><p>At the level of single neurons, the authors find that target motion modulates the activity is three main ways: gain modulation (scaling of the neural activity depending on the target direction), shift (shift of the preferred direction of neurons tuned to reach direction), or addition (offset to the neural activity).</p><p>At the level of the neural population, target motion information was largely encoded along the 3rd PC of the neural activity, leading to a tilt of the manifold along which reach direction was encoded that was proportional to target speed. The tilt of the neural manifold was found to be largely driven by the variation of activity of the population of gain modulated neurons.</p><p>Finally, the authors study the behaviour of an RNN trained to generate the correct hand velocity given the sensory input and reach direction. The RNN units are found to similarly exhibit mixed selectivity to the sensory information, and the geometry of the « neural population » resembles that observed in the monkeys.</p><p>Overall, the experiment is well set up to address the question of how sensory information that is directly relevant to the behaviour but does not lead to a direct change in behavioural output modulates motor cortical activity.</p><p>The finding that sensory information modulates the neural activity in M1 during motor preparation and execution is non trivial, given that this modulation of the activity must occur in the nullspace of the movement.</p><p>The authors provide analyses at both the single neuron and the population level, leading to a relatively complete characterization of the effect of the target motion on neural activity.</p><p>Additionally, they start exploring the link between the population geometry and the mixed selectivity of the single neurons in their RNN model. While they could be extended in future work, the analyses of the RNN provide a good starting point to address how exactly the task setup and constraints on the network shape the single neuron selectivity and the population geometry.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100064.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Yiheng</given-names></name><role specific-use="author">Author</role><aff><institution>Center for Excellence in Brain Science and Intelligence Technology</institution><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Yun</given-names></name><role specific-use="author">Author</role><aff><institution>Chinese Institute for Brain Research</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Tianwei</given-names></name><role specific-use="author">Author</role><aff><institution>German Primate Center</institution><addr-line><named-content content-type="city">Goettingen</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Cui</surname><given-names>He</given-names></name><role specific-use="author">Author</role><aff><institution>Chinese Institute for Brain Research</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>This study addresses the question of how task-relevant sensory information affects activity in the motor cortex. The authors use various approaches to address this question, looking at single units and population activity. They find that there are three subtypes of modulation by sensory information at the single unit level. Population analyses reveal that sensory information affects the neural activity orthogonally to motor output. The authors then compare both single unit and population activity to computational models to investigate how encoding of sensory information at the single unit level is coordinated in a network. They find that an RNN that displays similar orbital dynamics and sensory modulation to the motor cortex also contains nodes that are modulated similarly to the three subtypes identified by the single unit analysis.</p><p>Strengths:</p><p>The strengths of this study lie in the population analyses and the approach of comparing single-unit encoding to population dynamics. In particular, the analysis in Figure 3 is very elegant and informative about the effect of sensory information on motor cortical activity.</p><p>The task is also well designed to suit the questions being asked and well controlled.</p></disp-quote><p>We appreciate these kind comments.</p><disp-quote content-type="editor-comment"><p>It is commendable that the authors compare single units to population modulation. The addition of the RNN model and perturbations strengthen the conclusion that the subtypes of individual units all contribute to the population dynamics. However, the subtypes (PD shift, gain, and addition) are not sufficiently justified. The authors also do not address that single units exhibit mixed modulation, but RNN units are not treated as such.</p></disp-quote><p>We’re sorry that we didn’t provide sufficient grounds to introduce the subtypes. We have updated this in the revised manuscript, in Lines 102-104 as:</p><p>“We determined these modulations on the basis of the classical cosine tuning model (Georgopoulos et al., 1982) and several previous studies (Bremner and Andersen, 2012; Pesaran et al., 2010; Sergio et al., 2005).”</p><p>In our study, we applied the subtype analysis as a criterion to identify the modulation in neuron populations, rather than sorting neurons into exclusively different cell types.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>The main weaknesses of the study lie in the categorization of the single units into PD shift, gain, and addition types. The single units exhibit clear mixed selectivity, as the authors highlight. Therefore, the subsequent analyses looking only at the individual classes in the RNN are a little limited. Another weakness of the paper is that the choice of windows for analyses is not properly justified and the dependence of the results on the time windows chosen for single-unit analyses is not assessed. This is particularly pertinent because tuning curves are known to rotate during movements (Sergio et al. 2005 Journal of Neurophysiology).</p></disp-quote><p>In our study, the mixed selectivity or specifically the target-motion modulation on reach- direction tuning is a significant feature of the single neurons. We categorized the neurons into three subclasses, not intending to claim their absolute cell types, but meaning to distinguish target-motion modulation patterns. To further characterize these three patterns, we also investigated their interaction by perturbing connection weights in RNN.</p><p>Yes, it’s important to consider the role of rotating tuning curves in neural dynamics during interception. In our case, we observed population neural state with sliding windows, and we focused on the period around movement onset (MO) due to the unexpected ring-like structure and the highest decoding accuracy of transferred decoders (Figure S7C). Then, the single-unit analyses were implemented.</p><disp-quote content-type="editor-comment"><p>This paper shows sensory information can affect motor cortical activity whilst not affecting motor output. However, it is not the first to do so and fails to cite other papers that have investigated sensory modulation of the motor cortex (Stavinksy et al. 2017 Neuron, Pruszynski et al. 2011 Nature, Omrani et al. 2016 eLife). These studies should be mentioned in the Introduction to capture better the context around the present study. It would also be beneficial to add a discussion of how the results compare to the findings from these other works.</p></disp-quote><p>Thanks for the reminder. We’ve introduced these relevant researches in the updated manuscript in Lines 422-426 as:</p><p>“To further clarify, the discussing target-motion effect is different from the sensory modulation in action selection (Cisek and Kalaska, 2005), motor planning (Pesaran et al., 2006), visual replay and somatosensory feedback (Pruszynski et al., 2011; Stavisky et al., 2017; Suway and Schwartz, 2019; Tkach et al., 2007), because it occurred around movement onset and in predictive control trial-by-trial.”</p><disp-quote content-type="editor-comment"><p>This study also uses insights from single-unit analysis to inform mechanistic models of these population dynamics, which is a powerful approach, but is dependent on the validity of the single-cell analysis, which I have expanded on below.</p><p>I have clarified some of the areas that would benefit from further analysis below:</p><p>(1) Task:</p><p>The task is well designed, although it would have benefited from perhaps one more target speed (for each direction). One monkey appears to have experienced one more target speed than the others (seen in Figure 3C). It would have been nice to have this data for all monkeys.</p></disp-quote><p>A great suggestion; however, it is hardly feasible as the Utah arrays have already been removed.</p><disp-quote content-type="editor-comment"><p>(2) Single unit analyses:</p><p>In some analyses, the effects of target speed look more driven by target movement direction (e.g. Figures 1D and E). To confirm target speed is the main modulator, it would be good to compare how much more variance is explained by models including speed rather than just direction. More target speeds may have been helpful here too.</p></disp-quote><p>A nice suggestion. The fitting goodness of the simple model (only movement direction) is much worse than the complex models (including target speed). We’ve updated the results in the revised manuscript in Lines 119-122, as “We found that the adjusted R2 of a full model (0.55 ± 0.24, mean ± sd.) can be higher than that of the PD shift (0.47 ± 0.24), gain (0.46 ± 0.22), additive (0.41 ± 0.26), and simple models (only reach direction, 0.34 ± 0.25) for three monkeys (1162 neurons, ranksum test, one-tailed, p&lt;0.01, Figure S5).”</p><disp-quote content-type="editor-comment"><p>The choice of the three categories (PD shift, gain addition) is not completely justified in a satisfactory way. It would be nice to see whether these three main categories are confirmed by unsupervised methods.</p></disp-quote><p>A good point. It is a pity that we haven’t found an appropriate unsupervised method.</p><disp-quote content-type="editor-comment"><p>The decoder analyses in Figure 2 provide evidence that target speed modulation may change over the trial. Therefore, it is important to see how the window considered for the firing rate in Figure 1 (currently 100ms pre - 100ms post movement onset) affects the results.</p></disp-quote><p>Thanks for the suggestion and close reading. Because the movement onset (MO) is the key time point of this study, we colored this time period in Figure 1 to highlight the perimovement neuronal activity.</p><disp-quote content-type="editor-comment"><p>(3) Decoder:</p><p>One feature of the task is that the reach endpoints tile the entire perimeter of the target circle (Figure 1B). However, this feature is not exploited for much of the single-unit analyses. This is most notable in Figure 2, where the use of a SVM limits the decoding to discrete values (the endpoints are divided into 8 categories). Using continuous decoding of hand kinematics would be more appropriate for this task.</p></disp-quote><p>This is a very reasonable suggestion. In the revised manuscript, we’ve updated the continuous decoding results with support vector regression (SVR) in Figure S7A and in Lines 170-173 as:</p><p>“These results were stable on the data of the other two monkeys and the pseudopopulation of all three monkeys (Figure S6) and reconfirmed by the continuous decoding results with support vector regressions (Figure S7A), suggesting that target motion information existed in M1 throughout almost the entire trial.”</p><disp-quote content-type="editor-comment"><p>(4) RNN:</p><p>Mixed selectivity is not analysed in the RNN, which would help to compare the model to the real data where mixed selectivity is common. Furthermore, it would be informative to compare the neural data to the RNN activity using canonical correlation or Procrustes analyses. These would help validate the claim of similarity between RNN and neural dynamics, rather than allowing comparisons to be dominated by geometric similarities that may be features of the task. There is also an absence of alternate models to compare the perturbation model results to.</p></disp-quote><p>Thank you for these helpful suggestions. We have performed decoding analysis on RNN units and updated in Figure S12A and Lines 333-334 as: “First, from the decoding result, target motion information existed in nodes’ population dynamics shortly after TO (Figure S12A).”</p><p>We also have included the results of canonical correlation analysis and Procrustes analysis in Table S2 and Lines 340-342 as: “We then performed canonical component analysis (CCA) and Procrustes analysis (Table S2; see Methods), the results also indicated the similarity between network dynamics and neural dynamics.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>In this manuscript, Zhang et al. examine neural activity in the motor cortex as monkeys make reaches in a novel target interception task. Zhang et al. begin by examining the single neuron tuning properties across different moving target conditions, finding several classes of neurons: those that shift their preferred direction, those that change their modulation gain, and those that shift their baseline firing rates. The authors go on to find an interesting, tilted ring structure of the neural population activity, depending on the target speed, and find that (1) the reach direction has consistent positioning around the ring, and (2) the tilt of the ring is highly predictive of the target movement speed. The authors then model the neural activity with a single neuron representational model and a recurrent neural network model, concluding that this population structure requires a mixture of the three types of single neurons described at the beginning of the manuscript.</p><p>Strengths:</p><p>I find the task the authors present here to be novel and exciting. It slots nicely into an overall trend to break away from a simple reach-to-static-target task to better characterize the breadth of how the motor cortex generates movements. I also appreciate the movement from single neuron characterization to population activity exploration, which generally serves to anchor the results and make them concrete. Further, the orbital ring structure of population activity is fascinating, and the modeling work at the end serves as a useful baseline control to see how it might arise.</p></disp-quote><p>Thank you for your recognition of our work.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>While I find the behavioral task presented here to be excitingly novel, I find the presented analyses and results to be far less interesting than they could be. Key to this, I think, is that the authors are examining this task and related neural activity primarily with a singleneuron representational lens. This would be fine as an initial analysis since the population activity is of course composed of individual neurons, but the field seems to have largely moved towards a more abstract &quot;computation through dynamics&quot; framework that has, in the last several years, provided much more understanding of motor control than the representational framework has. As the manuscript stands now, I'm not entirely sure what interpretation to take away from the representational conclusions the authors made (i.e. the fact that the orbital population geometry arises from a mixture of different tuning types). As such, by the end of the manuscript, I'm not sure I understand any better how the motor cortex or its neural geometry might be contributing to the execution of this novel task.</p></disp-quote><p>This paper shows the sensory modulation on motor tuning in single units and neural population during motor execution period. It’s a pity that the findings were constrained in certain time windows. We are still working on this task, please look forward to our following work.</p><disp-quote content-type="editor-comment"><p>Main Comments:</p><p>My main suggestions to the authors revolve around bringing in the computation through a dynamics framework to strengthen their population results. The authors cite the Vyas et al. review paper on the subject, so I believe they are aware of this framework. I have three suggestions for improving or adding to the population results:</p><p>(1) Examination of delay period activity: one of the most interesting aspects of the task was the fact that the monkey had a random-length delay period before he could move to intercept the target. Presumably, the monkey had to prepare to intercept at any time between 400 and 800 ms, which means that there may be some interesting preparatory activity dynamics during this period. For example, after 400ms, does the preparatory activity rotate with the target such that once the go cue happens, the correct interception can be executed? There is some analysis of the delay period population activity in the supplement, but it doesn't quite get at the question of how the interception movement is prepared. This is perhaps the most interesting question that can be asked with this experiment, and it's one that I think may be quite novel for the field--it is a shame that it isn't discussed.</p></disp-quote><p>It’s a great idea! We are on the way, and it seems promising.</p><disp-quote content-type="editor-comment"><p>(2) Supervised examination of population structure via potent and null spaces: simply examining the first three principal components revealed an orbital structure, with a seemingly conserved motor output space and a dimension orthogonal to it that relates to the visual input. However, the authors don't push this insight any further. One way to do that would be to find the &quot;potent space&quot; of motor cortical activity by regression to the arm movement and examine how the tilted rings look in that space (this is actually fairly easy to see in the reach direction components of the dPCA plot in the supplement--the rings will be highly aligned in this space). Presumably, then, the null space should contain information about the target movement. dPCA shows that there's not a single dimension that clearly delineates target speed, but the ring tilt is likely evident if the authors look at the highest variance neural dimension orthogonal to the potent space (the &quot;null space&quot;)-this is akin to PC3 in the current figures, but it would be nice to see what comes out when you look in the data for it.</p></disp-quote><p>Thank you for this nice suggestion. While it was feasible to identify potent subspaces encoding reach direction and null spaces for target-velocity modulation, as suggested by the reviewer, the challenge remained that unsupervised methods were insufficient to isolate a pure target-velocity subspace from numerous possible candidates due to the small variance of target-velocity information. Although dPCA components can be used to construct orthogonal subspaces for individual task variables, we found that the targetvelocity information remained highly entangled with reach-direction representation. More details can be found in Figure S8C and its caption as below:</p><p>“We used dPCA components with different features to construct three subspaces (same data in A, reach-direction space #3, #4, #5; target-velocity space #10, #15, #17; interaction space #6, #11, #12), and we projected trial-averaged data into these orthogonal subspaces using different colormaps. This approach allowed us to obtain a “potent subspace” coding reach direction and a “null space” for target velocity. The results showed that the reach-direction subspace effectively represented the reach direction. However, while the target-velocity subspace encoded the target velocity information, it still contained reach-direction clusters within each target-velocity condition, corroborating the results of the addition model in the main text (Figure 4). The interaction subspace revealed that multiple reach-direction rings were nested within each other, similar to the findings from the gain model (Figure 3 &amp; 4). The interaction subspace also captured more variance than target-velocity subspace, consistent with our PCA results, suggesting the target-velocity modulation primarily coexists with reach-direction coding. Furthermore, we explored alternative methods to verify whether orthogonal subspaces could effectively separate the reach direction and target velocity. We could easily identify the reach-direction subspace, but its orthogonal subspace was relatively large, and the target-velocity information exhibited only small variance, making it difficult to isolate a subspace that purely encodes target velocity.”</p><disp-quote content-type="editor-comment"><p>(3) RNN perturbations: as it's currently written, the RNN modeling has promise, but the perturbations performed don't provide me with much insight. I think this is because the authors are trying to use the RNN to interpret the single neuron tuning, but it's unclear to me what was learned from perturbing the connectivity between what seems to me almost arbitrary groups of neurons (especially considering that 43% of nodes were unclassifiable). It seems to me that a better perturbation might be to move the neural state before the movement onset to see how it changes the output. For example, the authors could move the neural state from one tilted ring to another to see if the virtual hand then reaches a completely different (yet predictable) target. Moreover, if the authors can more clearly characterize the preparatory movement, perhaps perturbations in the delay period would provide even more insight into how the interception might be prepared.</p></disp-quote><p>We are sorry that we did not clarify the definition of “none” type, which can be misleading. The 43% unclassifiable nodes include those inactive ones; when only activate (taskrelated) nodes included, the ratio of unclassifiable nodes would be much lower. We recomputed the ratios with only activated units and have updated Table 1. By perturbing the connectivity, we intended to explore the interaction between different modulations.</p><p>Thank you for the great advice. We considered moving neural states from one ring to another without changing the directional cluster. However, we found that this perturbation design might not be fully developed: since the top two PCs are highly correlated with movement direction, such a move—similar to exchanging two states within the same cluster but under different target-motion conditions—would presumably not affect the behavior.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Summary:</p><p>This experimental study investigates the influence of sensory information on neural population activity in M1 during a delayed reaching task. In the experiment, monkeys are trained to perform a delayed interception reach task, in which the goal is to intercept a potentially moving target.</p><p>This paradigm allows the authors to investigate how, given a fixed reach endpoint (which is assumed to correspond to a fixed motor output), the sensory information regarding the target motion is encoded in neural activity.</p><p>At the level of single neurons, the authors found that target motion modulates the activity in three main ways: gain modulation (scaling of the neural activity depending on the target direction), shift (shift of the preferred direction of neurons tuned to reach direction), or addition (offset to the neural activity).</p><p>At the level of the neural population, target motion information was largely encoded along the 3rd PC of the neural activity, leading to a tilt of the manifold along which reach direction was encoded that was proportional to the target speed. The tilt of the neural manifold was found to be largely driven by the variation of activity of the population of gain-modulated neurons.</p><p>Finally, the authors studied the behaviour of an RNN trained to generate the correct hand velocity given the sensory input and reach direction. The RNN units were found to similarly exhibit mixed selectivity to the sensory information, and the geometry of the “ neural population” resembled that observed in the monkeys.</p><p>Strengths:</p><p>- The experiment is well set up to address the question of how sensory information that is directly relevant to the behaviour but does not lead to a direct change in behavioural output modulates motor cortical activity.</p><p>- The finding that sensory information modulates the neural activity in M1 during motor preparation and execution is non trivial, given that this modulation of the activity must occur in the nullspace of the movement.</p><p>- The paper gives a complete picture of the effect of the target motion on neural activity, by including analyses at the single neuron level as well as at the population level. Additionally, the authors link those two levels of representation by highlighting how gain modulation contributes to shaping the population representation.</p></disp-quote><p>Thank you for your recognition.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>- One of the main premises of the paper is the fact that the motor output for a given reach point is preserved across different target motions. However, as the authors briefly mention in the conclusion, they did not record muscle activity during the task, but only hand velocity, making it impossible to directly verify how preserved muscle patterns were across movements. While the authors highlight that they did not see any difference in their results when resampling the data to control for similar hand velocities across conditions, this seems like an important potential caveat of the paper whose implications should be discussed further or highlighted earlier in the paper.</p></disp-quote><p>Thanks for the suggestion. We’ve highlighted the resampling results as an important control in the revised manuscript in Figure S11 and Lines 257-260 as:</p><p>“To eliminate hand-speed effect, we resampled trials to construct a new dataset with similar distributions of hand speed in each target-motion condition and found similar orbital neural geometry. Moreover, the target-motion gain model provided a better explanation compared to the hand-speed gain model (Figure S11).”</p><disp-quote content-type="editor-comment"><p>- The main takeaway of the RNN analysis is not fully clear. The authors find that an RNN trained given a sensory input representing a moving target displays modulation to target motion that resembles what is seen in real data. This is interesting, but the authors do not dissect why this representation arises, and how robust it is to various task design choices. For instance, it appears that the network should be able to solve the task using only the motion intention input, which contains the reach endpoint information. If the target motion input is not used for the task, it is not obvious why the RNN units would be modulated by this input (especially as this modulation must lie in the nullspace of the movement hand velocity if the velocity depends only on the reach endpoint). It would thus be important to see alternative models compared to true neural activity, in addition to the model currently included in the paper. Besides, for the model in the paper, it would therefore be interesting to study further how the details of the network setup (eg initial spectral radius of the connectivity, weight regularization, or using only the target position input) affect the modulation by the motion input, as well as the trained population geometry and the relative ratios of modulated cells after training.</p></disp-quote><p>Great suggestions. In the revised manuscript, we’ve added the results of three alternative modes in Table S4 and Lines 355-365 as below:</p><p>“We also tested three alternative network models: (1) only receives motor intention and a GO-signal; (2) only receives target location and a GO-signal; (3) initialized with sparse connection (sparsity=0.1); the unmentioned settings and training strategies were as the same as those for original models (Table S4; see Methods). The results showed that the three modulations could emerge in these models as well, but with obviously distinctive distributions. In (1), the ring-like structure became overlapped rings parallel to the PC1PC2 plane or barrel-like structure instead; in (2), the target-motion related tilting tendency of the neural states remained, but the projection of the neural states on the PC1-PC2 plane was distorted and the reach-direction clusters dispersed. These implies that both motor intention and target location seem to be needed for the proposed ring-like structure. The initialization of connection weights of the hidden layer can influence the network’s performance and neural state structure, even so, the ring-like structure”</p><disp-quote content-type="editor-comment"><p>- Additionally, it is unclear what insights are gained from the perturbations to the network connectivity the authors perform, as it is generally expected that modulating the connectivity will degrade task performance and the geometry of the responses. If the authors wish the make claims about the role of the subpopulations, it could be interesting to test whether similar connectivity patterns develop in networks that are not initialized with an all-to-all random connectivity or to use ablation experiments to investigate whether the presence of multiple types of modulations confers any sort of robustness to the network.</p></disp-quote><p>Thank you for these great suggestions. By perturbations, we intended to explore the contribution of interaction between certain subpopulations. We’ve included the ablation experiments in the updated manuscript in Table S3 and Lines 344-346 as below: “The ablation experiments showed that losing any kind of modulation nodes would largely deteriorate the performance, and those nodes merely with PD-shift modulation could mostly impact the neural state structure (Table S3).”</p><disp-quote content-type="editor-comment"><p>- The results suggest that the observed changes in motor cortical activity with target velocity result from M1 activity receiving an input that encodes the velocity information. This also appears to be the assumption in the RNN model. However, even though the input shown to the animal during preparation is indeed a continuously moving target, it appears that the only relevant quantity to the actual movement is the final endpoint of the reach. While this would have to be a function of the target velocity, one could imagine that the computation of where the monkeys should reach might be performed upstream of the motor cortex, in which case the actual target velocity would become irrelevant to the final motor output. This makes the results of the paper very interesting, but it would be nice if the authors could discuss further when one might expect to see modulation by sensory information that does not directly affect motor output in M1, and where those inputs may come from. It may also be interesting to discuss how the findings relate to previous work that has found behaviourally irrelevant information is being filtered out from M1 (for instance, Russo et al, Neuron 2020 found that in monkeys performing a cycling task, context can be decoded from SMA but not from M1, and Wang et al, Nature Communications 2019 found that perceptual information could not be decoded from PMd)?</p></disp-quote><p>How and where sensory information modulating M1 are very interesting and open questions. In the revised manuscript, we discuss these in Lines 435-446, as below: “It would be interesting to explore whether other motor areas also allow sensory modulation during flexible interception. The functional differences between M1 and other areas lead to uncertain speculations. Although M1 has pre-movement activity, it is more related to task variables and motor outputs. Recently, a cycling task sets a good example that the supplementary motor area (SMA) encodes context information and the entire movement (Russo et al., 2020), while M1 preferably relates to cycling velocity (Saxena et al., 2022). The dorsal premotor area (PMd) has been reported to capture potential action selection and task probability, while M1 not (Cisek and Kalaska, 2005; Glaser et al., 2018; Wang et al., 2019). If the neural dynamics of other frontal motor areas are revealed, we might be able to tell whether the orbital neural geometry of mixed selectivity is unique in M1, or it is just inherited from upstream areas like PMd. Either outcome would provide us some insights into understanding the interaction between M1 and other frontal motor areas in motor planning.”</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>At times the writing was a little hard to parse. It could benefit from being fleshed out a bit to link sentences together better.</p><p>There are a few grammatical errors, such as:</p><p>&quot;These results support strong and similar roles of gain and additive nodes, but what is even more important is that the three modulations interact each other, so the PD-shift nodes should not be neglected.&quot;</p><p>should be</p><p>&quot;These results support strong and similar roles of gain and additive nodes, but what is even more important is that the three modulations interact WITH each other, so the PDshift nodes should not be neglected.&quot;</p><p>The discussion could also be more extensive to benefit non-experts in the field.</p></disp-quote><p>Thank you. We have proofread and polished the updated manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>Other comments:</p><p>- The authors mention mixed selectivity a few times, but Table 1 doesn't have a column for mixed selective neurons--this seems like an important oversight. Likewise, it would be good to see an example of a &quot;mixed&quot; neuron.</p><p>- The structure of the writing in the results section often talked about the supplementary results before the main results - this seems backwards. If the supplementary results are important enough to come before the main figures, then they should not be supplementary. Otherwise, if the results are truly supplementary, they should come after the main results are discussed.</p><p>- Line 305: Authors say &quot;most&quot; RNN units could be classified, and this is technically true, but only barely, according to Table 1. It might be good to put the actual percentage here in the text.</p><p>- Figure 5a: typo (&quot;Motion intention&quot; rather than &quot;Motor&quot;)</p><p>- I couldn't find any mention of code or data availability in the manuscript.</p><p>- There were a number of lines that didn't make much sense to me and should probably be rewritten or expanded on:</p><p>- Lines 167-168: &quot;These results qualitatively imply the interaction as that target speeds...&quot; - Lines 178-179: &quot;However, these neural trajectories were not yet the ideal description, because they were shaped mostly by time.&quot;</p><p>- Lines 187-188: &quot;...suggesting that target motion affects M1 neural dynamics via a topologically invariant transformation.&quot;</p><p>- Lines 224-226: &quot;Note that here we performed an linear transformation on all resulting neural state points to make the ellipse of the static condition orthogonal to the z-axis for better visualization.&quot; Does this mean that the z-axis is not PC 3 anymore?</p><p>- Lines 272-274: &quot;These simulations suggest that the existence of PD-shift and additive modulation would not disrupt the neural geometry that is primarily driven by gain modulation; rather it is possible that these three modulations support each other in a mixed population.&quot;</p></disp-quote><p>Thank you for these detailed suggestions. By “mixed selectivity”, we mean the joint tuning of both target-motion and movement. In this case, the target-motion modulated neurons (regardless of the modulation type) are of mixed selectivity. The term “motor intention” refers to Mazzoni et al., 1996, Journal of Neurophysiology. We also revised the manuscript for better readership.</p><p>We have updated the data and code availability in Data availability as below:</p><p>“The example experimental datasets and relevant analysis code have been deposited in Mendeley Data at <ext-link ext-link-type="uri" xlink:href="https://data.mendeley.com/datasets/8gngr6tphf">https://data.mendeley.com/datasets/8gngr6tphf</ext-link>. The RNN relevant code and example model datasets are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/yunchenyc/RNN_ringlike_structure">https://github.com/yunchenyc/RNN_ringlike_structure</ext-link>.“</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>Minor typos:</p><p>Line 153: “there were”</p><p>Line 301: “network was trained to generate”</p><p>Line 318: “interact with each other”</p><p>Suggested reformulations :</p><p>Line 310 : “tilting angles followed a pattern similar to that seen in the data” Line 187 : the claim of a “topologically invariant transformation” seems strong as the analysis is quite qualitative.</p><p>Suggested changes to the paper (aside from those mentioned in the main review): It could be nice to show behaviour in a main figure panel early on in the paper. This could help with the task description (as it would directly show how the trials are separated based on endpoint) and could allow for discussing the potential caveats of the assumption that behaviour is preserved.</p></disp-quote><p>Thank you. We have corrected these typos and writing problems. As the similar task design has been reported, we finally decided not to provide extra figures or videos. Still, we thank this nice suggestion.</p></body></sub-article></article>