<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">28728</article-id><article-id pub-id-type="doi">10.7554/eLife.28728</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Efficient and accurate extraction of in vivo calcium signals from microendoscopic video data</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-58658"><name><surname>Zhou</surname><given-names>Pengcheng</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1237-3931</contrib-id><email>zhoupc1988@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-89580"><name><surname>Resendez</surname><given-names>Shanna L</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="equal-contrib1">‚Ä†</xref><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-89488"><name><surname>Rodriguez-Romaguera</surname><given-names>Jose</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="equal-contrib1">‚Ä†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-89489"><name><surname>Jimenez</surname><given-names>Jessica C</given-names></name><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="fn" rid="equal-contrib1">‚Ä†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="other" rid="fund11"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-89490"><name><surname>Neufeld</surname><given-names>Shay Q</given-names></name><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="fn" rid="equal-contrib1">‚Ä†</xref><xref ref-type="other" rid="fund12"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-15272"><name><surname>Giovannucci</surname><given-names>Andrea</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7850-444X</contrib-id><xref ref-type="aff" rid="aff11">11</xref><xref ref-type="other" rid="fund13"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-102333"><name><surname>Friedrich</surname><given-names>Johannes</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1321-5866</contrib-id><xref ref-type="aff" rid="aff11">11</xref><xref ref-type="other" rid="fund13"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-102334"><name><surname>Pnevmatikakis</surname><given-names>Eftychios A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1509-6394</contrib-id><xref ref-type="aff" rid="aff11">11</xref><xref ref-type="other" rid="fund13"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-67000"><name><surname>Stuber</surname><given-names>Garret D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1730-4855</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff12">12</xref><xref ref-type="aff" rid="aff13">13</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund13"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-9852"><name><surname>Hen</surname><given-names>Rene</given-names></name><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="other" rid="fund11"/><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-89581"><name><surname>Kheirbek</surname><given-names>Mazen A</given-names></name><xref ref-type="aff" rid="aff14">14</xref><xref ref-type="aff" rid="aff15">15</xref><xref ref-type="aff" rid="aff16">16</xref><xref ref-type="aff" rid="aff17">17</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund14"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-24037"><name><surname>Sabatini</surname><given-names>Bernardo L</given-names></name><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="other" rid="fund15"/><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-89582"><name><surname>Kass</surname><given-names>Robert E</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff18">18</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-17187"><name><surname>Paninski</surname><given-names>Liam</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="aff" rid="aff19">19</xref><xref ref-type="aff" rid="aff20">20</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund13"/><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Center for the Neural Basis of Cognition</institution><institution>Carnegie Mellon University</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Statistics</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Machine Learning Department</institution><institution>Carnegie Mellon University</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">Grossman Center for the Statistics of Mind</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution content-type="dept">Center for Theoretical Neuroscience</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution content-type="dept">Department of Psychiatry</institution><institution>University of North Carolina at Chapel Hill</institution><addr-line><named-content content-type="city">Chapel Hill</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution content-type="dept">Department of Neuroscience</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff8"><label>8</label><institution content-type="dept">Division of Integrative Neuroscience, Department of Psychiatry</institution><institution>New York State Psychiatric Institute</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff9"><label>9</label><institution content-type="dept">Department of Psychiatry &amp; Pharmacology</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff10"><label>10</label><institution content-type="dept">Department of Neurobiology</institution><institution>Harvard Medical School, Howard Hughes Medical Institute</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff11"><label>11</label><institution content-type="dept">Center for Computational Biology</institution><institution>Flatiron Institute, Simons Foundation</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff12"><label>12</label><institution content-type="dept">Department of Cell Biology and Physiology</institution><institution>University of North Carolina at Chapel Hill</institution><addr-line><named-content content-type="city">Chapel Hill</named-content></addr-line><country>United States</country></aff><aff id="aff13"><label>13</label><institution content-type="dept">Neuroscience Center</institution><institution>University of North Carolina at Chapel Hill</institution><addr-line><named-content content-type="city">Chapel Hill</named-content></addr-line><country>United States</country></aff><aff id="aff14"><label>14</label><institution content-type="dept">Weill Institute for Neurosciences</institution><institution>University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff15"><label>15</label><institution content-type="dept">Neuroscience Graduate Program</institution><institution>University of California</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff16"><label>16</label><institution content-type="dept">Kavli Institute for Fundamental Neuroscience</institution><institution>University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff17"><label>17</label><institution content-type="dept">Department of Psychiatry</institution><institution>University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff18"><label>18</label><institution content-type="dept">Department of Statistics</institution><institution>Carnegie Mellon University</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff19"><label>19</label><institution content-type="dept">Kavli Institute for Brain Science</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff20"><label>20</label><institution content-type="dept">Neurotechnology Center</institution><institution>Columbia University</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-16662"><name><surname>Van Essen</surname><given-names>David C</given-names></name><role>Reviewing Editor</role><aff id="aff21"><institution>Washington University in St. Louis</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>‚Ä†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>22</day><month>02</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e28728</elocation-id><history><date date-type="received" iso-8601-date="2017-05-19"><day>19</day><month>05</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2018-02-20"><day>20</day><month>02</month><year>2018</year></date></history><permissions><copyright-statement>¬© 2018, Zhou et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Zhou et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-28728-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.28728.001</object-id><p>In vivo calcium imaging through microendoscopic lenses enables imaging of previously inaccessible neuronal populations deep within the brains of freely moving animals. However, it is computationally challenging to extract single-neuronal activity from microendoscopic data, because of the very large background fluctuations and high spatial overlaps intrinsic to this recording modality. Here, we describe a new constrained matrix factorization approach to accurately separate the background and then demix and denoise the neuronal signals of interest. We compared the proposed method against previous independent components analysis and constrained nonnegative matrix factorization approaches. On both simulated and experimental data recorded from mice, our method substantially improved the quality of extracted cellular signals and detected more well-isolated neural signals, especially in noisy data regimes. These advances can in turn significantly enhance the statistical power of downstream analyses, and ultimately improve scientific conclusions derived from microendoscopic data.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>calcium imaging</kwd><kwd>microendoscope</kwd><kwd>source extraction</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Zhou</surname><given-names>Pengcheng</given-names></name><name><surname>Jimenez</surname><given-names>Jessica C</given-names></name><name><surname>Hen</surname><given-names>Rene</given-names></name><name><surname>Kheirbek</surname><given-names>Mazen A</given-names></name><name><surname>Kass</surname><given-names>Robert E</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000026</institution-id><institution>National Institute on Drug Abuse</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Zhou</surname><given-names>Pengcheng</given-names></name><name><surname>Rodriguez-Romaguera</surname><given-names>Jose</given-names></name><name><surname>Stuber</surname><given-names>Garret D</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011039</institution-id><institution>Intelligence Advanced Research Projects Activity</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Zhou</surname><given-names>Pengcheng</given-names></name><name><surname>Paninski</surname><given-names>Liam</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000185</institution-id><institution>Defense Advanced Research Projects Agency</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Paninski</surname><given-names>Liam</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000183</institution-id><institution>Army Research Office</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Paninski</surname><given-names>Liam</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Paninski</surname><given-names>Liam</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009633</institution-id><institution>Eunice Kennedy Shriver National Institute of Child Health and Human Development</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Resendez</surname><given-names>Shanna L</given-names></name><name><surname>Stuber</surname><given-names>Garret D</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jimenez</surname><given-names>Jessica C</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000049</institution-id><institution>National Institute on Aging</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jimenez</surname><given-names>Jessica C</given-names></name><name><surname>Hen</surname><given-names>Rene</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution>New York State Stem Cell Science</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jimenez</surname><given-names>Jessica C</given-names></name><name><surname>Hen</surname><given-names>Rene</given-names></name></principal-award-recipient></award-group><award-group id="fund11"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006346</institution-id><institution>Hope for Depression Research Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jimenez</surname><given-names>Jessica C</given-names></name><name><surname>Hen</surname><given-names>Rene</given-names></name></principal-award-recipient></award-group><award-group id="fund12"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Neufeld</surname><given-names>Shay Q</given-names></name></principal-award-recipient></award-group><award-group id="fund13"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Giovannucci</surname><given-names>Andrea</given-names></name><name><surname>Friedrich</surname><given-names>Johannes</given-names></name><name><surname>Pnevmatikakis</surname><given-names>Eftychios A</given-names></name><name><surname>Stuber</surname><given-names>Garret D</given-names></name><name><surname>Paninski</surname><given-names>Liam</given-names></name></principal-award-recipient></award-group><award-group id="fund14"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006932</institution-id><institution>International Mental Health Research Organization</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Kheirbek</surname><given-names>Mazen A</given-names></name></principal-award-recipient></award-group><award-group id="fund15"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Sabatini</surname><given-names>Bernardo L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A new open-source computational toolbox for processing in vivo microendoscopic calcium imaging data performs signal demixing and denoising much more accurately than previously available methods, significantly improving the utility of this imaging modality.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Monitoring the activity of large-scale neuronal ensembles during complex behavioral states is fundamental to neuroscience research. Continued advances in optical imaging technology are greatly expanding the size and depth of neuronal populations that can be visualized. Specifically, in vivo calcium imaging through microendoscopic lenses and the development of miniaturized microscopes have enabled deep brain imaging of previously inaccessible neuronal populations of freely moving mice (<xref ref-type="bibr" rid="bib13">Flusberg et al., 2008</xref>; <xref ref-type="bibr" rid="bib16">Ghosh et al., 2011</xref>; <xref ref-type="bibr" rid="bib61">Ziv and Ghosh, 2015</xref>). This technique has been widely used to study the neural circuits in cortical, subcortical, and deep brain areas, such as hippocampus (<xref ref-type="bibr" rid="bib4">Cai et al., 2016</xref>; <xref ref-type="bibr" rid="bib60">Ziv et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Jimenez et al., 2018</xref>;¬†<xref ref-type="bibr" rid="bib46">Rubin et al., 2015</xref>), entorhinal cortex (<xref ref-type="bibr" rid="bib26">Kitamura et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Sun et al., 2015</xref>), hypothalamus (<xref ref-type="bibr" rid="bib22">Jennings et al., 2015</xref>), prefrontal cortex (PFC) (<xref ref-type="bibr" rid="bib39">Pinto and Dan, 2015</xref>), premotor cortex (<xref ref-type="bibr" rid="bib31">Markowitz et al., 2015</xref>), dorsal pons (<xref ref-type="bibr" rid="bib9">Cox et al., 2016</xref>), basal forebrain (<xref ref-type="bibr" rid="bib20">Harrison et al., 2016</xref>), striatum (<xref ref-type="bibr" rid="bib2">Barbera et al., 2016</xref>; <xref ref-type="bibr" rid="bib6">Carvalho Poyraz et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Klaus et al., 2017</xref>), amygdala (<xref ref-type="bibr" rid="bib56">Yu et al., 2017</xref>), and other brain regions.</p><p>Although microendoscopy has potential applications across numerous neuroscience fields (<xref ref-type="bibr" rid="bib61">Ziv and Ghosh, 2015</xref>), methods for extracting cellular signals from this data are currently limited and suboptimal. Most existing methods are specialized for two-photon or light-sheet microscopy. However, these methods are not suitable for analyzing single-photon microendoscopic data because of its distinct features: specifically, this data typically displays large, blurry background fluctuations due to fluorescence contributions from neurons outside the focal plane. In <xref ref-type="fig" rid="fig1">Figure 1</xref>, we use a typical microendoscopic dataset to illustrate these effects (see <xref ref-type="video" rid="video1">Video 1</xref> for raw video). <xref ref-type="fig" rid="fig1">Figure 1A</xref> shows an example frame of the selected data, which contains large signals additional to the neurons visible in the focal plane. These extra fluorescence signals contribute as background that contaminates the single-neuronal signals of interest. In turn, standard methods based on local correlations for visualizing cell outlines (<xref ref-type="bibr" rid="bib49">Smith and H√§usser, 2010</xref>) are not effective here, because the correlations in the fluorescence of nearby pixels are dominated by background signals (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). For some neurons with strong visible signals, we can manually draw regions-of-interest (ROI) (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Following (<xref ref-type="bibr" rid="bib2">Barbera et al., 2016</xref>; <xref ref-type="bibr" rid="bib39">Pinto and Dan, 2015</xref>), we used the mean fluorescence trace of the surrounding pixels (blue, <xref ref-type="fig" rid="fig1">Figure 1D</xref>) to roughly estimate this background fluctuation; subtracting it from the raw trace in the neuron ROI yields a relatively good estimation of neuron signal (red, <xref ref-type="fig" rid="fig1">Figure 1D</xref>). <xref ref-type="fig" rid="fig1">Figure 1D</xref> shows that the background (blue) has much larger variance than the relatively sparse neural signal (red); moreover, the background signal fluctuates on similar timescales as the single-neuronal signal, so we can not simply temporally filter the background away after extraction of the mean signal within the ROI. This large background signal is likely due to a combination of local fluctuations resulting from out-of-focus fluorescence or neuropil activity, hemodynamics of blood vessels, and global fluctuations shared more broadly across the field of view (photo-bleaching effects, drifts in <inline-formula><mml:math id="inf1"><mml:mi>z</mml:mi></mml:math></inline-formula> of the focal plane, etc.), as illustrated schematically in <xref ref-type="fig" rid="fig1">Figure 1E</xref>.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.002</object-id><label>Figure 1.</label><caption><title>Microendoscopic data contain large background signals with rapid fluctuations due to multiple sources.</title><p>(<bold>A</bold>) An example frame of microendoscopic data recorded in dorsal striatum (see Materials and¬†methods¬†section for experimental details). (<bold>B</bold>) The local ‚Äòcorrelation image‚Äô (<xref ref-type="bibr" rid="bib49">Smith and H√§usser, 2010</xref>) computed from the raw video data. Note that it is difficult to discern neuronal shapes in this image due to the high background spatial correlation level. (<bold>C</bold>) The mean-subtracted data within the cropped area (green) in (<bold>A</bold>). Two ROIs were selected and coded with different colors. (<bold>D</bold>) The mean fluorescence traces of pixels within the two selected ROIs (magenta and blue) shown in (<bold>C</bold>) and the difference between the two traces. (<bold>E</bold>) Cartoon illustration of various sources of fluorescence signals in microendoscopic data. ‚ÄòBG‚Äô abbreviates ‚Äòbackground‚Äô.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig1-v2"/></fig><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.003</object-id><label>Video 1.</label><caption><title>An example of typical microendoscopic data.</title><p>The video was recorded in dorsal striatum; experimental details can be found above. MP4</p></caption></media><p>The existing methods for extracting individual neural activity from microendoscopic data can be divided into two classes: semi-manual ROI analysis (<xref ref-type="bibr" rid="bib2">Barbera et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Klaus et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Pinto and Dan, 2015</xref>) and PCA/ICA analysis (<xref ref-type="bibr" rid="bib33">Mukamel et al., 2009</xref>). Unfortunately, both approaches have well-known flaws (<xref ref-type="bibr" rid="bib43">Resendez et al., 2016</xref>). For example, ROI analysis does not effectively demix signals of spatially overlapping neurons, and drawing ROIs is laborious for large population recordings. More importantly, in many cases, the background contaminations are not adequately corrected, and thus the extracted signals are not sufficiently clean enough for downstream analyses. As for PCA/ICA analysis, it is a linear demixing method and therefore typically fails when the neural components exhibit strong spatial overlaps (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>), as is the case in the microendoscopic setting.</p><p>Recently, constrained nonnegative matrix factorization (CNMF) approaches were proposed to simultaneously denoise, deconvolve, and demix calcium imaging data (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>). However, current implementations of the CNMF approach were optimized for <inline-formula><mml:math id="inf2"><mml:mn>2</mml:mn></mml:math></inline-formula>-photon and light-sheet microscopy, where the background has a simpler spatiotemporal structure. When applied to microendoscopic data, CNMF often has poor performance because the background is not modeled sufficiently accurately (<xref ref-type="bibr" rid="bib2">Barbera et al., 2016</xref>).</p><p>In this paper, we significantly extend the CNMF framework to obtain a robust approach for extracting single-neuronal signals from microendoscopic data. Specifically, our extended CNMF for microendoscopic data (CNMF-E) approach utilizes a more accurate and flexible spatiotemporal background model that is able to handle the properties of the strong background signal illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>, along with new specialized algorithms to initialize and fit the model components. After a brief description of the model and algorithms, we first use simulated data to illustrate the power of the new approach. Next, we compare CNMF-E with PCA/ICA analysis comprehensively on both simulated data and four experimental datasets recorded in different brain areas. The results show that CNMF-E outperforms PCA/ICA in terms of detecting more well-isolated neural signals, extracting higher signal-to-noise ratio (SNR) cellular signals, and obtaining more robust results in low SNR regimes. Finally, we show that downstream analyses of calcium imaging data can substantially benefit from these improvements.</p><sec id="s1-1"><title>Model and model fitting</title><sec id="s1-1-1"><title>CNMF for microendoscope data (CNMF-E)</title><p>The recorded video data can be represented by a matrix <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>‚àà</mml:mo><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf4"><mml:mi>d</mml:mi></mml:math></inline-formula> is the number of pixels in the field of view and <inline-formula><mml:math id="inf5"><mml:mi>T</mml:mi></mml:math></inline-formula> is the number of frames observed. In our model, each neuron <inline-formula><mml:math id="inf6"><mml:mi>i</mml:mi></mml:math></inline-formula> is characterized by its spatial ‚Äòfootprint‚Äô vector <inline-formula><mml:math id="inf7"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚àà</mml:mo><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> characterizing the cell‚Äôs shape and location, and ‚Äòcalcium activity‚Äô timeseries <inline-formula><mml:math id="inf8"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚àà</mml:mo><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, modeling (up to a multiplicative and additive constant) cell <inline-formula><mml:math id="inf9"><mml:mi>i</mml:mi></mml:math></inline-formula>‚Äôs mean fluorescence signal at each frame. Here, both <inline-formula><mml:math id="inf10"><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf11"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are constrained to be nonnegative because of their physical interpretations. The background fluctuation is represented by a matrix <inline-formula><mml:math id="inf12"><mml:mrow><mml:mi>B</mml:mi><mml:mo>‚àà</mml:mo><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. If the field of view contains a total number of <inline-formula><mml:math id="inf13"><mml:mi>K</mml:mi></mml:math></inline-formula> neurons, then the observed movie data is modeled as a superposition of all neurons‚Äô spatiotemporal activity, plus time-varying background and additive noise:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">‚àë</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>E</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">‚Ä¶</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">‚Ä¶</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>. The noise term <inline-formula><mml:math id="inf16"><mml:mrow><mml:mi>E</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mi>‚Ñù</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is modeled as Gaussian, <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àº</mml:mo><mml:mrow><mml:mi mathvariant="script">ùí©</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Œ£</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a diagonal matrix, indicating that the noise is spatially and temporally uncorrelated.</p><p>Estimating the model parameters <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> in model (1) gives us all neurons‚Äô spatial footprints and their denoised temporal activity. This can be achieved by minimizing the residual sum of squares (RSS), aka the Frobenius norm of the matrix <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>‚à•</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>‚à•</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>while requiring the model variables <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf21"><mml:mi>B</mml:mi></mml:math></inline-formula> to follow the desired constraints, discussed below.</p></sec></sec><sec id="s1-2"><title>Constraints on neuronal spatial footprints <inline-formula><mml:math id="inf22"><mml:mi>A</mml:mi></mml:math></inline-formula> and neural temporal traces <inline-formula><mml:math id="inf23"><mml:mi>C</mml:mi></mml:math></inline-formula></title><p>Each spatial footprint <inline-formula><mml:math id="inf24"><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> should be spatially localized and sparse, since a given neuron will cover only a small fraction of the field of view, and therefore most elements of <inline-formula><mml:math id="inf25"><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> will be zero. Thus, we need to incorporate spatial locality and sparsity constraints on <inline-formula><mml:math id="inf26"><mml:mi>A</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>). We discuss details further below.</p><p>Similarly, the temporal components <inline-formula><mml:math id="inf27"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are highly structured, as they represent the cells‚Äô fluorescence responses to sparse, nonnegative trains of action potentials. Following (<xref ref-type="bibr" rid="bib53">Vogelstein et al., 2010</xref>; <xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>), we model the calcium dynamics of each neuron <inline-formula><mml:math id="inf28"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> with a stable autoregressive (AR) process of order <inline-formula><mml:math id="inf29"><mml:mi>p</mml:mi></mml:math></inline-formula>,¬†<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">‚àë</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>Œ≥</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>‚Å¢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf30"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is the number of spikes that neuron fired at the <inline-formula><mml:math id="inf31"><mml:mi>t</mml:mi></mml:math></inline-formula>-th frame. (Note that there is no further noise input into <inline-formula><mml:math id="inf32"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> beyond the spike signal <inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.) The AR coefficients <inline-formula><mml:math id="inf34"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msubsup><mml:mi>Œ≥</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> are different for each neuron and they are estimated from the data. In practice, we usually pick <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, thus incorporating both a nonzero rise and decay time of calcium transients in response to a spike; then <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> can be expressed in matrix form as<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext>¬†with¬†</mml:mtext><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>‚ãØ</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>‚àí</mml:mo><mml:msubsup><mml:mi>Œ≥</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>‚ãØ</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>‚àí</mml:mo><mml:msubsup><mml:mi>Œ≥</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>‚àí</mml:mo><mml:msubsup><mml:mi>Œ≥</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mo>‚ãØ</mml:mo></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>‚ãÆ</mml:mo></mml:mtd><mml:mtd><mml:mo>‚ã±</mml:mo></mml:mtd><mml:mtd><mml:mo>‚ã±</mml:mo></mml:mtd><mml:mtd><mml:mo>‚ã±</mml:mo></mml:mtd><mml:mtd><mml:mo>‚ãÆ</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>‚ãØ</mml:mo></mml:mtd><mml:mtd><mml:mo>‚àí</mml:mo><mml:msubsup><mml:mi>Œ≥</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>‚àí</mml:mo><mml:msubsup><mml:mi>Œ≥</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The neural activity <inline-formula><mml:math id="inf36"><mml:msub><mml:mi mathvariant="bold-italic">ùíî</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is nonnegative and typically sparse; to enforce sparsity, we can penalize the <inline-formula><mml:math id="inf37"><mml:msub><mml:mi mathvariant="normal">‚Ñì</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib23">Jewell and Witten, 2017</xref>) or <inline-formula><mml:math id="inf38"><mml:msub><mml:mi mathvariant="normal">‚Ñì</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Vogelstein et al., 2010</xref>) norm of <inline-formula><mml:math id="inf39"><mml:msub><mml:mi mathvariant="bold-italic">ùíî</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, or limit the minimum size of nonzero spike counts (<xref ref-type="bibr" rid="bib15">Friedrich et al., 2017b</xref>). When the rise time constant is small compared to the timebin width (low imaging frame rate), we typically use a simpler AR(1) model (with an instantaneous rise following a spike) (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>).</p></sec><sec id="s1-3"><title>Constraints on background activity <inline-formula><mml:math id="inf40"><mml:mi>B</mml:mi></mml:math></inline-formula></title><p>In the above we have largely followed previously¬†described CNMF approaches (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>) for modeling calcium imaging signals. However, to accurately model the background effects in microendoscopic data, we need to depart significantly from these previous approaches. Constraints on the background term <inline-formula><mml:math id="inf41"><mml:mi>B</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref> are essential to the success of CNMF-E, since clearly, if <inline-formula><mml:math id="inf42"><mml:mi>B</mml:mi></mml:math></inline-formula> is completely unconstrained we could just absorb the observed data <inline-formula><mml:math id="inf43"><mml:mi>Y</mml:mi></mml:math></inline-formula> entirely into <inline-formula><mml:math id="inf44"><mml:mi>B</mml:mi></mml:math></inline-formula>, which would lead to recovery of no neural activity. At the same time, we need to prevent the residual of the background term (i.e. <inline-formula><mml:math id="inf45"><mml:mrow><mml:mi>B</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf46"><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> denotes the estimated spatiotemporal background) from corrupting the estimated neural signals <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> in model (1), since subsequently, the extracted neuronal activity would be mixed with background fluctuations, leading to artificially high correlations between nearby cells. This problem is even worse in the microendoscopic context because the background fluctuation usually has significantly larger variance than the isolated cellular signals of interest (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), and therefore any small errors in the estimation of <inline-formula><mml:math id="inf48"><mml:mi>B</mml:mi></mml:math></inline-formula> can severely corrupt the estimated neural signal <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula>.</p><p>In (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>), <inline-formula><mml:math id="inf50"><mml:mi>B</mml:mi></mml:math></inline-formula> is modeled as a rank-<inline-formula><mml:math id="inf51"><mml:mn>1</mml:mn></mml:math></inline-formula> nonnegative matrix <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ùíá</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf53"><mml:mrow><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo>‚àà</mml:mo><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi mathvariant="bold-italic">ùíá</mml:mi><mml:mo>‚àà</mml:mo><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. This model mainly captures the global fluctuations within the field of view (FOV). In applications to two-photon or light-sheet data, this rank-1 model has been shown to be sufficient for relatively small spatial regions; the simple low-rank model does not hold for larger fields of view, and so we can simply divide large FOVs into smaller patches for largely¬†parallel processing (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>; <xref ref-type="bibr" rid="bib18">Giovannucci et al., 2017b</xref>). (See [<xref ref-type="bibr" rid="bib38">Pachitariu et al., 2016</xref>] for an alternative approach.) However, as we will see below, the local rank-1 model fails in many microendoscopic datasets, where multiple large overlapping background sources exist even within modestly¬†sized FOVs.</p><p>Thus, we propose a new model to constrain the background term <inline-formula><mml:math id="inf55"><mml:mi>B</mml:mi></mml:math></inline-formula>. We first decompose the background into two terms:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>c</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf56"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> represents fluctuating activity and <inline-formula><mml:math id="inf57"><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>c</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> models constant baselines (<inline-formula><mml:math id="inf58"><mml:mrow><mml:mn>ùüè</mml:mn><mml:mo>‚àà</mml:mo><mml:msup><mml:mi>‚Ñù</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> denotes a vector of <inline-formula><mml:math id="inf59"><mml:mi>T</mml:mi></mml:math></inline-formula> ones). To model <inline-formula><mml:math id="inf60"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula>, we exploit the fact that background sources (largely due to blurred out-of-focus fluorescence) are empirically much coarser spatially than the average neuron soma size <inline-formula><mml:math id="inf61"><mml:mi>l</mml:mi></mml:math></inline-formula>. Thus, we model <inline-formula><mml:math id="inf62"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> at one pixel as a linear combination of the background fluorescence in pixels which are chosen to be nearby but not nearest neighbors:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mo>‚àë</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>‚àà</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">‚àÄ</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>‚Ä¶</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>j</mml:mi><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext>¬†dist</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àà</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf64"><mml:mrow><mml:mtext>dist</mml:mtext><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> the Euclidean distance between pixel <inline-formula><mml:math id="inf65"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf66"><mml:mi>j</mml:mi></mml:math></inline-formula>. Thus, <inline-formula><mml:math id="inf67"><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> only selects the neighboring pixels with a distance of <inline-formula><mml:math id="inf68"><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> from the <inline-formula><mml:math id="inf69"><mml:mi>i</mml:mi></mml:math></inline-formula>-th pixel (the green dot and black pixels in <xref ref-type="fig" rid="fig2">Figure 2B</xref> illustrate <inline-formula><mml:math id="inf70"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf71"><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, respectively); here <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> is a parameter that we choose to be greater than <inline-formula><mml:math id="inf73"><mml:mi>l</mml:mi></mml:math></inline-formula> (the size of the typical soma in the FOV), e.g., <inline-formula><mml:math id="inf74"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. This choice of <inline-formula><mml:math id="inf75"><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> ensures that pixels <inline-formula><mml:math id="inf76"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf77"><mml:mi>j</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref> share similar background fluctuations, but do not belong to the same soma.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.004</object-id><label>Figure 2.</label><caption><title>CNMF-E can accurately separate and recover the background fluctuations in simulated data.</title><p>(<bold>A</bold>) An example frame of simulated microendoscopic data formed by summing up the fluorescent signals from the multiple sources illustrated in <xref ref-type="fig" rid="fig1">Figure 1E</xref>. (<bold>B</bold>) A zoomed-in version of the circle in (<bold>A</bold>). The green dot indicates the pixel of interest. The surrounding black pixels are its neighbors with a distance of 15 pixels. The red area approximates the size of a typical neuron in the simulation. (<bold>C</bold>) Raw fluorescence traces of the selected pixel and some of its neighbors on the black ring. Note the high correlation. (<bold>D</bold>) Fluorescence traces (raw data; true and estimated background; true and initial estimate of neural signal) from the center pixel as selected in (<bold>B</bold>). Note that the background dominates the raw data in this pixel, but nonetheless we can accurately estimate the background and subtract it away here. Scalebars: <inline-formula><mml:math id="inf78"><mml:mn>10</mml:mn></mml:math></inline-formula> seconds. Panels (<bold>E‚ÄìG</bold>) show the cellular signals in the same frame as (<bold>A</bold>). (<bold>E</bold>) Ground truth neural activity. (<bold>F</bold>) The residual of the raw frame after subtracting the background estimated with CNMF-E; note the close correspondence with E. (<bold>G</bold>) Same as (<bold>F</bold>), but the background is estimated with rank-1 NMF. A video showing (<bold>E‚ÄìG</bold>) for all frames can be found at <xref ref-type="video" rid="video2">Video 2</xref>. (<bold>H</bold>) The mean correlation coefficient (over all pixels) between the true background fluctuations and the estimated background fluctuations. The rank of NMF varies and we run randomly-initialized NMF for 10 times for each rank. The red line is the performance of CNMF-E, which requires no selection of the NMF rank. (<bold>I</bold>) The performance of CNMF-E and rank-1 NMF in recovering the background fluctuations from the data superimposed with an increasing number of background sources.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig2-v2"/></fig><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video2.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.005</object-id><label>Video 2.</label><caption><title>Comparison of CNMF-E with rank-1 NMF in estimating background fluctuation in simulated data.</title><p>Top left: the simulated fluorescence data in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Bottom left: the ground truth of neuron signals in the simulation. Top middle: the estimated background from the raw video data (top left) using CNMF-E. Bottom middle: the residual of the raw video after subtracting the background estimated with CNMF-E. Top right and top bottom: same as top middle and bottom middle, but the background is estimated with rank-1 NMF. MP4</p></caption></media><p>We can rewrite <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref> in matrix form:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf79"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> if <inline-formula><mml:math id="inf80"><mml:mrow><mml:mrow><mml:mtext>dist</mml:mtext><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>‚àâ</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In practice, this hard constraint is difficult to enforce computationally and is overly stringent given the noisy observed data. We relax the model by replacing the right-hand side <inline-formula><mml:math id="inf81"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> with the more convenient closed-form expression<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>According to <xref ref-type="disp-formula" rid="equ1 equ5">Equations (1) and (5)</xref>, this change ignores the noise term <inline-formula><mml:math id="inf82"><mml:mi>E</mml:mi></mml:math></inline-formula>; since elements in <inline-formula><mml:math id="inf83"><mml:mi>E</mml:mi></mml:math></inline-formula> are spatially uncorrelated, <inline-formula><mml:math id="inf84"><mml:mrow><mml:mi>W</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula> contributes as a very small disturbance to <inline-formula><mml:math id="inf85"><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> in the left-hand side. We found this substitution for <inline-formula><mml:math id="inf86"><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> led to significantly faster and more robust model fitting.</p><sec id="s1-3-1"><title>Fitting the CNMF-E model</title><p><xref ref-type="table" rid="table1">Table 1</xref> lists the variables in the proposed CNMF-E model. Now we can formulate the estimation of all model variables as a single optimization meta-problem:<disp-formula id="equ9"><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(P-All)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>minimize</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi/><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mo>‚àí</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>T</mml:mi></mml:msup><mml:mo>‚àí</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mspace width="2em"/></mml:mstyle></mml:mtd><mml:mtd><mml:mi>A</mml:mi><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>A</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mtext>¬†is sparse¬†</mml:mtext><mml:mi mathvariant="normal">‚àÄ</mml:mi><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>‚Ä¶</mml:mo><mml:mi>K</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>‚ãÖ</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo>=</mml:mo><mml:mn mathvariant="bold">0</mml:mn></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mo>‚àí</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àâ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.006</object-id><label>Table 1.</label><caption><title>Variables used in the CNMF-E model and algorithm. <inline-formula><mml:math id="inf87"><mml:mi>‚Ñù</mml:mi></mml:math></inline-formula>: real numbers; <inline-formula><mml:math id="inf88"><mml:msub><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>: positive real numbers; <inline-formula><mml:math id="inf89"><mml:mi>‚Ñï</mml:mi></mml:math></inline-formula>: natural numbers; <inline-formula><mml:math id="inf90"><mml:msub><mml:mi>‚Ñï</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>: positive integers.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Name</th><th>Description</th><th>Domain</th></tr></thead><tbody><tr><td><inline-formula><mml:math id="inf91"><mml:mi>d</mml:mi></mml:math></inline-formula></td><td>number of pixels</td><td><inline-formula><mml:math id="inf92"><mml:msub><mml:mi>‚Ñï</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf93"><mml:mi>T</mml:mi></mml:math></inline-formula></td><td>number of frames</td><td><inline-formula><mml:math id="inf94"><mml:msub><mml:mi>‚Ñï</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf95"><mml:mi>K</mml:mi></mml:math></inline-formula></td><td>number of neurons</td><td><inline-formula><mml:math id="inf96"><mml:mi>‚Ñï</mml:mi></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf97"><mml:mi>Y</mml:mi></mml:math></inline-formula></td><td>motion corrected video data</td><td><inline-formula><mml:math id="inf98"><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf99"><mml:mi>A</mml:mi></mml:math></inline-formula></td><td>spatial footprints of all neurons</td><td><inline-formula><mml:math id="inf100"><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf101"><mml:mi>C</mml:mi></mml:math></inline-formula></td><td>temporal activities of all neurons</td><td><inline-formula><mml:math id="inf102"><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf103"><mml:mi>B</mml:mi></mml:math></inline-formula></td><td>background activity</td><td><inline-formula><mml:math id="inf104"><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf105"><mml:mi>E</mml:mi></mml:math></inline-formula></td><td>observation noise</td><td><inline-formula><mml:math id="inf106"><mml:msup><mml:mi>‚Ñù</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf107"><mml:mi>W</mml:mi></mml:math></inline-formula></td><td>weight matrix to reconstruct <inline-formula><mml:math id="inf108"><mml:mi>B</mml:mi></mml:math></inline-formula> using neighboring pixels</td><td><inline-formula><mml:math id="inf109"><mml:msup><mml:mi>‚Ñù</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf110"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula></td><td>constant baseline for all pixels</td><td><inline-formula><mml:math id="inf111"><mml:msubsup><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi></mml:msubsup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf112"><mml:msub><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula></td><td>spatial location of the <inline-formula><mml:math id="inf113"><mml:mi>i</mml:mi></mml:math></inline-formula>th pixel</td><td><inline-formula><mml:math id="inf114"><mml:msup><mml:mi>‚Ñï</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula></td></tr><tr><td><inline-formula><mml:math id="inf115"><mml:msub><mml:mi>œÉ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula></td><td>standard deviation of the noise at pixel <inline-formula><mml:math id="inf116"><mml:msub><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf117"><mml:msub><mml:mi>‚Ñù</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula></td></tr></tbody></table></table-wrap><p>We call this a ‚Äòmeta-problem‚Äô because we have not yet explicitly defined the sparsity and spatial locality constraints on <inline-formula><mml:math id="inf118"><mml:mi>A</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf119"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíî</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">‚Ä¶</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíî</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>; these can be customized by users under different assumptions (see details in Materials¬†and¬†methods). Also note that <inline-formula><mml:math id="inf120"><mml:msub><mml:mi mathvariant="bold-italic">ùíî</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is completely determined by <inline-formula><mml:math id="inf121"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf122"><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf123"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> is not optimized explicitly but (as discussed above) can be estimated as <inline-formula><mml:math id="inf124"><mml:mrow><mml:mi>W</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, so we optimize with respect to <inline-formula><mml:math id="inf125"><mml:mi>W</mml:mi></mml:math></inline-formula> instead.</p><p>The problem (P-All) optimizes all variables together and is non-convex but can be divided into three simpler subproblems that we solve iteratively:</p><p>Estimating <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>A</mml:mi><mml:mo mathvariant="normal">,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn mathvariant="normal">0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> given <inline-formula><mml:math id="inf127"><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo mathvariant="normal" stretchy="false">^</mml:mo></mml:mover><mml:mo mathvariant="normal">,</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo mathvariant="normal" stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula><disp-formula id="equ10"><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(P-S)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:mi mathvariant="normal">A</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>minimize</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi/><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>‚àí</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>T</mml:mi></mml:msup><mml:mo>‚àí</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi>A</mml:mi><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>A</mml:mi><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Estimating <inline-formula><mml:math id="inf128"><mml:mrow><mml:mi>C</mml:mi><mml:mo mathvariant="normal">,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn mathvariant="normal">0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> given <inline-formula><mml:math id="inf129"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo mathvariant="normal" stretchy="false">^</mml:mo></mml:mover><mml:mo mathvariant="normal">,</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo mathvariant="normal" stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula><disp-formula id="equ11"><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(P-T)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>minimize</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi/><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>T</mml:mi></mml:msup><mml:mo>‚àí</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:msub><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">‚àÄ</mml:mi><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>‚Ä¶</mml:mo><mml:mi>K</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Estimating <inline-formula><mml:math id="inf130"><mml:mrow><mml:mi>W</mml:mi><mml:mo mathvariant="normal">,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn mathvariant="normal">0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> given <inline-formula><mml:math id="inf131"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo mathvariant="normal" stretchy="false">^</mml:mo></mml:mover><mml:mo mathvariant="normal">,</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo mathvariant="normal" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula><disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(P-B)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>minimize</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi/><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>‚àí</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>T</mml:mi></mml:msup><mml:mo>‚àí</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>‚ãÖ</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo>=</mml:mo><mml:mn mathvariant="bold">0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àâ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For each of these subproblems, we are able to use well-established algorithms (e.g. solutions for (P-S) and (P-T) are discussed in <xref ref-type="bibr" rid="bib14">Friedrich et al., 2017a</xref>; <xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>) or slight modifications thereof. By iteratively solving these three subproblems, we obtain tractable updates for all model variables in problem (P-All). Furthermore, this strategy gives us the flexibility of further potential interventions (either automatic or semi-manual) in the optimization procedure, for¬†example, incorporating further prior information on neurons‚Äô morphology, or merging/splitting/deleting spatial components and detecting missed neurons from the residuals. These steps can significantly improve the quality of the model fitting; this is an advantage compared with PCA/ICA, which offers no easy option for incorporation of stronger prior information or manually¬†guided improvements on the estimates.</p><p>Full details on the algorithms for initializing and then solving these three subproblems are provided in the Materials and¬†methods¬†section.</p></sec></sec></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>CNMF-E can reliably estimate large high-rank background fluctuations</title><p>We first use simulated data to illustrate the background model in CNMF-E and compare its performance against the low-rank NMF model used in the basic CNMF approach (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>). We generated the observed fluorescence <inline-formula><mml:math id="inf132"><mml:mi>Y</mml:mi></mml:math></inline-formula> by summing up simulated fluorescent signals of multiple sources as shown in <xref ref-type="fig" rid="fig1">Figure 1E</xref> plus additive Gaussian white noise (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><p>An example pixel (green dot, <xref ref-type="fig" rid="fig2">Figure 2A,B</xref>) was selected to illustrate the background model in CNMF-E (<xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>), which assumes that each pixel‚Äôs background activity can be reconstructed using its neighboring pixels‚Äô activities. The selected neighbors form a ring and their distances to the center pixel are larger than a typical neuron size (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). <xref ref-type="fig" rid="fig2">Figure 2C</xref> shows that the fluorescence traces of the center pixel and its neighbors are highly correlated due to the shared large background fluctuations. Here, for illustrative purposes, we fit the background by solving problem (P-B) directly while assuming <inline-formula><mml:math id="inf133"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This mistaken assumption should make the background estimation more challenging (due to true neural components getting absorbed into the background), but nonetheless in <xref ref-type="fig" rid="fig2">Figure 2</xref> we see that the background fluctuation was well recovered (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Subtracting this estimated background from the observed fluorescence in the center yields a good visualization of the cellular signal (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Thus, this example shows that we can reconstruct a complicated background trace while leaving the neural signal uncontaminated.</p><p>For the example frame in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, the true cellular signals are sparse and weak (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). When we subtract the estimated background using CNMF-E from the raw data, we obtain a good recovery of the true signal (<xref ref-type="fig" rid="fig2">Figure 2D,F</xref>). For comparison, we also estimate the background activity by applying a rank-<inline-formula><mml:math id="inf134"><mml:mn>1</mml:mn></mml:math></inline-formula> NMF model as used in basic CNMF; the resulting background-subtracted image is still severely contaminated by the background (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). This is easy to understand: the spatiotemporal background signal in microendoscopic data typically has a rank higher than one, due to the various signal sources indicated in <xref ref-type="fig" rid="fig1">Figure 1E</xref>), and therefore a rank-<inline-formula><mml:math id="inf135"><mml:mn>1</mml:mn></mml:math></inline-formula> NMF background model is insufficient.</p><p>A naive approach would be to simply increase the rank of the NMF background model. <xref ref-type="fig" rid="fig2">Figure 2H</xref> demonstrates that this approach is ineffective: higher¬†rank NMF does yield generally better reconstruction performance, but with high variability and low reliability (due to randomness in the initial conditions of NMF). Eventually as the NMF rank increases many single-neuronal signals of interest are swallowed up in the estimated background signal (data not shown). In contrast, CNMF-E recovers the background signal more accurately than any of the high-rank NMF models.</p><p>In real data analysis settings, the rank of NMF is an unknown and the selection of its value is a nontrivial problem. We simulated data sets with different numbers of local background sources and use a single parameter setting to run CNMF-E for reconstructing the background over multiple such simulations. <xref ref-type="fig" rid="fig2">Figure 2I</xref> shows that the performance of CNMF-E does not degrade quickly as we have more background sources, in contrast to rank-<inline-formula><mml:math id="inf136"><mml:mn>1</mml:mn></mml:math></inline-formula> NMF. Therefore, CNMF-E can recover the background accurately across a diverse range of background sources, as desired.</p></sec><sec id="s2-2"><title>CNMF-E accurately initializes single-neuronal spatial and temporal components</title><p>Next, we used simulated data to validate our proposed initialization procedure (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). In this example, we simulated 200 neurons with strong spatial overlaps (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). One of the first steps in our initialization procedure is to apply a Gaussian spatial filter to the images to reduce the (spatially coarser) background and boost the power of neuron-sized objects in the images. In <xref ref-type="fig" rid="fig3">Figure 3C</xref>, we see that the local correlation image (<xref ref-type="bibr" rid="bib49">Smith and H√§usser, 2010</xref>) computed on the spatially filtered data provides a good initial visualization of neuron locations; compare to <xref ref-type="fig" rid="fig1">Figure 1B</xref>, where the correlation image computed on the raw data was highly corrupted by background signals.</p><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.007</object-id><label>Figure 3.</label><caption><title>CNMF-E accurately initializes individual neurons‚Äô spatial and temporal components in simulated data.</title><p>(<bold>A</bold>) An example frame of the simulated data. Green and red squares will correspond to panels (<bold>D</bold>) and (<bold>E</bold>) below, respectively. (<bold>B</bold>) The temporal mean of the cellular activity in the simulation. (<bold>C</bold>) The correlation image computed using the spatially filtered data. (<bold>D</bold>) An example of initializing an isolated neuron. Three selected pixels correspond to the center, the periphery, and the outside of a neuron. The raw traces and the filtered traces are shown as well. The yellow dashed line is the true neural signal of the selected neuron. Triangle markers highlight the spike times from the neuron. (<bold>E</bold>) Same as (<bold>D</bold>), but two neurons are spatially overlapping in this example. Note that in both cases neural activity is clearly visible in the filtered traces, and the initial estimates of the spatial footprints are already quite accurate (dashed lines are ground truth). (<bold>F</bold>) The contours of all initialized neurons on top of the correlation image as shown in (<bold>D</bold>). Contour colors represent the rank of neurons‚Äô SNR (SNR decreases from red to yellow). The blue dots are centers of the true neurons. (<bold>G</bold>) The spatial and the temporal cosine similarities between each simulated neuron and its counterpart in the initialized neurons. (<bold>H</bold>) The local correlation and the peak-to-noise ratio for pixels located in the central area of each neuron (blue) and other areas (green). The red lines are the thresholding boundaries for screening seed pixels in our initialization step. A video showing the whole initialization step can be found at <xref ref-type="video" rid="video3">Video 3</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig3-v2"/></fig><media id="video3" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video3.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.008</object-id><label>Video 3.</label><caption><title>Initialization procedure for the simulated data in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title><p>Top left: correlation image of the filtered data. Red dots are centers of initialized neurons. Top middle: candidate seed pixels (small red dots) for initializing neurons on top of PNR image. The large red dot indicates the current seed pixel. Top right: the correlation image surrounding the selected seed pixel or the spatial footprint of the initialized neuron. Bottom: the filtered fluorescence trace at the seed pixel or the initialized temporal activity (both raw and denoised). MP4</p></caption></media><p>We choose two example ROIs to illustrate how CNMF-E removes the background contamination and demixes nearby neural signals for accurate initialization of neurons‚Äô shapes and activity. In the first example, we choose a well-isolated neuron (green box, <xref ref-type="fig" rid="fig3">Figure 3A+B</xref>). We select three pixels located in the center, the periphery, and the outside of the neuron and show the corresponding fluorescence traces in both the raw data and the spatially filtered data (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). The raw traces are noisy and highly correlated, but the filtered traces show relatively clean neural signals. This is because spatial filtering reduces the shared background activity and the remaining neural signals dominate the filtered data. Similarly, <xref ref-type="fig" rid="fig3">Figure 3E</xref> is an example showing how CNMF-E demixes two overlapping neurons. The filtered traces in the centers of the two neurons still preserve their own temporal activity.</p><p>After initializing the neurons‚Äô traces using the spatially filtered data, we initialize our estimate of their spatial footprints. Note that simply initializing these spatial footprints with the spatially¬†filtered data does not work well (data not shown), since the resulting shapes are distorted by the spatial filtering process. We found that it was more effective to initialize each spatial footprint by regressing the initial neuron traces onto the raw movie data (see Materials¬†and¬†methods for details). The initial values already match the simulated ground truth with fairly high fidelity (<xref ref-type="fig" rid="fig3">Figure 3D+E</xref>). In this simulated data, CNMF-E successfully identified all 200 neurons and initialized their spatial and temporal components (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). We then evaluate the quality of initialization using all neurons‚Äô spatial and temporal similarities with their counterparts in the ground truth data. <xref ref-type="fig" rid="fig3">Figure 3G</xref> shows that all initialized neurons have high similarities with the truth, indicating a good recovery and demixing of all neuron sources.</p><p>Thresholds on the minimum local correlation and the minimum peak-to-noise ratio (PNR) for detecting seed pixels are necessary for defining the initial spatial components. To quantify the sensitivity of choosing these two thresholds, we plot the local correlations and the PNRs of all pixels chosen as the local maxima within an area of <inline-formula><mml:math id="inf137"><mml:mrow><mml:mfrac><mml:mi>l</mml:mi><mml:mn>4</mml:mn></mml:mfrac><mml:mo>√ó</mml:mo><mml:mfrac><mml:mi>l</mml:mi><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf138"><mml:mi>l</mml:mi></mml:math></inline-formula> is the diameter of a typical neuron, in the correlation image or the PNR image (<xref ref-type="fig" rid="fig3">Figure 3H</xref>). Pixels are classified into two classes according to their locations relative to the closest neurons: neurons‚Äô central areas and outside areas (see Materials and¬†methods¬†for full details). It is clear that the two classes are linearly well separated and the thresholds can be chosen within a broad range of values (<xref ref-type="fig" rid="fig3">Figure 3H</xref>), indicating that the algorithm is robust with respect to these threshold parameters here. In lower¬†SNR settings, these boundaries may be less clear, and an incremental approach (in which we choose the highest-SNR neurons first, then estimate the background and examine the residual to select the lowest-SNR cells) may be preferred; this incremental approach is discussed in more depth in the Materials and¬†methods¬†section.</p></sec><sec id="s2-3"><title>CNMF-E recovers the true neural activity and is robust to noise contamination and neuronal correlations in simulated data</title><p>Using the same simulated dataset as in the previous section, we further refine the neuron shapes (<inline-formula><mml:math id="inf139"><mml:mi>A</mml:mi></mml:math></inline-formula>) and the temporal traces (<inline-formula><mml:math id="inf140"><mml:mi>C</mml:mi></mml:math></inline-formula>) by iteratively fitting the CNMF-E model. We compare the final results with PCA/ICA analysis (<xref ref-type="bibr" rid="bib33">Mukamel et al., 2009</xref>) and the original CNMF method (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>).</p><p>After choosing the thresholds for seed pixels (<xref ref-type="fig" rid="fig3">Figure 3H</xref>), we run CNMF-E in full automatic mode, without any manual interventions. Two open-source MATLAB packages, CellSort¬†(<ext-link ext-link-type="uri" xlink:href="https://github.com/mukamel-lab/CellSort">https://github.com/mukamel-lab/CellSort</ext-link>;¬†<xref ref-type="bibr" rid="bib34">Mukamel, 2016</xref>) and ca_source_extraction¬†(<ext-link ext-link-type="uri" xlink:href="https://github.com/epnev/ca_source_extraction">https://github.com/epnev/ca_source_extraction</ext-link>;¬†<xref ref-type="bibr" rid="bib42">Pnevmatikakis, 2016</xref>), were used to perform PCA/ICA (<xref ref-type="bibr" rid="bib33">Mukamel et al., 2009</xref>) and basic CNMF (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>), respectively. Since the initialization algorithm in CNMF fails due to the large contaminations from the background fluctuations in this setting (recall <xref ref-type="fig" rid="fig2">Figure 2</xref>), we use the ground truth as its initialization. As for the rank of the background model in CNMF, we tried all integer values between 1 and 16 and set it as 7 because it has the best performance in matching the ground truth. We emphasize that including the CNMF approach in this comparison is not fair for the other two approaches, because it uses the ground truth heavily, while PCA/ICA and CNMF-E are blind to the ground truth. The purpose here is to show the limitations of basic CNMF in modeling the background activity in microendoscopic data.</p><p>We first pick three closeby neurons from the ground truth (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, top) and see how well these neurons‚Äô activities are recovered. PCA/ICA fails to identify one neuron, and for the other two identified neurons, it recovers temporal traces that are sufficiently noisy that small calcium transients are submerged in the noise. As for CNMF, the neuron shapes remain more or less at the initial condition (i.e. the ground truth spatial footprints), but clear contaminations in the temporal traces are visible. This is because the pure NMF model in CNMF does not model the true background well and the residuals in the background are mistakenly captured by neural components. In contrast, on this example, CNMF-E recovers the true neural shapes and neural activity with high accuracy.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.009</object-id><label>Figure 4.</label><caption><title>CNMF-E outperforms PCA/ICA analysis in extracting individual neurons‚Äô activity from simulated data and is robust to low SNR.</title><p>(<bold>A</bold>) The results of PCA/ICA, CNMF, and CNMF-E in recovering the spatial footprints and temporal traces of three example neurons. The trace colors match the neuron colors shown in the left. (<bold>B</bold>) The intermediate residual sum of squares (RSS) values (normalized by the final RSS value), during the CNMF-E model fitting. The 'refine initialization‚Äô step refers to the modification of the initialization results in the case of high temporal correlation (details in Materials¬†and¬†methods). (<bold>C</bold>) The spatial and the temporal cosine similarities between the ground truth and the neurons detected using different methods. (<bold>D</bold>) The pairwise correlations between the calcium activity traces extracted using different methods. (<bold>E‚ÄìG</bold>) The performances of PCA/ICA and CNMF-E under different noise levels: the number of missed neurons (<bold>E</bold>), and the spatial (<bold>F</bold>) and temporal (<bold>G</bold>) cosine similarities between the extracted components and the ground truth. (<bold>H</bold>) The calcium traces of one example neuron: the ground truth (black), the PCA/ICA trace (blue), the CNMF-E trace (red) and the CNMF-E trace without being denoised (cyan). The similarity values shown in the figure are computed as the cosine similarity between each trace and the ground truth (black). Two videos showing the demixing results of the simulated data can be found in <xref ref-type="video" rid="video4">Video 4</xref> (SNR reduction factor¬†=¬†1) and <xref ref-type="video" rid="video5">Video 5</xref> (SNR reduction factor¬†=¬†6).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig4-v2"/></fig><media id="video4" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video4.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.010</object-id><label>Video 4.</label><caption><title>The results of CNMF-E in demixing simulated data in <xref ref-type="fig" rid="fig4">Figure 4</xref> (SNR reduction factor¬†=¬†1).</title><p>Top left: the simulated fluorescence data. Bottom left: the estimated background. Top middle: the residual of the raw video (top left) after subtracting the estimated background (bottom left). Bottom middle: the denoised neural signals. Top right: the residual of the raw video data (top right) after subtracting the estimated background (bottom left) and denoised neural signal (bottom middle). Bottom right: the ground truth of neural signals in simulation. MP4</p></caption></media><media id="video5" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video5.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.011</object-id><label>Video 5.</label><caption><title>The results of CNMF-E in demixing the simulated data in <xref ref-type="fig" rid="fig4">Figure 4</xref> (SNR reduction factor¬†=¬†6).</title><p>Conventions as in previous video. MP4</p></caption></media><p>We also compare the number of detected neurons: PCA/ICA detected 195 out of 200 neurons, while CNMF-E detected all 200 neurons. We also quantitatively evaluated the performance of source extraction by showing the spatial and temporal cosine similarities between detected neurons and ground truth (<xref ref-type="fig" rid="fig4">Figure 4C</xref>); we find that the neurons detected using PCA/ICA have much lower similarities with the ground truth (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). We also note that the CNMF results are much worse than those of CNMF-E here, despite the fact that CNMF is initialized at the ground truth parameter values. This result clarifies an important point: the improvements from CNMF-E are not simply due to improvements in the initialization step. Furthermore, running the full iterative pipeline of CNMF-E leads to improvements in both spatial and temporal similarities, compared with the results in the initialization step.</p><p>In many downstream analyses of calcium imaging data, pairwise correlations provide an important metric to study coordinated network activity (<xref ref-type="bibr" rid="bib55">Warp et al., 2012</xref>; <xref ref-type="bibr" rid="bib2">Barbera et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Dombeck et al., 2009</xref>; <xref ref-type="bibr" rid="bib27">Klaus et al., 2017</xref>). Since PCA/ICA seeks statistically independent components, which forces the temporal traces to have near-zero correlation, the correlation structure is badly corrupted in the raw PCA/ICA outputs (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). We observed that a large proportion of the independence comes from the noisy baselines in the extracted traces (data not shown), so we postprocessed the PCA/ICA output by thresholding at the 3 standard deviation level. This recovers some nonzero correlations, but the true correlation structure is not recovered accurately (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). By contrast, the CNMF-E results matched the ground truth very well due to accurate extraction of individual neurons‚Äô temporal activity (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). As for CNMF, the estimated correlations are slightly elevated relative to the true correlations. This is due to the shared (highly correlated) background fluctuations that corrupt the recovered activity of nearby neurons.</p><p>Next, we compared the performance of the different methods under different SNR regimes. Because of the above inferior results we skip comparisons to the basic CNMF here. Based on the same simulation parameters as above, we vary the noise level <inline-formula><mml:math id="inf141"><mml:mi mathvariant="normal">Œ£</mml:mi></mml:math></inline-formula> by multiplying it with a SNR reduction factor. <xref ref-type="fig" rid="fig4">Figure 4E</xref> shows that CNMF-E detects all neurons over a wide SNR range, while PCA/ICA fails to detect the majority of neurons when the SNR drops to sufficiently low levels. Moreover, the detected neurons in CNMF-E preserve high spatial and temporal similarities with the ground truth (<xref ref-type="fig" rid="fig4">Figure 4F‚ÄìG</xref>). This high accuracy of extracting neurons‚Äô temporal activity benefits from the modeling of the calcium dynamics, which leads to significantly denoised neural activity. If we skip the temporal denoising step in the algorithm, CNMF-E is less robust to noise, but still outperforms PCA/ICA significantly (<xref ref-type="fig" rid="fig4">Figure 4G</xref>). When SNR is low, the improvements yielded by CNMF-E can be crucial for detecting weak neuron events, as shown in <xref ref-type="fig" rid="fig4">Figure 4H</xref>.</p><p>Finally, we examine the ability of CNMF-E to demix correlated and overlapping neurons. Using the two example neurons in <xref ref-type="fig" rid="fig3">Figure 3E</xref>, we ran multiple simulations at varying correlation levels and extracted neural components using the CNMF-E pipeline and PCA/ICA analysis. The spatial footprints in these simulations were fixed, but the temporal components were varied to have different correlation levels (<inline-formula><mml:math id="inf142"><mml:mi>Œ≥</mml:mi></mml:math></inline-formula>) between calcium traces by tuning their shared component with the common background fluctuations. For high correlation levels (<inline-formula><mml:math id="inf143"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>), the initialization procedure tends to first initialize a component that explains the common activity between two neurons and then initialize another component to account for the residual of one neuron. After iteratively refining the model variables, CNMF-E successfully extracted the two neurons‚Äô spatiotemporal activity even at very high correlation levels (<inline-formula><mml:math id="inf144"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig5">Figure 5A,B</xref>). PCA/ICA was also often able to separate two neurons for large correlation levels (<inline-formula><mml:math id="inf145"><mml:mrow><mml:mi>Œ≥</mml:mi><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig5">Figure 5B</xref>), but the extracted traces have problematic negative spikes that serve to reduce their statistical dependences (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.012</object-id><label>Figure 5.</label><caption><title>CNMF-E is able to demix neurons with high temporal correlations.</title><p>(<bold>A</bold>) An example simulation from the experiments summarized in panel (<bold>B</bold>), where <inline-formula><mml:math id="inf146"><mml:mrow><mml:mtext>corr</mml:mtext><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is 0.9: green and red traces correspond to the corresponding neuronal shapes in the left panels. The blue trace is the mean background fluorescence fluctuation over the whole FOV. (<bold>B</bold>) The extraction accuracy of the spatial (<inline-formula><mml:math id="inf147"><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf148"><mml:msub><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>) and the temporal (<inline-formula><mml:math id="inf149"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf150"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>) components of two close-by neurons, computed via the cosine similarity between the ground truth and the extraction results.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig5-v2"/></fig></sec><sec id="s2-4"><title>Application to dorsal striatum data</title><p>We now turn to the analysis of large-scale microendoscopic datasets recorded from freely behaving mice. We run both CNMF-E and PCA/ICA for all datasets and compare their performances in detail.</p><p>We begin by analyzing in vivo calcium imaging data of neurons expressing GCaMP6f in the mouse dorsal striatum. (Full experimental details and algorithm parameter settings for this and the following datasets appear in the Methods and Materials section.) CNMF-E extracted 692 putative neural components from this dataset; PCA/ICA extracted 547 components (starting from 700 initial components, and then automatically removing false positives using the same criterion as applied in CNMF-E). <xref ref-type="fig" rid="fig6">Figure 6A</xref> shows how CNMF-E decomposes an example frame into four components: the constant baselines that are invariant over time, the fluctuating background, the denoised neural signals, and the residuals. We highlight an example neuron by drawing its ROI to demonstrate the power of CNMF-E in isolating fluorescence signals of neurons from the background fluctuations. For the selected neuron, we plot the mean fluorescence trace of the raw data and the estimated background (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). These two traces are very similar, indicating that the background fluctuation dominates the raw data. By subtracting this estimated background component from the raw data, we acquire a clean trace that represents the neural signal.</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.013</object-id><label>Figure 6.</label><caption><title>Neurons expressing GCaMP6f recorded in vivo in mouse dorsal striatum area.</title><p>(<bold>A</bold>) An example frame of the raw data and its four components decomposed by CNMF-E. (<bold>B</bold>) The mean fluorescence traces of the raw data (black), the estimated background activity (blue), and the background-subtracted data (red) within the segmented area (red) in (<bold>A</bold>). The variance of the black trace is about 2x the variance of the blue trace and 4x the variance of the red trace. (<bold>C</bold>) The distributions of the variance explained by different components over all pixels; note that estimated background signals dominate the total variance of the signal. (<bold>D</bold>) The contour plot of all neurons detected by CNMF-E and PCA/ICA superimposed on the correlation image. Green areas represent the components that are only detected by CNMF-E. The components are sorted in decreasing order based on their SNRs (from red to yellow). (<bold>E</bold>) The spatial and temporal components of 14 example neurons that are only detected by CNMF-E. These neurons all correspond to green areas in (<bold>D</bold>). (<bold>F</bold>) The signal-to-noise ratios (SNRs) of all neurons detected by both methods. Colors match the example traces shown in (<bold>G</bold>), which shows the spatial and temporal components of 10 example neurons detected by both methods. Scalebar: 10 s. See <xref ref-type="video" rid="video6">Video 6</xref> for the demixing results.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig6-v2"/></fig><media id="video6" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video6.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.014</object-id><label>Video 6.</label><caption><title>The results of CNMF-E in demixing dorsal striatum data.</title><p>Top left: the recorded fluorescence data. Bottom left: the estimated background. Top middle: the residual of the raw video (top left) after subtracting the estimated background (bottom left). Bottom middle: the denoised neural signals. Top right: the residual of the raw video data (top right) after subtracting the estimated background (bottom left) and denoised neural signal (bottom middle). Bottom right: the denoised neural signals while all neurons‚Äô activity are coded with pseudocolors. MP4</p></caption></media><p>To quantify the background effects further, we compute the contribution of each signal component in explaining the variance in the raw data. For each pixel, we compute the variance of the raw data first and then compute the variance of the background-subtracted data. Then the reduced variance is divided by the variance of the raw data, giving the proportion of variance explained by the background. <xref ref-type="fig" rid="fig6">Figure 6C</xref> (blue) shows the distribution of the background-explained variance over all pixels. The background accounts for around 90% of the variance on average. We further remove the denoised neural signals and compute the variance reduction; <xref ref-type="fig" rid="fig6">Figure 6C</xref> shows that neural signals account for less than 10% of the raw signal variance. This analysis is consistent with our observations that background dominates the fluorescence signal and extracting high-quality neural signals requires careful background signal removal.</p><p>The contours of the spatial footprints inferred by the two approaches (PCA/ICA and CNMF-E) are depicted in <xref ref-type="fig" rid="fig6">Figure 6D</xref>, superimposed on the correlation image of the filtered raw data. The indicated area was cropped from <xref ref-type="fig" rid="fig6">Figure 6A</xref> (left). In this case, most neurons inferred by PCA/ICA were inferred by CNMF-E as well, with the exception of a few components that seemed to be false positives (judging by their spatial shapes and temporal traces and visual inspection of the raw data movie; detailed data not shown). However, many realistic components were only detected by CNMF-E (shown as the green areas in <xref ref-type="fig" rid="fig6">Figure 6D</xref>). In these plots, we rank the inferred components according to their SNRs; the color indicates the relative rank (decaying from red to yellow). We see that the components missed by PCA/ICA have low SNRs (green shaded areas with yellow contours).</p><p><xref ref-type="fig" rid="fig6">Figure 6E</xref> shows the spatial and temporal components of 14 example neurons detected only by CNMF-E. Here (and in the following figures), for illustrative purposes, we show the calcium traces before the temporal denoising step. For neurons that are inferred by both methods, CNMF-E shows significant improvements in the SNR of the extracted cellular signals (<xref ref-type="fig" rid="fig6">Figure 6F</xref>), even before the temporal denoising step is applied. In panel G we randomly select 10 examples and examine their spatial and temporal components. Compared with the CNMF-E results, PCA/ICA components have much smaller size, often with negative dips surrounding the neuron (remember that ICA avoids spatial overlaps in order to reduce nearby neurons‚Äô statistical dependences, leading to some loss of signal strength; see (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>) for further discussion). The activity traces extracted by CNMF-E are visually cleaner than the PCA/ICA traces; this is important for reliable event detection, particularly in low SNR examples. See <xref ref-type="bibr" rid="bib27">Klaus et al., 2017</xref>) for additional examples of CNMF-E applied to striatal data.</p></sec><sec id="s2-5"><title>Application to data in prefrontal cortex</title><p>We repeat a similar analysis on GCaMP6s data recorded from prefrontal cortex (PFC, <xref ref-type="fig" rid="fig7">Figure 7</xref>), to quantify the performance of the algorithm in a different brain area with a different calcium indicator. Again we find that CNMF-E successfully extracts neural signals from a strong fluctuating background (<xref ref-type="fig" rid="fig7">Figure 7A</xref>), which contributes a large proportion of the variance in the raw data (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). Similarly as with the striatum data, PCA/ICA analysis missed many components that have very weak signals (33 missed components here). For the matched neurons, CNMF-E shows strong improvements in the SNRs of the extracted traces (<xref ref-type="fig" rid="fig7">Figure 7D</xref>). Consistent with our observation in striatum (<xref ref-type="fig" rid="fig6">Figure 6G</xref>), the spatial footprints of PCA/ICA components are shrunk to promote statistical independence between neurons, while the neurons inferred by CNMF-E have visually reasonable morphologies (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). As for calcium traces with high SNRs (<xref ref-type="fig" rid="fig7">Figure 7E</xref>, cell 1-6), CNMF-E traces have smaller noise values, which is important for detecting small calcium transients (<xref ref-type="fig" rid="fig7">Figure 7E</xref>, cell¬†4). For traces with low SNRs (<xref ref-type="fig" rid="fig7">Figure 7</xref>, cell 7-10), it is challenging to detect any calcium events from the PCA/ICA traces due to the large noise variance; CNMF-E is able to visually recover many of these weaker signals. For those cells missed by PCA/ICA, their traces extracted by CNMF-E have reasonable morphologies and visible calcium events (<xref ref-type="fig" rid="fig7">Figure 7F</xref>).</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.015</object-id><label>Figure 7.</label><caption><title>Neurons expressing GCaMP6s recorded in vivo in mouse prefrontal cortex.</title><p>(<bold>A‚ÄìF</bold>) follow similar conventions as in the corresponding panels of <xref ref-type="fig" rid="fig6">Figure 6</xref>. (<bold>G</bold>) Three example neurons that are close to each other and detected by both methods. Yellow shaded areas highlight the negative ‚Äòspikes‚Äô correlated with nearby activity, and the cyan shaded area highlights one crosstalk between nearby neurons. Scalebar: 20 s. See <xref ref-type="video" rid="video7">Video 7</xref> for the demixing results and <xref ref-type="video" rid="video8">Video 8</xref> for the comparision of CNMF-E and PCA/ICA in the zoomed-in area of (<bold>G</bold>).</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig7-v2"/></fig><media id="video7" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video7.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.016</object-id><label>Video 7.</label><caption><title>The results of CNMF-E in demixing PFC data.</title><p>Conventions as in previous video. MP4</p></caption></media><media id="video8" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video8.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.017</object-id><label>Video 8.</label><caption><title>Comparison of CNMF-E with PCA/ICA in demixing overlapped neurons in <xref ref-type="fig" rid="fig7">Figure 7G</xref>.</title><p>Top left: the recorded fluorescence data. Bottom left: the residual of the raw video (top left) after subtracting the estimated background using CNMF-E. Top middle and top right: the spatiotemporal activity and temporal traces of three neurons extracted using CNMF-E. Bottom middle and bottom right: the spatiotemporal activity and temporal traces of three neurons extracted using PCA/ICA. MP4</p></caption></media><p>The demixing performance of PCA/ICA analysis can be relatively weak because it is inherently a linear demixing method (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>). Since CNMF-E uses a more suitable nonlinear matrix factorization method, it has a better capability of demixing spatially overlapping neurons. As an example, <xref ref-type="fig" rid="fig7">Figure 7G</xref> shows three closeby neurons identified by both CNMF-E and PCA/ICA analysis. PCA/ICA forces its obtained filters to be spatially separated to reduce their dependence (thus reducing the effective signal strength), while CNMF-E allows inferred spatial components to have large overlaps (<xref ref-type="fig" rid="fig7">Figure 7G</xref>, left), retaining the full signal power. In the traces extracted by PCA/ICA, the component labeled in green contains many negative ‚Äòspikes,‚Äô which are highly correlated with the spiking activity of the blue neuron (<xref ref-type="fig" rid="fig7">Figure 7G</xref>, yellow). In addition, the green PCA/ICA neuron has significant crosstalk with the red neuron due to the failure of signal demixing (<xref ref-type="fig" rid="fig7">Figure 7G</xref>, cyan); the CNMF-E traces shows no comparable negative ‚Äòspikes‚Äô or crosstalk. See also <xref ref-type="video" rid="video8">Video 8</xref> for further details.</p></sec><sec id="s2-6"><title>Application to ventral hippocampus neurons</title><p>In the previous two examples, we analyzed data with densely packed neurons, in which the neuron sizes are all similar. In the next example, we apply CNMF-E to a dataset with much sparser and more heterogeneous neural signals. The data used here were recorded from amygdala-projecting neurons expressing GCaMP6f in ventral hippocampus. In this dataset, some neurons that are slightly above or below the focal plane were visible with prominent signals, though their spatial shapes are larger than neurons in the focal plane.</p><p>This example is somewhat more challenging due to the large diversity of neuron sizes. It is possible to set multiple parameters to detect neurons of different sizes (or to e.g. differentially detect somas versus smaller segments of axons or dendrites passing through the focal plane), but for illustrative purposes here we use a single neural size parameter to initialize all of the components. This in turn splits some large neurons into multiple components. Following this crude initialization step, we updated the background component and then picked the missing neurons from the residual using a second greedy component initialization step. Next, we ran CNMF-E for three iterations of updating the model variables <inline-formula><mml:math id="inf151"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf152"><mml:mi>B</mml:mi></mml:math></inline-formula>. The first two iterations were performed automatically; we included manual interventions (e.g. merging/deleting components) before the last iteration, leading to improved source extraction results (see <xref ref-type="video" rid="video10">Video 10</xref> for details on the manual merge and delete interventions performed here). In this example, we detected 24 CNMF-E components and 24 PCA/ICA components. The contours of these inferred neurons are shown in <xref ref-type="fig" rid="fig8">Figure 8A</xref>. In total we have 20 components detected by both methods (shown in the first three rows of <xref ref-type="fig" rid="fig8">Figure 8B+C</xref>); each method detected extra components that are not detected by the other (the last rows of <xref ref-type="fig" rid="fig8">Figure 8B+C</xref>). Once again, the PCA/ICA filters contain many negative pixels in an effort to reduce spatial overlaps; see components 3 and 5 in <xref ref-type="fig" rid="fig8">Figure 8A‚ÄìC</xref>, for example. All traces of the inferred neurons are shown in <xref ref-type="fig" rid="fig8">Figure 8D+E</xref>. We can see that the CNMF-E traces have much lower noise level and cleaner neural signals in both high and low SNR settings. Conversely, the calcium traces of the three extra neurons identified by PCA/ICA show noisy signals that are unlikely to be neural responses.</p><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.018</object-id><label>Figure 8.</label><caption><title>Neurons expressing GCaMP6f recorded in vivo in mouse ventral hippocampus.</title><p>(<bold>A</bold>) Contours of all neurons detected by CNMF-E (red) and PCA/ICA method (green). The grayscale image is the local correlation image of the background-subtracted video data, with background estimated using CNMF-E. (<bold>B</bold>) Spatial components of all neurons detected by CNMF-E. The neurons in the first three rows are also detected by PCA/ICA, while the neurons in the last row are only detected by CNMF-E. (<bold>C</bold>) Spatial components of all neurons detected by PCA/ICA; similar to (<bold>B</bold>), the neurons in the first three rows are also detected by CNMF-E and the neurons in the last row are only detected by PCA/ICA method. (<bold>D</bold>) Temporal traces of all detected components in (<bold>B</bold>). ‚ÄòMatch‚Äô indicates neurons in top three rows in panel (<bold>B</bold>); ‚ÄòOther‚Äô indicates neurons in the fourth row. (<bold>E</bold>) Temporal traces of all components in (<bold>C</bold>). Scalebars: <inline-formula><mml:math id="inf153"><mml:mn>20</mml:mn></mml:math></inline-formula> seconds. See <xref ref-type="video" rid="video9">Video 9</xref> for demixing results.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig8-v2"/></fig><media id="video9" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video9.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.019</object-id><label>Video 9.</label><caption><title>The results of CNMF-E in demixing ventral hippocampus data.</title><p>Conventions as in <xref ref-type="video" rid="video6">Video 6</xref>. MP4</p></caption></media><media id="video10" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video10.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.020</object-id><label>Video 10.</label><caption><title>Extracted spatial and temporal components of CNMF-E at different stages (ventral hippocampal dataset).</title><p>After initializing components, we ran matrix updates and interventions in automatic mode, resulting in <inline-formula><mml:math id="inf154"><mml:mn>32</mml:mn></mml:math></inline-formula> components in total. In the next iteration, we manually deleted <inline-formula><mml:math id="inf155"><mml:mn>6</mml:mn></mml:math></inline-formula> components and automatically merged neurons as well. In the last iterations, <inline-formula><mml:math id="inf156"><mml:mn>4</mml:mn></mml:math></inline-formula> neurons were merged into <inline-formula><mml:math id="inf157"><mml:mn>2</mml:mn></mml:math></inline-formula> neurons with manual verifications. The correlation image in the top left panel is computed from the background-subtracted data in the final step. MP4</p></caption></media></sec><sec id="s2-7"><title>Application to footshock responses in the bed nucleus of the stria terminalis (BNST)</title><p>Identifying neurons and extracting their temporal activity is typically just the first step in the analysis of calcium imaging data; downstream analyses rely heavily on the quality of this initial source extraction. We showed above that, compared to PCA/ICA, CNMF-E is better at extracting activity dynamics, especially in regimes where neuronal activities are correlated (c.f. <xref ref-type="fig" rid="fig4">Figure 4D</xref>). Using in vivo electrophysiological recordings, we previously showed that neurons in the bed nucleus of the stria terminalis (BNST) show strong responses to unpredictable footshock stimuli (<xref ref-type="bibr" rid="bib21">Jennings et al., 2013</xref>). We therefore measured calcium dynamics in CaMKII-expressing neurons that were transfected with the calcium indicator GCaMP6s in the BNST and analyzed the synchronous activity of multiple neurons in response to unpredictable footshock stimuli. We chose 12 example neurons that were detected by both CNMF-E and PCA/ICA methods and show their spatial and temporal components in <xref ref-type="fig" rid="fig9">Figure 9A‚ÄìC</xref>. The activity around the onset of the repeated stimuli are aligned and shown as pseudo-colored images in panel D. The median responses of CNMF-E neurons display prominent responses to the footshock stimuli compared with the resting state before stimuli onset. In comparison, the activity dynamics extracted by PCA/ICA have relatively low SNR, making it more challenging to reliably extract footshock responses. Panel E summarizes the results of panel D; we see that CNMF-E outputs significantly more easily detectable responses than does PCA/ICA. This is an example in which downstream analyses of calcium imaging data can significantly benefit from the improvements in the accuracy of source extraction offered by CNMF-E. (sheintuch2017tracking recently presented another such example, showing that more neurons can be tracked across multiple days using CNMF-E outputs, compared to PCA/ICA.)</p><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.021</object-id><label>Figure 9.</label><caption><title>Neurons extracted by CNMF-E show more reproducible responses to footshock stimuli, with larger signal sizes relative to the across-trial variability, compared to PCA/ICA.</title><p>(<bold>A‚ÄìC</bold>) Spatial components (<bold>A</bold>), spatial locations (<bold>B</bold>) and temporal components (<bold>C</bold>) of 12 example neurons detected by both CNMF-E and PCA/ICA. (<bold>D</bold>) Calcium responses of all example neurons to footshock stimuli. Colormaps show trial-by-trial responses of each neuron, extracted by CNMF-E (top, red) and PCA/ICA (bottom, green), aligned to the footshock time. The solid lines are medians of neural responses over 11 trials and the shaded areas correpond to median <inline-formula><mml:math id="inf158"><mml:mrow><mml:mo>¬±</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>median absolute deviation (MAD). Dashed lines indicate the shock timings. (<bold>E</bold>) Scatter plot of peak-to-MAD ratios for all response curves in (<bold>D</bold>). For each neuron, Peak is corrected by subtracting the mean activity within 4 s prior to stimulus onset and MAD is computed as the mean MAD values over all timebins shown in (<bold>D</bold>). The red line shows <inline-formula><mml:math id="inf159"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></inline-formula>. Scalebars: 10 s. See <xref ref-type="video" rid="video11">Video 11</xref> for demixing results.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig9-v2"/></fig><media id="video11" mime-subtype="mp4" mimetype="video" xlink:href="elife-28728-video11.mp4"><object-id pub-id-type="doi">10.7554/eLife.28728.022</object-id><label>Video 11.</label><caption><title>The results of CNMF-E in demixing BNST data.</title><p>Conventions as in <xref ref-type="video" rid="video6">Video 6</xref>. MP4</p></caption></media></sec><sec id="s2-8"><title>Conclusion</title><p>Microendoscopic calcium imaging offers unique advantages and has quickly become a critical method for recording large neural populations during unrestrained behavior. However, previous methods fail to adequately remove background contaminations when demixing single neuron activity from the raw data. Since strong background signals are largely inescapable in the context of one-photon imaging, insufficient removal of the background could yield problematic conclusions in downstream analysis. This has presented a severe and well-known bottleneck in the field. We have delivered a solution for this critical problem, building on the constrained nonnegative matrix factorization framework introduced in <xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref> but significantly extending it in order to more accurately and robustly remove these contaminating background components.</p><p>The proposed CNMF-E algorithm can be used in either automatic or semi-automatic mode, and leads to significant improvements in the accuracy of source extraction compared with previous methods. In addition, CNMF-E requires very few parameters to be specified, and these parameters are easily interpretable and can be selected within a broad range. We demonstrated the power of CNMF-E using data from a wide diversity of brain areas (subcortical, cortical, and deep brain areas), SNR regimes, calcium indicators, neuron sizes and densities, and hardware setups. Among all these examples (and many others not shown here), CNMF-E performs well and improves significantly on the standard PCA/ICA approach. Considering that source extraction is typically just the first step in calcium imaging data analysis pipelines (<xref ref-type="bibr" rid="bib32">Mohammed et al., 2016</xref>), these improvements should in turn lead to more stable and interpretable results from downstream analyses. Further applications of the CNMF-E approach appear in (<xref ref-type="bibr" rid="bib5">Cameron et al., 2016</xref>; <xref ref-type="bibr" rid="bib12">Donahue and Kreitzer, 2017</xref>; <xref ref-type="bibr" rid="bib24">Jimenez et al., 2016</xref>; <xref ref-type="bibr" rid="bib25">Jimenez et al., 2018</xref>; <xref ref-type="bibr" rid="bib27">Klaus et al., 2017</xref>; <xref ref-type="bibr" rid="bib28">Lin et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Murugan et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Murugan et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">Rodriguez-Romaguera et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">Tombaz et al., 2016</xref>; <xref ref-type="bibr" rid="bib52">Ung et al., 2017</xref>; <xref ref-type="bibr" rid="bib56">Yu et al., 2017</xref>; <xref ref-type="bibr" rid="bib29">Mackevicius et al., 2017</xref>; <xref ref-type="bibr" rid="bib30">Madangopal et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Roberts et al., 2017</xref>; <xref ref-type="bibr" rid="bib47">Ryan et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Roberts et al., 2017</xref>; <xref ref-type="bibr" rid="bib48">Sheintuch et al., 2017</xref>).</p><p>We have released our MATLAB implementation of CNMF-E as open-source software (<ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/CNMF_E">https://github.com/zhoupc/CNMF_E</ext-link> (<xref ref-type="bibr" rid="bib58">Zhou, 2017a</xref>)). A Python implementation has also been incorporated into the CaImAn toolbox (<xref ref-type="bibr" rid="bib18">Giovannucci et al., 2017b</xref>). We welcome additions or suggestions for modifications of the code, and hope that the large and growing microendoscopic imaging community finds CNMF-E to be a helpful tool in furthering neuroscience research.</p></sec></sec><sec id="s3" sec-type="materials|methods"><title>Materials and methods</title><sec id="s3-1"><title>Algorithm for solving problem (P-S)</title><p>In problem (P-S), <inline-formula><mml:math id="inf160"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is unconstrained and can be updated in closed form: <inline-formula><mml:math id="inf161"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mn>ùüè</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. By plugging this update into problem (P-S), we get a reduced problem<disp-formula id="equ13"><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(P-S')</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>minimize</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi/><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mover><mml:mi>Y</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>‚àí</mml:mo><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi>A</mml:mi><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf162"><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mo>‚Å¢</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mn>ùüèùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mo>‚Å¢</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mn>ùüèùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. We approach this problem using a version of ‚Äùhierarchical alternating least squares‚Äô (HALS; <xref ref-type="bibr" rid="bib8">Cichocki et al., 2007</xref>), a standard algorithm for nonnegative matrix factorization. (<xref ref-type="bibr" rid="bib15">Friedrich et al., 2017b</xref>) modified the fastHALS algorithm (<xref ref-type="bibr" rid="bib7">Cichocki and Phan, 2009</xref>) to estimate the nonnegative spatial components <inline-formula><mml:math id="inf164"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi></mml:mrow></mml:math></inline-formula> and the nonnegative temporal activity <inline-formula><mml:math id="inf165"><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">ùíá</mml:mi></mml:mrow></mml:math></inline-formula> in the CNMF model <inline-formula><mml:math id="inf166"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ùíá</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> by including sparsity and localization constraints. We solve a problem similar to the subproblem solved in <xref ref-type="bibr" rid="bib15">Friedrich et al. (2017b</xref>):<disp-formula id="equ14"><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(P-S')</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>minimize</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi/><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mover><mml:mi>Y</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>‚àí</mml:mo><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi>A</mml:mi><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf167"><mml:msub><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> denotes the the spatial patch constraining the nonzero pixels of the <inline-formula><mml:math id="inf168"><mml:mi>k</mml:mi></mml:math></inline-formula>-th neuron and restricts the candidate spatial support of neuron <inline-formula><mml:math id="inf169"><mml:mi>k</mml:mi></mml:math></inline-formula>. This regularization reduces the number of free parameters in <inline-formula><mml:math id="inf170"><mml:mi>A</mml:mi></mml:math></inline-formula>, leading to speed and accuracy improvements. The spatial patches can be determined using a mildly dilated version of the support of the previous estimate of <inline-formula><mml:math id="inf171"><mml:mi>A</mml:mi></mml:math></inline-formula>¬†(<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Friedrich et al., 2017a</xref>).</p></sec><sec id="s3-2"><title>Algorithms for solving problem (P-T)</title><p>In problem (P-T), the model variable <inline-formula><mml:math id="inf172"><mml:mrow><mml:mi>C</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mi>‚Ñù</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> could be very large, making the direct solution of (P-T) computationally expensive. Unlike problem (P-S), the problem (P-T) cannot be readily parallelized because the constraints <inline-formula><mml:math id="inf173"><mml:mrow><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>‚Å¢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>‚â•</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> couple the entries within each row of C, and the residual term couples entries across columns. Here, we follow the block coordinate-descent approach used in (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>) and propose an algorithm that sequentially updates each <inline-formula><mml:math id="inf174"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf175"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. For each neuron, we start with a simple unconstrained estimate of <inline-formula><mml:math id="inf176"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, denoted as <inline-formula><mml:math id="inf177"><mml:mover accent="true"><mml:msub><mml:mi mathvariant="bold-italic">ùíö</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>, that minimizes the residual of the spatiotemporal data matrix while fixing other neurons‚Äô spatiotemporal activity and the baseline term <inline-formula><mml:math id="inf178"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>,<disp-formula id="equ15"><label>(9)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>argmin</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">‚àñ</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">‚àñ</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>‚àí</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>‚ãÖ</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mtext>res</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mtext>res</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:mrow><mml:mover><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>‚àí</mml:mo><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> represents the residual given the current estimate of the model variables. Due to its unconstrained nature, <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a noisy estimate of <inline-formula><mml:math id="inf181"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, plus a constant baseline resulting from inaccurate estimation of <inline-formula><mml:math id="inf182"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. Given <inline-formula><mml:math id="inf183"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíö</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, various deconvolution algorithms can be applied to obtain the denoised trace <inline-formula><mml:math id="inf184"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and deconvolved signal <inline-formula><mml:math id="inf185"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíî</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>(<xref ref-type="bibr" rid="bib54">Vogelstein et al., 2009</xref>; <xref ref-type="bibr" rid="bib40">Pnevmatikakis et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Deneux et al., 2016</xref>; <xref ref-type="bibr" rid="bib15">Friedrich et al., 2017b</xref>; <xref ref-type="bibr" rid="bib23">Jewell and Witten, 2017</xref>); in CNMF-E, we use the OASIS algorithm from (<xref ref-type="bibr" rid="bib15">Friedrich et al., 2017b</xref>). (Note that the estimation of <inline-formula><mml:math id="inf186"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is not dependent on accurate estimation of <inline-formula><mml:math id="inf187"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, because the algorithm for estimating <inline-formula><mml:math id="inf188"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> will also automatically estimate the baseline term in <inline-formula><mml:math id="inf189"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíö</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>.) After the <inline-formula><mml:math id="inf190"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>‚Äôs are updated, we update <inline-formula><mml:math id="inf191"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> using the closed-form expression <inline-formula><mml:math id="inf192"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚ãÖ</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mn>ùüè</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><sec id="s3-2-1"><title>Estimating background by solving problem (P-B)</title><p>Next we discuss our algorithm for estimating the spatiotemporal background signal by solving problem (P-B) as a linear regression problem given <inline-formula><mml:math id="inf193"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf194"><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>. Since <inline-formula><mml:math id="inf195"><mml:mrow><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>‚ãÖ</mml:mo><mml:mn>ùüè</mml:mn></mml:mrow><mml:mo>=</mml:mo><mml:mn>ùüé</mml:mn></mml:mrow></mml:math></inline-formula>, we can easily estimate the constant baselines for each pixel as<disp-formula id="equ16"><label>(10)</label><mml:math id="m16"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚ãÖ</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mn>1.</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Next we replace the <inline-formula><mml:math id="inf196"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> in (P-B) with this estimate and rewrite (P-B) as<disp-formula id="equ17"><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt"><mml:mlabeledtr><mml:mtd><mml:mtext>(P-W)</mml:mtext></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mover><mml:mstyle displaystyle="false" scriptlevel="1"><mml:mi>W</mml:mi></mml:mstyle><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mtext>minimize</mml:mtext></mml:mstyle></mml:mrow></mml:mover></mml:mrow></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi/><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>‚àí</mml:mo><mml:mi>W</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mtd><mml:mtd/></mml:mlabeledtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àâ</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚ãÖ</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Given the optimized <inline-formula><mml:math id="inf198"><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>, our estimation of the fluctuating background is <inline-formula><mml:math id="inf199"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The new optimization problem (P-W) can be readily parallelized into <inline-formula><mml:math id="inf200"><mml:mi>d</mml:mi></mml:math></inline-formula> linear regression problems for each pixel separately. By estimating all row columns of <inline-formula><mml:math id="inf201"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula>, we are able to obtain the whole background signal as<disp-formula id="equ18"><label>(11)</label><mml:math id="m18"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In some cases, <inline-formula><mml:math id="inf202"><mml:mi>X</mml:mi></mml:math></inline-formula> might include large residuals from the inaccurate estimation of the neurons‚Äô spatiotemporal activity <inline-formula><mml:math id="inf203"><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula>, for¬†example, missing neurons in the estimation. These residuals act as outliers and distort the estimation of <inline-formula><mml:math id="inf204"><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf205"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. To overcome this problem, we use robust least squares regression (RLSR) via hard thresholding to avoid contaminations from the outliers (<xref ref-type="bibr" rid="bib3">Bhatia et al., 2015</xref>). Before solving the problem (P-W), we compute <inline-formula><mml:math id="inf206"><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mo>-</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚ãÖ</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (the current estimate of the fluctuating background) and then apply a simple clipping preprocessing step to <inline-formula><mml:math id="inf207"><mml:mi>X</mml:mi></mml:math></inline-formula>:<disp-formula id="equ19"><label>(12)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>‚àí</mml:mo></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:msub><mml:mi mathvariant="normal">X</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo>‚â•</mml:mo><mml:msubsup><mml:mi mathvariant="normal">B</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mo>‚àí</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>Œ∂</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:msub><mml:mi>œÉ</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Then we update the regression estimate using <inline-formula><mml:math id="inf208"><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>l</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>i</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>p</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>p</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>e</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> instead of <inline-formula><mml:math id="inf209"><mml:mi>X</mml:mi></mml:math></inline-formula>, and iterate. Here, <inline-formula><mml:math id="inf210"><mml:msub><mml:mi>œÉ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the standard deviation of the noise at <inline-formula><mml:math id="inf211"><mml:msub><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and its value can be estimated using the power spectral density (PSD) method (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>). As for the first iteration of the model fitting, we set each <inline-formula><mml:math id="inf212"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>‚àí</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>‚àë</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>‚àà</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> as the mean of the <inline-formula><mml:math id="inf213"><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for all <inline-formula><mml:math id="inf214"><mml:mrow><mml:mi>j</mml:mi><mml:mo>‚àà</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The thresholding coefficient <inline-formula><mml:math id="inf215"><mml:mi>Œ∂</mml:mi></mml:math></inline-formula> can be specified by users, although we have found a fixed default works well across the datasets used here. This preprocessing removes most calcium transients by replacing those frames with the previously estimated background only. As a result, it increases the robustness to inaccurate estimation of <inline-formula><mml:math id="inf216"><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula>, and in turn leads to a better extraction of <inline-formula><mml:math id="inf217"><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> in the following iterations.</p></sec></sec><sec id="s3-3"><title>Initialization of model variables</title><p>Since problem (P-All) is not convex in all of its variables, a good initialization of model variables is crucial for fast convergence and accurate extraction of all neurons‚Äô spatiotemporal activity. Previous methods assume the background component is relatively weak, allowing us to initialize <inline-formula><mml:math id="inf218"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf219"><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> while ignoring the background or simply initializing it with a constant baseline over time. However, the noisy background in microendoscopic data fluctuates more strongly than the neural signals (c.f. <xref ref-type="fig" rid="fig6">Figure 6C</xref> and <xref ref-type="fig" rid="fig7">Figure 7B</xref>), which makes previous methods less valid for the initialization of CNMF-E.</p><p>Here, we design a new algorithm to initialize <inline-formula><mml:math id="inf220"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf221"><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> without estimating <inline-formula><mml:math id="inf222"><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>. The whole procedure is illustrated in <xref ref-type="fig" rid="fig10">Figure 10</xref> and described in Algorithm 1. The key aim of our algorithm is to exploit the relative spatial smoothness in the background compared to the single neuronal signals visible in the focal plane. Thus, we can use spatial filtering to reduce the background in order to estimate single neurons‚Äô temporal activity, and then initialize each neuron‚Äôs spatial footprint given these temporal traces. Once we have initialized <inline-formula><mml:math id="inf223"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf224"><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>, it is straightforward to initialize the constant baseline <inline-formula><mml:math id="inf225"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and the fluctuating background <inline-formula><mml:math id="inf226"><mml:msup><mml:mi>B</mml:mi><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> by solving problem (P-B).</p><fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.023</object-id><label>Figure 10.</label><caption><title>Illustration of the initialization procedure.</title><p>(<bold>A</bold>) Raw video data and the kernel for filtering the video data. (<bold>B</bold>) The spatially high-pass filtered data. (<bold>C</bold>) The local correlation image and the peak-to-noise ratio (PNR) image calculated from the filtered data in (<bold>B</bold>). (<bold>D</bold>) The temporal correlation coefficients between the filtered traces (<bold>B</bold>) of the selected seed pixel (the red cross) and all other pixels in the cropped area as shown in (<bold>A‚ÄìC</bold>). The red and green contour correspond to correlation coefficients equal to 0.7¬†and 0.3, respectively. (<bold>E</bold>) The estimated background fluctuation <inline-formula><mml:math id="inf227"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (green) and the initialized temporal trace <inline-formula><mml:math id="inf228"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the neuron (red). <inline-formula><mml:math id="inf229"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is computed as the median of the raw fluorescence traces of all pixels (green area) outside of the green contour shown in (<bold>D</bold>) and <inline-formula><mml:math id="inf230"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is computed as the mean of the filtered fluorescence traces of all pixels inside the red contour. (<bold>F</bold>) The decomposition of the raw video data within the cropped area. Each component is a rank-<inline-formula><mml:math id="inf231"><mml:mn>1</mml:mn></mml:math></inline-formula> matrix and the related temporal traces are estimated in (<bold>E</bold>). The spatial components are estimated by regressing the raw video data against these three traces. See <xref ref-type="video" rid="video3">Video 3</xref> for an illustration of the initialization procedure.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-28728-fig10-v2"/></fig><sec id="s3-3-1"><title>Spatially filtering the data</title><p>We first filter the raw video data with a customized image kernel (<xref ref-type="fig" rid="fig10">Figure 10A</xref>). The kernel is generated from a Gaussian filter<disp-formula id="equ20"><label>(13)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>‚Å°</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>‚à•</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo>‚à•</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, we use <inline-formula><mml:math id="inf232"><mml:mrow><mml:mi>h</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to approximate a cell body; the factor of <inline-formula><mml:math id="inf233"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> in the Gaussian width is chosen to match a Gaussian shape to a cell of width <inline-formula><mml:math id="inf234"><mml:mi>l</mml:mi></mml:math></inline-formula>. Instead of using <inline-formula><mml:math id="inf235"><mml:mrow><mml:mi>h</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as the filtering kernel directly, we subtract its spatial mean (computed over a region of width equal to <inline-formula><mml:math id="inf236"><mml:mi>l</mml:mi></mml:math></inline-formula>) and filter the raw data with <inline-formula><mml:math id="inf237"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">¬Ø</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The filtered data is denoted as <inline-formula><mml:math id="inf238"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mi>‚Ñù</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig10">Figure 10B</xref>). This spatial filtering step helps accomplish two goals: (1) reducing the background <inline-formula><mml:math id="inf239"><mml:mi>B</mml:mi></mml:math></inline-formula>, so that <inline-formula><mml:math id="inf240"><mml:mi>Z</mml:mi></mml:math></inline-formula> is dominated by neural signals (albeit somewhat spatially distorted) in the focal plane (see <xref ref-type="fig" rid="fig10">Figure 10B</xref> as an example); (2) performing a template matching to detect cell bodies similar to the Gaussian kernel. Consequently, <inline-formula><mml:math id="inf241"><mml:mi>Z</mml:mi></mml:math></inline-formula> has large values near the center of each cell body. (However, note that we can not simply e.g. apply CNMF to <inline-formula><mml:math id="inf242"><mml:mi>Z</mml:mi></mml:math></inline-formula>, because the spatial components in a factorization of the matrix <inline-formula><mml:math id="inf243"><mml:mi>Z</mml:mi></mml:math></inline-formula> will typically no longer be nonnegative, and therefore NMF-based approaches can not be applied directly.) More importantly, the calcium traces near the neuron center in the filtered data preserve the calcium activity of the corresponding neurons because the filtering step results in a weighted average of cellular signals surrounding each pixel (<xref ref-type="fig" rid="fig10">Figure 10B</xref>). Thus, the fluorescence traces in pixels close to neuron centers in <inline-formula><mml:math id="inf244"><mml:mi>Z</mml:mi></mml:math></inline-formula> can be used for initializing the neurons‚Äô temporal activity directly. These pixels are defined as seed pixels. We next propose a quantitative method to rank all potential seed pixels.</p></sec><sec id="s3-3-2"><title>Ranking seed pixels</title><p>A seed pixel <inline-formula><mml:math id="inf245"><mml:mi mathvariant="bold-italic">ùíô</mml:mi></mml:math></inline-formula> should have two main features: first, <inline-formula><mml:math id="inf246"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the filtered trace at pixel <inline-formula><mml:math id="inf247"><mml:mi mathvariant="bold-italic">ùíô</mml:mi></mml:math></inline-formula>, should have high peak-to-noise ratio (PNR) because it encodes the calcium concentration <inline-formula><mml:math id="inf248"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> of one neuron; second, a seed pixel should have high temporal correlations with its neighboring pixels (e.g. 4 nearest neighbors) because they share the same <inline-formula><mml:math id="inf249"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>. We computed two metrics for each of these two features:<disp-formula id="equ21"><label>(14)</label><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mo stretchy="false">(</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>œÉ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:munder><mml:mo>‚àë</mml:mo><mml:mrow><mml:mtext>dist</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">‚Ä≤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mtext>corr</mml:mtext><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">‚Ä≤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Recall that <inline-formula><mml:math id="inf250"><mml:mrow><mml:mi>œÉ</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the standard deviation of the noise at pixel <inline-formula><mml:math id="inf251"><mml:mi mathvariant="bold-italic">ùíô</mml:mi></mml:math></inline-formula>; the function <inline-formula><mml:math id="inf252"><mml:mrow><mml:mtext>ùêúùê®ùê´ùê´</mml:mtext><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> refers to Pearson correlation here. In our implementation, we usually threshold <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi>Z</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> by <inline-formula><mml:math id="inf254"><mml:mrow><mml:mn>3</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>œÉ</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> before computing <inline-formula><mml:math id="inf255"><mml:mrow><mml:mi>L</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to reduce the influence of the background residuals, noise, and spikes from nearby neurons.</p><p>Most pixels can be ignored when selecting seed pixels because their local correlations or PNR values are too small. To avoid unnecessary searches of the pixels, we set thresholds for both <inline-formula><mml:math id="inf256"><mml:mrow><mml:mi>P</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf257"><mml:mrow><mml:mi>L</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and only pick pixels larger than the thresholds <inline-formula><mml:math id="inf258"><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf259"><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula>. It is empirically useful to combine both metrics for screening seed pixels. For example, high PNR values could result from large noise, but these pixels usually have small <inline-formula><mml:math id="inf260"><mml:mrow><mml:mi>L</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> because the noise is not shared with neighboring pixels. On the other hand, insufficient removal of background during the spatial filtering leads to high <inline-formula><mml:math id="inf261"><mml:mrow><mml:mi>L</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, but the corresponding <inline-formula><mml:math id="inf262"><mml:mrow><mml:mi>P</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are usually small because most background fluctuations have been removed. So we create another matrix <inline-formula><mml:math id="inf263"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>‚ãÖ</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> that computes the pixelwise product of <inline-formula><mml:math id="inf264"><mml:mrow><mml:mi>P</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf265"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>). We rank all <inline-formula><mml:math id="inf266"><mml:mrow><mml:mi>R</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in a descending order and choose the pixel <inline-formula><mml:math id="inf267"><mml:msup><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> with the largest <inline-formula><mml:math id="inf268"><mml:mrow><mml:mi>R</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for initialization.</p><p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th>Algorithm 1. Initialize model variables <inline-formula><mml:math id="inf269"><mml:mi mathsize="111%">A</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf270"><mml:mi mathsize="111%">C</mml:mi></mml:math></inline-formula> given the raw data</th></tr></thead><tbody><tr><td><inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi><mml:mi mathvariant="bold">e</mml:mi><mml:mi mathvariant="bold">q</mml:mi><mml:mi mathvariant="bold">u</mml:mi><mml:mi mathvariant="bold">i</mml:mi><mml:mi mathvariant="bold">r</mml:mi><mml:mi mathvariant="bold">e</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo mathvariant="bold">:</mml:mo></mml:mrow></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi>Y</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">z</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left right" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mn>2</mml:mn><mml:mi mathvariant="normal">D</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:msub><mml:mi>œÉ</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>œÉ</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="normal">l</mml:mi><mml:mn>4</mml:mn></mml:mfrac><mml:mo>;</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mo>√ó</mml:mo><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">D</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">G</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>2</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mover><mml:mi>h</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">‚Üê</mml:mo><mml:mi>h</mml:mi><mml:mo>‚àí</mml:mo><mml:mrow><mml:mover><mml:mi>h</mml:mi><mml:mo stretchy="false">¬Ø</mml:mo></mml:mover></mml:mrow><mml:mo>;</mml:mo><mml:mrow><mml:mover><mml:mi>h</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>√ó</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>‚àí</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>3</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>Z</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mtext>conv</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>;</mml:mo><mml:mi>Z</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>√ó</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>4</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>L</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>‚àí</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">Z</mml:mi><mml:mo>;</mml:mo></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi>L</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>5</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>P</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">Z</mml:mi><mml:mo>;</mml:mo></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi>P</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>6</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>k</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>7</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mrow><mml:mi mathvariant="bold">w</mml:mi><mml:mi mathvariant="bold">h</mml:mi><mml:mi mathvariant="bold">i</mml:mi><mml:mi mathvariant="bold">l</mml:mi><mml:mi mathvariant="bold">e</mml:mi></mml:mrow></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="bold">d</mml:mi><mml:mi mathvariant="bold">o</mml:mi></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>8</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚â§</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mtext>¬†</mml:mtext><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚â§</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mrow><mml:mi mathvariant="bold">t</mml:mi><mml:mi mathvariant="bold">h</mml:mi><mml:mi mathvariant="bold">e</mml:mi><mml:mi mathvariant="bold">n</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>9</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mo>;</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>10</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="bold">e</mml:mi><mml:mi mathvariant="bold">l</mml:mi><mml:mi mathvariant="bold">s</mml:mi><mml:mi mathvariant="bold">e</mml:mi></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left right" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>11</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:mi>k</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>12</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">‚Üê</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>13</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>‚àó</mml:mo></mml:msup><mml:mo stretchy="false">‚Üê</mml:mo><mml:msub><mml:mtext>argmax</mml:mtext><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚ãÖ</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>14</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">‚Üê</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">q</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mtext>¬†</mml:mtext></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi mathvariant="normal">l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>‚àó</mml:mo></mml:msup><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>‚àó</mml:mo></mml:msup></mml:mrow></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>15</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">‚Üê</mml:mo><mml:mtext>corr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>‚àó</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>‚àà</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>16</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:msub><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">‚Üê</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:munder><mml:mo>‚àë</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚â§</mml:mo><mml:mn>0.3</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:munder><mml:mi>Y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>‚àë</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚â§</mml:mo><mml:mn>0.3</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:munder><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mstyle></mml:mtd><mml:mtd><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/><inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left right" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>17</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">‚Üê</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:munder><mml:mo>‚àë</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚â•</mml:mo><mml:mn>0.7</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:munder><mml:mi>Z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>‚àë</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚â•</mml:mo><mml:mn>0.7</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:munder><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>‚àà</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>18</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">‚Üê</mml:mo><mml:msub><mml:mtext>argmin</mml:mtext><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="normal">Œ©</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>‚àí</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo>‚ãÖ</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>‚ãÖ</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>‚ãÖ</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>19</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">‚Üê</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">k</mml:mi><mml:mo>‚àí</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>20</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:mi>Y</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mi>Y</mml:mi><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo>‚ãÖ</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mstyle></mml:mtd><mml:mtd><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>‚ñπ</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:msup><mml:mi mathvariant="normal">n</mml:mi><mml:mo>‚Ä≤</mml:mo></mml:msup><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>21</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mspace width="2em"/><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mtext>¬†</mml:mtext><mml:mi mathvariant="normal">Y</mml:mi></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>22</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>A</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>‚ãØ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>23</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mi>C</mml:mi><mml:mo stretchy="false">‚Üê</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>‚ãØ</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mi>T</mml:mi></mml:msup></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>24</mml:mn><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mo>:</mml:mo><mml:mtext>¬†</mml:mtext><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mi mathvariant="bold">e</mml:mi><mml:mi mathvariant="bold">t</mml:mi><mml:mi mathvariant="bold">u</mml:mi><mml:mi mathvariant="bold">r</mml:mi><mml:mi mathvariant="bold">n</mml:mi></mml:mrow></mml:mrow><mml:mtext>¬†</mml:mtext><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mstyle></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></p></sec><sec id="s3-3-3"><title>Greedy initialization</title><p>Our initialization method greedily initializes neurons one by one. Every time we initialize a neuron, we will remove its initialized spatiotemporal activity from the raw video data and initialize the next neuron from the residual. For the same neuron, there are several seed pixels that could be used to initialize it. But once the neuron has been initialized from any of these seed pixels (and the spatiotemporal residual matrix has been updated by peeling away the corresponding activity), the remaining seed pixels related to this neuron have lowered PNR and local correlation. This helps avoid the duplicate initialization of the same neuron. Also, <inline-formula><mml:math id="inf275"><mml:mrow><mml:mi>P</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf276"><mml:mrow><mml:mi>L</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> have to be updated after each neuron is initialized, but since only a small area near the initialized neuron is affected, we can update these quantities locally to reduce the computational cost. This procedure is repeated until the specified number of neurons have been initialized or no more candidate seed pixels exist.</p><p>This initialization algorithm can greedily initialize the required number of neurons, but the subproblem of estimating <inline-formula><mml:math id="inf277"><mml:msub><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> given <inline-formula><mml:math id="inf278"><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> still has to deal with the large background activity in the residual matrix. We developed a simple method to remove this background and accurately initialize neuron shapes, described next. We first crop a <inline-formula><mml:math id="inf279"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>√ó</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> square centered at <inline-formula><mml:math id="inf280"><mml:msup><mml:mi mathvariant="bold-italic">ùíô</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> in the field of view (<xref ref-type="fig" rid="fig10">Figure 10A‚ÄìE</xref>). Then we compute the temporal correlation between the filtered traces of pixel <inline-formula><mml:math id="inf281"><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> and all other pixels in the patch (<xref ref-type="fig" rid="fig10">Figure 10D</xref>). We choose those pixels with small temporal correlations (e.g. 0.3) as the neighboring pixels that are outside of the neuron (the green contour in <xref ref-type="fig" rid="fig10">Figure 10D</xref>). Next, we estimate the background fluctuations as the median values of these pixels for each frame in the raw data (<xref ref-type="fig" rid="fig10">Figure 10E</xref>). We also select pixels that are within the neuron by selecting correlation coefficients larger than <inline-formula><mml:math id="inf282"><mml:mn>0.7</mml:mn></mml:math></inline-formula>, then <inline-formula><mml:math id="inf283"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is refined by computing the mean filtered traces of these pixels (<xref ref-type="fig" rid="fig10">Figure 10E</xref>). Finally, we regress the raw fluorescence signal in each pixel onto three sources: the neuron signal (<xref ref-type="fig" rid="fig10">Figure 10E</xref>), the local background fluctuation (<xref ref-type="fig" rid="fig10">Figure 10F</xref>), and a constant baseline. Our initial estimate of <inline-formula><mml:math id="inf284"><mml:msub><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is given by the regression weights onto <inline-formula><mml:math id="inf285"><mml:msub><mml:mover accent="true"><mml:mi>c</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> in <xref ref-type="fig" rid="fig10">Figure 10F</xref>.</p></sec><sec id="s3-3-4"><title>Modifications for high temporal or spatial correlation</title><p>The above procedure works well in most experimental datasets as long as neurons are not highly spatially overlapped and temporally correlated. However, in a few extreme cases, this initialization may lead to bad local minima. We found that two practical modifications can lead to improved results.</p><sec id="s3-3-4-1"><title>High temporal correlation, low spatial overlaps</title><p>The greedy initialization procedure assumes that closeby neurons are not highly correlated. If this assumption fails, CNMF-E will first merge nearby neurons into one component for explaining the shared fluctuations, and then the following initialized components will only capture the residual signals of each neuron. Our solution to this issue relies on our accurate background removal procedure, after which we simply re-estimate each neural trace <inline-formula><mml:math id="inf286"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> as a weighted fluorescence trace of the background-subtracted video <inline-formula><mml:math id="inf287"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>,<disp-formula id="equ22"><label>(15)</label><mml:math id="m22"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mo>‚ãÖ</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>‚Å¢</mml:mo><mml:msup><mml:mn>ùüè</mml:mn><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mo>‚ãÖ</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf288"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> only selects pixels with large weights by thresholding the estimated <inline-formula><mml:math id="inf289"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> with <inline-formula><mml:math id="inf290"><mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo>‚Å°</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÇ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> (this reduces the contributions from smaller neighboring neurons). This strategy improves the extraction of individual neurons‚Äô traces in the high correlation scenarios and the spatial footprints can be corrected in the following step of updating <inline-formula><mml:math id="inf291"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>. <xref ref-type="fig" rid="fig4">Figure 4B</xref> and <xref ref-type="fig" rid="fig5">Figure 5</xref> illustrate this procedure.</p></sec><sec id="s3-3-4-2"><title>High spatial overlaps, low temporal correlation</title><p>CNMF-E may initialize components with shared temporal traces because they have highly overlapping areas. We solve this problem by de-correlating their traces (following a similar approach in [<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>]). We start by assuming that neurons with high spatial overlap do not fire spikes within the same frame. If so, only the inferred spiking trace with the largest value is kept and the rest will be set to 0. Then we initialize each <inline-formula><mml:math id="inf292"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> given these thresholded spiking traces and the corresponding AR coefficients.</p></sec></sec></sec><sec id="s3-4"><title>Interventions</title><p>We use iterative matrix updates to estimate model variables in CNMF-E. This strategy gives us the flexibility of integrating prior information on neuron morphology and temporal activity during the model fitting. The resulting interventions (which can in principle be performed either automatically or under manual control) can in turn lead to faster convergence and more accurate source extraction. We integrate 5 interventions in our CNMF-E implementation. Following these interventions, we usually run one more iteration of matrix updates.</p><sec id="s3-4-1"><title>Merge existing components</title><p>When a single neuron is split mistakenly into multiple components, a merge step is necessary to rejoin these components. If we can find all split components, we can superimpose all their spatiotemporal activities and run rank-1 NMF to obtain the spatial and temporal activity of the merged neuron. We automatically merge components for which the spatial and temporal components are correlated above certain thresholds. Our code also provides methods to manually specify neurons to be merged based on human judgment.</p></sec><sec id="s3-4-2"><title>Split extracted components</title><p>When highly correlated neurons are mistakenly merged into one component, we need to use spatial information to split into multiple components according to neurons‚Äô morphology. Our current implementation of component splitting requires users to manually draw ROIs for splitting the spatial footprint of the extracted component. Automatic methods for ROI segmentation (<xref ref-type="bibr" rid="bib1">Apthorpe et al., 2016</xref>; <xref ref-type="bibr" rid="bib37">Pachitariu et al., 2013</xref>) could be added as an alternative in future implementations.</p></sec><sec id="s3-4-3"><title>Remove false positives</title><p>Some extracted components have spatial shapes that do not correspond to real neurons or temporal traces that do not correspond to neural activity. These components might explain some neural signals or background activity mistakenly. Our source extraction can benefit from the removal of these false positives. This can be done by manually examining all extracted components, or in principle automatically by training a classifier for detecting real neurons. The current implementation relies on visual inspection to exclude false positives. We also rank neurons based on their SNRs and set a cutoff to discard all extracted components that fail to meet this cutoff. As with the splitting step, removing false positives could also potentially use automated ROI detection algorithms in the future. See <xref ref-type="video" rid="video10">Video 10</xref> for an example involving manual merge and delete operations.</p></sec><sec id="s3-4-4"><title>Pick undetected neurons from the residual</title><p>If all neural signals and background are accurately estimated, the residual of the CNMF-E model <inline-formula><mml:math id="inf293"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mtext>res</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula> should be relatively spatially and temporally uncorrelated. However, the initialization might miss some neurons due to large background fluctuations and/or high neuron density. After we estimate the background <inline-formula><mml:math id="inf294"><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> and extract a majority of the neurons, those missed neurons have prominent fluorescent signals left in the residual. To select these undetected neurons from the residual <inline-formula><mml:math id="inf295"><mml:msub><mml:mi>Y</mml:mi><mml:mtext>res</mml:mtext></mml:msub></mml:math></inline-formula>, we use the same algorithm as for initializing neurons from the raw video data, but typically now the task is easier because the background has been removed.</p></sec><sec id="s3-4-5"><title>Post-process the spatial footprints</title><p>Each single neuron has localized spatial shapes and including this prior into the model fitting of CNMF-E, as suggested in (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>), leads to better extraction of spatial footprints. In the model fitting step, we constrain <inline-formula><mml:math id="inf296"><mml:mi>A</mml:mi></mml:math></inline-formula> to be sparse and spatially localized. These constraints do give us compact neuron shapes in most cases, but in some cases there are still some visually abnormal components detected. We include a heuristic automated post-processing step after each iteration of updating spatial shapes (P-S). For each extracted neuron <inline-formula><mml:math id="inf297"><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>:</mml:mo><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we first convert it to a 2D image and perform morphological opening to remove isolated pixels resulting from noise (<xref ref-type="bibr" rid="bib19">Haralick et al., 1987</xref>). Next we label all connected components in the image and create a mask to select the largest component. All pixels outside of the mask in <inline-formula><mml:math id="inf298"><mml:mrow><mml:mi>A</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>:</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are set to be. This post-processing induces compact neuron shapes by removing extra pixels and helps avoid mistakenly explaining the fluorescence signals of the other neurons.</p></sec></sec><sec id="s3-5"><title>Further algorithmic details</title><p>The simplest pipeline for running CNMF-E includes the following steps:</p><list id="I1" list-type="order"><list-item><p>Initialize <inline-formula><mml:math id="inf299"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> using the proposed initialization procedure.</p></list-item><list-item><p>Solve problem (P-B) for updates of <inline-formula><mml:math id="inf300"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf301"><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula>.</p></list-item><list-item><p>Iteratively solve problem (P-S) and (P-T) to update <inline-formula><mml:math id="inf302"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo rspace="5.8pt">,</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf303"><mml:msub><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>.</p></list-item><list-item><p>If desired, apply interventions to intermediate results.</p></list-item><list-item><p>Repeat steps 2, 3, and 4 until the inferred components are stable.</p></list-item></list><p>In practice, the estimation of the background <inline-formula><mml:math id="inf304"><mml:mi>B</mml:mi></mml:math></inline-formula> (step 2) often does not vary greatly from iteration to iteration and so this step usually can be run with fewer iterations to save time. In practice, we also use spatial and temporal decimation for improved speed, following (<xref ref-type="bibr" rid="bib14">Friedrich et al., 2017a</xref>). We first run the pipeline on decimated data to get good initializations, then we up-sample the results <inline-formula><mml:math id="inf305"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> to the original resolution and run one iteration of steps (2-3) on the raw data. This strategy improves on processing the raw data directly because downsampling increases the signal-to-noise ratio and eliminates many false positives.</p><p>Step 4 provides a fast method for correcting abnormal components without redoing the whole analysis. (This is an important improvement over the PCA/ICA pipeline, where if users encounter poor estimated components it is necessary to repeat the whole analysis with new parameter values, which may not necessarily yield improved cell segmentations.) The interventions described here themselves can be independent tasks in calcium imaging analysis; with further work we expect many of these steps can be automated. In our interface for performing manual interventions, the most frequently used function is to remove false positives. Again, components can be rejected following visual inspection in PCA/ICA analysis, but the performance of CNMF-E can be improved with further iterations after removing false positives, while this is not currently an option for PCA/ICA.</p><p>We have also found a two-step initialization procedure useful for detecting neurons: we first start from relatively high thresholds of <inline-formula><mml:math id="inf306"><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf307"><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> to initialize neurons with large activity from the raw video data; then we estimate the background components by solving problem (P-B); finally we can pick undetected neurons from the residual using smaller thresholds. We can terminate the model iterations when the residual sum of squares (RSS) stabilizes (see <xref ref-type="fig" rid="fig4">Figure 4B</xref>), but this is seldom used in practice because computing the RSS is time-consuming. Instead we usually automatically stop the iterations after the number of detected neurons stabilizes. If manual interventions are performed, we typically run one last iteration of updating <inline-formula><mml:math id="inf308"><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf309"><mml:mi>C</mml:mi></mml:math></inline-formula> sequentially to further refine the results.</p><sec id="s3-5-1"><title>Parameter selection</title><p><xref ref-type="table" rid="table2">Table 2</xref> shows 5 key parameters used in CNMF-E. All of these parameters have interpretable meaning and can be easily picked within a broad range. The parameter <inline-formula><mml:math id="inf310"><mml:mi>l</mml:mi></mml:math></inline-formula> controls the size of the spatial filter in the initialization step and is chosen as the diameter of a typical neuron in the FOV. As long as <inline-formula><mml:math id="inf311"><mml:mi>l</mml:mi></mml:math></inline-formula> is much smaller than local background sources, the filtered data can be used for detecting seed pixels and then initializing neural traces. The distance between each seed pixel and its selected neighbors <inline-formula><mml:math id="inf312"><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> has to be larger than the neuron size <inline-formula><mml:math id="inf313"><mml:mi>l</mml:mi></mml:math></inline-formula> and smaller than the spatial range of local background sources; in practice, this range is fairly broad. We usually set <inline-formula><mml:math id="inf314"><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> as <inline-formula><mml:math id="inf315"><mml:mrow><mml:mn>2</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula>. To determine the thresholds <inline-formula><mml:math id="inf316"><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf317"><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula>, we first compute the correlation image and PNR image and then visually select very weak neurons from these two images. <inline-formula><mml:math id="inf318"><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf319"><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> are determined to ensure that CNMF-E is able to choose seed pixels from these weak neurons. Small <inline-formula><mml:math id="inf320"><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf321"><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula> yield more false positive neurons, but they can be removed in the intervention step. Finally, in practice, our results are not sensitive to the selection of the outlier parameter <inline-formula><mml:math id="inf322"><mml:mi>Œ∂</mml:mi></mml:math></inline-formula>, thus we frequently set it as 10.</p><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.024</object-id><label>Table 2.</label><caption><title>Optional user-specified parameters.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Name</th><th>Description</th><th>Default values</th><th>Used in</th></tr></thead><tbody><tr><td><inline-formula><mml:math id="inf323"><mml:mi>l</mml:mi></mml:math></inline-formula></td><td>size of a typical neuron soma in the FOV</td><td><inline-formula><mml:math id="inf324"><mml:mrow><mml:mn>30</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>Œº</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td><td>Algorithm 1</td></tr><tr><td><inline-formula><mml:math id="inf325"><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula></td><td>the distance between each pixel and its neighbors</td><td><inline-formula><mml:math id="inf326"><mml:mrow><mml:mn>60</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>Œº</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td><td>Problem (P-B)</td></tr><tr><td><inline-formula><mml:math id="inf327"><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula></td><td>the minimum peak-to-noise ratio of seed pixels</td><td>10</td><td>Algorithm 1</td></tr><tr><td><inline-formula><mml:math id="inf328"><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub></mml:math></inline-formula></td><td>the minimum local correlation of seed pixels</td><td>0.8</td><td>Algorithm 1</td></tr><tr><td><inline-formula><mml:math id="inf329"><mml:mi>Œ∂</mml:mi></mml:math></inline-formula></td><td>the ratio between the outlier threshold and the noise</td><td>10</td><td>Problem (P-B)</td></tr></tbody></table></table-wrap></sec><sec id="s3-5-2"><title>Complexity analysis</title><p>In step 1, the time cost is mainly determined by spatial filtering, resulting in <inline-formula><mml:math id="inf330"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> time. As for the initialization of a single neuron given a seed pixel, it is only (<inline-formula><mml:math id="inf331"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). Considering the fact that the number of neurons is typically much smaller than the number of pixels in this data, the complexity for step one remains <inline-formula><mml:math id="inf332"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In step 2, the complexity of estimating <inline-formula><mml:math id="inf333"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíÉ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is <inline-formula><mml:math id="inf334"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and estimating <inline-formula><mml:math id="inf335"><mml:msup><mml:mover accent="true"><mml:mi>B</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msup></mml:math></inline-formula> scales linearly with the number of pixels <inline-formula><mml:math id="inf336"><mml:mi>d</mml:mi></mml:math></inline-formula>. For each pixel, the computational complexity for estimating <inline-formula><mml:math id="inf337"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> is <inline-formula><mml:math id="inf338"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, the computational complexity in updating the background component is <inline-formula><mml:math id="inf339"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In step 3, the computational complexities of solving problems (P-S) and (P-T) have been discussed in previous literature (<xref ref-type="bibr" rid="bib41">Pnevmatikakis et al., 2016</xref>) and they scale linearly with pixel number <inline-formula><mml:math id="inf340"><mml:mi>d</mml:mi></mml:math></inline-formula> and time <inline-formula><mml:math id="inf341"><mml:mi>T</mml:mi></mml:math></inline-formula>, that¬†is, <inline-formula><mml:math id="inf342"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For the interventions, the one with the largest computational cost is picking undetected neurons from the residual, which is the same as the initialization step. Therefore, the computational cost for step 4 is <inline-formula><mml:math id="inf343"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. To summarize, the complexity for running CNMF-E is <inline-formula><mml:math id="inf344"><mml:mrow><mml:mi>O</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, that¬†is, the method scales linearly with both the number of pixels and the total recording time.</p></sec><sec id="s3-5-3"><title>Implementations</title><p>Our MATLAB implementation supports running CNMF-E in three different modes that are optimized for different datasets: single-mode, patch-mode and multi-batch-mode.</p><p>Single-mode is a naive implementation that loads data into memory and fits the model. It is fast for processing small datasets (&lt;1 GB).</p><p>For larger datasets, many computers have insufficient RAM for loading all data into memory and storing intermediate results. Patch-mode CNMF-E divides the whole FOV into multiple small patches and maps data to the hard drive (<xref ref-type="bibr" rid="bib18">Giovannucci et al., 2017b</xref>). The data within each patch are loaded only when we process that patch. This significantly reduces the memory consumption. More importantly, this mode allows running CNMF-E in parallel on multi-core CPUs, yielding a speed-up roughly proportional to the number of available cores.</p><p>Multi-batch mode builds on patch-mode and is optimized for even larger datasets, especially data collected over multiple sessions/days. This mode segments data into multiple batches temporally and assumes that the neuron footprints <inline-formula><mml:math id="inf345"><mml:mi>A</mml:mi></mml:math></inline-formula> are shared across all batches. We process each batch using patch mode and perform partial weighted updates on <inline-formula><mml:math id="inf346"><mml:mi>A</mml:mi></mml:math></inline-formula> given the traces <inline-formula><mml:math id="inf347"><mml:mi>C</mml:mi></mml:math></inline-formula> obtained in each batch.</p><p>All modes also include a logging system for keeping track of manual interventions and intermediate operations.</p><p>The Python implementation is similar; see <xref ref-type="bibr" rid="bib18">Giovannucci et al., 2017b</xref>) for full details.</p></sec><sec id="s3-5-4"><title>Running time</title><p>To provide a sense of the running time of the different steps of the algorithm, we timed the code on the simulation data shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>. This dataset is <inline-formula><mml:math id="inf348"><mml:mrow><mml:mn>253</mml:mn><mml:mo>√ó</mml:mo><mml:mn>316</mml:mn></mml:mrow></mml:math></inline-formula> pixels <inline-formula><mml:math id="inf349"><mml:mrow><mml:mi/><mml:mo>√ó</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula> frames. The analyses were performed on a desktop with Intel Xeon CPU E5-2650 v4 @2.20 GHz and 128 GB RAM running Ubuntu 16.04. We used a parallel implementation for performing the CNMF-E analysis, with patch size <inline-formula><mml:math id="inf350"><mml:mrow><mml:mn>64</mml:mn><mml:mo>√ó</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:math></inline-formula> pixels, using up to 12 cores. PCA/ICA took <inline-formula><mml:math id="inf351"><mml:mrow><mml:mi/><mml:mo>‚àº</mml:mo><mml:mn>211</mml:mn></mml:mrow></mml:math></inline-formula> seconds to converge, using 250 PCs and 220 ICs. CNMF-E spent 55 s for initialization, 1 s for merging and deleting components, 110 s for the first round of the background estimation and 40 s in the following updates, 8 s for picking neurons from the residual, and 10 s per iteration for updating spatial (<inline-formula><mml:math id="inf352"><mml:mi>A</mml:mi></mml:math></inline-formula>) and temporal (<inline-formula><mml:math id="inf353"><mml:mi>C</mml:mi></mml:math></inline-formula>) components, resulting in a total of 258 s.</p><p>Finally, <xref ref-type="table" rid="table3">Table 3</xref> shows the running time of processing the four experimental datasets.</p><table-wrap id="table3" position="float"><object-id pub-id-type="doi">10.7554/eLife.28728.025</object-id><label>Table 3.</label><caption><title>Running time (sec) for processing the 4 experimental datasets.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Striatum</th><th>PFC<break/></th><th>Hippocampus</th><th>BNST<break/></th></tr></thead><tbody><tr><td>Size (<italic>x</italic> √ó <italic>y</italic> √ó <italic>t</italic>)</td><td>256¬†√ó¬†256¬†√ó¬†6000</td><td>175¬†√ó¬†184¬†√ó¬†9000</td><td>175¬†√ó¬†184¬†√ó¬†9000</td><td>175¬†√ó¬†184¬†√ó¬†9000</td></tr><tr><td>(# PCs, # ICs)</td><td>(2000,¬†700)</td><td>(275,¬†250)</td><td>(100,¬†50)</td><td>(200,¬†150)</td></tr><tr><td>PFC/ICA</td><td>986</td><td>181</td><td>174</td><td>52</td></tr><tr><td>CNMF-E</td><td>726</td><td>221</td><td>225</td><td>435</td></tr></tbody></table></table-wrap></sec></sec><sec id="s3-6"><title>Simulation experiments</title><sec id="s3-6-1"><title>Details of the simulated experiment of <xref ref-type="fig" rid="fig2">Figure 2</xref></title><p>The field of view was <inline-formula><mml:math id="inf354"><mml:mrow><mml:mn>256</mml:mn><mml:mo>√ó</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:math></inline-formula>, with 1000 frames. We simulated 50 neurons whose shapes were simulated as spherical 2-D Gaussian. The neuron centers were drawn uniformly from the whole FOV and the Gaussian widths <inline-formula><mml:math id="inf355"><mml:msub><mml:mi>œÉ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf356"><mml:msub><mml:mi>œÉ</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math></inline-formula> for each neuron was also randomly drawn from <inline-formula><mml:math id="inf357"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ùí©</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mfrac><mml:mi>l</mml:mi><mml:mn>4</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>10</mml:mn></mml:mfrac><mml:mo>‚Å¢</mml:mo><mml:mfrac><mml:mi>l</mml:mi><mml:mn>4</mml:mn></mml:mfrac></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf358"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:math></inline-formula> pixels. Spikes were simulated from a Bernoulli process with probability of spiking per timebin <inline-formula><mml:math id="inf359"><mml:mn>0.01</mml:mn></mml:math></inline-formula> and then convolved with a temporal kernel <inline-formula><mml:math id="inf360"><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mo>‚Å¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>‚Å°</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>œÑ</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>‚Å°</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>œÑ</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with fall time <inline-formula><mml:math id="inf361"><mml:mrow><mml:msub><mml:mi>œÑ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> timebin and rise time <inline-formula><mml:math id="inf362"><mml:mrow><mml:msub><mml:mi>œÑ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> timebin. We simulated the spatial footprints of local backgrounds as 2-D Gaussian as well, but the mean Gaussian width is 5 times larger than the neurons‚Äô widths. As for the spatial footprint of the blood vessel in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, we simulated a cubic function and then convolved it with a 2-D Gaussian (Gaussian width=<inline-formula><mml:math id="inf363"><mml:mn>3</mml:mn></mml:math></inline-formula>pixel). We use a random walk model to simulate the temporal fluctuations of local background and blood vessel. For the data used in <xref ref-type="fig" rid="fig2">Figure 2A‚ÄìH</xref>, there were 23 local background sources; for <xref ref-type="fig" rid="fig2">Figure 2I</xref>, we varied the number of background sources.</p><p>We used the raw data to estimate the background in CNMF-E without subtracting the neural signals <inline-formula><mml:math id="inf364"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>‚Å¢</mml:mo><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> in problem (P-B). We set <inline-formula><mml:math id="inf365"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula> pixels and left the remaining parameters at their default values. The plain NMF was performed using the built-in MATLAB function nnmf, which utilizes random initialization.</p></sec><sec id="s3-6-2"><title>Details of the simulated experiment of <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig5">Figure 5</xref></title><p>We used the same simulation settings for both <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig4">Figure 4</xref>. The field of view was <inline-formula><mml:math id="inf366"><mml:mrow><mml:mn>253</mml:mn><mml:mo>√ó</mml:mo><mml:mn>316</mml:mn></mml:mrow></mml:math></inline-formula> and the number of frames was 2000. We simulated 200 neurons using the same method as the simulation in <xref ref-type="fig" rid="fig2">Figure 2</xref>, but for the background we used the spatiotemporal activity of the background extracted using CNMF-E from real experimental data (data not shown). The noise level <inline-formula><mml:math id="inf367"><mml:mi mathvariant="normal">Œ£</mml:mi></mml:math></inline-formula> was also estimated from the data. When we varied the SNR in <xref ref-type="fig" rid="fig4">Figure 4D‚ÄìG</xref>, we multiplied <inline-formula><mml:math id="inf368"><mml:mi mathvariant="normal">Œ£</mml:mi></mml:math></inline-formula> with an SNR reduction factor.</p><p>We set <inline-formula><mml:math id="inf369"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:math></inline-formula> pixels to create the spatial filtering kernel. As for the thresholds used for determining seed pixels, we varied them for different SNR settings by visually checking the corresponding local correlation images and PNR images. The selected values were <inline-formula><mml:math id="inf370"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0.9</mml:mn><mml:mo>,</mml:mo><mml:mn>0.8</mml:mn><mml:mo>,</mml:mo><mml:mn>0.8</mml:mn><mml:mo>,</mml:mo><mml:mn>0.8</mml:mn><mml:mo>,</mml:mo><mml:mn>0.6</mml:mn><mml:mo>,</mml:mo><mml:mn>0.6</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf371"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>15</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for different SNR reduction factors <inline-formula><mml:math id="inf372"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. For PCA/ICA analysis, we set the number of PCs and ICs as 600 and 300, respectively.</p><p>The simulation in <xref ref-type="fig" rid="fig5">Figure 5</xref> only includes two neurons (as seen in <xref ref-type="fig" rid="fig3">Figure 3E</xref>) using the same simulation parameters. We replaced their temporal traces <inline-formula><mml:math id="inf373"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf374"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> with <inline-formula><mml:math id="inf375"><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>œÅ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>‚Å¢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>œÅ</mml:mi><mml:mo>‚Å¢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf376"><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>œÅ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>‚Å¢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>œÅ</mml:mi><mml:mo>‚Å¢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf377"><mml:mi>œÅ</mml:mi></mml:math></inline-formula> is tuned to generate different correlation levels (<inline-formula><mml:math id="inf378"><mml:mi>Œ≥</mml:mi></mml:math></inline-formula>), and <inline-formula><mml:math id="inf379"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> is simulated in the same way as <inline-formula><mml:math id="inf380"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf381"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. We also added a new background source whose temporal profile is <inline-formula><mml:math id="inf382"><mml:msub><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula> to increase the neuron-background correlation as <inline-formula><mml:math id="inf383"><mml:mi>œÅ</mml:mi></mml:math></inline-formula> increases. CNMF-E was run as in <xref ref-type="fig" rid="fig4">Figure 4</xref>. We used 20 PCs and ICs for PCA/ICA.</p></sec></sec><sec id="s3-7"><title>In vivo microendoscopic imaging and data analysis</title><p>For all experimental data used in this work, we ran both CNMF-E and PCA/ICA. For CNMF-E, we chose parameters so that we initialized about 10‚Äì20% extra components, which were then merged or deleted (some automatically, some under manual supervision) to obtain the final estimates. Exact parameter settings are given for each dataset below. For PCA/ICA, the number of ICs were selected to be slightly larger than our extracted components in CNMF-E (as we found this led to the best results for this algorithm), and the number of PCs was selected to capture over 90% of the signal variance. The weight of temporal information in spatiotemporal ICA was set as 0.1. After obtaining PCA/ICA filters, we again manually removed components that were clearly not neurons based on neuron morphology.</p><p>We computed the SNR of extracted cellular traces to quantitatively compare the performances of two approaches. For each cellular trace <inline-formula><mml:math id="inf384"><mml:mi mathvariant="bold-italic">ùíö</mml:mi></mml:math></inline-formula>, we first computed its denoised trace <inline-formula><mml:math id="inf385"><mml:mi mathvariant="bold-italic">ùíÑ</mml:mi></mml:math></inline-formula> using the selected deconvolution algorithm (here, it is thresholded OASIS); then the SNR of <inline-formula><mml:math id="inf386"><mml:mi mathvariant="bold-italic">ùíö</mml:mi></mml:math></inline-formula> is<disp-formula id="equ23"><label>(16)</label><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mo>‚àí</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:msubsup><mml:mo fence="false" stretchy="false">‚Äñ</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>For PCA/ICA results, the calcium signal <inline-formula><mml:math id="inf387"><mml:mi mathvariant="bold-italic">ùíö</mml:mi></mml:math></inline-formula> of each IC is the output of its corresponding spatial filter, while for CNMF-E results, it is the trace before applying temporal deconvolution, that¬†is, <inline-formula><mml:math id="inf388"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">ùíö</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ15">Equation (9)</xref>. All the data can be freely accessed online (<xref ref-type="bibr" rid="bib57">Zhou et al., 2017</xref>).</p><sec id="s3-7-1"><title>Dorsal striatum data</title><p>Expression of the genetically encoded calcium indicator GCaMP6f in neurons was achieved using a recombinant adeno-associated virus (AAV) encoding the GCaMP6f protein under transcriptional control of the synapsin promoter (AAV-Syn-GCaMP6f). This viral vector was packaged (Serotype 1) and stored in undiluted aliquots at a working concentration of <inline-formula><mml:math id="inf389"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>1012</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> genomic copies per ml at <inline-formula><mml:math id="inf390"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>‚àí</mml:mo><mml:msup><mml:mn>80</mml:mn><mml:mrow><mml:mo>‚àò</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>C until intracranial injection. <inline-formula><mml:math id="inf391"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>500</mml:mn><mml:mtext>¬†</mml:mtext><mml:mi>Œº</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>l of AAV1-Syn-GCaMP6f was injected unilaterally into dorsal striatum (<inline-formula><mml:math id="inf392"><mml:mn>0.6</mml:mn></mml:math></inline-formula> mm anterior to Bregma, <inline-formula><mml:math id="inf393"><mml:mn>2.2</mml:mn></mml:math></inline-formula>mm lateral to Bregma, <inline-formula><mml:math id="inf394"><mml:mn>2.5</mml:mn></mml:math></inline-formula>mm ventral to the surface of the brain). 1 week post-injection, a <inline-formula><mml:math id="inf395"><mml:mn>1</mml:mn></mml:math></inline-formula>mm gradient index of refraction (GRIN) lens was implanted into dorsal striatum <inline-formula><mml:math id="inf396"><mml:mrow><mml:mi/><mml:mo>‚àº</mml:mo><mml:mrow><mml:mn>300</mml:mn><mml:mo>‚Å¢</mml:mo><mml:mi>Œº</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>m above the center of the viral injection. Three weeks after the implantation, the GRIN lens was reversibly coupled to a miniature one-photon microscope with an integrated <inline-formula><mml:math id="inf397"><mml:mn>475</mml:mn></mml:math></inline-formula>nm LED (Inscopix). Using nVistaHD Acquisition software, images were acquired at 30 frames per second with the LED transmitting <inline-formula><mml:math id="inf398"><mml:mpadded lspace="3.3pt" width="+3.3pt"><mml:mn>0.1</mml:mn></mml:mpadded></mml:math></inline-formula> to <inline-formula><mml:math id="inf399"><mml:mn>0.2</mml:mn></mml:math></inline-formula> mW of light while the mouse was freely moving in an open-field arena. Images were down sampled to <inline-formula><mml:math id="inf400"><mml:mn>10</mml:mn></mml:math></inline-formula>Hz and processed into TIFFs using Mosaic software. All experimental manipulations were performed in accordance with protocols approved by the Harvard Standing Committee on Animal Care following guidelines described in the US NIH Guide for the Care and Use of Laboratory Animals.</p><p>The parameters used in running CNMF-E were: <inline-formula><mml:math id="inf401"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf402"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>18</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf403"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf404"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo form="prefix" movablelimits="true">min</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>7.728</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> components were initialized from the raw data in the first pass before subtracting the background, and then additional components were initialized in a second pass. Highly¬†correlated nearby components were merged and false positives were removed using the automated approach described above. In the end, we obtained <inline-formula><mml:math id="inf405"><mml:mn>692</mml:mn></mml:math></inline-formula> components.</p></sec><sec id="s3-7-2"><title>Prefrontal cortex data</title><p>Cortical neurons were targeted by administering two microinjections of 300 ul of AAV-DJ-CamkIIa-GCaMP6s (titer: 5.3 √ó 1012, 1:6 dilution, UNC vector core) into the prefrontal cortex (PFC) (coordinates relative to bregma; injection 1: +1.5 mm AP, 0.6 mm ML, ‚àí2.4 ml DV; injection 2: +2.15 AP, 0.43 mm ML, ‚àí2.4 mm DV) of an adult male wild type (WT) mice. Immediately following the virus injection procedure, a 1 mm diameter GRIN lens implanted 300 um above the injection site (coordinates relative to bregma: +1.87 mm AP, 0.5 mm ML, ‚àí2.1 ml DV). After sufficient time had been allowed for the virus to express and the tissue to clear underneath the lens (3 weeks), a baseplate was secured to the skull to interface the implanted GRIN lens with a miniature, integrated microscope (nVista, 473 nm excitation LED, Inscopix) and subsequently permit the visualization of Ca2 +signals from the PFC of a freely behaving mouse. The activity of PFC neurons were recorded at 15 Hz over a 10 min period (nVista HD Acquisition Software, Inscopix) while the test subject freely explored an empty novel chamber. Acquired data was spatially down sampled by a factor of 2, motion corrected, and temporally down sampled to 15 Hz (Mosaic Analysis Software, Inscopix). All procedures were approved by the University of North Carolina Institutional Animal Care and Use Committee (UNC IACUC).</p><p>The parameters used in running CNMF-E were: <inline-formula><mml:math id="inf406"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf407"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>18</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf408"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf409"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula>. There were <inline-formula><mml:math id="inf410"><mml:mn>169</mml:mn></mml:math></inline-formula> components initialized in the first pass and we obtained <inline-formula><mml:math id="inf411"><mml:mn>225</mml:mn></mml:math></inline-formula> components after running the whole CNMF-E pipeline.</p></sec><sec id="s3-7-3"><title>Ventral hippocampus data</title><p>The calcium indicator GCaMP6f was expressed in ventral hippocampal-amygdala projecting neurons by injecting a retrograde canine adeno type 2-Cre virus (CAV2-Cre; from Larry Zweifel, University of Washington) into the basal amydala (coordinates relative to bregma: ‚àí1.70 AP, 3.00 mm ML, and ‚àí4.25 mm DV from brain tissue at site), and a Cre-dependent GCaMP6f adeno associated virus (AAV1-flex-Synapsin-GCaMP6f, UPenn vector core) into ventral CA1 of the hippocampus (coordinates relative to bregma: ‚àí3.16 mm AP, 3.50 mm ML, and ‚àí3.50 mm DV from brain tissue at site). A 0.5 mm diameter GRIN lens was then implanted over the vCA1 subregion and imaging began 3 weeks after surgery to allow for sufficient viral expression. Mice were then imaged with Inscopix miniaturized microscopes and nVistaHD Acquisition software as described above; images were acquired at 15 frames per second, while mice explored an anxiogenic Elevated Plus Maze arena. Videos were motion corrected and spatially downsampled using Mosaic software. All procedures were performed in accordance with protocols approved by the New York State Psychiatric Institutional Animal Care and Use Committee following guidelines described in the US NIH Guide for the Care and Use of Laboratory Animals.</p><p>The parameters used in running CNMF-E were: <inline-formula><mml:math id="inf412"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf413"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf414"><mml:mrow><mml:mi>Œ∂</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf415"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf416"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula>. We first temporally downsampled the data by <inline-formula><mml:math id="inf417"><mml:mn>2</mml:mn></mml:math></inline-formula>. Then we applied CNMF-E to the downsampled data. There were <inline-formula><mml:math id="inf418"><mml:mn>53</mml:mn></mml:math></inline-formula> components initialized. After updating the background component, the algorithm detected six more neurons from the residual. We merged most of these components and deleted false positives. In the end, there were <inline-formula><mml:math id="inf419"><mml:mn>24</mml:mn></mml:math></inline-formula> components left. The intermediate results before and after each manual intervention are shown in <xref ref-type="video" rid="video10">Video 10</xref>.</p></sec><sec id="s3-7-4"><title>BNST data with footshock</title><p>Calcium indicator GCaMP6s was expressed within CaMKII-expressing neurons in the BNST by injecting the recombinant adeno-associated virus AAVdj-CaMKII-GCaMP6s (packaged at UNC Vector Core) into the anterior dorsal portion of BNST (coordinates relative to bregma: 0.10 mm AP, ‚àí0.95 mm ML, ‚àí4.30 mm DV). A 0.6 mm diameter GRIN lens was implanted above the injection site within the BNST. As described above, images were acquired using a detachable miniature one-photon microscope and nVistaHD Acquisition Software (Inscopix). Images were acquired at 20 frames per second while the animal was freely moving inside a sound-attenuated chamber equipped with a house light and a white noise generator (Med Associates). Unpredictable foot shocks were delivered through metal bars in the floor as an aversive stimulus during a 10 min session. Each unpredictable foot shock was 0.75 mA in intensity and 500 ms in duration on a variable interval (VI-60). As described above, images were motion corrected, downsampled and processed into TIFFs using Mosaic Software. These procedures were conducted in adult C57BL/6J mice (Jackson Laboratories) and in accordance with the Guide for the Care and Use of Laboratory Animals, as adopted by the NIH, and with approval from the Institutional Animal Care and Use Committee of the University of North Carolina at Chapel Hill (UNC).</p><p>The parameters used in running CNMF-E were: <inline-formula><mml:math id="inf420"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf421"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>23</mml:mn></mml:mrow></mml:math></inline-formula> pixels, <inline-formula><mml:math id="inf422"><mml:mrow><mml:mi>Œ∂</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf423"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf424"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>min</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula>. There were <inline-formula><mml:math id="inf425"><mml:mn>149</mml:mn></mml:math></inline-formula> components initialized and we detected <inline-formula><mml:math id="inf426"><mml:mn>29</mml:mn></mml:math></inline-formula> more components from the residual after estimating the background. there were <inline-formula><mml:math id="inf427"><mml:mn>127</mml:mn></mml:math></inline-formula> components left after running the whole pipeline.</p></sec></sec><sec id="s3-8"><title>Code availability</title><p>All analyses were performed with custom-written MATLAB code. MATLAB implementations of the CNMF-E algorithm can be freely downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/CNMF_E">https://github.com/zhoupc/CNMF_E</ext-link> (<xref ref-type="bibr" rid="bib58">Zhou, 2017a</xref>). We also implemented CNMF-E as part of the Python package CaImAn (<xref ref-type="bibr" rid="bib18">Giovannucci et al., 2017b</xref>), a computational analysis toolbox for large-scale calcium imaging and behavioral data (<ext-link ext-link-type="uri" xlink:href="https://github.com/simonsfoundation/CaImAn">https://github.com/simonsfoundation/CaImAn</ext-link> [<xref ref-type="bibr" rid="bib17">Giovannucci et al., 2017a</xref>]).</p><p>The scripts for generating all figures and the experimental data in this paper can be accessed from <ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/eLife_submission">https://github.com/zhoupc/eLife_submission</ext-link>¬†(<xref ref-type="bibr" rid="bib59">Zhou, 2017b</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We would like to thank CNMF-E users who received early access to our package and provided tremendously helpful feedback and suggestions, especially James Hyde, Jesse Wood, and Sean Piantadosi in Susanne Ahmari‚Äôs lab in University of Pittsburgh, Andreas Klaus in Rui Costa‚Äôs Lab in the Champalimaud Neurobiology of Action Laboratory, Suoqin Jin in Xiangmin Xu‚Äôs lab at University of California - Irvine, Conor Heins at the National Institute of Drug Abuse, Chris Donahue in Anatol Kreitzer‚Äôs lab at University of California - San Francisco, Xian Zhang in Bo Li‚Äôs lab at Cold Spring Harbor Laboratory, Emily Mackevicius in Michale Fee‚Äôs lab at Massachusetts Institute of Technology, Courtney Cameron and Malavika Murugan in Ilana Witten‚Äôs lab at Princeton University, Pranav Mamidanna in Jonathan Whitlock‚Äôs lab at Norwegian University of Science and Technology, and Milekovic Tomislav in Gregoire Courtine‚Äôs group at EPFL. We also thank Andreas Klaus for valuable comments on the manuscript.</p></ack><sec id="s4" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing‚Äîoriginal draft, Project administration, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con2"><p>Resources, Data curation, Funding acquisition, Validation, Investigation, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Data curation, Validation, Investigation, Visualization, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con4"><p>Resources, Data curation, Funding acquisition, Validation, Investigation, Visualization, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con5"><p>Resources, Data curation, Funding acquisition, Validation, Investigation, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con6"><p>Software</p></fn><fn fn-type="con" id="con7"><p>Software</p></fn><fn fn-type="con" id="con8"><p>Software</p></fn><fn fn-type="con" id="con9"><p>Resources, Supervision, Funding acquisition</p></fn><fn fn-type="con" id="con10"><p>Resources, Supervision, Funding acquisition</p></fn><fn fn-type="con" id="con11"><p>Resources, Supervision, Funding acquisition, Validation, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con12"><p>Resources, Supervision, Funding acquisition, Visualization, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con13"><p>Resources, Supervision, Funding acquisition, Visualization, Writing‚Äîreview and editing</p></fn><fn fn-type="con" id="con14"><p>Conceptualization, Resources, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing‚Äîoriginal draft, Project administration, Writing‚Äîreview and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: These procedures were conducted in accordance with the Guide for the Care and Use of Laboratory Animals, as adopted by the NIH, and with approval from the Harvard Standing Committee on Animal Care (protocol number: IS00000571 ), or the University of North Carolina Institutional Animal Care and Use Committee (UNC IACUC, protocol number: 16-075.0), or the New York State Psychiatric Institutional Animal Care and Use Committee (protocol number: NYSPI-1412 ).</p></fn></fn-group></sec><sec id="s5" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.28728.026</object-id><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-28728-transrepform-v2.pdf"/></supplementary-material><sec id="s6" sec-type="datasets"><title>Major datasets</title><p>The following dataset was generated:</p><p><related-object content-type="generated-dataset" id="dataset1" source-id="https://doi.org/10.5061/dryad.kr17k" source-id-type="uri"><collab collab-type="author">Zhou P</collab><collab collab-type="author">Resendez SL</collab><collab collab-type="author">Rodriguez-Romaguera J</collab><collab collab-type="author">Jimenez JC</collab><collab collab-type="author">Neufeld SQ</collab><collab collab-type="author">Giovannucci A</collab><collab collab-type="author">Friedrich J</collab><collab collab-type="author">Pnevmatikakis EA</collab><collab collab-type="author">Stuber GD</collab><collab collab-type="author">Hen R</collab><collab collab-type="author">Kheirbek MA</collab><collab collab-type="author">Sabatini BL</collab><collab collab-type="author">Kass RE</collab><collab collab-type="author">Paninski L</collab><year>2017</year><source>Data from: Efficient and accurate extraction of in vivo calcium signals from microendoscopic video data</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.kr17k">https://doi.org/10.5061/dryad.kr17k</ext-link><comment>Available at Dryad Digital Repository under a CC0 Public Domain Dedication</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Apthorpe</surname> <given-names>N</given-names></name><name><surname>Riordan</surname> <given-names>A</given-names></name><name><surname>Aguilar</surname> <given-names>R</given-names></name><name><surname>Homann</surname> <given-names>J</given-names></name><name><surname>Gu</surname> <given-names>Y</given-names></name><name><surname>Tank</surname> <given-names>D</given-names></name><name><surname>Seung</surname> <given-names>HS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Automatic neuron detection in calcium imaging data using convolutional networks</article-title><source>Advances in Neural Information Processing Systems</source><volume>29</volume><fpage>3270</fpage><lpage>3278</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbera</surname> <given-names>G</given-names></name><name><surname>Liang</surname> <given-names>B</given-names></name><name><surname>Zhang</surname> <given-names>L</given-names></name><name><surname>Gerfen</surname> <given-names>CR</given-names></name><name><surname>Culurciello</surname> <given-names>E</given-names></name><name><surname>Chen</surname> <given-names>R</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Lin</surname> <given-names>DT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spatially compact neural clusters in the dorsal striatum encode locomotion relevant information</article-title><source>Neuron</source><volume>92</volume><fpage>202</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.037</pub-id><pub-id pub-id-type="pmid">27667003</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhatia</surname> <given-names>K</given-names></name><name><surname>Jain</surname> <given-names>P</given-names></name><name><surname>Kar</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Robust regression via hard thresholding</article-title><source>Advances in Neural Information Processing Systems</source><volume>28</volume><fpage>721</fpage><lpage>729</lpage></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname> <given-names>DJ</given-names></name><name><surname>Aharoni</surname> <given-names>D</given-names></name><name><surname>Shuman</surname> <given-names>T</given-names></name><name><surname>Shobe</surname> <given-names>J</given-names></name><name><surname>Biane</surname> <given-names>J</given-names></name><name><surname>Song</surname> <given-names>W</given-names></name><name><surname>Wei</surname> <given-names>B</given-names></name><name><surname>Veshkini</surname> <given-names>M</given-names></name><name><surname>La-Vu</surname> <given-names>M</given-names></name><name><surname>Lou</surname> <given-names>J</given-names></name><name><surname>Flores</surname> <given-names>SE</given-names></name><name><surname>Kim</surname> <given-names>I</given-names></name><name><surname>Sano</surname> <given-names>Y</given-names></name><name><surname>Zhou</surname> <given-names>M</given-names></name><name><surname>Baumgaertel</surname> <given-names>K</given-names></name><name><surname>Lavi</surname> <given-names>A</given-names></name><name><surname>Kamata</surname> <given-names>M</given-names></name><name><surname>Tuszynski</surname> <given-names>M</given-names></name><name><surname>Mayford</surname> <given-names>M</given-names></name><name><surname>Golshani</surname> <given-names>P</given-names></name><name><surname>Silva</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A shared neural ensemble links distinct contextual memories encoded close in time</article-title><source>Nature</source><volume>534</volume><fpage>115</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1038/nature17955</pub-id><pub-id pub-id-type="pmid">27251287</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Cameron</surname> <given-names>CM</given-names></name><name><surname>Pillow</surname> <given-names>J</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cellular resolution calcium imaging and optogenetic excitation reveal a role for IL to NAc projection neurons in encoding of spatial information during cocaine-seeking</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>San Diego</conf-loc></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carvalho Poyraz</surname> <given-names>F</given-names></name><name><surname>Holzner</surname> <given-names>E</given-names></name><name><surname>Bailey</surname> <given-names>MR</given-names></name><name><surname>Meszaros</surname> <given-names>J</given-names></name><name><surname>Kenney</surname> <given-names>L</given-names></name><name><surname>Kheirbek</surname> <given-names>MA</given-names></name><name><surname>Balsam</surname> <given-names>PD</given-names></name><name><surname>Kellendonk</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decreasing striatopallidal pathway function enhances motivation by energizing the initiation of goal-directed action</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>5988</fpage><lpage>6001</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0444-16.2016</pub-id><pub-id pub-id-type="pmid">27251620</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cichocki</surname> <given-names>A</given-names></name><name><surname>Phan</surname> <given-names>AH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fast local algorithms for large scale nonnegative matrix and tensor factorizations</article-title><source>IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences</source><volume>E92-A</volume><fpage>708</fpage><lpage>721</lpage><pub-id pub-id-type="doi">10.1587/transfun.E92.A.708</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cichocki</surname> <given-names>A</given-names></name><name><surname>Zdunek</surname> <given-names>R</given-names></name><name><surname>Amari</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hierarchical ALS Algorithms for Nonnegative Matrix and 3D Tensor Factorization</article-title><source>Lecture Notes in Computer Science</source><volume>4666</volume><fpage>169</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1007/978-3-540-74494-8_22</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname> <given-names>J</given-names></name><name><surname>Pinto</surname> <given-names>L</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Calcium imaging of sleep-wake related neuronal activity in the dorsal pons</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>10763</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms10763</pub-id><pub-id pub-id-type="pmid">26911837</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneux</surname> <given-names>T</given-names></name><name><surname>Kaszas</surname> <given-names>A</given-names></name><name><surname>Szalay</surname> <given-names>G</given-names></name><name><surname>Katona</surname> <given-names>G</given-names></name><name><surname>Lakner</surname> <given-names>T</given-names></name><name><surname>Grinvald</surname> <given-names>A</given-names></name><name><surname>R√≥zsa</surname> <given-names>B</given-names></name><name><surname>Vanzetta</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Accurate spike estimation from noisy calcium signals for ultrafast three-dimensional imaging of large neuronal populations in vivo</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12190</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12190</pub-id><pub-id pub-id-type="pmid">27432255</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Graziano</surname> <given-names>MS</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Functional clustering of neurons in motor cortex determined by cellular resolution imaging in awake behaving mice</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>13751</fpage><lpage>13760</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2985-09.2009</pub-id><pub-id pub-id-type="pmid">19889987</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Donahue</surname> <given-names>CH</given-names></name><name><surname>Kreitzer</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Function of Basal Ganglia Circuitry in Motivation</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>Washinton, DC</conf-loc></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flusberg</surname> <given-names>BA</given-names></name><name><surname>Nimmerjahn</surname> <given-names>A</given-names></name><name><surname>Cocker</surname> <given-names>ED</given-names></name><name><surname>Mukamel</surname> <given-names>EA</given-names></name><name><surname>Barretto</surname> <given-names>RP</given-names></name><name><surname>Ko</surname> <given-names>TH</given-names></name><name><surname>Burns</surname> <given-names>LD</given-names></name><name><surname>Jung</surname> <given-names>JC</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>High-speed, miniaturized fluorescence microscopy in freely moving mice</article-title><source>Nature Methods</source><volume>5</volume><fpage>935</fpage><lpage>938</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1256</pub-id><pub-id pub-id-type="pmid">18836457</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname> <given-names>J</given-names></name><name><surname>Yang</surname> <given-names>W</given-names></name><name><surname>Soudry</surname> <given-names>D</given-names></name><name><surname>Mu</surname> <given-names>Y</given-names></name><name><surname>Ahrens</surname> <given-names>MB</given-names></name><name><surname>Yuste</surname> <given-names>R</given-names></name><name><surname>Peterka</surname> <given-names>DS</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Multi-scale approaches for high-speed imaging and analysis of large neural populations</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005685</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005685</pub-id><pub-id pub-id-type="pmid">28771570</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname> <given-names>J</given-names></name><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Fast online deconvolution of calcium imaging data</article-title><source>PLOS Computational Biology</source><volume>13</volume><fpage>e1005423</fpage><lpage>1005426</lpage><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005423</pub-id><pub-id pub-id-type="pmid">28291787</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghosh</surname> <given-names>KK</given-names></name><name><surname>Burns</surname> <given-names>LD</given-names></name><name><surname>Cocker</surname> <given-names>ED</given-names></name><name><surname>Nimmerjahn</surname> <given-names>A</given-names></name><name><surname>Ziv</surname> <given-names>Y</given-names></name><name><surname>Gamal</surname> <given-names>AE</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Miniaturized integration of a fluorescence microscope</article-title><source>Nature Methods</source><volume>8</volume><fpage>871</fpage><lpage>878</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1694</pub-id><pub-id pub-id-type="pmid">21909102</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Giovannucci</surname> <given-names>A</given-names></name><name><surname>Friedrich</surname> <given-names>J</given-names></name><name><surname>Deverett</surname> <given-names>B</given-names></name><name><surname>Staneva</surname> <given-names>V</given-names></name><name><surname>Chklovskii</surname> <given-names>D</given-names></name><name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2017">2017a</year><data-title>CaImAn</data-title><source>Github</source><version designator="6bd51e2">6bd51e2</version><ext-link ext-link-type="uri" xlink:href="https://github.com/flatironinstitute/CaImAn">https://github.com/flatironinstitute/CaImAn</ext-link></element-citation></ref><ref id="bib18"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Giovannucci</surname> <given-names>A</given-names></name><name><surname>Friedrich</surname> <given-names>J</given-names></name><name><surname>Deverett</surname> <given-names>B</given-names></name><name><surname>Staneva</surname> <given-names>V</given-names></name><name><surname>Chklovskii</surname> <given-names>D</given-names></name><name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>CaImAn: an open source toolbox for large scale calcium imaging data analysis on standalone machines</article-title><source>Cosyne Abstracts</source><conf-name>Cosyne2017</conf-name></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haralick</surname> <given-names>RM</given-names></name><name><surname>Sternberg</surname> <given-names>SR</given-names></name><name><surname>Zhuang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Image analysis using mathematical morphology</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>9</volume><fpage>532</fpage><lpage>550</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.1987.4767941</pub-id><pub-id pub-id-type="pmid">21869411</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname> <given-names>TC</given-names></name><name><surname>Pinto</surname> <given-names>L</given-names></name><name><surname>Brock</surname> <given-names>JR</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Calcium imaging of basal forebrain activity during innate and learned behaviors</article-title><source>Frontiers in Neural Circuits</source><volume>10</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.3389/fncir.2016.00036</pub-id><pub-id pub-id-type="pmid">27242444</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jennings</surname> <given-names>JH</given-names></name><name><surname>Sparta</surname> <given-names>DR</given-names></name><name><surname>Stamatakis</surname> <given-names>AM</given-names></name><name><surname>Ung</surname> <given-names>RL</given-names></name><name><surname>Pleil</surname> <given-names>KE</given-names></name><name><surname>Kash</surname> <given-names>TL</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Distinct extended amygdala circuits for divergent motivational states</article-title><source>Nature</source><volume>496</volume><fpage>224</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1038/nature12041</pub-id><pub-id pub-id-type="pmid">23515155</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jennings</surname> <given-names>JH</given-names></name><name><surname>Ung</surname> <given-names>RL</given-names></name><name><surname>Resendez</surname> <given-names>SL</given-names></name><name><surname>Stamatakis</surname> <given-names>AM</given-names></name><name><surname>Taylor</surname> <given-names>JG</given-names></name><name><surname>Huang</surname> <given-names>J</given-names></name><name><surname>Veleta</surname> <given-names>K</given-names></name><name><surname>Kantak</surname> <given-names>PA</given-names></name><name><surname>Aita</surname> <given-names>M</given-names></name><name><surname>Shilling-Scrivo</surname> <given-names>K</given-names></name><name><surname>Ramakrishnan</surname> <given-names>C</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Otte</surname> <given-names>S</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Visualizing hypothalamic network dynamics for appetitive and consummatory behaviors</article-title><source>Cell</source><volume>160</volume><fpage>516</fpage><lpage>527</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.12.026</pub-id><pub-id pub-id-type="pmid">25635459</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jewell</surname> <given-names>S</given-names></name><name><surname>Witten</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Exact Spike Train Inference Via <italic>‚Ñì</italic><sub>0</sub> Optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1703.08644">https://arxiv.org/abs/1703.08644</ext-link></element-citation></ref><ref id="bib24"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Jimenez</surname> <given-names>JC</given-names></name><name><surname>Goldberg</surname> <given-names>A</given-names></name><name><surname>Ordek</surname> <given-names>G</given-names></name><name><surname>Luna</surname> <given-names>VM</given-names></name><name><surname>Su</surname> <given-names>K</given-names></name><name><surname>Pena</surname> <given-names>S</given-names></name><name><surname>Zweifel</surname> <given-names>L</given-names></name><name><surname>Hen</surname> <given-names>R</given-names></name><name><surname>Kheirbek</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Subcortical projection-specific control of innate anxiety and learned fear by the ventral hippocampus</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>San Diego</conf-loc></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jimenez</surname> <given-names>JC</given-names></name><name><surname>Su</surname> <given-names>K</given-names></name><name><surname>Goldberg</surname> <given-names>AR</given-names></name><name><surname>Luna</surname> <given-names>VM</given-names></name><name><surname>Biane</surname> <given-names>JS</given-names></name><name><surname>Ordek</surname> <given-names>G</given-names></name><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Ong</surname> <given-names>SK</given-names></name><name><surname>Wright</surname> <given-names>MA</given-names></name><name><surname>Zweifel</surname> <given-names>L</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Hen</surname> <given-names>R</given-names></name><name><surname>Kheirbek</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Anxiety Cells in a Hippocampal-Hypothalamic Circuit</article-title><source>Neuron</source><volume>97</volume><fpage>670</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.016</pub-id><pub-id pub-id-type="pmid">29397273</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitamura</surname> <given-names>T</given-names></name><name><surname>Sun</surname> <given-names>C</given-names></name><name><surname>Martin</surname> <given-names>J</given-names></name><name><surname>Kitch</surname> <given-names>LJ</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name><name><surname>Tonegawa</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Entorhinal cortical ocean cells encode specific contexts and drive context-specific fear memory</article-title><source>Neuron</source><volume>87</volume><fpage>1317</fpage><lpage>1331</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.036</pub-id><pub-id pub-id-type="pmid">26402611</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klaus</surname> <given-names>A</given-names></name><name><surname>Martins</surname> <given-names>GJ</given-names></name><name><surname>Paixao</surname> <given-names>VB</given-names></name><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Costa</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The spatiotemporal organization of the striatum encodes action space</article-title><source>Neuron</source><volume>95</volume><fpage>1171</fpage><lpage>1180</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.08.015</pub-id><pub-id pub-id-type="pmid">28858619</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>X</given-names></name><name><surname>Grieco</surname> <given-names>SF</given-names></name><name><surname>Jin</surname> <given-names>S</given-names></name><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Nie</surname> <given-names>Q</given-names></name><name><surname>Kwapis</surname> <given-names>J</given-names></name><name><surname>Wood</surname> <given-names>MA</given-names></name><name><surname>Baglietto-Vargas</surname> <given-names>D</given-names></name><name><surname>Laferla</surname> <given-names>FM</given-names></name><name><surname>Xu</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>In vivo calcium imaging of hippocampal neuronal network activity associated with memory behavior deficits in the Alzheimer‚Äôs disease mouse model</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>Washinton, DC</conf-loc></element-citation></ref><ref id="bib29"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mackevicius</surname> <given-names>EM</given-names></name><name><surname>Denisenko</surname> <given-names>N</given-names></name><name><surname>Fee</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural sequences underlying the rapid learning of new syllables in juvenile zebra finches</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>Washinton, DC</conf-loc></element-citation></ref><ref id="bib30"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Madangopal</surname> <given-names>R</given-names></name><name><surname>Heins</surname> <given-names>C</given-names></name><name><surname>Caprioli</surname> <given-names>D</given-names></name><name><surname>Liang</surname> <given-names>B</given-names></name><name><surname>Barbera</surname> <given-names>G</given-names></name><name><surname>Komer</surname> <given-names>L</given-names></name><name><surname>Bossert</surname> <given-names>J</given-names></name><name><surname>Hope</surname> <given-names>B</given-names></name><name><surname>Shaham</surname> <given-names>Y</given-names></name><name><surname>Lin</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>In vivo calcium imaging to assess the role of prelimbic cortex neuronal ensembles in encoding reinstatement of palatable food-seeking in rats</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>Washinton, DC</conf-loc></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markowitz</surname> <given-names>JE</given-names></name><name><surname>Liberti</surname> <given-names>WA</given-names></name><name><surname>Guitchounts</surname> <given-names>G</given-names></name><name><surname>Velho</surname> <given-names>T</given-names></name><name><surname>Lois</surname> <given-names>C</given-names></name><name><surname>Gardner</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mesoscopic patterns of neural activity support songbird cortical sequences</article-title><source>PLOS Biology</source><volume>13</volume><elocation-id>e1002158</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002158</pub-id><pub-id pub-id-type="pmid">26039895</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohammed</surname> <given-names>AI</given-names></name><name><surname>Gritton</surname> <given-names>HJ</given-names></name><name><surname>Tseng</surname> <given-names>HA</given-names></name><name><surname>Bucklin</surname> <given-names>ME</given-names></name><name><surname>Yao</surname> <given-names>Z</given-names></name><name><surname>Han</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An integrative approach for analyzing hundreds of neurons in task performing mice using wide-field calcium imaging</article-title><source>Scientific Reports</source><volume>6</volume><fpage>20986</fpage><pub-id pub-id-type="doi">10.1038/srep20986</pub-id><pub-id pub-id-type="pmid">26854041</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukamel</surname> <given-names>EA</given-names></name><name><surname>Nimmerjahn</surname> <given-names>A</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Automated analysis of cellular signals from large-scale calcium imaging data</article-title><source>Neuron</source><volume>63</volume><fpage>747</fpage><lpage>760</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.009</pub-id><pub-id pub-id-type="pmid">19778505</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Mukamel</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>CellSort</data-title><source>Github</source><version designator="45f28d7">45f28d7</version><ext-link ext-link-type="uri" xlink:href="https://github.com/mukamel-lab/CellSort">https://github.com/mukamel-lab/CellSort</ext-link></element-citation></ref><ref id="bib35"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Murugan</surname> <given-names>M</given-names></name><name><surname>Park</surname> <given-names>M</given-names></name><name><surname>Taliaferro</surname> <given-names>J</given-names></name><name><surname>Jang</surname> <given-names>HJ</given-names></name><name><surname>Cox</surname> <given-names>J</given-names></name><name><surname>Parker</surname> <given-names>N</given-names></name><name><surname>Bhave</surname> <given-names>V</given-names></name><name><surname>Nectow</surname> <given-names>A</given-names></name><name><surname>Pillow</surname> <given-names>J</given-names></name><name><surname>Witten</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Combined social and spatial coding in a descending projection from the prefrontal cortex</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/155929</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Murugan</surname> <given-names>M</given-names></name><name><surname>Taliaferro</surname> <given-names>JP</given-names></name><name><surname>Park</surname> <given-names>M</given-names></name><name><surname>Jang</surname> <given-names>H</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Detecting action potentials in neuronal populations with calcium imaging</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>San Diego</conf-loc></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Packer</surname> <given-names>AM</given-names></name><name><surname>Pettit</surname> <given-names>N</given-names></name><name><surname>Dalgleish</surname> <given-names>H</given-names></name><name><surname>Hausser</surname> <given-names>M</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Extracting regions of interest from biological images with convolutional sparse block coding</article-title><source>Advances in Neural Information Processing Systems</source><volume>26</volume><fpage>1745</fpage><lpage>1753</lpage></element-citation></ref><ref id="bib38"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Schr√∂der</surname> <given-names>S</given-names></name><name><surname>Dipoppa</surname> <given-names>M</given-names></name><name><surname>Rossi</surname> <given-names>LF</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/061507</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname> <given-names>L</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cell-type-specific activity in prefrontal cortex during goal-directed behavior</article-title><source>Neuron</source><volume>87</volume><fpage>437</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.021</pub-id><pub-id pub-id-type="pmid">26143660</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></name><name><surname>Merel</surname> <given-names>J</given-names></name><name><surname>Pakman</surname> <given-names>A</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><chapter-title>Bayesian spike inference from calcium imaging data</chapter-title><source>2013 Asilomar Conference on Signals, Systems and Computers</source><fpage>349</fpage><lpage>353</lpage><pub-id pub-id-type="doi">10.1109/ACSSC.2013.6810293</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></name><name><surname>Soudry</surname> <given-names>D</given-names></name><name><surname>Gao</surname> <given-names>Y</given-names></name><name><surname>Machado</surname> <given-names>TA</given-names></name><name><surname>Merel</surname> <given-names>J</given-names></name><name><surname>Pfau</surname> <given-names>D</given-names></name><name><surname>Reardon</surname> <given-names>T</given-names></name><name><surname>Mu</surname> <given-names>Y</given-names></name><name><surname>Lacefield</surname> <given-names>C</given-names></name><name><surname>Yang</surname> <given-names>W</given-names></name><name><surname>Ahrens</surname> <given-names>M</given-names></name><name><surname>Bruno</surname> <given-names>R</given-names></name><name><surname>Jessell</surname> <given-names>TM</given-names></name><name><surname>Peterka</surname> <given-names>DS</given-names></name><name><surname>Yuste</surname> <given-names>R</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Simultaneous denoising, deconvolution, and demixing of calcium imaging data</article-title><source>Neuron</source><volume>89</volume><fpage>285</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.037</pub-id><pub-id pub-id-type="pmid">26774160</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Ca_source_extraction</data-title><source>Github</source><version designator="5a25d5a">5a25d5a</version><ext-link ext-link-type="uri" xlink:href="https://github.com/epnev/ca_source_extraction">https://github.com/epnev/ca_source_extraction</ext-link></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resendez</surname> <given-names>SL</given-names></name><name><surname>Jennings</surname> <given-names>JH</given-names></name><name><surname>Ung</surname> <given-names>RL</given-names></name><name><surname>Namboodiri</surname> <given-names>VM</given-names></name><name><surname>Zhou</surname> <given-names>ZC</given-names></name><name><surname>Otis</surname> <given-names>JM</given-names></name><name><surname>Nomura</surname> <given-names>H</given-names></name><name><surname>McHenry</surname> <given-names>JA</given-names></name><name><surname>Kosyk</surname> <given-names>O</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Visualization of cortical, subcortical and deep brain neural circuit dynamics during naturalistic mammalian behavior with head-mounted microscopes and chronically implanted lenses</article-title><source>Nature Protocols</source><volume>11</volume><fpage>566</fpage><lpage>597</lpage><pub-id pub-id-type="doi">10.1038/nprot.2016.021</pub-id><pub-id pub-id-type="pmid">26914316</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberts</surname> <given-names>TF</given-names></name><name><surname>Hisey</surname> <given-names>E</given-names></name><name><surname>Tanaka</surname> <given-names>M</given-names></name><name><surname>Kearney</surname> <given-names>MG</given-names></name><name><surname>Chattree</surname> <given-names>G</given-names></name><name><surname>Yang</surname> <given-names>CF</given-names></name><name><surname>Shah</surname> <given-names>NM</given-names></name><name><surname>Mooney</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Identification of a motor-to-auditory pathway important for vocal learning</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>978</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1038/nn.4563</pub-id><pub-id pub-id-type="pmid">28504672</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></name><name><surname>Ung</surname> <given-names>RL</given-names></name><name><surname>Nomura</surname> <given-names>H</given-names></name><name><surname>Namboodiri</surname> <given-names>VMK</given-names></name><name><surname>Otis</surname> <given-names>JM</given-names></name><name><surname>Robinson</surname> <given-names>JE</given-names></name><name><surname>Resendez</surname> <given-names>SL</given-names></name><name><surname>McHenry</surname> <given-names>JA</given-names></name><name><surname>Eckman</surname> <given-names>LEH</given-names></name><name><surname>Kosyk</surname> <given-names>TL</given-names></name><name><surname>van den Munkhof</surname> <given-names>HE</given-names></name><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Kash</surname> <given-names>TL</given-names></name><name><surname>Bruchas</surname> <given-names>MR</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Nociceptin neurons in the bed nucleus of the stria terminalis regulate anxiety</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>Washinton, DC</conf-loc></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname> <given-names>A</given-names></name><name><surname>Geva</surname> <given-names>N</given-names></name><name><surname>Sheintuch</surname> <given-names>L</given-names></name><name><surname>Ziv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal ensemble dynamics timestamp events in long-term memory</article-title><source>eLife</source><volume>4</volume><elocation-id>e12247</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12247</pub-id><pub-id pub-id-type="pmid">26682652</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ryan</surname> <given-names>PJ</given-names></name><name><surname>Ross</surname> <given-names>SI</given-names></name><name><surname>Campos</surname> <given-names>CA</given-names></name><name><surname>Derkach</surname> <given-names>VA</given-names></name><name><surname>Palmiter</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Oxytocin-receptor-expressing neurons in the parabrachial nucleus regulate fluid intake</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1722</fpage><lpage>1733</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0014-z</pub-id><pub-id pub-id-type="pmid">29184212</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheintuch</surname> <given-names>L</given-names></name><name><surname>Rubin</surname> <given-names>A</given-names></name><name><surname>Brande-Eilat</surname> <given-names>N</given-names></name><name><surname>Geva</surname> <given-names>N</given-names></name><name><surname>Sadeh</surname> <given-names>N</given-names></name><name><surname>Pinchasof</surname> <given-names>O</given-names></name><name><surname>Ziv</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Tracking the same neurons across multiple days in Ca<sup>2+¬†</sup>imaging data</article-title><source>Cell Reports</source><volume>21</volume><fpage>1102</fpage><lpage>1115</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.10.013</pub-id><pub-id pub-id-type="pmid">29069591</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SL</given-names></name><name><surname>H√§usser</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Parallel processing of visual space by neighboring neurons in mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1144</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1038/nn.2620</pub-id><pub-id pub-id-type="pmid">20711183</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname> <given-names>C</given-names></name><name><surname>Kitamura</surname> <given-names>T</given-names></name><name><surname>Yamamoto</surname> <given-names>J</given-names></name><name><surname>Martin</surname> <given-names>J</given-names></name><name><surname>Pignatelli</surname> <given-names>M</given-names></name><name><surname>Kitch</surname> <given-names>LJ</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name><name><surname>Tonegawa</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct speed dependence of entorhinal island and ocean cells, including respective grid cells</article-title><source>PNAS</source><volume>112</volume><fpage>9466</fpage><lpage>9471</lpage><pub-id pub-id-type="doi">10.1073/pnas.1511668112</pub-id><pub-id pub-id-type="pmid">26170279</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tombaz</surname> <given-names>T</given-names></name><name><surname>Dunn</surname> <given-names>BA</given-names></name><name><surname>Hovde</surname> <given-names>K</given-names></name><name><surname>Whitlock</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Action planning and action observation in rodent parietal cortex</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>San Diego</conf-loc></element-citation></ref><ref id="bib52"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ung</surname> <given-names>RL</given-names></name><name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></name><name><surname>Nomura</surname> <given-names>H</given-names></name><name><surname>Namboodiri</surname> <given-names>VMK</given-names></name><name><surname>Otis</surname> <given-names>JM</given-names></name><name><surname>Robinson</surname> <given-names>JE</given-names></name><name><surname>Resendez</surname> <given-names>SL</given-names></name><name><surname>McHenry</surname> <given-names>JA</given-names></name><name><surname>Eckman</surname> <given-names>LEH</given-names></name><name><surname>Kosyk</surname> <given-names>TL</given-names></name><name><surname>van den Munkhof</surname> <given-names>HE</given-names></name><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Kash</surname> <given-names>TL</given-names></name><name><surname>Bruchas</surname> <given-names>MR</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Encoding the relationship between anxiety-related behaviors and nociceptin neurons of the bed nucleus of the stria terminalis</article-title><source>Neuroscience Meeting Planner</source><conf-name>Society for Neuroscience</conf-name><conf-loc>Washinton, DC</conf-loc></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogelstein</surname> <given-names>JT</given-names></name><name><surname>Packer</surname> <given-names>AM</given-names></name><name><surname>Machado</surname> <given-names>TA</given-names></name><name><surname>Sippy</surname> <given-names>T</given-names></name><name><surname>Babadi</surname> <given-names>B</given-names></name><name><surname>Yuste</surname> <given-names>R</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Fast nonnegative deconvolution for spike train inference from population calcium imaging</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>3691</fpage><lpage>3704</lpage><pub-id pub-id-type="doi">10.1152/jn.01073.2009</pub-id><pub-id pub-id-type="pmid">20554834</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogelstein</surname> <given-names>JT</given-names></name><name><surname>Watson</surname> <given-names>BO</given-names></name><name><surname>Packer</surname> <given-names>AM</given-names></name><name><surname>Yuste</surname> <given-names>R</given-names></name><name><surname>Jedynak</surname> <given-names>B</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spike inference from calcium imaging using sequential Monte Carlo methods</article-title><source>Biophysical Journal</source><volume>97</volume><fpage>636</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1016/j.bpj.2008.08.005</pub-id><pub-id pub-id-type="pmid">19619479</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warp</surname> <given-names>E</given-names></name><name><surname>Agarwal</surname> <given-names>G</given-names></name><name><surname>Wyart</surname> <given-names>C</given-names></name><name><surname>Friedmann</surname> <given-names>D</given-names></name><name><surname>Oldfield</surname> <given-names>CS</given-names></name><name><surname>Conner</surname> <given-names>A</given-names></name><name><surname>Del Bene</surname> <given-names>F</given-names></name><name><surname>Arrenberg</surname> <given-names>AB</given-names></name><name><surname>Baier</surname> <given-names>H</given-names></name><name><surname>Isacoff</surname> <given-names>EY</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Emergence of patterned activity in the developing zebrafish spinal cord</article-title><source>Current Biology</source><volume>22</volume><fpage>93</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.12.002</pub-id><pub-id pub-id-type="pmid">22197243</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>K</given-names></name><name><surname>Ahrens</surname> <given-names>S</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Schiff</surname> <given-names>H</given-names></name><name><surname>Ramakrishnan</surname> <given-names>C</given-names></name><name><surname>Fenno</surname> <given-names>L</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Zhao</surname> <given-names>F</given-names></name><name><surname>Luo</surname> <given-names>MH</given-names></name><name><surname>Gong</surname> <given-names>L</given-names></name><name><surname>He</surname> <given-names>M</given-names></name><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The central amygdala controls learning in the lateral amygdala</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1680</fpage><lpage>1685</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0009-9</pub-id><pub-id pub-id-type="pmid">29184202</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>P</given-names></name><name><surname>Resendez</surname> <given-names>SL</given-names></name><name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></name><name><surname>Jimenez</surname> <given-names>JC</given-names></name><name><surname>Neufeld</surname> <given-names>SQ</given-names></name><name><surname>Giovannucci</surname> <given-names>A</given-names></name><name><surname>Friedrich</surname> <given-names>J</given-names></name><name><surname>Pnevmatikakis</surname> <given-names>EE</given-names></name><name><surname>Stuber</surname> <given-names>GD</given-names></name><name><surname>Hen</surname> <given-names>R</given-names></name><name><surname>Kheirbek</surname> <given-names>MA</given-names></name><name><surname>Sabatini</surname> <given-names>BL</given-names></name><name><surname>Kass</surname> <given-names>RE</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Data from: efficient and accurate extraction of in vivo calcium signals from microendoscopic video data</article-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.kr17k</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017a</year><data-title>CNMF-E</data-title><source>Github</source><version designator="088afc1">088afc1</version><ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/CNMF_E">https://github.com/zhoupc/CNMF_E</ext-link></element-citation></ref><ref id="bib59"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017b</year><data-title>eLife_submission</data-title><source>Github</source><version designator="1c65f70">1c65f70</version><ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/eLife_submission">https://github.com/zhoupc/eLife_submission</ext-link></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname> <given-names>Y</given-names></name><name><surname>Burns</surname> <given-names>LD</given-names></name><name><surname>Cocker</surname> <given-names>ED</given-names></name><name><surname>Hamel</surname> <given-names>EO</given-names></name><name><surname>Ghosh</surname> <given-names>KK</given-names></name><name><surname>Kitch</surname> <given-names>LJ</given-names></name><name><surname>El Gamal</surname> <given-names>A</given-names></name><name><surname>Schnitzer</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-term dynamics of CA1 hippocampal place codes</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nn.3329</pub-id><pub-id pub-id-type="pmid">23396101</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname> <given-names>Y</given-names></name><name><surname>Ghosh</surname> <given-names>KK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Miniature microscopes for large-scale imaging of neuronal activity in freely behaving rodents</article-title><source>Current Opinion in Neurobiology</source><volume>32</volume><fpage>141</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2015.04.001</pub-id><pub-id pub-id-type="pmid">25951292</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.28728.030</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Van Essen</surname><given-names>David C</given-names></name><role>Reviewing Editor</role><aff id="aff22"><institution>Washington University in St. Louis</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot; Efficient and accurate extraction of in vivo calcium signals from microendoscopic video data&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by David Van Essen as the Senior Editor and Reviewing Editor. One of the reviewers was Dr Timothy Holy (Reviewer 2); the other two have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Senior Editor has drafted this decision to help you prepare a revised submission. With regard to the issue raised with you by email as to whether the new algorithm's success is perhaps more of an accident of initialization than a reflection of good statistical design, the reviewers found your response to be thoughtful and helpful, but not entirely convincing. We therefore plan to ask the original reviewers to take another look at your revised manuscript before making a final decision.</p><p>Summary:</p><p>This is an excellent paper showing how the CNMF technique has been adapted for use with 1-P calcium imaging in endoscopic data. The paper is for the most part clearly written, and the simulations backed up by the in-vivo imaging data clearly demonstrates that this technique is by far superior to any other currently being used, including ICA/PCA or other variations. It builds on previous work from Pnevmatikakis and colleagues, differing primarily in the statistical model used to describe the background. It will likely be essential to use this technique to obtain the highest quality data, as background fluctuations and cross-talk between neurons can severely impact the data recorded.</p><p>However, some aspects of the analysis are difficult to judge, and there are a number of concerns and recommendations raised by the reviewers.</p><p>Essential revisions:</p><p>1) It is important to discuss carefully to what degree this new algorithm's success reflects more of an accident of initialization than good statistical design. Given that (a) SVD will always produce a lower reconstruction error than NMF for the same number of components, and that (b) having a high background might allow the neural components to &quot;insulate&quot; themselves from the constraints of nonnegativity by offsetting them from zero, it seems possible that the model also admits solutions that are better from the standpoint of the loss function yet worse from the standpoint of biological plausibility. As a consequence, it may only be the initialization causing the algorithm to land in a local (but far from global) minimum that is leading to the kinds of plausible solutions exhibited in the manuscript; the risk is that a more exhaustive optimization algorithm, applied to the same data and model, would prefer solutions that lack this plausibility.</p><p>2) The exposition of the CNMF-E algorithm in this paper could stand to be improved substantially. It is extremely hard (or, really, impossible) to make sense of the details of the proposed algorithm as presented in this paper! While the big picture of the algorithm is clear from a quick glance at Equation 8, the details are not clear from the many pages of text that follow.</p><p>3) There are concerns about how well the technique would work if the true firing correlations increase. Can the authors do a simulation where they increase pair-wise correlations between the deltaF traces systematically and see at what point segmentation breaks down or cross-talk removal artificially lowers the correlations.</p><p>4) Please provide more practical advice about how to implement the software. This method is very computationally intensive, and some direction needs to be given on how to run the software to allow a large number of movies to be analyzed in a reasonable amount of time. There are no benchmarks given (from my reading) on how long the analysis takes per minute of recording and how this can be optimized.</p><p>5) Please comment on success of being able to segment the same region over several recordings over days and match up neurons across days?</p><p>6) The authors should also present what happens when they iterate their model to full convergence (e.g. square root of the machine precision) and discuss the heuristics they use to choose when to terminate the iteration early.</p><p>7) How does the quality of the neuronal reconstruction compare if you just use CNMF on the spatially-filtered (and 0-truncated) image? If it performs similarly, it's not entirely clear that this more complex model represents much of an advance.</p><p>8) It is mentioned in subsection ‚Äúin vivomicroendoscopic imaging and data analysis‚Äù that manual interventions were applied in the data analysis shown in this paper. This makes the comparisons shown in this paper unfair to competitors that are fully automated (since of course any method can be improved using manual intervention). Can the authors show results of CNMF-E without manual intervention? Also, how much manual investment (time, numbers of each type of decision, etc.) is necessary, and how much the manual intervention improves the result.</p><p>9) How does CNMF-E fare against CNMF when applied to two-photon data? i.e., when the additional flexibility of the model is perhaps not essential, does this extra flexibility degrade the performance in some fashion?</p><p>10) It is important to make the data and the scripts available for recreating the figures shown in this paper, for both the simulated and the real data. Otherwise it will be very hard for others to apply CNMF-E and get comparable results, given the many tuning parameters and semi-manual interventions involved.</p><p>11) What happens if one passes in the initialization described in subsection ‚ÄúInitialization of model variables‚Äù to the CNMF algorithm or to other competitors in the literature?</p><p><italic>Reviewer #1:</italic> </p><p>This is an excellent paper showing how the CNMF technique has been adapted for use with 1-P calcium imaging in endoscopic data. The paper is very clearly written, and the simulations backed up by the in-vivo imaging data clearly demonstrates that this technique is by far superior to any other currently being used, including ICA/PCA or other variations. In fact, it will be essential to use this technique to obtain the highest quality data as background fluctuations and cross-talk between neurons can severely impact the data recorded.</p><p>These are my concerns:</p><p>1) I have some concerns about how well the technique would work if the true firing correlations increase. Can the authors do a simulation where they increase pair-wise correlations between the deltaF traces systematically and see at what point segmentation breaks down or cross-talk removal artificially lowers the correlations.</p><p>2 I felt that the authors could provide more practical advice about how to implement the software. This method is very computationally intensive, and some direction needs to be given on how to run the software to allow a large number of movies to be analyzed in a reasonable amount of time. There are no benchmarks given (from my reading) on how long the analysis takes per minute of recording and how this can be optimized.</p><p>3) Can the authors comment on success of being able to segment the same region over several recordings over days and match up neurons across days?</p><p><italic>Reviewer #2:</italic> </p><p>The manuscript by Zhou and colleagues presents a computational method for extracting calcium signals from neurons in images that are &quot;corrupted&quot; by high background, with a specific interest in microendoscopic recordings. It builds on previous work from Pnevmatikakis and colleagues, differing primarily in the statistical model used to describe the background. The authors present several examples using both simulations and real experimental data to demonstrate the characteristics of their new method. In comparison with their previous method and a PCA/ICA method, the authors show examples where the new method outperforms the previous one.</p><p>The manuscript has many strengths, including the application to several different in vivo data sets and the realistic-looking simulated (with available ground truth) data sets. The model also seems thoughtfully designed, and considerable effort was made to ensure that it will be practical at least for data sets of the size of typical endoscopic recordings. The figures are mostly clear except as noted below.</p><p>Overall, this may be a worthy addition to the armamentum of methods; however, some aspects of the analysis are difficult to judge, and my overall assessment is that its importance is not yet clear. My major questions/concerns are:</p><p>1) First, this reviewer doesn't fully understand why/how the background/foreground separation works. Loosely, the model is of the form `Y ‚âà b + a*c`, where `b` is the background and `a` and `c` are the spatial/temporal components of the neurons. In previous work they argued that a non-negativity constraint on `a` and `c` led to substantial improvement over unconstrained methods and effective separation of the neurons from a (small) background. However, in this case `b` is of quite large magnitude, and one might expect this to effectively &quot;relax&quot; the constraint on `a` and `c`: the model could fit a smaller value for `b` in the vicinity of a neuron, allowing `a` and `c` to take on larger positive values and thus &quot;cushioning&quot; them against the impact of the nonnegativity constraint. In a sense, one might imagine that the fully-converged result would not be terribly different from a (sparse, local) singular value decomposition, which is known to not properly segment cells particularly in the presence of temporal correlations among nearby/overlapping cells.</p><p>Nevertheless, the temporal traces exhibit the characteristics expected from a &quot;meaningful&quot; nonnegative factorization. So, the question is, why? One possible answer is that the authors are not iterating their model to convergence, and that an intermediate initialization via a &quot;meaningful&quot; nonnegative step still has substantial influence over the final form of the solution. If this is the case, the authors should also present what happens when they iterate their model to full convergence (e.g. square root of the machine precision) and discuss the heuristics they use to choose when to terminate the iteration early.</p><p>2) For the real datasets they initialize the neuronal factorization using a high-pass spatial filtering of the raw image, then reintroduce the full image and fit the complete model. But in the end, we're mostly interested in the neurons, and we may not really care that much about an accurate model of the background. How does the quality of the neuronal reconstruction compare if you just use CNMF on the spatially-filtered (and 0-truncated) image? If it performs similarly, it's not entirely clear that this more complex model represents much of an advance.</p><p>It's possible that there's a bit of data in the manuscript on this point (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, black dots), but to this reviewer it's not clearly described, and this is shown only for simulated data. If you don't know the ground truth, would you care about the difference between 0.99 similarity and 0.999 similarity?</p><p>3) The authors describe some manual interventions in the methods, but there does not appear to be much in the way of description of exactly how these interventions were leveraged. It would be helpful to readers to understand what the &quot;raw&quot; output of the unsupervised algorithm really looks like, how much manual investment (time, numbers of each type of decision, etc.) is necessary, and how much the manual intervention improves the result.</p><p>Related to these points (particularly the first two), how does CNMF-E fare against CNMF when applied to two-photon data? i.e., when the additional flexibility of the model is perhaps not essential, does this extra flexibility degrade the performance in some fashion?</p><p><italic>Reviewer #3:</italic> </p><p>This paper introduces the CNMF-E algorithm for extraction of neurons from 1-photon calcium imaging data.</p><p>1) First and foremost, CNMF-E has quickly become widely-adopted by scientists who are collecting micro-endoscopic video data. Clearly this paper is very high impact and deserves to be published in a prominent journal. I congratulate the authors for an important piece of work, which will surely have a sustained and important impact on the field.</p><p>2) I'm concerned about the semi-manual &quot;interventions&quot; described in subsection ‚ÄúInterventions‚Äù. It is mentioned in subsection ‚Äúin vivomicroendoscopic imaging and data analysis‚Äù that manual interventions were applied in the data analysis shown in this paper. This makes the comparisons shown in this paper unfair to competitors that are fully automated (since of course any method can be improved using manual intervention). Can the authors show results of CNMF-E without manual intervention?</p><p>3) The CNMF-E algorithm is just a slight tweak on CNMF, which is itself a pretty standard matrix factorization. This lack of statistical innovation is probably OK, though, since <italic>eLife</italic> is not looking to publish innovative statistical methodology, but rather an algorithm that works well and has very high impact.</p><p>4) I feel very strongly that the exposition of the CNMF-E algorithm in this paper could stand to be improved substantially. It is extremely hard (or, really, impossible) to make sense of the details of the proposed algorithm as presented in this paper! While the big picture of the algorithm is clear from a quick glance at Equation 8, the details are not clear from the many pages of text that follow. When I read a statistical- or computational-focused paper, I wonder &quot;would a statistically/computationally-literate reader of this paper be able to re-implement this algorithm, from scratch, based on the description of this paper?&quot; The answer to that question is definitely &quot;no&quot;. More details about this are provided below.</p><p>5) It is really wonderful that the authors have easy-to-use code available for the CNMF-E algorithm! However, it is also very important that they post scripts online recreating the figures shown in this paper, for both the simulated and the real data. For instance, I'd like to see a script that one can simply call into matlab that will read in the mouse dorsal striatum data and output exactly the results shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>. (A similar request applies to the other figures). This is particularly important in light of the &quot;semi-manual interventions&quot; mentioned in my point 2 above. Furthermore, the actual data used to make the figures (e.g. the calcium recordings for the mouse dorsal striatum area that were used to make <xref ref-type="fig" rid="fig5">Figure 5</xref>) should be made available.</p><p>Without the availability of the data and a script to get the results shown in the paper, I think it will be very hard for others to apply CNMF-E and get comparable results, given the many tuning parameters and semi-manual interventions involved. It will also be very hard for others to objectively evaluate how well CNMF-E works, and how sensitive the results in this paper are to tuning parameter selection, etc.!</p><p>6) I think that most of the benefit of CNMF-E over CNMF comes from the careful initialization of the algorithm described in subsection ‚ÄúInitialization of model variables‚Äù, rather than from the details of the optimization problem Equation 8. What happens if one passes in the initialization described in subsection ‚ÄúInitialization of model variables‚Äù to the CNMF algorithm or to other competitors in the literature?</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Efficient and accurate extraction of in vivo calcium signals from microendoscopic video data&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by David Van Essen (Senior Editor and Reviewing Editor), and the original three reviewers.</p><p>The manuscript has been improved but there are two small remaining technical points that need to be addressed before acceptance, as outlined below. Both should be easy to address.</p><p>1) In subsection ‚ÄúFitting the CNMF-E model‚Äù, the optimization problem (P-All) needs to list s and B^f as optimization variables (i.e. they should appear under 'minimize'). While the reviewer agrees with the authors that &quot;s_i is completely determined by c_i and G^{(i)}, and B^f is not optimized explicitly&quot;, nonetheless s_i and B^f are optimization variables. This is actually just a fundamental math issue that has nothing to do with the specifics of the paper at hand!</p><p>To understand this point, consider the optimization problem &quot;minimize_{x,y} f(x,y) s.t. x=y&quot;. It would NOT be correct to instead write this as &quot;minimize_x f(x,y) s.t. x=y&quot;, EVEN THOUGH (to quote the authors), &quot;x is completely determined by y&quot;. (Why is &quot;minimize_x f(x,y) s.t. x=y&quot; incorrect? Well, unless y is listed as an optimization variable, then it is treated as a constant in the optimization problem; therefore, the solution to that problem is trivially just x=y, with minimum value attained at f(y,y).)</p><p>Thus, (P-All) is simply incorrect as written. The fix is simple: put &quot;s_i&quot; and &quot;B^f&quot; under the &quot;minimize&quot;.</p><p>2) In a couple of places (e.g. subsections ‚ÄúFitting the CNMF-E model‚Äùand‚Äù Ranking seed pixels‚Äù) it is mentioned that (P-All) is not jointly convex in the optimization variables. Unfortunately, though this statement is true, it is misleading: when we say that a problem is not &quot;jointly convex&quot;, we are implying that it is convex in the individual optimization variables. By contrast, (P-All) isn't even convex in the individual optimization variables. This is because details aren't provided of what (for instance) &quot;is sparse&quot; means. If that means that the l1 norm is penalized, then yes, it is convex in the individual optimization variables. But if it means some other notion of sparsity, e.g. that the l0 norm is penalized, then (P-All) isn't convex in the individual optimization variables.</p><p>Therefore, the reviewer feels that stating that (P-All) is &quot;not jointly convex&quot; or &quot;jointly non-convex&quot; is misleading and should be removed from the text where it appears. The authors should instead just say &quot;non-convex&quot; without the word &quot;jointly&quot;.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.28728.031</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>Thank you for your letter and for the thoughtful and constructive comments, which helped us greatly. We believe the revision is a substantial improvement over the original submission.</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) It is important to discuss carefully to what degree this new algorithm's success reflects more of an accident of initialization than good statistical design. Given that (a) SVD will always produce a lower reconstruction error than NMF for the same number of components, and that (b) having a high background might allow the neural components to &quot;insulate&quot; themselves from the constraints of nonnegativity by offsetting them from zero, it seems possible that the model also admits solutions that are better from the standpoint of the loss function yet worse from the standpoint of biological plausibility. As a consequence, it may only be the initialization causing the algorithm to land in a local (but far from global) minimum that is leading to the kinds of plausible solutions exhibited in the manuscript; the risk is that a more exhaustive optimization algorithm, applied to the same data and model, would prefer solutions that lack this plausibility.</p></disp-quote><p>Thanks for these thoughtful points.</p><p>Regarding the importance of initialization, we note first that the initialization results are typically not perfect; running the iterative optimization proposed here does lead to quantitatively better solutions, as shown in simulated data in <xref ref-type="fig" rid="fig4">Figure 4</xref> and the new <xref ref-type="fig" rid="fig5">Figure 5</xref>. In real data, we often find that the initialization picks out high-SNR neurons but misses low-SNR neurons that can only be detected after further iterations. Second, the results of <xref ref-type="fig" rid="fig4">Figure 4</xref> further show that if we apply a perfect initialization (i.e., initialize with the ground truth) and then apply a statistical model that fits the data poorly (e.g., CNMF with a rank-1 background model) then we obtain significantly worse results than CNMF-E initialized with no prior knowledge of the ground truth. We have clarified both of these important points in the revised text (see Results section). Regarding the reviewer‚Äôs interesting point about the SVD: we agree that SVD minimizes a certain approximation norm: svds(Y,k) finds the closest rank-k matrix to Y in terms of the mean-square reconstruction error. However, the resulting singular vectors will typically be very poor estimators of the neuronal components, for reasons that are well-understood: unlike real neural components, the singular vectors will be orthogonal, not sparse, not non-negative, not spatially localized, etc. In short, the SVD is solving the wrong optimization problem, because while it is minimizing a reasonable cost function it is optimizing over the wrong constraint space. We don‚Äôt want to search over all possible low-rank matrices to approximate the data matrix Y; instead, to obtain good estimates we need to impose constraints both on the single-neuron components (e.g. sparsity and nonnegativity of neural activity, sparsity and locality of neuronal shapes, etc.) and on the background (which is spatially smooth, as encoded by the novel ‚Äúring‚Äù background model introduced here). We have tried to impose these constraints in a tractable manner in this work.</p><p>So, to address this question of artificially increasing the size of the background: yes, by doing this one could reduce the mean-squared reconstruction error but at the cost of forcing the inferred neural activity to be highly non-sparse and the background to be highly non-smooth in the spatial domain. In other words, this solution would achieve a good objective value (like the SVD solution) but would grossly violate the constraints we have placed on the problem, and thus this solution is not favored by our optimizer ‚Äì as desired.</p><p>Regarding the point about local vs global optima ‚Äì it is theoretically possible there is a solution that satisfies the constraints and gives better MSE but is less neurally plausible. Due to the non-convexity of the objective function completely exhaustive search seems intractable. But our experience as described in this manuscript (and the experience of our users) has been that solutions that find a good MSE under the objective function are ‚Äúplausible.‚Äù The new <xref ref-type="fig" rid="fig4">Figure 4B</xref> provides additional support for this claim; see further discussion below.</p><disp-quote content-type="editor-comment"><p>2) The exposition of the CNMF-E algorithm in this paper could stand to be improved substantially. It is extremely hard (or, really, impossible) to make sense of the details of the proposed algorithm as presented in this paper! While the big picture of the algorithm is clear from a quick glance at Equation 8, the details are not clear from the many pages of text that follow.</p></disp-quote><p>Thanks for this feedback. We have edited the text significantly to clarify a number of details that were not sufficiently clear in the original manuscript. See detailed changes discussed further below.</p><disp-quote content-type="editor-comment"><p>3) There are concerns about how well the technique would work if the true firing correlations increase. Can the authors do a simulation where they increase pair-wise correlations between the deltaF traces systematically and see at what point segmentation breaks down or cross-talk removal artificially lowers the correlations.</p></disp-quote><p>Great suggestion. See the new <xref ref-type="fig" rid="fig5">Figure 5</xref> and the new text paragraph in subsection ‚Äúinitialization of model variables‚Äù describing highly spatially- or temporally-correlated data.</p><disp-quote content-type="editor-comment"><p>4) Please provide more practical advice about how to implement the software. This method is very computationally intensive and some direction needs to be given on how to run the software to allow a large number of movies to be analyzed in a reasonable amount of time. There are no benchmarks given (from my reading) on how long the analysis takes per minute of recording and how this can be optimized.</p></disp-quote><p>Good suggestion. We added more practical advice right after the summary of the CNMF-E pipeline (subsection ‚ÄúInitialization of model variables‚Äù). We also improved our CNMF-E implementation to support large scale data analysis and to process multiple videos together. Details are included in the revised manuscript (subsection ‚ÄúRanking seed pixels‚Äù). We also provided more timing information. Regarding optimization of timing, we believe further significant speedups could be achieved with more parallelization, implementation in low-level languages, etc., and plan to pursue these directions in the future, but we chose to focus this manuscript on the model, estimation, and demonstrations on real and simulated data, rather than these lower-level timing optimizations.</p><p>We are also maintaining wiki pages for CNMF-E (<ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/CNMF_E/wiki">https://github.com/zhoupc/CNMF_E/wiki</ext-link>) for continuously providing practical advice about how to use the software.</p><disp-quote content-type="editor-comment"><p>5) Please comment on success of being able to segment the same region over several recordings over days and match up neurons across days?</p></disp-quote><p>We think CNMF-E should make this task significantly easier (because the output SNR is much improved compared to PCA/ICA), but we have not pursued a quantitative analysis of this point. A recent paper (Sheintuch et al., 2017) addressed exactly this issue and showed that more neurons could be reliably tracked using CNMF-E vs PCA/ICA; we have added a reference to this work.</p><disp-quote content-type="editor-comment"><p>6) The authors should also present what happens when they iterate their model to full convergence (e.g., square root of the machine precision), and discuss the heuristics they use to choose when to terminate the iteration early.</p></disp-quote><p>We added a residual sum of squares (RSS) vs iteration plot in <xref ref-type="fig" rid="fig4">Figure 4</xref>. We note in the revised text that we can use the RSS as a convergence criterion, but actually computing the RSS is relatively slow; instead we monitor the estimated neural components A and C, e.g., the number of detected components.</p><disp-quote content-type="editor-comment"><p>7) How does the quality of the neuronal reconstruction compare if you just use CNMF on the spatially-filtered (and 0-truncated) image? If it performs similarly, it's not entirely clear that this more complex model represents much of an advance.</p></disp-quote><p>Yes, this occurred to us as well. We tried this, and it doesn‚Äôt work well, because spatial filtering distorts the neural shapes and also removes the useful nonnegativity constraint from the optimization. We have added a note to the text making this point clear.</p><disp-quote content-type="editor-comment"><p>8) It is mentioned in subsection ‚Äúin vivo microendoscopic imaging and data analysis‚Äù that manual interventions were applied in the data analysis shown in this paper. This makes the comparisons shown in this paper unfair to competitors that are fully automated (since of course any method can be improved using manual intervention). Can the authors show results of CNMF-E without manual intervention? Also, how much manual investment (time, numbers of each type of decision, etc.) is necessary, and how much the manual intervention improves the result.</p></disp-quote><p>Fair points. We should clarify one point: it is not quite true that any method can be trivially improved using manual intervention. Specifically, PCA/ICA outputs a collection of spatial &amp; temporal filters, after the user inputs the dataset and the number of principal components and the number of independent components. Users can then easily manually delete components; however, there is not an obvious way to merge or split neurons (e.g., after splitting a neural component it is not clear how to assign temporal traces to the resulting split components). More importantly, there is no mechanism for refining the analysis results after manual interventions (for example, to account for a gap left after deleting some bad components that were partially explaining some of the observed signal). In CNMF-E, on the other hand, we can run additional iterative updates of the estimated components following manual interventions, which in practice can lead to significantly improved results. This point has been clarified in the revised text.</p><p>That said, to respond to the main point, we emphasize that the manual intervention in CNMF-E is an optional choice for correcting results using human knowledge, instead of being required by processing data. For the simulated data and three out of the four real datasets in the revised manuscript (subsection ‚ÄúInitialization of model variables‚Äù), we now apply no manual interventions at all: the algorithm was run in fully automatic mode. For the more challenging hippocampal dataset, we show the results before and after manual intervention in Video S10.</p><p>Of course, fully automated algorithms are preferable where possible. We believe that most of the interventions discussed here (e.g., detection of ‚Äúbad‚Äù components) can be cast as standard classification or computer vision tasks and can in the future be fully automated with sufficient training data; this is the topic of ongoing work. Our open-source pipeline makes it easy to swap in more automated intervention steps when and if these become available and reliable in the future. Again, these points have been clarified in the revised text.</p><disp-quote content-type="editor-comment"><p>9) How does CNMF-E fare against CNMF when applied to two-photon data? i.e., when the additional flexibility of the model is perhaps not essential, does this extra flexibility degrade the performance in some fashion?</p></disp-quote><p>The CNMF-E model also works for 2p data in which the background has simple spatiotemporal structure. This is hinted at in <xref ref-type="fig" rid="fig2">Figure 2I</xref>, where the CNMF-E model works well for both a small and large number of background sources. Several labs already use CNMF-E for processing their 2p data e.g. obtained via GRIN lenses; we hope to present these results in future work but decided against including these results here to avoid lengthening an already-long paper. That said, for ‚Äúvanilla‚Äù 2p data where the rank-1 background model suffices, the basic CNMF model is preferred in practice, because the resulting inference is faster (though not significantly more accurate) than in the CNMF-E model. In the toolbox we have developed users can easily choose different initialization options and background models depending on the type of data under analysis.</p><disp-quote content-type="editor-comment"><p>10) It is important to make the data and the scripts available for recreating the figures shown in this paper, for both the simulated and the real data. Otherwise it will be very hard for others to apply CNMF-E and get comparable results, given the many tuning parameters and semi-manual interventions involved.</p></disp-quote><p>Agreed. We now provide all code and scripts for generating the figures and the videos (<ext-link ext-link-type="uri" xlink:href="https://github.com/zhoupc/eLife_submission">https://github.com/zhoupc/<italic>eLife</italic>_submission</ext-link>)</p><disp-quote content-type="editor-comment"><p>11) What happens if one passes in the initialization described in subsection ‚ÄúInitialization of model variables‚Äù to the CNMF algorithm or to other competitors in the literature?</p></disp-quote><p>This is an important point that we emphasize more clearly in the revised text (subsection ‚ÄúCNMF-E accurately initializes single-neuronal spatial and temporal components‚Äù). In <xref ref-type="fig" rid="fig4">Figure 4</xref> we initialize CNMF with the ground truth and find that it performs poorly, due to the poor fit of its background model here. (We obtained similar results with real instead of simulated data; in real micro-endoscopic data, performing CNMF iterations significantly reduces the SNR of the estimated traces, due to background contamination.)</p><p>Reviewer #1:</p><disp-quote content-type="editor-comment"><p>This is an excellent paper showing how the CNMF technique has been adapted for use with 1-P calcium imaging in endoscopic data. The paper is very clearly written, and the simulations backed up by the in-vivo imaging data clearly demonstrates that this technique is by far superior to any other currently being used, including ICA/PCA or other variations. In fact, it will be essential to use this technique to obtain the highest quality data as background fluctuations and cross-talk between neurons can severely impact the data recorded.</p></disp-quote><p>Thanks very much for your kind comments.</p><disp-quote content-type="editor-comment"><p>These are my concerns:</p><p>1) I have some concerns about how well the technique would work if the true firing correlations increase. Can the authors do a simulation where they increase pair-wise correlations between the deltaF traces systematically and see at what point segmentation breaks down or cross-talk removal artificially lowers the correlations.</p></disp-quote><p>Please see our responses to the Essential revision question (Bhatia et al., 2015).</p><disp-quote content-type="editor-comment"><p>2 I felt that the authors could provide more practical advice about how to implement the software. This method is very computationally intensive, and some direction needs to be given on how to run the software to allow a large number of movies to be analyzed in a reasonable amount of time. There are no benchmarks given (from my reading) on how long the analysis takes per minute of recording and how this can be optimized.</p></disp-quote><p>Please see our responses to the Essential revision question (4).</p><disp-quote content-type="editor-comment"><p>3) Can the authors comment on success of being able to segment the same region over several recordings over days and match up neurons across days?</p></disp-quote><p>Please see our responses to the Essential revision question (Cameron et al., 2016).</p><p>Reviewer #2:</p><disp-quote content-type="editor-comment"><p>The manuscript by Zhou and colleagues presents a computational method for extracting calcium signals from neurons in images that are &quot;corrupted&quot; by high background, with a specific interest in microendoscopic recordings. It builds on previous work from Pnevmatikakis and colleagues, differing primarily in the statistical model used to describe the background. The authors present several examples using both simulations and real experimental data to demonstrate the characteristics of their new method. In comparison with their previous method and a PCA/ICA method, the authors show examples where the new method outperforms the previous one.</p><p>The manuscript has many strengths, including the application to several differentin vivo data sets and the realistic-looking simulated (with available ground truth) data sets. The model also seems thoughtfully designed, and considerable effort was made to ensure that it will be practical at least for data sets of the size of typical endoscopic recordings. The figures are mostly clear except as noted below.</p><p>Overall, this may be a worthy addition to the armamentum of methods; however, some aspects of the analysis are difficult to judge, and my overall assessment is that its importance is not yet clear. My major questions/concerns are:</p><p>1) First, this reviewer doesn't fully understand why/how the background/foreground separation works. Loosely, the model is of the form `Y ‚âà b + a*c`, where `b` is the background and `a` and `c` are the spatial/temporal components of the neurons. In previous work they argued that a non-negativity constraint on `a` and `c` led to substantial improvement over unconstrained methods and effective separation of the neurons from a (small) background. However, in this case `b` is of quite large magnitude, and one might expect this to effectively &quot;relax&quot; the constraint on `a` and `c`: the model could fit a smaller value for `b` in the vicinity of a neuron, allowing `a` and `c` to take on larger positive values and thus &quot;cushioning&quot; them against the impact of the nonnegativity constraint. In a sense, one might imagine that the fully-converged result would not be terribly different from a (sparse, local) singular value decomposition, which is known to not properly segment cells particularly in the presence of temporal correlations among nearby/overlapping cells.</p><p>Nevertheless, the temporal traces exhibit the characteristics expected from a &quot;meaningful&quot; nonnegative factorization. So, the question is, why? One possible answer is that the authors are not iterating their model to convergence, and that an intermediate initialization via a &quot;meaningful&quot; nonnegative step still has substantial influence over the final form of the solution. If this is the case, the authors should also present what happens when they iterate their model to full convergence (e.g., square root of the machine precision), and discuss the heuristics they use to choose when to terminate the iteration early.</p></disp-quote><p>Thanks for these very thoughtful comments.</p><p>Re: the `Y ‚âà b + a*c`model ‚Äì yes, but additionally recall that the background term b here is constrained to have a strong degree of spatial smoothness, so the model can‚Äôt simply add a ‚Äúhole‚Äù into the new time-varying background term b to somehow help a*c avoid the nonnegativity constraint. In addition, as noted above, the model would also have to violate the sparsity constraint on c to avoid the nonnegativity constraint. We have also significantly revised the ‚ÄúAlgorithms for solving problem (P-T)‚Äù subsection in the Materials and methods section to clarify this point.</p><p>Re: iterating to convergence ‚Äì our results are not dependent on early stopping. See the new panel B in <xref ref-type="fig" rid="fig4">Figure 4</xref>, and also our responses to Essential revision question (Carvalho Poyraz et al., 2016).</p><disp-quote content-type="editor-comment"><p>2) For the real datasets they initialize the neuronal factorization using a high-pass spatial filtering of the raw image, then reintroduce the full image and fit the complete model. But in the end, we're mostly interested in the neurons, and we may not really care that much about an accurate model of the background. How does the quality of the neuronal reconstruction compare if you just use CNMF on the spatially-filtered (and 0-truncated) image? If it performs similarly, it's not entirely clear that this more complex model represents much of an advance.</p></disp-quote><p>See our response to the Essential revision question (Cichocki and Phan, 2009).</p><p>To expand on this slightly: we agree that many users may not care much about the background signals, just as many users of extracellular voltage recordings only care about extracted spikes, not local field potentials. But our goal for CNMF-E is to demix and assign all the signals in the data correctly, with minimal spatial or temporal distortion. In our opinion it is likely that the background signal (like the local field potential) carries a lot of useful information which has to date been largely ignored, and we want to avoid corrupting or discarding this information. Without accurate background-subtraction, the extracted temporal components will often be highly contaminated, as we have emphasized in this manuscript (subsection ‚ÄúModel and model fitting‚Äù).</p><disp-quote content-type="editor-comment"><p>It's possible that there's a bit of data in the manuscript on this point (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, black dots), but to this reviewer it's not clearly described, and this is shown only for simulated data. If you don't know the ground truth, would you care about the difference between 0.99 similarity and 0.999 similarity?</p></disp-quote><p>Fair question. In addition to our response above (emphasizing the importance of a full separation of the movie data into properly-defined and interpretable spatial, temporal, and background components), our response to Essential Revision question (Apthorpe et al., 2016) touches on this issue (on fitting a complete model compared to just using the initializations directly). See also the new <xref ref-type="fig" rid="fig5">Figure 5</xref>, showing a more direct example of significant improvements of running the full CNMF-E pipeline (not just the initialization).</p><disp-quote content-type="editor-comment"><p>3) The authors describe some manual interventions in the methods, but there does not appear to be much in the way of description of exactly how these interventions were leveraged. It would be helpful to readers to understand what the &quot;raw&quot; output of the unsupervised algorithm really looks like, how much manual investment (time, numbers of each type of decision, etc.) is necessary, and how much the manual intervention improves the result.</p></disp-quote><p>Please see our respondents to the Essential revision question (8).</p><disp-quote content-type="editor-comment"><p>Related to these points (particularly the first two), how does CNMF-E fare against CNMF when applied to two-photon data? i.e., when the additional flexibility of the model is perhaps not essential, does this extra flexibility degrade the performance in some fashion?</p></disp-quote><p>Please see our respondents to the Essential revision question (9).</p><p>Reviewer #3:</p><disp-quote content-type="editor-comment"><p>This paper introduces the CNMF-E algorithm for extraction of neurons from 1-photon calcium imaging data.</p><p>1) First and foremost, CNMF-E has quickly become widely-adopted by scientists who are collecting micro-endoscopic video data. Clearly this paper is very high impact and deserves to be published in a prominent journal. I congratulate the authors for an important piece of work, which will surely have a sustained and important impact on the field.</p></disp-quote><p>Thanks for this kind comment.</p><disp-quote content-type="editor-comment"><p>2) I'm concerned about the semi-manual &quot;interventions&quot; described in subsection ‚ÄúInterventions‚Äù. It is mentioned in subsection ‚Äúin vivo microendoscopic imaging and data analysis‚Äù that manual interventions were applied in the data analysis shown in this paper. This makes the comparisons shown in this paper unfair to competitors that are fully automated (since of course any method can be improved using manual intervention). Can the authors show results of CNMF-E without manual intervention?</p></disp-quote><p>Please see our responses to the Essential revision question (8).</p><disp-quote content-type="editor-comment"><p>3) The CNMF-E algorithm is just a slight tweak on CNMF, which is itself a pretty standard matrix factorization. This lack of statistical innovation is probably OK, though, since eLife is not looking to publish innovative statistical methodology, but rather an algorithm that works well and has very high impact.</p></disp-quote><p>We would argue against the comment that there is no statistical innovation here. Much careful, effective, cutting-edge statistical treatment of neural data might be dismissed as &quot;slight tweaks,&quot; in this sense. But statistical methods cannot be judged solely from an abstract perspective, and as soon as methods are brought to bear on complicated problems, the &quot;tweaks&quot; constitute a major portion of the research effort. It is a serious statistical challenge to cleanly demix data in which the background artifacts are an order of magnitude larger than the desired single-neuronal signals ‚Äì and as we have argued here, both PCA/ICA and vanilla CNMF do not do an adequate job of removing this background contamination. (To put it another way, we experimented with many ‚Äútweaks‚Äù of CNMF that did not work well; this was a highly non-trivial development process.) But that said, we agree that in the end the main differences between CNMF and CNMF-E are a different background model and a different initialization procedure; these two innovations led to an algorithm that works well and that we hope will have a significant positive impact on the field.</p><disp-quote content-type="editor-comment"><p>4) I feel very strongly that the exposition of the CNMF-E algorithm in this paper could stand to be improved substantially. It is extremely hard (or, really, impossible) to make sense of the details of the proposed algorithm as presented in this paper! While the big picture of the algorithm is clear from a quick glance at Equation 8, the details are not clear from the many pages of text that follow. When I read a statistical- or computational-focused paper, I wonder &quot;would a statistically/computationally-literate reader of this paper be able to re-implement this algorithm, from scratch, based on the description of this paper?&quot; The answer to that question is definitely &quot;no&quot;. More details about this are provided below.</p></disp-quote><p>Please see our responses to the Essential revision question (Barbera et al., 2016).</p><disp-quote content-type="editor-comment"><p>5) It is really wonderful that the authors have easy-to-use code available for the CNMF-E algorithm! However, it is also very important that they post scripts online recreating the figures shown in this paper, for both the simulated and the real data. For instance, I'd like to see a script that one can simply call into matlab that will read in the mouse dorsal striatum data and output exactly the results shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>. (A similar request applies to the other figures). This is particularly important in light of the &quot;semi-manual interventions&quot; mentioned in my point 2 above. Furthermore, the actual data used to make the figures (e.g. the calcium recordings for the mouse dorsal striatum area that were used to make <xref ref-type="fig" rid="fig5">Figure 5</xref>) should be made available.</p><p>Without the availability of the data and a script to get the results shown in the paper, I think it will be very hard for others to apply CNMF-E and get comparable results, given the many tuning parameters and semi-manual interventions involved. It will also be very hard for others to objectively evaluate how well CNMF-E works, and how sensitive the results in this paper are to tuning parameter selection, etc.!</p></disp-quote><p>Please see our responses to the Essential revision question (10).</p><disp-quote content-type="editor-comment"><p>6) I think that most of the benefit of CNMF-E over CNMF comes from the careful initialization of the algorithm described in subsection ‚ÄúInitialization of model variables‚Äù, rather than from the details of the optimization problem Equation 8. What happens if one passes in the initialization described in subsection ‚ÄúInitialization of model variables‚Äù to the CNMF algorithm or to other competitors in the literature?</p></disp-quote><p>Please see our responses to the Essential revision question (Apthorpe et al., 2016) for explaining the limitations of the initialization step.</p><p>To our knowledge, the background model in CNMF-E is the first one that accurately models the background components in this type of data; this new background model (along with our new initialization approach) is the main innovation of our work.</p><p>As for the suggestion of passing the initialization to other competitors, we did so using simulated data, where we passed in the ground truth spatial and temporal components to the vanilla CNMF algorithm (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The results are much worse than CNMF-E. This is a clear evidence that the low rank NMF background model used in vanilla CNMF is not enough for modeling the background components in microendoscopic data. We would expect similar results with related methods that use a similar low-rank matrix factorization model (e.g. Diego-Andilla and Hamprecht, 2013, or Maruyama et al., 2014). We also tried the similar model in Suite2p (Pachitariu et.al., 2016), which projects the background onto a prespecified spatial basis, and again found that this led to worse results in recovering the background signal in the datasets examined here.</p><p>PCA/ICA does not offer an easy method for incorporating warm initialization starts, as discussed further above.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>1) In subsection ‚ÄúFitting the CNMF-E model‚Äù, the optimization problem (P-All) needs to list s and B^f as optimization variables (i.e. they should appear under 'minimize'). While the reviewer agrees with the authors that &quot;s_i is completely determined by c_i and G^{(i)}, and B^f is not optimized explicitly&quot;, nonetheless s_i and B^f are optimization variables. This is actually just a fundamental math issue that has nothing to do with the specifics of the paper at hand!</p><p>To understand this point, consider the optimization problem &quot;minimize_{x,y} f(x,y) s.t. x=y&quot;. It would NOT be correct to instead write this as &quot;minimize_x f(x,y) s.t. x=y&quot;, EVEN THOUGH (to quote the authors), &quot;x is completely determined by y&quot;. (Why is &quot;minimize_x f(x,y) s.t. x=y&quot; incorrect? Well, unless y is listed as an optimization variable, then it is treated as a constant in the optimization problem; therefore, the solution to that problem is trivially just x=y, with minimum value attained at f(y,y).)</p><p>Thus, (P-All) is simply incorrect as written. The fix is simple: put &quot;s_i&quot; and &quot;B^f&quot; under the &quot;minimize&quot;.</p></disp-quote><p>Great suggestion. We made three changes:</p><p>a) in (P-All), we put 'S' and 'B^f' under the 'minimize'</p><p>b) in (P-T), we put 'S' under the minimize</p><p>c) in (P-B), we put 'B^f' under the minimize.</p><disp-quote content-type="editor-comment"><p>2) In a couple of places (e.g. subsections ‚ÄúFitting the CNMF-E model‚Äùand ‚ÄúRanking seed pixels‚Äù) it is mentioned that (P-All) is not jointly convex in the optimization variables. Unfortunately, though this statement is true, it is misleading: when we say that a problem is not &quot;jointly convex&quot;, we are implying that it is convex in the individual optimization variables. By contrast, (P-All) isn't even convex in the individual optimization variables. This is because details aren't provided of what (for instance) &quot;is sparse&quot; means. If that means that the l1 norm is penalized, then yes, it is convex in the individual optimization variables. But if it means some other notion of sparsity, e.g. that the l0 norm is penalized, then (P-All) isn't convex in the individual optimization variables.</p><p>Therefore, the reviewer feels that stating that (P-All) is &quot;not jointly convex&quot; or &quot;jointly non-convex&quot; is misleading and should be removed from the text where it appears. The authors should instead just say &quot;non-convex&quot; without the word &quot;jointly&quot;.</p></disp-quote><p>Great suggestion. We removed the word ‚Äòjointly‚Äô in all places.</p></body></sub-article></article>