<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">75038</article-id><article-id pub-id-type="doi">10.7554/eLife.75038</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Controllability boosts neural and cognitive signatures of changes-of-mind in uncertain environments</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-79335"><name><surname>Rouault</surname><given-names>Marion</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6586-3788</contrib-id><email>marion.rouault@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-260630"><name><surname>Weiss</surname><given-names>Aurélien</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-260629"><name><surname>Lee</surname><given-names>Junseok K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8622-6259</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-199772"><name><surname>Drugowitsch</surname><given-names>Jan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7846-0408</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-68480"><name><surname>Chambon</surname><given-names>Valerian</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-165830"><name><surname>Wyart</surname><given-names>Valentin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6522-7837</contrib-id><email>valentin.wyart@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf3"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02dg3n954</institution-id><institution>Laboratoire de Neurosciences Cognitives et Computationnelles, Institut National de la Santé et de la Recherche Médicale (Inserm)</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01qfab443</institution-id><institution>Institut Jean Nicod, Centre National de la Recherche Scientifique (CNRS)</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013cjyk83</institution-id><institution>Département d’Études Cognitives, École Normale Supérieure, Université Paris Sciences et Lettres (PSL University)</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f82e368</institution-id><institution>Université de Paris</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff5"><label>5</label><institution>Department of Neurobiology, Harvard Medical School</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Roiser</surname><given-names>Jonathan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>13</day><month>09</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e75038</elocation-id><history><date date-type="received" iso-8601-date="2021-10-28"><day>28</day><month>10</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-07-19"><day>19</day><month>07</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-01-04"><day>04</day><month>01</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.01.04.425114"/></event></pub-history><permissions><copyright-statement>© 2022, Rouault et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Rouault et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-75038-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-75038-figures-v1.pdf"/><abstract><p>In uncertain environments, seeking information about alternative choice options is essential for adaptive learning and decision-making. However, information seeking is usually confounded with changes-of-mind about the reliability of the preferred option. Here, we exploited the fact that information seeking requires control over which option to sample to isolate its behavioral and neurophysiological signatures. We found that changes-of-mind occurring with control require more evidence against the current option, are associated with reduced confidence, but are nevertheless more likely to be confirmed on the next decision. Multimodal neurophysiological recordings showed that these changes-of-mind are preceded by stronger activation of the dorsal attention network in magnetoencephalography, and followed by increased pupil-linked arousal during the presentation of decision outcomes. Together, these findings indicate that information seeking increases the saliency of evidence perceived as the direct consequence of one’s own actions.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>confidence</kwd><kwd>information seeking</kwd><kwd>exploration</kwd><kwd>inference</kwd><kwd>decision-making</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001961</institution-id><institution>AXA Research Fund</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Rouault</surname><given-names>Marion</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-17-EURE-0017</award-id><principal-award-recipient><name><surname>Rouault</surname><given-names>Marion</given-names></name><name><surname>Weiss</surname><given-names>Aurélien</given-names></name><name><surname>Lee</surname><given-names>Junseok K</given-names></name><name><surname>Chambon</surname><given-names>Valerian</given-names></name><name><surname>Wyart</surname><given-names>Valentin</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-10-IDEX-0001-02 PSL</award-id><principal-award-recipient><name><surname>Rouault</surname><given-names>Marion</given-names></name><name><surname>Weiss</surname><given-names>Aurélien</given-names></name><name><surname>Lee</surname><given-names>Junseok K</given-names></name><name><surname>Chambon</surname><given-names>Valerian</given-names></name><name><surname>Wyart</surname><given-names>Valentin</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-16-CE37-0012-01 and ANR-19-CE37-0014-01</award-id><principal-award-recipient><name><surname>Chambon</surname><given-names>Valerian</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000913</institution-id><institution>James S. McDonnell Foundation</institution></institution-wrap></funding-source><award-id>grant #220020462</award-id><principal-award-recipient><name><surname>Drugowitsch</surname><given-names>Jan</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>ERC-StG-759341</award-id><principal-award-recipient><name><surname>Wyart</surname><given-names>Valentin</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-14-CE13-0028-01</award-id><principal-award-recipient><name><surname>Wyart</surname><given-names>Valentin</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-17-NEUC-0001-02</award-id><principal-award-recipient><name><surname>Drugowitsch</surname><given-names>Jan</given-names></name><name><surname>Wyart</surname><given-names>Valentin</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>1R01MH115554-01</award-id><principal-award-recipient><name><surname>Drugowitsch</surname><given-names>Jan</given-names></name><name><surname>Wyart</surname><given-names>Valentin</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Task controllability manipulations reveal that information seeking is associated with reduced confidence and active hypothesis testing, as well as stronger neurophysiological correlates of attention and arousal.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The ability to form and revise uncertain beliefs through information sampling is a hallmark of human cognition. This inference process has been extensively studied using two main classes of decision tasks (<xref ref-type="bibr" rid="bib3">Bartolo and Averbeck, 2021</xref>; <xref ref-type="bibr" rid="bib60">Wyart and Koechlin, 2016</xref>). In passive sampling tasks, participants are observers who sample information over which they have no control (<xref ref-type="bibr" rid="bib37">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib52">van den Berg et al., 2016</xref>; <xref ref-type="bibr" rid="bib62">Zylberberg et al., 2018</xref>). This is the case in most perceptual decision tasks, in which the experimenter controls the sensory information provided to participants (for reviews, see <xref ref-type="bibr" rid="bib22">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib24">Hanks and Summerfield, 2017</xref>). Outside the laboratory, for example, one might see an ad for a new movie at a bus stop. By contrast, active sampling tasks let participants choose which source of information to sample from <xref ref-type="bibr" rid="bib6">Charpentier et al., 2018</xref>; <xref ref-type="bibr" rid="bib23">Gureckis and Markant, 2012</xref>; <xref ref-type="bibr" rid="bib33">Markant and Gureckis, 2014</xref>. In these situations, the information provided to participants corresponds to the outcome of their own choices. Using the same example, one can alternatively browse the web for information about new movies. Critically, unlike passive sampling, active sampling provides participants with control over which source of information to sample from, even if the information itself (about the new movie) can be exactly the same in both cases.</p><p>In both passive and active sampling tasks, recent work has assigned a key role for confidence in the formation and revision of uncertain beliefs (<xref ref-type="bibr" rid="bib35">Meyniel et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib46">Rouault et al., 2019</xref>; <xref ref-type="bibr" rid="bib47">Sarafyazd and Jazayeri, 2019</xref>). Low confidence in current beliefs has been shown to predict changes-of-mind (<xref ref-type="bibr" rid="bib2">Balsdon et al., 2020</xref>; <xref ref-type="bibr" rid="bib18">Folke et al., 2016</xref>) and allows for the flexible adaptation of behavioral strategies even when external feedback is unavailable (<xref ref-type="bibr" rid="bib11">Desender et al., 2018</xref>; <xref ref-type="bibr" rid="bib12">Desender et al., 2019</xref>; <xref ref-type="bibr" rid="bib17">Fleming et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Rollwage et al., 2020</xref>). But besides this pervasive role of confidence in belief updating, the control conferred by active sampling allows one to seek information about alternative strategies, a cognitive process that is by definition not possible in the absence of control over information sampling. Information seeking has been mostly studied using ‘exploration-exploitation’ dilemmas (<xref ref-type="bibr" rid="bib9">Costa et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Daw et al., 2006</xref>), where it is confounded with changes-of-mind about the reliability of the current behavioral strategy. In these paradigms, participants evolve in controllable environments and usually sample one among several options to maximize reward. Therefore, they have to either exploit a currently rewarding option or sacrifice rewards to explore alternative options and seek information about their possible rewards (<xref ref-type="bibr" rid="bib43">Rich and Gureckis, 2018</xref>; <xref ref-type="bibr" rid="bib58">Wilson et al., 2014</xref>). This trade-off means that in these paradigms exploration differs from exploitation not only in terms of information seeking, but also in terms of other co-occurring cognitive events, including overt response switches and covert changes-of-mind.</p><p>These different families of paradigms developed for studying information seeking vary on several dimensions, particularly the sources of uncertainty (<xref ref-type="bibr" rid="bib17">Fleming et al., 2018</xref>), stimuli used (<xref ref-type="bibr" rid="bib20">Gesiarz et al., 2019</xref>), desirability of the information to be sought (<xref ref-type="bibr" rid="bib26">Hertwig and Engel, 2021</xref>), and degree of control over information sampled (<xref ref-type="bibr" rid="bib11">Desender et al., 2018</xref>). These differences have made direct comparisons between paradigms extremely challenging. To date, no study has directly manipulated control over evidence sampling in otherwise aligned experimental conditions. At the neurophysiological level, exploration is known to be associated with larger pupil-linked arousal (<xref ref-type="bibr" rid="bib28">Jepma and Nieuwenhuis, 2011</xref>) and increased activity in lateral prefrontal regions in electroencephalographic (EEG) and blood oxygen-level dependent (BOLD) activity (<xref ref-type="bibr" rid="bib13">Donoso et al., 2014</xref>; <xref ref-type="bibr" rid="bib51">Tzovara et al., 2012</xref>). However, due to confounds between information seeking and other cognitive events during exploration in these studies, it remains unclear whether information seeking is associated with specific neurophysiological signatures.</p><p>Here, to isolate the specific signatures of information seeking, we contrasted changes-of-mind occurring with and without control over information sampling. We employed an adaptive decision-making task that allows comparing the formation and revision of uncertain beliefs between controllable and uncontrollable conditions (<xref ref-type="fig" rid="fig1">Figure 1</xref>). We previously used these experimental conditions to compare how participants integrate evidence when it is a cue (uncontrollable condition) vs. when it is an outcome (controllable condition) (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). Here, we focus on the comparison of repeat and switch decisions between these conditions so as to isolate the behavioral signatures and neural basis of information seeking, while replicating most of the previously observed effects in Weiss et al. on behavioral choices and their computational modeling (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). We found that participants need more evidence against their current beliefs to change their behavior in the controllable condition, and that they do so with decreased confidence. Nevertheless, participants are more likely to probe again their new behavioral strategy in the next decision, even in the absence of objective evidence supporting this new strategy – a form of active ‘hypothesis testing’ (<xref ref-type="bibr" rid="bib33">Markant and Gureckis, 2014</xref>). Using computational modeling (<xref ref-type="bibr" rid="bib21">Glaze et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>), we show that controllability increases the stability of participants’ beliefs, a mechanism that explains the observed behavioral correlates of information seeking. At the physiological level, changes-of-mind occurring in the controllable condition are preceded by stronger suppression of neuromagnetic alpha-band activity in the dorsal attention network, and followed by increased pupil-linked arousal during the presentation of decision outcomes. Taken together, these features suggest that information seeking increases the saliency of information that is perceived as the direct consequence of one’s own actions.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental paradigm probing changes-of-mind across two controllability conditions.</title><p>(<bold>A</bold>) Participants underwent two experimental conditions that varied only in the degree of control over stimuli. In the uncontrollable condition (C-, blue), observers were asked to monitor the category from which stimuli were drawn. In the controllable condition (C+, pink), agents were asked to select an action that will produce stimuli from either category. The evidence available for each choice, but also all stimuli and motor responses were tightly matched across conditions (see ‘Materials and methods’). (<bold>B</bold>) Task structure. The hidden state reversed unpredictably after a pseudo-random number of trials. In the C+ condition, the category drawn at trial <italic>t</italic> only depends on the hidden state <italic>s<sub>t</sub></italic>. In the C- condition, the category drawn at trial <italic>t</italic> depends on both the hidden state <italic>s<sub>t</sub></italic> and the previous response <italic>r<sub>t-1</sub></italic>, as indicated by pink arrows. (<bold>C</bold>) On each trial, participants were presented with sequences of 2–8 stimuli drawn from either category and were asked to indicate their choice and the associated confidence using four response keys. Confidence keys (low, high) were assigned to the inner and outer keys of each choice (left and right). A schematic sequence of events related to information seeking is depicted. Hidden-state reversals are determined by the experimental design (‘task event’). During an exploratory decision, several steps co-occur: a covert change-of-mind (‘cognitive event’) about the expected reward of the current option; an overt response switch (‘behavioral event’); and information seeking, i.e., an active search for information about the new option being considered, which is only possible in the C+ condition, where participants have control. (<bold>D</bold>) Stimuli were oriented bars drawn from either of two categories (orange and blue), whose means are orthogonal to each other. The generative probability distributions of drawn orientation for each category are depicted.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig1-v1.tif"/></fig></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experimental paradigm</title><p>To examine the cognitive signatures of information seeking in controllable environments, we asked human participants to perform an adaptive decision-making task consisting of two tightly matched conditions that only vary in the degree of control over information sampling bestowed to participants (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). Participants were presented with visual sequences of oriented stimuli drawn from either of two categories (blue or orange) associated with distinct but overlapping probability distributions over orientation (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; see ‘Materials and methods’). In-between each sequence, participants were asked to provide a response regarding the current hidden state of the task, together with a binary confidence estimate in their response (high or low confidence) using four response keys (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><p>In the uncontrollable (C-) condition, participants were asked to monitor the category from which stimuli were drawn and report this category at the end of each sequence. By contrast, in the controllable (C+) condition, the same participants were asked to draw stimuli from either of the two categories. In this C+ condition, the two response keys from one hand were associated with a draw of stimuli from the target category, whereas the other two response keys were associated with a draw from the other (nontarget) category (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). In the uncontrollable condition, the drawn category reversed unpredictably, requiring participants to adapt their responses to these changes (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). By contrast, in the controllable condition, it is the association between response keys and categories that reversed unpredictably, also requiring participants to adapt their responses to these changes. In both conditions, participants perform one action per trial. By design, the only difference between conditions is the degree of control bestowed to participants over the sampling of stimuli. Participants were observers monitoring the external source of stimuli in the C- (uncontrollable) condition, whereas participants were agents sampling stimuli through their actions in the C+ (controllable) condition (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). To experience the difference between experimental conditions, we provide a short gamified analog experiment at <ext-link ext-link-type="uri" xlink:href="https://infdm.scicog.fr/aodemo/runner.html">infdm.scicog.fr/aodemo/runner.html</ext-link>.</p></sec><sec id="s2-2"><title>Psychometric analyses of choice and confidence</title><p>By examining differences between conditions, we first established that participants adapted their behavior after a reversal to select the response corresponding to the new hidden state (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). We found that participants were slower to adapt after a reversal in the C+ condition, with psychometric fits indicating a higher reversal time constant in this controllable condition (<italic>t</italic><sub>32</sub> = 5.0, p=1.95 × 10<sup>–5</sup>; see ‘Materials and methods’). Participants also reached a higher asymptotic reversal rate in the C+ condition (<italic>t</italic><sub>32</sub> = 6.3, p=4.0 × 10<sup>–7</sup>; <xref ref-type="fig" rid="fig2">Figure 2B</xref>), replicating earlier findings (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Behavioral reversal and repetition curves characterizing participants’ responses and their confidence.</title><p>(<bold>A</bold>) Fraction of hidden state correctly reported as a function of trial number before and after a reversal. Vertical lines indicate the position of reversals. Horizontal dotted line indicates chance level. Circles and error bars indicate mean and SEM across participants (N = 33). Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting truncated exponential functions. (<bold>B</bold>) Psychometric parameters ‘reversal time constant’ and ‘asymptotic reversal rate’ characterizing the fitted response reversal curve in (<bold>A</bold>) (see ‘Materials and methods’). Circles indicate individual participants, and bars and error bars indicate the mean and SEM across participants. ***p&lt;0.001, paired <italic>t</italic>-tests. (<bold>C</bold>) Fraction of high-confidence responses as a function of trial number before and after a reversal. Horizontal dotted line indicates mean confidence. Circles and error bars indicate mean and SEM across participants (N = 33). Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting sigmoid functions. (<bold>D</bold>) Psychometric parameters ‘confidence time constant’ and ‘confidence drop’ for the fitted confidence reversal curve in (<bold>B</bold>). Circles indicate individual participants, and bars and error bars indicate the mean and SEM across participants. **p&lt;0.01, ~p=0.064 paired <italic>t</italic>-test and p&lt;0.008 Wilcoxon signed-rank test. (<bold>E</bold>) Fraction of response repetitions as a function of whether the evidence was consistent (in favor of repeating) or inconsistent with the previous choice. Circles indicate human data (N = 33), and error bars display SEM across participants. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting truncated exponential functions. (<bold>F</bold>) Psychometric parameters ‘point of subjective equivalence’ (choice-PSE) and ‘sensitivity to evidence’ (slope) characterizing the response repetition curves in (<bold>E</bold>). ***p&lt;0.001, n.s., not significant, paired <italic>t</italic>-tests. (<bold>G</bold>) Fraction of high-confidence responses as a function of whether the evidence was consistent or inconsistent with the previous choice. Circles indicate human data (N = 33), and error bars display within-participant SEM. Within-participant error bars are represented to allow a comparison between conditions without an influence of inter-individual variability about the use and calibration of the high- and low-confidence responses. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting mixture of two sigmoid functions for repeat and switch trials respectively. (<bold>H</bold>) Psychometric parameters characterizing the confidence repetition curves in (<bold>G</bold>). Left panel: ‘confidence-PSE’ (point of subjective equivalence) representing the quantity of evidence for which participants are as confident in their repeat decisions as in their switch decisions. **p&lt;0.01, Wilcoxon signed-rank test (see ‘Materials and methods’). Right panel: ‘sensitivity to evidence’ for the switch trials. ***p&lt;0.001, paired <italic>t</italic>-test. Circles indicate individual participants, and bars and error bars indicate the mean and SEM across participants. In all panels, uncontrollable (C-) condition is in blue and controllable (C+) condition in pink.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Psychometric analysis of choice and confidence reversal and repetition curves in retrospective (purple) and prospective (green) conditions (Experiment 3).</title><p>(<bold>A</bold>) Fraction of hidden state correctly reported as a function of trial number before and after a reversal. Vertical lines indicate the position of reversals. Horizontal dotted line indicates chance level. Circles and error bars indicate mean and SEM across participants (N = 25). Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting truncated exponential functions. (<bold>B</bold>) Psychometric parameters ‘reversal time constant’ and ‘asymptotic reversal rate’ characterizing the fitted response reversal curve in (<bold>A</bold>) (see ‘Materials and methods’). Circles indicate individual participants, and bars and error bars indicate the mean and SEM across participants. ~p=0.038, n.s., not significant, paired <italic>t</italic>-tests. (<bold>C</bold>) Fraction of high-confidence responses as a function of trial number before and after a reversal. Vertical lines indicate the position of reversals. Horizontal dotted lines indicate mean confidence. Circles indicate human data, and error bars display SEM across participants. Shaded areas indicate psychometric predictions from the best-fitting sigmoid functions. (<bold>D</bold>) Psychometric parameter for the confidence reversal curve in (<bold>C</bold>). Dots indicate individual participants. Because confidence drop is not different from zero in both conditions, confidence time constants are not reliably estimable and therefore are not presented. n.s., not significant, paired <italic>t</italic>-tests. (<bold>E</bold>) Fraction of response repetitions as a function of whether the evidence was consistent (in favor of repeating) or inconsistent with the previous choice. Circles indicate human data, and error bars display SEM across participants. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting truncated exponential functions. (<bold>F</bold>) Psychometric parameters ‘point of subjective equivalence’ (choice-PSE) and ‘sensitivity to evidence’ (slope) characterizing the response repetition curves in (<bold>E</bold>). n.s., not significant, paired <italic>t</italic>-tests. (<bold>G</bold>) Fraction of high-confidence responses as a function of whether the evidence was consistent or inconsistent with the previous choice. Circles indicate human data, and error bars display within-subject SEM. Within-subject error bars are presented to allow a comparison between conditions without an influence of inter-individual variability about the use and calibration of the high- and low-confidence responses. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting mixture of two sigmoid functions for repeat and switch trials, respectively (see ‘Materials and methods’). (<bold>H</bold>) Psychometric parameters characterizing the confidence repetition curves in (<bold>G</bold>). Left panel: ‘confidence-PSE’ (point of subjective equivalence) representing the quantity of evidence for which participants are as confident in their repeat decisions as in their switch decisions. **p&lt;0.01, Wilcoxon signed-rank test (see ‘Materials and methods’). Right panel: ‘sensitivity to evidence’ for the switch trials. Dots indicate individual participants, and bars and error bars indicate the mean and SEM across participants. Panels (<bold>A, B, E, F</bold>) were adapted from <xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Psychometric analysis of Experiment 2B.</title><p>(<bold>A</bold>) Fraction of hidden state correctly reported as a function of trial number before and after a reversal. Vertical line indicates the position of reversals. Horizontal line indicates chance level. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting truncated exponential functions. (<bold>B</bold>) Fraction of response repetitions as a function of whether the evidence was consistent (in favor of repeating) or inconsistent with the previous choice. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting sigmoid functions. (<bold>C</bold>) Fraction of high-confidence responses as a function of trial number before and after a reversal. Horizontal dotted lines indicate mean confidence. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting sigmoid functions. In (<bold>A</bold>–<bold>C</bold>), circles and error bars indicate mean and SEM across participants. (<bold>D</bold>) Fraction of high-confidence responses as a function of whether the evidence was consistent or inconsistent with the previous choice. Circles indicate human data, and error bars display within-subject SEM. Within-subject error bars allow a comparison between conditions without an influence of inter-individual variability about the use and calibration of high- and low-confidence responses. Shaded areas indicate mean and SEM of psychometric predictions from the best-fitting mixture of two sigmoid functions for repeat and switch trials, respectively. Bars and error bars indicate mean and SEM across participants, and dots indicate individual participants. Blue: uncontrollable (C-) condition; pink: controllable (C+) condition. In all panels, sample size is N = 18 participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Behavioral signatures of choice and confidence validate the computational model.</title><p>Simulations from the best-fitting parameters (shaded areas) in uncontrollable (C-, blue) and controllable (C+, pink) conditions. Same conventions as <xref ref-type="fig" rid="fig2">Figure 2</xref>. (<bold>A</bold>) Fraction of hidden state correctly reported as a function of trial number before and after a reversal. (<bold>B</bold>) Psychometric parameters ‘reversal time constant’ (***p=9.5 × 10<sup>–7</sup>, <italic>t</italic><sub>32</sub> = −6.0) and ‘asymptotic reversal rate’ (***p=2.0 × 10<sup>–7</sup>, <italic>t</italic><sub>32</sub> = −6.6) characterizing the fitted response reversal curve in (<bold>A</bold>) (paired <italic>t</italic>-tests). (<bold>C</bold>) Fraction of high-confidence responses as a function of trial number before and after a reversal. (<bold>D</bold>) Psychometric parameters ‘confidence time constant’ and ‘confidence drop’ for the fitted confidence reversal curve in (<bold>B</bold>). n.s., not significant, p=0.62, <italic>t</italic><sub>32</sub> = 0.50; ***p=1.0 × 10<sup>–5</sup>, <italic>t</italic><sub>32</sub> = −5.22; paired <italic>t</italic>-tests. (<bold>E</bold>) Fraction of response repetitions as a function of whether the evidence was consistent or inconsistent with the previous choice. (<bold>F</bold>) Psychometric parameters ‘point of subjective equivalence’ (choice-PSE) and ‘sensitivity to evidence’ (slope) characterizing the response repetition curves in (<bold>E</bold>). ***p=1.7 × 10<sup>–9</sup>, <italic>t</italic><sub>32</sub> = −8.3; n.s., not significant, p=0.43, <italic>t</italic><sub>32</sub> = 0.79; paired <italic>t</italic>-tests. (<bold>G</bold>) Fraction of high-confidence responses as a function of whether the evidence was consistent or inconsistent with the previous choice. (<bold>H</bold>) Psychometric parameters characterizing the confidence repetition curves in (<bold>G</bold>). Left panel: ‘confidence-PSE’ (point of subjective equivalence) representing the quantity of evidence for which participants are as confident in their repeat decisions as in their switch decisions. ***p=0.00033, <italic>z</italic> = −3.69, Wilcoxon signed-rank test. Right panel: ‘sensitivity to evidence’ for the switch trials. <italic>t</italic><sub>32</sub> = 1.86, p=0.07, paired <italic>t</italic>-test. In all panels, sample size is N = 33. In panels (<bold>B, D, F, H</bold>), bars and error bars are mean and SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig2-figsupp3-v1.tif"/></fig></fig-group><p>As expected, participants’ confidence decreased after a reversal in both conditions (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). However, confidence decreased more sharply in the C+ (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), an observation confirmed by psychometric fits of a confidence ‘drop’ parameter (<italic>t</italic><sub>32</sub> = 3.59, p=0.0011; see ’Methods’). In addition, the confidence time constant characterizing the slope of confidence increase after a reversal was slightly higher in the C+ condition (paired <italic>t</italic>-test, <italic>t</italic><sub>32</sub> = −1.9, p=0.064; Wilcoxon signed-rank test, <italic>z</italic> = −2.65, p=0.008) (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Together, these findings indicate that participants adapted their behavior more slowly and their confidence dropped more strongly in the C+, controllable condition (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><p>We then established that participants switched their category choice more often in the C- (32% of trials) than in the C+ (22% of trials) condition (<italic>t</italic><sub>32</sub> = 8.64, p=7.2 × 10<sup>–10</sup>). Participants’ choice accuracy was slightly higher in the C+ (81.9% correct) than in the C- (78.4% correct) condition (<italic>t</italic><sub>32</sub> = −4.9, p=2.6 × 10<sup>–5</sup>). Moreover, response times (RTs) on repeat decisions were similar between C- (mean = 693.2 ms, SEM = 55.4 ms, median = 608.9 ms) and C+ (mean = 677.5 ms, SEM = 45.2 ms, median = 626.7 ms) conditions (<italic>t</italic><sub>32</sub> = −1.52, p=0.14, BF<sub>10</sub> = 0.531). This was also true in earlier work using the same conditions (see Experiment 4 described below, <italic>t</italic><sub>23</sub> = 0.50, p=0.62, BF<sub>10</sub> = 0.241) (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). These initial results indicate that the differences between conditions are unlikely to be generated by working memory or executive demand differences.</p><p>To better understand the origin of the differences between conditions, we reanalyzed participants’ choices and confidence as a function of the objective evidence available in favor of repeating their previous choice (‘consistent evidence’) vs. switching away from their previous choice (‘inconsistent evidence’; <xref ref-type="fig" rid="fig2">Figure 2E–H</xref>). In both conditions, we found that the stronger the consistent evidence, the more often participants repeated their previous choice (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). Crucially, psychometric fits revealed a difference in the point of subjective equivalence (choice-PSE) between conditions (<italic>t</italic><sub>32</sub> = −7.83, p=6.2 × 10<sup>–9</sup>; <xref ref-type="fig" rid="fig2">Figure 2F</xref>). The choice-PSE parameter reflects the amount of evidence required for a participant to switch away from their previous choice more often than repeat it. This difference means that participants needed more evidence against their previous decision for switching in the C+ condition. In contrast, participants’ sensitivity to the available objective evidence was not significantly different across conditions (<italic>t</italic><sub>32</sub> = 1.09, p=0.28, BF<sub>10</sub> = 0.323; <xref ref-type="fig" rid="fig2">Figure 2F</xref>).</p><p>We analyzed confidence reports using the same procedure. As expected, confidence increased with the strength of consistent evidence in both conditions (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). By contrast, participants were considerably less confident in their choices following inconsistent evidence in the C+ condition (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). To quantify these effects, we fitted two sigmoid functions to switch and repeat choices separately, each sigmoid being characterized by an offset and a slope (see ‘Materials and methods’). Based on these fits, we estimated the quantity of evidence for which confidence is equal for repeat and switch decisions (confidence-PSE, <xref ref-type="fig" rid="fig2">Figure 2G</xref>). We found a significant confidence-PSE difference between conditions (Wilcoxon signed-rank test, <italic>z =</italic> −2.89, p=0.0038; <xref ref-type="fig" rid="fig2">Figure 2H</xref>), indicating that participants needed more inconsistent evidence to be equally confident in switch and repeat decisions in the C+ condition. We also found that the sensitivity of confidence reports to evidence (slope) was smaller in the C+ than in the C- condition on switch decisions (<italic>t</italic><sub>32</sub> = 5.1, p=1.6 × 10<sup>–5</sup>; <xref ref-type="fig" rid="fig2">Figure 2H</xref>).</p></sec><sec id="s2-3"><title>Ruling out alternative accounts of differences between conditions</title><p>Although the degree of control over evidence sampling is the key difference between conditions, we sought to examine two alternative interpretations. First, we examined whether the temporal direction of inference could explain the observed differences between conditions: prospective in the C+ condition and retrospective in the C- condition (see ‘Materials and methods’). Participants were now asked to guess which category the computer <italic>drew</italic> from when they saw the sequence of stimuli (retrospective condition) or guess which category the computer <italic>will draw</italic> from based on what they saw (prospective condition). Neither condition conferred any control to participants. Psychometric analyses of behavior indicate no difference in reversal time constant between retrospective and prospective conditions (<italic>t</italic><sub>24</sub> = −0.016, p=0.98, BF<sub>10</sub> = 0.21) and a small difference in asymptotic reversal rate (<italic>t</italic><sub>24</sub> = 2.2, p=0.038, BF<sub>10</sub> = 1.59). Importantly, there was no difference in choice-PSE (<italic>t</italic><sub>24</sub> = −1.67, p=0.11, BF<sub>10</sub> = 0.70) or sensitivity to evidence (<italic>t</italic><sub>24</sub> = 1.2, p=0.25, BF<sub>10</sub> = 0.39) between retrospective and prospective conditions (see <xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref> for a detailed analysis). As expected, participants’ confidence decreased after a reversal, but its dynamics were similar across conditions (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1E</xref>). This was revealed in the similar values of the confidence drop parameter across conditions (<italic>t</italic><sub>24</sub> = 0.89, p=0.38, BF<sub>10</sub> = 0.30) (because confidence drop is not different from zero in both conditions, confidence time constant is not reliably determinable, and therefore are not presented) (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1F</xref>). Furthermore, we found a difference in confidence-PSE (<italic>t</italic><sub>24</sub> = −3.1, p=0.0049), but in contrast to the original conditions of Experiments 1 and 2A, we observed no difference in the sensitivity to evidence parameter on switch decisions (<italic>t</italic><sub>24</sub> = 0.95, p=0.35, BF<sub>10</sub> = 0.32; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1H</xref>). These results provide evidence that the differences between the original C- and C+ conditions are not due to a retrospective or prospective temporal orientation, but instead indicate differences due to the degree of control over decision evidence.</p><p>Second, we examined whether the maintenance of a constant (fixed) category goal across trials was critical for participants to experience a different degree of control between conditions (Experiment 2B). We created a condition in which the instructions (which category to draw from in the C+ condition, which category/action mapping to use in the C- condition) changed on a trial basis, instead of on a block basis (see ‘Methods’). We found that confidence in trials with inconsistent evidence was less different between conditions (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>), and the confidence increase after a reversal was similar across conditions (paired <italic>t</italic>-test, <italic>t</italic><sub>17</sub> = −1.01, p=0.33; Wilcoxon signed-rank test, <italic>z</italic> = −1.02, p=0.31, BF<sub>10</sub> = 0.380), in line with Experiments 1 and 2B. Moreover, a difference in choice-PSE between conditions (<italic>t</italic><sub>17</sub> = −6.4, p=6.4 × 10<sup>–6</sup>) revealed that participants needed more evidence to change their mind in the C+ condition, again in line with Experiments 1 and 2A (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Importantly, even if Experiment 2B effectively changes the number of tasks that need to be performed, we observed a similar choice-PSE between Experiments 2A and 2B (C-: <italic>t</italic><sub>17</sub> = 0.77, p=0.45, BF<sub>10</sub> = 0.315; C+: <italic>t</italic><sub>17</sub> = 0.73, p=0.47, BF<sub>10</sub> = 0.308), and the difference in choice-PSE between the C- and C+ conditions did not differ between Experiments 2A and 2B (<italic>t</italic><sub>17</sub> = 0.49, p=0.63, BF<sub>10</sub> = 0.271).</p></sec><sec id="s2-4"><title>Separable effects of confidence and controllability on changes-of-mind</title><p>We have seen that participants changed their mind less often in the C+ condition. Following a switch decision, we found that participants were generally less confident when they switched than when they repeated their previous response (main effect of <sc>response type</sc>, F<sub>1,32</sub> = 55.8, p=1.7 × 10<sup>–8</sup>), and were also less confident in the C+ compared to the C- condition (main effect of <sc>condition</sc>, F<sub>1,32</sub> = 17.9, p=0.00018; <xref ref-type="fig" rid="fig3">Figure 3A</xref>). We further identified a significant interaction between <sc>response type</sc> and <sc>condition</sc> (F<sub>1,32</sub> = 18.9, p=0.00014), indicating a more pronounced decrease in confidence on switch decisions in the C+ compared to the C- condition. A logistic regression confirmed these results (see ‘Materials and methods’). Repeat trials led to higher confidence than switch decisions (<italic>t</italic><sub>32</sub> = 7.66, p=9.8 × 10<sup>–9</sup>), confidence was higher in the C- than in the C+ condition (<italic>t</italic><sub>32</sub> = 4.05, p=0.00029), with a significant interaction between <sc>response type</sc> and <sc>condition</sc> (<italic>t</italic><sub>32</sub> = −4.43, p=0.0001), while controlling for evidence level in the same regression model, which positively contributed to confidence, as expected (<italic>t</italic><sub>32</sub> = 14.69, p=8.8 × 10<sup>–16</sup>) (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>A possible role for confidence in changes-of-mind.</title><p>(<bold>A</bold>) Fraction of high-confidence responses as a function of whether participants repeated their previous choice (‘repeat’) or changed their mind (‘switch’) in the uncontrollable (C-, blue) and controllable (C+, pink) conditions. (<bold>B</bold>) Fraction of high-confidence responses following switch decisions that were confirmed or aborted, i.e., when participants return back to their previous response in the two conditions. Bars and error bars indicate mean and SEM across participants, and gray lines display individual data points (N = 33). (<bold>C</bold>) Fraction of switch decisions confirmed on the next trial (see ‘Materials and methods’) as a function of whether the change-of-mind was performed with high or low confidence, for each condition. Bars and error bars indicate mean and SEM across participants (N = 28, due to some participants not exhibiting all types of responses [see ‘Materials and methods’]; note that jackknifed statistics with all 33 participants provided virtually identical results). In all panels, statistical significance from an ANOVA is indicated for the interaction (cross) between <sc>response type</sc> (repeat, switch) and <sc>condition</sc> (C-, C+). ***p&lt;0.001, **p&lt;0.005, n.s., nonsignificant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Isolating the interaction between controllability and changes-of-mind on confidence.</title><p>(<bold>A</bold>) Logistic regression predicting confidence as a function of response type (Resp.) (repeat, switch), condition (Cond.) (C-, C+), their interaction (Int.), and the strength of evidence in favor of repeating the previous response (Evid.). (<bold>B</bold>) Logistic regression predicting confidence as a function of whether the change-of-mind of the previous response was confirmed or aborted (Co/Ab), condition (Cond.) (C-, C+), their interaction (Int.), and the strength of evidence in favor of repeating the previous response (Evid.). (<bold>C</bold>) Mean evidence level as a function of whether participants repeated their previous choice (‘repeat’) or changed their mind (‘switch’) in the uncontrollable (C-, blue) and controllable (C+, pink) conditions. (<bold>D</bold>) Mean evidence levels following switch decisions that were confirmed or aborted, i.e., when participants return back to their previous response in the two conditions. Note that individual variability is higher on the right panel because there are less events per participant in each of the cases. Bars and error bars indicate mean and SEM across participants, and gray lines display individual data points (N = 33).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig3-figsupp1-v1.tif"/></fig></fig-group><p>After changing their mind, participants could either confirm their category choice on the next trial (‘confirmed’ switch) or return back to the category selected before the switch occurred (‘aborted’ switch). We found that after a switch decision participants were less willing to go back to their previous response in the C+ condition, with 72.7% of switches being confirmed, but only 58.9% in the C- condition (<italic>t</italic><sub>32</sub> = −8.19, p=2.4 × 10<sup>–9</sup>). This was in the context of a different baseline switch rate differs across conditions, with participants switching choice more often in the C- (32% of trials) than in the C+ (22% of trials) condition. This is consistent with a stronger stickiness tendency observed in the C+ condition, suggesting a reluctance to switch back and forth when participants were in control, and instead a willingness to test again their new category choice. Moreover, participants were more confident on trials in which switch decisions were confirmed compared to aborted (F<sub>1,32</sub> = 10.3, p=0.0030), and more confident in the C- than in the C+ condition (F<sub>1,32</sub> = 20.6, p=0.0001), with an interaction between these factors (F<sub>1,32</sub> = 10.7, p=0.0026), due to participants’ confidence decreasing on aborted switches as compared to confirmed switches in the C+ condition (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). When they are not in control, participants may be more flexible and switch back and forth more easily, as indicated by a similar level of confidence for switches confirmed and aborted in the C- condition. A logistic regression confirmed these results (see ‘Materials and methods’), with participants overall being more confident when they confirm than when they abort a change-of-mind (<italic>t</italic><sub>32</sub> = 5.49, p=4.6 × 10<sup>–6</sup>), also more confident in the C- than in the C+ condition (<italic>t</italic><sub>32</sub> = 3.92, p=0.0004), with a significant interaction between these factors (<italic>t</italic><sub>32</sub> = −3.38, p=0.0019), while controlling for evidence level (<italic>t</italic><sub>32</sub> = 11.9, p=2.49 × 10<sup>–13</sup>) (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). Moreover, while these results indicate that evidence partly contributes to confidence, as expected, the patterns of evidence strength were markedly different from those of changes-of-mind (compare <xref ref-type="fig" rid="fig3">Figure 3A and B</xref> to <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C and D</xref>).</p><p>Finally, we examined whether switch decisions performed with high (resp. low) confidence more often led to choices being confirmed (resp. aborted) in each condition (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). We found a main effect of <sc>confidence</sc> on the fraction of switches confirmed (F<sub>1,27</sub> = 30.4, p=7.8 × 10<sup>–6</sup>), meaning that participants confirmed their switch more often when it was made with high confidence. This suggests a causal role for confidence in controlling changes-of-mind, even though we acknowledge that there was no experimentally causal manipulation of confidence here. Switch decisions were more often confirmed in the C+ condition (F<sub>1,27</sub> = 47.8, p=1.98 × 10<sup>–7</sup>), consistent with a higher flexibility of responses in the C- condition, without an interaction between <sc>confidence</sc> and <sc>condition</sc> (F<sub>1,27</sub> = 0.093, p=0.76). Together these findings reveal that participants (1) changed their mind less often in the C+ condition, (2) did so with reduced confidence, and (3) were afterward more willing to confirm a change-of-mind than returning to their previous response compared to the C- condition.</p></sec><sec id="s2-5"><title>Computational model with inference noise and metacognitive noise</title><p>To further characterize the mechanisms underpinning choice and confidence differences between conditions, we developed a normative Bayesian model (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). In line with previous work on a closely related task, we endowed it with noisy inference (<xref ref-type="bibr" rid="bib14">Drugowitsch et al., 2016</xref>; see ‘Materials and methods’). We observed a similar amount of inference noise between conditions (<italic>t</italic><sub>32</sub> = 1.45, p=0.16), indicating that evidence was integrated equally well across conditions, in line with psychometric results (<xref ref-type="fig" rid="fig2">Figure 2</xref>). We found a lower perceived hazard rate in the C+ relative to the C- condition (<italic>t</italic><sub>32</sub> = 7.46, p=1.7 × 10<sup>–8</sup>), indicating that participants perceived the environment as less volatile when being in control (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Bayesian normative model describing choices and confidence.</title><p>(<bold>A</bold>) Model schematic of computations. The model updates a belief about category from the evidence acquired through the sequence of stimuli, additionally corrupted by inference noise that scales with sequence length, and with a hazard rate controlling reversal occurrence. Based on the strength of the belief about category, responses above (resp. below) a confidence threshold are given with high (resp. low) confidence, with choices and confidence therefore being based on the same posterior belief. An imperfect readout of the posterior belief is modeled by metacognitive noise, and a confidence gain parameter selectively applied of switch trials (see ‘Materials and methods’). (<bold>B</bold>) Best-fitting model parameters: inference noise, hazard rate, confidence threshold, metacognitive noise, and confidence gain in the uncontrollable (C-, blue) and controllable (C+, pink) conditions. Circles and error bars indicate mean and SEM across participants (N = 33), and gray lines display individual parameter values. ***p&lt;0.00001, n.s., nonsignificant, paired <italic>t</italic>-tests.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Parameter recovery analysis.</title><p>Pairwise correlations between generative and recovered inference noise, hazard rate, confidence threshold, metacognitive noise, and confidence gain parameters, in both conditions (blue: uncontrollable [C-]; pink: controllable [C+]). We simulated choice and confidence sequences using generative parameters randomly sampled in a uniform distribution between the minimum and maximum of participants’ best-fitting parameter values in each condition. This procedure ensures that generative parameters were independently sampled. We then fitted these data using the same fitting procedure as for participants (see ‘Materials and methods’). The diagonal line corresponds to a very satisfactory recovery with strong correlations between generative and fitted parameters. Bottom-right panel: confusion matrix for the five parameters indicating a satisfactory recovery.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Correlation between model parameters.</title><p>Individual best-fitting parameters are averaged across conditions. (1) inference noise; (2) hazard rate; (3) confidence threshold; (4) metacognitive noise; (5) confidence gain. ***p=0.0025, *p=0.041 indicates the significant correlations (N = 33 participants). All other correlations were not significant (all abs(ρ) &lt; 0.32, all p&gt;0.074).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Effect of inference noise and hazard rate parameters on choice and confidence patterns.</title><p>(<bold>A, B</bold>) Effect of inference noise (<bold>A</bold>) and perceived hazard rate (<bold>B</bold>) parameters on choice and confidence patterns. Reversal and repetition curves for responses and confidence, with human data (circles) and simulations from the best-fitting computational model (shaded area) in uncontrollable (C-, blue) and controllable (C+, pink) conditions. Circles and error bars represent mean and SEM across participants (N = 16 per group, median split of best-fitting inference noise and hazard rate, respectively). Lighter colors indicate lower parameter values in all panels. Same conventions as <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Effect of confidence threshold, metacognitive noise, and confidence gain parameters on confidence patterns.</title><p>(<bold>A–C</bold>) Effect of confidence threshold (<bold>A</bold>), metacognitive noise (<bold>B</bold>), and confidence gain (<bold>C</bold>) parameters on confidence patterns. Reversal and repetition curves for confidence, with human data (circles) and simulations from the best-fitting computational model (shaded area) in uncontrollable (C-, blue) and controllable (C+, pink) conditions. Bars and error bars represent mean and SEM across participants (N = 16 per group, median split of best-fitting confidence threshold, metacognitive noise, and confidence gain, respectively). Note that choice curves are not shown because the three confidence parameters have no effect on choices, by definition. Lighter colors indicate lower parameter values in all panels. Same conventions as <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig4-figsupp4-v1.tif"/></fig></fig-group><p>To capture the patterns of confidence responses, we further introduced three additional parameters: confidence threshold, metacognitive noise, and confidence gain associated with switch trials, all capturing unique aspects of confidence response patterns (see ‘Materials and methods’ and <xref ref-type="fig" rid="fig4">Figure 4A</xref>). In line with model-free analyses indicating a difference in the fraction of high-confidence responses between conditions, we found a lower confidence threshold in the C- condition, which corresponds to more high-confident responses, compared to the C+ condition (<italic>t</italic><sub>32</sub> = −4.3, p=1.3 × 10<sup>–4</sup>), together with no difference in metacognitive noise (<italic>t</italic><sub>32</sub> = −0.29, p=0.76), or confidence gain for switch trials (<italic>t</italic><sub>32</sub> = 0.10, p=0.92; <xref ref-type="fig" rid="fig4">Figure 4B</xref>). Using best-fitting parameters fitted to individual participants, we validated our model by simulating choice and confidence responses, and analyzed the simulated data in the same way as human data (<xref ref-type="bibr" rid="bib40">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Wilson and Collins, 2019</xref>). We show that simulations provided an accurate fit to participants’ choice and confidence responses (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Importantly, we also established that our fitting procedure provided a satisfactory parameter recovery (see ‘Materials and methods’). All correlations between generative and recovered parameters were high (all ρ&gt;0.78, all p&lt;10<sup>–14</sup>), while other correlations were low as indicated in a confusion matrix (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Finally, we found no meaningful order effects as to which condition was shown first. Mean accuracy and mean confidence were similar across order groups (independent <italic>t</italic>-tests, all <italic>t</italic><sub>31</sub> &lt; −1.2, all p&gt;0.23). Likewise, there were no order effects for any of the best-fitting parameters (for all comparisons between conditions, all <italic>t</italic><sub>31</sub> &lt; 1.85, all p&gt;0.074).</p><p>We further validated the independent role of each parameter in two ways. First, we examined correlations between best-fitting parameters across participants (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We found a significant negative correlation between inference noise and hazard rate (ρ = −0.51, p=0.0025), in line with a previously reported trade-off between these two sources of variability (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). We also found a borderline correlation between confidence threshold and hazard rate (ρ = −0.36, p=0.0409). However, all other correlations were not significant (all ρ &lt; 0.31, all p&gt;0.074), indicating that each parameter captured independent portions of the variance (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Second, we did a median split of participants into groups of high and low parameter values (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref> and <xref ref-type="fig" rid="fig4s4">4</xref>), each parameter having a selective influence on choices and confidence. Even when parameters were similar across conditions (e.g., confidence gain), there was still a substantial inter-individual variability that had a visible effect on participants’ confidence, indicating the necessity of each parameter in capturing qualitative signatures participants’ choices and confidence.</p><p>We next examined whether our computational model could not only predict choice and confidence (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>), but also predict effects on the next decision. We refitted the psychometric choice-PSE (<xref ref-type="fig" rid="fig2">Figure 2F</xref>) separately for subsamples of trials for both human data and simulated choice data from the best-fitting parameters (see ‘Materials and methods’). For human choices in the C- condition, we found a higher PSE following a repeat compared to a switch trial, indicating that more evidence was required to switch away from the current best option (<italic>t</italic><sub>32</sub> = 3.2, p=0.0033), whereas in the C+ condition, PSEs were similar after repeat and switch trials (<italic>t</italic><sub>32</sub> = 0.08, p=0.93; <xref ref-type="fig" rid="fig5">Figure 5A</xref>, bars). In the C- condition, the PSE pattern predicted by the model matched human choices (<italic>t</italic><sub>32</sub> = 5.4, p=7.0 × 10<sup>–6</sup>), with a smaller PSE after a switch than after a repeat trial (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, squares). By contrast, in the C+ condition, the PSE pattern predicted by the model showed the same difference between repeat and switch trials (<italic>t</italic><sub>32</sub> = 8.9, p=3.3 × 10<sup>–10</sup>), unlike what was observed for human choices (interaction between <sc>data type</sc> [human, model] and <sc>response type</sc> [after a repeat, after a switch]; F<sub>1,32</sub>=16.94, p=0.000025; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). This deviation from model predictions indicates that participants required more evidence to switch back following a change-of-mind in the controllable C+ condition.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Bayesian normative model describing choices and confidence.</title><p>(<bold>A</bold>) Psychometric parameter choice-PSE (point of subjective equivalence) fitted separately on trials following a repeat vs. a switch in the uncontrollable (C-, blue) and controllable (C+, pink) conditions. Statistical significance from an ANOVA is indicated for the interaction (cross) between <sc>response type</sc> (after a repeat, after a switch) and <sc>data type</sc> (human, model). *p=0.027, ***p=0.000025, n.s., nonsignificant. (<bold>B</bold>) Psychometric parameter choice-PSE fitted separately on trials following a high-confidence vs. a low-confidence response in each condition. Small circles indicate individual data points (N = 33), bars and error bars indicate mean and SEM for human data. White squares and error bars indicate mean and SEM for model simulations of different participant sessions. Statistical significance from an ANOVA is indicated for the interaction (cross) between <sc>response type</sc> (after high confidence, after low confidence) and <sc>data type</sc> (human, model). n.s., nonsignificant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig5-v1.tif"/></fig><p>We further investigated whether confidence had a role in this deviation. We again fitted choice-PSEs separately for trials following a high- or a low-confidence response in each condition (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). As expected, PSEs were lower following a low-confidence response, indicating that participants are more willing to change their minds after a low-confident response. Importantly, and unlike what was observed when comparing responses following repeat and switch trials, we observed a similar qualitative pattern for human and model choices (<xref ref-type="fig" rid="fig5">Figure 5</xref>). This indicates that the difference in PSE following switches in the C+ condition cannot be due to the model having miscalibrated confidence because the differences in PSE observed for human choices across confidence levels and between conditions were adequately captured (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>).</p></sec><sec id="s2-6"><title>Neuromagnetic signatures of information seeking during changes-of-mind</title><p>We examined whether the aforementioned features of switch decisions in the C+ condition were related to changes in cortical, subcortical, and peripheral systems. First, we analyzed fluctuations in spectral power of brain signals recorded in MEG in the alpha band (Experiment 4), a frequency range known to be associated with changes in attentional and arousal systems (<xref ref-type="bibr" rid="bib8">Corbetta and Shulman, 2002</xref>).</p><p>We computed a ‘repeat minus switch’ contrast in the alpha-band power at [⎼4, + 4] s around the response probe onset in all channels. Then, we clustered the channels according to the strength of pairwise correlations of time courses of this contrast across channels (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). This analysis identified two main spatial clusters of channels: an occipital cluster and a frontal cluster. Inspecting time courses of the ‘repeat minus switch’ contrast (hereafter, ‘switch effect’; <xref ref-type="fig" rid="fig6">Figure 6B</xref>) revealed that the switch effect occurred earlier in the occipital cluster (time from trial onset, occipital: 1.450 ± 0.229 s, frontal: 2.099 ± 0.243 s, jackknifed mean ± SEM; jackknifed <italic>t</italic><sub>23</sub> = 3.1, p=0.005) and peaked before the response probe onset (time from probe onset, occipital: –0.393 ± 0.028 s; jackknifed <italic>t</italic><sub>23</sub> = −14.2, p&lt;0.001). In contrast, the switch effect started later and peaked after the probe onset (+0.958 ± 0.032 s; jackknifed <italic>t</italic><sub>23</sub> = 29.6, p&lt;0.001) in the frontal cluster (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). The two clusters were therefore defined by two distinct time windows. The occipital switch effect was larger than the frontal effect before the response probe onset (during the sequence, peak <italic>t</italic><sub>23</sub> = 6.0, cluster-level p&lt;0.001), whereas the frontal effect was larger than the occipital effect after the probe onset (during and after the response, peak <italic>t</italic><sub>23</sub> = 7.5, cluster-level p&lt;0.001; <xref ref-type="fig" rid="fig6">Figure 6C</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Alpha-band magnetoencephalography (MEG) as a window onto the neural basis of changes-of-mind (Experiment 4).</title><p>(<bold>A</bold>) Pairwise correlation matrix of time courses of alpha-band contrast between repeat and switch trials across all MEG channels, grouped into two main clusters, labeled as occipital and frontal based on their localization. (<bold>B</bold>) Average time course of alpha-band contrast between repeat and switch trials for the occipital (dark gray) and frontal (light gray) clusters, time-locked at trial onset (left panels) or response probe onset (right panels). Shaded areas indicate time windows (1: before probe onset, 2: after probe onset) in which time courses in the two clusters significantly differ. (<bold>C</bold>) Left panel: onset latency of the contrast between repeat and switch trials, locked to trial onset. Right panel: peak latency of the contrast between repeat and switch trials, time-locked to response probe onset. Bars and error bars indicate jackknifed means and SEM. (<bold>D, G</bold>) Spatial topography of the contrast between repeat and switch trials in the time window (1) before probe onset (<bold>D</bold>) and in the time window (2) after probe onset (<bold>G</bold>), in the uncontrollable (left) and controllable conditions (right). (<bold>E, H</bold>) Contrast of repeat minus switch trials in the C- (blue) and C+ (pink) conditions time-locked at the trial onset (left panels) or response probe onset (right panels). Horizontal lines indicate statistical significance at p&lt;0.05 corrected. Vertical lines indicate trial events: probe onset, samples of the sequence, and the response probe onset. The black arrow indicates the average response time across conditions and participants. (<bold>F, I</bold>) Left panels: stars indicate significance from post hoc tests from an ANOVA with <sc>condition</sc> (C-, C+) and <sc>response type</sc> (repeat, switch) as within-participant factors on the time window statistically significant after correction identified in (<bold>E</bold>) and (<bold>H</bold>), respectively. Bars and error bars indicate mean and SEM. Right panels: stars indicate significance for paired <italic>t</italic>-tests of the contrast between repeat and switch trials in each condition separately. Circle and error bar indicate mean and SEM. *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001. N = 24 participants. See also <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> for raw effects in occipital and frontal clusters.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Raw time courses of magnetoencephalography (MEG), pupil, and interbeat interval (IBI) data.</title><p>(<bold>A</bold>) Raw time course of alpha-band power on repeat (left panels) and switch (right panels) trials in MEG for the occipital cluster. (<bold>B</bold>) Raw time course of alpha-band power on repeat (left panels) and switch (right panels) trials in alpha-band for the frontal cluster. (<bold>C</bold>) Raw time course of pupil dilation on repeat (left panels) and switch (right panels) trials. (<bold>D</bold>) Raw time course of cardiac IBI on repeat (left panels) and switch (right panels) trials. In all panels, physiological responses were time-locked at the trial onset or the response probe onset. Vertical lines indicate trial events: trial onset, samples of the sequence, and response probe onset. Black arrows indicate the average response time across conditions and participants. Blue, uncontrollable (C-) condition; pink, controllable (C+) condition. N = 24 participants from Experiment 4 for panels (<bold>A, B, D</bold>). N = 32 participants pooled across Experiments 1 and 2A for panel (<bold>C</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Motor response preparation effects in alpha-band magnetoencephalography (MEG) (Experiment 4).</title><p>(<bold>A</bold>) Spatial topography of response hand selectivity at response onset, measured in units of signal-to-noise ratio. Large dots indicate the left and right channels used to compute a lateralization effect over time surrounding response probe onset. (<bold>B</bold>) Contrast of switch minus repeat trials time-locked at the trial onset (left part) or the response probe onset (right part). Vertical lines indicate trial events: probe onset, samples of the sequence, and response probe onset. The black arrow indicates the average response time across conditions and participants (N = 24). Blue, uncontrollable condition (C-); pink, controllable condition (C+).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig6-figsupp2-v1.tif"/></fig><fig id="fig6s3" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 3.</label><caption><title>Physiological analyses controlling for sequence length.</title><p>Contrast between repeat and switch trials for alpha-band power in the occipital cluster (<bold>A</bold>) and frontal cluster (<bold>B</bold>) for pupil dilation (<bold>C</bold>) and cardiac interbeat interval (<bold>D</bold>) separately for short (2–4 samples) and long (6–8 samples) trial sequences. In all panels, physiological responses were time-locked to trial onset (left panels) or response probe onset (right panels). Lines represent averages and shaded areas SEM across participants. Vertical lines indicate trial events: probe onset, samples of the sequence, and the response probe onset. Black arrows indicate average response time across conditions and participants. Blue: uncontrollable (C-) condition; pink: controllable (C+) condition. N = 24 participants from Experiment 4 for panels (<bold>A, B, D</bold>). N = 32 participants pooled across Experiments 1 and 2A for panel (<bold>C</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig6-figsupp3-v1.tif"/></fig></fig-group><p>In the occipital cluster (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), the switch effect was larger in the C+ than the C- condition (peak <italic>t</italic><sub>23</sub> = 6.2, cluster-level p&lt;0.001), with the largest difference just before probe onset (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, see also <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A and B</xref> for the raw effects). We found no significant difference between conditions on repeat trials (<italic>t</italic><sub>23</sub> = 0.6, p=0.528) but a significant one on switch trials (<italic>t</italic><sub>23</sub> = 3.9, p&lt;0.001) (<xref ref-type="fig" rid="fig6">Figure 6F</xref>) (interaction: F<sub>1,23</sub> = 40.7, p&lt;0.001; <xref ref-type="fig" rid="fig6">Figure 6E</xref>). The frontal cluster (<xref ref-type="fig" rid="fig6">Figure 6G</xref>) featured a larger (and longer) switch effect in the C+ than the C- condition (peak <italic>t</italic><sub>23</sub> = 4.4, cluster-level p&lt;0.001), with the largest difference just after probe onset (<xref ref-type="fig" rid="fig6">Figure 6H</xref>, see also <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C and D</xref> for the raw effects). As for the occipital cluster, we found no significant difference between conditions on repeat trials (<italic>t</italic><sub>23</sub> = 1.1, p=0.27), but a significant one on switch trials (<italic>t</italic><sub>23</sub> = 4.1, p&lt;.001) (<xref ref-type="fig" rid="fig6">Figure 6I</xref>) (interaction: F<sub>1,23</sub> = 24.6, p&lt;0.001; <xref ref-type="fig" rid="fig6">Figure 6H</xref>). Thus, in both clusters, switch decisions are driving the differences between conditions. Since previous work has identified links between motor preparation and alpha-band activity, we further sought to examine whether these switch effects were due to response preparation. For this purpose, we selected a subsample of channels sensitive to response-hand selectivity in the frontal cluster. We found no difference in motor lateralization between conditions at a liberal sample-wise threshold p&lt;0.05. This suggests that the effects described above are truly about changes-of-mind, not the preparation of a response switch (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>).</p><p>We reasoned that if participants treated all trials independently, repeat or switch decisions would have a similar ‘status’ and we should observe a choice-PSE close to zero. This should be related to a lower alpha suppression (repeat minus switch effect) because repeat and switch trials are treated almost similarly, irrespective of the condition. Therefore, for each condition we examined whether a lower alpha suppression effect (<xref ref-type="fig" rid="fig6">Figure 6F</xref> for the occipital cluster and <xref ref-type="fig" rid="fig6">Figure 6I</xref> for the frontal cluster) was associated with a lower choice-PSE (i.e., closer to zero). In the occipital cluster, we found significant correlations between the alpha effect and the choice-PSE across participants in the C- (ρ = 0.496, p=0.013) and C+ (ρ = 0.585, p=0.002) condition. In the frontal cluster, however, the direction of correlations was similar, but these effects were not statistically significant (C- condition: ρ = 0.311, p=0.137; C+ condition: ρ = 0.357, p=0.086). Likewise, in the occipital cluster, we observed significant correlations between the alpha effect and the best-fitting hazard rate (the model-based counterpart of choice-PSE) across participants in the C- (ρ = −0.467, p=0.021) and C+ (ρ = −0.605, p=0.001) conditions. In the frontal cluster, however, the correlations were similar though not statistically significant (C- condition: ρ = −0.345, p=0.098; C+ condition: ρ = −0.347, p=0.096). These correlations should be taken with caution since our sample size is relatively small and our experiments were not designed and powered to examine them.</p></sec><sec id="s2-7"><title>Pupillometric and cardiac signatures of information seeking during changes-of-mind</title><p>We analyzed pupil dilation time-locked at the trial onset and response probe onset (pooled over Experiments 1 and 2A; see ‘Materials and methods’). In both conditions, pupil dilation increased slightly before, but mainly after probe onset, with a first peak around 1 s after probe onset and a second peak corresponding to the next trial (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1E and F</xref> for raw effects). To compare pupil dilation between switch and repeat trials, we compared the time courses of these two trial types in <xref ref-type="fig" rid="fig7">Figure 7A</xref>, and, at each time point, performed a 2 × 2 ANOVA with <sc>response type</sc> (repeat, switch) and <sc>condition</sc> (C-, C+) as within-participant factors. This revealed a large time window (time from probe onset, +0.93 to +7.77 s), in which the interaction between <sc>response type</sc> and <sc>condition</sc> was significant (p<sub>corr</sub>&lt;0.001; <xref ref-type="fig" rid="fig7">Figure 7B</xref>). Within this time window, pupil dilation was similar across conditions on repeat trials (<italic>t</italic><sub>30</sub> = 1.37, p=0.18), but was larger in the C+ than in the C- condition on switch trials (<italic>t</italic><sub>30</sub> = −5.48, p=5.94 × 10<sup>–6</sup>). At the trial onset, we also found a time window with a significant interaction between <sc>condition</sc> and <sc>response type</sc> (starting at +3.45 s from probe onset, p<sub>corr</sub>&lt;0.001; <xref ref-type="fig" rid="fig7">Figure 7A</xref>).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Larger pupil dilation and cardiac interbeat interval (IBI) signals on changes-of-mind.</title><p>(<bold>A</bold>) Pupil dilation on switch minus repeat decisions time-locked at the trial onset (left panels) and response probe onset (right panels). Shaded areas indicate mean and standard error across participants at each time point. The horizontal lines indicate statistical significance at p&lt;0.05 corrected from ANOVAs with <sc>condition</sc> (C-, C+) and <sc>response type</sc> (repeat, switch) as within-participant factors. The black arrow indicates the average response time across conditions and participants (N = 31, pooled across Experiments 1 and 2). (<bold>B</bold>) Post hoc ANOVA effects on the time windows statistically significant after correction using permutation tests identified in (<bold>A</bold>). Stars correspond to significance of paired <italic>t</italic>-tests between conditions in the time window, ***p&lt;0.001, n.s., not significant. Bars and error bars indicate mean and SEM (N = 31). (<bold>C</bold>) Cardiac IBI on switch minus repeat decisions time-locked at the trial onset (left panels) and response probe onset (right panels). Shaded areas indicate mean and standard error across participants at each time point (N = 24, Experiment 4). (<bold>D</bold>) Post hoc ANOVA effects on the time window statistically significant after correction using permutation tests identified in (<bold>C</bold>). Stars indicate significance for paired <italic>t</italic>-tests of the contrast between switch and repeat trials in each condition separately (***p&lt;0.001). Circle and error bar indicate mean and SEM (N = 24). In all panels, vertical lines indicate trial events: trial onset, samples of the evidence, and the response probe onset (dotted line). Blue: C- condition; pink: C+ condition. See also <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> for raw dynamics of pupil response and cardiac IBI.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig7-v1.tif"/></fig><p>To investigate whether the peripheral nervous system also contains specific signatures of information seeking, we examined the cardiac interbeat interval (IBI) from electrocardiogram (ECG) signals recorded in Experiment 4. In both conditions, the IBI increased before probe onset and slowly decreased thereafter (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1G and H</xref> for raw effects), a dynamic comparable to that of the alpha-band response suppression observed in MEG. This increase was larger on switch than on repeat trials (C-: <italic>t</italic><sub>23</sub> = 3.8, p&lt;0.001; C+: <italic>t</italic><sub>23</sub> = 6.5, p&lt;0.001; <xref ref-type="fig" rid="fig7">Figure 7C</xref>), an effect that was more pronounced in the C+ than in the C- condition (main effect of <sc>condition</sc>: F<sub>1,23</sub> = 12.6, p=0.002; main effect of <sc>response type</sc>: F<sub>1,23</sub> = 34.8, p&lt;0.001; interaction <sc>response type</sc> and <sc>condition</sc>: F<sub>1,23</sub> = 5.8, p=0.024; <xref ref-type="fig" rid="fig7">Figure 7D</xref>).</p><p>We further examined whether these physiological markers of changes-of-mind can indicate when commitments to a change-of-mind occur: whether they accompany the stimulus sequence progression, already ramping up before the response; or whether they occur when the response is provided. We separated physiological data for short (2–4) and long (6–8) stimulus sequences (see ‘Materials and methods’). We observed that the alpha-band effects associated with switch responses arose earlier for long compared to short sequences across conditions, both in the occipital (<xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3A</xref>) and frontal (<xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3B</xref>) clusters (main effect of <sc>sequence length</sc>, occipital: peak F<sub>1,23</sub> = 25.1, cluster-level p&lt;0.001; frontal: peak F<sub>1,23</sub> = 17.7, cluster-level p&lt;0.001). Thus, the difference between conditions observed for changes-of-mind starts before probe onset, with participants engaging more attention early in sequences that eventually lead to a response switch. In contrast, pupil dilation did not differ significantly across the two sequence length groups. In both conditions, pupil dilation on changes-of-mind increased only after the response (<xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3C</xref>). Finally, the IBI revealed dynamics comparable to those of the alpha-band suppression, with differences between short and long sequences restricted to before the probe onset (main effect of <sc>sequence length</sc>: peak F<sub>1,23</sub> = 10.4, cluster-level p&lt;0.05; <xref ref-type="fig" rid="fig6s3">Figure 6—figure supplement 3D</xref>). Together, these results highlight distinct within-trial dynamics, with alpha-band power and IBI effects of changes-of-mind already starting pre-switch, whereas pupillary effects of changes-of-mind being restricted to post-switch.</p></sec><sec id="s2-8"><title>Isolating the effects of information seeking from model variables</title><p>Since changes-of-mind occurred (1) more often when decision evidence was inconsistent with the previous choice (<xref ref-type="fig" rid="fig3">Figure 3</xref>) and (2) less often when participants’ prior beliefs were stronger, we reasoned that these two variables may differently influence changes-of-mind in each condition, which would impact a pure effect of changes-of-mind. In other words, if decision evidence and prior belief differ across repeat and switch trials, fluctuations in these two quantities may differently contribute to the neurophysiological time courses observed. We thus sought to examine whether neurophysiological effects in the C+ condition were specifically related to changes-of-mind, over and above (1) the absolute strength of prior belief and/or (2) the amount of decision evidence signed by the prior belief (hereafter, ‘prior belief’ and ‘evidence direction’). To account for these two quantities, we relied on the variables inferred from our computational model (see ‘Materials and methods’).</p><p>First, using particle filtering, we extracted trajectories of these two quantities conditioned on participants’ responses and established the statistical relationships between these quantities and changes-of-mind. As expected, we found that absolute prior beliefs were stronger on a repeat than on a switch trial (F<sub>1,32</sub> = 59.02, p=9.3 × 10<sup>–9</sup>) and higher than in the C+ than in the C- condition (F<sub>1,32</sub> = 72.3, p=1.0 × 10<sup>–9</sup>), in line with a lower perceived hazard rate found in the C+ condition, with an interaction between <sc>response type</sc> and <sc>condition</sc> (F<sub>1,32</sub> = 11.7, p=0.0017). We also established that evidence direction strongly was positive (resp. negative) on repeat (resp. switch) decisions (F<sub>1,32</sub> = 7527.9, p&lt;1 × 10<sup>–11</sup>), an effect that was more pronounced in the C+ than in the C- condition (F<sub>1,32</sub> = 52.5, p=3.1 × 10<sup>–8</sup>) with an interaction between <sc>response type</sc> and <sc>condition</sc> (F<sub>1,32</sub> = 5.59, p=0.024).</p><p>In both conditions, both prior belief and evidence direction showed strong and sustained correlations with alpha power suppression in occipital and frontal clusters (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). In the occipital cluster, when controlling for the effects of both model variables, the C- switch effect disappears before probe onset, but remains afterward. By contrast, the C+ switch effect remained present, albeit smaller, before and after probe onset (residual variance, <xref ref-type="fig" rid="fig8">Figure 8B</xref>). Importantly, the difference in switch effect remained significant when accounting for these two model variables (interaction <sc>response type</sc> and <sc>condition</sc>: F<sub>1,23</sub> = 21.9, p&lt;0.001), meaning that the original difference between conditions (<xref ref-type="fig" rid="fig6">Figure 6</xref>) cannot be explained away by different prior beliefs or decision evidence. In the frontal cluster, all effects again fully remained after controlling for prior belief and decision evidence (interaction <sc>response type</sc> and <sc>condition</sc>: F<sub>1,23</sub> = 18.0, p&lt;0.001; residual variance, <xref ref-type="fig" rid="fig8">Figure 8B</xref>).</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>In controllable environments, changes-of-mind effects cannot be explained away by fluctuations in prior beliefs or evidence direction.</title><p>(<bold>A</bold>) Effects of prior belief and evidence direction on magnetoencephalography (MEG) alpha-band power in the occipital cluster (left panels) and frontal cluster (right panels). (<bold>B</bold>) For MEG alpha-band power in the occipital cluster (left panels) and frontal cluster (right panels), contrast between repeat and switch trials time-locked at the trial onset (left panels) or response probe onset (right panels) after removing the variance due to fluctuations in prior belief and evidence direction (thick lines, residual variance) in the uncontrollable (blue, C-) and controllable (pink, C+) conditions. Raw contrasts are displayed for comparison (thin lines, total variance). Vertical lines indicate trial events: probe onset, samples of the sequence, and response probe onset (dotted line). The black arrow indicates the average response time across conditions and participants. total var.: total variance; residual var.: residual variance after accounting for the two model variables, prior belief and evidence direction. Shaded error bars indicate SEM (N = 24).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig8-v1.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Changes-of-mind effects after accounting for fluctuations in prior beliefs or evidence direction.</title><p>(<bold>A</bold>) Effects of prior belief and evidence direction on pupil dilation (N = 31) and cardiac interbeat interval (IBI; N = 24). For pupil dilation (<bold>A</bold>) and cardiac IBI (<bold>B</bold>), contrast between repeat and switch trials time-locked at the trial onset (left panels) or response probe onset (right panels) after removing the variance due to fluctuations in prior belief and evidence direction (thick lines, residual variance) in the uncontrollable (blue, C-) and controllable (pink, C+) conditions. Raw contrasts are displayed for comparison (thin lines, total variance). Vertical lines indicate trial events: probe onset, samples of the sequence, and response probe onset (dotted line). The black arrow indicates the average response time across conditions and participants. total var.: total variance; residual var.: residual variance after accounting for the two model variables, prior belief and evidence direction. Shaded error bars indicate SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-fig8-figsupp1-v1.tif"/></fig></fig-group><p>Likewise, in pupil dilation, when controlling for the effects of both variables, the switch effect remained larger in the C+ than in the C- condition (interaction <sc>response type</sc> and <sc>condition</sc>: F<sub>1,30</sub> = 8.9, p=0.005) (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). Like alpha power suppression, prior belief also showed a sustained positive correlation with cardiac IBI, and evidence direction was negatively associated with cardiac IBI (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). When controlling for both variables, the switch effect remained in both conditions, albeit smaller, but the difference between conditions was no longer significant, indicating that evidence direction was driving the switch effect observed in cardiac IBI (compare <xref ref-type="fig" rid="fig7">Figure 7C</xref> and <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>) (interaction <sc>response type</sc> and <sc>condition</sc>: F<sub>1,23</sub> = 0.3, p=0.57). Finally, additionally controlling for the effect of RTs, together with prior belief and evidence direction, provided virtually identical results for all physiological modalities.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Accurate decisions in uncertain environments require forming and updating beliefs through efficient information sampling. Previous studies of human decisions and confidence have often relied on tasks in which participants have no control over the sampling of information (<xref ref-type="bibr" rid="bib17">Fleming et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib52">van den Berg et al., 2016</xref>). However, outside the laboratory, we usually have some control over information sampling: which way to look, which food to try, which person to listen to. We do not passively <italic>receive</italic> information but rather actively <italic>seek</italic> information for decision-making (<xref ref-type="bibr" rid="bib23">Gureckis and Markant, 2012</xref>; <xref ref-type="bibr" rid="bib48">Sharot and Sunstein, 2020</xref>). Here, we reasoned that control is necessary for information seeking, which we used to dissociate information seeking from changes in beliefs and behavior. Across several variants of the same task tested with and without control over information sampling, we obtained converging evidence that information seeking is associated with decreased confidence and drives active hypothesis testing. At the physiological level, information seeking is associated with stronger and longer-lasting correlates of attention and arousal.</p><p>In previous work, information seeking has often been studied and theorized in the context of ‘exploration-exploitation’ dilemmas (<xref ref-type="bibr" rid="bib9">Costa et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Daw et al., 2006</xref>). In these tasks, participants are typically immersed in controllable environments and asked to sample one among several options to maximize reward. Therefore, they have to choose between exploiting a currently rewarding option and foregoing rewards to explore alternative options to seek information about their associated rewards (<xref ref-type="bibr" rid="bib43">Rich and Gureckis, 2018</xref>; <xref ref-type="bibr" rid="bib58">Wilson et al., 2014</xref>). This cognitive trade-off raises the issue that exploration and exploitation not only differ in terms of information seeking, but also in terms of other cognitive and behavioral events. In particular, three main events co-occur during an exploratory decision: (1) a covert change-of-mind about the expected reward of the current option, (2) an overt change in behavior (e.g., a response switch), and (3) information seeking, that is, an active search for information about the new option being considered. The latter is only possible in the controllable condition, allowing us to isolate information seeking by comparing response switches between the two conditions.</p><p>We fitted a Bayesian inference model to participants’ choices and extended our model to predict confidence reports. Simulations with best-fitting parameters of individual participants confirmed that each parameter captures a specific behavioral gradient matching participants’ psychometric signatures (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref> and <xref ref-type="fig" rid="fig4s4">4</xref>). First, we replicate our previous finding of a lower perceived hazard rate in the controllable condition (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), corresponding to participants perceiving contingencies as more stable in controllable environments (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). This lower perceived hazard rate contributes to explaining a larger loss of confidence on changes-of-mind in the controllable condition. In the model, the lower perceived hazard rate creates stronger prior beliefs, such that more inconsistent evidence is required for them to be reversed. This mechanism predicts lower confidence during changes-of-mind despite stronger evidence in favor of a change-of-mind in the current trial. This increase in the magnitude of prior beliefs also explains why participants confirm more often their changes-of-mind in the controllable condition, despite lower confidence in these changes-of-mind.</p><p>In both conditions, our model predicts that the quantity of inconsistent evidence required for participants to change their minds (reflected in choice-PSE estimates) should be smaller following a switch than a repeat decision (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). This prediction was verified in the uncontrollable condition. By contrast, in the controllable condition, participants violated this prediction by showing similar choice-PSEs following repeat and switch decisions (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). This deviation between model and data in this condition where changes-of-mind are associated with information seeking could reflect at least two cognitive effects. First, participants may believe a new reversal in task contingencies to be less likely just after a perceived reversal. Second, participants may engage in an active form of hypothesis testing; that is, testing that the new action draws from the target category. Such hypothesis testing is by definition only possible in the controllable condition, where participants can actively sample the environment to confirm or discard their new hypothesis (<xref ref-type="bibr" rid="bib7">Collins and Frank, 2013</xref>; <xref ref-type="bibr" rid="bib33">Markant and Gureckis, 2014</xref>). Hypothesis testing is known to be particularly valuable in environments with many choice options (<xref ref-type="bibr" rid="bib23">Gureckis and Markant, 2012</xref>), but the fact that we observe it in a condition with only two options suggests that it is a constitutive feature of information seeking.</p><p>The notion of controllability bears a partial resemblance with the distinction between learning under selection vs. reception (<xref ref-type="bibr" rid="bib23">Gureckis and Markant, 2012</xref>), and between free vs. forced choices (<xref ref-type="bibr" rid="bib5">Chambon et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Ligneul, 2021</xref>; <xref ref-type="bibr" rid="bib49">Sidarus et al., 2019</xref>; <xref ref-type="bibr" rid="bib58">Wilson et al., 2014</xref>). Performance benefits have been identified in selection contexts and free choice contexts, where participants can maximize the informativeness of their choices (<xref ref-type="bibr" rid="bib19">Freeman et al., 2014</xref>; <xref ref-type="bibr" rid="bib53">Voss et al., 2010</xref>; <xref ref-type="bibr" rid="bib61">Xu and Tenenbaum, 2007</xref>). However, in these previous studies, sequences from selection and reception (and, likewise, from free and forced) choices vastly differ, which make it difficult to separate the specific effects of controllability from its consequences on the evidence available for subsequent choices. Instead, the current paradigm carefully matched the amount of evidence provided in both controllability conditions. Furthermore, we sought to validate controllability as the true cause of differences between conditions. In Experiment 3, we examined whether a distinction in temporal focus (prospective instead of retrospective inference in an uncontrollable context) would account for the differences between the original conditions (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Although the pattern of choices was markedly different, for confidence it remains possible that a lingering effect of temporality affected the original conditions, even if it cannot account for the results overall. In Experiment 2B, when the instructions changed unpredictably across trials instead of blocks, participants still perceived the controllable condition as more stable, providing evidence that the specificity of this condition arises from the controllability of information sampling experienced (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p><p>Despite stimuli carrying no explicitly affective or rewarding value, it remains possible that the mere presence of a target in the C+ condition makes the target category desirable and may produce a form of confirmation bias (<xref ref-type="bibr" rid="bib50">Talluri et al., 2018</xref>). However, at the behavioral level, a confirmation bias would predict that in the controllable condition the sensitivity to evidence should be degraded when the sequence of evidence is inconsistent with participants’ previous choice, a prediction that is absent from human data (<xref ref-type="fig" rid="fig2">Figure 2</xref>). At the neural level, a confirmation bias would decrease the weighting of belief-inconsistent evidence. Instead, in our previous study, we found an absence of difference between the neural coding of belief-consistent and belief-inconsistent evidence (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). In addition, the findings of Experiment 2B, where the target category changes from trial to trial, also mean that the differences between conditions are unlikely to reflect a bias in direction of the target category (<xref ref-type="bibr" rid="bib20">Gesiarz et al., 2019</xref>). Indeed, the direction of this bias would change from one trial to the next, and should therefore decrease in Experiment 2B – which we did not observe. Finally, based on theoretical considerations and empirical results, we also found evidence that our controllability manipulation did not create differences in working memory or executive demands between experimental conditions. We designed our conditions so that they were strictly matched in terms of number of tasks to do, sources of uncertainty, and motor actions to perform. At the behavioral level, the lack of a difference in choice accuracy, sensitivity to the objective evidence, and inference noise parameter between conditions makes it unlikely that the controllable condition was more demanding. At the physiological level, an increased load should have triggered changes in attention and arousal signals across all trials, unlike our observations that the neurophysiological measures only differed on switch decisions, whereas no difference was observed on repeat decisions. Together, these considerations make it unlikely that observed differences between conditions are due to an increased executive or working memory load in the controllable condition. At the neurophysiological level, we observed a stronger suppression of neuromagnetic alpha-band activity in the dorsal attention networks during the last seconds preceding and following response switches, in both conditions (<xref ref-type="fig" rid="fig6">Figure 6</xref>). This observation suggests that uncertainty at the time of a change-of-mind is associated with participants being more strongly oriented toward the presented evidence before the response switch occurs. Critically, this finding does not merely reflect greater attention or engagement in the controllable condition, which would have suggested general differences in task processing between conditions across repeat and switch decisions. Previous work using fMRI showed that task switching recruits a similar dorsal frontoparietal network involved in attentional control (<xref ref-type="bibr" rid="bib8">Corbetta and Shulman, 2002</xref>), whereas response switching recruits a frontal network involved in executive control (<xref ref-type="bibr" rid="bib10">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib13">Donoso et al., 2014</xref>; <xref ref-type="bibr" rid="bib16">Findling et al., 2019</xref>). However, the use of MEG here allowed us to reveal largely anticipatory activations preceding response switches. Our results are also generally consistent with medial frontal activations during hypothesis testing (for a review, see <xref ref-type="bibr" rid="bib36">Monosov and Rushworth, 2022</xref>) and in situations where the gathered information affords to predict but does not influence future outcomes (<xref ref-type="bibr" rid="bib56">White et al., 2019</xref>). The temporal dissociation between switch effects observed in the occipital and frontal clusters suggests that changes-of-mind are preceded by a state of increased attention toward external (here, visual) evidence. This first stage is followed by a covert change-of-mind and ends with an overt response switch reflected in strong alpha-band suppression overlying frontal cortex (<xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>).</p><p>In contrast to MEG dynamics, phasic pupil dilation revealed noradrenergic responses starting after the response probe onset and remained during presentation of the outcomes (<xref ref-type="fig" rid="fig7">Figure 7</xref>). This pattern of findings suggests a functional dissociation between alpha-band correlates of attention and pupil-linked arousal during changes-of-mind. The pupil-linked arousal associated with response switches is consistent with previous evidence for an association between pupil response and belief updating in uncertain environments (<xref ref-type="bibr" rid="bib15">Filipowicz et al., 2020</xref>). Our results are also consistent with a previous study providing evidence that pupil-linked arousal following decision uncertainty increased participants’ tendency to switch their choice on the next trial (<xref ref-type="bibr" rid="bib4">Braun et al., 2017</xref>). The fact that the pupil effect extends well into the next trial suggests that participants pay attention to the consequences of their changes-of-mind well into the next trial, particularly so in the controllable condition where they are in control of the upcoming sequence of evidence. This again stands in contrast to alpha suppression that was mostly anticipatory, a distinction between pupil dilation and alpha-band suppression previously observed in relation to attention (<xref ref-type="bibr" rid="bib57">Whitmarsh et al., 2021</xref>). Even when accounting for the slower dynamics of pupillary responses (<xref ref-type="bibr" rid="bib27">Hoeks and Levelt, 1993</xref>), the 4 s difference between the onsets of the effects observed in pupil dilation and alpha-band suppression makes it highly unlikely that the two effects arise from the same source. An additional difference between switch and repeat trials was further observed in the cardiac IBI, with similar dynamics as the alpha-band suppression. This increased slowing of heartbeats preceding response switches could partly reflect, but are unlikely to entirely reduce to, changes in respiration (<xref ref-type="bibr" rid="bib41">Park et al., 2014</xref>), for example, participants holding their breath before response switches in the controllable condition. Together, these findings indicate that information seeking is characterized by a specific temporal succession of neurophysiological mechanisms in cortical, subcortical, and peripheral nervous systems.</p><p>By comparing changes-of-mind occurring in controllable and uncontrollable environments, we identified cognitive and neurophysiological signatures of information seeking that had otherwise proved difficult to isolate. We found that in controllable environments humans require more evidence to change their mind and do so with reduced confidence but are nevertheless more likely to stick to their decision on the next trial, suggesting a form of hypothesis testing. With computational modeling indicating that participants perceive controllable environments as more stable, we were not only able to explain why information seeking is associated with a higher degree of perceived uncertainty, but also to identify stronger and longer-lasting effects of changes-of-mind on cognition and behavior. Alterations in confidence (<xref ref-type="bibr" rid="bib45">Rouault et al., 2018</xref>), information seeking (<xref ref-type="bibr" rid="bib25">Hauser et al., 2017</xref>), and perceived controllability (<xref ref-type="bibr" rid="bib54">Voss et al., 2017</xref>) are associated with various psychiatric symptoms. For instance, participants with obsessive-compulsive disorder typically need to gather more evidence before committing to a decision, while participants with schizophrenia present an inflated sense of agency associated with an inability to accurately update these representations (<xref ref-type="bibr" rid="bib34">Metcalfe et al., 2014</xref>). By clarifying the effects of controllability on inference and confidence, our study lays the groundwork for explaining how the interplay between perceived control, information seeking, and confidence may go awry in psychiatric conditions.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Human participants were recruited in the participant pool from the French platform ‘Relay for Information about Cognitive Sciences’ and provided written informed consent. The study was approved by the Comité de Protection des Personnes Ile-de-France VI, ID RCB: 2007-A01125-48, 2017-A01778-45. <italic>Experiment 1</italic>: 17 participants were originally recruited in February–March 2016. One participant was excluded for aborting the experiment before the end and one for performing at chance level, leaving 15 participants for behavioral analyses. <italic>Experiment 2</italic>: 20 participants were initially recruited in November–December 2016 and in March–May 2017. Two participants were excluded for performing at chance level, leaving 18 participants for behavioral analyses. <italic>Experiment 3:</italic> 30 participants were initially recruited in March 2019. Four participants were excluded for performing at chance level and one participant aborted the experiment before the end, leaving 25 participants for behavioral analyses. <italic>Experiment 4</italic>: 24 participants were tested in September–November 2015, whose behavior is described in <xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>.</p></sec><sec id="s4-2"><title>Behavioral tasks</title><sec id="s4-2-1"><title>Experiment 1</title><p>Participants performed a reversal learning task similar to that of our previous study (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). Participants were presented with sequences of stimuli drawn from two discrete color categories (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) and were asked to make a decision about the generative category on each trial (each sequence; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). To examine a role for subjective confidence in relation to inference and changes-of-mind about category, in addition to their choice, participants indicated their confidence (high or low) in their response using four response keys (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><p>Participants performed two experimental conditions that aimed at examining the influence of the degree of control over stimuli on choice and confidence. In both conditions, participants were required to track a hidden state (category). In the uncontrollable (C-) condition, participants were instructed that the computer draws sequences of stimuli and were asked to identify the category from which the stimuli were drawn (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). An instruction screen indicated the mapping between response keys and color categories (counterbalanced across blocks). In the controllable (C+) condition, participants were instructed to draw stimuli from a given category (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). An instruction screen indicated the target color category for each block (counterbalanced across blocks). In the C+ condition, participants have control over which stimuli to sample, but are not fully freely sampling, since they asked to produce stimuli from a target color category. Consequently, the hidden state differed between conditions: participants monitored changes in the category being drawn in the uncontrollable condition, whereas they monitored changes in the response key drawing from the target category in the controllable condition (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). In both conditions, participants perform one action per sequence (after seeing a sequence in the uncontrollable condition, before seeing a sequence in the controllable condition). In other words, the uncontrollable condition requires monitoring the drawn category that flips occasionally, but does not require monitoring the category-action rule that is known and fixed over the course of the block. By contrast, the controllable condition requires monitoring the category-action rule that flips occasionally, but does not require monitoring the target category that is known and fixed over the course of the block. The conditions were therefore otherwise fully symmetric, tightly matched in terms of visual and motor requirements, and working memory demands. The order of condition administration was also counterbalanced pseudo-randomly across participants (C-/C+/C-/C+ for odd-numbered subjects, C+/C-/C+/C- for even-numbered subjects).</p><p>The generating category (hidden state) reversed occasionally and unpredictably at the same rate as in both conditions, with ‘episodes’ (i.e., chunks of trials) during which the hidden state was fixed (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Episode duration was sampled pseudo-randomly from a truncated exponential probability distribution (between 4 and 24 trials), resulting in a near-constant hazard rate in each block. Participants completed a total of 576 trials divided into blocks of 72 trials (72 sequences). The detailed instructions provided to participants are reported in <xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>. To experience the difference between experimental conditions, we provide a short gamified analog experiment at <ext-link ext-link-type="uri" xlink:href="https://infdm.scicog.fr/aodemo/runner.html">infdm.scicog.fr/aodemo/runner.html</ext-link>.</p></sec><sec id="s4-2-2"><title>Experiment 2</title><p>To examine whether the retention of a category goal over a longer time scale was critical in the participants’ experience of control, and therefore influenced the results, we introduced a new rule manipulation. In half of the blocks, rules were stable across a block (hereafter, Experiment 2A). Since behavior was virtually identical in this rule condition, we then pooled these data with Experiment 1 for a total of 33 participants. In the other half of blocks, rules were changing on a trial basis instead of a block basis (hereafter, Experiment 2B). In the C- condition, participants were still asked to monitor the category from which samples were generated, but the action mapping (response keys) for reporting either category now changed on every trial. In the C+ condition, participants were still asked to generate samples from either category, but the target category now changed on every trial. The generative structure of the task and all other experimental features remained identical to Experiment 1. We analyzed this experimental data (2B) separately (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p></sec><sec id="s4-2-3"><title>Experiment 3</title><p>We reasoned that our C- and C+ conditions differ in terms of the degree of control that participants experience over stimuli. However, an alternative interpretation of these differences would be in terms of temporal orientation, with the C- condition being about monitoring past stimuli retrospectively (instruction to ‘monitor’), whereas the C+ condition would be about producing stimuli prospectively (instruction to ‘draw’). We set out to test this hypothesis using a modified version of the original conditions. Here, after each sequence of stimuli, participants were asked to guess from which category the computer drew from (retrospective condition) or to guess which category the computer will draw from (prospective condition). All other experimental features remained identical to Experiments 1 and 2A. Findings related to choice behavior have been reported earlier (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>); we focus here on confidence analyses.</p></sec><sec id="s4-2-4"><title>Experiment 4</title><p>Detailed behavioral, modeling, and MEG analyses of this experimental data have been presented elsewhere (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). In short, the experimental design was similar to that of Experiment 1 with the exception that no confidence responses were asked, only category choices.</p></sec><sec id="s4-2-5"><title>Stimuli</title><p>Stimuli were oriented bars presented on top of a colored circle displaying an angular gradient between orange and blue color categories spaced by π/2 (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Stimuli were drawn from either of these two categories (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). On each trial, a sequence of 2, 4, 6, or 8 stimuli was drawn from a von Mises probability distribution centered on either category with a concentration of 0.5 and presented to participants for making a decision about category of origin at the end of the sequence (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Participants were not informed about sequence length on each trial, meaning that they had to pay attention to all stimuli within each sequence and could make up their mind until the time gap between the last stimulus of the sequence and the next probe. The number of stimuli per sequence was drawn from a uniform distribution and pseudo-randomized across trials. Stimuli were displayed at an average rate of 2 Hz with an inter-stimulus interval of 500 ± 50 ms. This rate is sufficiently low to perceive stimuli properly; here, the cognitive bottleneck was not on sensory processing, but on inference (<xref ref-type="bibr" rid="bib14">Drugowitsch et al., 2016</xref>). The last stimulus of each sequence was followed by a longer delay of 1000 ± 50 ms, before participants were probed for their response.</p></sec></sec><sec id="s4-3"><title>Statistical and quantitative analyses</title><sec id="s4-3-1"><title>Psychometric analysis of behavior</title><p>We first examined two reversal curves: the proportion of choosing either option (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) and the proportion of high-confidence responses (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) as a function of trial number before and after a reversal. We modeled choices using a truncated exponential function characterized by two parameters, an asymptotic level and a (reversal) time constant (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). For confidence as a function of reversal, we also fitted an exponential learning model for which we report two characteristic parameters (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), a (confidence) time constant, and a ‘confidence drop’ parameter reflecting the drop between the lower (<inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>) and upper (<inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>) asymptotic levels (corrected by the time constant <inline-formula><mml:math id="inf3"><mml:mi>t</mml:mi></mml:math></inline-formula>), such that<disp-formula id="equ1"><mml:math id="m1"><mml:mtext>Confidence drop</mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mi> </mml:mi><mml:mo>×</mml:mo><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>We also examined the proportion of repeating the previous choice (<xref ref-type="fig" rid="fig2">Figure 2E</xref>) as a function of evidence recoded in favor of repeating a previous choice (‘consistent evidence’) or in favor of switching choice (‘inconsistent evidence’). We quantified this by fitting a logistic function to quantify the amount of evidence required to switch a response in each condition (PSE) and the sensitivity to the evidence (slope of the sigmoid function; <xref ref-type="fig" rid="fig2">Figure 2F</xref>). Similarly, we analyzed the proportion of high-confidence responses as a function of consistent vs. inconsistent evidence (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). For confidence, we computed within-participant error bars by removing the mean confidence level across conditions before computing the standard error. This was done to allow a fair comparison between conditions without an influence of inter-individual variability about the use and calibration of the high- and low-confidence responses. As expected, trials with consistent evidence correspond more often to repeat choices (right part of <xref ref-type="fig" rid="fig2">Figure 2G</xref>), whereas trials with inconsistent evidence correspond more often to changes-of-mind (left part of <xref ref-type="fig" rid="fig2">Figure 2G</xref>). To quantify these findings, we fitted two logistic sigmoid functions, one for repeat and one for switch choices, for each condition separately. The sensitivity to the evidence (slope) parameter was entered into a 2 × 2 ANOVA with factors <sc>condition</sc> (C-, C+) and <sc>response type</sc> (repeat, switch). We also quantified the evidence level at which the two sigmoid for repeat and switch trials intersect, which corresponds to the quantity of evidence at which participants are equally confident in their repeat and switch decisions (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). For all psychometric analyses, we compared parameters of best-fitting functions across conditions using paired <italic>t</italic>-tests. Wherever appropriate, we also performed Bayesian paired <italic>t</italic>-tests to assess the evidence in favor of the null hypothesis using JASP version 0.8.1.2 with classic priors (zero-centered Cauchy distribution with a default scale of 0.707). When individual estimates were too noisy (e.g., for 6/33 participants, confidence was very little modulated by evidence level on switch trials), we performed a nonparametric Wilcoxon signed-rank test and displayed only the participants who did not have extreme values.</p><p>We additionally fitted the PSE on subsamples of trials corresponding to trials following a repeat and a switch decision, respectively (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), and for trials following a high- or a low-confidence response, respectively (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). This allowed us to examine how participants adapted their PSE on a dynamic basis, depending on the choice sequence experienced in the task.</p></sec><sec id="s4-3-2"><title>Change-of-mind analyses</title><p>In Experiments 1 and 2A, we sought to characterize the behavioral properties of changes-of-mind across conditions. In a 2 × 2 repeated-measures ANOVA, we examined the influence of <sc>response type</sc> (repeat, switch) and <sc>condition</sc> (C-, C+) on the fraction of high-confidence responses (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, which corresponds to the same data as <xref ref-type="fig" rid="fig2">Figure 2G</xref> pooled over objective evidence levels). For switch trials, we further examined confidence on switch trials that were confirmed on the next trial (‘change-of-mind confirmed’) compared to switch trials after which participants went back to their previous response (‘change-of-mind aborted’; <xref ref-type="fig" rid="fig3">Figure 3B</xref>). Finally, we examined the fraction of changes-of-mind confirmed (over all changes-of-mind) as a function of whether the change-of-mind was done with high or low confidence (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). These analyses are pooled over objective evidence levels due to each of these events not being distributed homogeneously across evidence levels.</p><p>To take into account any effects of evidence strength in these change-of-mind analyses, we further performed two logistic regressions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A and B</xref>). First, we aimed to predict confidence using Response type, Condition, their interaction, and trial-by-trial evidence strength in favor of the previous response as a co-regressor (related to <xref ref-type="fig" rid="fig3">Figure 3A</xref>). Second, we aimed to predict confidence using change-of-mind (confirmed vs. aborted), Condition, their interaction, and trial-by-trial evidence strength in favor of the previous response (related to <xref ref-type="fig" rid="fig3">Figure 3B</xref>). We implemented regularized logistic regressions with Gaussian priors on each regression coefficient (mean = 0, SD = 2) in order to account for the fact that some of our participants have few events per cell, which otherwise led to unreliable regression coefficient estimates. Group-level significance of regression coefficients was assessed using one-sample <italic>t</italic>-tests. We also computed the average evidence quantity in favor of the participant’s previous response and compared the obtained interactions patterns to those obtained in the change-of-mind analyses in <xref ref-type="fig" rid="fig3">Figure 3</xref> (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C and D</xref>).</p></sec></sec><sec id="s4-4"><title>Computational model</title><sec id="s4-4-1"><title>Model structure</title><p>We implemented a normative model of perceptual inference in volatile environments with contingency reversals (<xref ref-type="bibr" rid="bib21">Glaze et al., 2015</xref>). A key aspect of the model is that it operates on the same evidence quantities and in a similar way in both C- and C+ conditions. Since previous work indicates that inference noise and not selection noise explains most of choice variability in such an inference task (<xref ref-type="bibr" rid="bib14">Drugowitsch et al., 2016</xref>), we included no selection noise but we introduced inference noise on each sample of the sequence, which scales with sequence length (<xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>). We extended the model in key ways to predict not only choices, but also confidence. First, we introduced a confidence threshold parameter for determining whether the response will be provided with high or low confidence based on the posterior belief about the chosen category. This parameter captured baseline differences in proportion of high-confidence responses between conditions, representing the most parsimonious extension possible to provide a normative confidence response. Second, we introduced metacognitive noise to model an imperfect readout, as previously proposed (<xref ref-type="bibr" rid="bib31">Maniscalco and Lau, 2012</xref>; <xref ref-type="bibr" rid="bib42">Pouget et al., 2016</xref>). Third, we introduced a confidence gain parameter on switch trials modeling a differential readout of the posterior belief on changes-of-mind only as a multiplicative factor on the posterior belief applied on switch trials only.</p></sec><sec id="s4-4-2"><title>Model fitting</title><p>We fitted the model using a Bayesian Adaptive Direct Search (BADS) with 100 validation samples that provides point estimates for each parameter (<xref ref-type="bibr" rid="bib1">Acerbi and Ma, 2017</xref>). We used five random starting points and parameters were bounded as follows (hazard rate: range = 0.000001–0.999999, inference noise: range = 0–10, metacognitive noise: range = 0–10, confidence threshold: range=-10, +10, confidence gain for switches: range = 0–10). Here, we selected the most complete (parameterized) model, even at the risk of overfitting, because our goal was not to arbitrate between different models, but to compare our two conditions and our parameters under the same model. In addition, the behavioral effects associated with each of our parameters at the group level indicate that overfitting is unlikely to have occurred (see ‘Model validation’). Indeed, if overfitting had occurred, meaning that if one of the parameters was essentially capturing noise, we would not observe consistent effects of a given parameter across participants (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref> and <xref ref-type="fig" rid="fig4s4">4</xref>).</p><p>We maximized the likelihood that model choices and confidence reproduce the reversal (<xref ref-type="fig" rid="fig2">Figure 2</xref>) and repetition (<xref ref-type="fig" rid="fig3">Figure 3</xref>) curves of participants, which are the key dimensions of interest for understanding participants’ choice and confidence patterns. One participant was excluded for having an unreliable fit. All trials were fitted together, but each parameter was allowed to vary between conditions, and we compared the best-fitting parameters using paired <italic>t</italic>-tests at the group level. To ensure that our fitting procedure was unbiased, we performed a parameter recovery analysis (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We simulated choice and confidence sequences using generative parameters randomly sampled in a uniform distribution between the minimum and maximum of participants’ best-fitting parameter values in each condition. This procedure ensures that generative parameters were independently sampled. We then fitted these data using the same fitting procedure as for participants (except with three instead of five random starting points) and calculated the correlations between generative and recovered parameters, presented in a confusion matrix (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p></sec><sec id="s4-4-3"><title>Model validation</title><p>To validate the model, we simulated model choice and confidence from the best-fitting parameters on the same stimuli sequences as participants and analyzed the simulations similarly as for participants’ data (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>; <xref ref-type="bibr" rid="bib40">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Wilson and Collins, 2019</xref>). We examined correlations of the best-fitting parameters averaged across conditions between participants (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). We also performed a median split across participants on the best-fitting parameter values (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref> and <xref ref-type="fig" rid="fig4s4">4</xref>). We then averaged simulations of the model for each subgroup to further illustrate the independent contribution of each of these parameters. Note that we do not draw group inferences from these median split analyses – the goal is to visualize the effect of each of the parameters qualitatively.</p><p>Finally, to compare the characteristics of changes-of-mind between model and participants, we reproduced one of the psychometric analyses that fits the choice-PSE separately for trials following a repeat vs. a change-of-mind, and separately for trials following a high- vs. a low-confidence response. For model simulations, we averaged across 50 simulations per participant session (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p></sec></sec><sec id="s4-5"><title>Magnetoencephalography</title><p>As reported in our previous study (Experiment 4, <xref ref-type="bibr" rid="bib55">Weiss et al., 2021</xref>), we recorded MEG data using a whole-head Elekta Neuromag TRIUX system (Elekta Instrument AB, Stockholm, Sweden) composed of 204 planar gradiometers and 102 magnetometers using a sampling frequency of 1000 Hz. Prior to the experiment, each participant’s head shape was digitized in the MEG coordinate frame. We used four additional head position indicator (HPI) coils, whose positions were also digitized, to monitor and correct for small head movements across blocks. The movement of HPI coils between blocks remained small (mean: 2.3 mm) was similar across blocks and across conditions (<italic>t</italic><sub>23</sub> = 1.6, p=0.128).</p><p>We first removed magnetic noise from external sources using temporal signal space separation, after manually removing detected nonphysiological jumps in MEG signals. Stereotyped ocular and cardiac artifacts were corrected using a supervised principal component analysis (PCA). First, the onset of artifacts (either eye blinks or cardiac R-peaks) was automatically detected on auxiliary electrodes (EOG and ECG) synchronized with MEG signals using a threshold-based approach. MEG signals were then epoched from 100ms before to 400 ms after artifact onsets, and a PCA was used to extract the spatial components of cardiac and ocular artifacts. Typically, one stereotyped PCA component was removed from continuous MEG signals for eye blinks and two components for heartbeats.</p><p>The spectral power of band-limited MEG oscillations between 8 and 16 Hz was estimated using the ‘multitapering’ time-frequency transform implemented in FieldTrip (<xref ref-type="bibr" rid="bib39">Oostenveld et al., 2011</xref>) (Slepian tapers, eight cycles and three tapers per window, corresponding to a frequency smoothing of 25%), in two distinct time windows time-locked either to trial onset (from to 0 to +4s from trial onset) or to probe onset (from –4 to +4s from probe onset). We computed the contrast between repeat and switch decisions across conditions at each MEG channel, and examined pairwise correlations of these contrasts across all MEG channels. This analysis identified two main clusters, thereafter labeled ‘occipital’ and ‘frontal’ clusters based on their spatial localization. In these clusters, we employed jackknifed statistics to estimate temporal windows of significant differences between switch and repeat decisions, and between conditions (<xref ref-type="bibr" rid="bib29">Kiesel et al., 2008</xref>).</p></sec><sec id="s4-6"><title>Pupillometry</title><p>To analyze physiological correlates of uncertainty across conditions, we measured pupil dilation at a sampling rate of 1000 Hz in Experiments 1 and 2. We preprocessed data with resampling at 100 Hz and corrected for blinks in a window between –100 ms and +500 ms around the event of interest using a derivative padding window between –200 ms and +200 ms and an instantaneous derivative threshold of 15. We smoothed the data with a moving average window size of 50 ms, detrended slow fluctuations from the signal using a characteristic time constant of 30 s, and z-scored the data. We excluded from the analyses blocks in which participants had more than 50% of low-quality data due to blinks (N = 2 participants excluded from these analyses).</p><p>We focused our analyses on phasic pupil RT-locked at the trial onset and response probe onset. We used an exclusion threshold of 2 s (if the window of missing data remained too large). For statistical analyses, we used a first-level uncorrected threshold of 0.05 and further performed correction for multiple comparisons with nonparametric cluster-level statistics computed across adjacent time points (<xref ref-type="bibr" rid="bib32">Maris and Oostenveld, 2007</xref>). <italic>t</italic>, F, and p-values reported in the main text correspond to corrected statistical values based on permutation tests with 1000 permutations (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). We report post hoc paired <italic>t</italic>-tests for comparing pupil dilation between conditions on repeat and switch trials separately in the time window identified after correction.</p></sec><sec id="s4-7"><title>Electrocardiography</title><p>We extracted the time points of cardiac R-peaks from ECG signals recorded continuously during Experiment 4 using an automatic threshold-based approach (z-score = 3) on band-pass-filtered signals between 1 and 16 Hz. We constructed time courses of cardiac IBI from these estimated R-peaks time-locked either to trial onset (from to 0 to +4 s from trial onset) or to response probe onset (from –4 to +4 s from probe onset). We analyzed these time courses similarly to time courses of alpha power suppression.</p></sec><sec id="s4-8"><title>Neurophysiological activity controlled for fluctuations in prior belief and evidence direction</title><p>To examine whether the differences between conditions visible in neurophysiological signals remain after controlling for our model variables, we analyzed alpha-band suppression time-locked at the trial onset and response probe onset in occipital and frontal clusters. We regressed out the effect of prior belief and evidence direction. We extracted these two variables from our computational model using particle filtering to only extract trajectories consistent with each participant’s choice sequence (<xref ref-type="fig" rid="fig8">Figure 8</xref>). We performed analogous analyses for phasic pupil RT-locked at the response probe onset, and for time courses of cardiac IBI time-locked to the response probe onset.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf3"><p>Reviewing editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Formal analysis, Investigation, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con4"><p>Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Data curation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Human participants were recruited in the participant pool from the French platform 'Relay for Information about Cognitive Sciences' and provided written informed consent. The study was approved by the Comité; de Protection des Personnes Ile-de-France VI, ID RCB: 2007-A01125-48, 2017-A01778-45.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-75038-transrepform1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data and code availability. Participants' data and MATLAB code for behavioral and psychometric analyses of Experiments 1 and 2A, and code for fitting the computational model are available at <ext-link ext-link-type="uri" xlink:href="https://www.github.com/marionrouault/actobscom/">https://www.github.com/marionrouault/actobscom/</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:709298b3dee98ea59a9be41f0437415b9a9ad5bc;origin=https://www.github.com/marionrouault/actobscom/;visit=swh:1:snp:4771209b9cf3df502cd6f2df394ac0212c92dc5a;anchor=swh:1:rev:43bfb417394bd243aa4ccf2ee2b2f50850d4cea8">swh:1:rev:43bfb417394bd243aa4ccf2ee2b2f50850d4cea8</ext-link>). Because tested participants did not provide written consent regarding the posting of their anonymized data on public repositories, the MEG, pupillometric and ECG datasets are available from the corresponding authors upon request.</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Weiss</surname><given-names>A</given-names></name><name><surname>Chambon</surname><given-names>V</given-names></name><name><surname>Lee</surname><given-names>JK</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Weiss_2020_NatComm_data_behavior</data-title><source>figshare</source><pub-id pub-id-type="doi">10.6084/m9.figshare.13200128.v1</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>MR is the beneficiary of a postdoctoral fellowship from the AXA Research Fund. MR work was also supported by La Fondation des Treilles and department-wide grant from the Agence Nationale de la Recherche (ANR-17-EURE-0017, FrontCog). This work has received support under the program «Investissements d’Avenir» launched by the French Government and implemented by ANR (ANR-10-IDEX-0001-02 PSL). AW was supported by the FIRE Doctoral School. VC was supported by the French National Research Agency (ANR-16-CE37-0012-01 and ANR-19-CE37-0014-01). JD was supported by the James S McDonnell Foundation (grant #220020462). This work was supported by a starting grant from the European Research Council (ERC-StG-759341) awarded to VW, a junior researcher grant from the French National Research Agency (ANR-14-CE13-0028-01) awarded to VW, a France-US collaborative research grant from the French National Research Agency (ANR-17-NEUC-0001-02) and the National Institute of Mental Health (1R01MH115554-01) awarded to VW and JD.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Acerbi</surname><given-names>L</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Practical Bayesian optimization for model fitting with Bayesian adaptive direct search</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>1836</fpage><lpage>1846</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balsdon</surname><given-names>T</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Confidence controls perceptual evidence accumulation</article-title><source>Nature Communications</source><volume>11</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1038/s41467-020-15561-w</pub-id><pub-id pub-id-type="pmid">32273500</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartolo</surname><given-names>R</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Inference as a fundamental process in behavior</article-title><source>Current Opinion in Behavioral Sciences</source><volume>38</volume><fpage>8</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.06.005</pub-id><pub-id pub-id-type="pmid">35492434</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname><given-names>A</given-names></name><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</article-title><source>Nature Communications</source><volume>8</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1038/ncomms14637</pub-id><pub-id pub-id-type="pmid">28256514</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chambon</surname><given-names>V</given-names></name><name><surname>Théro</surname><given-names>H</given-names></name><name><surname>Vidal</surname><given-names>M</given-names></name><name><surname>Vandendriessche</surname><given-names>H</given-names></name><name><surname>Haggard</surname><given-names>P</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Information about action outcomes differentially affects learning from self-determined versus imposed choices</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>1067</fpage><lpage>1079</lpage><pub-id pub-id-type="doi">10.1038/s41562-020-0919-5</pub-id><pub-id pub-id-type="pmid">32747804</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charpentier</surname><given-names>CJ</given-names></name><name><surname>Bromberg-Martin</surname><given-names>ES</given-names></name><name><surname>Sharot</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Valuation of knowledge and ignorance in mesolimbic reward circuitry</article-title><source>PNAS</source><volume>115</volume><fpage>E7255</fpage><lpage>E7264</lpage><pub-id pub-id-type="doi">10.1073/pnas.1800547115</pub-id><pub-id pub-id-type="pmid">29954865</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title><source>Psychological Review</source><volume>120</volume><fpage>190</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1037/a0030852</pub-id><pub-id pub-id-type="pmid">23356780</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname><given-names>M</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title><source>Nature Reviews. Neuroscience</source><volume>3</volume><fpage>201</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1038/nrn755</pub-id><pub-id pub-id-type="pmid">11994752</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>VD</given-names></name><name><surname>Mitz</surname><given-names>AR</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Subcortical substrates of explore-exploit decisions in primates</article-title><source>Neuron</source><volume>103</volume><fpage>533</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.017</pub-id><pub-id pub-id-type="pmid">31196672</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nature04766</pub-id><pub-id pub-id-type="pmid">16778890</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desender</surname><given-names>K</given-names></name><name><surname>Boldt</surname><given-names>A</given-names></name><name><surname>Yeung</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Subjective confidence predicts information seeking in decision making</article-title><source>Psychological Science</source><volume>29</volume><fpage>761</fpage><lpage>778</lpage><pub-id pub-id-type="doi">10.1177/0956797617744771</pub-id><pub-id pub-id-type="pmid">29608411</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desender</surname><given-names>K</given-names></name><name><surname>Murphy</surname><given-names>P</given-names></name><name><surname>Boldt</surname><given-names>A</given-names></name><name><surname>Verguts</surname><given-names>T</given-names></name><name><surname>Yeung</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A postdecisional neural marker of confidence predicts information-seeking in decision-making</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>3309</fpage><lpage>3319</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2620-18.2019</pub-id><pub-id pub-id-type="pmid">30804091</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donoso</surname><given-names>M</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Human cognition: Foundations of human reasoning in the prefrontal cortex</article-title><source>Science</source><volume>344</volume><fpage>1481</fpage><lpage>1486</lpage><pub-id pub-id-type="doi">10.1126/science.1252254</pub-id><pub-id pub-id-type="pmid">24876345</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Devauchelle</surname><given-names>AD</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational precision of mental inference as critical source of human choice suboptimality</article-title><source>Neuron</source><volume>92</volume><fpage>1398</fpage><lpage>1411</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.005</pub-id><pub-id pub-id-type="pmid">27916454</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filipowicz</surname><given-names>AL</given-names></name><name><surname>Glaze</surname><given-names>CM</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil diameter encodes the idiosyncratic, cognitive complexity of belief updating</article-title><source>eLife</source><volume>9</volume><elocation-id>e57872</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57872</pub-id><pub-id pub-id-type="pmid">32420866</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Findling</surname><given-names>C</given-names></name><name><surname>Skvortsova</surname><given-names>V</given-names></name><name><surname>Dromnelle</surname><given-names>R</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational noise in reward-guided learning drives behavioral variability in volatile environments</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>2066</fpage><lpage>2077</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0518-9</pub-id><pub-id pub-id-type="pmid">31659343</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>van der Putten</surname><given-names>EJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural mediators of changes of mind about perceptual decisions</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>617</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0104-6</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Folke</surname><given-names>T</given-names></name><name><surname>Jacobsen</surname><given-names>C</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>De Martino</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Explicit representation of confidence informs future value-based decisions</article-title><source>Nature Human Behaviour</source><volume>1</volume><fpage>105</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/s41562-016-0002</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>S</given-names></name><name><surname>Eddy</surname><given-names>SL</given-names></name><name><surname>McDonough</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>MK</given-names></name><name><surname>Okoroafor</surname><given-names>N</given-names></name><name><surname>Jordt</surname><given-names>H</given-names></name><name><surname>Wenderoth</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Active learning increases student performance in science, engineering, and mathematics</article-title><source>PNAS</source><volume>111</volume><fpage>8410</fpage><lpage>8415</lpage><pub-id pub-id-type="doi">10.1073/pnas.1319030111</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gesiarz</surname><given-names>F</given-names></name><name><surname>Cahill</surname><given-names>D</given-names></name><name><surname>Sharot</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Evidence accumulation is biased by motivation: A computational account</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007089</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007089</pub-id><pub-id pub-id-type="pmid">31246955</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaze</surname><given-names>CM</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Normative evidence accumulation in unpredictable environments</article-title><source>eLife</source><volume>4</volume><elocation-id>e08825</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08825</pub-id><pub-id pub-id-type="pmid">26322383</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gureckis</surname><given-names>TM</given-names></name><name><surname>Markant</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Self-directed learning: A cognitive and computational perspective</article-title><source>Perspectives on Psychological Science</source><volume>7</volume><fpage>464</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1177/1745691612454304</pub-id><pub-id pub-id-type="pmid">26168504</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Perceptual decision making in rodents, monkeys, and humans</article-title><source>Neuron</source><volume>93</volume><fpage>15</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.003</pub-id><pub-id pub-id-type="pmid">28056343</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>TU</given-names></name><name><surname>Moutoussis</surname><given-names>M</given-names></name><name><surname>Iannaccone</surname><given-names>R</given-names></name><name><surname>Brem</surname><given-names>S</given-names></name><name><surname>Walitza</surname><given-names>S</given-names></name><name><surname>Drechsler</surname><given-names>R</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Increased decision thresholds enhance information gathering performance in juvenile Obsessive-Compulsive Disorder (OCD)</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005440</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005440</pub-id><pub-id pub-id-type="pmid">28403139</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hertwig</surname><given-names>R</given-names></name><name><surname>Engel</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><source>Age Differences in Deliberate Ignorance</source><publisher-name>Psychology and Aging</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/13757.001.0001</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoeks</surname><given-names>B</given-names></name><name><surname>Levelt</surname><given-names>WJM</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Pupillary dilation as a measure of attention: A quantitative system analysis</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><volume>25</volume><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.3758/BF03204445</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil diameter predicts changes in the exploration-exploitation trade-off: evidence for the adaptive gain theory</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>1587</fpage><lpage>1596</lpage><pub-id pub-id-type="doi">10.1162/jocn.2010.21548</pub-id><pub-id pub-id-type="pmid">20666595</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiesel</surname><given-names>A</given-names></name><name><surname>Miller</surname><given-names>J</given-names></name><name><surname>Jolicoeur</surname><given-names>P</given-names></name><name><surname>Brisson</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Measurement of ERP latency differences: A comparison of single-participant and jackknife-based scoring methods</article-title><source>Psychophysiology</source><volume>45</volume><fpage>250</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2007.00618.x</pub-id><pub-id pub-id-type="pmid">17995913</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ligneul</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Prediction or causation? Towards a redefinition of task controllability</article-title><source>Trends in Cognitive Sciences</source><volume>25</volume><fpage>431</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2021.02.009</pub-id><pub-id pub-id-type="pmid">33712402</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>Lau</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings</article-title><source>Consciousness and Cognition</source><volume>21</volume><fpage>422</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2011.09.021</pub-id><pub-id pub-id-type="pmid">22071269</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markant</surname><given-names>DB</given-names></name><name><surname>Gureckis</surname><given-names>TM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Is it better to select or to receive? Learning via active and passive hypothesis testing</article-title><source>Journal of Experimental Psychology. General</source><volume>143</volume><fpage>94</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1037/a0032108</pub-id><pub-id pub-id-type="pmid">23527948</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Metcalfe</surname><given-names>J</given-names></name><name><surname>Van Snellenberg</surname><given-names>JX</given-names></name><name><surname>DeRosse</surname><given-names>P</given-names></name><name><surname>Balsam</surname><given-names>P</given-names></name><name><surname>Malhotra</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><chapter-title>Judgments of agency in schizophrenia: an impairment in autonoetic metacognition</chapter-title><person-group person-group-type="editor"><name><surname>Metcalfe</surname><given-names>JF</given-names></name></person-group><source>In: The Cognitive Neuroscience of Metacognition</source><publisher-name>Springer</publisher-name><fpage>367</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-45190-4</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Schlunegger</surname><given-names>D</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The sense of confidence during probabilistic learning: A normative account</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004305</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004305</pub-id><pub-id pub-id-type="pmid">26076466</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monosov</surname><given-names>IE</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Interactions between ventrolateral prefrontal and anterior cingulate cortex during learning and behavioural change</article-title><source>Neuropsychopharmacology</source><volume>47</volume><fpage>196</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1038/s41386-021-01079-2</pub-id><pub-id pub-id-type="pmid">34234288</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Harty</surname><given-names>S</given-names></name><name><surname>OConnell</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural evidence accumulation persists after choice to inform metacognitive judgments</article-title><source>eLife</source><volume>1</volume><elocation-id>e23</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11946.001</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id><pub-id pub-id-type="pmid">20844132</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><elocation-id>156869</elocation-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id><pub-id pub-id-type="pmid">21253357</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The importance of falsification in computational cognitive modeling</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>425</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.03.011</pub-id><pub-id pub-id-type="pmid">28476348</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>HD</given-names></name><name><surname>Correia</surname><given-names>S</given-names></name><name><surname>Ducorps</surname><given-names>A</given-names></name><name><surname>Tallon-Baudry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spontaneous fluctuations in neural responses to heartbeats predict visual detection</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>612</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.1038/nn.3671</pub-id><pub-id pub-id-type="pmid">24609466</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Confidence and certainty: distinct probabilistic quantities for different goals</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>366</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1038/nn.4240</pub-id><pub-id pub-id-type="pmid">26906503</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rich</surname><given-names>AS</given-names></name><name><surname>Gureckis</surname><given-names>TM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Exploratory choice reflects the future value of information</article-title><source>Decision</source><volume>5</volume><fpage>177</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1037/dec0000074</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rollwage</surname><given-names>M</given-names></name><name><surname>Loosen</surname><given-names>A</given-names></name><name><surname>Hauser</surname><given-names>TU</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Confidence drives a neural confirmation bias</article-title><source>Nature Communications</source><volume>11</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1038/s41467-020-16278-6</pub-id><pub-id pub-id-type="pmid">32457308</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouault</surname><given-names>M</given-names></name><name><surname>Seow</surname><given-names>T</given-names></name><name><surname>Gillan</surname><given-names>CM</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Psychiatric symptom dimensions are associated with dissociable shifts in metacognition but not task performance</article-title><source>Biological Psychiatry</source><volume>84</volume><fpage>443</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2017.12.017</pub-id><pub-id pub-id-type="pmid">29458997</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouault</surname><given-names>M</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Forming global estimates of self-performance from local confidence</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>1141</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-09075-3</pub-id><pub-id pub-id-type="pmid">30850612</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarafyazd</surname><given-names>M</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hierarchical reasoning by neural circuits in the frontal cortex</article-title><source>Science</source><volume>364</volume><elocation-id>eaav8911</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav8911</pub-id><pub-id pub-id-type="pmid">31097640</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharot</surname><given-names>T</given-names></name><name><surname>Sunstein</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>How people decide what they want to know</article-title><source>Nature Human Behaviour</source><volume>4</volume><fpage>14</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0793-1</pub-id><pub-id pub-id-type="pmid">31932690</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sidarus</surname><given-names>N</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Chambon</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cost-benefit trade-offs in decision-making and learning</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007326</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007326</pub-id><pub-id pub-id-type="pmid">31490934</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talluri</surname><given-names>BC</given-names></name><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Confirmation bias through selective overweighting of choice-consistent evidence</article-title><source>Current Biology</source><volume>28</volume><fpage>3128</fpage><lpage>3135</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.07.052</pub-id><pub-id pub-id-type="pmid">30220502</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzovara</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>MM</given-names></name><name><surname>Bourdaud</surname><given-names>N</given-names></name><name><surname>Chavarriaga</surname><given-names>R</given-names></name><name><surname>Millán</surname><given-names>JDR</given-names></name><name><surname>De Lucia</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The timing of exploratory decision-making revealed by single-trial topographic EEGanalyses</article-title><source>NeuroImage</source><volume>60</volume><fpage>1959</fpage><lpage>1969</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.136</pub-id><pub-id pub-id-type="pmid">22342874</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Berg</surname><given-names>R</given-names></name><name><surname>Anandalingam</surname><given-names>K</given-names></name><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A common mechanism underlies changes of mind about decisions and confidence</article-title><source>eLife</source><volume>5</volume><elocation-id>e12192</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12192</pub-id><pub-id pub-id-type="pmid">26829590</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>JL</given-names></name><name><surname>Gonsalves</surname><given-names>BD</given-names></name><name><surname>Federmeier</surname><given-names>KD</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Cohen</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Hippocampal brain-network coordination during volitional exploratory behavior enhances learning</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>115</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1038/nn.2693</pub-id><pub-id pub-id-type="pmid">21102449</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voss</surname><given-names>M</given-names></name><name><surname>Chambon</surname><given-names>V</given-names></name><name><surname>Wenke</surname><given-names>D</given-names></name><name><surname>Kühn</surname><given-names>S</given-names></name><name><surname>Haggard</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>In and out of control: brain mechanisms linking fluency of action selection to self-agency in patients with schizophrenia</article-title><source>Brain</source><volume>140</volume><fpage>2226</fpage><lpage>2239</lpage><pub-id pub-id-type="doi">10.1093/brain/awx136</pub-id><pub-id pub-id-type="pmid">28899009</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiss</surname><given-names>A</given-names></name><name><surname>Chambon</surname><given-names>V</given-names></name><name><surname>Lee</surname><given-names>JK</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Interacting with volatile environments stabilizes hidden-state inference and its brain signatures</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>2228</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-22396-6</pub-id><pub-id pub-id-type="pmid">33850124</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>JK</given-names></name><name><surname>Bromberg-Martin</surname><given-names>ES</given-names></name><name><surname>Heilbronner</surname><given-names>SR</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>Pai</surname><given-names>J</given-names></name><name><surname>Haber</surname><given-names>SN</given-names></name><name><surname>Monosov</surname><given-names>IE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A neural network for information seeking</article-title><source>Nature Communications</source><volume>10</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1038/s41467-019-13135-z</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitmarsh</surname><given-names>S</given-names></name><name><surname>Gitton</surname><given-names>C</given-names></name><name><surname>Jousmäki</surname><given-names>V</given-names></name><name><surname>Sackur</surname><given-names>J</given-names></name><name><surname>Tallon-Baudry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neuronal correlates of the subjective experience of attention</article-title><source>The European Journal of Neuroscience</source><volume>55</volume><fpage>3465</fpage><lpage>3482</lpage><pub-id pub-id-type="doi">10.1111/ejn.15395</pub-id><pub-id pub-id-type="pmid">34278629</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Geana</surname><given-names>A</given-names></name><name><surname>White</surname><given-names>JM</given-names></name><name><surname>Ludvig</surname><given-names>EA</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Humans use directed and random exploration to solve the explore-exploit dilemma</article-title><source>Journal of Experimental Psychology. General</source><volume>143</volume><fpage>2074</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1037/a0038199</pub-id><pub-id pub-id-type="pmid">25347535</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Collins</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Ten simple rules for the computational modeling of behavioral data</article-title><source>eLife</source><volume>8</volume><elocation-id>e49547</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.49547</pub-id><pub-id pub-id-type="pmid">31769410</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Choice variability and suboptimality in uncertain environments</article-title><source>Current Opinion in Behavioral Sciences</source><volume>11</volume><fpage>109</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.07.003</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>F</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Sensitivity to sampling in bayesian word learning</article-title><source>Developmental Science</source><volume>10</volume><fpage>288</fpage><lpage>297</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2007.00590.x</pub-id><pub-id pub-id-type="pmid">17444970</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Counterfactual reasoning underlies the learning of priors in decision making</article-title><source>Neuron</source><volume>99</volume><fpage>1083</fpage><lpage>1097</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.035</pub-id><pub-id pub-id-type="pmid">30122376</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75038.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Roiser</surname><given-names>Jonathan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.01.04.425114" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.01.04.425114"/></front-stub><body><p>This article will be of interest to psychologists and cognitive neuroscientists studying learning, decision-making, belief formation, and metacognition. The authors use an elegant task in which people make decisions with or without control over the information they sample, and link the cognitive processes at play to magnetoencephalography and pupillometry signatures. The key finding is that when participants have control over information sampling (i.e., they are seeking information), they need more contradictory evidence in order to switch their choices, and such switches are made with lower confidence, which is a clear conceptual advance in this field.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75038.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Roiser</surname><given-names>Jonathan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Press</surname><given-names>Clare</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02mb95055</institution-id><institution>Birkbeck, University of London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.01.04.425114">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.01.04.425114v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Controllability reveals defining features of information seeking&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Clare Press (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission. The reviewers felt that the conclusions of of paper are mostly well supported by data, but some aspects of the effects reported, the model and psychological interpretation need to be clarified and extended.</p><p>Essential revisions:</p><p>The reviewers enjoyed this paper, which they found to be well written and with excellent figures, but felt that the number of different effects, psychological constructs, and data types presented at times impeded their understanding of a clear take-home message that captures how this paper furthers our understanding of decision-making. Any changes that could help focus the manuscript better in this regard would be welcome. Additionally, there are several re-analyses and changes to the interpretations that are required as detailed below, as well as some further details relating to the analyses. In principle the reviewers think that it should be possible to address these concerns without further data, but if it is more straightforward to conduct further experiments to bolster their conclusions then the authors should feel free to do that.</p><p>Key re-analyses required</p><p>1) The Ob trials require selection of an action, monitoring the action-outcome relationship, and a judgement about the stimulus. The Cb trials, in contrast, simply require monitoring the stimulus (it was unclear whether participants perform an action to start each trial, but regardless, they will not need to keep track of action-outcome mappings). Therefore, the fact that participants are slower to notice the shift in Ob trials and that their judgements are associated with lower confidence could easily be driven by the fact that they have three tasks (or at least two) rather than one. Relatedly, can the fact that α suppression and pupil dilation effects are increased with changes-of-mind in the Ob condition also be explained by the fact participants have more tasks? If there are greater executive/working memory demands, this will reduce α and increase dilation (as already discussed in the manuscript). Participants may detect stimulus changes less readily because there is a greater executive/working memory load in this condition, and this has nothing to do with controllability/action or stability of beliefs per se.</p><p>The authors claim that the participants were &quot;equally sensitive&quot; to the available objective evidence across conditions, which would indeed be reassuring, but at the moment it is not clear how solid this inference is. It would be good for the authors to clarify what they mean here – did they test for a significant slope/precision effect in the data shown in Figure 3A? Is it possible to say participants are equally sensitive to the evidence (other than on switch trials), when the insight into their sensitivity is given by a response that only requires them to process the evidence on switch trials? More generally, it remains to be convincingly demonstrated that the Ob-Cb differences are generated by something other than number of tasks and generic working memory/executive differences. For example, it would be important to demonstrate that performance accuracy (i.e. how often participants make the correct choice), and choice reaction times are equivalent between conditions, which could be achieved using a Bayesian approach. (This analysis would need to exclude the switch trials). If there are differences in performance accuracy or reaction times across conditions, then this could undermine the authors' conclusions.</p><p>2) In experiment 3, which aimed to test whether the temporal direction of the inference (prospective vs retrospective) could in fact explain the observed differences between condition, the effects on change of mind are not shown. Instead, only the effects on confidence are displayed – why is that? Additionally, the confidence data presented in Figure S1 still shows some apparent differences: lower overall confidence, higher confidence time-constant, and higher confidence-PSE in the prospective vs retrospective condition. Those differences are reported but the authors then nonetheless conclude that these results constitute evidence that the observed differences between Ob and Cb conditions in the main experiment are only due to controllability and not to the temporal orientation. At present, this conclusion is not supported by the data. One could conclude that temporality has no effect only if no difference in choice or confidence were observed. Again, a Bayesian approach to demonstrate equivalence could be of use here.</p><p>Introduction</p><p>3) Please unify, or at least operationalize more clearly, the terms that are used to describe the main effect of interest. Is information seeking (which indeed is often studied in bandit-type tasks) the same as changes of mind (which are more often studied in within-trial evidence accumulation paradigms)? How does this relate to belief updating, hypothesis testing, exploration, and the observers' stickiness tendency? While it is laudable that the authors reach across subfields of neuroscience that have their own terminology, in places the text was confusing about what's a general psychological process vs. an effect in the behavioral data vs. a model-derived computational latent variable.</p><p>4) Related to the above point, some of the terminology or logical formulation of conclusions was a bit confusing. The authors use the term &quot;information-seeking&quot; specifically to refer to the controllable condition. In the uncontrollable condition, there is no &quot;seeking&quot; of information, only passive sampling. If that understanding is correct, some sentences are redundant. For example, shouldn't the title read &quot;Controllability reveals defining features of information-sampling&quot; or even (and more consistent with the findings) &quot;Controllability over information sampling reveals defining features of changes of mind&quot;? At times &quot;controllability&quot; and &quot;information-seeking&quot; seem to be used interchangeably, while at other times they seem to have different meanings. It would be important to specify those terms better.</p><p>5) It would greatly help the reader to include a short paragraph in the introduction listing the ways in which this work replicates vs. extends the previous paper by Weiss et al.</p><p>6) Overall the introduction is a little thin and would benefit from being expanded. First, the statement that &quot;information-seeking has been mostly studied under 'exploration-exploitation' dilemma is not true – there are many recent studies that have studied information-seeking in humans using other paradigms. Second, and most importantly, the introduction currently lacks the rationale for the proposed work – in addition to dissociating information-seeking from changes-of-mind, which is more of a methodological aim, what are the key questions that the authors trying to address, and what are the hypotheses given the current literature? Finally, the use of MEG and other physiological measures (pupillometric, cardiac patterns) is not motivated at all in the introduction. The introduction should set the stage as to why collecting these data is needed given the question of interest. Similarly, the hypotheses should also set the stage for the specific analysis choices performed later, i.e. in what way does each presented analysis answer the question?</p><p>Methods</p><p>7) Was the model fitted to all trials together, or separately for each condition?</p><p>8) The model validation is rigorous, but would the same patterns also be observed out-of-sample? Since only one model is tested, there is always a risk of overfitting, which could be addressed with out-of-sample validation.</p><p>9) Please provides the statistics for the validation data presented on p12 (Figure S2 and S3)</p><p>10) How recoverable are the parameters if the model is re-fit to simulated data?</p><p>11) Are parameters correlated with each other? The authors should provide a correlation table of the parameters in the supplement.</p><p>Results</p><p>12) It would help to preview the specific diagnostic effects that isolate the process of interest, and then to repeat those in the model fit. Currently, we see four effects in Figure 2, four effects in Figure 3, and three effects in Figure 4. When we get to Figure 5D, slightly different effects are presented in comparison to the model. This was quite confusing and more clarity is required about the specific behavioral pattern of interest. This may just be a matter of slight reordering: the supplement has clear model-data matches, and placing those in the main figure (to highlight that most of the basic effects in Figures2-4 are indeed explained by the model) would allow a better appreciation of where the model fails to capture human behavior.</p><p>13) (see also (2) above) The data in Figure S1 are a crucial control, but it is not yet clear that there is no substantial difference in pro- vs. retro-spective decisions, which might (partially) explain the Cb vs. Ob differences. If controllability was the only important factor for behavioral effects, wouldn't we expect no difference between conditions in Figure S1? This would require a change in the authors' strength of interpretation as specifically pertaining to control.</p><p>14) Do the analyses in Figure 4 control for the difference in objective evidence (logL per trial)?</p><p>15) It is frequently stated that the Ob condition bestows instrumental control to participants over the sampling of stimuli. These statements should be modified, given that participants are told which category of stimulus they must generate. They do not have complete control over which stimuli they sample, unless they are willing to upset the experimenter!</p><p>16) It is not clear what action participants perform to start the trial in the Ob condition. This needs including. In outlining this it would also be great to include consideration of potential overlaps between the responses at the start and end of the trial in Ob, and whether this might have played into the effects.</p><p>17) Please add the change-of-mind data (i.e. equivalent of Figure 2A-B and 3A-B) for experiment 3, so it is possible to dissociate which effects are unique to the main experiment and which effects may be due to the temporal direction of the decisions. It is important to clarify this distinction as it can actually help narrow down the unique effect of controllability over temporality.</p><p>18) It would be useful to provide follow-up analyses to determine how much of the behavioral results can be explained by the difference in prior belief reported on p19, as well as discuss how much of these findings are then more consistent with a role of controllability per se, rather than a role for motivated beliefs/confirmation bias due to the presence of a target.</p><p>Discussion</p><p>19) There is some concern about the interpretation of the results – in particular, whether the observed differences between the cue-based and outcome-based conditions could be better explained by the presence of a target-induced confirmation bias in the outcome-based condition, which would induce a strong motivation to confirm that the chosen action does lead to the target. In other words, it is possible that having a target (e.g. &quot;draw orange&quot;) may bias subjects towards believing they are drawing from that target even when they are not, and as a result needing less evidence to reach that conclusion (similar to the effect shown in Gesiarz, Cahill and Sharot, 2019, Plos Computational Biology). This could in turn lead to the observed patterns of results, i.e. needing more evidence against orange to switch, being less confident when switching etc. Additionally, the result that prior beliefs are stronger in the Ob condition (p18-19) is consistent with this idea, since confirmation bias is usually associated with stronger prior beliefs.</p><p>20) The authors claim that there is a causal role for confidence in controlling changes-of-mind (p11). While this is an interesting idea, it is not clear that it can be fully evidenced in this task without an experimentally-controlled manipulation of confidence. The reason is that there could be a common cause to both high confidence and high propensity to confirm switch decisions without the two processes actually being causally related. One such common cause could be the strength of evidence. Therefore, this conclusion needs to be tempered and this issue mentioned in the discussion.</p><p>21) There is no discussion of alternative ways in which these data might have turned out. The discussion entirely reports claims and findings with which the present data are consistent. Are there no data or theories that could have led to alternative predictions? Currently the manuscript portrays the impression of such high consensus that there was little point running the studies, suggesting that the empirical patterns to date all point in identical directions. One possibility is that the stimulus ISIs are not very variable. Given participants can perceive better at certain oscillatory phases of visual processing (peaks), could they choose to start trials in Ob to align with peaks and thereby improve perceptual acuity? If this occurred, the influence must be weaker than those pulling in the opposite direction, but it could have led to an alternative outcome. If it's a straightforward analysis to perform/report, it may be interesting to see how the oscillations align with events differentially in Ob and Cb.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75038.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>The reviewers enjoyed this paper, which they found to be well written and with excellent figures, but felt that the number of different effects, psychological constructs, and data types presented at times impeded their understanding of a clear take-home message that captures how this paper furthers our understanding of decision-making. Any changes that could help focus the manuscript better in this regard would be welcome. Additionally, there are several re-analyses and changes to the interpretations that are required as detailed below, as well as some further details relating to the analyses. In principle the reviewers think that it should be possible to address these concerns without further data, but if it is more straightforward to conduct further experiments to bolster their conclusions then the authors should feel free to do that.</p></disp-quote><p>We thank both the editor and reviewers for their positive assessment of our paper, and for their helpful and thorough comments, which had a substantial impact on the manuscript. Following the editor and reviewers’ feedback:</p><list list-type="bullet"><list-item><p>We have re-written our introduction to clarify: 1. how the paper contributes to the characterisation of information seeking in decision-making under uncertainty by positioning it with respect to the previous literature on this topic, and 2. the relationship between information seeking and the two related concepts of exploration and changes-of-mind;</p></list-item><list-item><p>We now present more data from Experiment 3 to address the possibility that our main findings could be interpreted in terms of temporal orientation (retrospective vs. prospective inference) rather than controllability;</p></list-item><list-item><p>We use several lines of evidence to show that the effects observed in the controllable condition that we attribute to information seeking cannot be explained by higher cognitive demands and/or working memory load;</p></list-item><list-item><p>Please note that upon the reviewers’ suggestion, we have now renamed the conditions: uncontrollable condition (C-) (ex. cue-based condition) and controllable condition (C+) (ex. outcome-based condition).</p></list-item></list><p>Below we describe how we have revised our manuscript in response to each individual comment.</p><disp-quote content-type="editor-comment"><p>Key re-analyses required</p><p>1) The Ob trials require selection of an action, monitoring the action-outcome relationship, and a judgement about the stimulus. The Cb trials, in contrast, simply require monitoring the stimulus (it was unclear whether participants perform an action to start each trial, but regardless, they will not need to keep track of action-outcome mappings). Therefore, the fact that participants are slower to notice the shift in Ob trials and that their judgements are associated with lower confidence could easily be driven by the fact that they have three tasks (or at least two) rather than one. Relatedly, can the fact that α suppression and pupil dilation effects are increased with changes-of-mind in the Ob condition also be explained by the fact participants have more tasks? If there are greater executive/working memory demands, this will reduce α and increase dilation (as already discussed in the manuscript). Participants may detect stimulus changes less readily because there is a greater executive/working memory load in this condition, and this has nothing to do with controllability/action or stability of beliefs per se.</p></disp-quote><p>We understand the reviewer’s request for clarifications regarding the paradigm. From a computational standpoint, and although the uncontrollable (C-) and controllable (C+) conditions are different in that they require participants to track different hidden states, they do not differ in the number of cognitive operations (or ‘tasks’) that need to be performed to solve them. We now use model simulations to show that the observed differences between the two conditions are inconsistent with the idea that participants have more cognitive operations to perform in the C+ condition. Finally, in response to the second part of the reviewer’s comment below, we provide new analyses of the behavioral data that speak against a higher load in the C+ condition. We hope that these different additions have clarified why the observed differences between the two conditions cannot be attributed to a difference in executive or working memory load.</p><p>In both conditions, participants track a single hidden state, but the nature of this hidden state differs between conditions. Each condition requires tracking a single hidden state of the task: the category (A or B) drawn by the computer in the uncontrollable condition, and the action (left or right) drawing the target category in the C+ condition. In both conditions, participants need to select an action for each stimulus sequence. In the uncontrollable condition, participants select the action most likely to be associated with the category being drawn by the computer, based on a category-action rule defined at the beginning of the current block (A-left and B-right or vice versa). In the C+ condition, participants select the action most likely to be associated with the target category defined at the beginning of the current block. In other words, the uncontrollable condition requires monitoring the drawn category which flips occasionally, but does not require monitoring the category-action rule which is known and fixed over the course of the block. By contrast, the C+ condition requires monitoring the category-action rule which flips occasionally, but does not require monitoring the target category which is known and fixed over the course of the block. Importantly, in both conditions, each trial (sequence of stimuli) is associated with a single action (key press). Therefore, and while the two conditions are indisputably different, because participants have instrumental control over the category being drawn in the C+ condition, they do not differ in the number of task variables that need to be monitored.</p><p>We have now rewritten the protocol in our Methods section to make this point clearer (p. 27-28):</p><p>“Participants performed two experimental conditions that aimed at examining the influence of the degree of control over stimuli on choice and confidence. In both conditions, participants were required to track a hidden state (category). In the uncontrollable (C-) condition, participants were instructed that the computer draws sequences of stimuli, and were asked to identify the category from which the stimuli were drawn (Figure 1C). An instruction screen indicated the mapping between response keys and color categories (counterbalanced across blocks). In the controllable (C+) condition, participants were instructed to draw stimuli from a given category (Figure 1C). An instruction screen indicated the target color category for each block (counterbalanced across blocks). Consequently, the hidden state differed between conditions: participants monitored changes in the category being drawn in the uncontrollable condition, whereas they monitored changes in the response key drawing from the target category in the controllable condition (Figure 1D). In both conditions, participants perform one action per sequence (after seeing a sequence in the uncontrollable condition, before seeing a sequence in the controllable condition). In other words, the uncontrollable condition requires monitoring the drawn category which flips occasionally, but does not require monitoring the category-action rule which is known and fixed over the course of the block. By contrast, the controllable condition requires monitoring the category-action rule which flips occasionally, but does not require monitoring the target category which is known and fixed over the course of the block. The conditions were therefore otherwise fully symmetric, tightly matched in terms of visual and motor requirements, and working memory demands. The order of condition administration was also counterbalanced pseudo-randomly across participants (C-/C+/C/C+ for odd-numbered subjects, C+/C-/C+/C- for even-numbered subjects).”</p><p>Beyond the structure of the paradigm, there are also several aspects of the behavioral and neurophysiological data that are inconsistent with the idea of an increased executive or working memory load in the C+ condition. We agree with the reviewers that reduced attention and/or increased load due to the larger number of tasks to perform in the C+ condition would translate into slower behavioral adaptation to hidden-state reversals, as observed in the C+ condition. However, this alternative account of the behavioral effect would also produce a <italic>decrease</italic> in the asymptotic reversal rate in the C+ condition – a prediction which conflicts with the <italic>increased</italic> asymptotic reversal rate observed in this condition (Figure 2B).</p><p>To support this argument, we ran model simulations implementing the idea of an increased working memory load. Specifically, we reasoned that increased working memory load would result in attentional lapses, meaning that either a fraction of stimuli within a sequence would be missed (variant 1), or a fraction of sequences would be missed (variant 2). We implemented such a model with attentional lapses corrupting inference at the level of stimuli (variant 1) or sequences (variant 2; <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>). We started from best-fitting parameters in the C- condition, and added attentional lapses to simulate behavior in the C+ condition.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>Model simulations of the original uncontrollable condition (blue) and an uncontrollable condition further altered by an increased working memory demand (purple).</title><p>Attentional lapses were implemented at the level of the stimulus within a sequence (variant 1, top row) or at the level of the whole sequence (variant 2, bottom row). Both forms of attentional lapses resulted in a slower adaptation after reversals (left column) and a decreased sensitivity to evidence (right column), all inconsistent with participants’ choice patterns observed in the C+ condition.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75038-sa2-fig1-v1.tif"/></fig><p>At the level of stimuli (variant 1, top row), model simulations indicate that 60% of stimuli would need to be missed (i.e., ignored) to obtain a choice-PSE – i.e., the quantity of conflicting evidence needed to switch – similar to the one we observed in the C+ condition. This fraction of attentional lapses seems highly unlikely.</p><p>As expected, adaptation to reversals is slower in the presence of lapses. Psychometric fits of model simulations are qualitatively inconsistent with those of human participants: with lapses, the asymptotic reversal rate is strongly decreased relative to the C- condition (without lapses). At the level of sequences (variant 2, bottom row), a similar pattern is obtained: 30% of sequences would need to be missed to obtain a choice-PSE similar to that of the one observed in the C+ condition, which again seems highly unlikely. As for stimulus-level lapses (variant 1), sequence-level lapses produce a slower adaptation to reversals and a reduced asymptotic reversal rate, an effect inconsistent with participants’ behavior in the C+ condition (Figure R1). Together, these patterns are therefore inconsistent with an interpretation that the C+ condition required an increased demand.</p><p>Furthermore, attentional lapses due to increased working memory load would decrease the sensitivity to the available objective evidence – a prediction which conflicts with the similar sensitivity found in the two conditions (Figure 2F). An increased working memory load would also predict slower response times (RTs) in the C+ condition on repeat decisions, which we did not observe in our data (please see response to the next comment for a full breakdown). Together, these different considerations make it highly unlikely that observed differences between conditions are due to an increased executive or working memory load in the C+ condition.</p><p>Last, there are important aspects in physiological data that are inconsistent with an increased load in the C+ condition. Indeed, an increase in working memory load (due to more tasks to perform in the C+ condition) should trigger increased arousal and attentional signals across all trials in the C+ condition. This prediction does not match our observations (Figure 6F and 7B): indeed, α-band power and pupil dilation do not differ between conditions for trials ending with a repetition of the previous response (the majority of the trials). These two neurophysiological measures differ between conditions only for trials ending with a switch from the previous response (i.e., the minority of trials associated with information seeking). These selective differences between conditions for switch trials only are again inconsistent with the idea of an overall increase in executive or working memory load in the C+ condition.</p><p>We have now added a new paragraph in the Discussion section to describe – and rule out – this alternative account of the differences between conditions (p. 24):</p><p>“Finally, based on theoretical considerations and empirical results, we also found evidence that our controllability manipulation did not create differences in working memory or executive demands between experimental conditions. We designed our conditions so that they were strictly matched in terms of number of tasks to do, quantities to monitor, sources of uncertainty, and motor actions to perform. At the behavioral level, the lack of a difference in choice accuracy, sensitivity to the objective evidence, and inference noise parameter between conditions makes it unlikely that the C+ condition was more demanding. At the physiological level, an increased load should have triggered changes in attention and arousal signals across all trials, unlike our observations that the neurophysiological measures only differed on switch decisions, whereas no difference was observed on repeat decisions. Together, these considerations make it highly unlikely that observed differences between conditions are due to an increased executive or working memory load in the C+ condition.”</p><disp-quote content-type="editor-comment"><p>The authors claim that the participants were &quot;equally sensitive&quot; to the available objective evidence across conditions, which would indeed be reassuring, but at the moment it is not clear how solid this inference is. It would be good for the authors to clarify what they mean here – did they test for a significant slope/precision effect in the data shown in Figure 3A? Is it possible to say participants are equally sensitive to the evidence (other than on switch trials), when the insight into their sensitivity is given by a response that only requires them to process the evidence on switch trials? More generally, it remains to be convincingly demonstrated that the Ob-Cb differences are generated by something other than number of tasks and generic working memory/executive differences. For example, it would be important to demonstrate that performance accuracy (i.e. how often participants make the correct choice), and choice reaction times are equivalent between conditions, which could be achieved using a Bayesian approach. (This analysis would need to exclude the switch trials). If there are differences in performance accuracy or reaction times across conditions, then this could undermine the authors' conclusions.</p></disp-quote><p>Upon the reviewer’s suggestions, we have performed several additional analyses that provide strong evidence against a difference in executive demands or working memory load between conditions, which we develop below.</p><p><italic>1) Sensitivity to the evidence.</italic> Two findings support the claim that participants were equally sensitive to the available objective evidence across conditions. It is important to note that participants had to process the evidence provided by stimuli on <italic>all</italic> trials, not only on switch trials. First, as suggested by the reviewer, we have tested for a difference in slope in the data shown in Figure 2E/F. We found no difference in this slope parameter (<italic>t</italic><sub>32</sub>=1.09, <italic>p</italic>=.28), as displayed on (ex-Figure 3B) as the ‘sensitivity to evidence’ parameter:</p><p>Second, in our computational model, the best-fitting inference noise parameter was not significantly larger in the C+ condition (<italic>t</italic><sub>32</sub>=1.45, <italic>p</italic>=.16; Figure 4B). This parameter corresponds to a model-based equivalent of the variability of participants’ decisions with respect to the objective evidence presented (inverse of sensitivity to evidence). Together, these results indicate that objective evidence was integrated equally well across experimental conditions.</p><p><italic>2) Choice accuracy.</italic> There was a difference in choice accuracy (i.e., how often participants make the correct choice) between conditions (<italic>t<sub>32</sub></italic>=-3.103, <italic>p</italic>=.004). Importantly however, the difference was in the direction of a <italic>worse</italic> choice accuracy in the C- (78.74% correct) than in the C+ (80.57% correct) condition. This result therefore goes against the alternative interpretation raised by the reviewer that the C+ condition would create more tasks and more cognitive demands, hence a lower choice accuracy. Instead, the performance of participants in the C+ condition being not degraded and actually a bit higher suggests that participants do not miss significantly more information in this condition.</p><p>Despite being significant in Experiments 1 and 2A, the magnitude of the difference in choice accuracy is small (a 2% increase). Moreover, across datasets, this result was not consistent. Indeed, no difference in choice accuracy was found in Experiment 2B (<italic>t<sub>17</sub></italic>=.58, <italic>p</italic>=.569). No difference in choice accuracy was found in Experiment 4 (<italic>t<sub>23</sub></italic>=0.3, <italic>p</italic>=.784) (Weiss et al., 2021). In an ongoing online version of the task (unpublished) that corresponds to the experimental design of Experiments 1 and 2A, we found no difference in choice accuracy between conditions with <italic>N</italic>=200 participants (<italic>t<sub>199</sub></italic>=-1.46, <italic>p</italic>=0.145; C-: mean=77.06% correct; C+: mean=77.96% correct). Together, these observations provide further evidence against significant differences in working memory demands between conditions.</p><p><italic>3) Response times.</italic> Upon the reviewer’s suggestion, we compared RTs between conditions on repeat trials. We found similar RTs between C- and C+ condition (<italic>t<sub>32</sub></italic>=-1.52, <italic>p</italic>=.14). These results indicate that the differences between conditions are unlikely to be generated by working memory or executive differences. Using JASP, we further performed a Bayesian t-test which provided evidence for a genuine lack of a difference between C- and C+ conditions (repeat decisions: BF<sub>10</sub>=0.531). Together, these findings provide additional evidence that the working memory demands were very similar across experimental conditions, and that participants did not perform more tasks in the C+ condition (Results section, p. 7):</p><p>“Participants’ choice accuracy was higher in the C+ (80.6% correct) than in the C- (78.7% correct) condition (t<sub>32</sub>=-3.103, p=.004), although this difference was only of 2% correct. Moreover, response times (RTs) on repeat decisions were similar between C- and C+ condition (t<sub>32</sub>=-1.52, p=.14, BF<sub>10</sub>=0.531). These initial results indicate that the differences between conditions are unlikely to be generated by working memory or executive demand differences.”</p><p><italic>4) Additional condition.</italic> Experiment 2B includes a manipulation which effectively changes the number of tasks that need to be performed. We changed the category-action mapping randomly from one trial to the next in the C- condition, and changed the target category randomly from one trial to the next in the C+ condition. This variant requires participants to account for the rule provided on each trial, rather than relying on a fixed rule across trials in the original variant of the two conditions (Experiments 1 and 2A). To measure the effects of an increase in the number of tasks that need to be performed, we compared task metrics between Experiments 2A and 2B variants of the two conditions (done by the same participants). Importantly, we found that the choice-PSE did not increase in the conditions of Experiment 2B where more tasks need to be performed as compared to the conditions of Experiment 2A (C-: <italic>t<sub>17</sub></italic>=.77, <italic>p</italic>=.45; C+: <italic>t<sub>17</sub></italic>=.73, <italic>p</italic>=.47). Furthermore, the difference in choice-PSE between the C- and C+ conditions did not differ between Experiments 2A and 2B (<italic>t<sub>17</sub></italic>=.49, <italic>p=</italic>.63). Together, these additional findings show that increasing the number of tasks that need to be performed does not alter the choice-PSE in either condition. Therefore, even if participants performed more tasks in the C+ condition (something which is highly unlikely based on the evidence detailed above), it is unlikely that this difference would cause the larger choice-PSE in the C+ condition, or the selective change in pupil dilation and α power only in trials ending with response switches (i.e., where participants engage in information seeking).</p><p>We now report these new findings in the Results section (p. 10):</p><p>“Importantly, even if Experiment 2B effectively changes the number of tasks that need to be performed, we observed a similar Choice-PSE between Experiments 2A and 2B (C-: t<sub>17</sub>=.77, p=.45; C+: t<sub>17</sub>=.73, p=.47), and the difference in choice-PSE between the C- and C+ conditions did not differ between Experiments 2A and</p><p>2B (t<sub>17</sub>=.49, p=.63).”</p><p>In our Discussion section, we now detail our new analyses and findings regarding the working memory demands of the two conditions (p. 24):</p><p>“Finally, based on theoretical considerations and empirical results, we also found evidence that our controllability manipulation did not create differences in working memory or executive demands between experimental conditions. We designed our conditions so that they were strictly matched in terms of number of tasks to do, quantities to monitor, sources of uncertainty, and motor actions to perform. At the behavioral level, the lack of a difference in choice accuracy, sensitivity to the objective evidence, and inference noise parameter between conditions makes it unlikely that the C+ condition was more demanding. At the physiological level, an increased load should have triggered changes in attention and arousal signals across all trials, unlike our observations that the neurophysiological measures only differed on switch decisions, whereas no difference was observed on repeat decisions. Together, these considerations make it highly unlikely that observed differences between conditions are due to an increased executive or working memory load in the C+ condition.”</p><disp-quote content-type="editor-comment"><p>2) In experiment 3, which aimed to test whether the temporal direction of the inference (prospective vs retrospective) could in fact explain the observed differences between condition, the effects on change of mind are not shown. Instead, only the effects on confidence are displayed – why is that? Additionally, the confidence data presented in Figure S1 still shows some apparent differences: lower overall confidence, higher confidence time-constant, and higher confidence-PSE in the prospective vs retrospective condition. Those differences are reported but the authors then nonetheless conclude that these results constitute evidence that the observed differences between Ob and Cb conditions in the main experiment are only due to controllability and not to the temporal orientation. At present, this conclusion is not supported by the data. One could conclude that temporality has no effect only if no difference in choice or confidence were observed. Again, a Bayesian approach to demonstrate equivalence could be of use here.</p></disp-quote><p>We thank the reviewer for raising the important point of the nature of the difference between the C- and C+ conditions, whether controllability or temporal orientation (prospective vs. retrospective). We now also present the choice data in addition to the confidence data from Experiment 3, which we adapted from Weiss et al., 2021 and included in a new Figure 2 supplement 1. Critically, the findings of Experiment 3 reveal that the nature and magnitude of the contrast between retrospective and prospective conditions is different from the contrast between the original C- and C+ conditions, and therefore cannot account for them as an overall explanation of the results, even if a remaining effect of temporal direction of the inference might still be present in the C- vs. C+ conditions, which we now acknowledge in our Discussion section. We also expand below on the differences and similarities between Experiment 3 and the main Experiments 1 and 2A.</p><p><italic>Choices</italic>. In contrast to the comparison between C- and C+ conditions, there were no significant differences in choice adaptation after a reversal between retrospective and prospective conditions. Participants’ reversal time constants were similar across retrospective and prospective conditions (<italic>t<sub>24</sub></italic>=0.1, <italic>p</italic>=.98). Critically, the amount of inconsistent evidence required to change their mind (choice-PSE) was the same between retrospective and prospective conditions (<italic>t<sub>24</sub></italic>=1.7, <italic>p</italic>=.109), unlike between the original C- and C+ conditions.</p><p><italic>Confidence</italic>. First, there was no difference in overall confidence between retrospective and prospective conditions (<italic>t<sub>24</sub></italic>=-1.2, <italic>p</italic>=.25). Moreover, the differences between conditions are not the same, of different direction. Even if there was a higher confidence time constant (<italic>t<sub>24</sub></italic>=-2.58, <italic>p</italic>=.016), the effect is small and noisy: indeed, it depends on the presence of a confidence drop to be measured reliably. In Experiment 3, however, the confidence drop was not different from zero in both retrospective (<italic>t<sub>24</sub></italic>=1.6, <italic>p</italic>=.12) and prospective (<italic>t<sub>24</sub></italic>=.42, <italic>p</italic>=.67) conditions. Therefore, the confidence time constant should not be interpreted, and we no longer present it on Figure 2 supplement 1, due to the unreliability of its estimation. Second, even if the confidence-PSE is increased in the prospective as compared to the retrospective condition, the confidence drop is no longer different between retrospective and prospective conditions. Third, the sensitivity of confidence to the evidence on switch decisions, that was about twice larger in C- as compared to C+, is now similar between prospective and retrospective conditions (<italic>t<sub>24</sub></italic>=-0.94, <italic>p</italic>=.35). This result indicates that participants were less confident both in the face of evidence consistent and inconsistent with their previous choice, which was not the case for the original C- and C+ conditions.</p><p>Taken together, these results indicate that even if a small temporality effect possibly remained present in Experiments 1 and 2A, it cannot alone be an overall explanation of our results, and cannot explain the main differences observed between the C- and C+ conditions as a whole, which we therefore ascribe mostly to controllability. We now include a Discussion point for acknowledging this alternative interpretation in our Discussion section (p. 23):</p><p>“Furthermore, we sought to validate controllability as the true cause of differences between conditions. In Experiment 3, we examined whether a distinction in temporal focus (prospective instead of retrospective inference in an uncontrollable context) would account for the differences between the original conditions (Figure 2 supplement 1). Although the pattern of choices was markedly different, for confidence it remains possible that a lingering effect of temporality affected the original conditions, even if it cannot account for the results overall.”</p><disp-quote content-type="editor-comment"><p>Introduction</p><p>3) Please unify, or at least operationalize more clearly, the terms that are used to describe the main effect of interest. Is information seeking (which indeed is often studied in bandit-type tasks) the same as changes of mind (which are more often studied in within-trial evidence accumulation paradigms)? How does this relate to belief updating, hypothesis testing, exploration, and the observers' stickiness tendency? While it is laudable that the authors reach across subfields of neuroscience that have their own terminology, in places the text was confusing about what's a general psychological process vs. an effect in the behavioral data vs. a model-derived computational latent variable.</p></disp-quote><p>We thank the reviewer for prompting clarity on the meaning and terminology for the different effects of interest. We agree with the reviewer that the term ‘exploration’ in the literature has a heterogeneous meaning, and has been used to refer to a number of different cognitive processes.</p><p>We have typically used ‘changes-of-mind’ to refer to the cognitive operation, while ‘response switch’ and ‘switch decision’ refer to the behaviour observable by the experimenter. We consider information seeking to be only possible in the controllable condition, whereas in the uncontrollable condition, only passive sampling occurs. It is the control over evidence conferred to participants in the controllable experimental condition that renders information seeking possible. We have revised the manuscript to use appropriate terms throughout, and we have now updated Figure 1 about the paradigm to explain the interactions between the different experimental and cognitive events. Hidden-state reversals are determined by the experimenter (“task event”). During an exploratory decision, several steps co-occur: a covert change-of-mind (“cognitive event”) about the expected reward of the current option; an overt response switch (“behavioral event”); and information seeking, i.e., an active search for information about the new option being considered, which is only possible in the C+ condition where participants are in control. (Results section, p. 6):</p><p>Upon the reviewer’s suggestion, in our introduction section, we now clarify the relationship between information seeking and other related concepts such as belief updating, hypothesis testing and exploration:</p><p>“In these paradigms, participants evolve in controllable environments and usually sample one among several options to maximize reward. Therefore, they have to either exploit a currently rewarding option, or sacrifice rewards to explore alternative options and seek information about their possible rewards (Rich and Gureckis, 2018; Wilson et al., 2014). This trade-off means that in these paradigms, exploration differs from exploitation not only in terms of information seeking, but also in terms of other co-occurring cognitive events, including overt response switches and covert changes-of-mind.</p><p>These different families of paradigms developed for studying information seeking vary on several dimensions, particularly the sources of uncertainty (Fleming et al., 2018), the stimuli used (Gesiarz et al., 2019), the desirability of the information to be sought (Hertwig et al., 2021), and the degree of control over information sampled (Desender et al., 2018). These differences have made direct comparisons between paradigms extremely challenging. To date, no study has directly manipulated control over evidence sampling in otherwise aligned experimental conditions.” (p. 3-4)</p><disp-quote content-type="editor-comment"><p>4) Related to the above point, some of the terminology or logical formulation of conclusions was a bit confusing. The authors use the term &quot;information-seeking&quot; specifically to refer to the controllable condition. In the uncontrollable condition, there is no &quot;seeking&quot; of information, only passive sampling. If that understanding is correct, some sentences are redundant. For example, shouldn't the title read &quot;Controllability reveals defining features of information-sampling&quot; or even (and more consistent with the findings) &quot;Controllability over information sampling reveals defining features of changes of mind&quot;? At times &quot;controllability&quot; and &quot;information-seeking&quot; seem to be used interchangeably, while at other times they seem to have different meanings. It would be important to specify those terms better.</p></disp-quote><p>We thank the reviewer for prompting clarification on the concepts manipulated. The reviewer is correct that we consider information seeking to be only possible in the controllable condition, whereas in the uncontrollable condition, only passive sampling occurs. We define controllability as the manipulation created by the experimenter. It is the control over evidence conferred to participants in the controllable experimental condition that renders information seeking possible. We have revised the manuscript so as to use the right terms for the right meaning throughout, and we have now updated Figure 1 about the paradigm to explain the interactions between the different experimental and cognitive events. Hidden-state reversals are determined by the experimenter (“task event”). During an exploratory decision, several steps co-occur: a covert change-of-mind (“cognitive event”) about the expected reward of the current option; an overt response switch (“behavioral event”); and information seeking, i.e., an active search for information about the new option being considered, which is only possible in the C+ condition where participants are in control.</p><p>Accordingly, following upon the reviewer’s suggestion, we have now changed the title of the study to “Controllability boosts neural and cognitive signatures of changes-of-mind in uncertain environments”, a title now focusing more specifically on our results.</p><p>Although we fully agree with the reviewer’s statement that control is necessary for information seeking, other authors have reasoned otherwise, based on other definitions of information seeking. In particular, Monosov and Rushworth distinguish the notions of ‘passive’ and ‘active’ information seeking (Bromberg-Martin and Monosov, 2020 <italic>Current Opinion in Behavioral Science</italic>; Monosov and Rushworth, 2022 <italic>Neuropsychopharmacology</italic>). The authors refer to decision-making tasks under uncertainty, in which non human primates typically can select to sample information about potential rewards, even if the information sampled typically has no direct instrumental value, and does not confer them control over these rewards (e.g., White et al., 2019 <italic>Nat Commun</italic>). Such ‘non instrumental information sampling’ or ‘passive information seeking’ is proposed to be valuable in and of itself if acquiring this information might be useful in the future for guiding behavior – i.e., that might become instrumental later on in the long run. However, our definition of information <italic>seeking</italic> is tightly coupled to the presence of active control, in line with what other authors have proposed (Gureckis and Markant, 2012 <italic>Psychological Science</italic>). We refer to the notion of non-instrumental information <italic>sampling</italic> (not <italic>seeking</italic>) in our Discussion section:</p><p>“Our results are also generally consistent with medial frontal activations during hypothesis testing (for a review, see Monosov and Rushworth, 2022) and in non-instrumental information sampling, where the gathered information affords to predict but does not influence future outcomes.” (Discussion section, p. 24)</p><disp-quote content-type="editor-comment"><p>5) It would greatly help the reader to include a short paragraph in the introduction listing the ways in which this work replicates vs. extends the previous paper by Weiss et al.</p></disp-quote><p>We thank the reviewer for prompting clarity on the respective purpose of each study. The previous paper by Weiss et al., 2021 focused on the physiological analysis of evidence integration within a sequence. We pooled all trials and focused our analyses on the comparison between how participants process evidence when it is a cue (uncontrollable condition) vs. when it is an outcome (controllable condition). We did not focus on the differences between repeat and switch trials in this previous paper.</p><p>In sharp contrast to this previous study, here, we specifically focus on response switches, when participants change their mind about the current hidden state. This focus allows us to study and characterise a moment in which participants seek information in the task. Importantly, for behavioral analyses, we no longer analyse what happens during the course of a sequence of stimuli, we instead take into account the cumulative evidence brought by the whole sequence. Our physiological analyses then focus on studying the contrast between repeat and switch decisions between experimental conditions so as to characterise the neural basis of information seeking. We now clarify the goal of each study in our introduction:</p><p>“We previously used these experimental conditions to compare how participants integrate evidence when it is a cue (uncontrollable condition) vs. when it is an outcome (controllable condition) (Weiss et al., 2021). Here, we focus on the comparison of repeat and switch decisions between these conditions so as to isolate the behavioral signatures and neural basis of information seeking, while replicating most of the previously observed effects in Weiss et al. on behavioral choices and their computational modeling (Weiss et al., 2021).” (p. 4)</p><disp-quote content-type="editor-comment"><p>6) Overall, the introduction is a little thin and would benefit from being expanded. First, the statement that &quot;information-seeking has been mostly studied under 'exploration-exploitation' dilemma is not true – there are many recent studies that have studied information-seeking in humans using other paradigms. Second, and most importantly, the introduction currently lacks the rationale for the proposed work – in addition to dissociating information-seeking from changes-of-mind, which is more of a methodological aim, what are the key questions that the authors trying to address, and what are the hypotheses given the current literature? Finally, the use of MEG and other physiological measures (pupillometric, cardiac patterns) is not motivated at all in the introduction. The introduction should set the stage as to why collecting these data is needed given the question of interest. Similarly, the hypotheses should also set the stage for the specific analysis choices performed later, i.e. in what way does each presented analysis answer the question?</p></disp-quote><p>We thank the reviewer for prompting clarity on the purpose of the study, the motivation for our hypotheses, and the conceptual advances on information seeking processes that the study allows.</p><p>First, we agree with the reviewer that other important previous work has studied information seeking outside of exploitation-exploration dilemmas, which we now review in more depth. In particular, we have identified several families of paradigms tested in human and non-human primates which we now unpack in our introduction, highlighting the similarities and differences with the present paradigm:</p><p>1. A first family of information seeking paradigms are belief updating tasks in which human participants are presented with statements about life events or self-relevant information or judgements from others, and are asked whether they would like to see more information about this (e.g., Sharot et al., 2011 <italic>Nat Neurosci</italic>; Kelly and Sharot, 2021 <italic>Nat Commun</italic>; Gesiarz et al., 2019 <italic>Plos comput biology</italic>). Another “intermediate” study has manipulated not actual controllability, but instructed controllability, i.e., what participants are told about their degree of control (Stolz et al., 2020 <italic>Nature communications</italic>). Typically, these trials are not decision-making under uncertainty but are one-shots, and do not require learning or adaptation unlike in our study and in more continuous and open-ended ecological environments in which information seeking usually occurs. These decisions are described (in the sense of Hertwig and Erev, 2009) with probabilities or uncertainty depicted directly without ambiguity. Another important difference is that the nature of the information proposed varies in its valence and desirability (e.g., Hertwig et al., 2021 <italic>Psychology and Aging</italic>).</p><p>2. A second family of paradigms relies on perceptual decision-making as a model system to study the cognitive and neurobiological mechanisms underlying perceptual changes-of-mind (e.g., Desender et al., 2018 <italic>Psychological Science</italic>; Fleming et al., 2018 <italic>Nat Neurosci</italic>; Rollwage et al., 2020 <italic>Nat Commun</italic>). In these studies, expected uncertainty typically comes from the same source and is manipulated as the amount of sensory noise present in decision evidence. All trials and independent and there is no notion of volatility or reversals to adapt to – no unexpected uncertainty is manipulated.</p><p>3. Non-instrumental information-seeking has been the focus of recent studies in non-human primates (Monosov and Rushworth, 2022 <italic>Neuropsychopharmacology</italic>). In these studies, typically non-human primates are presented with visual cues predicting upcoming rewards, and acquiring information about these cues presents no immediate or direct instrumental value to the animal (e.g., White et al., 2019 <italic>Nat Commun</italic>). These paradigms also include no notion of volatility, with independent trials (no hidden state to track).</p><p>4. In decision-making under uncertainty, finally, a common family of paradigms is bandit tasks in which participants are asked to sample between two or more slot machines so as to maximize gains or rewards, and/or avoid losses or punishments, leading to exploite-explore dilemmas (e.g., Daw et al., 2006 <italic>Nature</italic>; Zorowitz and Niv, 2021 <italic>BioRxiv</italic>; Collins and Frank, 2012 <italic>Eur J of Neurosci</italic>), or other forms of economic decision-making (Kaanders et al., 2021 <italic>J Neuro</italic>; Wilson et al., 2014 <italic>J Exp Psychol Gen</italic>), and foraging (e.g., Kolling et al., 2012 <italic>Science</italic>). The present paradigm follows this line of research but critically moves away from it and explore-exploit dilemmas and instead focus on isolating information seeking from exploratory decisions, i.e., when people change their mind about the reliability of the current strategy and go explore something else.</p><p>These previous families of paradigms vary on many dimensions, in particular the sources of uncertainty sources and the type of stimuli manipulated, which has made their findings’ direct comparison difficult. Critically, none of these previous paradigms has directly manipulated controllability over decision evidence (information acquired). The unique contribution of the present study is to isolate information seeking by contrasting evidence sampling under controllable and uncontrollable conditions, all other decision features such as stimuli and levels and forms of uncertainty being equal.</p><p>Second, the main goal of the study in isolating information seeking from changes-of-mind is much more fundamental than a methodological goal. We have now reworked Figure 1 and included a new panel to explain the different concepts at play in the study. Current protocols proposed to study information seeking in the context of exploitation-exploration trade-offs have important confounds, in that information seeking is virtually always associated with changes-of-mind, meaning that different cognitive steps co-occur that are not specific to information seeking per se. It is an important conceptual distinction that has not been addressed by previous work (although for an exception, see Collins and Koechlin, 2012 <italic>Plos biology</italic>).</p><p>Third, we agree with the reviewer that our physiological hypotheses should be presented early on and we now better motivate our physiological analyses in our introduction section. We sought to evaluate whether there were additional correlates of subjective uncertainty associated with the process of information seeking. Because a switch response engages participants’ sense of agency in the C+ but not in the C- condition, we expected this form of evidence sampling to engage different networks, but it has not been examined in previous work whether these different forms of information seeking rely on separate or similar brain systems.</p><p>We have now rewritten our introduction to reflect this larger background (p. 3-4):</p><p>“In these paradigms, participants evolve in controllable environments and usually sample one among several options to maximize reward. Therefore, they have to either exploit a currently rewarding option, or sacrifice rewards to explore alternative options and seek information about their possible rewards (Rich and Gureckis, 2018; Wilson et al., 2014). This trade-off means that in these paradigms, exploration differs from exploitation not only in terms of information seeking, but also in terms of other co-occurring cognitive events, including overt response switches and covert changes-of-mind.</p><p>These different families of paradigms developed for studying information seeking vary on several dimensions, particularly the sources of uncertainty (Fleming et al., 2018), the stimuli used (Gesiarz et al., 2019), the desirability of the information to be sought (Hertwig et al., 2021), and the degree of control over information sampled (Desender et al., 2018). These differences have made direct comparisons between paradigms extremely challenging. To date, no study has directly manipulated control over evidence sampling in otherwise aligned experimental conditions. At the neurophysiological level, exploration is known to be associated with larger pupil-linked arousal (Jepma and Nieuwenhuis, 2011) and increased activity in lateral prefrontal regions in electroencephalographic (EEG) and blood oxygen-level dependent (BOLD) activity (Donoso et al., 2014; Tzovara et al., 2012). However, due to confounds between information seeking and other cognitive events during exploration in these studies, it remains unclear whether information seeking is associated with specific neurophysiological signatures.”</p><disp-quote content-type="editor-comment"><p>Methods</p><p>7) Was the model fitted to all trials together, or separately for each condition?</p></disp-quote><p>We have now clarified this point in our Methods section (p. 29):</p><p>“All trials were fitted together, but each parameter was allowed to vary between conditions, and we compared the best-fitting parameters using paired t-tests at the group level.”</p><disp-quote content-type="editor-comment"><p>8) The model validation is rigorous, but would the same patterns also be observed out-of-sample? Since only one model is tested, there is always a risk of overfitting, which could be addressed with out-of-sample validation.</p></disp-quote><p>Here, our goal was not to arbitrate between models, but to compare our two conditions under the same model, with parameters between conditions under the same model. This is why we have fitted the same model in both our conditions. We have selected the most parameterised model, with all the free parameters allowed to vary between conditions. Even if we were to be overfitting, this is not an issue here, because our statistics are based on the comparison between best-fitting parameter values across C+ and C- conditions. Overfitting does not inflate the probability of observing significant differences in parameter values across conditions. This is important in order to avoid that parameters’ estimates may be contaminated by variance that is unrelated to the cognitive process each parameter aims to capture. Our approach here is similar to incorporating regressors of no interest in a regression, so as to avoid regressors of interest to capture unrelated variance.</p><p>In addition, the behavioral effects associated with each of our parameters at the group level indicate that overfitting is unlikely here. If we were overfitting, meaning that if one of the parameters was essentially capturing noise, we would not observe consistent effects of a given parameter across participants, as is illustrated in Figure 4 supplement 3 (choice parameters) and Figure 4 supplement 4 (confidence parameters). For example, when we do a median split of participants according to their best-fitting perceived hazard rate, we observe a translation in the repetition curve indicating that the lower the hazard rate, the more inconsistent evidence is needed for participants to change their mind. Had hazard rate captured noise in case of overfitting, we would not observe such a consistent effect at the group level.</p><p>In sum, our assumption that overfitting is very unlikely to have occurred is validated by the fact that each parameter is specifically associated with a given consistent behavioral pattern (Figure 4 supplement 3 and 4), which would not happen if any of these parameters was capturing noise as in the case of overfitting. We now provide more information about our model validation approach and the risk of overfitting in our Methods section (p. 30):</p><p>“Here, we selected the most complete (parameterized) model, even at the risk of overfitting, because our goal was not to arbitrate between different models, but to compare our two conditions and our parameters under the same model. In addition, the behavioral effects associated with each of our parameters at the group level indicate that overfitting is unlikely to have occurred (see ‘Model validation’ below). Indeed, if overfitting had occurred, meaning that if one of the parameters was essentially capturing noise, we would not observe consistent effects of a given parameter across participants (Figure 4 supplement 3 and 4).”</p><disp-quote content-type="editor-comment"><p>9) Please provides the statistics for the validation data presented on p12 (Figure S2 and S3)</p></disp-quote><p>Figure S2 (now Figure 2 supplement 3) provides model simulations from individual best-fitting parameters. Upon the reviewer’s suggestion, we have now performed a full psychometric analysis of these simulation data. Note that the psychometric analysis of model behavior is not as central to our conclusions as that of participants’ behavior. Indeed, the purpose of model validation is to ensure that the model reproduces key <italic>signatures</italic> or behavioral <italic>patterns</italic> present in the human data (Palminteri et al., 2017 <italic>TICS</italic>; Wilson and Collins, 2019 <italic>eLife</italic>), which our model does very well. For the sake of concision, we have therefore included the statistical values for this full psychometric analysis directly into the figure, but we report them below for completeness.</p><p>We observed that the model was slower to adapt after a reversal in the C+ condition, with psychometric fits indicating a higher reversal time constant in this controllable condition (<italic>t</italic><sub>32</sub>=-6.0, <italic>p</italic>=9.5×10<sup>-7</sup>). The model behavior also reached a higher asymptotic reversal rate in the C+ condition (<italic>t</italic><sub>32</sub>=-6.6, <italic>p</italic>=2.0×10<sup>-7</sup>). The model’s simulated confidence decreased after a reversal in both conditions. However, confidence decreased more sharply in the C+ condition as indicated by psychometric fits of a confidence ‘drop’ parameter (<italic>t</italic><sub>32</sub>=5.22, <italic>p</italic>=1.0×10<sup>-5</sup>). The confidence time constant characterizing the slope of confidence increase after a reversal was similar across conditions (paired <italic>t</italic>-test, <italic>t</italic><sub>32</sub>=-0.50, <italic>p</italic>=.62).</p><p>We found a stronger choice-PSE in the C+ condition, as in human data (<italic>t</italic><sub>32</sub>=-8.3, <italic>p</italic>=1.7×10<sup>-9</sup>), together with a similar sensitivity to the evidence, as in human data (<italic>t</italic><sub>32</sub>=0.79, <italic>p</italic>=0.44). Finally, we found a significant confidence-PSE difference between conditions (Wilcoxon signed rank test, <italic>z=</italic>-3.59, <italic>p</italic>=.00033), indicating that the model needed more inconsistent evidence to be equally confident in switch and repeat decisions in the C+ condition, like humans. We also found that the sensitivity of confidence reports to evidence (slope) was slightly smaller in the C+ than in the C- condition on switch decisions, albeit only borderline significant (<italic>t</italic><sub>32</sub>=1.86, <italic>p</italic>=0.07).</p><p>Figure S3 (now Figure 4 supplement 3 and 4) displays the effects of parameters on the four main behavioral signatures, namely, reversal and repetition curves for choice and confidence, from which we only draw qualitative conclusions. The purpose of these figures is only to visualise the selective effects of each of our free parameters. We do not perform any group inference or statistical analyses at the group level from these analyses. We now make this point clear in our Methods section (p. 30-31):</p><p>“We also performed a median split across participants on the best-fitting parameter values (Figure 4 supplement 3 and 4). We then averaged simulations of the model for each subgroup, to further illustrate the independent contribution of each of these parameters. Note that we do not draw group inferences from these median split analyses – the goal is to visualise the effect of each of the parameters qualitatively.”</p><disp-quote content-type="editor-comment"><p>10) How recoverable are the parameters if the model is re-fit to simulated data?</p></disp-quote><p>We have now performed a full parameter recovery analysis, as described in our Methods section (p. 29):</p><p>“To ensure that our fitting procedure was unbiased, we performed a parameter recovery analysis (Figure 4 supplement 1). We simulated choice and confidence sequences using generative parameters randomly sampled in a uniform distribution between the minimum and maximum of participants’ best-fitting parameter values in each condition. This procedure ensures that generative parameters were independently sampled. We then fitted these data using the same fitting procedure as for participants (except with three instead of five random starting points) and calculated the correlations between generative and recovered parameters, presented in a confusion matrix (Figure 4 supplement 1).”</p><p>We now provide these results in a new Figure 4 supplement 1.</p><p>We found a satisfactory parameter recovery, indicating that our fitting procedure was reliable, as explained in our Results section (p. 12):</p><p>“Importantly, we also established that our fitting procedure provided a satisfactory parameter recovery (see Methods). All correlations between generative and recovered parameters were high (all rho&gt;0.78, all p&lt;1014), while other correlations were low as indicated in a confusion matrix (Figure 4 supplement 1).”</p><disp-quote content-type="editor-comment"><p>11) Are parameters correlated with each other? The authors should provide a correlation table of the parameters in the supplement.</p></disp-quote><p>We have now inspected the correlation between our five model parameters. Apart from a significant negative correlation between inference noise and hazard rate (rho=-0.51, <italic>p</italic>=.0025), and a borderline negative correlation between confidence threshold and hazard rate (rho=-0.36, <italic>p</italic>=.0409), no other correlations were significant (all rho&lt;0.31, all <italic>p</italic>&gt;.074) (<italic>N</italic>=33 participants, individual best-fitting parameters averaged between conditions). We now provide a correlation matrix of parameters as a new Figure 4 supplement 2:</p><p>We also provide these findings in our Results section and comment on their implications (p. 14):</p><p>“We further validated the independent role of each parameter in two ways. First, we examined correlations between best-fitting parameters across participants (Figure 4 supplement 2). We found a significant negative correlation between inference noise and hazard rate (rho=-0.51, p=.0025), in line with a previously reported trade-off between these two sources of noise (Weiss et al., 2021). We also found a borderline correlation between confidence threshold and hazard rate (rho=-0.36, p=.0409). However, all other correlations were not significant (all rho&lt;0.31, all p&gt;.074), indicating that each parameter captured independent portions of the variance (Figure 4 supplement 2). Second, we did a median-split of participants into groups of high and low parameter values (Figure 4 supplement 3 and 4), each parameter having a selective influence on choices and confidence. Even when parameters were similar across conditions (e.g. confidence gain), there was still a substantial inter-individual variability that had a visible effect on participants’ confidence, indicating the necessity of each parameter in capturing qualitative signatures participants’ choices and confidence. Although the model allows for potentially distinct effects between inference noise and hazard rate, here, our participants happened to be distributed along a particular regime, with no independence between these two parameters, as visible in similar effects of lower inference noise and higher hazard rate on behavior (Figure 4 supplement 3), in line with their negative correlation.”</p><p>“We examined correlations of the best-fitting parameters averaged across conditions between participants (Figure 4 supplement 2)”. (Methods section, p. 29)</p><disp-quote content-type="editor-comment"><p>Results</p><p>12) It would help to preview the specific diagnostic effects that isolate the process of interest, and then to repeat those in the model fit. Currently, we see four effects in Figure 2, four effects in Figure 3, and three effects in Figure 4. When we get to Figure 5D, slightly different effects are presented in comparison to the model. This was quite confusing and more clarity is required about the specific behavioral pattern of interest. This may just be a matter of slight reordering: the supplement has clear model-data matches, and placing those in the main figure (to highlight that most of the basic effects in Figures2-4 are indeed explained by the model) would allow a better appreciation of where the model fails to capture human behavior.</p></disp-quote><p>We thank the reviewer for prompting clarity on the specific behavioral signatures that are key to diagnose the model validity and have now fully reorganised our figures accordingly. We have now grouped ex. Figure 2 and Figure 3 into a single figure with the four key curves and the corresponding psychometric parameters (new Figure 2). To allow for an easy comparison between human and model behaviours, we now have the model validation in a figure aligned with the same signature patterns.</p><p>Upon the reviewer’s suggestion, we have separated the ex. Figure 5C and 5D in a new separate Figure 5 to isolate where the model fails to capture human behavior. We hope that this reorganisation now allows to appreciate the similarities between model and human behavior and between experiments.</p><disp-quote content-type="editor-comment"><p>13) (see also (2) above) The data in Figure S1 are a crucial control, but it is not yet clear that there is no substantial difference in pro- vs. retro-spective decisions, which might (partially) explain the Cb vs. Ob differences. If controllability was the only important factor for behavioral effects, wouldn't we expect no difference between conditions in Figure S1? This would require a change in the authors' strength of interpretation as specifically pertaining to control.</p></disp-quote><p>We agree with the reviewer that the strength of our conclusions on the nature of the difference between the C- and C+ conditions, whether controllability or temporal orientation (prospective vs. retrospective), need to be aligned with the evidence provided and we now nuance our interpretations. We refer the reviewer to our detailed response to the main comment 2.</p><p>Briefly, we now also present the choice data in addition to the confidence data from Experiment 3. Critically, the findings of Experiment 3 reveal that the nature and magnitude of the contrast between retrospective and prospective conditions is different from the contrast between the original C- and C+ conditions, and therefore cannot account for them as an overall explanation of the results; however, a remaining effect of temporal direction of the inference might still be present in the C- vs. C+ conditions, which we now acknowledge:</p><p>“Furthermore, we sought to validate controllability as the true cause of differences between conditions. In Experiment 3, we examined whether a distinction in temporal focus (prospective instead of retrospective inference in an uncontrollable context) would account for the differences between the original conditions (Figure 2 supplement 1). Although the pattern of choices was markedly different, for confidence it remains possible that a lingering effect of temporality affected the original conditions, even if it cannot account for the results overall.” (Discussion section, p. 23)</p><disp-quote content-type="editor-comment"><p>14) Do the analyses in Figure 4 control for the difference in objective evidence (logL per trial)?</p></disp-quote><p>We controlled indeed for the strength of evidence provided by the sequence of stimuli in Figure 2G-2H for the data presented in (ex)Figure 4A (now Figure 3). In other words, Figure 4A presents the same data as Figure 2G but pooled across evidence strength levels. However, because in Figure 4A predictors would be binary, i.e., repeat and switch, and C- and C+ conditions, we considered that an ANOVA was the most relevant and appropriate test here. Unfortunately, too few events per cell are included in Figure 4B and 4C to further be able to do a breakdown as a function of evidence strength in bins, as we did for confidence in Figure 4A. Moreover, it is worth noting that the observed effects are in the opposite direction of what we would expect if evidence strength was a confound. Indeed, we found that in the C+ condition, participants need more evidence to switch, which should lead to higher confidence (more evidence =&gt; more confidence). Instead, we found a <italic>reduced</italic> confidence on switch decisions in the C+ condition.</p><p>Regarding Figure 4B and 4C (now Figure 3B and 3C), these analyses do not control for variations in objective evidence. Data for these analyses cannot be further split further as a function of objective evidence due to a low number of events corresponding to each case (cell) studied: as expected, there was not a homogenous amount of evidence leading all of these events. For instance, participants would rarely confirm a change-ofmind with high confidence if it was based on very little objective evidence.</p><p>Note, however, that by design, the objective evidence level was matched across conditions on average, and that the PSE psychometric analyses take into account the objective evidence – instead, Figure 4 focuses on the consequences of response switches on participants’ subsequent behaviour.</p><p>We now clarify this point in our Methods section (p. 29):</p><p>“In a 2 × 2 repeated measures ANOVA, we examined the influence of RESPONSE TYPE (repeat, switch) and CONDITION (C-, C+) on the fraction of high confidence responses (Figure 3A, which corresponds to the same data as Figure 2G pooled over objective evidence levels). For switch trials, we further examined confidence on switch trials that were confirmed on the next trial (“change-of-mind confirmed”) as compared to switch trials after which participants went back to their previous response (“change-of-mind aborted”; Figure 3B). Finally, we examined the fraction of changes-of-mind confirmed (over all changes-of-mind) as a function of whether the change-of-mind was done with high or low confidence (Figure 3C). These analyses are pooled over objective evidence levels due to each of these events not being distributed homogeneously across evidence levels.”</p><p>Upon the reviewer’s suggestion, we have now performed a logistic regression to take into account strength of evidence. Specifically, we included the trial-by-trial evidence strength in favour of the previous response as a co-regressor:</p><p>Confidence(t) (high/low) ~ Response type(t) (repeat/switch) + Condition(t) (C-/C+) + Response type(t)*Condition(t) + Evidence level(t)</p><p>and</p><p>Confidence(t) (high/low) ~ change-of-mind(t) (confirmed/aborted) + Condition(t) (C-/C+) + change-ofmind(t)*Condition(t) + Evidence level(t)</p><p>We implemented a regularised logistic regression with gaussian priors on each regression coefficient (mean=0, SD=2) in order to account for the fact that some of our participants have few events per cell, which otherwise led to unreliable regression coefficient estimates.</p><p>The results are in line with our initial model-free analysis (original Figure 4A). Namely, repeat trials led to higher confidence (<italic>t<sub>32</sub></italic>=7.66, <italic>p</italic>=9.8×10<sup>-9</sup>), confidence was higher in the C- than in the C+ condition (<italic>t<sub>32</sub></italic>=4.05, <italic>p</italic>=.00029), with a significant interaction between Response type and Condition factors (<italic>t<sub>32</sub></italic>=-4.43, <italic>p</italic>=.0001), while controlling for evidence level in the same regression model, which positively contributed to confidence, as expected (<italic>t<sub>32</sub></italic>=14.69, <italic>p</italic>=8.8×10<sup>-16</sup>) (Figure 3 supplement 1A).</p><p>Likewise, in a logistic regression we have controlled for evidence strength in the analysis relating confidence to whether the change-of-mind of the previous trial was confirmed or aborted (related to original Figure 4B). The results confirm model-free observations, with participants overall being more confident when they confirm than when they abort a change-of-mind (<italic>t<sub>32</sub></italic>=5.49, <italic>p</italic>=4.6×10<sup>-6</sup>), also more confident in the C- than in the C+ condition (<italic>t<sub>32</sub></italic>=3.92, <italic>p</italic>=.0004), with a significant interaction between these factor (<italic>t<sub>32</sub></italic>=-3.38, <italic>p</italic>=.0019), while controlling for evidence level (<italic>t<sub>32</sub></italic>=11.9, <italic>p</italic>=2.49×10<sup>-13</sup>) (Figure 3 supplement 1B).</p><p>We also computed, for each of the cases, the average evidence quantity in favour of the participant’s previous response, and compared the obtained interactions patterns to those obtained in the original Figure 4 (Figure 3 supplement 1C-D). If the interaction patterns are different from the original results, it means that the original results cannot be explained away by differences in evidence level.</p><p>In a 2 × 2 ANOVA on mean evidence level, as expected, we found a main effect of RESPONSE TYPE, F<sub>1,32</sub>=147.8, <italic>p</italic>=1.6x10<sup>-13</sup>, because negative evidence will lead participants to switch from their previous response. We found a higher overall evidence level in the C+ than in the C- conditions (main effect of CONDITION, F<sub>1,32</sub>=6.19, <italic>p</italic>=.018). We observed a significant interaction between RESPONSE TYPE and CONDITION (F<sub>1,32</sub>=57.1, <italic>p</italic>=1.3x10<sup>-8</sup>), indicating that in the C+ condition, participants have seen more evidence against their previous choice when they switch their response than in the C- condition, in line with choice-PSE results. Having seen more evidence, we would expect them to be <italic>more</italic> confident, whereas they actually are <italic>less</italic> confident in that condition (original Figure 4A). Therefore, these findings provide further evidence that the strength of evidence does not explain away our results on confidence in response switches.</p><p>Moreover, evidence levels were higher on trials in which switch decisions were confirmed as compared to aborted (F<sub>1,32</sub>=264.2, <italic>p</italic>&lt;.001). There was no main effect of CONDITION (F<sub>1,32</sub>=0.67, <italic>p</italic>=.41), with an interaction between CONDITION and CONFIRM-ABORT factors (F<sub>1,32</sub>=42.6, <italic>p</italic>=2.3x10<sup>-7</sup>) (Figure 3 supplement 1B). This pattern reflects that evidence level partly contributes to confidence reports, but is markedly different from the patterns observed for the fraction of high confidence responses (original Figure 4B).</p><p>In the case of original Figure 4C, we have displayed proportions, namely, the fraction of changes-of-mind confirmed out of the total changes-of-mind performed with high confidence and low confidence respectively. For this reason, we cannot compute a mean evidence level in each of the four cases in original Figure 4C. Instead, to take into account evidence level, we can compare the mean evidence level on (i) changes-ofmind performed with high confidence and then confirmed, (ii) performed with low confidence and then confirmed, (iii) performed with high confidence and then aborted, and (iv) performed with low confidence and then aborted, separately for the two conditions so a total of 8 cells. However, data for these analyses cannot be further split further as a function of evidence due to a low number of events corresponding to each case (cell) studied: as expected, there was not a homogenous amount of evidence leading all of these events. For instance, participants would rarely confirm a change-of-mind with high confidence if it was based on very little objective evidence. Likewise, a logistic regression would not be appropriate if we have too few data points, as in the case of the original Figure 4C. Note, however, that by design, the objective evidence level was matched across conditions on average, and that the PSE psychometric analyses take into account the objective evidence – instead, Figure 4 focuses on the consequences of response switches on participants’ subsequent behaviour.</p><p>We now clarify this point in our Methods section (p. 29):</p><p>“In a 2 × 2 repeated measures ANOVA, we examined the influence of RESPONSE TYPE (repeat, switch) and CONDITION (C-, C+) on the fraction of high confidence responses (Figure 3A, which corresponds to the same data as Figure 2G pooled over objective evidence levels). For switch trials, we further examined confidence on switch trials that were confirmed on the next trial (“change-of-mind confirmed”) as compared to switch trials after which participants went back to their previous response (“change-of-mind aborted”; Figure 3B). Finally, we examined the fraction of changes-of-mind confirmed (over all changes-of-mind) as a function of whether the change-of-mind was done with high or low confidence (Figure 3C). These analyses are pooled over objective evidence levels due to each of these events not being distributed homogeneously across evidence levels.”</p><p>We also include these new logistic regressions controlling for evidence level in our revised manuscript:</p><p>“To take into account any effects of evidence strength in these change-of-mind analyses, we further performed two logistic regressions (Figure 3 supplement 1A-B). First, we aimed to predict confidence using Response type, Condition, their interaction, and trial-by-trial evidence strength in favour of the previous response as a co-regressor (related to Figure 3A). Second, we aimed to predict confidence using change-ofmind (confirmed vs. aborted), Condition, their interaction, and trial-by-trial evidence strength in favour of the previous response (related to Figure 3B). We implemented regularised logistic regressions with gaussian priors on each regression coefficient (mean=0, SD=2) in order to account for the fact that some of our participants have few events per cell, which otherwise led to unreliable regression coefficient estimates. Group-level significance of regression coefficients was assessed using one-sample t-tests. We also computed the average evidence quantity in favour of the participant’s previous response, and compared the obtained interactions patterns to those obtained in the change-of-mind analyses in Figure 3 (Figure 3 supplement 1C-D).” (Methods section, p. 31)</p><p>“A logistic regression confirmed these results (see Methods). Repeat trials led to higher confidence than switch decisions (t<sub>32</sub>=7.66, p=9.8×10<sup>-9</sup>), confidence was higher in the C- than in the C+ condition (t<sub>32</sub>=4.05, p=.00029), with a significant interaction between RESPONSE TYPE and CONDITION (t<sub>32</sub>=-4.43, p=.0001), while controlling for evidence level in the same regression model, which positively contributed to confidence, as expected (t<sub>32</sub>=14.69, p=8.8×10<sup>-16</sup>) (Figure 3 supplement 1A).” (Results section, p. 11)</p><p>“A logistic regression confirmed these results (see Methods), with participants overall being more confident when they confirm than when they abort a change-of-mind (t<sub>32</sub>=5.49, p=4.6×10<sup>-6</sup>), also more confident in the C- than in the C+ condition (t<sub>32</sub>=3.92, p=.0004), with a significant interaction between these factor (t<sub>32</sub>=-3.38, p=.0019), while controlling for evidence level (t<sub>32</sub>=11.9, p=2.49×10<sup>-13</sup>) (Figure 3 supplement 1B). Moreover, while these results indicate that evidence partly contributes to confidence, as expected, the patterns of evidence strength were markedly different from those of changes-of-mind (compare Figure 3A-B to Figure 3 supplement 1C-D).” (Results section, p. 12)</p><disp-quote content-type="editor-comment"><p>15) It is frequently stated that the Ob condition bestows instrumental control to participants over the sampling of stimuli. These statements should be modified, given that participants are told which category of stimulus they must generate. They do not have complete control over which stimuli they sample, unless they are willing to upset the experimenter!</p></disp-quote><p>The reviewer is correct that the control is indeed over the category of stimuli produced, not over each stimulus in the sequence itself. In other words, participants have control / can decide over which stimulus to sample (left or right action in the controllable condition), although they do not have control over the target category, i.e., the generative category from which samples are drawn.</p><p>Controllability is a property of this C+ (ex. Ob) condition, in which participants have a goal, just like in classic n-arm bandit task. It is not a forced choice but they are asked to produce stimuli from a particular target category; in that sense, it is not a pure free sampling but goal-directed sampling. We have now clarified this point in our Methods section (p. 27):</p><p>“In the controllable (C+) condition, participants were instructed to draw stimuli from a given category (Figure 1C). An instruction screen indicated the target color category for each block (counterbalanced across blocks). In the C+ condition, participants have control over which stimuli to sample, but are not fully freely sampling, since they asked to produce stimuli from a target color category.”</p><disp-quote content-type="editor-comment"><p>16) It is not clear what action participants perform to start the trial in the Ob condition. This needs including. In outlining this it would also be great to include consideration of potential overlaps between the responses at the start and end of the trial in Ob, and whether this might have played into the effects.</p></disp-quote><p>In both conditions, participants perform exactly only one motor action per trial. In the very beginning of a block of trials of the C+ condition, participants are asked to perform a random action to initiate the very first sequence of stimuli, as they have no idea yet of what the current mapping of categories is. In the C- condition, similarly, participants are asked to initiate the block of trials by performing a random action. Therefore, the first response required before having seen any sequence is random in both conditions, so that motor actions are precisely aligned between the C+ and C- conditions.</p><p>We now clarify this point in our Results (p. 5) and Methods (p. 26-27) sections:</p><p>“In-between each sequence, participants were asked to provide a response regarding the current hidden state of the task, together with a binary confidence estimate in their response (high or low confidence) using four response keys (Figure 1B). […] In both conditions, participants perform one action per trial.” (p. 5)</p><p>“The conditions were otherwise fully symmetric, tightly matched in terms of visual and motor requirements. In both conditions, participants perform one action per sequence (after seeing a sequence in the C- condition, before seeing a sequence in the C+ condition).” (p. 26-27)</p><disp-quote content-type="editor-comment"><p>17) Please add the change-of-mind data (i.e. equivalent of Figure 2A-B and 3A-B) for experiment 3, so it is possible to dissociate which effects are unique to the main experiment and which effects may be due to the temporal direction of the decisions. It is important to clarify this distinction as it can actually help narrow down the unique effect of controllability over temporality.</p></disp-quote><p>We have now added the choice psychometric analysis (equivalent of ex Figure 2A-B, adapted from Weiss et al., 2021) and the confidence psychometric analysis (equivalent of ex Figure 3A-B) in a new Figure 2 supplement 1 (printed in response to comment 2). We fully agree with the reviewer about the importance of isolating the unique effect of controllability over temporality using Experiment 3, and we refer the reviewer to our responses to comment (2) that addresses this point in depth.</p><disp-quote content-type="editor-comment"><p>18) It would be useful to provide follow-up analyses to determine how much of the behavioral results can be explained by the difference in prior belief reported on p19, as well as discuss how much of these findings are then more consistent with a role of controllability per se, rather than a role for motivated beliefs/confirmation bias due to the presence of a target.</p></disp-quote><p>We agree with the reviewer that these notions are related, and we now provide a number of pieces of evidence in our data that speak against an interpretation in terms of confirmation bias or motivated beliefs.</p><p>First, by using a computational model, we seek to provide a mechanistic explanation for our observed behavioral effects. Specifically, stronger prior beliefs are actually what will <italic>produce</italic> the effects we see. Controllability is only a high-level notion manipulated by the experimenter, while the computational model has no notion of controllability built into it. But by fitting the computational model to participants’ data in the two controllability conditions, the model happens to explain participants’ choices and confidence by the presence of stronger prior beliefs in the controllable (C+) condition. It is those stronger prior beliefs that produce behavior, not the other way around.</p><p>Second, Experiment 2B also addresses this point to some extent. In Experiment 2B, the target goal is not constant during a block and varies between trials. This means that if confirmation bias were an explanation for the findings, the direction of the confirmation bias would change from one trial to the next, and its impact on behaviour should therefore decrease.</p><p>Third, at the neural level, in our previous study, we have argued that “the strength of belief-inconsistent evidence could be decoded [from MEG signals] with equal precision across conditions”, something at odds with a confirmation bias which would decrease the weighting of belief-inconsistent evidence. Instead, we found an absence of difference between the neural coding of belief-consistent and belief-inconsistent evidence.</p><p>Fourth, at the behavioral level, the reviewer is correct that a confirmation bias in the C+ would be associated with an increased choice-PSE, which we observe in the data. Confirmation bias has previously been defined as a selective weighting of belief-consistent evidence (Bronfman et al., 2015 <italic>Proc R Soc B</italic>; Peters et al., 2017 <italic>Nat human behaviour</italic>; Talluri et al., 2018 <italic>Current Biol</italic>).</p><p>However, a confirmation bias in the C+ condition would also be accompanied by a significant decrease in the sensitivity to the objective evidence in the C+ condition, an aspect that is absent from the human data (Figure 2). Indeed, a confirmation bias would predict that in the C+ condition, the evidence used by the participant is not the objective evidence, but a biased subjective representation of the evidence where the inconsistent evidence is underweighted relative to the consistent evidence. Hence, sensitivity to the objective evidence (measured as our psychometric parameter) would be decreased in the presence of a confirmation bias in the C+ condition. In other words, we have considered the objective evidence with respect to participants’ previous response (Figure 2E-H) as a key relevant variable for decision-making, but if participants use irrelevant or wrong variables (e.g., confirmation bias), it should have produced a degraded sensitivity to the objective evidence (Beck et al. 2012 <italic>Neuron</italic>).</p><p>To falsify more directly a confirmation bias explanation, we have conducted a new analysis. We fitted the differences in response reversal and response repetitions curves (Figure 2) between the C- and C+ conditions in Experiment 4 using two alternative accounts: 1. a change in perceived hazard rate in the C+ condition, and 2. a confirmation bias in the C+ condition (controlled by a gain parameter assigned to belief-inconsistent evidence). As expected, a change in perceived hazard rate produced a minimal change in the sensitivity to evidence which matched human data (interaction with participants: F<sub>1,23</sub>=0.4, <italic>p</italic>=0.54). In contrast, a confirmation bias produced a substantial decrease in the sensitivity to evidence in the C+ condition which did not match human data (interaction with participants: F<sub>1,23</sub>=10.0, <italic>p</italic>=.004). This interaction ‘falsifies’ (in the meaning of Palminteri et al., 2017 <italic>TICS</italic>) the most standard account of confirmation bias.</p><p>We now provide evidence to rule out this alternative explanation in terms of “confirmation bias” in our Discussion section (p. 23-24):</p><p>“Despite stimuli carrying no explicitly affective or rewarding value, it remains possible that the mere presence of a target in the C+ condition makes the target category desirable, and may produce a form of confirmation bias (Talluri et al., 2018). However, at the behavioral level, a confirmation bias would predict that in the controllable condition, the sensitivity to evidence should be degraded when the sequence of evidence is inconsistent with participants’ previous choice, a prediction that is absent from human data (Figure 2). At the neural level, a confirmation bias would decrease the weighting of belief-inconsistent evidence. Instead, in our previous study, we found an absence of difference between the neural coding of belief-consistent and belief-inconsistent evidence (Weiss et al., 2021). In addition, the findings of Experiment 2B, where the target category changes from trial to trial, also mean that the differences between conditions are unlikely to reflect a bias in direction of the target category (Gesiarz et al., 2019). Indeed, the direction of this bias would change from one trial to the next, and should therefore decrease in Experiment 2B – which we did not observe.”</p><disp-quote content-type="editor-comment"><p>Discussion</p><p>19) There is some concern about the interpretation of the results – in particular, whether the observed differences between the cue-based and outcome-based conditions could be better explained by the presence of a target-induced confirmation bias in the outcome-based condition, which would induce a strong motivation to confirm that the chosen action does lead to the target. In other words, it is possible that having a target (e.g. &quot;draw orange&quot;) may bias subjects towards believing they are drawing from that target even when they are not, and as a result needing less evidence to reach that conclusion (similar to the effect shown in Gesiarz, Cahill and Sharot, 2019, Plos Computational Biology). This could in turn lead to the observed patterns of results, i.e. needing more evidence against orange to switch, being less confident when switching etc. Additionally, the result that prior beliefs are stronger in the Ob condition (p18-19) is consistent with this idea, since confirmation bias is usually associated with stronger prior beliefs.</p></disp-quote><p>We would like to refer the reviewer to the series of arguments in response to comment (18), which we hope have thoroughly addressed the alternative explanation of a confirmation bias producing our pattern of results.</p><p>We also note that the types of motivated beliefs in the paradigm of Gesiarz et al., 2019 are beliefs that are associated with desirable states: one prefers to be in a state with greater rewards than losses rather than the other way around. In contrast, here, participants had no particular reason to be more motivated that the blue or the orange category of perceptual stimuli is the current hidden state. Moreover, no reward or losses were manipulated explicitly, for instance using monetary outcomes. No notion of valence or affective value is different between the C- and C+ conditions, or between the blue and orange generative categories, unlike in other confirmation bias paradigms where stimulus statements carry a strong affective content (e.g., Sharot et al., 2011 <italic>Nat Neurosci</italic>).</p><p>Nevertheless, it remains possible that the mere presence of a target category in the C+ condition could constitute a goal and create desirability to find more evidence in favour of that target category (Castagnetti et al., 2021 <italic>Sci Advances</italic>); however, as detailed in response to the previous comment, this would have translated into specific effects which we do not observe.</p><p>We now unpack this point in our Discussion section (p. 24):</p><p>“Despite stimuli carrying no explicitly affective or rewarding value, it remains possible that the mere presence of a target in the C+ condition makes the target category desirable, and may produce a form of confirmation bias (Talluri et al., 2018). However, at the behavioral level, a confirmation bias would predict that in the controllable condition, the sensitivity to evidence should be degraded when the sequence of evidence is inconsistent with participants’ previous choice, a prediction that is absent from human data (Figure 2). At the neural level, a confirmation bias would decrease the weighting of belief-inconsistent evidence. Instead, in our previous study, we found an absence of difference between the neural coding of belief-consistent and belief-inconsistent evidence (Weiss et al., 2021). In addition, the findings of Experiment 2B, where the target category changes from trial to trial, also mean that the differences between conditions are unlikely to reflect a bias in direction of the target category (Gesiarz et al., 2019). Indeed, the direction of this bias would change from one trial to the next, and should therefore decrease in Experiment 2B – which we did not observe.”</p><disp-quote content-type="editor-comment"><p>20) The authors claim that there is a causal role for confidence in controlling changes-of-mind (p11). While this is an interesting idea, it is not clear that it can be fully evidenced in this task without an experimentally-controlled manipulation of confidence. The reason is that there could be a common cause to both high confidence and high propensity to confirm switch decisions without the two processes actually being causally related. One such common cause could be the strength of evidence. Therefore, this conclusion needs to be tempered and this issue mentioned in the discussion.</p></disp-quote><p>We agree with the reviewer about the existence of a common cause being possible. Note that we do take into account the strength of the evidence, one of such possible common causes, in our analyses on confidence (Figure 3, now Figure 2G-H). We would also like to refer the reviewer to our response to comment (14) and (xiii), in which we provide new analyses taking into account the strength of evidence, which shows consistent results. Here, in writing “a role for confidence”, we meant causality in a weak sense: the sense of temporal precedence. Yet, because we have not performed a direct causal manipulation of confidence here, we now have now tempered the claims associated with these findings in our Results section, paragraph ‘Separable effects of confidence and controllability on changes-of-mind’:</p><p>‘A possible role for confidence in changes-of-mind’ (title of Figure 3, p. 11)</p><p>‘We found a main effect of CONFIDENCE on the fraction of switches confirmed (F<sub>1,27</sub>=30.4, p=7.8×10<sup>-6</sup>), meaning that participants confirmed their switch more often when it was made with high confidence. This suggests a causal role for confidence in controlling changes-of-mind, even though we acknowledge that there was no experimentally causal manipulation of confidence here.’ (p. 12)</p><disp-quote content-type="editor-comment"><p>21) There is no discussion of alternative ways in which these data might have turned out. The discussion entirely reports claims and findings with which the present data are consistent. Are there no data or theories that could have led to alternative predictions? Currently the manuscript portrays the impression of such high consensus that there was little point running the studies, suggesting that the empirical patterns to date all point in identical directions. One possibility is that the stimulus ISIs are not very variable. Given participants can perceive better at certain oscillatory phases of visual processing (peaks), could they choose to start trials in Ob to align with peaks and thereby improve perceptual acuity? If this occurred, the influence must be weaker than those pulling in the opposite direction, but it could have led to an alternative outcome. If it's a straightforward analysis to perform/report, it may be interesting to see how the oscillations align with events differentially in Ob and Cb.</p></disp-quote><p>The purpose of the present study was to examine changes-of-mind in controllable and uncontrollable while otherwise comparable conditions, an endeavor that has not been examined before, to the best of our knowledge. It was not an easy or a given or trivial observation that the results turned out the way they have: indeed, information seeking has been mostly studied in separate fields of the decision-making literature, among which for instance:</p><p>(i) in the context of perceptual decision-making tasks, where participants are presented with evidence over which they have no control (e.g., Desender et al., 2018 <italic>Psychological Science</italic>);</p><p>(ii) in the context of belief update paradigms, where the information to be acquired is controllable and the proposed information typically varies in its desirability (e.g., Gesiarz et al., 2019 <italic>Plos computational biology</italic>); (iii) in the context of value-based decision-making tasks, where participants have control over options sampled (e.g., Daw et al., 2006 <italic>Nature</italic>).</p><p>It had not been investigated whether the different forms of information sampling at play would be similar or turn out to be different in controllable and uncontrollable environments, which we could investigate in the present paradigm. We have now highlighted this in our Introduction section (p. 3-4):</p><p>“In these paradigms, participants evolve in controllable environments and usually sample one among several options to maximize reward. Therefore, they have to either exploit a currently rewarding option, or sacrifice rewards to explore alternative options and seek information about their possible rewards (Rich and Gureckis, 2018; Wilson et al., 2014). This trade-off means that in these paradigms, exploration differs from exploitation not only in terms of information seeking, but also in terms of other co-occurring cognitive events, including overt response switches and covert changes-of-mind.</p><p>These different families of paradigms developed for studying information seeking vary on several dimensions, particularly the sources of uncertainty (Fleming et al., 2018), the stimuli used (Gesiarz et al., 2019), the desirability of the information to be sought (Hertwig et al., 2021), and the degree of control over information sampled (Desender et al., 2018). These differences have made direct comparisons between paradigms extremely challenging. To date, no study has directly manipulated control over evidence sampling in otherwise aligned experimental conditions. At the neurophysiological level, exploration is known to be associated with larger pupil-linked arousal (Jepma and Nieuwenhuis, 2011) and increased activity in lateral prefrontal regions in electroencephalographic (EEG) and blood oxygen-level dependent (BOLD) activity (Donoso et al., 2014; Tzovara et al., 2012). However, due to confounds between information seeking and other cognitive events during exploration in these studies, it remains unclear whether information seeking is associated with specific neurophysiological signatures.”</p><p>Regarding the alternative interpretation proposed by the reviewer, it is important to note that in both conditions, participants’ key presses trigger the presentation of the next sequence of stimuli after the same jitter delay in the two conditions. Therefore, participants could align their perceptual acuity with the stimuli equally well in the two conditions. Nevertheless, it is also important to note that stimuli are presented at 2 Hz, a rate that is sufficiently low to perceive stimuli properly. Here, the difficulty is to integrate, i.e., infer, the category source properly, despite perceiving stimuli easily. In other words, stimuli are of high contrast, they are not masked, and they are presented for sufficient time. Therefore, the cognitive bottleneck in our experiment is not on sensory processing, but on inference (see Drugowitsch et al., 2016 <italic>Neuron</italic> for an extensive decomposition of decision variability in terms of sensory, inference and action selection sources of variability).</p><p>We now clarify this point in our Methods section (p. 29):</p><p>“Stimuli were displayed at an average rate of 2 Hz with an inter-stimulus interval of 500 ± 50 ms. This rate is sufficiently low to perceive stimuli properly; here, the cognitive bottleneck was not on sensory processing, but on inference (Drugowitsch et al., 2016 Neuron). The last stimulus of each sequence was followed by a longer delay of 1000 ± 50 ms, before participants were probed for their response.”</p></body></sub-article></article>