<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">72331</article-id><article-id pub-id-type="doi">10.7554/eLife.72331</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Medicine</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Virtual mouse brain histology from multi-contrast MRI via deep learning</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-246776"><name><surname>Liang</surname><given-names>Zifei</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-189556"><name><surname>Lee</surname><given-names>Choong H</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-189554"><name><surname>Arefin</surname><given-names>Tanzil M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-246777"><name><surname>Dong</surname><given-names>Zijun</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-246778"><name><surname>Walczak</surname><given-names>Piotr</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-167008"><name><surname>Shi</surname><given-names>Song-Hai</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-246779"><name><surname>Knoll</surname><given-names>Florian</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-246780"><name><surname>Ge</surname><given-names>Yulin</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-246781"><name><surname>Ying</surname><given-names>Leslie</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-189558"><name><surname>Zhang</surname><given-names>Jiangyang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0740-2662</contrib-id><email>jiangyang.zhang@nyulangone.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Bernard and Irene Schwartz Center for Biomedical Imaging, Department of Radiology, New York University School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04rq5mt64</institution-id><institution>Department of Diagnostic Radiology and Nuclear Medicine, University of Maryland</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02yrq0923</institution-id><institution>Developmental Biology Program, Sloan Kettering Institute, Memorial Sloan Kettering Cancer Center</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01y64my43</institution-id><institution>Departments of Biomedical Engineering, Electrical Engineering, University at Buffalo, the State University of New York</institution></institution-wrap><addr-line><named-content content-type="city">Buffalo</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Jbabdi</surname><given-names>Saad</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>28</day><month>01</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e72331</elocation-id><history><date date-type="received" iso-8601-date="2021-07-20"><day>20</day><month>07</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-01-27"><day>27</day><month>01</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2020-05-03"><day>03</day><month>05</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.05.01.072561"/></event></pub-history><permissions><copyright-statement>Â© 2022, Liang et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Liang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-72331-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-72331-figures-v2.pdf"/><abstract><p><sup>1</sup>H MRI maps brain structure and function non-invasively through versatile contrasts that exploit inhomogeneity in tissue micro-environments. Inferring histopathological information from magnetic resonance imaging (MRI) findings, however, remains challenging due to absence of direct links between MRI signals and cellular structures. Here, we show that deep convolutional neural networks, developed using co-registered multi-contrast MRI and histological data of the mouse brain, can estimate histological staining intensity directly from MRI signals at each voxel. The results provide three-dimensional maps of axons and myelin with tissue contrasts that closely mimic target histology and enhanced sensitivity and specificity compared to conventional MRI markers. Furthermore, the relative contribution of each MRI contrast within the networks can be used to optimize multi-contrast MRI acquisition. We anticipate our method to be a starting point for translation of MRI results into easy-to-understand virtual histology for neurobiologists and provide resources for validating novel MRI techniques.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>magnetic resonance imaging</kwd><kwd>deep learning</kwd><kwd>mouse brain</kwd><kwd>axon</kwd><kwd>myelin</kwd><kwd>histology</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009633</institution-id><institution>Eunice Kennedy Shriver National Institute of Child Health and Human Development</institution></institution-wrap></funding-source><award-id>R01HD074593</award-id><principal-award-recipient><name><surname>Zhang</surname><given-names>Jiangyang</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>R01NS102904</award-id><principal-award-recipient><name><surname>Zhang</surname><given-names>Jiangyang</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Deep convolutional neural networks can generate virtual histology from magnetic resonance imaging (MRI) data to map cellular structures in the mouse brain with high specificity, which enables neurobiologists to use MRI to characterize neuropathology effectively.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Magnetic resonance imaging (MRI) is one of a few techniques that can image the brain non-invasively and without ionizing radiation, and this advantage is further augmented by a large collection of versatile tissue contrasts. While MRI provides unparalleled insight into brain structures and functions at the macroscopic level (<xref ref-type="bibr" rid="bib17">Lerch et al., 2017</xref>), inferring the spatial organization of microscopic structures (e.g., axons and myelin) and their integrity from MR signals remains a challenging inverse problem. Without a thorough understanding of the link between MR signals and specific cellular structures, uncertainty often arises when determining the exact pathological events and their severities. The lack of specificity hinders direct translation of MRI findings into histopathology and limits its diagnostic value.</p><p>Tremendous efforts have been devoted to developing new mechanisms to amplify the affinity of MRI signals to target cellular structures in order to improve sensitivity and specificity. Recent progress in multi-modal MRI promises enhanced specificity by integrating multiple MR contrasts that target distinct aspects of a cellular structure (<xref ref-type="bibr" rid="bib19">Mangeat et al., 2015</xref>). For example, magnetization transfer (MT), T<sub>2</sub>, and diffusion MRI are sensitive to the physical and chemical compositions of myelin, and combining them can lead to more specific myelin measurements than individual contrast (<xref ref-type="bibr" rid="bib4">Cercignani and Bouyagoub, 2018</xref>). Progress in this front, however, has been hindered by the lack of realistic tissue models for inference and ground truth histological data for validation.</p><p>The objective of this study is to test whether deep convolutional neural networks (CNNs), developed using co-registered histology and MRI data, can bypass the above-mentioned obstacles and enhance our ability to map key cellular structures from MR signals. With its capability to bridge data acquired with different modalities (<xref ref-type="bibr" rid="bib7">Christiansen et al., 2018</xref>; <xref ref-type="bibr" rid="bib18">Leynes et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Ounkomol et al., 2018</xref>), the deep learning framework (<xref ref-type="bibr" rid="bib16">LeCun et al., 2015</xref>) has certain advantages over existing modeling approaches, as it is data-driven and not limited by particular models and associated assumptions. As MR signals are the ensemble average of all spins within each voxel, a typical set of three-dimensional (3D) MRI data, with millions of voxels, thus provides ample instances to train deep CNNs. Through training, the networks can potentially reconstruct the link between MR signals and cellular structures in co-registered histology and translate multi-contrast MRI data into maps that mimic histology. Our results demonstrate that this approach offers enhanced specificity for detecting axons and myelin compared to existing MRI-based markers. Furthermore, adding perturbations to the networks allows us to probe the relative contribution of individual MR contrast, which can be used to optimize multi-contrast MRI strategy and evaluate novel imaging contrasts.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Prediction of auto-fluorescence images of the mouse brain from MR images using deep learning</title><p>We first demonstrated our method using co-registered 3D MRI and auto-fluorescence (AF) data. MRI dataset from ex vivo C57BL/6 mouse brain (P60, n = 6), each contained 67 3D MR (T<sub>2</sub>, MT, and diffusion) images, were spatially normalized to the Allen Reference Atlas (ARA) (<xref ref-type="bibr" rid="bib21">Ng et al., 2009</xref>; <xref ref-type="fig" rid="fig1">Figure 1A</xref>). We then selected 100 AF datasets from the Allen Mouse Brain Connectivity Atlas (AMBCA) (<xref ref-type="bibr" rid="bib23">Oh et al., 2014</xref>) with minimal amounts of tracer signals in the forebrain. The contrast in the AF data is not specific to a particular structure, but a majority of hypo-intense regions co-localized with myelinated white matter tracts (<xref ref-type="bibr" rid="bib6">Christensen et al., 2014</xref>). These 3D AF data had already been normalized to the ARA and were down-sampled to the resolution of the MRI data (0.06 mm isotropic). Mismatches between the MRI and AF images were mostly within one to two voxels (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1A-B</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Connect multi-contrast magnetic resonance imaging (MRI) and auto-fluorescence (AF) data of the mouse brain using deep learning.</title><p>(<bold>A</bold>) T<sub>2</sub>-weighted (T<sub>2</sub>W), magnetization transfer ratio (MTR), and diffusion-weighted images (DWIs) were registered to the Allen Reference Atlas (ARA) space, from which 100 already registered AF data were selected and down-sampled to the same resolution of the MRI data. Parameter maps derived from DWI, for example, fractional anisotropy (FA) and mean kurtosis (MK), were also included in this study. (<bold>B</bold>) The deep convolutional neural network (CNN) contained 64 layers (two layers for each residual block Ã 30 residual blocks plus four additional layers at the input and output ends) and was trained using multiple 3 Ã 3 MRI patches as inputs and corresponding 3 Ã 3 patches from histology as targets. (<bold>C</bold>) The CNN was trained using the MRI data (n = 6) and different amounts of randomly selected AF data (iâv). The results generated by applying the CNN to a separate set of MRI data (n = 4) were shown on the right for visual comparison with the reference (Ref: average AF data from 1675 subject). (<bold>DâE</bold>) Quantitative evaluation of the results in <bold>C</bold> with respect to the reference using root mean square error (RMSE) and structural similarity indices (SSIM). The error bars indicate the standard deviations due to random selections of AF data used to train the network. (<bold>F</bold>) The receiver operating characteristic (ROC) curves of the results in <bold>C</bold> in identifying hypo-intense structures in the reference and their areas under the curve (AUCs). The ROC curves from 25 separate experiments in (iii) (light green) show the variability with respect to the mean ROC curve (dark green) due to inter-subject variations in AF intensity. (<bold>G</bold>) The distribution of randomly selected 3 Ã 3 MRI patches in the networkâs two-dimensional (2D) feature space, defined using the t-SNE analysis based on case (iii) in <bold>C</bold>, shows three clusters of patches based on the intensity of their corresponding patches in the reference AF data (turquoise: hyper-intense, orange: hypo-intense; gray: brain surfaces). (<bold>H</bold>) MRI signals from two representative patches with hyper-intense AF signals (turquoise) and two patches with hypo-intense AF signals (orange). The orange profiles show higher DWI signals and larger oscillation among them than the turquoise profiles (both at b = 2000 and 5000 s/mm<sup>2</sup>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 1.</label><caption><title>Evaluate the effects of mismatches between input magnetic resonance imaging (MRI) data and target auto-fluorescence (AF) data on deep learning outcomes.</title><p>(<bold>A</bold>) The overall registration accuracy was visually examined by overlaying a set of landmarks on AF and average diffusion-weighted (DWI) images. (<bold>B</bold>) Distribution of pixel displacement due to mismatches between AF and MRI data was estimated using image mapping. Overall, 70% of the pixel displacements are within one pixel (0.0625 mm) and 95% within two pixels (0.125 mm). (<bold>C</bold>) A convolutional neural network with a similar architecture as the one in the main text was trained using DWIs of ex vivo mouse brains as inputs and corresponding maps of fractional anisotropy (FA), generated by fitting the DWIs to a diffusion tensor model, as targets. In this case, the inputs and targets are perfectly co-registered. (<bold>D</bold>) Comparisons of FA maps generated from model fitting and from the convolutional neural network (deep learning). Overall, the deep learning results show good agreement with the reference from perfectly registered input and target data. The 3 Ã 3 patch size used by the network caused smoothing in the deep learning results. (<bold>E</bold>) Smoothed curves of mean square error loss (left) and root mean square error (RMSE) (right) with respect to the reference FA maps during training measured on the training (blue) and validation (yellow) datasets. Each epoch is 300 iterations. (<bold>F</bold>) Two-dimensional random displacement fields with the same distribution as shown in <bold>A</bold> were introduced to deform FA maps in <bold>C</bold>. The white arrows in the horizontal images indicated the misalignments introduced by this method compared to the original FA maps. Notice the zip-zagged boundaries in the deformed FA map compared to the smooth boundaries in the original FA map. (<bold>G</bold>) Deep learning results generated using different patch sizes. Larger patch size was able to accommodate more mismatches between input and target data but also increased image smoothing in the results. For the amounts of residual mismatches shown in <bold>A</bold>, the 3 Ã 3 patch size was robust to the mismatches with minimal smoothing effects. (<bold>H</bold>) RMSE and structural similarity index (SSIM) values of results generated using different patch sizes. There were significant differences between different patch sizes (t-test, p &lt; 0.00001).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 2.</label><caption><title>Training convergence curves of MRH auto-fluorescence (MRH-AF) network (<bold>AâB</bold>) and MRH myelin basic protein (MRH-MBP) during transfer learning.</title><p>Smoothed curves of mean square error loss (<bold>A, C</bold>) and root mean square error (RMSE) (<bold>B, D</bold>) with respect to the reference during training measured on the training (blue) and validation (yellow) datasets. Each epoch is 300 iterations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 3.</label><caption><title>Evaluation of MRH auto-fluorescence (MRH-AF) results generated using modified 3 Ã 3 patches with nine voxels assigned the same values as the center voxel as inputs.</title><p>(<bold>A</bold>) Visual inspection showed no apparent differences between results generated using original patches and those using patches with uniform values. (<bold>B</bold>) Receiver operating characteristic (ROC) analysis showed a slight decrease in area under the curve (AUC) for the MRH-AF results generated using patches with uniform values (dashed purple curve) compared to the original (solid black curve). (<bold>C</bold>) Correlation between MRH-AF using modified 3 Ã 3 patches as inputs and reference AF signals (purple open circles) was slightly lower than the original (black open circles).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig1-figsupp3-v2.tif"/></fig></fig-group><p>A deep CNN, named MRH-AF, which contained 30 residual blocks, was trained using multiple 3 Ã 3 patches from the forebrain region of each MRI data (40,000 patches, N = 6) as inputs and their corresponding patches in the co-registered AF data as targets (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) (details on the network and training can be found in the Materials and methods section). In order to determine the amount of training data sufficient to capture the relationship between these two modalities, we performed separate training sessions with target AF data ranging from randomly selected 60 subjects (i), 6 subjects (ii), single subject data (iii), down to 5000 and 1000 3 Ã 3 patches randomly selected within a single subject data (iv and v) (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The 3 Ã 3 patch size was shown to accommodate residual mismatches between MRI and AF data (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1F-H</xref>), and we chose such a small patch size instead of the entire image for training because we aimed to define the local relationship between cellular structures within an MRI voxel and corresponding ensemble-averaged MRI signals.</p><p>The performance of MRH-AF was evaluated using the average 3D AF data in the ARA (CCF version 3, average of 1675 mouse brains)(<xref ref-type="bibr" rid="bib23">Oh et al., 2014</xref>) as the reference and MRI data from a separate group of mice (P60, n = 4) as the inputs. The MRH-AF results trained with 60-subject AF data as training targets (i) showed good agreement with the reference (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) and strong voxel-wise signal correlation (R<sup>2</sup> = 0.71, p &lt; 0.001, <xref ref-type="fig" rid="fig1s3">Figure 1âfigure supplement 3C</xref>). The agreement was maintained for (ii) and (iii) both visually and quantitatively, as measured by the root mean square errors (RMSEs) and structural similarity index (SSIM) (<xref ref-type="fig" rid="fig1">Figure 1DâE</xref>). The specificity to hypo-intense regions in the reference defined by optimal thresholding was evaluated using receiver operating characteristic (ROC) analysis. The MRH-AFs trained with 60- and 6-subject AF data (i and ii) showed high specificity with areas under curve (AUCs) greater than 0.94, and the MRH-AF trained with 1-subject data (iii) had a slightly reduced average AUC of 0.937 (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). The variation in the ROC curves in (iii), caused by the inter-subject variations in AF signals among subjects chosen for training, was relatively small. Further reducing the size of training data (iv and v) resulted in declined performances (<xref ref-type="fig" rid="fig1">Figure 1DâF</xref>), emphasizing the need for sufficient training data.</p><p>The way that MRH-AF in (iii) translated individual 3 Ã 3 MR patches into AF signals was visualized in a 2D feature space derived by t-distributed stochastic neighbor embedding (t-SNE) analysis (<xref ref-type="bibr" rid="bib33">van der Maaten and Hinton, 2008</xref>; <xref ref-type="fig" rid="fig1">Figure 1G</xref>). Patches in the MRI data that were assigned with hypo-intense AF signals (orange) mostly clustered at the lower right corner, well separated from patches that were assigned with hyper-intense AF signals (turquoise) or near the brain surface (gray). Representative patches from the first two categories showed distinctive signal profiles (<xref ref-type="fig" rid="fig1">Figure 1H</xref>). Switching the network inputs to modified 3 Ã 3 patches, in which all voxels were assigned the same MR signals as the center voxel, resulted in no apparent loss in sensitivity and specificity and still produced strong voxel-wise signal correlation with the reference AF maps (R<sup>2</sup> = 0.68, p &lt; 0.001, <xref ref-type="fig" rid="fig1s3">Figure 1âfigure supplement 3</xref>), suggesting that MRH-AF primarily relied on multi-contrast MR signals, not patterns within patches, to generate its predictions. Overall, the result demonstrates that the ability of MRH-AF to translate multi-contrast MRI data into maps that mimic the tissue AF contrast in the AMBCA.</p><p>Reducing the number of residual blocks from 30 to 10 resulted in a slight reduction in quality of the predicted AF map (<xref ref-type="fig" rid="fig2">Figure 2AâB</xref>) with significantly increased RMSEs but no significant change in SSIM (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). MRH-AF outperformed first- and second-order polynomial fittings (<xref ref-type="fig" rid="fig2">Figure 2AâB</xref>, case i vs. case iv, case iii vs. cases v and vi), potentially due to the networkâs ability to accommodate remaining mismatch between AF and MRI data. Replacing the 67 rawdata with five commonly used MR parameter maps (T<sub>2</sub>, MTR, FA, MD, and MK) as inputs to train the network produced less accurate AF predictions, for example, the loss of contrasts in the thalamus (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) as well as significantly increased RMSEs and decreased SSIMs (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). This suggests that the five MR parameters, although reflecting key tissue properties, do not contain all the information available from the 67 rawdata. However, using empirical or model-based MR parameters as inputs to the network has the advantage of broader applicability without requiring particular acquisition protocols and instruments, and a carefully selected and comprehensive set of such parameters will likely improve the predictions.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Understanding how multi-contrast magnetic resonance imaging (MRI) input influences the performance of MRH auto-fluorescence (MRH-AF).</title><p>(<bold>A</bold>) MRH-AF results generated under different conditions (top panel) compared to polynomial fitting results (lower panel). (<bold>B</bold>) Root mean square error (RMSEs) and structural similarity indices (SSIMs) of the predicted AF maps shown in A with respect to the reference AF map. (<bold>C</bold>) Plots of the relative contribution of individual MRI images, normalized by the total contribution of all MR images, measured by RMSE. Images displayed on the outer ring (light blue, MRH-AF) show the network outcomes after adding 10% random noises to a specific MR image on the inner ring (light yellow). (<bold>D</bold>) The relative contributions of all 67 MR images arranged in descending order and their cumulative contribution. The images on the right show the MRH-AF results with the network trained using only the top 4, 17, 38, and all images as inputs. (<bold>E</bold>) RMSE measurements of images in D(n = 4) with respect to the reference AF data. Lower RMSE values indicate better image quality. * indicates statistically significant difference (p = 0.028, t-test). (<bold>F</bold>) Receiver operating characteristic (ROC) curves of MRH-AF results in D and the area under the curve (AUC) values.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 1.</label><caption><title>Changes in network output after adding random noises to the original images.</title><p>Adding noises to T<sub>2</sub>-weighted (T<sub>2</sub>W) and magnetization transfer (MT) images made the network outputs noticeably noisier compared to the output with noisy-free inputs. In comparison, similar level of noises added to two diffusion-weighted images (DWI#1 and DWI#3) produced less apparent changes in the output.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig2-figsupp1-v2.tif"/></fig></fig-group><p>Based on the local ensemble average property of MR signals, we added random noises to each of the 67 MR images, one at a time, as perturbations to the network (<xref ref-type="bibr" rid="bib24">Olden et al., 2004</xref>) and measured the effect on network outcomes with respect to noise-free results (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), which reflected how each MR image influenced the outcome of MRH-AF or its relative contribution in the network. Similar information can also be obtained by training the networks with different subsets of the MRI contrasts and comparing the network predictions, but the perturbation method allows us to probe the existing network without retraining. We found that adding noises to a few images (e.g., T<sub>2</sub> and MT images) produced noticeably larger effects, in terms of output image quality and the ability of the network to separate different tissue types, than adding a comparable level of noises to other images (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref>), potentially due to redundant information shared among the 60 rawdata in the diffusion MRI dataset. This noise perturbation result can be used to accelerate MRI acquisition by prioritizing the acquisition of images or contrasts with high relative contributions. The top 4, 17, and 38 images ranked based on their contributions accounted for 28%, 50%, and 75% of the total contribution to the final result, respectively (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Results from training the network with the top 38 MR images as inputs showed comparable visual quality (<xref ref-type="fig" rid="fig2">Figure 2DâE</xref>) and diagnostic power (<xref ref-type="fig" rid="fig2">Figure 2F</xref>) as the results based on the full dataset, but only required 57% the imaging time.</p></sec><sec id="s2-2"><title>Use deep learning to generate virtual maps of axon and myelin and enhance specificity</title><p>Next, we trained our network using serial histological sections immuno-stained for neurofilament (NF) and myelin basic protein (MBP), two commonly used markers for axons and myelin, from the Allen mouse brain atlas. These images were down-sampled, normalized to the ARA (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>). Part of the images were used for training and the rest were used as references. Due to limited histological images stained for myelin and axons, we adopted the transfer learning strategy (<xref ref-type="bibr" rid="bib35">Weiss et al., 2016</xref>). Using the MRH-AF network as a starting point, we fixed most of its network layers while leaving the last three convolutional layers as trainable with MBP and NF-stained histological images.</p><p>The MRH results (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) showed closer visual congruence with the histological references than commonly used MRI-based markers for axons (fractional anisotropy [FA]) and myelin (magnetization transfer ratio [MTR] and radial diffusivity [<xref ref-type="bibr" rid="bib29">Song et al., 2002</xref>], D<sub>R</sub>) as well as linear fitting results using the five parameters as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Even though MRH was trained using coronal sections, it can generate maps along other axes when applied to 3D MRI data (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). The MRH-NF/MBP results also showed strong signal correlations with the reference data (R<sup>2</sup> = 0.61/0.73, respectively, <xref ref-type="fig" rid="fig3s2">Figure 3âfigure supplement 2</xref>). ROC analyses (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) on detecting axon and myelin-rich structures demonstrate improved specificity compared to any single MRI-based markers or 5-parameters linear fitting, while t-SNE analyses visualize how the two networks separate the patches in MRI data that corresponded to NF- and MBP-rich structures from the rest (<xref ref-type="fig" rid="fig3">Figure 3D</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Inferring maps of neurofilament (NF) and myelin basic protein (MBP) from multi-contrast magnetic resonance imaging (MRI) data.</title><p>(<bold>A</bold>) Comparisons of MRH-NF/MBP results with reference histology and MRI-based markers that are commonly used to characterize axon and myelin in the brain (MTR: magnetization transfer ratio; FA: fractional anisotropy; D<sub>R</sub>: radial diffusivity) as well as linear prediction of NF and MBP (fitting-NF/MBP) based on five MRI parameter maps (T<sub>2</sub>, MTR, FA, MD, and MK). (<bold>B</bold>) Even though MRH-NF/MBP were trained using coronal sections, they were able to generate maps for other orthogonal sections (e.g., horizontal sections shown here) from three-dimensional (3D) MRI, as expected from the local ensemble average property. The results show general agreements with structures in comparable horizontal MTR, FA, and five-parameter linear fitting maps. (<bold>C</bold>) Receiver operating characteristic (ROC) analyses of MRH-NF and MRH-MBP show enhanced specificity to their target structures defined in the reference data than MTR, FA, D<sub>R</sub>, and five-parameter linear fittings. Here, D<sub>R</sub> values from diffusion-weighted images (DWIs) with b-values of 2000 and 5000 s/mm<sup>2</sup> are examined separately. (<bold>D</bold>) The distribution of randomly selected 3 Ã 3 MRI patches in the networkâs 2D feature spaces of MRH-NF and MRH-MBP defined using the t-distributed stochastic neighbor embedding (t-SNE) analyses. (<bold>EâF</bold>) Enlarged maps of the cortical (<bold>E</bold>) and hippocampal (<bold>F</bold>) regions of normal C57BL6 mouse brains comparing the tissue contrasts in MRH-NF/MBP with histology and MRI. In (<bold>E</bold>), white arrows point to a layer structure in the hippocampus. ROC analyses performed within the cortex and hippocampus show that MRH-NF/MBP have higher specificity than FA, MTR, and D<sub>R</sub>, but with lower areas under the curve (AUCs) than in <bold>C</bold> due to distinct tissue properties. (<bold>G</bold>) Relative contributions of T<sub>2</sub>-weighted (T<sub>2</sub>W), MT, diffusion MRI (DWI-L: b = 2000 s/mm<sup>2</sup>; DWI-H: b = 5000 s/mm<sup>2</sup>) for the whole brain, white matter, and cortex/hippocampus. *: p &lt; 0.005 (paired t-test, n = 4, from left to right, p = 0.0043/0.000021/0.00072/0.0014 for NF, p = 0.000058/0.000035/0.000002/0.00392 for MBP, respectively). Details on the contributions of each MRI contrast can be found in <xref ref-type="fig" rid="fig3s3">Figure 3âfigure supplement 3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>Preparation and co-registration of serial two-dimensional (2D) histological sections to magnetic resonance imaging (MRI) data.</title><p>(<bold>A</bold>) Two types of common artifacts in neurofilament (NF)-stained images were repaired, and the ventricular spaces were filled with the average intensity values of the cortex. (<bold>B</bold>) Examples of co-registered histological and MRI data. Both NF-stained histological images and ex vivo MRI data were aligned to the space defined by Allen Reference Atlas (ARA). Manually placed landmarks were overlaid to show the overall registration quality. The fractional anisotropy (FA) maps are shown here because white matter structures usually have high FA values due to the coherently arranged axons.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 2.</label><caption><title>Correlations between MRH generated results based on test magnetic resonance imaging (MRI) data and reference data for neurofilament (NF) and myelin basic protein (MBP).</title><p>p Values for all these tests are less than 0.001.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 3.</label><caption><title>Plots of the contributions of 67 magnetic resonance (MR) images in MRH neurofilament (MRH-NF) (<bold>A</bold>) and MRH myelin basic protein (MRH-MBP) (<bold>B</bold>).</title><p>T<sub>2</sub>-weighted (T<sub>2</sub>) and magnetization transfer (MT) images show the highest contributions in both cases. In both plots, the contributions are normalized by the total contribution of all MR images. Images displayed on the outer ring (light blue, MRH-NF/MBP) show the network outcomes after adding 10% random noises to a specific MR image on the inner ring (light yellow).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 4.</label><caption><title>Resolution of down-sampled auto-fluorescence (AF) reference data, MRH-AF data, and fractional anisotropy (FA) map of the input magnetic resonance imaging (MRI) data estimated using deconvolution analysis.</title><p>The top row shows the actual images and the bottom row shows the deconvolution analysis results. The estimated resolutions were computed by dividing the nominal resolution (62.5 Âµm/pixel) by the highest normalized spatial frequency detected in the images (indicated by the vertical lines). (<bold>D</bold>) The resolutions of input MRI and histological data were higher than the resolutions of MRH outputs based on the deconvolution analysis (paired t-test, p &lt; 0.000001). In this case, the histological data had been first down-sampled to 0.1 mm/pixel.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig3-figsupp4-v2.tif"/></fig></fig-group><p>The MRH results, in combination with the structural labels in ARA, provided insights into how the networks balanced multiple MRI contrasts to map axons and myelin in brain regions with distinct microstructural compositions. In the cortex, MRH-NF and MTR showed similar contrasts and comparable specificities to axons (<xref ref-type="fig" rid="fig3">Figure 3E</xref>), while in the whole brain, MTR had a noticeable lower specificity than MRH-NF and FA (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). This suggests that MRH-NF assigned additional weightings on MTR when processing cortical patches. Similarly, in ROC analysis for voxels within the hippocampus, the curve of MRH-MBP closely followed the curve of D<sub>R</sub> at b = 5000 s/mm<sup>2</sup>, in a departure from the whole brain result (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Visual inspections of the MRH-MBP results revealed a layer structure in the hippocampus, which was not obvious in the MTR map but visible in the radial diffusivity (D<sub>R</sub>) map at b = 5000 s/mm<sup>2</sup> (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). Relative contributions of T<sub>2</sub>-weighted (T<sub>2</sub>W) and MT signals were significantly higher in the cortex and hippocampus than in white matter regions for both MRH-NF and MRH-MBP (<xref ref-type="fig" rid="fig3">Figure 3G</xref>).</p><p>Applying the MRH-MBP network to MRI data, collected from dysmyelinating <italic>shiverer</italic> and control mouse brains (n = 5/5) and not included in training MRH-MBP, generated maps that resembled the MBP-stained histology (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). In the corpus callosum, the MRH-MBP results showed similar contrasts between <italic>shiverer</italic> and control moue brains as MTR (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Voxel-wise correlation between MRH-MBP predictions and co-registered MTR and MBP signals from the <italic>shiverer</italic> and control mice showed a slightly stronger correlation (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) and small improvement in myelin specificity than MTR (<xref ref-type="fig" rid="fig4">Figure 4D</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Comparisons of MRH myelin basic protein (MRH-MBP) with common magnetic resonance imaging (MRI)-based myelin markers in the shiverer mice.</title><p>(<bold>A</bold>) Representative MRH-MBP results from dysmyelinated shiverer and control mouse brains show better agreement with histology than maps of magnetization transfer ratio (MTR), fractional anisotropy (FA), and D<sub>R</sub>. (<bold>B</bold>) Differences in MRH-MBP, MTR, and D<sub>R</sub> values of the corpus callosum (t-test, n = 5 in each group, p = 0.00018/0.0061/0.475, respectively). (<bold>C</bold>) Voxel-wise analysis showed a slightly stronger correlation between MRH-MBP and actual MBP signals than MTR (R<sup>2</sup> = 0.91 vs. 0.81). (<bold>D</bold>) MRH-MBP showed slightly improved sensitivity and specificity for MBP-positive regions than MTR in the shiverer and control mouse brains. Scale bar = 1 mm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig4-v2.tif"/></fig></sec><sec id="s2-3"><title>Use deep learning to generate maps that mimic Nissl staining</title><p>MRH networks can also be extended to other types of MR contrasts and histology. To demonstrate this, we used MRH to test whether cellularity in the mouse brain can be inferred from diffusion MRI signals, as our previous studies suggest that oscillating gradient spin echo (OGSE) (<xref ref-type="bibr" rid="bib10">Does et al., 2003</xref>) diffusion MRI can generate a contrast similar to Nissl staining in both normal and injured mouse brains (<xref ref-type="bibr" rid="bib2">Aggarwal et al., 2014</xref>; <xref ref-type="bibr" rid="bib1">Aggarwal et al., 2012</xref>). We separated the down-sampled single subject 3D Nissl data from ARA into two parts. One was used as the training target, and the rest was used as the reference for testing (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). The inputs to the so-called MRH-Nissl network included conventional pulsed gradient spin echo (PGSE) and recently developed OGSE diffusion MRI data. In the testing regions, the network that utilized all OGSE and PGSE data as inputs generated maps with good agreement with the ground truth Nissl data (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), showing higher sensitivity and specificity than PGSE (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). In the 2D feature space from t-SNE analysis (<xref ref-type="fig" rid="fig5">Figure 5C</xref>), the patches that correspond to regions with low Nissl signals were separated from other patches that correspond to regions with strong Nissl signals. Representative signal profiles from the three categories (<xref ref-type="fig" rid="fig5">Figure 5D</xref>) revealed that signals in the high Nissl signal patches decreased as the oscillating frequency increased, whereas the other two types of patches showed no such pattern. Detailed analysis of contrast contribution showed that PGSE and OGSE data contribute equally (<xref ref-type="fig" rid="fig5">Figure 5E</xref>), indicating the importance of OGSE data in generating the target tissue contrast. The MRH-Nissl map of the <italic>sas4</italic><sup>-/-</sup><italic>p53</italic><sup>-/-</sup> mouse brain, which contains a band of heterotopia consists of undifferentiated neurons (<xref ref-type="bibr" rid="bib13">Insolera et al., 2014</xref>), produced image contrasts that matched Nissl-stained histology (<xref ref-type="fig" rid="fig5">Figure 5F</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Generating maps that mimic Nissl stained histology from multi-contrast magnetic resonance imaging (MRI) data.</title><p>(<bold>A</bold>) Comparisons of reference Nissl histology and MRH-Nissl results with pulsed gradient spin echo (PGSE), oscillating gradient spin echo (OGSE), combined PGSE and OGSE diffusion MRI data in both training and testing datasets. The entire datasets consist of PGSE and OGSE data acquired with oscillating frequencies of 50, 100, and 150 Hz, a total of 42 images. (<bold>B</bold>) Receiver operating characteristic (ROC) curves of MRH-Nissl show enhanced specificity for structures with high cellularity (strong Nissl staining) when both PGSE and OGSE data were included in the inputs than PGSE only. (<bold>C</bold>) The distribution of randomly selected 3 Ã 3 MRI patches in the networkâs 2D feature spaces of MRH-Nissl defined using t-distributed stochastic neighbor embedding (t-SNE) analyses. Green and orange dots correspond to regions with high and low cellularity, respectively, and gray dots represent patches on the brain surface. (<bold>D</bold>) Representative signal profiles from different groups in C. (<bold>E</bold>) Relative contributions of PGSE and three OGSE diffusion MRI datasets (<bold>F</bold>) Representative MRH-Nissl results from sas4<sup>-/-</sup>p53<sup>-/-</sup> and control mouse brains compared with Nissl-stained sections. The location of the cortical heterotopia, consists of undifferentiated neurons, is indicated by the dashed lines in the mutant mouse brain image.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-72331-fig5-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The present study focused on inferring maps of key cellular structures in the mouse brain from multi-contrast MRI data. Previous works on this problem include: new MRI contrasts that capture specific aspects of cellular structures of interest (<xref ref-type="bibr" rid="bib30">Stikov et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">Veraart et al., 2020</xref>); carefully constructed tissue models for MR signals (<xref ref-type="bibr" rid="bib14">Jelescu and Budde, 2017</xref>); statistical methods to extract relevant information from multi-contrast MRI (<xref ref-type="bibr" rid="bib19">Mangeat et al., 2015</xref>); and techniques to register histology and MRI data (<xref ref-type="bibr" rid="bib32">Tward et al., 2020</xref>; <xref ref-type="bibr" rid="bib37">Xiong et al., 2018</xref>) for validation (<xref ref-type="bibr" rid="bib27">Schilling et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Stolp et al., 2018</xref>). Here, we built on these efforts by demonstrating that deep learning networks trained by co-registered histological and MRI data can improve our ability to detect target cellular structures.</p><p>Previous studies on the relationship between histology and MRI signals focused on correlating histological and MRI markers as co-registered MRI and histological data as well as realistic tissue models are scarce (<xref ref-type="bibr" rid="bib14">Jelescu and Budde, 2017</xref>; <xref ref-type="bibr" rid="bib22">Novikov et al., 2018</xref>). Adopting similar approaches described by recent reports (<xref ref-type="bibr" rid="bib7">Christiansen et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Ounkomol et al., 2018</xref>) on using deep learning to generate histological labels from unlabeled light microscopy images, we demonstrate a proof of concept of using deep learning to solve the inverse problem of inferring histological information from MRI signals. Even though the resolution of the virtual histology is inevitably limited by the resolution of the input MRI data (~100 Î¼m/voxel) (<xref ref-type="fig" rid="fig3s4">Figure 3âfigure supplement 4</xref>), the presented approach has many potential applications in biomedical research involving MRI. It can enhance our ability to accurately map selected cellular structures and their pathology in mouse models of diseases using non-invasive MRI, with contrasts familiar to neurobiologists. Although the networks cannot be applied to human MRI directly due to vast differences in tissue properties and scanning protocols, understanding how the networks improve specificity based on given MRI contrasts will guide the development of optimal imaging strategy in the clinics. In addition, the co-registered histology and MRI dataset provide a testbed for developing new MRI strategies. As it is relatively easy to normalize any new MRI data to our 3D multi-contrast MRI data and co-registered histology, the sensitivity and specificity of a new MRI contrast to target cellular structures can be evaluated. With quantitative information on the contributions of different MR contrasts, it is now straightforward to design accurate and efficient multi-contrast MRI strategy.</p><p>Perfect co-registration between MRI and histology is highly challenging, as conventional tissue preparations inevitably introduce tissue deformation and damages. In addition, differences in tissue contrasts between histology and MRI also limit the accuracy of registration. Serial two-photon tomography used by the Allen Institute and similar methods allow 3D uniform sampling of the entire brain, which facilitate registration using established registration pipelines (<xref ref-type="bibr" rid="bib15">Kuan et al., 2015</xref>). We expect recent advances in tissue clearing techniques can assist in this aspect once issues such as tissue shrinkage and penetration of antibodies for more target cellular structures are resolved. Remaining mismatches can be accommodated by choosing the appropriate patch size in the network as shown in our results and earlier studies (<xref ref-type="bibr" rid="bib26">Rivenson et al., 2019</xref>).</p><p>There are several directions to further improve our work. First, it is important to curate a training dataset that covers a broad spectrum of normal and pathological conditions and, ideally, with MRI and histology data acquired from the same animal. The data included in this study were adult mouse brain and most white matter structures are myelinated. As a result, the network to predict axons place a substantial weight on MRI contrasts that reflect myelin content (e.g., MT). With the inclusion of unmyelinated embryonic or neonatal mouse brains, we anticipate that the contribution of myelin will be reduced. Inclusion of pathological examples, such as <italic>shiverer</italic> mouse brain data, for training will likely improve our ability to characterize pathological conditions. The result from the <italic>shiverer</italic> data, while demonstrating the usage of the tool, does not tell us whether it will work for cases with more complex pathology, which will require further investigation. Second, the CNNs constructed in this study involved several common building blocks of deep learning, and new advances on network architecture design (e.g., <xref ref-type="bibr" rid="bib11">Goodfellow et al., 2014</xref>; <xref ref-type="bibr" rid="bib38">Zhu et al., 2017</xref>) could further enhance the performance. While CNNs have been commonly treated as black boxes, several recently reported approaches, such as deep Taylor decomposition (<xref ref-type="bibr" rid="bib20">Montavon et al., 2017</xref>) and Grad-CAM (<xref ref-type="bibr" rid="bib28">Selvaraju et al., 2017</xref>), can help explain the inner working. Third, developing similar networks for in vivo MRI data and potential clinical application will require additional effort. The MRI data used in this study were collected from post-mortem mouse brain specimens, which are different from in vivo mouse brains due to death and chemical fixation. Differences in tissue properties between human and mouse brains also require additional steps. MRI parameters, either empirical or model based, may help to bridge this gap as they are translatable and less dependent on acquisition settings. As demonstrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>, networks trained using well-selected MRI parameters can predict tissue histology with reasonable accuracy. Finally, deep learning cannot replace the good understanding of the physics involved in MRI contrasts and the development of new MRI contrast that targets specific cellular structures.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals and ex vivo MRI</title><p>All animal experiments have been approved by the Institute Animal Care and Use Committee at New York University, Memorial Sloan Kettering Cancer Center, and Johns Hopkins University. Adult C57BL/6 mice (P60, n = 10, Charles River, Wilmington, MA), <italic>sas4</italic><sup>-/-</sup><italic>p53</italic><sup>-/-</sup> (<xref ref-type="bibr" rid="bib13">Insolera et al., 2014</xref>) and littermate controls (n = 4/4, P28), <italic>rag2<sup>-/-</sup> shiverer</italic> and littermate controls (n = 5/5, P50) were perfusion fixed with 4% paraformaldehyde (PFA) in PBS. The samples were preserved in 4% PFA for 24 hr before transferring to PBS. Ex vivo MRI of mouse brain specimens was performed on a horizontal 7 T MR scanner (Bruker Biospin, Billerica, MA) with a triple-axis gradient system. Images were acquired using a quadrature volume excitation coil (72 mm inner diameter) and a receive-only four-channel phased array cryogenic coil. The specimens were imaged with the skull intact and placed in a syringe filled with Fomblin (perfluorinated polyether, Solvay Specialty Polymers USA, LLC, Alpharetta, GA) to prevent tissue dehydration (<xref ref-type="bibr" rid="bib3">Arefin et al., 2021</xref>). Three-dimensional diffusion MRI data were acquired using a modified 3D diffusion-weighted gradient- and spin-echo sequence (<xref ref-type="bibr" rid="bib36">Wu et al., 2013</xref>) with the following parameters: echo time (TE)/repetition time (TR) = 30/400 ms; two signal averages; field of view (FOV) = 12.8 mm Ã 10 mm Ã 18 mm, resolution = 0.1 mm Ã 0.1 mm Ã 0.1 mm; two non-DWIs (b<sub>0</sub>s); 30 diffusion encoding directions; and b = 2000 and 5000 s/mm<sup>2</sup>, total 60 diffusion-weighted images (DWIs). Co-registered T<sub>2</sub>W and MT MRI data were acquired using a rapid acquisition with relaxation enhancement sequence with the same FOV, resolution, and signal averages as the diffusion MRI acquisition and the following parameters: T<sub>2</sub>: TE/TR = 50/3000 ms; MT: TE/TR = 8/800 ms, one baseline non-MT-weighted (M<sub>0</sub>) image and one MT-weighted (M<sub>t</sub>) images with offset frequency/power = â3 KHz/20 Î¼T were acquired. The total imaging time was approximately 12 hr for each specimen. For the <italic>sas4</italic><sup>-/-</sup><italic>p53</italic><sup>-/-</sup> and littermate controls (n = 4/4, P28), PGSE and OGSE diffusion MRI data were acquired with the protocol described in <xref ref-type="bibr" rid="bib1">Aggarwal et al., 2012</xref> and a spatial resolution of 0.1 mm Ã 0.1 mm Ã 0.1 mm. All 3D MRI data were interpolated to a numerical resolution of 0.06 mm Ã 0.06 mm Ã 0.06 mm to match the resolution of our MRI-based atlas (<xref ref-type="bibr" rid="bib8">Chuang et al., 2011</xref>).</p><p>MTR images were generated as MTR=(M<sub>0</sub>âM<sub>t</sub>)/M<sub>0</sub>. From the diffusion MRI data, diffusion tensors were calculated using the log-linear fitting method implemented in MRtrix (<ext-link ext-link-type="uri" xlink:href="http://www.mrtrix.org">http://www.mrtrix.org</ext-link>) at each voxel, and maps of mean and radial diffusivities and FA were generated, The mouse brain images were spatial normalized to an ex vivo MRI template (<xref ref-type="bibr" rid="bib8">Chuang et al., 2011</xref>) using the large deformation diffeomorphic metric mapping (LDDMM) method (<xref ref-type="bibr" rid="bib5">Ceritoglu et al., 2009</xref>) implemented in the DiffeoMap software (<ext-link ext-link-type="uri" xlink:href="https://www.mristudio.org">https://www.mristudio.org</ext-link>). The template images had been normalized to the ARA using landmark-based image mapping and LDDMM.</p></sec><sec id="s4-2"><title>Histological data</title><p>From the Allen moue brain atlas, single subject 3D Nissl data and 3D AF data (n = 100), which were already registered to the ARA space, were down-sampled to 0.06 mm isotropic resolution. The <italic>sas4</italic><sup>-/-</sup><italic>p53</italic><sup>-/-</sup>, <italic>rag2<sup>-/-</sup> shiverer</italic> and control mouse brains were cryopreserved and cut into 30 Î¼m coronal sections and processed for Nissl and immunofluorescence. For immunofluorescence, sections were first washed with PBS, blocked with 5% bovine serum albumin, and incubated overnight at 4Â°C with primary antibodies: anti-MBP (AbD Serotec, MCA4095). Sections were rinsed with PBS and incubated with Alexa Fluor secondary antibodies (Invitrogen) cover-slipped with anti-fade mounting medium containing DAPI (Vectrolabs, H-1200). Images were obtained and tile-stitched using an inverted microscope (Zeiss, Axio Observer.Z1) equipped with a motorized table.</p></sec><sec id="s4-3"><title>Registration of MRI and histological data</title><p>Group average 3D MRI data in our previously published mouse brain atlas (<xref ref-type="bibr" rid="bib8">Chuang et al., 2011</xref>) were first spatially normalized to the ARA space. Briefly, 14 major brain structures (e.g., cortex, hippocampus, striatum) in the atlas MRI data were manually segmented following the structural delineations in the ARA. Voxels that belong to these structures in the MRI and average 3D AF data in the ARA (down-sampled to 0.06 mm isotropic resolution) were assigned distinct intensity values, and a diffeomorphic mapping between the discretized atlas MRI and ARA AF data was computed using LDDMM. The mapping was then applied to the original atlas MRI data to generate an MRI template registered to the ARA space. Using dual-channel LDDMM (<xref ref-type="bibr" rid="bib5">Ceritoglu et al., 2009</xref>) based on tissue contrasts in the average DWI and FA images and the MRI template, the 3D MRI data acquired in this study were accurately normalized to the ARA space.</p><p>NF- and MBP-stained images of the C57BL/6 mouse brain were downloaded from the ARA reference dataset. Images with major artifacts or tissue loss were excluded. Small tissue tearing and staining artifacts were removed using the inpainting feature implemented in the photoshop heading brush tool (<ext-link ext-link-type="uri" xlink:href="https://www.adobe.com">https://www.adobe.com</ext-link>), and dark voxels in the ventricles were replaced by the average intensity values of the cortex to match MRI data (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>). The repaired images were down-sampled to an in-plane resolution of 0.06 mm/voxel. For each 2D histological image, the best-matching MRI section in the MRI template was identified, and a coarse-to-fine alignment from histology to MRI using affine transform and landmark-based image warping tool in ImageJ (<ext-link ext-link-type="uri" xlink:href="https://imageJ.nete/BUnwarpJ">https://imageJ.nete/BUnwarpJ</ext-link>). The aligned 2D sections were then assembled into a 3D volume and mapped to the MRI template using LDDMM (between NF/MBP and FA) to further improve the quality of registration.</p></sec><sec id="s4-4"><title>Evaluation of image resolution</title><p>The resolution of MRI, histological images, were evaluated using a parameter-free decorrelation analysis method (<xref ref-type="bibr" rid="bib9">Descloux et al., 2019</xref>), without the initial edge apodization step.</p></sec><sec id="s4-5"><title>Design and training of the MRH networks</title><p>MRH networks are constructed using a CNN model with convolutions from the MRI to histology space. The networks were implemented using the deep learning toolbox in Matlab (<ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com">https://www.mathworks.com</ext-link>) using the directed acyclic graph architecture. To accommodate residual mismatches between MRI and histological data, the network consistently applied convolutional layers until the end layer that computed the distance loss to the target histology. The number of layers and neurons in each layer was determined empirically to balance performance and the risk of overfitting. We chose 64 hidden layers (60 layers in 30 residual blocks plus four layers at the input and output ends), each with 64 neurons, which applied a filter size of 3 Ã 3 and included a rectified linear unit (ReLu). Most of the hidden layers utilized skip connections to jump over layers to avoid vanishing gradients (<xref ref-type="bibr" rid="bib12">He et al., 2016</xref>). The network was initialized with orthogonal random weights and was trained using a stochastic gradient descent optimizer to minimize voxel-level absolute distance loss (<xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2A-B</xref>). Several choices of mini batch sizes were tested and the size was set to 128 to attain a balance between training speed and performance. Stochastic gradient descent with a momentum beta of 0.9 was used for stochastic optimization, with an initial learning rate of 0.1 and a learning rate factor of 0.1. During training, the learning rate was reduced by a factor of 0.1 every 10 epochs. Maximum epoch number was set at 60, but early stopping was employed if the validation set loss did not decrease in five epochs. During hyper-parameter tuning, 1000 3 Ã 3 patches were randomly held out to as the validation dataset and isolated from the training dataset. The weights from the epoch with the lowest validation loss were selected for final testing.</p><p>When retraining the MRH-AF neural network using MBP/NF data, we refined the last three layersâ parameters while leaving the parameters in other layers untouched in the Matlab deep learning toolbox using the directed acyclic graph architecture. The hyperparameters and training patches are the same as MRH-AF. Specifically, the network training initial learning rate was 0.0001, while learning rate factor was 0.1 to accomplish transfer learning. Using the stochastic gradient descent optimizer, our transfer learning converged as shown in <xref ref-type="fig" rid="fig1s2">Figure 1âfigure supplement 2C-D</xref>.</p></sec><sec id="s4-6"><title>t-SNE analysis</title><p>The t-SNE cluster was performed using the Matlab t-SNE analysis function on the network prediction based on values in 2000 randomly selected 3 Ã 3 patches in the mouse brain MRI data.</p></sec><sec id="s4-7"><title>Contribution analysis</title><p>Following the perturbation method described by <xref ref-type="bibr" rid="bib24">Olden et al., 2004</xref>, Rician noises were added to one input MR image to the pre-trained MRH networks, and RMSE between the noise contaminated outputs and the original output without noise was recorded. By repeating this procedure for all MR images, the sensitivities of MRH to each of the 67 input MR image or their contributions were obtained.</p></sec><sec id="s4-8"><title>Evaluate the effect of voxel mismatches</title><p>In the experiment that used the DWI and FA data of the mouse brains to train an MRH network, simulated voxel displacements were used to deform the FA data (target), which were perfectly co-registered to the DWI data (inputs), to test the effect of voxel mismatches between input and target data on network prediction. Gaussian random displacement fields were generated for pixels on a 1 mm by 1 mm grid in the coronal plane and propagated to other voxels by B-spline interpolations. The displacement fields followed a Chi distribution with 2 degrees of freedom and were adjusted to match the level of voxel mismatches observed between MRI and histological data.</p></sec><sec id="s4-9"><title>Statistical analysis</title><p>Statistical significance was determined using unpaired Studentâs t-test with threshold set at 0.05. All statistical tests were performed with Prism (GraphPad). All values in bar graphs indicate mean + standard deviation.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Resources, Software, Validation, Visualization, Writing â original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Writing â original draft</p></fn><fn fn-type="con" id="con5"><p>Data curation, Investigation, Methodology, Writing â original draft</p></fn><fn fn-type="con" id="con6"><p>Data curation, Writing â original draft</p></fn><fn fn-type="con" id="con7"><p>Formal analysis, Investigation, Methodology, Validation, Writing â original draft</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Funding acquisition, Writing â original draft</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Funding acquisition, Methodology, Writing â original draft</p></fn><fn fn-type="con" id="con10"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Software, Supervision, Validation, Visualization, Writing â original draft, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocols (s16-00145-133) of the New York University.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-72331-transrepform1-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data and source codes used in this study are available at <ext-link ext-link-type="uri" xlink:href="https://www.github.com/liangzifei/MRH-net/">https://www.github.com/liangzifei/MRH-net/</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:957e617dda5839ee36e09e7c1f957d6bc4b97401;origin=https://www.github.com/liangzifei/MRH-net/;visit=swh:1:snp:19d94023ec4a6c4dea9ff0ad8da4582de966a320;anchor=swh:1:rev:f116deb1fa6eedde6fc4aa4c5b6edf72a88d058d">swh:1:rev:f116deb1fa6eedde6fc4aa4c5b6edf72a88d058d</ext-link>). The data can also be found at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.1vhhmgqv8">https://doi.org/10.5061/dryad.1vhhmgqv8</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Data fromMulti-contrast MRI and histology datasets used to train and validate MRH networks to generate virtual mouse brain histology</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.1vhhmgqv8</pub-id></element-citation></p><p>The following previously published dataset was used:</p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Lein</surname><given-names>ES</given-names></name></person-group><year iso-8601-date="2006">2006</year><data-title>Reference data</data-title><source>Allen Mouse Brain Atlas</source><pub-id pub-id-type="accession" xlink:href="http://connectivity.brain-map.org/static/referencedata">referencedata</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by NIH grants R01NS102904 and R01HD074593.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aggarwal</surname><given-names>M</given-names></name><name><surname>Jones</surname><given-names>MV</given-names></name><name><surname>Calabresi</surname><given-names>PA</given-names></name><name><surname>Mori</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Probing mouse brain microstructure using oscillating gradient diffusion MRI</article-title><source>Magnetic Resonance in Medicine</source><volume>67</volume><fpage>98</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1002/mrm.22981</pub-id><pub-id pub-id-type="pmid">21590726</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aggarwal</surname><given-names>M</given-names></name><name><surname>Burnsed</surname><given-names>J</given-names></name><name><surname>Martin</surname><given-names>LJ</given-names></name><name><surname>Northington</surname><given-names>FJ</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Imaging neurodegeneration in the mouse hippocampus after neonatal hypoxia-ischemia using oscillating gradient diffusion MRI</article-title><source>Magnetic Resonance in Medicine</source><volume>72</volume><fpage>829</fpage><lpage>840</lpage><pub-id pub-id-type="doi">10.1002/mrm.24956</pub-id><pub-id pub-id-type="pmid">24123409</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arefin</surname><given-names>TM</given-names></name><name><surname>Lee</surname><given-names>CH</given-names></name><name><surname>White</surname><given-names>JD</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Kaffman</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Macroscopic Structural and Connectome Mapping of the Mouse Brain Using Diffusion Magnetic Resonance Imaging</article-title><source>Bio-Protocol</source><volume>11</volume><elocation-id>e4221</elocation-id><pub-id pub-id-type="doi">10.21769/BioProtoc.4221</pub-id><pub-id pub-id-type="pmid">34909442</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cercignani</surname><given-names>M</given-names></name><name><surname>Bouyagoub</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Brain microstructure by multi-modal MRI: Is the whole greater than the sum of its parts?</article-title><source>NeuroImage</source><volume>182</volume><fpage>117</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.052</pub-id><pub-id pub-id-type="pmid">29097317</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ceritoglu</surname><given-names>C</given-names></name><name><surname>Oishi</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Chou</surname><given-names>M-C</given-names></name><name><surname>Younes</surname><given-names>L</given-names></name><name><surname>Albert</surname><given-names>M</given-names></name><name><surname>Lyketsos</surname><given-names>C</given-names></name><name><surname>van Zijl</surname><given-names>PCM</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name><name><surname>Mori</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Multi-contrast large deformation diffeomorphic metric mapping for diffusion tensor imaging</article-title><source>NeuroImage</source><volume>47</volume><fpage>618</fpage><lpage>627</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.04.057</pub-id><pub-id pub-id-type="pmid">19398016</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>PC</given-names></name><name><surname>Brideau</surname><given-names>C</given-names></name><name><surname>Poon</surname><given-names>KWC</given-names></name><name><surname>DÃ¶ring</surname><given-names>A</given-names></name><name><surname>Yong</surname><given-names>VW</given-names></name><name><surname>Stys</surname><given-names>PK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>High-resolution fluorescence microscopy of myelin without exogenous probes</article-title><source>NeuroImage</source><volume>87</volume><fpage>42</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.050</pub-id><pub-id pub-id-type="pmid">24188810</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christiansen</surname><given-names>EM</given-names></name><name><surname>Yang</surname><given-names>SJ</given-names></name><name><surname>Ando</surname><given-names>DM</given-names></name><name><surname>Javaherian</surname><given-names>A</given-names></name><name><surname>Skibinski</surname><given-names>G</given-names></name><name><surname>Lipnick</surname><given-names>S</given-names></name><name><surname>Mount</surname><given-names>E</given-names></name><name><surname>OâNeil</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>K</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Goyal</surname><given-names>P</given-names></name><name><surname>Fedus</surname><given-names>W</given-names></name><name><surname>Poplin</surname><given-names>R</given-names></name><name><surname>Esteva</surname><given-names>A</given-names></name><name><surname>Berndl</surname><given-names>M</given-names></name><name><surname>Rubin</surname><given-names>LL</given-names></name><name><surname>Nelson</surname><given-names>P</given-names></name><name><surname>Finkbeiner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>In Silico Labeling: Predicting Fluorescent Labels in Unlabeled Images</article-title><source>Cell</source><volume>173</volume><fpage>792</fpage><lpage>803</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.03.040</pub-id><pub-id pub-id-type="pmid">29656897</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chuang</surname><given-names>N</given-names></name><name><surname>Mori</surname><given-names>S</given-names></name><name><surname>Yamamoto</surname><given-names>A</given-names></name><name><surname>Jiang</surname><given-names>H</given-names></name><name><surname>Ye</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Richards</surname><given-names>LJ</given-names></name><name><surname>Nathans</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name><name><surname>Toga</surname><given-names>AW</given-names></name><name><surname>Sidman</surname><given-names>RL</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>An MRI-based atlas and database of the developing mouse brain</article-title><source>NeuroImage</source><volume>54</volume><fpage>80</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.043</pub-id><pub-id pub-id-type="pmid">20656042</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Descloux</surname><given-names>A</given-names></name><name><surname>GruÃmayer</surname><given-names>KS</given-names></name><name><surname>Radenovic</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Parameter-free image resolution estimation based on decorrelation analysis</article-title><source>Nature Methods</source><volume>16</volume><fpage>918</fpage><lpage>924</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0515-7</pub-id><pub-id pub-id-type="pmid">31451766</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Does</surname><given-names>MD</given-names></name><name><surname>Parsons</surname><given-names>EC</given-names></name><name><surname>Gore</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Oscillating gradient measurements of water diffusion in normal and globally ischemic rat brain</article-title><source>Magnetic Resonance in Medicine</source><volume>49</volume><fpage>206</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1002/mrm.10385</pub-id><pub-id pub-id-type="pmid">12541239</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Pouget-Abadie</surname><given-names>J</given-names></name><name><surname>Mirza</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>B</given-names></name><name><surname>Warde-Farley</surname><given-names>D</given-names></name><name><surname>Ozair</surname><given-names>S</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Generative adversarial nets</article-title><conf-name>NIPSâ14: Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2</conf-name><fpage>2672</fpage><lpage>2680</lpage></element-citation></ref><ref id="bib12"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deep Residual Learning for Image Recognition</article-title><conf-name>Conference on Computer Vision and Pattern Recognition (CVPR)</conf-name><fpage>770</fpage><lpage>778</lpage></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Insolera</surname><given-names>R</given-names></name><name><surname>Bazzi</surname><given-names>H</given-names></name><name><surname>Shao</surname><given-names>W</given-names></name><name><surname>Anderson</surname><given-names>KV</given-names></name><name><surname>Shi</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical neurogenesis in the absence of centrioles</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1528</fpage><lpage>1535</lpage><pub-id pub-id-type="doi">10.1038/nn.3831</pub-id><pub-id pub-id-type="pmid">25282615</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jelescu</surname><given-names>IO</given-names></name><name><surname>Budde</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Design and validation of diffusion MRI models of white matter</article-title><source>Frontiers in Physics</source><volume>28</volume><elocation-id>61</elocation-id><pub-id pub-id-type="doi">10.3389/fphy.2017.00061</pub-id><pub-id pub-id-type="pmid">29755979</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Sunkin</surname><given-names>SM</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuroinformatics of the Allen Mouse Brain Connectivity Atlas</article-title><source>Methods (San Diego, Calif.)</source><volume>73</volume><fpage>4</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1016/j.ymeth.2014.12.013</pub-id><pub-id pub-id-type="pmid">25536338</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning</article-title><source>Nature</source><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerch</surname><given-names>JP</given-names></name><name><surname>van der Kouwe</surname><given-names>AJW</given-names></name><name><surname>Raznahan</surname><given-names>A</given-names></name><name><surname>Paus</surname><given-names>T</given-names></name><name><surname>Johansen-Berg</surname><given-names>H</given-names></name><name><surname>Miller</surname><given-names>KL</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Studying neuroanatomy using MRI</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>314</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1038/nn.4501</pub-id><pub-id pub-id-type="pmid">28230838</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leynes</surname><given-names>AP</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Wiesinger</surname><given-names>F</given-names></name><name><surname>Kaushik</surname><given-names>SS</given-names></name><name><surname>Shanbhag</surname><given-names>DD</given-names></name><name><surname>Seo</surname><given-names>Y</given-names></name><name><surname>Hope</surname><given-names>TA</given-names></name><name><surname>Larson</surname><given-names>PEZ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Zero-Echo-Time and Dixon Deep Pseudo-CT (ZeDD CT): Direct Generation of Pseudo-CT Images for Pelvic PET/MRI Attenuation Correction Using Deep Convolutional Neural Networks with Multiparametric MRI</article-title><source>Journal of Nuclear Medicine</source><volume>59</volume><fpage>852</fpage><lpage>858</lpage><pub-id pub-id-type="doi">10.2967/jnumed.117.198051</pub-id><pub-id pub-id-type="pmid">29084824</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mangeat</surname><given-names>G</given-names></name><name><surname>Govindarajan</surname><given-names>ST</given-names></name><name><surname>Mainero</surname><given-names>C</given-names></name><name><surname>Cohen-Adad</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Multivariate combination of magnetization transfer, T2* and B0 orientation to study the myelo-architecture of the in vivo human cortex</article-title><source>NeuroImage</source><volume>119</volume><fpage>89</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.033</pub-id><pub-id pub-id-type="pmid">26095090</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montavon</surname><given-names>G</given-names></name><name><surname>Lapuschkin</surname><given-names>S</given-names></name><name><surname>Binder</surname><given-names>A</given-names></name><name><surname>Samek</surname><given-names>W</given-names></name><name><surname>MÃ¼ller</surname><given-names>K-R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Explaining nonlinear classification decisions with deep Taylor decomposition</article-title><source>Pattern Recognition</source><volume>65</volume><fpage>211</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2016.11.008</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Overly</surname><given-names>CC</given-names></name><name><surname>Dong</surname><given-names>H-W</given-names></name><name><surname>Kuan</surname><given-names>C</given-names></name><name><surname>Pathak</surname><given-names>S</given-names></name><name><surname>Sunkin</surname><given-names>SM</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Bohland</surname><given-names>JW</given-names></name><name><surname>Bokil</surname><given-names>H</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name><name><surname>Puelles</surname><given-names>L</given-names></name><name><surname>Hohmann</surname><given-names>J</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name><name><surname>Lein</surname><given-names>ES</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>An anatomic gene expression atlas of the adult mouse brain</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>356</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1038/nn.2281</pub-id><pub-id pub-id-type="pmid">19219037</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Novikov</surname><given-names>DS</given-names></name><name><surname>Kiselev</surname><given-names>VG</given-names></name><name><surname>Jespersen</surname><given-names>SN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On modeling</article-title><source>Magnetic Resonance in Medicine</source><volume>79</volume><fpage>3172</fpage><lpage>3193</lpage><pub-id pub-id-type="doi">10.1002/mrm.27101</pub-id><pub-id pub-id-type="pmid">29493816</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oh</surname><given-names>SW</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Winslow</surname><given-names>B</given-names></name><name><surname>Cain</surname><given-names>N</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Henry</surname><given-names>AM</given-names></name><name><surname>Mortrud</surname><given-names>MT</given-names></name><name><surname>Ouellette</surname><given-names>B</given-names></name><name><surname>Nguyen</surname><given-names>TN</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Slaughterbeck</surname><given-names>CR</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Ho</surname><given-names>A</given-names></name><name><surname>Nicholas</surname><given-names>E</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Joines</surname><given-names>KM</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Hawrylycz</surname><given-names>MJ</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Hohmann</surname><given-names>JG</given-names></name><name><surname>Wohnoutka</surname><given-names>P</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A mesoscale connectome of the mouse brain</article-title><source>Nature</source><volume>508</volume><fpage>207</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1038/nature13186</pub-id><pub-id pub-id-type="pmid">24695228</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olden</surname><given-names>JD</given-names></name><name><surname>Joy</surname><given-names>MK</given-names></name><name><surname>Death</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data</article-title><source>Ecological Modelling</source><volume>178</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.ecolmodel.2004.03.013</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ounkomol</surname><given-names>C</given-names></name><name><surname>Seshamani</surname><given-names>S</given-names></name><name><surname>Maleckar</surname><given-names>MM</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name><name><surname>Johnson</surname><given-names>GR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy</article-title><source>Nature Methods</source><volume>15</volume><fpage>917</fpage><lpage>920</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0111-2</pub-id><pub-id pub-id-type="pmid">30224672</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivenson</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Wei</surname><given-names>Z</given-names></name><name><surname>de Haan</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>GÃ¼naydÄ±n</surname><given-names>H</given-names></name><name><surname>Zuckerman</surname><given-names>JE</given-names></name><name><surname>Chong</surname><given-names>T</given-names></name><name><surname>Sisk</surname><given-names>AE</given-names></name><name><surname>Westbrook</surname><given-names>LM</given-names></name><name><surname>Wallace</surname><given-names>WD</given-names></name><name><surname>Ozcan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Virtual histological staining of unlabelled tissue-autofluorescence images via deep learning</article-title><source>Nature Biomedical Engineering</source><volume>3</volume><fpage>466</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1038/s41551-019-0362-y</pub-id><pub-id pub-id-type="pmid">31142829</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schilling</surname><given-names>KG</given-names></name><name><surname>Janve</surname><given-names>V</given-names></name><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Stepniewska</surname><given-names>I</given-names></name><name><surname>Landman</surname><given-names>BA</given-names></name><name><surname>Anderson</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Histological validation of diffusion MRI fiber orientation distributions and dispersion</article-title><source>NeuroImage</source><volume>165</volume><fpage>200</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.046</pub-id><pub-id pub-id-type="pmid">29074279</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Selvaraju</surname><given-names>RR</given-names></name><name><surname>Cogswell</surname><given-names>M</given-names></name><name><surname>Das</surname><given-names>A</given-names></name><name><surname>Vedantam</surname><given-names>R</given-names></name><name><surname>Parikh</surname><given-names>D</given-names></name><name><surname>Batra</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</article-title><conf-name>2017 IEEE International Conference on Computer Vision (ICCV)</conf-name><conf-loc>Venice</conf-loc><pub-id pub-id-type="doi">10.1109/ICCV.2017.74</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S-K</given-names></name><name><surname>Sun</surname><given-names>S-W</given-names></name><name><surname>Ramsbottom</surname><given-names>MJ</given-names></name><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Russell</surname><given-names>J</given-names></name><name><surname>Cross</surname><given-names>AH</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dysmyelination revealed through MRI as increased radial (but unchanged axial) diffusion of water</article-title><source>NeuroImage</source><volume>17</volume><fpage>1429</fpage><lpage>1436</lpage><pub-id pub-id-type="doi">10.1006/nimg.2002.1267</pub-id><pub-id pub-id-type="pmid">12414282</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stikov</surname><given-names>N</given-names></name><name><surname>Campbell</surname><given-names>JSW</given-names></name><name><surname>Stroh</surname><given-names>T</given-names></name><name><surname>LavelÃ©e</surname><given-names>M</given-names></name><name><surname>Frey</surname><given-names>S</given-names></name><name><surname>Novek</surname><given-names>J</given-names></name><name><surname>Nuara</surname><given-names>S</given-names></name><name><surname>Ho</surname><given-names>M-K</given-names></name><name><surname>Bedell</surname><given-names>BJ</given-names></name><name><surname>Dougherty</surname><given-names>RF</given-names></name><name><surname>Leppert</surname><given-names>IR</given-names></name><name><surname>Boudreau</surname><given-names>M</given-names></name><name><surname>Narayanan</surname><given-names>S</given-names></name><name><surname>Duval</surname><given-names>T</given-names></name><name><surname>Cohen-Adad</surname><given-names>J</given-names></name><name><surname>Picard</surname><given-names>P-A</given-names></name><name><surname>Gasecka</surname><given-names>A</given-names></name><name><surname>CÃ´tÃ©</surname><given-names>D</given-names></name><name><surname>Pike</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>In vivo histology of the myelin g-ratio with magnetic resonance imaging</article-title><source>NeuroImage</source><volume>118</volume><fpage>397</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.05.023</pub-id><pub-id pub-id-type="pmid">26004502</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolp</surname><given-names>HB</given-names></name><name><surname>Ball</surname><given-names>G</given-names></name><name><surname>So</surname><given-names>P-W</given-names></name><name><surname>Tournier</surname><given-names>J-D</given-names></name><name><surname>Jones</surname><given-names>M</given-names></name><name><surname>Thornton</surname><given-names>C</given-names></name><name><surname>Edwards</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Voxel-wise comparisons of cellular microstructure and diffusion-MRI in mouse hippocampus using 3D Bridging of Optically-clear histology with Neuroimaging Data (3D-BOND)</article-title><source>Scientific Reports</source><volume>8</volume><elocation-id>4011</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-22295-9</pub-id><pub-id pub-id-type="pmid">29507311</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tward</surname><given-names>D</given-names></name><name><surname>Brown</surname><given-names>T</given-names></name><name><surname>Kageyama</surname><given-names>Y</given-names></name><name><surname>Patel</surname><given-names>J</given-names></name><name><surname>Hou</surname><given-names>Z</given-names></name><name><surname>Mori</surname><given-names>S</given-names></name><name><surname>Albert</surname><given-names>M</given-names></name><name><surname>Troncoso</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Diffeomorphic Registration With Intensity Transformation and Missing Data: Application to 3D Digital Pathology of Alzheimerâs Disease</article-title><source>Frontiers in Neuroscience</source><volume>14</volume><elocation-id>52</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2020.00052</pub-id><pub-id pub-id-type="pmid">32116503</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Maaten</surname><given-names>L</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Visualizing Data using t-SNE</article-title><source>Journal of Machine Learning Research: JMLR</source><volume>9</volume><fpage>2579</fpage><lpage>2605</lpage></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Veraart</surname><given-names>J</given-names></name><name><surname>Nunes</surname><given-names>D</given-names></name><name><surname>Rudrapatna</surname><given-names>U</given-names></name><name><surname>Fieremans</surname><given-names>E</given-names></name><name><surname>Jones</surname><given-names>DK</given-names></name><name><surname>Novikov</surname><given-names>DS</given-names></name><name><surname>Shemesh</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Nonivasive quantification of axon radii using diffusion MRI</article-title><source>eLife</source><volume>9</volume><elocation-id>e49855</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.49855</pub-id><pub-id pub-id-type="pmid">32048987</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiss</surname><given-names>K</given-names></name><name><surname>Khoshgoftaar</surname><given-names>TM</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A survey of transfer learning</article-title><source>Journal of Big Data</source><volume>3</volume><elocation-id>43</elocation-id><pub-id pub-id-type="doi">10.1186/s40537-016-0043-6</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>D</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>McMahon</surname><given-names>MT</given-names></name><name><surname>van Zijl</surname><given-names>PCM</given-names></name><name><surname>Mori</surname><given-names>S</given-names></name><name><surname>Northington</surname><given-names>FJ</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>In vivo high-resolution diffusion tensor imaging of the mouse brain</article-title><source>NeuroImage</source><volume>83</volume><fpage>18</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.06.012</pub-id><pub-id pub-id-type="pmid">23769916</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiong</surname><given-names>J</given-names></name><name><surname>Ren</surname><given-names>J</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name><name><surname>Horowitz</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mapping Histological Slice Sequences to the Allen Mouse Brain Atlas Without 3D Reconstruction</article-title><source>Frontiers in Neuroinformatics</source><volume>12</volume><elocation-id>93</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2018.00093</pub-id><pub-id pub-id-type="pmid">30618698</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>JY</given-names></name><name><surname>Park</surname><given-names>T</given-names></name><name><surname>Isola</surname><given-names>P</given-names></name><name><surname>Efros</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks</article-title><conf-name>2017 IEEE International Conference on Computer Vision (ICCV)</conf-name><conf-loc>Venice</conf-loc><pub-id pub-id-type="doi">10.1109/ICCV.2017.244</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.72331.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Jbabdi</surname><given-names>Saad</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/2020.05.01.072561" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/2020.05.01.072561"/></front-stub><body><p>This paper demonstrates how MRI can be used to mimic histological measures. This is something that the field of MRI has dubbed virtual histology (or MR-histology) for a while, but this paper is the first convincing demonstration that it can be achieved.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.72331.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Jbabdi</surname><given-names>Saad</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Jbabdi</surname><given-names>Saad</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.05.01.072561">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.05.01.072561v1.full">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Virtual Mouse Brain Histology from Multi-contrast MRI via Deep Learning&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, including Saad Jbabdi as Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Floris de Lange as the Senior Editor.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) As per reviewer #2, please include some quantitative evaluations of the model predictions in the cases where MRI and histology are available in the same animals (e.g. in the mutant mice).</p><p>2) Please make sure to address reviewer #1's points on the added value of a deep net , the concerns on the generalisability of the method, and the validity of the noise contamination experiments.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I would advocate two additional sets of experiments; in the simple form, align the existing histology maps (from, for example, the shiverer mice) to the MRIs from the same animals to provide direct quantifiable estimates of where the predicted histology slices deviate from the actual histology slices.</p><p>More broadly, this paper would greatly benefit from an enhanced training set consisting of MRI and histology from the same animals co-aligned. This would both provide better training and, importantly, better evaluation of the trained maps.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.72331.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) As per reviewer #2, please include some quantitative evaluations of the model predictions in the cases where MRI and histology are available in the same animals (e.g. in the mutant mice).</p></disp-quote><p>We have evaluated the performance of MRH-MBP using MRI and myelin histology (MBP) data from shiverer and control mouse brains (Figure 4), which showed a stronger correlation between MRH-MBP predictions and actual MBP signals as well as higher myelin specificity than magnetization transfer ratio (MTR), a commonly used marker for myelin. We have also clarified that the shiverer and control data were not used for training the MRH-MBP network.</p><disp-quote content-type="editor-comment"><p>2) Please make sure to address reviewer #1's points on the added value of a deep net , the concerns on the generalisability of the method, and the validity of the noise contamination experiments.</p></disp-quote><p>We have revised our manuscript based on rev1âs comments. Specifically,</p><p>1) We have included results from a network trained using five summary measures as inputs (Figure 2A-B). The results suggest that using summary measures as inputs to the network can generate reasonable predictions of histology, which improve the prospect of generalizing the method to data generated from other MR systems.</p><p>2) We have compared the deep net with linear and quadratic fitting (Figure 2A-B), and the result demonstrates that deep learning network outperforms linear/quadratic fitting. One reason for this difference is that the deep network can accommodate residual mismatches between histology and MRI data (as demonstrated in Figure 1 âfigure supplement 1). Such mismatches, often hard to completely remove, will affect polynomial fitting.</p><p>3) We also examined the need for deep net by varying the number of layers and compared the results. As shown in Figure 2A, lowering the number of residual blocks, each consists of two layers, from 30 to 10, still produce reasonable predictions for tissue auto-fluorescence (AF) signals. Further reducing the number of layers produces less satisfactory results. Furthermore, the number of layers needed also depends on the target histology. While a network with 10 residual blocks (~ 24 layers) can generate satisfactory predictions for tissue auto-fluorescence, 30 residual blocks (~64 layers) are needed to generate satisfactory predictions for Nissl staining as shown in Figure 5. We also clarified that convolution mostly work across channels in our network.</p><p>4) We have clarified the noise perturbation experiments. In the revised manuscript, we have removed the supplementary figure on t-SNE analysis of the noise perturbation, clarified that there are redundant information in the diffusion MRI dataset. We have focused on using the information to accelerate image acquisition as shown in Figure 2.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>I would advocate two additional sets of experiments; in the simple form, align the existing histology maps (from, for example, the shiverer mice) to the MRIs from the same animals to provide direct quantifiable estimates of where the predicted histology slices deviate from the actual histology slices.</p></disp-quote><p>We have performed the experiment comparing predicted myelin histology from shiverer and control mice, whose data were not used to train MRH-MBP, with MBP stained histology from the same animals. The result in Figure 4 shows that the predicted MBP signals correlated strongly with the actual MBP signals (R<sup>2</sup>=0.91) and have higher sensitivity and specificity than magnetization transfer ratio (MTR), a commonly used MRI marker for myelin. However, in the Discussion section, we emphasized that more work needs to be done to investigate whether the tool works for more complex myelin pathology.</p><disp-quote content-type="editor-comment"><p>More broadly, this paper would greatly benefit from an enhanced training set consisting of MRI and histology from the same animals co-aligned. This would both provide better training and, importantly, better evaluation of the trained maps.</p></disp-quote><p>We agree with the reviewer on this point. Currently, it is still a time consuming and challenging task to acquire high quality 3D histology from tissue specimens. Although tissue clearing promising techniques have made significant progress over the recent years, getting antibodies into deep structures in the adult mouse brain remains inconsistent. We have just started working with two groups to collect co-registered histology and MRI data, and it may take a year to fine-tune the protocols to obtain high quality 3D histology and co-registration process.</p></body></sub-article></article>