<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">71969</article-id><article-id pub-id-type="doi">10.7554/eLife.71969</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A parameter-free statistical test for neuronal responsiveness</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-209209"><name><surname>Montijn</surname><given-names>Jorrit S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5621-090X</contrib-id><email>jsmontijn@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-211293"><name><surname>Seignette</surname><given-names>Koen</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7398-6291</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-211294"><name><surname>Howlett</surname><given-names>Marcus H</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9620-8014</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-211295"><name><surname>Cazemier</surname><given-names>J Leonie</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2875-6283</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-94163"><name><surname>Kamermans</surname><given-names>Maarten</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0847-828X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-42751"><name><surname>Levelt</surname><given-names>Christiaan N</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1813-6243</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-153567"><name><surname>Heimel</surname><given-names>J Alexander</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5291-4184</contrib-id><email>a.heimel@nin.knaw.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Netherlands Institute for Neuroscience, Royal Netherlands Academy of Arts and Sciences</institution><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>van Rossum</surname><given-names>Mark CW</given-names></name><role>Reviewing Editor</role><aff><institution>University of Nottingham</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>27</day><month>09</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e71969</elocation-id><history><date date-type="received" iso-8601-date="2021-07-06"><day>06</day><month>07</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-09-22"><day>22</day><month>09</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Montijn et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Montijn et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-71969-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-71969-figures-v2.pdf"/><abstract><p>Neurophysiological studies depend on a reliable quantification of whether and when a neuron responds to stimulation. Simple methods to determine responsiveness require arbitrary parameter choices, such as binning size, while more advanced model-based methods require fitting and hyperparameter tuning. These parameter choices can change the results, which invites bad statistical practice and reduces the replicability. New recording techniques that yield increasingly large numbers of cells would benefit from a test for cell-inclusion that requires no manual curation. Here, we present the parameter-free ZETA-test, which outperforms t-tests, ANOVAs, and renewal-process-based methods by including more cells at a similar false-positive rate. We show that our procedure works across brain regions and recording techniques, including calcium imaging and Neuropixels data. Furthermore, in illustration of the method, we show in mouse visual cortex that (1) visuomotor-mismatch and spatial location are encoded by different neuronal subpopulations and (2) optogenetic stimulation of VIP cells leads to early inhibition and subsequent disinhibition.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural data analysis</kwd><kwd>statistics</kwd><kwd>responsiveness</kwd><kwd>response latency</kwd><kwd>visual cortex</kwd><kwd>VIP disinhibition</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd><kwd>Zebrafish</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Stichting Vrienden van het Herseninstituut</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Heimel</surname><given-names>J Alexander</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A simple and robust statistical test for neuronal stimulus response, that outperforms PSTH-based approaches such as t-tests and ANOVAs.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Many neuroscience studies rely on the analysis and visualization of neuronal spiking signals. Classical studies used manual curation during experiments to select cells for analysis (<xref ref-type="bibr" rid="bib17">Hubel and Wiesel, 1959</xref>; <xref ref-type="bibr" rid="bib38">Mountcastle, 1957</xref>), but this method cannot provide a statistically unbiased sample. Moreover, such manual curation is unsuitable for state-of-the-art large-scale recording techniques, such as Neuropixels and high-density multi-electrode arrays (<xref ref-type="bibr" rid="bib3">Bartolo et al., 2020</xref>; <xref ref-type="bibr" rid="bib20">Jun et al., 2017</xref>; <xref ref-type="bibr" rid="bib56">Semedo et al., 2019</xref>; <xref ref-type="bibr" rid="bib60">Steinmetz et al., 2019</xref>).</p><p>Despite the widespread application of neuronal responsiveness analyses, neuroscience currently lacks a standard practice for determining whether a neuron is responsive to an experimental stimulus or treatment (<xref ref-type="bibr" rid="bib34">Mesa et al., 2021</xref>). Common approaches, such as comparing a neuron’s average spike rate during the presence and absence of a stimulus, can only detect mean-rate modulated cells (<xref ref-type="bibr" rid="bib33">Mazurek et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">Ringach et al., 2002</xref>). On the other hand, approaches such as computing a peri-stimulus time histogram (PSTH) and applying an ANOVA, require the a priori selection of an arbitrary binning window size (<xref ref-type="bibr" rid="bib45">Palm et al., 1988</xref>). Choosing the wrong bin size reduces the test’s sensitivity, while optimizing from a range of window sizes creates a multiple-comparison problem. This lowers the approach’s statistical power when corrections are applied, or can even lead to (unintentional) ‘p-hacking’ if the results are not corrected (<xref ref-type="bibr" rid="bib16">Head et al., 2015</xref>). Finally, while (point-process) model-based approaches can circumvent many of the above problems (<xref ref-type="bibr" rid="bib22">Kass et al., 2014</xref>), they still require the a priori selection, or tuning, of hyperparameters specific to the statistical properties of classes of cells, or even individual neurons. Many model-based approaches are therefore not well suited to an unsupervised analysis of large-scale data recorded with state-of-the-art techniques.</p><p>To solve these problems, we developed a method that detects whether a cell is responsive to stimulation in a statistically robust way and avoids binning and parameter selection altogether. This method, which we call ZETA (Zenith of Event-based Time-locked Anomalies), either outperformed or matched that of t-tests, ANOVAs and point-process-based methods in all conditions tested. Building upon this framework, we also present a procedure to visualize instantaneous spiking rates without the need for binning, and show how this can be used to estimate peak-activity latencies with sub-millisecond accuracy. We apply these methods to transient-detected two-photon calcium imaging data from the visual cortex of mice traversing a virtual linear track and find that visuomotor mismatch signals and spatial location are encoded by different V1 neuronal subpopulations. Finally, we apply our approach to Allen Brain Institute Neuropixels data and show that optogenetic stimulation of VIP-expressing cells in mouse visual cortex has a separable early inhibitory and late disinhibitory effect on the local neural circuit. We anticipate that the ZETA-test will be a useful resource for a wide range of applications across various disciplines.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>ZETA: Zenith of event-based time-locked anomalies</title><p>A common procedure in pre-processing neural data is removing cells that are not responsive to an experimental stimulus. Many experimenters determine the ‘stimulus responsiveness’ of a cell by comparing its average spiking rate during the presentation and absence of a stimulus (see <xref ref-type="fig" rid="fig1">Figure 1A–C</xref> for an example V1 cell). This procedure will therefore remove neurons that show no response, but has the risk of also removing neurons that show a strong, but complex time-locked response to stimuli. To remedy this shortcoming, we developed a binning-free method for determining whether a neuron shows any time-locked modulation. We call this statistical test ZETA for Zenith of Event-based Time-locked Anomalies (<xref ref-type="fig" rid="fig1">Figure 1D–F</xref>). It represents whether a neuron’s spike train could be observed by chance, if it were not responding to an experimenter’s event of interest: for example, the presentation of a visual stimulus, the onset of optogenetic stimulation, or a self-generated variable, such as an animal’s location on a track.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The ZETA-test detects an example visually responsive neuron in V1.</title><p>(<bold>A,B</bold>) Raster plot (<bold>A</bold>) and PSTH (<bold>B</bold>) for a neuron that shows an onset peak and a reduced sustained spiking in response to a visual stimulus (purple bars). (<bold>C</bold>) A common approach for computing a neuron’s responsiveness is to perform a t-test on the average activity per trial during stimulus presence (0–1 s) and absence (1.0–1.5 s), which fails to detect this neuron’s response (paired t-test, p = 0.404, n = 480 trials). (<bold>D</bold>) ZETA avoids binning, by using the spike times to construct a fractional position for each spike (blue) and compares this with a null-distribution of a stationary rate (grey). (<bold>E</bold>) The difference between the real and null curves gives a deviation from expectation (blue), where the most extreme value is defined as the Zenith of Event-based Time-locked Anomalies (ZETA, red cross). To compute its statistical significance (here, p = 3.84 × 10<sup>–9</sup>), we compare ZETA to the variability over repeats of the procedure with jittered onsets (grey curves). (<bold>F</bold>) A ZETA-derived instantaneous spiking rate allows a reliable estimation of response onset. (<bold>G</bold>) At a significance threshold of <italic>α</italic> = 0.05, ZETA detects more stimulus-responsive cells than both a mean-rate t-test (***: paired t-test, p = 2.8 x 10<sup>–7</sup>, n = 12 data sets) and an ANOVA over bins using an optimal bin width (**: p = 0.0014).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig1-v2.tif"/></fig><p>ZETA is calculated on a single cell by performing the following steps. First, we align all spikes to stimulus onsets, as when making a raster plot (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Pooling all spikes across trials, we obtain a single vector of spike times relative to stimulus onset, and calculate the cumulative distribution as a function of time (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). The deviation of this curve from a linear baseline represents whether the neuron has a higher or lower spiking density relative to a non-modulated spiking rate (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, blue curve). We compare this pattern to the likelihood of observing it by chance by running multiple bootstraps by jittering stimulus-onset times to generate a null hypothesis distribution (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, gray curves). After scaling the experimentally observed curve to the variation in the null hypothesis distribution, we use it to obtain a p-value corresponding to the Zenith of Event-based Time-locked Anomalies. Low ZETA-test p-values indicate that the neuron’s firing pattern is statistically unlikely to be observed if the neuron is not modulated by the event of interest.</p><p>The ZETA-test bears similarities to a mean-subtracted Kolmogorov-Smirnov test applied to a renewal process model (see methods). In the method section ‘ZETA and renewal-process models’ we show how the ZETA-test gains robustness to violations of the assumptions underlying renewal processes and outperforms alternative approaches. In short, the ZETA-test’s main difference from other approaches used to infer a neuron’s stimulus responsiveness, is that our test makes no a priori assumptions about the underlying distribution of temporal modulations and is binning-free. It can therefore detect both long-timescale changes in mean firing rate, as well as short-timescale stimulus-locked bursts or lapses of activity at any point in time relative to stimulus onset.</p></sec><sec id="s2-2"><title>Benchmarking the ZETA-test</title><p>To investigate whether the ZETA-test includes more cells recorded in mouse visual cortex in response to a drifting grating, while still retaining a 5 % false-positive rate at a significance level of <italic>α</italic> = 0.05, we used a benchmarking test comparing onset-jittered and non-jittered data (<xref ref-type="fig" rid="fig2">Figure 2</xref>). In the non-jittered case, we compared the inclusion rate of the ZETA-test, as described above, to that of a mean-rate t-test. For the t-test, we calculated the average spiking rate of a cell during stimulation (0 s – 1 s after onset) and after stimulation (1 s – 1.5 s), and performed a paired t-test over trial repetitions (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). This showed that cells included with a t-test were almost exclusively a subset of the cells detected with ZETA (see <xref ref-type="fig" rid="fig2">Figure 2B</xref> for all V1 cells recorded with Neuropixels). In other words, if a cell is detected as being visually responsive with a t-test, it is almost guaranteed to also be detected by the ZETA-test. In addition to these cells, the ZETA-test also includes cells that were not registered by a t-test. Although many varieties exist, <xref ref-type="fig" rid="fig2">Figure 2C</xref> shows an example cell that is detected by both t-tests and ZETA (top, sustained change in firing rate), and an example only detected by ZETA (bottom, balanced on/off peaks). In general, any cell lacking a sustained change but displaying a temporally non-uniform spiking distribution would be picked up by the ZETA-test but not a t-test: for example, cells with a sharp but narrow onset peak and variable baseline activity, cells with a balanced on/off response, or oscillatory cells that phase-reset on stimulus onset.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The ZETA-test outperforms the t-test for V1 neurons (n = 119).</title><p>(<bold>A</bold>) Spikes were recorded with neuropixels in mouse V1 and aligned with the onset of square-wave drifting gratings. (<bold>B</bold>) Applying the ZETA-test, we found that 93.3 % of all V1 neurons showed significant firing rate modulations that were time-locked to stimulus onset. Using a rate-based t-test between stimulation (0–1 s) and no stimulation (1–1.5 s) epochs across trials registered 77.3 % of neurons to be visually responsive. Neurons detected by only ZETA are green, by both methods are blue, by only a mean-rate t-test are red, and by neither are grey. Arrows indicate the neurons shown in C. (<bold>C</bold>) Two example neurons that are (1) detected by a rate-based t-test as well as ZETA (top) and (2) not detected by a rate-based t-test, but only by ZETA (bottom). (<bold>D</bold>) We investigated the false-positive rate of both approaches by jittering the onsets of visual stimuli; this preserved the temporal structure of the spiking response, but destroys the time-locked modulations in activity. (<bold>E–F</bold>) same cells and analyses as in B-C but for jittered onsets. Red indicates neurons included by ZETA, but not a t-test; green indicates neurons included by a t-test, but not ZETA. As expected, the percentage of false positives (i.e., neurons with ζ<sub>c</sub>/z-statistic &gt; 2.0) was around 5 % (<italic>α</italic> = 0.05) for both approaches. Note the change in axis magnitude from B to E.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Several important variables underlying the ZETA-test can be derived analytically in the case of exponentially-distributed inter-spike intervals.</title><p>(<bold>A</bold>) We sampled 100,000 artificial neurons with exponentially-distributed inter-spike intervals, each spiking at 1 Hz during 100 trials that last 2 s. To compile data over neurons, we interpolated the spike position to [1 200], regardless of the real number of spikes. Blue shows the mean ± standard deviation of the mean of <italic>δ<sub>i</sub></italic> for each spike number <italic>i</italic>, while the theoretical prediction is shown in red. (<bold>B</bold>) Same as A, but for the variance of <italic>δ<sub>i</sub></italic> as a function of <italic>i</italic>. (<bold>C</bold>) Same as B, but after recentering <italic>δ</italic> to mean-zero, showing the variance of <italic>d<sub>i</sub></italic> as a function of <italic>i</italic>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig2-figsupp1-v2.tif"/></fig></fig-group><p>Next, we ran the same tests again, but now on data where we randomly jittered the stimulus onset times between –τ and +τ, where τ is median onset-to-onset duration. This procedure preserves the properties of a neuron’s spike train, but removes locking of the responses to the stimulus (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). If the ZETA-test simply always gave low p-values, then this would result in a high false-positive rate as many neurons would still be included. In contrast, the false-positive rate of the ZETA-test was generally low, and consistent with that expected for a significance level of <italic>α</italic> = 0.05 (<xref ref-type="fig" rid="fig2">Figure 2E–F</xref>).</p></sec><sec id="s2-3"><title>Sensitivity of ZETA is superior to mean-rate T-tests</title><p>We performed this benchmark for single-cell activity obtained from n = 12 combinations of various visual regions (V1, AM, PM, LGN, SC, LP, NOT, APN, Retina) using multiple techniques (Neuropixels, n = 8; Neuronexus, n = 2; GCaMP6, n = 1; pMEA, n = 1), in response to light flashes (retina, n = 1) or drifting gratings (all others, n = 11). Under all conditions, the inclusion rate using ZETA-tests was higher than using t-tests: at a significance level of <italic>α</italic> = 0.05, the inclusion rate for the ZETA-tests was 79 % and for mean-rate t-tests was 64 %; t-test of ZETA vs mean-rate t-test inclusion rates: n = 12 data sets, p = 2.8 × 10<sup>–7</sup> (<xref ref-type="fig" rid="fig1">Figures 1G</xref> and <xref ref-type="fig" rid="fig3">3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). This means that the ZETA-test includes 42 % of the cells that were not included by a t-test. A significance level of <italic>α</italic> = 0.05 is rather arbitrary, so we also performed a receiver operating characteristic (ROC) analysis, where we investigated the number of inclusions as a function of the number of false positives (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The ROC’s summary statistic is the area under the curve (AUC); one being a perfect discriminator. Again, we found that the ZETA-test showed a higher statistical sensitivity (ZETA-test, mean AUC = 0.914) than a mean-rate t-test (t-test, mean AUC = 0.843), and that this difference was statistically significant (paired t-test, n = 12, p = 4.9 x 10<sup>–6</sup>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The ZETA-test’s superior sensitivity is independent of brain area.</title><p>We recorded neuronal responses to drifting gratings (1 s with 500 ms blank ITIs) from various visual brain areas: V1, SC, AM, LP, NOT, APN, PM, and LGN. For each area, we show an example neuron’s raster plot (left) and binned responses (right). All cells depicted here were significant using ZETA. Area-level benchmark summaries show ROC analyses of the inclusion rate (y-axis) and false-positive (FP) rate (x-axis) for ZETA (Z, blue), bin-wise ANOVA (A, red), and rate-based t-tests (T, black). In all cases, the AUC of the ZETA-test exceeded both the ANOVA’s AUC and t-test’s AUC.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>The ZETA-test is more sensitive than a mean-rate approach across a range of areas, recording techniques and stimuli.</title><p>From left to right the figure shows the following. First column: the recorded area. Second column: recording technique. Third column: stimulus. Fourth column: example data including raster plot or heat map (lhs), neural activity in spiking rate (Hz) or dF/F0 (middle) and activation deviation (rhs, ΔFrac). All cells depicted here were significant using ZETA. Fifth column: benchmark performance for neuronal inclusion percentage (‘Real’, green) and false alarm rate after jittering (‘Jitter’, red) for tests using mean-rate (black, µ) and ZETA (blue, Z). From top to bottom, we investigated several data sets: mouse V1 responses to drifting gratings recorded with a Neuronexus probe (top row) and GCaMP6f (second row), mouse superior colliculus responses to drifting gratings recorded with a Neuronexus probe (third row), and zebrafish retinal ganglion cell responses to on/off light flashes recorded with a perforated micro-electrode array (fourth row). Bar graphs show inclusion rate and 75th percentile confidence interval.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Model-based methods require high spike counts or hyperparameter tuning.</title><p>(<bold>A</bold>) Raster plot of example (high firing rate) V1 cell. Because of the prohibitively long computation time of fitting a multiplicative inhomogeneous Markov interval (MIMI) model to the data we opted to use only the first 480 trials recorded for each cell (N = 119 neurons in V1 from two animals). (<bold>B</bold>) Spiking anomaly (blue) and shuffle controls (grey) for the same cell, showing a clear stimulus-locked response. (<bold>C</bold>) The instantaneous firing rate captures the neuron’s spiking response very well. (<bold>D</bold>) 1 ms binning provides a similar time resolution to both the IFR-method (panel C) and the MIMI-fit (panel E) but is much noisier at the level of single bins. (<bold>E</bold>) The MIMI-model fit also captures the neuron’s spiking response well (see F). Statistical significance with the MIMI-model fit was determined by calculating bin-wise <italic>d’</italic> values from the confidence intervals at each 1 ms bin (see Materials and methods). (<bold>F</bold>) The MIMI-model fit explains a large proportion of the variance of the PSTH (R<sup>2</sup> = 0.89 for this example cell), but still underperforms when used as the basis for a statistical test for stimulus-responsiveness (see panel G). (<bold>G</bold>) ROC analysis showing the performance of the ZETA-test, t-test, and two versions of the MIMI-model fit. While the MIMI-model fitting worked well for cells with high spiking rates, cells with low firing rates were prone to spurious low p values during shuffle controls (see panel I). While the base MIMI-model gave an AUC of 0.749 (versus 0.996 of ZETA), excluding cells with fewer than 1,000 spikes during this 480-trial epoch increased the MIMI-model’s performance to on-par with the t-test (t-test AUC = 0.900, MIMI-1k AUC = 0.898). The threshold of 1000 spikes corresponds to an average firing rate of 1.38 Hz. (<bold>H</bold>) In addition to performing worse than the ZETA-test, the MIMI-method was also much more computationally intensive: the median computation time was 557 times longer than for the ZETA-test. (<bold>I</bold>) Distribution of p-values for real data (top) and shuffled controls (bottom) for the four tests; note that excluding cells with low firing rates removes all of the MIMI’s false positives.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Intermediate statistical tests reveal the functions of the components of the ZETA-test.</title><p>(<bold>A</bold>) Various forms of statistical tests; most perform well when the test’s null distribution matches the real distribution of the unresponsive population (shuffled inter-spike intervals). (<bold>B</bold>) When the test’s assumed (shuffled ISIs) and real (jittered onsets) null distributions are different, the Kolmogorov-Smirnov based tests fail. Of the remaining tests, the ZETA-test and ISI-shuffle ZETA-test perform best. Note that the difference in performance with <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> is due to different data selection. (<bold>C</bold>) Bin-based tests (SISI, Poisson) are slower than binless tests (ZETA, ZETA-ISI). (<bold>D</bold>) Although the ZETA-test and ISI-shuffle ZETA-test performed similarly for data sets with mostly regular spiking cells (panels A,B), the ISI-shuffle ZETA-test performs considerably worse in differentiating stimulus-modulated from unmodulated bursty cells; ZETA-test AUC = 0.941; Mean-rate t-test AUC = 0.902; ISI-shuffle ZETA-test AUC = 0.845.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>The ZETA-test performs better than t-tests at low trial numbers and regardless of data preparation.</title><p>(<bold>A</bold>) Graphs show V1 inclusion percentage as a function of number of trials subsampled from the whole data set, using the ZETA-test (blue) and t-test (black), and false alarms after jittering using the ZETA-test (purple) and t-test (red). Left-hand panel shows results when trials of all orientations are pooled. Middle and right-hand panels show results when t-test p-values are calculated separately per orientation (24 groups) and Bonferroni-corrected (middle) or not corrected (right). (<bold>B</bold>) As panel A, but now using a 300 ms window preceding stimulus onset as baseline. There is little difference in t-test performance between using a 300 ms or 500 ms window. In all cases, the ZETA-test performs better than t-tests.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig3-figsupp4-v2.tif"/></fig></fig-group><p>We also benchmarked various versions of tests derived from the theoretical framework of renewal and Poisson process models. None of these models reached the statistical power and computational efficiency of the ZETA-test (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplements 2</xref> and <xref ref-type="fig" rid="fig3s3">3</xref>), but they do provide an attractive mathematical connection to a more widely studied class of models. We have therefore provided more information on the mathematical relationship between this class of models and the ZETA-test in the method section.</p><p>The percentage of visually responsive cells detected by the ZETA-test is higher than typically reported. For example, using gratings that only differed by orientation, we found 93.3 % of all V1 cells to be visually-modulated. Even more striking was that the lower bound of the binomial 95%-confidence interval was at 89.7 %. This lower-bound is higher than the responsiveness previously reported in many studies, including our own (<xref ref-type="bibr" rid="bib35">Montijn et al., 2016a</xref>; <xref ref-type="bibr" rid="bib39">Niell and Stryker, 2008</xref>; <xref ref-type="bibr" rid="bib58">Shuler and Bear, 2006</xref>; <xref ref-type="bibr" rid="bib60">Steinmetz et al., 2019</xref>), exemplifying the advantage of the ZETA-test.</p><p>The data used so far for benchmarking contains more stimulus repetitions than commonly used in neuroscience. This raises the possibility that the ZETA-test is only advantageous when large numbers of trials are used. To test this, we randomly subsampled the number of trials included in the analysis, and repeated our benchmark. As the results for V1 in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4A</xref> show, the ZETA-test consistently included more than the t-test, regardless of the number of trials.</p><p>We hypothesized that the t-test’s worse performance might result from pooling the responses to different orientations into one group. Therefore, we repeated the t-test’s benchmark after first splitting the trials into 24 groups corresponding to the 24 directions we presented. A neuron was included if the spiking rate during stimulus presentation was significantly different from its pre-stimulus baseline rate in any group, after applying a Bonferroni correction. However, this procedure reduced the t-tests’ performance (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4A</xref>, middle panel).</p><p>We noticed that the t-test’s false positive rate was rather low after Bonferroni corrections. To test whether we over-corrected the t-test, we removed the multiple-comparison correction (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4A</xref>, right-hand panel). In this case, the t-test false positive rate increased to &gt;50%, while its inclusion rate (89.9%) remained lower than that of the ZETA-test (95.0%). Finally, we investigated whether the t-test’s performance was hampered by including the immediate off-response after stimulus offset in the baseline period. We reran the above analyses, but now limited the baseline to the 300 ms preceding the stimulus onset. As can be seen in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4B</xref>, this did not improve the t-test’s performance. In summary, the t-test is at its most sensitive when using the full 500 ms epoch in-between stimulus presentations as baseline period and when pooling data across all orientations.</p></sec><sec id="s2-4"><title>The sensitivity of ZETA is superior to an ANOVA with an optimal bin width</title><p>Mean-rate t-tests are common in neuroscientific analysis, but it could be argued that this is somewhat of a strawman to use as baseline performance. An alternative is to construct a peri-stimulus time histogram (PSTH) and run a one-way ANOVA across bins to test a neuron’s responsiveness to a particular stimulus. However, because this requires picking a bin width, this can lead to arbitrary choices based on the experimenter’s visual inspection of the data, which might increase false positive rates. A better solution is to use one of the various methods to estimate optimal widths for binning (<xref ref-type="bibr" rid="bib11">Freedman and Diaconis, 1981</xref>; <xref ref-type="bibr" rid="bib54">Scott, 2009</xref>; <xref ref-type="bibr" rid="bib57">Shimazaki and Shinomoto, 2007</xref>). We therefore calculated the optimal bin width using the Shimazaki &amp; Shinomoto method, which was specifically designed for building a PSTH, and repeated the benchmark described above, but now testing the responsiveness of neurons using an ANOVA (see Materials and methods). This ANOVA procedure performed markedly better than a mean-rate t-test (<xref ref-type="fig" rid="fig1">Figures 1G</xref> and <xref ref-type="fig" rid="fig3">3</xref>). However, we found that it still showed an inclusion rate (at <italic>α</italic> = 0.05) that was lower than using the ZETA-test (ANOVA mean inclusion rate = 71 %; ZETA-test inclusion = 79%, paired t-test, n = 12, p = 0.0014). Importantly, this difference could not be explained by different levels of false positives, as an ROC analysis also showed a superior statistical sensitivity for the ZETA-test: mean ANOVA-AUC = 0.880, mean ZETA-AUC = 0.914, paired t-test, n = 12, p = 7.7 × 10<sup>–4</sup>.</p><p>Taken together, the results of comparing the ZETA-test to t-tests, ANOVAs, and renewal-process based tests show that the binless ZETA-test has a statistical sensitivity superior to all alternative tests, regardless of number of trial repetitions, brain region where the data were recorded, or specifics of the data preparation.</p></sec><sec id="s2-5"><title>ZETA-test in the absence of short peaks of activity</title><p>Having established that the ZETA-test performs well in real neural data, we looked for conditions under which the ZETA-test fails. We know that the t-test has access to information that the ZETA-test does not: the spike times used by the ZETA-test are flattened over trials, while the t-test uses the variability across trials. Therefore, when the variability of mean activity across trials is low, but the variability of spike times within a trial is high, the ZETA-test could perform worse than a t-test.</p><p>To test this hypothesis, we simulated Poisson-spiking artificial neurons (see Materials and methods) where we changed two variables: (1) we varied the difference in spiking rate (dHz) between stimulus and baseline (both 1 s) from 0 to 1 Hz with a background rate of 1 Hz and (2) we varied the period over which the neuron was active during stimulus presentation (T<sub>r</sub>) from 0.5 to 1.0 s while keeping the total spike count constant. In effect, neurons with T<sub>r</sub> &lt;1.0 show a tri-phasic response, first increasing their spiking rate, then showing a cessation of activity, and finally returning to baseline. As before, we compared the tests’ performance using an ROC analysis. The ROC’s area under the curve (AUC) is conveniently similar to a Wilcoxon-Mann-Whitney statistic and can be used to directly determine which of two procedures is more sensitive (<xref ref-type="bibr" rid="bib7">Calders and Jaroszewicz, 2007</xref>). As expected (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), the t-test’s AUC depends only on dHz and fails when dHz = 0, while the ZETA-test also discriminates well when there is no difference in spike counts, but there is a consistent temporal discontinuity (dHz = 0, T<sub>r</sub> &lt;1.0). Interestingly, while the t-test performs better than the ZETA-test when T<sub>r</sub> = 1.0, the ZETA-test also still performs reasonably well (<xref ref-type="fig" rid="fig4">Figure 4B</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>The t-test exceeds the ZETA-test’s performance only in the hypothetical case of purely Poisson-distributed spike counts and only for a small range of spiking rate differences.</title><p>(<bold>A</bold>) Top: the ability of the t-test to differentiate simulated stimulus (non)modulated cells depends only the total spike count during stimulus (0–1 s) and inter-trial interval (ITI, 1–2 s) periods (x axis; firing rate difference <italic>d(Hz</italic>)), but not on the duration of the cell’s response when keeping the spike count constant (y axis; response duration <italic>T</italic>). Bottom: in contrast, the ZETA-test can differentiate stimulus modulation using either variable. (<bold>B</bold>) Top: example PSTHs of single cells corresponding to the markers 1–4 in (<bold>A</bold>). Bottom: ROC curves for the combination of variables marked as 1–4 in (<bold>A</bold>). The ZETA-test always exceeds the t-test’s performance, except for a limited range where the response duration is 1 s. (<bold>C</bold>) A more biologically plausible test case is bursting neurons that have an elevated probability of bursting during stimuli. (<bold>D–E</bold>) This simulation produces no ‘onset’ peaks of activity that the ZETA-test can exploit. (<bold>F</bold>) However, despite the lack of clear peaks of activity, the ZETA-test exceeds the t-test’s ability to detect stimulus-modulated bursting cells (ZETA AUC = 0.941, t-test AUC = 0.902).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig4-v2.tif"/></fig><p>While this scenario is important to consider from a theoretical perspective, pure Poisson-spiking neurons probably do not exist in the brain. We therefore proceeded with a (somewhat) more biologically plausible simulation of bursting cells, where their bursting probability is orientation-tuned (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, see Materials ad methods and <xref ref-type="table" rid="table1">Table 1</xref>). These neurons show no consistent peaks or troughs of activity (<xref ref-type="fig" rid="fig4">Figure 4D and E</xref>). However, the highly variable spike counts this bursting produces result in the ZETA-test outperforming the t-test (AUC, ZETA = 0.941, t-test = 0.902, z-test, p = 4.1 × 10<sup>–11</sup>). To conclude, even in hypothetical scenarios that we specifically constructed to investigate the limits of the ZETA-test, it performs close to the t-test (<xref ref-type="fig" rid="fig4">Figure 4B4</xref>). Importantly, in the case of strongly bursting cells (<xref ref-type="fig" rid="fig4">Figure 4F</xref>), the ZETA-test clearly outperforms the t-test.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Parameters of bursting neurons used in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title><p>Abbreviations and mathematical symbols are as follows: ISI = Inter-spike interval; IBI = Inter-burst interval; Exp = exponential distribution; |x| = absolute of x; <italic>N</italic> = standard normal distribution; U(x,y) = uniform distribution on interval [x,y]; ℳ = von Mises distribution; <italic>Γ</italic> = Gamma distribution.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Property</th><th align="left" valign="bottom">Unit</th><th align="left" valign="bottom">Distributed as</th><th align="left" valign="bottom">Sampled from:</th></tr></thead><tbody><tr><td align="left" valign="bottom">Single-spike ISI</td><td align="left" valign="bottom">s</td><td align="left" valign="bottom">Exp(1 /r)</td><td align="left" valign="bottom"><italic>r</italic>~Exp(λ = 1)</td></tr><tr><td align="left" valign="bottom">Baseline IBI</td><td align="left" valign="bottom">s</td><td align="left" valign="bottom">Exp(1/| R<sub>b</sub>|)</td><td align="left" valign="bottom">R<sub>b</sub>~|<italic>N</italic>|/20 + 1/80</td></tr><tr><td align="left" valign="bottom">Preferred orientation IBI</td><td align="left" valign="bottom">s</td><td align="left" valign="bottom">Exp(1/| R<sub>t</sub>|)</td><td align="left" valign="bottom">R<sub>t</sub>~|<italic>N</italic>| + 1/4</td></tr><tr><td align="left" valign="bottom">Preferred orientation</td><td align="left" valign="bottom">rad</td><td align="left" valign="bottom">θ<sub>p</sub></td><td align="left" valign="bottom">θ<sub>p</sub>~U(0,2π)</td></tr><tr><td align="left" valign="bottom">Orientation-tuned bursting</td><td align="left" valign="bottom">Hz</td><td align="left" valign="bottom">1/R<sub>b</sub> + 1/R<sub>t</sub> ∙ ℳ(θ<sub>p</sub>, κ)</td><td align="left" valign="bottom">κ ~ 5 + U(0,5)</td></tr><tr><td align="left" valign="bottom">Burst duration</td><td align="left" valign="bottom">ms</td><td align="left" valign="bottom">Γ(2*k, <italic>θ</italic> = 0.5)</td><td align="left" valign="bottom">k~90 + 10*N</td></tr><tr><td align="left" valign="bottom">ISI in bursts</td><td align="left" valign="bottom">ms</td><td align="left" valign="bottom">Γ(2*k, <italic>θ</italic> = 0.5)</td><td align="left" valign="bottom">k~0.5 + Exp(λ = 2.4)</td></tr></tbody></table></table-wrap></sec><sec id="s2-6"><title>Neuronal responsiveness to natural movies</title><p>Next, we asked how the performance of the ZETA-test compares to that of an ANOVA, in a case where there is no a priori knowledge regarding the neuronal response profile, but where the stimulus itself provides a natural timescale that may be used for binning neuronal responses. We therefore determined the responsiveness of neurons to natural movies, using either the ZETA-test, or a one-way ANOVA across bins, repeated for different bin sizes (i.e. timescales). Single-cell data were recorded using Neuropixels in seven visual brain areas of 3 mice, while the animals were presented with repetitions of 20 s long natural movies (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Determining neuronal responsiveness to natural movies.</title><p>(<bold>A</bold>) We recorded neuronal responses to natural movies (four scenes that repeated every 20 s) from various visual brain areas: V1, AM, PM, LGN, LP, NOT, and APN. For each area, we show an example neuron’s raster plot (left) and binned responses (right). All cells depicted here were significant using ZETA. (<bold>B</bold>) We determined a neuron’s responsiveness using a 1-way ANOVA over all binned responses (i.e. PSTH-level ANOVA) for various bin sizes and MC-corrected (black) and using the ZETA-test (blue). Note that the ZETA-test is timescale-free and plotted at all x-values only for easy comparison with the ANOVAs. Curves show mean ± SEM over brain regions (n = 7). ZETA shows an inclusion rate similar to the most optimal bin sizes (0.0333s – 0.2667s), and significantly higher than bin sizes of 0.0167 s or shorter, as well as 0.533 s or longer (*, FDR-corrected paired t-tests, p &lt; 0.05). (<bold>C</bold>) An ROC analysis on all n = 977 cells showed that the ZETA-test and a combined set of ANOVAs were similarly sensitive (ZETA-test AUC: 0.792 ± 0.011; ANOVAs AUC: 0.798 ± 0.010; z-test, p = 0.554).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig5-v2.tif"/></fig><p>To ensure that the ANOVA approach could detect short bursts of activity, as well as long timescale whole-scene modulations of firing rates, we chose a wide range of bin sizes. We picked a single movie frame duration (0.0167 s) as the centre point, and used bins from 1/512th up to 512 movie frames, spaced equidistantly on a base-2 logarithmic scale in 18 steps. For each area, we pooled all cells, and calculated the area-level inclusion rate with either the timescale-free ZETA-test or Bonferroni-corrected ANOVAs at different timescales (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Bin sizes of 33–267 ms did not differ significantly from the ZETA-test’s inclusion rate (FDR-corrected paired t-tests, p &gt; 0.05, n = 7 areas), while the ZETA-test’s inclusion rate was higher than with an ANOVA for all short ( &lt; 33 ms) and long ( &gt; 267 ms) bin durations (p &lt; 0.05).</p><p>The above approaches give some insight into which bin sizes best capture the dominant temporal components in neuronal responses in our data, but a more powerful approach might be to classify a neuron as “included” whenever any of the 19 ANOVAs reached significance (i.e. p &lt; α). Repeating this procedure for various significance levels α on the interval (0,1) produces an ROC curve (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Using this approach, we found there was no significant difference in performance between a set of ANOVAs and the ZETA-test (z-test, p = 0.554): ANOVAs AUC = 0.798 ± 0.010, ZETA-test AUC = 0.792 ± 0.011 (mean ± sd). Overall, the above results show that, under these conditions, the binless and timescale-free ZETA-test performs as well as an aggregate set of ANOVAs binned at various timescales.</p></sec><sec id="s2-7"><title>Instantaneous firing rates (IFRs) for visualization and onset latency detection</title><p>The above paragraphs have shown that the ZETA-test is a sensitive statistical tool to detect whether neurons respond to a stimulus. However, it cannot be used to determine when exactly the strongest response of a neuron occurs. Therefore, we also developed a method that determines the instantaneous firing rate (IFR) using the temporal deviations upon which ZETA is based. Like the ZETA-test, it avoids the bin size selection issue of peri-stimulus time histograms (PSTHs). Another advantage of this IFR is that its temporal resolution is limited only by the neuron’s spike density. Moreover, unlike model-based methods, such as the multiplicative inhomogeneous Markov interval (MIMI) model (<xref ref-type="bibr" rid="bib21">Kass and Ventura, 2001</xref>), it requires no fitting and is orders of magnitude faster (see Materials and methods, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). It is therefore a useful tool for determining spike train features with high precision, such as a neuron’s onset latency.</p><p><xref ref-type="fig" rid="fig6">Figure 6A and B</xref> show two example V1 neurons with a relatively high (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) and low (<xref ref-type="fig" rid="fig6">Figure 6B</xref>) firing rate. Here we define ‘onset’ as the time the half-maximal response of the peak is first crossed, a metric that is heavily influenced by the chosen bin size when using PSTH-based analyses. Moreover, this bin-width-dependent estimation makes PSTH-based comparisons across cell classes problematic, as the choice of optimal bin width depends on spiking properties such as the firing rate and peak firing duration (<xref ref-type="bibr" rid="bib11">Freedman and Diaconis, 1981</xref>; <xref ref-type="bibr" rid="bib54">Scott, 2009</xref>; <xref ref-type="bibr" rid="bib57">Shimazaki and Shinomoto, 2007</xref>), which are heterogeneous across neuronal cell types (<xref ref-type="fig" rid="fig6">Figure 6A5 and B5</xref>). Hence, the main advantage of our method is that it avoids having to tailor the bin size to each neuron individually; allowing for better comparisons across varying cell types and brain regions.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>A ZETA-derived measure for instantaneous firing rates (IFR) avoids binning and allows more accurate latency determination than with PSTHs.</title><p>(<bold>A,B</bold>) Responses of two example V1 cells to drifting gratings. From left to right: (1) Raster plots showing the estimated onset latency (‘L’, green), and times of ZETA (blue) and –ZETA (purple). (2) Spiking rates using 25 ms bins. (3) Spiking rates using multiplicative inhomogeneous Markov interval (MIMI) model-based fits. (4) Binning-free instantaneous spiking rates provide a much higher temporal resolution. Using the first crossing of half-peak firing rates, we determined the onset latencies of these cells to be 52.5 and 59.4 ms. (5) Estimated onset times using our method for instantaneous firing rates (blue), MIMI model-based fits (red), or PSTHs with bin widths from 0.1 to 100 ms (black). Onset latency estimates depend on the chosen bin size, and the optimal size varies across cells. (<bold>C–D</bold>) The median (± SE) difference in onsets estimated by our instantaneous firing rates compared to that of various sized bins for V1 cells (C, n = 119) and for cells from all brain regions (D, n = 1403). Both C and D show the onsets estimated by the two methods were most similar for bin sizes between 1–10 ms. (<bold>E–K</bold>) Benchmarking of peak detection using artificial Poisson neurons that show a transient peak. (<bold>E</bold>) Example Poisson cell for a background rate of 10 Hz and a peak-width of 10 ms. With the true peak at 100 ms, the estimation error here was 1.1 ms. (<bold>F</bold>) Binning the cell’s spiking response in 25 ms bins reduces the peak height and temporal precision. (<bold>G</bold>) Our instantaneous spiking rate preserves a sharper peak response and allows for a temporally accurate latency estimation. (<bold>H</bold>) The detection of peak latencies is insensitive to realistic levels of a stationary Poisson background firing rate (13 base rates, 0.5–32 Hz). (<bold>I</bold>) The mean error is unbiased, and the standard deviation in the onset peak latency estimate scales linearly with the width of the peak. Dotted lines show the real peak width. Graphs in H-I show mean ± sd. (<bold>J</bold>) The error in peak latency estimation depends on both the bin width and the width of the neuron’s peak response. Red crosses indicate the bin size with the lowest error for a given peak width. (<bold>K</bold>) Plotting the latency estimation error shows that different bin sizes (red-green) are optimal for different peak-widths. The accuracy of the latency obtained from MIMI-based fits (black) is less sensitive to the peak width, but never performs as well as well as the most optimal bin size. The error based on our binning-less IFR (blue) is as at least as low as the most optimal bin size, for any peak width.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig6-v2.tif"/></fig><p>To test performance on real data, we compared the estimated onset latency using our IFR to what we obtain from a PSTH analysis with varying bin sizes. Across all V1 neurons (<xref ref-type="fig" rid="fig6">Figure 6C</xref>, n = 119 neurons) as well as all neurons recorded in visual areas (<xref ref-type="fig" rid="fig6">Figure 6D</xref>, n = 1403 neurons), our metric showed the strongest agreement in latency estimation with PSTH bin sizes between 1 and 10 ms.</p><p>As no ground truth is known for the real latencies of experimentally recorded neurons, we performed a benchmark test with artificially generated spike trains. Like before, we used Poisson neurons with a constant background spiking rate, where each neuron was assigned a background rate ranging from 0.5 to 32 Hz (<xref ref-type="fig" rid="fig6">Figure 6E–G</xref>). We used 100 trials, each 2 s long, and created a peak response on top of this baseline rate by adding a single spike in 50 % of all trials (i.e. 50 spikes in total). We also varied the peak-response width by jittering the time each spike was added according to a normal distribution, σ ranging from 1 to 10 ms. We found that the error in the peak estimate was independent of background spiking rate (<xref ref-type="fig" rid="fig6">Figure 6H</xref>), indicating robust performance even when the spikes contributing to the peak were only 0.78 % of the total (i.e. for 32 Hz). The mean error was also independent of the jitter, while the standard deviation of the error estimate grew in a theoretically optimal fashion as <italic>O</italic>(<italic>σ</italic>) (<xref ref-type="fig" rid="fig6">Figure 6I</xref>).</p><p>We next tested the estimator accuracy when using a binning-based PSTH approach (bin width 1–58 ms) and found it depends on both the bin width and the width of the peak response (<xref ref-type="fig" rid="fig6">Figure 6J</xref>). This means that accurate latency determination using PSTHs requires the use of multiple bin sizes. More importantly, when comparing the estimation error between these bin-based methods and our IFR, we found that the binning-less IFR-based latencies were consistently as accurate as, or more accurate than, the best possible bin-width for any given peak-width (<xref ref-type="fig" rid="fig6">Figure 6K</xref>). Finally, the IFR-latency accuracy also exceeded the MIMI-model fit based method. In other words, the IFR-based accuracy supersedes the PSTH-based (and MIMI-based) accuracy without the need to hand-pick the optimal binning width per neuron for a PSTH-method, nor tune hyperparameters such as knot number, location, and regularization strength for the MIMI-method.</p></sec><sec id="s2-8"><title>Visuomotor mismatch and spatial location are mediated by different neuronal subpopulations</title><p>Having established that the ZETA-test and IFR are statistically robust and have clear advantages over mean-rate approaches and PSTHs, we applied these tools to a GCaMP6 data set. Many theories, such as predictive coding (<xref ref-type="bibr" rid="bib12">Friston, 2005</xref>; <xref ref-type="bibr" rid="bib13">Gregory et al., 1980</xref>; <xref ref-type="bibr" rid="bib51">Rao and Ballard, 1999</xref>), biologically realistic error backpropagation (<xref ref-type="bibr" rid="bib42">Ooyen and Roelfsema, 2003</xref>; <xref ref-type="bibr" rid="bib62">Whittington and Bogacz, 2019</xref>), and canonical cortical microcircuit operation (<xref ref-type="bibr" rid="bib4">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="bib10">Douglas et al., 1989</xref>), define a ‘top-down’ signal representing an expectation, error or surprise signal as distinct from a bottom-up sensory drive. In mouse V1, such top-down visuomotor mismatch signals have been reported previously (<xref ref-type="bibr" rid="bib2">Attinger et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Keller et al., 2012</xref>; <xref ref-type="bibr" rid="bib29">Leinweber et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Saleem et al., 2013</xref>). However, whether individual V1 neurons can be classified into different groups based on their encoding of top-down visuomotor mismatch or bottom-up sensory-driven spatial location signals has not been studied.</p><p>To examine this issue, and to provide an example of how one could use ZETA in a neurophysiology study, we used neuronal calcium data recorded in L2/3 V1 of 4 mice running on a virtual-reality linear track (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). In 87 % of all corridor runs (N = 622/713 trials), the track was rendered normally, and the mice received visual feedback matching their running speed. In the remaining 13 % of runs (N = 91), rendering was halted at a random location for 500 ms before resuming (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). After performing calcium-transient detection to obtain putative spike times (<xref ref-type="bibr" rid="bib36">Montijn et al., 2016b</xref>), we calculated ZETA-scores for all neurons in three different ways. We aligned the spikes to mismatch-onsets, to trial starts, or converted the spike times into locations on the track, and aligned these spike locations to the start. For each recording (n = 7), we calculated the Pearson correlation for each pair of these three ZETA-scores (<xref ref-type="fig" rid="fig7">Figure 7C–F</xref>). Across recordings, time- and location-modulation were positively correlated (mean <italic>r</italic> = 0.23, one-sample t-test, n = 7 recordings, p = 0.016); time- and mismatch-modulation were not significant (<italic>r</italic> = 0.13, p = 0.28); and location- and mismatch-modulation were negatively correlated (<italic>r</italic> = −0.22, p = 0.04).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Neurons in V1 encode either visuomotor mismatch signals or spatial location.</title><p>(<bold>A</bold>) Schematic of setup showing mouse on running wheel (lhs) viewing a virtual tunnel (rhs). (<bold>B</bold>) Trials consist of a 100 cm linear track. One second after the mice ran to the end of the tunnel, an auditory stimulus signaled that a water reward would be delivered two seconds later. 6 s after reward delivery, mice were transported to the start of the virtual tunnel. In a subset of trials, the rendering of the tunnel was paused at a random location, eliciting a visuomotor mismatch signal. Top right shows calcium imaging data for an example ‘mismatch neuron’ during 16 control and 16 mismatch trials. (<bold>C</bold>) Spiking data for example neuron obtained from exponential fits of the dF/F0 signals. Putative spikes were aligned to start (left), location of the animal on the track (middle), or mismatch onset (right). From top to bottom: raster plot of putative spike times; mean ± SEM of firing rates over trials (n = 105 trials, of which n = 16 mismatch trials); spiking deviation underlying ZETA; instantaneous firing rate. (<bold>D–I</bold>) Relationship between time-, location-, and mismatch-modulation. One point is one neuron. (<bold>D–F</bold>) ZETA-scores for example recording 6 (N = 120 neurons). (<bold>G–I</bold>) Analysis using a kernel-density estimate (KDE) to test whether joint-encoding of two features is more common than expected by chance (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). (<bold>G</bold>) More neurons showed joint-encoding of both spatial and temporal location than expected by chance (p = 1.1 × 10<sup>–4</sup>). (<bold>H</bold>) Joint-encoding of temporal location and mismatch was not significantly different from chance (p = 0.932). (<bold>I</bold>) Location on the virtual track and visuomotor mismatch are less likely to be encoded by the same neuron than expected from chance (p = 2.0 × 10<sup>–5</sup>). See <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> for more details on the KDE procedure.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Using a kernel-density estimator (KDE) to investigate the joint-encoding of two features.</title><p>Each column shows one step in our analysis procedure, and each row shows the comparison of two features. Top row shows the comparison of location-modulation (x-axis) with time-modulation (y-axis). Left-hand panel: probability density derived from combining the independent KDE-distributions of location-modulation and time-modulation. Middle-left panel: real joint probability distribution (red-scale). One point is a single neuron’s modulation after z-scoring per recording. Middle-right panel: the difference in probability density between the real and null-hypothesis distributions. Blue indicates fewer neurons in the real joint-distribution than in the null-hypothesis distribution. The upper-right quadrant is mostly red, indicating the real distribution contains more neurons that encode both location and time than expected by chance. Right-hand panel: we sampled 10,000 synthetic neuronal populations from the null-hypothesis probability distribution, and calculated for each synthetic population the number of neurons that fell in the upper-right quadrant (URQ): that is, the number of neurons that show both above-average location-modulation as well as above-average time-modulation. The histogram shows the number of neurons in the URQ for each of the 10,000 populations, and the blue vertical line shows that the real number of neurons in the URQ is much higher than expected by chance (z = 3.812, p = 1.144 × 10<sup>–4</sup>). Middle row: as top row, but now comparing time- and mismatch-modulation. The URQ-analysis showed that time- and mismatch-modulation were not more often seen in the same neurons than expected by chance if the two features are independently encoded (z = −0.059, p = 0.953 (n.s.)). Bottom row: location on the virtual track and visuomotor mismatch are less likely to be encoded by the same neuron than if the two features were randomly distributed (z = −4.310, p = 2.019 × 10<sup>–5</sup>). This shows that neurons show an encoding specialization for either spatial location or visuomotor mismatch, but not both. Analyzing the Pearson correlation per recording we find qualitatively similar results. Mean Pearson correlation between time-modulation and location-modulation across recordings: n = 7, mean <italic>r</italic> = 0.2272; one-sample t-test vs. 0: p = 0.0164. Mean correlation between time- and mismatch-modulation: <italic>r</italic> = 0.1267, p = 0.2829 (n.s.). Mean correlation between location- and mismatch-modulation: <italic>r</italic> = −0.2249, p = 0.0414.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig7-figsupp1-v2.tif"/></fig></fig-group><p>We next used a kernel-density estimate (KDE) to directly test whether the joint encoding of two features within single neurons was different from chance (<xref ref-type="fig" rid="fig7">Figure 7G–I</xref>; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Indeed, we found that it was less likely that a neuron showed high modulation values for both spatial location and visuomotor mismatch than if the two features were encoded independently (z = −4.3, p = 2.0 × 10<sup>–5</sup>). We also found time and location to be more likely to be encoded by the same neurons (z = 3.8, p = 1.1 × 10<sup>–4</sup>), while time- and mismatch-modulation show no effect (z = −0.06, p = 0.95). This suggests a functional specialization for many neurons to encode either visuomotor mismatch signals or spatial location, but not both. While it is possible that location- and mismatch-encoding are also mediated by specific genetic subtypes of interneurons (<xref ref-type="bibr" rid="bib2">Attinger et al., 2017</xref>), our analysis of putative pyramidal cells demonstrates that principal cells also show encoding specialization.</p></sec><sec id="s2-9"><title>Optogenetic stimulation of VIP cells disinhibits visual cortex</title><p>Finally, we applied the IFR and ZETA-test to data recorded at the Allen Brain Institute (<xref ref-type="bibr" rid="bib59">Siegle et al., 2019</xref>). In this case, we investigate whether optogenetic stimulation of VIP cells in visual cortex disinhibits the local circuit, as has been shown previously for auditory cortex and mPFC (<xref ref-type="bibr" rid="bib48">Pi et al., 2013</xref>). The analysis of optogenetic stimulation in visually-responsive areas is complicated by the fact that mice can see the blue light used for optogenetic stimulation. In other words, if a neuron is active after a laser pulse, it could be caused by direct stimulation, indirect circuit disinhibition, or simply be a sensory-driven response. Using the methods described in this paper to overcome these issues, we show that optogenetic stimulation of VIP-expressing cells in mouse visual cortex causes short-latency inhibition and longer latency disinhibition in separate neuronal subpopulations (<xref ref-type="fig" rid="fig8">Figure 8</xref>).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Optogenetic stimulation of VIP-expressing cells in mouse visual cortex causes short-latency inhibition and longer latency disinhibition of the local neural circuit.</title><p>(<bold>A–F</bold>) Response of example cells classified as VIP (<bold>A,B</bold>), Inhibited (<bold>C,D</bold>) and Activated (<bold>E,F</bold>). (<bold>G</bold>) Data were recorded in visual cortex from 5 Vip-Cre mice at the Allen Brain Institute. Cells were only included if the clustering quality was sufficient (1707 cells total). A ZETA-test included cells that were modulated within (–0.5, + 0.5 s) after optogenetic stimulation (N = 1144 cells). IFR peak- and trough-latency was computed and cells were discarded if their peak was earlier than 1 ms after optogenetic stimulation onset. Remaining cells were classified as VIP (N = 13), Inhibited (N = 59), Activated (N = 137), or Other (N = 700). (<bold>H</bold>) Heat map showing normalized firing rate of VIP (top), Inhibited (middle), and Activated (bottom) cells. (<bold>I</bold>) Mean ± SEM of PSTH (2.5 ms bin size) over all VIP (green), Inhibited (orange), Activated (yellow), and Other (gray) cells. (<bold>J</bold>) Inhibited cells showed significantly lower mean IFR-peak latencies after optogenetic stimulation than Activated cells (Inh: 17.4 ms; Act: 23.0 ms; Mann-Whitney U-test, p = 5.1 × 10<sup>–7</sup>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-71969-fig8-v2.tif"/></fig><p>Data used for this analysis were recorded from 5 Vip-IRES-Cre; Ai32 mice at the Allen Brain Institute. Cells were only included for analysis if the clustering quality was sufficient, and they were recorded in a visual cortex area (1706 cells total in AL, AM, PM, L, V1, RL, MMP). We performed a ZETA-test to discard cells that were not modulated within the interval (–0.5, + 0.5 s) after optogenetic stimulation (N = 1144 cells remaining). Instantaneous firing rate peak- and trough-latencies were computed and cells were discarded if their peak occurred earlier than +1 ms after optogenetic stimulation onset. The remaining cells (N = 909) were classified as VIP (N = 13) if their peak latencies occurred within the 10 ms duration of the optogenetic stimulation, as Inhibited (N = 59) or Activated (N = 137) if they displayed respectively decreased or increased firing within 20 ms from the stimulus offset, or Other (N = 700). We limited our classification window to the first 30 ms after the onset of the optogenetic stimulus as it takes about 30–50 ms for retinal light responses to emerge in the visual cortex. Hence, the majority of ‘Other’ cells likely show sensory-driven responses.</p><p>Based on these classifications, we compared the single-cell latencies of Inhibited and Activated neurons, restricting our analysis to peaks within the 10–30 ms post-optogenetic stimulation window. The latency of Inhibited cells was significantly shorter after optogenetic stimulation than it was for Activated cells (median latency Inh = 16.5 ms, Act = 23.6, Mann-Whitney U-test, p = 5.1 × 10<sup>–7</sup>). These results show a VIP-mediated disinhibition mechanism operates in vivo in visual cortex, confirm slice connectivity studies (<xref ref-type="bibr" rid="bib47">Pfeffer et al., 2013</xref>), and are in general agreement with results from the auditory cortex and mPFC (<xref ref-type="bibr" rid="bib48">Pi et al., 2013</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We developed the ZETA-test, a statistical method for determining whether neuronal spiking responses are modulated by the occurrence of events, such as the onset of sensory stimulation. The ZETA-test is widely applicable: we have shown that it can accurately detect neuronal responsiveness in a wide range of settings, across various brain regions, stimuli, and recording techniques. In most cases, the ZETA-test showed markedly improved statistical sensitivity compared to established and powerful statistical techniques, such as t-tests and ANOVAs. For example, the ZETA-test detected a visual response in 42 % of the cells that were not included by a t-test and in 28 % of the cells not included by a PSTH-based ANOVA. In addition to its improved statistical performance, the ZETA-test avoids arbitrary parameter choices, as it does not require the selection of a temporal bin size. This makes the ZETA-test even easier to use than established methods, as it can be applied directly to raw spike times and stimulus onsets, and the lack of a parameter selection naturally lends itself to the bulk-analysis of large numbers of cells.</p><p>Secondly, we developed an instantaneous firing rate for analysis and visualization of neuronal firing patterns. Similar to the ZETA-test, it has two main advantages over alternative common approaches, such as PSTHs: (1) it does not require binning, and therefore removes the need to tune binning widths for individual cells or cell types and (2) its temporal resolution is only limited by the spike density, which allows more accurate determination of spike train events such as peak response latencies. When benchmarking its performance for latency-estimation, it outperformed PSTH-based approaches without the need to fine-tune bin sizes for each neuron individually (<xref ref-type="fig" rid="fig6">Figure 6K</xref>). Finally, compared to methods that rely on model fitting, such as the multiplicative inhomogeneous Markov interval (MIMI) model, the ZETA-test is considerably faster, not subject to overfitting, and does not require tuning of hyperparameters (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>We investigated the performance of the ZETA-test in a variety of cases and observed that the ZETA-test sometimes performed as well as other techniques and sometimes better. So when, and why, exactly does the ZETA-test provide extra statistical power? We have shown in the methods that the ZETA-test shares mathematical properties with a Kolmogorov-Smirnov test of a neuron’s spike train against permuted onset-jitter bootstraps. Various components of the ZETA-test were chosen to relax the assumptions made by other tests with the aim to gain relative invariance to the specifics of a neuron’s spike train (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). While the ZETA-test is slightly worse than a t-test for purely Poisson-distributed spike counts, it outperforms the t-test in every other case we tested, including those where the interspike interval distribution is highly peaked, such as in bursting cells (<xref ref-type="fig" rid="fig1">Figures 1</xref>—<xref ref-type="fig" rid="fig4">4</xref>). Finally, while more sophisticated model-based approaches might be able to attain better performance than the ZETA-test, this requires that their hyperparameters be individually tuned to a cell’s firing statistics (e.g. MIMI-based methods; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Therefore, the ZETA-test may often be the preferred choice as it required no fitting, hyperparameter tuning, and shows a statistical sensitivity superior to model-based approaches in all cases we tested.</p><p>An alternative to using the ZETA-test could be to perform a set of ANOVAs as in <xref ref-type="fig" rid="fig5">Figure 5</xref>. While this would certainly be an improvement over doing a paired t-test, multiple ANOVAs are more complex to implement and the procedure needs multiple-comparison correction (<xref ref-type="bibr" rid="bib16">Head et al., 2015</xref>). More importantly, it still requires choosing an arbitrary set of bin sizes, as simply taking the optimal bin size still leads to an underperformance relative to the ZETA-test (<xref ref-type="fig" rid="fig1">Figure 1G</xref>). Moreover, the ZETA-test has the advantage of not having to choose any parameter at all. As we have shown in <xref ref-type="fig" rid="fig8">Figure 8</xref>, using the ZETA-test and IFR allowed us to significantly simplify various analysis steps when investigating the heterogeneous latency effects of optogenetic stimulation of VIP neurons.</p><p>However, like all statistical tools, the ZETA-test also has its limitations. As we designed it to be a generalist test applicable to any spike train, the ZETA-test might not perform as well as models manually fitted to describe a particular cell’s response. However, we believe in many cases it will provide a superior alternative to other responsiveness tests, and response-latency determinations. The ZETA-test shows great merit especially as an unbiased parameter-free inclusion criterion, which is something that currently often varies between studies and can adversely affect the replicability of scientific results (<xref ref-type="bibr" rid="bib34">Mesa et al., 2021</xref>). Another, and fairly obvious, limitation is that the ZETA-test only compares point-events (e.g. spike times) to other point-events (e.g. stimulus onsets). Consequentially, it is a powerful tool for state-of-the-art electrophysiological techniques, like Neuropixels recordings, but does not apply to calcium imaging dF/F0 traces. However, as we show in <xref ref-type="fig" rid="fig7">Figure 7</xref>, the ZETA-test performs well when applied to putative spiking events extracted from calcium imaging data. Therefore, the ZETA-test would still be useful in calcium imaging data sets where the temporal response profile of neurons to the experimental treatment is unknown. Moreover, optical recording techniques continue to improve, allowing better single-spike extractions with calcium imaging (<xref ref-type="bibr" rid="bib44">Packer et al., 2015</xref>) and genetically encoded voltage indicators (<xref ref-type="bibr" rid="bib26">Knöpfel and Song, 2019</xref>). As such, in all likelihood near-future neural data will remain spike-based regardless of the underlying recording technique used.</p><p>The main aim of this paper is to present the IFR and ZETA-test and show how they improve upon commonly used analysis tools, such as PSTHs, t-tests, Markov-model-based approaches, and ANOVAs. However, we also show some results that by themselves are scientifically noteworthy. For example, our results indicate that almost all V1 neurons ( &gt; 93%) are responsive to drifting gratings, even if the spatial frequency (SF) and temporal frequency (TF) parameters are not optimal to drive these cells (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This calls into question the idea that V1 cells are generally narrowly tuned and can only be driven by specific stimulus feature parameters (<xref ref-type="bibr" rid="bib63">Xing et al., 2004</xref>). Our analysis indicates that neuronal responsiveness rarely drops to 0 for a combination of stimulus features, as otherwise we would not have found such a large number of responsive V1 cells using a feature-sparse stimulus (24 directions, 1 SF: 0.05cpd, 1 TF: 2 Hz).</p><p>This suggests that the response of V1 neurons to features such as SF and TF may drop off rather slowly with distance to their preferred stimulus properties. Conceptually, this would mean that the V1 neural code may in fact be more ‘dense’ than proposed by some (<xref ref-type="bibr" rid="bib40">Ohiorhenuan et al., 2010</xref>; <xref ref-type="bibr" rid="bib41">Olshausen and Field, 1997</xref>; <xref ref-type="bibr" rid="bib61">Vinje and Gallant, 2000</xref>). That said, our results show that only a relatively small group of neurons is strongly driven by any one stimulus: sparse coding may therefore still operate in V1, but it acts on top of a dense, but weak code.</p><p>Two other noteworthy findings are that VIP cell activation drives disinhibition in visual cortex (<xref ref-type="fig" rid="fig8">Figure 8</xref>) and that the strength of visuomotor signals and modulation by spatial location are negatively correlated (<xref ref-type="fig" rid="fig7">Figure 7</xref>). This suggests that bottom-up and top-down processing in visual cortex may be mediated by distinct neuronal subnetworks. While this functional segregation has previously been shown based on a macroanatomical (e.g. laminar) analysis (<xref ref-type="bibr" rid="bib27">Kok et al., 2016</xref>; <xref ref-type="bibr" rid="bib31">Markov et al., 2014</xref>; <xref ref-type="bibr" rid="bib49">Poort et al., 2012</xref>; <xref ref-type="bibr" rid="bib55">Self et al., 2019</xref>), our results suggest that this functional segregation also holds at a microanatomical level for neurons located within a single recording plane (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><p>In conclusion, the IFR and ZETA-test are simpler, more statistically powerful, and less error-prone tools than bin-based PSTHs, t-tests, Markov-model based approaches, and ANOVAs widely used in neuroscience today. Statistically underpowered studies are still common in neuroscience, which makes the development of statistically sensitive tools especially important (<xref ref-type="bibr" rid="bib6">Button et al., 2013</xref>). Moreover, when power analyses are used to determine the necessary sample size, then increased statistical sensitivity, such as with the ZETA-test, can reduce the number of required experimental animals. To facilitate the adoption of the ZETA-test by the neuroscientific community, we provide easy-to-use and well-documented open-source implementations online in MATLAB (<ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/ZETA">https://github.com/JorritMontijn/ZETA</ext-link>, <xref ref-type="bibr" rid="bib19">Jorrit, 2021b</xref>) and Python (<ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/zetapy">https://github.com/JorritMontijn/zetapy</ext-link>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>ZETA</title><p>Well documented and easy-to-use Matlab and python code performing the procedures described in the following paragraphs can be found here: <ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/ZETA">https://github.com/JorritMontijn/ZETA</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/zetapy">https://github.com/JorritMontijn/zetapy</ext-link>.</p><p>We developed a timescale-free, binning-less statistical test for determining whether a neuron shows a time-locked modulation of spiking activity. It is derived from a metric that represents the reliability, as number of standard deviations away from chance, that the temporal density of spikes is non-random across trial repetitions. This metric, we call ZETA (ζ), can be computed on a vector of <italic>i = [1 … N]</italic> spike times <bold><italic>x</italic></bold>, and a vector of <italic>k = [1 … q]</italic> event times (e.g. stimulus onsets), <bold><italic>w</italic></bold>, using the following steps.</p><p>First, we make a vector <bold><italic>v</italic></bold> of the spike times in <bold><italic>x</italic></bold> relative to the most recent stimulus onset, as when making a raster plot of spike times:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>where<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>Next, we remove all spike times that are larger than a cut-off value <italic>τ</italic>, for example the trial duration, and add two artificial spikes at t = 0 and t=<italic>τ</italic> to ensure coverage of the full epoch. We sort the <italic>n</italic> spike times in <bold><italic>v</italic></bold> such that <italic>v<sub>i</sub> &lt; v<sub>i+1</sub></italic>, and calculate the fractional position <italic>g<sub>i</sub></italic>, ranging from 1 <italic>/n</italic> to 1, of each spike time in <bold><italic>v</italic></bold>:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Therefore, another interpretation is that <bold><italic>g</italic></bold> represents a neuron’s cumulative density function sampled at the spike times in <bold><italic>v</italic></bold>. In order to quantify whether this distribution is different from our null hypothesis – that is that the neuron’s firing rate is not modulated with respect to the stimulus onset – we compare this vector to a linear baseline density vector <bold><italic>b</italic></bold>. If a neuron’s spiking rate is constant, the cumulative density function is linear over time, and therefore the expected fractional position of spike <italic>i</italic> at time <italic>v<sub>i</sub></italic> converges to the spike time divided by the trial duration <italic>τ</italic> as the number of events <italic>q</italic> increases:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The difference <italic>δ<sub>i</sub></italic> between <italic>g<sub>i</sub></italic> and <italic>b<sub>i</sub></italic> therefore gives a neuron’s deviation from a temporally non-modulated spiking rate at time point <italic>v<sub>i</sub></italic>:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>As we show in the Materials and methods section ‘A proof of time-invariance’, using <italic>δ<sub>i</sub></italic> to compute ZETA would make it dependent on the choice of onset times. Therefore, we create <bold><italic>d</italic></bold>, a time-invariant mean-normalized version of <bold><italic>δ</italic></bold>:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>We then define the Zenith of Event-based Time-locked Anomalies (ZETA, or <italic>ζ<sub>r</sub></italic>) as the most extreme value, that is the maximum of the absolute values:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>ζ</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-2"><title>Null hypothesis for ZETA</title><p>Having calculated ZETA from the temporal deviation vector <bold><italic>d</italic></bold>, we wish to quantify its statistical significance. First, we scale it such that its value is interpretable as a z-score. We therefore construct a null hypothesis distribution by repeating the above procedure <italic>P</italic> times with jittered event-times <bold><italic>w’</italic></bold>, where we move each event time by a random sample drawn from the interval [-τ, τ]. This way, we calculate the chance of observing randomly high values in <bold><italic>d</italic></bold> without having to make assumptions about the underlying distribution of <bold><italic>d</italic></bold>. However, a naive approach would lead to difficulties here, as jittering <bold><italic>w</italic></bold> also changes the corresponding values of <bold><italic>v</italic></bold>; and any jittered vector <bold><italic>d’</italic></bold> we obtain would be sampled at different times than the original vector <bold><italic>d</italic></bold>. Therefore, we instead linearly interpolate the values of jittered fractional position vector <bold><italic>g’</italic></bold> at the original spike times of <bold><italic>v</italic></bold>. First, we construct a vector <bold><italic>f</italic></bold> of fractional spiking positions analogously to <bold><italic>g</italic></bold>, but based on jittered event-times <bold><italic>w’</italic></bold>:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mrow><mml:mi>`</mml:mi></mml:math></disp-formula></p><p>Note that we cannot simply take <bold><italic>g</italic></bold>, as the total number of spikes <italic>n’</italic> in this jittered version is likely different from the original number of spikes <italic>n</italic>, because we only consider the spike times in the interval [0, τ] after the (jittered) event times. Next, we interpolate the values of <bold><italic>f</italic></bold> at sample times <bold><italic>v’</italic></bold> to the original sample times <bold><italic>v</italic></bold>:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:msubsup><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>with<disp-formula id="equ12">.<label>(12)</label><mml:math id="m12"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>≤</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>We repeat this process <italic>P</italic> times; where for each jitter iteration <italic>j</italic>, we calculate <bold><italic>δ</italic></bold><italic>’(j</italic>):<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">δ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Note that <bold><italic>b</italic></bold> is invariant with respect to the jitter iteration, as it is simply the <italic>n</italic>-element linear vector from <italic>1</italic> /n to <italic>n</italic>. As before, we mean-normalize <bold><italic>δ’</italic></bold>(<italic>j</italic>) to obtain a temporal deviation vector <bold><italic>d’</italic></bold>(<italic>j</italic>).<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">δ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>δ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Now we can define a null-hypothesis ZETA sample <italic>j</italic> as:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:msup><mml:mi>ζ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-3"><title>Statistical significance of ZETA</title><p>Having constructed a way to generate samples from a null-hypothesis distribution, we are left with the task of using it in calculating the statistical significance of ZETA. If we had infinite samples, we could directly calculate the percentile of the empirical <italic>ζ<sub>r</sub></italic> from the null-distribution. However, as this is computationally intractable, we will approximate the true distribution from a finite number of null-hypothesis samples. From extreme value theory we know that the distribution of maximum values is known as a Gumbel distribution (<xref ref-type="bibr" rid="bib14">Gumbel, 1941</xref>). Its cumulative density is given by:<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mi>F</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>-</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math></disp-formula></p><p>Here, <italic>x</italic> is the sample maximum (i.e., <italic>ζ<sub>r</sub></italic>), <italic>m</italic> is the mode, and <italic>β</italic> is the scale parameter. Therefore, we need to find <italic>m</italic> and <italic>β</italic>, which can be derived from the estimated sample mean and variance over jittered ZETAs of <bold><italic>ζ’</italic></bold>. The mean <inline-formula><mml:math id="inf1"><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>´</mml:mo></mml:mover></mml:math></inline-formula> and variance <italic>v</italic> are given by <xref ref-type="bibr" rid="bib15">Gumbel, 1954</xref>:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>γ</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Here, γ is the Euler–Mascheroni constant (γ ≈ 0.577), <italic>m</italic> is the mode, and <italic>β</italic> is the scale parameter. Using <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mtext>Var</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ζ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , and <xref ref-type="disp-formula" rid="equ18">Equation 18</xref>, we can write the scale parameter <italic>β</italic> as:<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msqrt><mml:mrow><mml:mn>6</mml:mn><mml:mo>⋅</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>ζ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:msqrt><mml:mi>π</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Then using <xref ref-type="disp-formula" rid="equ17">Equation 17</xref> and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>ζ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , the mode can be computed from <italic>β</italic> and the mean:<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>ζ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>γ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Now we can define the p-value by reading out the cumulative Gumbel distribution at ζ<sub>r</sub>:<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>F</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>ζ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>Finally, we can use <italic>p</italic> with the standard normal’s quantile function <inline-formula><mml:math id="inf4"><mml:msup><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> to obtain a corrected ZETA ζ that is interpretable as a z-score:<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mi>ζ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>Note that when we refer to ZETA or ζ in the rest of the manuscript, we mean the corrected version and its p-value as defined above.</p></sec><sec id="s4-4"><title>Computing an optimal bin size</title><p>For the analyses where we used an optimal binning width to compare the performance of the ZETA-test and a bin-wise ANOVA, we computed the optimal bin width using the procedure described by <xref ref-type="bibr" rid="bib57">Shimazaki and Shinomoto, 2007</xref>. Their method describes a loss function that can be computed for a given bin-width. To find the optimal bin width, we used a simple iterative 10-point grid search until a local minimum was found. The code used for finding the optimal bin size is available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/GeneralAnalysis">https://github.com/JorritMontijn/GeneralAnalysis</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:8513b81b1bf6bc9167f02e3e5f003d0389ae1a13;origin=https://github.com/JorritMontijn/GeneralAnalysis;visit=swh:1:snp:700ebc029d18a736abcdb7eed24016d003ecb6b0;anchor=swh:1:rev:7f866e0c875af17e9d76fdfbd8cec3d41145c031">swh:1:rev:7f866e0c875af17e9d76fdfbd8cec3d41145c031</ext-link>, <xref ref-type="bibr" rid="bib18">Jorrit, 2021a</xref>) in the function <italic>opthist.m</italic>.</p></sec><sec id="s4-5"><title>The multiplicative inhomogeneous Markov Interval (MIMI) Model</title><p>A classic model for neuronal firing rates are inhomogeneous Poisson processes, where a time-dependent function <italic>f(t</italic>) can be used to describe how the mean firing rate <italic>λ</italic> of a cell varies with time <italic>t</italic> after some experimental intervention, such as the onset of a visual stimulus (<xref ref-type="bibr" rid="bib22">Kass et al., 2014</xref>):<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mi>λ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>Spike-times <bold><italic>v</italic></bold> can then be generated by sampling from an exponential distribution with an inter-spike interval equal to 1/<italic>λ</italic>:<disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext>Exp</mml:mtext><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>While this framework is attractive in its simplicity, it cannot capture several important properties of spiking dynamics, such as refractory periods or burst firing. Even when one is only interested in the question whether a particular neuron responds to a visual stimulus, bursting cells might produce apparent bumps in a peri-stimulus time histogram (PSTH). This could lead to the possibly erroneous conclusion that a cell is stimulus-modulated, simply because their spiking patterns are non-Poisson by nature. This problem is remedied by a class of models that combine a Poisson process with a renewal process, which describes the likelihood of a spike conditioned on the time since the last spike. These processes are called multiplicative inhomogeneous Markov interval (MIMI) processes (<xref ref-type="bibr" rid="bib21">Kass and Ventura, 2001</xref>):<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, <italic>s<sub>*</sub>(t</italic>) is the time of the last spike, the <italic>λ<sub>1</sub></italic> term refers to the inhomogeneous Poisson process described above, while the latter <italic>λ<sub>2</sub></italic> term captures the inter-spike-interval dependent spiking probability. While this model can be extended to include interaction terms, n-back spike dependencies, and bias constants per trial, prior work has shown these additions do not appreciably improve the fitting quality (<xref ref-type="bibr" rid="bib21">Kass and Ventura, 2001</xref>). As an additional baseline model, we therefore also compared the performance of the ZETA-test to that of a method based on the MIMI-model (<xref ref-type="disp-formula" rid="equ25">Equation 25</xref>).</p></sec><sec id="s4-6"><title>MIMI-model fit evaluation as a statistical test for responsiveness</title><p>To use the MIMI-model framework as a statistical test, we binned spikes in 1 ms bins. We used cubic splines with 16 B-form coefficients spread uniformly over the trial’s 1.5 s duration for the inhomogeneous Poisson component, and 16 B-form coefficients spread uniformly over a time horizon of 500 ms for the renewal-process component (<xref ref-type="bibr" rid="bib22">Kass et al., 2014</xref>). We then simultaneously fitted these 32 coefficients to produce the closest match to the neuron’s spike train by running a least-squares curve fitting algorithm. Specifically, we minimized the error between the stimulus-locked trace reconstituted from the B-form splines and the real average spiking rate per bin of the PSTH. The fitting procedure used 1 ms binning, but the resulting model can be resolved at theoretically infinitesimal time steps. We ran a couple of fits with different numbers of coefficients ranging from 8 + 8–32 + 32, but this did not strongly impact either the fitting quality or computation time (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>Theoretically, we could now follow the same procedure as with the ZETA-test by generating a null-hypothesis distribution from multiple iterations of jittered onset times. However, the MIMI fitting procedure’s computational time cost meant this was not a realistic solution: even a single MIMI-model fit took 557 times as long to run as the ZETA-test, which already included 100 random jitter iterations (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, panel H). This means that using 100 random jitters for the MIMI-model test would take 55,700 times as long as the ZETA-test. We therefore took an alternative approach by calculating pairwise d’ values (i.e. the distance in standard deviations between the two bins) for all bin pairs, and transformed the highest d’ into a p-value. This is obviously a suboptimal approach, as this will lead to a high number of false positives. However, our goal here is not to develop a full-fledged MIMI-based test, but rather to verify what the statistical sensitivity of such an approach could be. It is possible to investigate the statistical sensitivity as the low p-value bias exists for both real data and shuffle controls, so instead of comparing the inclusion level at an alpha of 0.05, we performed an ROC analysis over all cells in V1.</p><p>The ROC analysis is insensitive to the absolute level of significance values, but instead provides insight in the discriminability of real inclusions from false positives (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, panel G). To keep the computational time tractable, we subsampled the data to include only V1 cells, and only their response to the first 480 drifting grating trials. We compared the ZETA-test, t-test and MIMI-model method as described above. The ZETA-test gave an area under the curve (AUC) of 0.996, the t-test 0.900, and the MIMI-method 0.749. However, we noticed that the MIMI-method appeared to fail mostly for cells with low firing rates, so we also added a hypothetical curve where we only included neurons with &gt; 1000 spikes during the 480-trial long epoch (MIMI-1k). This significantly boosted the MIMI-method’s discriminability to an AUC similar to the t-test’s at 0.898. Perhaps choosing a different number of coefficients would improve the MIMI test, but the issue remains that this test does not work without manual tuning. These results suggest it will require significant work to develop a MIMI-based test that can compete with a t-test, and that even if we were successful, it might not exceed the ZETA-test’s performance. Moreover, as the MIMI-model requires parameters to be iteratively fitted to experimental data, it is multiple orders of magnitude slower than the ZETA-test and t-test. To conclude, full MIMI-model based methods do not seem to be suited for unsupervised, large-scale use as neuronal responsiveness tests.</p></sec><sec id="s4-7"><title>Decomposition of ZETA</title><p>While using full multiplicative inhomogeneous Markov interval models of the form of <xref ref-type="disp-formula" rid="equ25">Equation 25</xref> is not a viable option when creating a responsiveness test, we used it as a starting point to further explore which properties of the ZETA allow it to function so well. As already noted above, the main problem for developing a robust responsiveness test is finding a suitable null-hypothesis distribution to test against. As a first naïve baseline, we built a simple test that checks whether a cell’s firing rate, binned with width τ and averaged across trials, differs from a homogeneous Poisson process with rate λ. Under this null-hypothesis, the number of spikes per bin <italic>X</italic> is therefore distributed as:<disp-formula id="equ26"><label>(26)</label><mml:math id="m26"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The null-hypothesis random variable H<sub>0</sub> for rates averaged over T trials follows:<disp-formula id="equ27"><label>(27)</label><mml:math id="m27"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>T</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>Whether a neuron’s observed number of spikes per bin, averaged over trials, differs from this null distribution can then be tested using a standard Kolmogorov-Smirnov test.</p><p>We benchmarked this approach with V1 cells, using 1 ms bins, and performed an ROC analysis of real inclusions versus false positives using two different ways to construct neuronal responses that are unmodulated by the visual stimulation: (1) we shuffled the inter-spike intervals to construct a new set of spike times (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3A</xref>) and (2) we jittered the stimulus onset times by ±6 s (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3B</xref>). We found that the Poisson-based test performed well if the H0 spiking statistics matched the shuffle-control (Poiss-KS, AUC = 0.976), but failed due to high numbers of false positives when we instead jittered the stimulus onset times (Poiss-KS, AUC = 0.611). By construction, the fluctuations in the rate are not linked to the stimulus onset times anymore, but the distribution of the spike times over the trial period are not consistent with a Poisson neuron.</p><p>This may seem a trivial result, as the null-hypothesis distribution in this latter case does not match the null (Poisson) distribution used by the statistical test. This is a critical issue, however: in the case of real experimental data sets, there is no known ground truth, so a robust statistical test for neuronal responsiveness must be able to handle a wide variety of intrinsic spiking behaviors. Clearly, the Poisson test fails this requirement, as it is only able to distinguish i.i.d. Poisson-distributed spiking from anything that is not exactly i.i.d. Poisson-distributed spiking. For comparison, both the ZETA-test and t-test show robust behavior that is insensitive to the specifics of the shuffle-control we use. The ZETA-test gives an AUC of 0.983 using ISI-shuffles and 0.984 using onset jittering; and the mean-rate t-test gives AUCs of 0.899 and 0.902 respectively. In the following section, we investigate which properties of the ZETA-test allow it to perform so much better than the Poisson test.</p><p>The first aspect we investigated is the assumption of the homogeneous Poisson-distributed spiking when a neuron is unmodulated by visual stimulation. We know that neurons can be intrinsically bursting and have refractory periods, so even the most purely sensory-driven cell in V1 is likely to not fire i.i.d. Poisson when no visual stimulus is present. A more versatile and possibly more accurate H0 might be a renewal process. We therefore constructed an inter-spike-interval (ISI)-based test, where we first calculated a neuron’s inter-spike intervals <italic>d<bold>t</bold></italic> from its spike time vector <bold><italic>t</italic></bold>:<disp-formula id="equ28"><label>(28)</label><mml:math id="m28"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>We then randomly permuted the ISIs, creating a shuffled ISI vector <italic>d<bold>t</bold><sup>s</sup></italic> and using it to construct a null-hypothesis vector of spike times <bold><italic>t</italic></bold><italic><sup>0</sup></italic>:<disp-formula id="equ29"><label>(29)</label><mml:math id="m29"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p><p>In effect, this null-hypothesis vector is a different random sample of the same renewal process that would generate the real neuron’s spiking times, under the simplifying assumption that the spike times are generated by a renewal process. We constructed mean firing rates <bold><italic>x</italic></bold><italic><sup>0</sup></italic> by binning <bold><italic>t<sup>0</sup></italic></bold> using 1 ms bins. We repeated this 100 times, and used a two-sample K-S test between the real binned spike count vector <bold><italic>x</italic></bold> and shuffle-control spike count matrix <bold><italic>X</italic></bold><italic><sup>0</sup></italic>, as we also did for the Poisson test described above. Unfortunately, this SISI-KS (Shuffled Inter-Spike-Interval Kolmogorov-Smirnov) test performed very similar to the Poisson test, resulting in an AUC of 0.985 for the ISI-shuffle control, and an AUC of 0.610 for the jitter-control.</p><p>This similarity might be explained by the ability of the KS test to distinguish with high sensitivity between the spiking distributions obtained from shuffling ISIs and jittering stimulus onsets, as these are not identical. If we wish to construct a more robust test, we must therefore use a procedure that is less sensitive to the full shape of the H0 distribution, and only takes into account the likelihood of observing extreme deviations from the average firing rate. This will make the test less sensitive to real stimulus-induced activity, but also less sensitive to errors in the specific shape of the null hypothesis distribution we use to estimate the neuron’s natural variability. We achieved this by using the Gumbel-distribution of maximum absolute deviations in our random ISI-shuffle samples to calculate a p-value of the maximum absolute deviation in the real, unshuffled, PSTH. The procedure works as intended: this SISI-G test gives an AUC of 0.844 for the ISI-shuffle controls, and an AUC of 0.821 for the jitter controls.</p><p>We noticed that the SISI-G test suffered from high variance in the PSTH when using 1 ms bins, especially for cells with few spikes. One option would therefore be to increase the bin width, but this would come at the expense of temporal resolution and ability to detect short peaks of activity. We therefore opted instead to calculate the maximum absolute deviation of the cumulative sum of spikes counts, similar to the ZETA-test’s, but in this case over the discrete 1 ms spike count vector <bold><italic>x</italic></bold><italic><sup>0</sup></italic>. For the SISI-∫G test, we defined the normalized cumulative spike count vector T0 (similar to <xref ref-type="disp-formula" rid="equ29">Equation 29</xref>) as:<disp-formula id="equ30"><label>(30)</label><mml:math id="m30"><mml:mrow><mml:msubsup><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>Moreover, as this would create fixed points with 0 variance at j = 1 and j = n, we also mean-subtracted the T0 vector itself:<disp-formula id="equ31"><label>(31)</label><mml:math id="m31"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">T</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>T</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>In essence, this test is a 1 ms binned and ISI-shuffle based version of the binless onset-jittering ZETA-test. Benchmarking this test, we found that it performed close to, but slightly less well than, the ZETA-test. This SISI-∫G test gave an AUC of 0.968 for the ISI-shuffle controls and an AUC of 0.974 for the jitter controls.</p><p>Finally, we created an alternative, also binless, version of the ZETA-test where we created the null distributions by shuffling the inter-spike intervals rather than jittering the stimulus onsets. The alternative ZETA-ISI test performed at a level indistinguishable from ZETA; the ZETA-ISI gave an AUC of 0.986 for the ISI-shuffle controls and an AUC of 0.982 for the jitter controls. To conclude; the (alternative) ZETA-test strongly outperforms other tests, mainly for two reasons: (1) using the Gumbel distribution to calculate a cell’s significance based on the most extreme stimulus-locked spiking deviation rather than a KS test allows the ZETA-test to be relatively invariant to the full, and a priori unknown, spike time distribution of a neuron and (2) using an integral-based approach has a timescale-free smoothing effect that reduces spurious peaks that can occur in the firing rate domain. Finally, the binless ZETA-test shows a small, but significant, improvement over its 1 ms binned cousin in terms of both statistical power and computational efficiency (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3C</xref>). While the random null distribution (ISI shuffling or onset jittering) did not seem to have a large impact on the ZETA-test’s performance for this data set of predominantly regular-spiking V1 neurons, the following section shows that this distinction becomes more important when one tests the responsiveness of bursting cells.</p></sec><sec id="s4-8"><title>Simulated bursting cells: onset jittering versus inter-spike interval shuffling</title><p>Stimulus onset jittering and inter-spike interval shuffling produce different distributions, unless a neuron’s probability of spiking only depends on the time since the last spike. The previous section showed that, when using our V1 data set, performance has already saturated too much to show a difference between the ISI-shuffle ZETA and onset-jitter ZETA tests. To better differentiate their performance, we therefore generated a population of simulated bursting cells. While bursting cells are rare in visual cortex, they are abundant in many brain regions, such as the subiculum and others (<xref ref-type="bibr" rid="bib9">Cooper, 2002</xref>; <xref ref-type="bibr" rid="bib32">Mattia et al., 1993</xref>). To test the performance on bursting cells, we generated artificial spike trains, using the parameters for burst properties from <xref ref-type="bibr" rid="bib8">Chen et al., 2009</xref> as listed in <xref ref-type="table" rid="table1">Table 1</xref>.</p><p>All cells were assigned a background single-spike firing rate that was on average 1 Hz; on top of these single spikes we generated bursts with varying length and inter-spike intervals. The inter-burst intervals were 16 s on average during inter-trial intervals and non-preferred stimuli; and 0.8 s during the neuron’s preferred stimulus. Each neuron had a randomly assigned preferred orientation and tuning width following a von Mises distribution. We presented 20 repetitions of 24 orientations (15 degree steps) for a total of 480 trials. We generated responses for 1,000 independently parameterized neurons (see <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3D-E</xref>). To create stimulus non-responsive neurons, we set the inter-burst intervals to be approximately 6.8 s both within and outside stimulus presentation; we chose this value to ensure the spiking rate distributions for stimulus-responsive and unresponsive neurons were approximately equal (25th-75th population percentiles of firing rates; stimulus-responsive: 6.7–19.7 Hz; unresponsive: 6.9–20.7 Hz).</p><p>Running the same benchmark as before on this artificial data set, we found that the onset-jitter ZETA-test indeed outperformed both the ISI-shuffle ZETA-test and mean-rate t-test (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3F</xref>). The ZETA-test gave an AUC of 0.941, the ISI-shuffle ZETA-test an AUC of 0.845, and the mean-rate t-test an AUC of 0.902. This difference in performance can be attributed to the fact that jittering stimulus onsets keeps the properties of individual bursts intact, while ISI-shuffling changes these properties, leading to more variable burst spike trains. While shuffling of ISIs or stimulus onsets both produce spike trains that are unmodulated by stimulus presence, we have shown that they are not equivalent.</p></sec><sec id="s4-9"><title>Multi-scale derivatives of ZETA for latency detection</title><p>The ZETA-test indicates whether a neuron shows reliable deviations in spiking rate with respect to a particular series of events. The time of this maximum deviation, however, is not necessarily when the neuron shows its strongest firing rate modulation, but rather when the cumulative distribution reaches peak statistical significance. Therefore, in order to use the ZETA procedure to calculate the time of peaks in modulations (e.g. onset latencies), we should take the derivative of the temporal deviation vector <bold><italic>d</italic></bold> underlying ZETA. A naïve approach with a simple spike-to-spike derivative unfortunately yields a curve with many spurious peaks. One solution would be to calculate the derivative over a larger time interval, but this comes at the expense of temporal resolution. Moreover, many different cell types exist with different dominant time constants. To balance temporal resolution and robustness, we therefore developed a multi-scale derivative procedure. First, we define a vector <bold><italic>t</italic></bold> of <italic>S</italic> timescales at which to compute derivatives. By default, we define the timescales to lie on a logarithmic scale with base 1.5, as this gave a reasonable trade-off between computational speed and accuracy. Base values closer to one will give more accurate results at the cost of computational speed. For base <italic>b</italic> and a trial duration of <italic>τ:</italic><disp-formula id="equ32"><label>(32)</label><mml:math id="m32"><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ33"><label>(33)</label><mml:math id="m33"><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∣</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">Z</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mi>τ</mml:mi><mml:mn>10</mml:mn></mml:mfrac></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The derivative <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> at spike <italic>i</italic> can then be defined for <italic>d<sub>i</sub></italic> and timescale <italic>t<sub>k</sub></italic> as:<disp-formula id="equ34"><label>(34)</label><mml:math id="m34"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where<disp-formula id="equ35"><label>(35)</label><mml:math id="m35"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Here, <bold><italic>v</italic></bold> are spike times, following the definition above. To avoid undefined edges, we set <italic>a</italic> and <italic>b</italic> to one and <italic>n</italic> respectively, iff <italic>v<sub>i</sub> ± t<sub>k</sub>/2</italic> falls outside the interval <italic>[0, τ]</italic>. Taking the mean over all <italic>S</italic> timescales, we obtain an average of multi-scale derivatives <bold><italic>m</italic></bold>,<disp-formula id="equ36"><label>(36)</label><mml:math id="m36"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>S</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>which has two important properties. First, long-timescale derivatives tend to 0, so there is a bias of <bold><italic>m</italic></bold> to more strongly follow shorter timescales. Secondly, random noise at the shortest timescales averages out over multiple short-timescale derivatives. Therefore, these two properties combined lead <bold><italic>m</italic></bold> to reflect the shortest timescales at which a real signal starts to emerge from random noise.</p></sec><sec id="s4-10"><title>Calculation of high-resolution instantaneous firing rates</title><p>Another interesting property of the mean multi-scale derivative <bold><italic>m</italic></bold> is that it scales with the actual firing rate. In other words, it produces a time-locked neural activation curve, similar to a peri-stimulus time histogram (PSTH). If we properly rescale <bold><italic>m</italic></bold>, we can therefore create an instantaneous firing rate metric with a temporal resolution that is only limited by the spike density.</p><p>Remember that the temporal deviation vector <bold><italic>δ</italic></bold> itself is scaled to lie between –1 and +1, as its value depends on the difference between the fractional position of a spike (from 0 to 1) and the linear interval from <italic>x,y=[0,0]</italic> to <italic>[τ,1]</italic>. The theoretical lower limit of the multi-scale derivative is therefore <inline-formula><mml:math id="inf6"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. This can be illustrated as follows. Imagine a hypothetical neuron where all spikes are fired in an arbitrarily short interval close the start of each trial. This means that <bold><italic>δ</italic></bold> rises from 0 to 1 in a short interval and from then decays linearly from 1 to 0 over an interval of <italic>τ</italic>. As <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is defined between two spikes (including window edges 0 and <italic>τ</italic>), this means that the lowest possible value in this extreme case is the point between the last spike <italic>n</italic> and <italic>τ</italic>, i.e.:<disp-formula id="equ37"><label>(37)</label><mml:math id="m37"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">min</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The lowest possible firing rate is 0 Hz, which therefore corresponds to <inline-formula><mml:math id="inf8"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> . An upper bound for <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> does not exist, as an arbitrarily short interval with a finite number of <italic>n</italic> spikes would lead to arbitrarily high <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> :<disp-formula id="equ38"><label>(38)</label><mml:math id="m38"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>d</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo form="prefix" movablelimits="true">max</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></disp-formula></p><p>This is a desirable property, as the maximum instantaneous firing rate of a neuron is not theoretically constrained. Finally, the average firing rate of our metric should correspond to the real average firing rate in Hz (<italic>n/τq</italic>), where <italic>q</italic> is the number of events as defined above. We therefore define our instantaneous firing rate metric <italic>r</italic> as:<disp-formula id="equ39"><label>(39)</label><mml:math id="m39"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⋅</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is the weighted average of <bold><italic>m</italic></bold> by the inter-spike interval, such that the averaging occurs in the time domain and not the spike-number domain:<disp-formula id="equ40"><label>(40)</label><mml:math id="m40"><mml:mrow><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Considering the definitions above, we can therefore state that the maximum firing rate in <bold><italic>r</italic></bold> occurs where<disp-formula id="equ41"><label>(41)</label><mml:math id="m41"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>is at its maximum, with <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the index of the largest spike time smaller than <inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the index of the smallest spike time larger than <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula> ; with <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> being the logarithmically distributed time ranges. In the limit of a high number of spikes, we find that <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula> , and therefore,<disp-formula id="equ42"><label>(42)</label><mml:math id="m42"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>S</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">#</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>which is an average of the instantaneous spike rates at <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at timescales <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-11"><title>Mean-rate artificial Poisson neurons</title><p>We tested whether ZETA required short bursts of activity to work by generating artificial spike trains that only varied in mean-rate between a 1 s stimulus presentation and a 1 s inter-stimulus interval, and did not show onset peak responses. We created spike trains for 100 neurons with an orientation preference θ randomly sampled from a uniform distribution on the interval (0,π). The shape of the tuning curve was defined as the sum of two von Mises distributions centered at preferred orientation θ and θ+π with a concentration parameter of κ = 5 + ε, where ε was randomly sampled from a uniform distribution on the interval (0,5). The von Mises probability density function with mean θ and concentration parameter κ is given by:<disp-formula id="equ43"><label>(43)</label><mml:math id="m43"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∣</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>κ</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>κ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Here, where <italic>I</italic><sub>0</sub>(κ) is the modified Bessel function of order 0. The baseline mean spiking rate µ<sub>base</sub> was defined by randomly sampling from an exponential distribution with a mean of λ<sub>base</sub> = 5 Hz. µ<sub>base</sub> defined the trough of the neuron’s tuning curve (i.e. the activity at θ+π/2 and θ-π/2) as well as the activity of the neuron when no stimulus was present. The firing rate for the preferred stimulus µ<sub>stim</sub> was determined by similarly sampling from an exponential distribution with a mean of λ<sub>stim</sub> = µ<sub>base</sub> +20 Hz. We generated spiking activity for 160 trials (20 repetitions of 8 stimulus orientations: θ<sub>stim</sub> = [0, 45, …, 315]). The average baseline firing across all n = 10,000 artificial neurons was therefore 5 Hz and the average firing rate during the preferred stimulus was 25 Hz. Spike times were generated for each trial-epoch (stimulus/baseline) independently by consecutively drawing inter-spike intervals from a Poisson distribution with λ = 1/µ.</p></sec><sec id="s4-12"><title>Artificial Poisson neurons for peak-latency benchmarking</title><p>We also addressed the question whether our instantaneous firing rate metric was sufficiently robust to allow accurate peak-time detection over a range of background firing rates and a range of peak widths. The procedure here was similar as above, with the exception that the firing rate during baseline and stimulus periods was identical: µ<sub>base</sub> = µ<sub>stim</sub>. We tested 13 base rates (0.5–32 Hz) and 19 jitter widths (1–10 ms in steps of 0.5). For each combination of base rate and jitter width, we generated 100 neurons and 100 trials per neuron. Peaks were added to the background activity by adding a single spike to half of all trials. Spike times were chosen by random sampling from a normal distribution with the standard deviation equal to the above jitter width and centered at 100 ± 10 ms after stimulus onset.</p><p>Figure panels 6 J,K used slightly different parameters. Instead, we used 10 jitter widths (1–10 ms in steps of 1), simulated only a base rate of 32 Hz, used 160 trials for 1000 neurons, and compared the peak-latency detection using the ZETA-IFR with binning windows ranging from 1.00 ms to 57.67 ms; a logarithmic scale of base 1.5 with the exponent ranging from 0 to 10 in steps of 1.</p></sec><sec id="s4-13"><title>Acquisition and preprocessing of laminar probe data (neuronexus and neuropixels)</title><p>We performed silicon probe recordings in six C57BL/6 mice, 2–7 months of age. Mice were housed in a 12 hr/12 hr dark/light cycle with ad libitum access to food and water. All experiments were approved by the animal ethics committee of the Royal Netherlands Academy of Arts and Sciences, in compliance with all relevant ethical regulations.</p><p>Mice were habituated for 1–4 weeks before being implanted with a cranial bar used for head-fixation. Mice were anesthetized with isoflurane (3 % induction, 1–1.5% maintenance in 50 % O2) and injected subcutaneously with an analgesic and anti-inflammatory compound (Metacam, 2 mg/kg). The eyes were protected from drying by Cavasan eye ointment. They were moved to a stereotact with a thermal mat to keep their core temperature at 37°C, and the fur on their heads was removed. Once anesthesia was sufficiently deep, as indicated by the absence of a toe-pinch reflex, we applied lidocaine locally on the skin of the head and sterilized it with 70%-ethanol or betadine. The skin was removed, the skull cleaned, and a small metal rod was fixed to the skull anterior of bregma with the use of blue-light curing dental cement. If necessary, we sutured the skin, and let the mice recover for 2–7 days.</p><p>After the mice recovered as indicated by a return to their pre-operative weight, mice were habituated to sitting head-fixed in the electrophysiology rig for 3–10 days. Once habituated, they underwent a craniotomy surgery, following the same preparatory steps as described above. Before performing the craniotomy (1.5–3 mm in diameter), we first constructed a small ring of dental cement so the brain could be bathed in saline during recordings to avoid tissue desiccation. Once the craniotomy was complete, this ring was filled with sterile silicone, and the animals were left to recover for at least 16 hr. Over the next 1–7 days, we performed repeated-insertion recordings using either NeuroNexus or Neuropixels silicon probes. For a subset of animals, we dipped the probe into DiI on the last day of recording, and perfused the animal to perform post-hoc tracing of the electrode recording locations. For the remaining recordings, the probe position was determined using anatomical landmarks (i.e., bregma and lambda).</p><p>NeuroNexus recordings were performed using either a Tucker-Davis Technologies digitizer and custom-written MATLAB code as described previously (<xref ref-type="bibr" rid="bib1">Ahmadlou and Heimel, 2015</xref>). Neuropixels recordings were performed using a National Instruments I/O PXIe-6341 module and SpikeGLX (<ext-link ext-link-type="uri" xlink:href="https://github.com/billkarsh/SpikeGLX">https://github.com/billkarsh/SpikeGLX</ext-link>). Visual stimulation was performed as described previously (<xref ref-type="bibr" rid="bib35">Montijn et al., 2016a</xref>), and synchronized with high accuracy ( &lt; 1 ms) using photodiode signals that recorded visual stimulus onsets. Spikes were sorted post-hoc using Kilosort2 (<ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/Kilosort2">https://github.com/MouseLand/Kilosort2</ext-link>, <xref ref-type="bibr" rid="bib43">Pachitariu, 2021</xref>) and only clusters of sufficient quality, as defined by Kilosort2’s default threshold, were included for further analysis. High-quality clusters (i.e. putative neurons) were assigned a brain region using the AllenCCF MATLAB toolbox (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/allenCCF">https://github.com/cortex-lab/allenCCF</ext-link>, <xref ref-type="bibr" rid="bib46">Peters, 2021</xref>), which automatically calculates a neuron’s anatomical position based on penetration location, angle, and depth of the silicon probe. Abbreviations for brain areas mostly follow the Allen Brain Atlas area codes. V1: primary visual cortex. AM: anteromedial visual cortex. PM: posteromedial visual cortex. LGN: lateral geniculate nucleus. LP: lateral posterior nucleus. NOT: nucleus of the optic tract. APN: anterior pretectal nucleus. SC: superior colliculus. All code used in laminar probe data acquisition and pre-processing is available online (<ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/Acquipix">https://github.com/JorritMontijn/Acquipix</ext-link>, <xref ref-type="bibr" rid="bib37">Montijn, 2021</xref>).</p></sec><sec id="s4-14"><title>Visual stimulus parameters</title><p>Visual stimuli during Neuronexus and Neuropixels recordings were shown at 60 Hz on a 51 by 29 cm Dell screen at 17 cm distance from the animal’s eyes, using Psychtoolbox three in Matlab. Drifting gratings were displayed within a 120 visual-degree diameter window with two visual-degree cosine edge that faded smoothly into a neutral-gray background. Drifting gratings were shown in 24 directions: [0, 15, … 345] degrees at a spatial frequency of 0.05 cycles per degree and a temporal frequency of 1 cycle per second. Natural movies were 20 s long and consisted of four distinct scenes taken from the BBC nature documentary Earthflight (<xref ref-type="bibr" rid="bib35">Montijn et al., 2016a</xref>).</p><sec id="s4-14-1"><title>Acquisition and preprocessing of retinal multi-electrode array data</title><p>Adult ( &gt; 1 year) zebrafish (<italic>Danio rerio</italic>), were dark-adapted for at least 1 hr. Then under IR illumination fish were euthanized by rapid immersion in ice-cold water, the eyes removed, the retina isolated and placed photoreceptor side up on a perforated 60 electrode array (60pMEA200/30iR-Ti using a MEA2100 system: Multichannel systems, Reutlingen, Germany) in a recording chamber mounted on an Nikon Optiphot-2 upright microscope and viewed under IR with an Olympus 2 x objective and video camera (Abus TVCC 20530). Room temperature Ames’ medium (Sigma-Aldrich) gassed with a mixture of O2 and CO2 at pH of 7.6 continuously superfused the MEA recording chamber.</p><p>Extracellular multiunit GC activity was recorded at 25 kHz in MC rack (Multichannel systems, Reutlingen, Germany), zero-phase bandpass filtered (250–6250 Hz) with a fourth-order Butterworth filter in Matlab (MathWorks, Natick, MA, USA), and sorted into single-unit activity with ‘offline spike sorter’ (Plexon, Dallas, TX, USA). Spikes were detected using an amplitude threshold <italic>&gt;</italic> 4σ<sub>n</sub> where σ<sub>n</sub> is an estimation of the background noise<disp-formula id="equ44"><label>(44)</label><mml:math id="m44"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>0.6745</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>with <italic>x</italic> being the bandpass-filtered signal (<xref ref-type="bibr" rid="bib50">Quiroga et al., 2004</xref>). The detected spikes were manually sorted into single units based on the first two principal components versus time.</p><p>The light stimulus consisted of a 500 ms full field light flash, preceded and followed by a 500- and 1000 ms period of darkness, generated using Psychophysics Toolbox Version 3 (<xref ref-type="bibr" rid="bib5">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib25">Kleiner et al., 2007</xref>), and repeated either 50 or 100 times. Stimuli were projected onto the retina from the photoreceptor side by a DLP projector (Light Crafter 4500, Wintech, Carlsbad, CA, USA) using a custom-built 2 x water immersion objective. Only white light stimuli were used. The “dark” light intensity was 6 μW/m2, and the maximal ‘light’ intensity was 176.2 μW/m<sup>2</sup>.</p></sec><sec id="s4-14-2"><title>Acquisition and preprocessing of calcium imaging data</title><p>Drifting grating responses were recorded as previously described (<xref ref-type="bibr" rid="bib35">Montijn et al., 2016a</xref>) and putative spike times were extracted using an exponential fitting algorithm (<xref ref-type="bibr" rid="bib36">Montijn et al., 2016b</xref>). All codes used in pre-processing of drifting grating calcium imaging data are available online (<ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/Preprocessing_Toolbox">https://github.com/JorritMontijn/Preprocessing_Toolbox</ext-link>).</p><p>Virtual corridor experiments were performed on adult male RCFL-tdTOM x PV FlpO x VIP2r-cre (n = 1) and VIP2r-cre mice (n = 3). During water restriction, the weight of the animals was carefully monitored and kept stable through powdered milk intake (10 % diluted in drinking water) in the corridor or additionally fed solid drink. Mice were kept on a reversed day/night schedule (12 hr/12 hr) and experiments were performed in their active dark phase.</p><p>For virus injection and chronic window implantation procedures, animals were anesthetized with isoflurane at 5 % for induction and 1.0–1.5% for maintenance. Metacam (1 mg/kg) was administered subcutaneously for systemic analgesia and dexamethasone (8 mg/kg) was administered to prevent brain swelling. The eyes were covered throughout the surgeries with Cavasan ointment. For virus injections, three small holes were drilled around the center of the right V1 (2.9 mm lateral from midline, 0.5 mm anterior from lambda). Animals were injected with saline-diluted AAV2/1.hSyn.GCaMP6f.WPRE.SV40 (Addgene) at a depth of 250 and 550 µm (final concentration, 10<sup>12</sup> viral particles/ml; 36.8 nl/depth/location). Mice were allowed to recover for a minimum of 2 weeks in their home cage before window implantations. For chronic window implantations, a custom-made head bar was positioned above V1 and fixed on the skull with dental cement (Kerr). A circular 3 mm craniotomy was made on the area of injection while the dura was kept intact. A double glass window (3 + 4 mm diameter) was placed inside the craniotomy and fixed on the skull with dental cement (Kerr). Animals were allowed to recover for a minimum of 1 week before training began.</p><p>Before imaging, mice were trained to being head fixed and run through a virtual corridor on a custom-made treadmill (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). Running speed of the mice was measured with a rotary encoder and processed using an Arduino and Matlab. Absolute running speed was used to render the virtual corridor in real-time. The left half of the virtual corridor was rendered on a gamma-corrected monitor (Dell) placed under an angle of 45° with a mirror to create the perception of a symmetrical corridor. The virtual corridor was written in Matlab using OpenGL and Psychophysics Toolbox three and contained a 100 cm black and white Gaussian noise texture with overlying visual stimuli. We used three vertical gratings and three checkerboard stimuli positioned 11 cm apart, at locations 22–77 cm (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). After completing a run in the corridor, mice were immediately shown a luminance-matched gray screen followed by a 0.5 s auditory cue (8 kHz) 1 second later. Two seconds after this cue, the mice received a 5–10 µl milk reward. Mice were trained for ~ 10 sessions until they completed up to ~ 150 trials during imaging sessions.</p><p>Imaging was performed with a two-photon microscope (Neurolabware) equipped with a Ti-sapphire laser (Mai-Tai ‘Deepsee’, Spectraphysics; wavelength, 920 nm) and a 16 x, 0.8 NA water immersion objective (Nikon). The microscope was controlled by Scanbox (Neurolabware) running on Matlab. One one mouse we performed dual-plane imaging at 15.5 Hz/plane using an electrically tunable lens (OptoTune). The other three mice were imaged in a single plane at 15.5 Hz. During the pre-processing stage, we discarded all interneurons and only included putative pyramidal cells for further analysis.</p></sec><sec id="s4-14-3"><title>Analysis of virtual corridor joint-feature encoding</title><p>For each neuron, we calculated ZETA-scores after aligning the putative spike times to trial start (‘time-aligned’), converting spike times to locations and aligning them to the beginning of the corridor (‘location-aligned’), or aligning the spike times to a visuomotor mismatch event, where rendering of the virtual corridor was paused for 500 ms (‘mismatch-aligned’) (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). We call the resulting values time-modulation, location-modulation and mismatch-modulation respectively. In the case of the spatial “location-aligned” analysis, we furthermore discarded the first and last 10 % of the track to avoid including the start and end box locations. We investigated whether there was a relationship between the modulation values that neurons showed for these three different features in two ways. First, we simply calculated the Pearson correlation at the level of a single recording between time/location, time/mismatch, and location/mismatch modulations (<xref ref-type="fig" rid="fig7">Figure 7D–F</xref>). A one-sample t-test on these correlation values showed there was a significant, positive correlation for time/location and a significant, negative correlation for location/mismatch. However, this analysis does not directly answer the question whether the joint encoding of two features at the level of single neurons is more or less likely than we would expect by chance.</p><p>We therefore z-scored the modulation values per recording and pooled all neurons. We then used a kernel-density estimator (KDE) to construct a probability density estimate for the distribution of modulation values for time, location, and mismatch (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Combining these distributions for a pair of features, we obtain a null-hypothesis distribution of what the joint-feature-encoding distribution would look like if the modulation-scores are independent of each other. Using the same bandwidths as for the single-feature KDE-distributions, we smoothed the real data so we could directly compare which regions are over- or under-represented in the real data, producing the heat maps in <xref ref-type="fig" rid="fig7">Figure 7G–I</xref>. To quantify this over/underrepresentation, we counted the number of neurons in the upper-right quadrant, where neurons lie that have high modulation scores for both features. We compared the real count to the distribution obtained from 10,000 random samples taken from the joint-feature KDE-derived null-hypothesis distribution, where there is no correlation between the two feature modulation scores. As shown in <xref ref-type="fig" rid="fig7">Figure 7G-I</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, time and location-modulation scores were more often both high in single neurons than expected from chance. Moreover, there were fewer neurons that showed a joint encoding of both spatial location and visuomotor mismatch than expected from chance.</p></sec><sec id="s4-14-4"><title>VIP-optogenetics analysis of Allen Brain Institute cephys data</title><p>Detailed information on experimental and data acquisition procedures can be found online at the Allen Brain Institute website: <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>. We used data from 5 Vip-IRES-Cre; Ai32 mice that underwent laser-based optogenetic stimulation. We pre-selected 1706 clusters that were recorded in visually-responsive cortex (AL, AM, PM, L, V1, RL, or MMP) and were of sufficient quality, specifically: KiloSort2 tagged the cluster as “good”, ISI violations were under 0.5, amplitude thresholds under 0.1, and presence ratios over 0.9. The next step was to cull this population to only cells that showed modulated spiking with respect to the onset of optogenetic stimulation. We therefore included N = 1144 cells that showed <italic>P</italic> &lt; 0.05 with a ZETA-test on the window between (–0.5, + 0.5 s) after optogenetic stimulation. We calculated the peak-response latency using our IFR method and discarded cells with peak responses earlier than 1 ms after optogenetic stimulation onset (N = 909). The remaining cells were classified as VIP if their IFR peak latency was &lt; 10 ms (N = 13), as Inhibited if their firing rate was significantly lower during 10–30 ms after optogenetic stimulation than during the 50 ms preceding optogenetic onsets (N = 59), as Activated if their rate was significantly higher during 10–30 ms after optogenetic onset than during the pre-stimulus baseline (N = 137), and otherwise as Other (N = 700). The large size of this latter group could be explained by many cells being visually-responsive to the blue laser light. We chose a 10–30 ms window to compare the IFR peak/trough latencies of Activated and Inhibited cells, as 10 ms was the time of laser offset, and visual responses start to emerge in visual cortex after about 30–50 ms.</p></sec></sec><sec id="s4-15"><title>A Proof of Time-Invariance</title><p>We have described some properties of the ZETA-test in the main method section, but we have not yet explained what the function is of the mean-subtraction of <italic>δ</italic> in <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>. This step plays a critical role in ensuring that the ZETA-test is time-invariant: i.e., that the latency of a neuronal response with respect to the stimulus onset does not affect the statistical significance of the ZETA-test.</p><p>We can see that this is the case if we have made a specific choice for the trial onsets, consisting of consecutive intervals of <italic>τ</italic>, and made a set of <italic>n</italic> spike times <italic>v<sub>1</sub></italic> to <italic>v<sub>n</sub></italic> in the interval <italic>[0, τ]</italic>. First we rewrite <xref ref-type="disp-formula" rid="equ1">Equations 1</xref>–<xref ref-type="disp-formula" rid="equ4">4</xref> as:<disp-formula id="equ45"><label>(45)</label><mml:math id="m45"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Recall that <italic>d<sub>i</sub> = δ<sub>i</sub> – 1 /n Σ<sub>i</sub> δ<sub>i</sub></italic> (<xref ref-type="disp-formula" rid="equ6">Equations 6</xref>; <xref ref-type="disp-formula" rid="equ7">7</xref>). Now, consider a shift of the trial onset times by <italic>Δ</italic> and let <italic>v<sub>k</sub></italic> be the highest spike time smaller than <italic>Δ</italic>. This results in a new set of <italic>n</italic> spike times <italic>v<sub>i</sub>’</italic>:<disp-formula id="equ46"><label>(46)</label><mml:math id="m46"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:mspace width="1em"/><mml:mtext>for</mml:mtext><mml:mspace width="1em"/><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ47"><label>(47)</label><mml:math id="m47"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mspace width="1em"/><mml:mtext>for</mml:mtext><mml:mspace width="1em"/><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></disp-formula></p><p>Note that <xref ref-type="disp-formula" rid="equ47">Equation 47</xref> implies circular time with the recording wrapping back to the beginning at the end of all trials, which we assume here to keep <italic>n</italic> constant. If we define <italic>δ<sub>i</sub>’</italic>, analogous to <italic>δ<sub>i</sub></italic>, and use <xref ref-type="disp-formula" rid="equ46">Equation 46</xref>–<xref ref-type="disp-formula" rid="equ47">47</xref> we find:<disp-formula id="equ48"><label>(48)</label><mml:math id="m48"><mml:mrow><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>τ</mml:mi></mml:mfrac><mml:mspace width="1em"/><mml:mtext>for</mml:mtext><mml:mspace width="1em"/><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ49"><label>(49)</label><mml:math id="m49"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>τ</mml:mi></mml:mfrac><mml:mspace width="1em"/><mml:mtext>for</mml:mtext><mml:mspace width="1em"/><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>And if we subtract its mean, the constants are removed, and we get:<disp-formula id="equ50"><label>(50)</label><mml:math id="m50"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mtext>for</mml:mtext><mml:mspace width="1em"/><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ51"><label>(51)</label><mml:math id="m51"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mtext>for</mml:mtext><mml:mspace width="1em"/><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></disp-formula></p><p>The set of <italic>d’</italic><sub>i</sub> are thus identical to the set <italic>d<sub>i</sub></italic> except for a reordering. The maximum of the set <italic>|d<sub>i</sub>|</italic> will therefore also be the maximum of the set <italic>|d<sub>i</sub>’|</italic>. This means that it does not matter when the trial onsets are taken to compute ZETA. Note that this is not the case if <italic>δ<sub>i</sub></italic> is used instead of <italic>d<sub>i</sub></italic>.</p><p>To illustrate this difference, we will now derive closed-form solutions for the expectation and variance of <italic>δ<sub>i</sub></italic> and <italic>d<sub>i</sub></italic> in the specific case of step-wise changing Poisson-distributed spiking rates. Note that this section serves only to illustrate the above derivation (<xref ref-type="disp-formula" rid="equ45">Equation 45</xref>–<xref ref-type="disp-formula" rid="equ51">51</xref>) for a specific case, so the reader may choose to skip the rest of this section without missing out on any particularly important comments.</p><p>First, recall the base variables: we use <bold><italic>v</italic></bold> as a vector of spike times relative to stimulus onset, with the total onset-to-onset epoch duration defined as τ (see <xref ref-type="disp-formula" rid="equ1">equation 1</xref>). We will set the neuron’s firing probability to be homogeneous with Poisson rate <italic>λ</italic>. Since exponentially distributed inter-spike intervals generate Poisson-distributed spike counts, we use:<disp-formula id="equ52"><label>(52)</label><mml:math id="m52"><mml:mrow><mml:mi>S</mml:mi><mml:mo>∼</mml:mo><mml:mtext>Exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Therefore, spike time <italic>w<sub>i</sub></italic> is:<disp-formula id="equ53"><label>(53)</label><mml:math id="m53"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>In the limit of large <italic>n</italic>, the incremental deviation <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> from an exactly uniform spike-time distribution (i.e., <italic>1/λ</italic>) is therefore:<disp-formula id="equ54"><label>(54)</label><mml:math id="m54"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>D</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>In reality, however, the rate <inline-formula><mml:math id="inf22"><mml:mover accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> is estimated from data that are limited by the observation window τ, number of trials <italic>m</italic>, and observed number of spikes <inline-formula><mml:math id="inf23"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>τ</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> . First we collapse all spikes over trials, following <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, such that <italic>v<sub>n</sub>=τ</italic>. Then we normalize by τ to make <italic>v<sub>n</sub> = 1</italic>, which means that we now have:<disp-formula id="equ55">,<label>(55)</label><mml:math id="m55"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>m</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">n</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>generating spike times<disp-formula id="equ56"><label>(56)</label><mml:math id="m56"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>with incremental deviations<disp-formula id="equ57">.<label>(57)</label><mml:math id="m57"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>m</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>We can confirm this is correct by rewriting the total deviation <italic>δ<sub>i</sub></italic> at spike <italic>i</italic> as:<disp-formula id="equ58"><label>(58)</label><mml:math id="m58"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mi>i</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>To compute a closed-form for the variance of <italic>d</italic>, we need the first and second central moments of <italic>δ</italic> (i.e., the mean and variance). <italic>δ</italic> depends on <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, the variance of which is:<disp-formula id="equ59"><label>(59)</label><mml:math id="m59"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>Exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>In the case for large <italic>n</italic>, each <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is an exponential random variable. As <italic>δ<sub>i</sub></italic> is a sum over <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, we can approximate its pdf as an Erlang distribution with scale parameter <italic>k</italic> equal to the spike number <italic>i</italic>:<disp-formula id="equ60"><label>(60)</label><mml:math id="m60"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>∼</mml:mo><mml:mtext>Erlang</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>The Erlang distribution is a special case of the gamma distribution with discrete parameters. An equivalent formulation is therefore:<disp-formula id="equ61"><label>(61)</label><mml:math id="m61"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>However, we have so far ignored that <italic>δ<sub>i</sub></italic> is mean-zero and fixed at 0 at t = 0 and t = τ. For a Wiener process W, such fixed points are known as a Brownian bridge (<xref ref-type="bibr" rid="bib30">Mansuy and Yor, 2008</xref>), which is described by:<disp-formula id="equ62"><label>(62)</label><mml:math id="m62"><mml:mrow><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mi>τ</mml:mi></mml:mfrac><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>However, since the underlying stochastic process in our case is not a standard normal, but gamma-distributed, we cannot directly apply the above equation. Instead, we found that with sufficiently large <italic>n</italic>, the behavior of <italic>δ</italic> is described by a weighted difference of two time-symmetric series of gammas (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>). One series grows as <xref ref-type="disp-formula" rid="equ60">Equation 60</xref>, whereas its symmetric counterpart shrinks as <italic>k = n-i</italic>:<disp-formula id="equ63"><label>(63)</label><mml:math id="m63"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The central moments of the difference between two gamma distributions are given by <xref ref-type="bibr" rid="bib24">Klar, 2015</xref>:<disp-formula id="equ64"><label>(64)</label><mml:math id="m64"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ65"><label>(65)</label><mml:math id="m65"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi/><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msubsup></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Where the subscripts indicate the two distributions and <italic>α<sub>1</sub>= k =</italic> i, <italic>α<sub>2</sub>= n</italic> - i, and <italic>β<sub>1</sub> = β<sub>2</sub> = 1/λ</italic>. Filling in the above parameters and weighting variables, we therefore get:<disp-formula id="equ66"><label>(66)</label><mml:math id="m66"><mml:mi>E</mml:mi><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mi>i</mml:mi><mml:mi>λ</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></disp-formula><disp-formula id="equ67"><label>(67)</label><mml:math id="m67"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mi>i</mml:mi><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mi>i</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Now, we need to compute the variance over <italic>d<sub>i</sub></italic>, which is defined as the mean-subtracted <italic>δ<sub>i</sub></italic>.</p><p>To simplify the following derivation, we will assume that time is circular (as in <xref ref-type="disp-formula" rid="equ47">Equation 47</xref>) and that jittering does not strongly impact the number of spikes <italic>n</italic>, so we can we treat <italic>n</italic> as a fixed number of samples. As shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C</xref>, these assumptions allow accurate estimations. Now, we consider <italic>v<sub>k</sub></italic>, <inline-formula><mml:math id="inf27"><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> taken from a uniform distribution on [0,1] and ordered such that <inline-formula><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mo>…</mml:mo><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. We recognize the v<sub>k</sub> as the order statistics of the sample, for which the probability distribution is<disp-formula id="equ68"><label>(68)</label><mml:math id="m68"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>!</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></disp-formula></p><p>The expectation of <inline-formula><mml:math id="inf29"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf30"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> are given by<disp-formula id="equ69"><label>(69)</label><mml:math id="m69"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>!</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ70"><label>(70)</label><mml:math id="m70"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>!</mml:mo></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>!</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Now, redefine<disp-formula id="equ71"><label>(71)</label><mml:math id="m71"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>Then using <xref ref-type="disp-formula" rid="equ69">Equation 69</xref> and <xref ref-type="disp-formula" rid="equ70">Equation 70</xref>, we find<disp-formula id="equ72"><label>(72)</label><mml:math id="m72"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></disp-formula><disp-formula id="equ73"><label>(73)</label><mml:math id="m73"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>i</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>We find that the variance of <inline-formula><mml:math id="inf31"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is parabolic with respect to i, with its minimum at <inline-formula><mml:math id="inf32"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf33"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> and its maxium at the middle between those points. The maximum of all <inline-formula><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is thus also more likely to at the middle <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> than at the extremes.</p><p>We define again<disp-formula id="equ74"><label>(74)</label><mml:math id="m74"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>n</mml:mi><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. We know already that <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the same for all i, and we can thus write<disp-formula id="equ75"><label>(75)</label><mml:math id="m75"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>To compute <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> , we need to know <inline-formula><mml:math id="inf39"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and therefore <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. To compute <inline-formula><mml:math id="inf41"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> for <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, we can write <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and understand that <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> follows the same order statistic distribution as <inline-formula><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> except that there are now only <inline-formula><mml:math id="inf46"><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:math></inline-formula> samples taken from an interval <inline-formula><mml:math id="inf47"><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>0,1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the j-i<sup>th</sup> sample.<disp-formula id="equ76"><label>(76)</label><mml:math id="m76"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>i</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Using this we see that for<inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ77"><label>(77)</label><mml:math id="m77"><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>i</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Then we find, after a long but straightforward calculation, that<disp-formula id="equ78"><label>(78)</label><mml:math id="m78"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>δ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>12</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>And therefore<disp-formula id="equ79"><label>(79)</label><mml:math id="m79"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>δ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>12</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>12</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Note that the dependence on <italic>i</italic> has disappeared: i.e., the variance of <italic>d</italic> is time-invariant; which is what we aimed to show. Also note that while we made various assumptions to simplify the above derivations, our theoretical solutions accurately predict simulated data (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>); showing these assumptions have little impact on the results.</p><p>If we could now compute Var[max(<italic>d’</italic>)], E[max(<italic>d’</italic>)] and E[max(<italic>d</italic>)] from the above solutions for <italic>d’</italic>, we would even be able to construct a closed-form solution for the ZETA-test’s p-value in the case of exponentially-distributed inter-spike intervals. Unfortunately, the distribution of max(<italic>d</italic>) is unknown and fairly complex, because the elements of <italic>d</italic> are not statistically independent.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Formal analysis, Funding acquisition, Methodology, Project administration, Software, Supervision, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experiments were approved by the animal ethics committee of the Royal Netherlands Academy of Arts and Sciences, in compliance with all relevant ethical regulations. Animals received anesthetics and analgesics where applicable, such as during surgeries, and every effort was made to minimize animal suffering.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-71969-transrepform1-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>As stated in the manuscript, open-source code for the ZETA-test is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/ZETA">https://github.com/JorritMontijn/ZETA</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/zetapy">https://github.com/JorritMontijn/zetapy</ext-link>. Furthermore, code to reproduce the ZETA benchmarks are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/ZETA_analysis_repository">https://github.com/JorritMontijn/ZETA_analysis_repository</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:58dc4d8d3e9db6c06906445a8c3fa4a253b1fe3a">https://archive.softwareheritage.org/swh:1:rev:58dc4d8d3e9db6c06906445a8c3fa4a253b1fe3a</ext-link>) The Neuropixels data are annotated and available here: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.6djh9w108">https://doi.org/10.5061/dryad.6djh9w108</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Montijn</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>ZETA benchmarking neuropixels data</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.6djh9w108</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>Brain images in <xref ref-type="fig" rid="fig3">Figures 3</xref>—<xref ref-type="fig" rid="fig5">5</xref> were generated using Brain Explorer 2 (<xref ref-type="bibr" rid="bib28">Lau et al., 2008</xref>). We thank the Allen Brain Institute for their openly accessible data sets. We also thank the engineers of the mechatronics workshop at the NIN.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmadlou</surname><given-names>M</given-names></name><name><surname>Heimel</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Preference for concentric orientations in the mouse superior colliculus</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>6773</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms7773</pub-id><pub-id pub-id-type="pmid">25832803</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attinger</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Visuomotor coupling shapes the functional development of mouse visual cortex</article-title><source>Cell</source><volume>169</volume><fpage>1291</fpage><lpage>1302</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2017.05.023</pub-id><pub-id pub-id-type="pmid">28602353</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartolo</surname><given-names>R</given-names></name><name><surname>Saunders</surname><given-names>RC</given-names></name><name><surname>Mitz</surname><given-names>AR</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Information-limiting correlations in large neural populations</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>1668</fpage><lpage>1678</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2072-19.2019</pub-id><pub-id pub-id-type="pmid">31941667</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Mangun</surname><given-names>GR</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Canonical microcircuits for predictive coding</article-title><source>Neuron</source><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id><pub-id pub-id-type="pmid">23177956</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Button</surname><given-names>KS</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name><name><surname>Mokrysz</surname><given-names>C</given-names></name><name><surname>Nosek</surname><given-names>BA</given-names></name><name><surname>Flint</surname><given-names>J</given-names></name><name><surname>Robinson</surname><given-names>ESJ</given-names></name><name><surname>Munafò</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Power failure: Why small sample size undermines the reliability of neuroscience</article-title><source>Nature Reviews. Neuroscience</source><volume>14</volume><fpage>365</fpage><lpage>376</lpage><pub-id pub-id-type="doi">10.1038/nrn3475</pub-id><pub-id pub-id-type="pmid">23571845</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Calders</surname><given-names>T</given-names></name><name><surname>Jaroszewicz</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><chapter-title>Efficient AUC optimization for classification</chapter-title><person-group person-group-type="editor"><name><surname>Kok</surname><given-names>JN</given-names></name><name><surname>Koronacki</surname><given-names>J</given-names></name><name><surname>Lopez de Mantaras</surname><given-names>R</given-names></name><name><surname>Matwin</surname><given-names>S</given-names></name><name><surname>Mladenič</surname><given-names>D</given-names></name><name><surname>Skowron</surname><given-names>A</given-names></name></person-group><source>Knowledge Discovery in Databases</source><publisher-loc>Berlin Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><fpage>42</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1007/978-3-540-74976-9_8</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Deng</surname><given-names>Y</given-names></name><name><surname>Luo</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Zeng</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Detection of bursts in neuronal spike trains by the mean inter-spike interval method</article-title><source>Progress in Natural Science</source><volume>19</volume><fpage>229</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/j.pnsc.2008.05.027</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The significance of action potential bursting in the brain reward circuit</article-title><source>Neurochemistry International</source><volume>41</volume><fpage>333</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1016/s0197-0186(02)00068-2</pub-id><pub-id pub-id-type="pmid">12176075</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Douglas</surname><given-names>RJ</given-names></name><name><surname>Martin</surname><given-names>KAC</given-names></name><name><surname>Whitteridge</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>A canonical microcircuit for neocortex</article-title><source>Neural Computation</source><volume>1</volume><fpage>480</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1162/neco.1989.1.4.480</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>D</given-names></name><name><surname>Diaconis</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>On the histogram as a density estimator:L 2 theory</article-title><source>Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete</source><volume>57</volume><fpage>453</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1007/BF01025868</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A theory of cortical responses</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>360</volume><fpage>815</fpage><lpage>836</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1622</pub-id><pub-id pub-id-type="pmid">15937014</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregory</surname><given-names>RL</given-names></name><name><surname>Longuet-Higgins</surname><given-names>HC</given-names></name><name><surname>Sutherland</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Perceptions as hypotheses</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>290</volume><fpage>181</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1098/rstb.1980.0090</pub-id><pub-id pub-id-type="pmid">6106237</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gumbel</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="1941">1941</year><article-title>The return period of flood flows</article-title><source>The Annals of Mathematical Statistics</source><volume>12</volume><fpage>163</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1214/aoms/1177731747</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gumbel</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="1954">1954</year><source>Statistical Theory of Extreme Values and Some Practical Applications: A Series of Lectures</source><publisher-name>U.S. Government Printing Office</publisher-name></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Head</surname><given-names>ML</given-names></name><name><surname>Holman</surname><given-names>L</given-names></name><name><surname>Lanfear</surname><given-names>R</given-names></name><name><surname>Kahn</surname><given-names>AT</given-names></name><name><surname>Jennions</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The extent and consequences of P-hacking in science</article-title><source>PLOS Biology</source><volume>13</volume><elocation-id>e1002106</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002106</pub-id><pub-id pub-id-type="pmid">25768323</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Receptive fields of single neurones in the cat’s striate cortex</article-title><source>The Journal of Physiology</source><volume>148</volume><fpage>574</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1959.sp006308</pub-id><pub-id pub-id-type="pmid">14403679</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jorrit</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2021">2021a</year><data-title>General Analysis</data-title><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:8513b81b1bf6bc9167f02e3e5f003d0389ae1a13;origin=https://github.com/JorritMontijn/GeneralAnalysis;visit=swh:1:snp:700ebc029d18a736abcdb7eed24016d003ecb6b0;anchor=swh:1:rev:7f866e0c875af17e9d76fdfbd8cec3d41145c031">https://archive.softwareheritage.org/swh:1:dir:8513b81b1bf6bc9167f02e3e5f003d0389ae1a13;origin=https://github.com/JorritMontijn/GeneralAnalysis;visit=swh:1:snp:700ebc029d18a736abcdb7eed24016d003ecb6b0;anchor=swh:1:rev:7f866e0c875af17e9d76fdfbd8cec3d41145c031</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jorrit</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2021">2021b</year><data-title>ZETA</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/ZETA">https://github.com/JorritMontijn/ZETA</ext-link></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Barbarits</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Andrei</surname><given-names>A</given-names></name><name><surname>Aydın</surname><given-names>Ç</given-names></name><name><surname>Barbic</surname><given-names>M</given-names></name><name><surname>Blanche</surname><given-names>TJ</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Couto</surname><given-names>J</given-names></name><name><surname>Dutta</surname><given-names>B</given-names></name><name><surname>Gratiy</surname><given-names>SL</given-names></name><name><surname>Gutnisky</surname><given-names>DA</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Lopez</surname><given-names>CM</given-names></name><name><surname>Mitelut</surname><given-names>C</given-names></name><name><surname>Musa</surname><given-names>S</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Putzeys</surname><given-names>J</given-names></name><name><surname>Rich</surname><given-names>PD</given-names></name><name><surname>Rossant</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>W-L</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><volume>551</volume><fpage>232</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/nature24636</pub-id><pub-id pub-id-type="pmid">29120427</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kass</surname><given-names>RE</given-names></name><name><surname>Ventura</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A spike-train probability model</article-title><source>Neural Computation</source><volume>13</volume><fpage>1713</fpage><lpage>1720</lpage><pub-id pub-id-type="doi">10.1162/08997660152469314</pub-id><pub-id pub-id-type="pmid">11506667</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kass</surname><given-names>RE</given-names></name><name><surname>Eden</surname><given-names>U</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Analysis of Neural Data</source><publisher-name>Springer-Verlag</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4614-9602-1</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sensorimotor mismatch signals in primary visual cortex of the behaving mouse</article-title><source>Neuron</source><volume>74</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.040</pub-id><pub-id pub-id-type="pmid">22681686</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klar</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A note on gamma difference distributions</article-title><source>Journal of Statistical Computation and Simulation</source><volume>85</volume><fpage>3708</fpage><lpage>3715</lpage><pub-id pub-id-type="doi">10.1080/00949655.2014.996566</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleiner</surname><given-names>M</given-names></name><name><surname>Brainard</surname><given-names>D</given-names></name><name><surname>Pelli</surname><given-names>D</given-names></name><name><surname>Ingling</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>R</given-names></name><name><surname>Broussard</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>What’s new in psychtoolbox-3</article-title><source>Perception</source><volume>36</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1068/v070821</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knöpfel</surname><given-names>T</given-names></name><name><surname>Song</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optical voltage imaging in neurons: Moving from technology development to practical tool</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>719</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0231-4</pub-id><pub-id pub-id-type="pmid">31705060</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Bains</surname><given-names>LJ</given-names></name><name><surname>van Mourik</surname><given-names>T</given-names></name><name><surname>Norris</surname><given-names>DG</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Selective activation of the deep layers of the human primary visual cortex by top-down feedback</article-title><source>Current Biology</source><volume>26</volume><fpage>371</fpage><lpage>376</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.12.038</pub-id><pub-id pub-id-type="pmid">26832438</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Thompson</surname><given-names>C</given-names></name><name><surname>Pathak</surname><given-names>S</given-names></name><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Jones</surname><given-names>A</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Exploration and visualization of gene expression with neuroanatomy in the adult mouse brain</article-title><source>BMC Bioinformatics</source><volume>9</volume><elocation-id>153</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2105-9-153</pub-id><pub-id pub-id-type="pmid">18366675</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leinweber</surname><given-names>M</given-names></name><name><surname>Ward</surname><given-names>DR</given-names></name><name><surname>Sobczak</surname><given-names>JM</given-names></name><name><surname>Attinger</surname><given-names>A</given-names></name><name><surname>Keller</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A sensorimotor circuit in mouse cortex for visual flow predictions</article-title><source>Neuron</source><volume>95</volume><fpage>1420</fpage><lpage>1432</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.08.036</pub-id><pub-id pub-id-type="pmid">28910624</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mansuy</surname><given-names>R</given-names></name><name><surname>Yor</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Aspects of Brownian Motion</source><publisher-loc>Heidelberg, Germany</publisher-loc><publisher-name>Springer-Verlag</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-540-49966-4</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markov</surname><given-names>NT</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Chameau</surname><given-names>P</given-names></name><name><surname>Falchier</surname><given-names>A</given-names></name><name><surname>Quilodran</surname><given-names>R</given-names></name><name><surname>Huissoud</surname><given-names>C</given-names></name><name><surname>Lamy</surname><given-names>C</given-names></name><name><surname>Misery</surname><given-names>P</given-names></name><name><surname>Giroud</surname><given-names>P</given-names></name><name><surname>Ullman</surname><given-names>S</given-names></name><name><surname>Barone</surname><given-names>P</given-names></name><name><surname>Dehay</surname><given-names>C</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anatomy of hierarchy: Feedforward and feedback pathways in macaque visual cortex</article-title><source>The Journal of Comparative Neurology</source><volume>522</volume><fpage>225</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1002/cne.23458</pub-id><pub-id pub-id-type="pmid">23983048</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattia</surname><given-names>D</given-names></name><name><surname>Hwa</surname><given-names>GG</given-names></name><name><surname>Avoli</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Membrane properties of rat subicular neurons in vitro</article-title><source>Journal of Neurophysiology</source><volume>70</volume><fpage>1244</fpage><lpage>1248</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.70.3.1244</pub-id><pub-id pub-id-type="pmid">8229171</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazurek</surname><given-names>M</given-names></name><name><surname>Kager</surname><given-names>M</given-names></name><name><surname>Van Hooser</surname><given-names>SD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Robust quantification of orientation selectivity and direction selectivity</article-title><source>Frontiers in Neural Circuits</source><volume>8</volume><elocation-id>92</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2014.00092</pub-id><pub-id pub-id-type="pmid">25147504</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mesa</surname><given-names>N</given-names></name><name><surname>Waters</surname><given-names>J</given-names></name><name><surname>de Vries</surname><given-names>SEJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The Effect of Inclusion Criteria on the Functional Properties Reported in Mouse Visual Cortex</article-title><source>ENeuro</source><volume>8</volume><elocation-id>ENEURO.0188-20.2021</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0188-20.2021</pub-id><pub-id pub-id-type="pmid">33509948</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montijn</surname><given-names>JS</given-names></name><name><surname>Meijer</surname><given-names>GT</given-names></name><name><surname>Lansink</surname><given-names>CS</given-names></name><name><surname>Pennartz</surname><given-names>CMA</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Population-level neural codes are robust to single-neuron variability from a multidimensional coding perspective</article-title><source>Cell Reports</source><volume>16</volume><fpage>2486</fpage><lpage>2498</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2016.07.065</pub-id><pub-id pub-id-type="pmid">27545876</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montijn</surname><given-names>JS</given-names></name><name><surname>Olcese</surname><given-names>U</given-names></name><name><surname>Pennartz</surname><given-names>CMA</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Visual stimulus detection correlates with the consistency of temporal sequences within stereotyped events of v1 neuronal population activity</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>8624</fpage><lpage>8640</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0853-16.2016</pub-id><pub-id pub-id-type="pmid">27535910</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Montijn</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Acquipix</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/JorritMontijn/Acquipix">https://github.com/JorritMontijn/Acquipix</ext-link></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mountcastle</surname><given-names>VB</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>Modality and topographic properties of single neurons of cat’s somatic sensory cortex</article-title><source>Journal of Neurophysiology</source><volume>20</volume><fpage>408</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1152/jn.1957.20.4.408</pub-id><pub-id pub-id-type="pmid">13439410</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohiorhenuan</surname><given-names>IE</given-names></name><name><surname>Mechler</surname><given-names>F</given-names></name><name><surname>Purpura</surname><given-names>KP</given-names></name><name><surname>Schmid</surname><given-names>AM</given-names></name><name><surname>Hu</surname><given-names>Q</given-names></name><name><surname>Victor</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sparse coding and high-order correlations in fine-scale cortical networks</article-title><source>Nature</source><volume>466</volume><fpage>617</fpage><lpage>621</lpage><pub-id pub-id-type="doi">10.1038/nature09178</pub-id><pub-id pub-id-type="pmid">20601940</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Sparse coding with an overcomplete basis set: a strategy employed by V1?</article-title><source>Vision Research</source><volume>37</volume><fpage>3311</fpage><lpage>3325</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(97)00169-7</pub-id><pub-id pub-id-type="pmid">9425546</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ooyen</surname><given-names>A</given-names></name><name><surname>Roelfsema</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2003">2003</year><conf-name>In Artificial Neural Networks and Neural Information</conf-name><article-title>Processing Supplementary Proceedings ICANN/ICONIP 2003</article-title></element-citation></ref><ref id="bib43"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Kilosort3: spike sorting on GPUs with template matching, drift correction and fancy clustering</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/Kilosort">https://github.com/MouseLand/Kilosort</ext-link></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Packer</surname><given-names>AM</given-names></name><name><surname>Russell</surname><given-names>LE</given-names></name><name><surname>Dalgleish</surname><given-names>HWP</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Simultaneous all-optical manipulation and recording of neural circuit activity with cellular resolution in vivo</article-title><source>Nature Methods</source><volume>12</volume><fpage>140</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3217</pub-id><pub-id pub-id-type="pmid">25532138</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palm</surname><given-names>G</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name><name><surname>Gerstein</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>On the significance of correlations among neuronal spike trains</article-title><source>Biological Cybernetics</source><volume>59</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1007/BF00336885</pub-id><pub-id pub-id-type="pmid">3401513</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Peters</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>allen CCF tools</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/allenCCF">https://github.com/cortex-lab/allenCCF</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeffer</surname><given-names>CK</given-names></name><name><surname>Xue</surname><given-names>M</given-names></name><name><surname>He</surname><given-names>M</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inhibition of inhibition in visual cortex: The logic of connections between molecularly distinct interneurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1068</fpage><lpage>1076</lpage><pub-id pub-id-type="doi">10.1038/nn.3446</pub-id><pub-id pub-id-type="pmid">23817549</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pi</surname><given-names>H-J</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Kvitsiani</surname><given-names>D</given-names></name><name><surname>Sanders</surname><given-names>JI</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical interneurons that specialize in disinhibitory control</article-title><source>Nature</source><volume>503</volume><fpage>521</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1038/nature12676</pub-id><pub-id pub-id-type="pmid">24097352</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>Raudies</surname><given-names>F</given-names></name><name><surname>Wannig</surname><given-names>A</given-names></name><name><surname>Lamme</surname><given-names>VAF</given-names></name><name><surname>Neumann</surname><given-names>H</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The role of attention in figure-ground segregation in areas v1 and v4 of the visual cortex</article-title><source>Neuron</source><volume>75</volume><fpage>143</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.032</pub-id><pub-id pub-id-type="pmid">22794268</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Nadasdy</surname><given-names>Z</given-names></name><name><surname>Ben-Shaul</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Unsupervised spike detection and sorting with wavelets and superparamagnetic clustering</article-title><source>Neural Computation</source><volume>16</volume><fpage>1661</fpage><lpage>1687</lpage><pub-id pub-id-type="doi">10.1162/089976604774201631</pub-id><pub-id pub-id-type="pmid">15228749</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RPN</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringach</surname><given-names>DL</given-names></name><name><surname>Shapley</surname><given-names>RM</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Orientation selectivity in macaque V1: Diversity and laminar dependence</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>5639</fpage><lpage>5651</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-13-05639.2002</pub-id><pub-id pub-id-type="pmid">12097515</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Ayaz</surname><given-names>A</given-names></name><name><surname>Jeffery</surname><given-names>KJ</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Integration of visual motion and locomotion in mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1864</fpage><lpage>1869</lpage><pub-id pub-id-type="doi">10.1038/nn.3567</pub-id><pub-id pub-id-type="pmid">24185423</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sturges’ rule</article-title><source>WIREs Computational Statistics</source><volume>1</volume><fpage>303</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1002/wics.35</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Goebel</surname><given-names>R</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Benchmarking laminar FMRI: Neuronal spiking and synaptic activity during top-down and bottom-up processing in the different layers of cortex</article-title><source>NeuroImage</source><volume>197</volume><fpage>806</fpage><lpage>817</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.045</pub-id><pub-id pub-id-type="pmid">28648888</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semedo</surname><given-names>JD</given-names></name><name><surname>Zandvakili</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical areas interact through a communication subspace</article-title><source>Neuron</source><volume>102</volume><fpage>249</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.026</pub-id><pub-id pub-id-type="pmid">30770252</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shimazaki</surname><given-names>H</given-names></name><name><surname>Shinomoto</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A method for selecting the bin size of a time histogram</article-title><source>Neural Computation</source><volume>19</volume><fpage>1503</fpage><lpage>1527</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.6.1503</pub-id><pub-id pub-id-type="pmid">17444758</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shuler</surname><given-names>MG</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reward timing in the primary visual cortex</article-title><source>Science</source><volume>311</volume><fpage>1606</fpage><lpage>1609</lpage><pub-id pub-id-type="doi">10.1126/science.1123513</pub-id><pub-id pub-id-type="pmid">16543459</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Durand</surname><given-names>S</given-names></name><name><surname>Gale</surname><given-names>S</given-names></name><name><surname>Bennett</surname><given-names>C</given-names></name><name><surname>Graddis</surname><given-names>N</given-names></name><name><surname>Heller</surname><given-names>G</given-names></name><name><surname>Ramirez</surname><given-names>TK</given-names></name><name><surname>Choi</surname><given-names>H</given-names></name><name><surname>Luviano</surname><given-names>JA</given-names></name><name><surname>Groblewski</surname><given-names>PA</given-names></name><name><surname>Ahmed</surname><given-names>R</given-names></name><name><surname>Arkhipov</surname><given-names>A</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Billeh</surname><given-names>YN</given-names></name><name><surname>Brown</surname><given-names>D</given-names></name><name><surname>Buice</surname><given-names>MA</given-names></name><name><surname>Cain</surname><given-names>N</given-names></name><name><surname>Caldejon</surname><given-names>S</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Survey of Spiking Activity Reveals a Functional Hierarchy of Mouse Corticothalamic Visual Areas</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/805010</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Zatka-Haas</surname><given-names>P</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title><source>Nature</source><volume>576</volume><fpage>266</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1787-x</pub-id><pub-id pub-id-type="pmid">31776518</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinje</surname><given-names>WE</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Sparse coding and decorrelation in primary visual cortex during natural vision</article-title><source>Science</source><volume>287</volume><fpage>1273</fpage><lpage>1276</lpage><pub-id pub-id-type="doi">10.1126/science.287.5456.1273</pub-id><pub-id pub-id-type="pmid">10678835</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Theories of Error Back-Propagation in the Brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>235</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.12.005</pub-id><pub-id pub-id-type="pmid">30704969</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>D</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name><name><surname>Shapley</surname><given-names>R</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Correlation of local and global orientation and spatial frequency tuning in macaque v1</article-title><source>The Journal of Physiology</source><volume>557</volume><fpage>923</fpage><lpage>933</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2004.062026</pub-id><pub-id pub-id-type="pmid">15090603</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.71969.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>van Rossum</surname><given-names>Mark CW</given-names></name><role>Reviewing Editor</role><aff><institution>University of Nottingham</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Victor</surname><given-names>Jonathan D</given-names></name><role>Reviewer</role><aff><institution>Weill Cornell Medical College</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>A central question in neuroscience is whether a neuron responds to a certain stimulus. However, when the response is complex, e.g., bi-phasic where an increase in rate is followed by a lower rate, this is not always easy to determine. In this methods paper, the authors introduce a new bin-less method that detects whether a neuron responds to a stimulus. In particular for labs using high-throughput data collection, the method should be useful.</p><p><bold>Decision letter after peer review:</bold></p><p>[Editors’ note: the authors submitted for reconsideration following the decision after peer review. What follows is the decision letter after the first round of review.]</p><p>Thank you for submitting your work entitled &quot;A parameter-free statistical test that improves the detection of neuronal responsiveness&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by a Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Jonathan D Victor (Reviewer #3).</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>.</p><p>While the reviewers saw considerable merit in the study, in particular regarding the extensive and robust result of applying the method to data, the claims regarding the method being state of the art were found to be insufficiently convincing for e<italic>Life</italic>.</p><p><italic>Reviewer #1:</italic></p><p>This paper introduces a, as far as I know, new method to detect modulation of neural firing rates. It is particularly more sensitive to neurons with a bi-phasic modulation of rate.</p><p>The method is straightforward and perhaps not very advanced but should be of interest to a wide community, also because it does not depend on binning.</p><p>The study appears to be competently carried out and applies the method to a very large range of systems.</p><p><italic>Reviewer #2:</italic></p><p>This paper will be of interest to researchers using electrophysiology or Calcium imaging who want to detect whether cells are responsive to a stimulus and are concerned that testing the mean firing rate may miss cells that are responsive through temporal patterns of their spike trains. The method reported here is rigorous and is an advance compared to doing a standard statistical test on mean firing rate, since it is sensitive to additional temporal information. However, other methods for detecting responsiveness based on temporal information are available and it is not clear that the new test has a meaningful performance advantage compared to these.</p><p>The goal here is (1) to develop a reliable method for detecting whether and when a neuron responds to stimulation and does so without requiring the bin size to be specified and (2) that this method is superior to previous approaches. As stated by the authors &quot;we present the parameter-free ZETA-test, which outperforms t-tests and ANOVAs by including more cells at a similar false-positive rate&quot;.</p><p>The authors have achieved the first goal; developing a parameter-free &quot;zeta test&quot;, which works by testing whether the cumulative distribution of spike times deviates significantly from what would be expected from random firing. However, achievement of the second goal is not proven.</p><p>Readers should consider the following when reading the paper:</p><p>1. The binless aspect of the zeta test is elegant as it avoids the need to choose a binsize for the analysis.</p><p>2. That the zeta test is more sensitive than a t-test is a straightforward consequence of the fact that the two tests are applied to different inputs. The t-test is used to compare whether the mean firing rate in some temporal interval is greater during the stimulus compared to baseline. The zeta test works on the basis of the spike times within the response interval. The increased sensitivity of the zeta test compared to the t-test stems from the property that the timing of spikes within an interval necessarily conveys as much or more information then the mean firing rate within the interval.</p><p>3. Given the previous point, a better benchmark for the zeta test is against other approaches that take spike timing into account. The authors consider an ANOVA, which splits the response interval into bins, and tests whether or not the pattern of firing rate over those bins is temporally modulated. They find that the zeta test is more sensitive than the ANOVA for some binsizes. However, for the most physiologically relevant binsizes (those around the time-scale of the stimulus), the two methods perform similarly. The apparent advantage of the zeta test is largest at small bin sizes &lt; 1 ms. It is possible that the apparent performance advantage in these small bins compared to 20-100 ms bins, is a sampling artefact. Further work is needed to exclude this. In sum, contrary to the claim of the abstract, it is not clear that the zeta method has a genuine performance improvement compared to ANOVA.</p><p>Overall, following on from the comments above, this method will be of potential interest to a broad community of researchers seeking that measure neural activity with cellular resolution (extracellular electrophysiology and Calcium imaging) but the advance is at a level more suited to a specialised journal.</p><p>The authors find the inclusion rates of the zeta and ANOVA to be indistinguishable for binsizes of ~2-20 times the sampling interval of the movie, so within this broad range of timescales, there is no performance advantage for the zeta test. There is an advantage for smaller bins and for larger bins. The advantage for larger bins is presumably for the same reason as occurs in the t-test section (this should be explained in Results). The advantage for small bins is problematic for two reasons. First, the range of bin sizes is taken down to &lt; 0.1 ms. This is 100 times less than the natural time-scale of the movie stimulus (its frame interval) so, although not impossible, it is surprising/interesting/unconvincing that there is extra temporal information there missed by the ANOVA. Another possibility (as extensively considered in the information theory literature, e.g. Panzeri et al., 2007) is that this is a sampling artefact. Further work is needed to address this point, for example by using simulated data where the response time-scales are controlled. It is also possible that the ANOVA is underperforming due to over-conservative nature of Bonferroni correction. the ANOVA's inclusion rate might be better with multiple comparisons control done via the Benjamini-Hochberg-Yekutieli procedure.</p><p><italic>Reviewer #3:</italic></p><p>This work presents a new approach to determining whether neuronal responses are modulated in response to a stimulus. The approach is motivated by the need for statistical tests that do not require a choice of a timeframe for analysis, or other analysis parameters. The investigators derive a null distribution for the new measure, provide code for its implementation, and benchmark it against the t-test for both simulated and real data in several diverse systems.</p><p>While I am generally sympathetic to the motivation of the work, I have both conceptual and technical concerns. The most critical is that, while I think they have presented strong evidence that the tool is useful, I don't think that they have shown that it advances the state of the art (point 1 below): they compare their approach to a t-test, which I think is something of a straw man. I believe the biological results are strong and interesting, but, since the paper is submitted as &quot;Tools and Resources&quot; paper, my review focuses on the tool itself, and whether it has been shown to be an advance.</p><p>1. The main comparisons are to the t-test. While the t-test may well be widely used and simple, it is far from the state of the art. Whenever a response is modulated in time (and not just steadily elevated), there is almost always a better approach. For example, for periodic stimulation, such as the examples of Figure 2, one can use Fourier analysis to identify modulations in the response. More generally, point process models – see for example the work of Emery Brown and Rob Kass, including the Kass, Eden, and Brown textbook &quot;Analysis of Neural Data&quot;, provide a theoretical framework for detecting response modulations in a wide variety of settings, as well as determining when the peak modulation occurs; these methods provide estimates of the underlying firing rate along with error bars. As is the case for the proposed method, these point-process approaches work directly with spike times, and do not require the choice of a bin width. So, while it is a good point that t-statistics may underestimate the fraction of neurons that are modulated by an experimental manipulation in some situations, there are a number of standard solutions already available. The manuscript does not discuss these other approaches or compare the new approach to them, and therefore stops substantially short of showing that the ZETA-test is an advance on the state of the art. [On a subjective note, I think that as a general approach, the point-process framework mentioned above is superior conceptually, as it begins with an explicit statistical model and an inference framework.]</p><p>2. For the examples in which the response is constructed to be a pure elevation of the firing rate, the ZETA test does not appear to be superior (Figure 4, row 1): there is a larger fraction of cells detected as responsive, but also a greater number of false positives. An ROC curve would likely show this. But more importantly, if the underlying firing statistics are Poisson – as they are constructed to be – then, since the firing rate is a sufficient statistic, simple estimation of the firing rate cannot be worse than the zeta statistic.</p><p>3. The derivation of the null distribution for the statistic makes a lot of assumptions, including the extent of jittering and the use of extreme-value asymptotics; there may be a much simpler way to the goal. If I understand correctly, the idea is to construct an estimate of the cumulative distribution of spike times, and to compare that with the null hypothesis that they are uniformly distributed. If that is the case, perhaps one could just use the Kolmogorov-Smirnov test? This also brings up another issue: if the neuron's underlying firing pattern is far from Poisson, e.g., that it is similar to a renewal process whose interspike interval distribution is highly peaked – will the zeta test work?</p><p>4. Finally, I think that the virtues of a &quot;nonparametric&quot; test is not as obvious or universal as they might first appear. On the one hand, even with a test such as the one proposed here, one still needs to choose the time period to analyze. On the other hand, one often cares very much about the timescale of the response variation, both to exclude phenomena that one is not interested in, and to understand what aspects of the response are informative. This point is of course not germane to whether the paper makes an advance, but I think it would be preferable to discuss these considerations, rather than to assert that nonparametric tests are preferable.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.71969.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the authors resubmitted a revised version of the paper for consideration. What follows is the authors’ response to the first round of review.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>This paper introduces a, as far as I know, new method to detect modulation of neural firing rates. It is particularly more sensitive to neurons with a bi-phasic modulation of rate.</p><p>The method is straightforward and perhaps not very advanced but should be of interest to a wide community, also because it does not depend on binning.</p></disp-quote><p>We would like to thank the reviewer for the positive comments and review. As noted above, we now show that the ZETA-test is not only superior in the case of bi-phasic neurons, but also for bursting cells (Figure 4). We have also added an analysis of the marginal case of purely exponentially distributed inter-spike intervals (ISIs); in this hypothetical scenario, the t-test exceeds the ZETA-test.</p><p>However, we also show that only small deviations from exact alignment are required for the ZETA test to exceed the t-test’s performance (Figure 4).</p><disp-quote content-type="editor-comment"><p>The study appears to be competently carried out and applies the method to a very large range of systems. All my comments are minor.</p><p>Reviewer #2:</p><p>This paper will be of interest to researchers using electrophysiology or Calcium imaging who want to detect whether cells are responsive to a stimulus and are concerned that testing the mean firing rate may miss cells that are responsive through temporal patterns of their spike trains. The method reported here is rigorous and is an advance compared to doing a standard statistical test on mean firing rate, since it is sensitive to additional temporal information. However, other methods for detecting responsiveness based on temporal information are available and it is not clear that the new test has a meaningful performance advantage compared to these.</p><p>The goal here is (1) to develop a reliable method for detecting whether and when a neuron responds to stimulation and does so without requiring the bin size to be specified and (2) that this method is superior to previous approaches. As stated by the authors &quot;we present the parameter-free ZETA-test, which outperforms t-tests and ANOVAs by including more cells at a similar false-positive rate&quot;.</p><p>The authors have achieved the first goal; developing a parameter-free &quot;zeta test&quot;, which works by testing whether the cumulative distribution of spike times deviates significantly from what would be expected from random firing. However, achievement of the second goal is not proven.</p></disp-quote><p>We thank the reviewer for these useful comments on our manuscript. We appreciate that our previous version lacked sufficient comparisons with more advanced statistical approaches. As noted above, we have added a considerable amount of new material to the manuscript, including multiple alternative statistical tests. We hope that the reviewer finds the new comparisons sufficiently convincing. Regarding the comparison with the multi-timescale ANOVA, we believe that our previous manuscript was not sufficiently clear, and we have now rewritten parts of the description of the ANOVA-based analysis.</p><disp-quote content-type="editor-comment"><p>Readers should consider the following when reading the paper:</p><p>1. The binless aspect of the zeta test is elegant as it avoids the need to choose a binsize for the analysis.</p></disp-quote><p>Thank you, we appreciate the comment.</p><disp-quote content-type="editor-comment"><p>2. That the zeta test is more sensitive than a t-test is a straightforward consequence of the fact that the two tests are applied to different inputs. The t-test is used to compare whether the mean firing rate in some temporal interval is greater during the stimulus compared to baseline. The zeta test works on the basis of the spike times within the response interval. The increased sensitivity of the zeta test compared to the t-test stems from the property that the timing of spikes within an interval necessarily conveys as much or more information then the mean firing rate within the interval.</p></disp-quote><p>We agree with the reviewer that the number of data points used by a t-test (n=number of trials) is much lower than with the ZETA-test (n=number of spikes). However, the t-test does have access to information that the ZETA-test does not: the spike times used by the ZETA-test are flattened over trials, while the t-test uses the variability across trials. Therefore, when the variability across trials is low, but the variability within a trial is high, the ZETA-could perform worse than a t-test. The important analysis here would therefore be to find where their point of equality lies. As we show in our new Figure 4A-B, the t-test exceeds the ZETA-test’s sensitivity only for biologically implausible exponentially-spiking cells. Importantly, even in the case of strongly bursting cells (Figure 4C-F), the ZETA-test outperforms the t-test. We discuss this issue in the paragraph “ZETA-test in the absence of short peaks of activity” (lines 172-202).</p><disp-quote content-type="editor-comment"><p>3. Given the previous point, a better benchmark for the zeta test is against other approaches that take spike timing into account.</p></disp-quote><p>We have now added a detailed comparison of the ZETA-test with alternative tests derived from renewal-process theory to the manuscript (lines 112-117, 542-697, Supplementary Methods and Figure 3 – Supplements 2,3), and performed a new comparison with an optimally-binned ANOVA (lines 149-170, 533-540, Figure 3). The ZETA-test is superior to all alternatives we have tested, and we now also describe more clearly which mathematical properties are crucial to the ZETA-test’s superior statistical sensitivity.</p><disp-quote content-type="editor-comment"><p>The authors consider an ANOVA, which splits the response interval into bins, and tests whether or not the pattern of firing rate over those bins is temporally modulated. They find that the zeta test is more sensitive than the ANOVA for some binsizes. However, for the most physiologically relevant binsizes (those around the time-scale of the stimulus), the two methods perform similarly. The apparent advantage of the zeta test is largest at small bin sizes &lt; 1 ms. It is possible that the apparent performance advantage in these small bins compared to 20-100 ms bins, is a sampling artefact. Further work is needed to exclude this. In sum, contrary to the claim of the abstract, it is not clear that the zeta method has a genuine performance improvement compared to ANOVA.</p><p>Overall, following on from the comments above, this method will be of potential interest to a broad community of researchers seeking that measure neural activity with cellular resolution (extracellular electrophysiology and Calcium imaging) but the advance is at a level more suited to a specialised journal.</p><p>The authors find the inclusion rates of the zeta and ANOVA to be indistinguishable for binsizes of ~2-20 times the sampling interval of the movie, so within this broad range of timescales, there is no performance advantage for the zeta test. There is an advantage for smaller bins and for larger bins. The advantage for larger bins is presumably for the same reason as occurs in the t-test section (this should be explained in Results). The advantage for small bins is problematic for two reasons. First, the range of bin sizes is taken down to &lt; 0.1 ms. This is 100 times less than the natural time-scale of the movie stimulus (its frame interval) so, although not impossible, it is surprising/interesting/unconvincing that there is extra temporal information there missed by the ANOVA. Another possibility (as extensively considered in the information theory literature, eg Panzeri et al., 2007) is that this is a sampling artefact. Further work is needed to address this point, for example by using simulated data where the response time-scales are controlled.</p></disp-quote><p>We apologize for not describing this procedure sufficiently clearly. The ZETA-test is intrinsically timescale-free, and we chose different bin widths (i.e., timescales) only for the various ANOVAs. The fact that the ANOVAs perform worse than the ZETA-test at short and long timescales is not an indication that the ANOVA missed information at those timescales. Rather, no information about the stimulus exists at those timescales, and therefore the ANOVA performs poorly. We agree with the reviewer’s logic if this were what our results showed, but this is not the case: the reviewer’s interpretation was caused by us describing our methods insufficiently clearly. We have made various changes to the text (lines 204-229) and the legend of Figure 5 to further clarify that only the ANOVAs used different bin sizes.</p><disp-quote content-type="editor-comment"><p>It is also possible that the ANOVA is underperforming due to over-conservative nature of Bonferroni correction. the ANOVA's inclusion rate might be better with multiple comparisons control done via the Benjamini-Hochberg-Yekutieli procedure.</p></disp-quote><p>Using a less conservative correction procedure would increase the ANOVA’s inclusion, but also increase the number of false alarms. As such, it would not change the ROC curve shown in Figure 5C, except that the curve’s inclusion and FA rates would correspond to different values of the significance level α.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>This work presents a new approach to determining whether neuronal responses are modulated in response to a stimulus. The approach is motivated by the need for statistical tests that do not require a choice of a timeframe for analysis, or other analysis parameters. The investigators derive a null distribution for the new measure, provide code for its implementation, and benchmark it against the t-test for both simulated and real data in several diverse systems.</p><p>While I am generally sympathetic to the motivation of the work, I have both conceptual and technical concerns. The most critical is that, while I think they have presented strong evidence that the tool is useful, I don't think that they have shown that it advances the state of the art (point 1 below): they compare their approach to a t-test, which I think is something of a straw man. I believe the biological results are strong and interesting, but, since the paper is submitted as &quot;Tools and Resources&quot; paper, my review focuses on the tool itself, and whether it has been shown to be an advance.</p><p>1. The main comparisons are to the t-test. While the t-test may well be widely used and simple, it is far from the state of the art. Whenever a response is modulated in time (and not just steadily elevated), there is almost always a better approach. For example, for periodic stimulation, such as the examples of Figure 2, one can use Fourier analysis to identify modulations in the response. More generally, point process models – see for example the work of Emery Brown and Rob Kass, including the Kass, Eden, and Brown textbook &quot;Analysis of Neural Data&quot;, provide a theoretical framework for detecting response modulations in a wide variety of settings, as well as determining when the peak modulation occurs; these methods provide estimates of the underlying firing rate along with error bars. As is the case for the proposed method, these point-process approaches work directly with spike times, and do not require the choice of a bin width. So, while it is a good point that t-statistics may underestimate the fraction of neurons that are modulated by an experimental manipulation in some situations, there are a number of standard solutions already available. The manuscript does not discuss these other approaches or compare the new approach to them, and therefore stops substantially short of showing that the ZETA-test is an advance on the state of the art. [On a subjective note, I think that as a general approach, the point-process framework mentioned above is superior conceptually, as it begins with an explicit statistical model and an inference framework.]</p></disp-quote><p>We understand the reviewer’s point of view that (A) the ZETA-test was not well described in terms of existing mathematical frameworks and (B) that more specialized and advanced techniques may outperform the ZETA-test.</p><p>Regarding point A: In this revised version, we have dedicated significant work to better ground the ZETA-test in existing mathematical frameworks. We compare the ZETA-test to alternative formulations derived from renewal and point-process models (lines 608-697 and Figure 3 – Supplements 2,3), showing how ZETA can be constructed step-by-step from a simple Kolmogorov Smirnov test of real spike-times versus a Poisson H0 distribution up to the full-fledged ZETA-test. Comparing the performance of these various alternative tests, we found that the ZETA-test outperforms all others (Figure 3 – Supplement 3). Moreover, we now describe how the ZETA-test achieves time-invariance (Supplementary Methods), and show that an ANOVA that uses an optimal bin width still performs worse than the ZETA-test (lines 149-170, Figure 3).</p><p>Regarding point B: We created the ZETA-test as an easy-to-use, first-pass test for neuronal responsiveness that requires no hyperparameter tuning and is relatively fast, as no such test yet exists for neurophysiological analysis. We do not claim that the ZETA-test always exceeds the performance of more sophisticated and specialized model-based approaches, nor was this our aim. Rather, the point we wish to make in our manuscript is that the ZETA-test is a powerful, statistically sensitive test that exceeds the performance of other naïve approaches. That said, we acknowledge that the range of alternative statistical tests in our previous version was limited. We have therefore added a comparison with a multiplicative inhomogeneous Markov interval (MIMI) model, as described in (Kass and Ventura, 2001; <italic>Neural computation</italic>; Kass, Eden and Brown, 2014; <italic>Analysis of Neural Data</italic>), to the current version. We use it to both detect responsive cells (Figure 3 – Supplement 2) and to determine response latencies (Figure 6). In both cases, the MIMI-method performed somewhat mediocrely. It was very well able to detect responsive cells with many spikes, but showed a high false alarm rate for cells with few spikes, presumably due to overfitting. As we also note in the manuscript, the MIMI-method may be a useful technique in many regards, but it requires hyperparameter tuning, such as regularization and the choice of number and location of knots, in order to perform well. It is therefore not suited as an automated generalist test for responsiveness of neurons with varied spiking statistics. Moreover, any alternative method that uses model fitting will likely show similar requirements. Using the MIMI-method to determine latencies, we found that it showed more timescale-invariance than PSTH-based approaches, but still did not perform as well as the ZETA-IFR (Figure 6). We made numerous edits throughout the manuscript to better communicate the aim and applicability of the ZETA-test, and expanded the discussion of the proposed scope of the ZETA-test (lines 377-418). In summary, full MIMI-model based methods do not seem to be suited for unsupervised, large-scale use as neuronal responsiveness tests.</p><disp-quote content-type="editor-comment"><p>2. For the examples in which the response is constructed to be a pure elevation of the firing rate, the ZETA test does not appear to be superior (Figure 4, row 1): there is a larger fraction of cells detected as responsive, but also a greater number of false positives. An ROC curve would likely show this. But more importantly, if the underlying firing statistics are Poisson – as they are constructed to be – then, since the firing rate is a sufficient statistic, simple estimation of the firing rate cannot be worse than the zeta statistic.</p></disp-quote><p>We have added a more in-depth analysis of how the ZETA-test and t-test behave in the case of cells with purely exponentially-distributed inter-spike intervals (Figure 4A-B). Our analyses show that there indeed exists a range of a parameters where the t-test outperforms the ZETA-test. Importantly, however, this is a fairly narrow range and only holds for biologically implausible parameter values.</p><disp-quote content-type="editor-comment"><p>3. The derivation of the null distribution for the statistic makes a lot of assumptions, including the extent of jittering and the use of extreme-value asymptotics; there may be a much simpler way to the goal.</p></disp-quote><p>As we now also better explain in the methods (lines 514-521), we use the extreme value asymptotics only to limit the number of random samples needed to calculate the p-value of ZETA. In the limit of infinite random jitters, we would obtain the true null distribution. The use of the Gumbel approximation is therefore simply to make the test more computationally tractable.</p><disp-quote content-type="editor-comment"><p>If I understand correctly, the idea is to construct an estimate of the cumulative distribution of spike times, and to compare that with the null hypothesis that they are uniformly distributed. If that is the case, perhaps one could just use the Kolmogorov-Smirnov test?</p></disp-quote><p>We agree with the reviewer that this is indeed an interesting idea. We have therefore explored it in more detail. As we show in lines 608-668 and Figure 3 – Supplement 3, the basis of ZETA is not dissimilar to a K-S test, but a K-S test shows a very high false alarm rate. In short, this is presumably caused by the issue that any deviation from non-uniform ISIs will lead to a low p-value; i.e., stimulus non-responsive, but bursting, cells will cause significant p-values.</p><disp-quote content-type="editor-comment"><p>This also brings up another issue: if the neuron's underlying firing pattern is far from Poisson, e.g., that it is similar to a renewal process whose interspike interval distribution is highly peaked – will the zeta test work?</p></disp-quote><p>Again, we agree with the reviewer that this is an important question, and thank the reviewer for bringing this up. We further investigated this issue using simulated bursting cells. Our new analysis show that even in the absence of peaks, but in the presence of bursting and highly peaked ISI distributions, the ZETA-test performs very well, and better than the t-test (Figure 4C-F).</p><disp-quote content-type="editor-comment"><p>4. Finally, I think that the virtues of a &quot;nonparametric&quot; test is not as obvious or universal as they might first appear. On the one hand, even with a test such as the one proposed here, one still needs to choose the time period to analyze. On the other hand, one often cares very much about the timescale of the response variation, both to exclude phenomena that one is not interested in, and to understand what aspects of the response are informative. This point is of course not germane to whether the paper makes an advance, but I think it would be preferable to discuss these considerations, rather than to assert that nonparametric tests are preferable.</p></disp-quote><p>We have now added some additional comments to the discussion on model-based approaches (e.g., lines 386-391, noting that they may attain better performance than the ZETA-test), but require supervision and hyperparameter selection. As we wrote above, we do not wish to claim that the ZETA-test is the <italic>end-all and be-all</italic> of statistical tests: each test must be chosen for a specific use case. We have added various comments relating to the scope of the ZETA-test throughout the manuscript.</p></body></sub-article></article>