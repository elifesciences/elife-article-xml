<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">36419</article-id><article-id pub-id-type="doi">10.7554/eLife.36419</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>Temporal processing and context dependency in <italic>Caenorhabditis elegans</italic> response to mechanosensation</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-108808"><name><surname>Liu</surname><given-names>Mochi</given-names></name><email>mochil@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-108809"><name><surname>Sharma</surname><given-names>Anuj K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5061-9731</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-17888"><name><surname>Shaevitz</surname><given-names>Joshua W</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-30795"><name><surname>Leifer</surname><given-names>Andrew M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5362-5093</contrib-id><email>leifer@princeton.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Lewis-Sigler Institute for Integrative Genomics</institution><institution>Princeton University</institution><addr-line><named-content content-type="city">New Jersey</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Physics</institution><institution>Princeton University</institution><addr-line><named-content content-type="city">New Jersey</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Princeton Neuroscience Institute</institution><institution>Princeton University</institution><addr-line><named-content content-type="city">New Jersey</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-49705"><name><surname>O'Leary</surname><given-names>Timothy</given-names></name><role>Reviewing Editor</role><aff id="aff4"><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>26</day><month>06</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e36419</elocation-id><history><date date-type="received" iso-8601-date="2018-03-06"><day>06</day><month>03</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-06-10"><day>10</day><month>06</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Liu et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Liu et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-36419-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.36419.001</object-id><p>A quantitative understanding of how sensory signals are transformed into motor outputs places useful constraints on brain function and helps to reveal the brain’s underlying computations. We investigate how the nematode <italic>Caenorhabditis elegans</italic> responds to time-varying mechanosensory signals using a high-throughput optogenetic assay and automated behavior quantification. We find that the behavioral response is tuned to temporal properties of mechanosensory signals, such as their integral and derivative, that extend over many seconds. Mechanosensory signals, even in the same neurons, can be tailored to elicit different behavioral responses. Moreover, we find that the animal’s response also depends on its behavioral context. Most dramatically, the animal ignores all tested mechanosensory stimuli during turns. Finally, we present a linear-nonlinear model that predicts the animal’s behavioral response to stimulus.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.36419.002</object-id><title>eLife digest</title><p>A worm called <italic>Caenorhabditis elegans</italic> has a nervous system made up of only 302 neurons, far fewer than the billions of cells that comprise our own brains. And yet these few hundred neurons are enough for these worms to detect and respond to their surroundings. <italic>C. elegans</italic> is thus a popular choice for studying how nervous systems process sensory information and use it to control behavior. Yet, most experiments to date have used only simple stimuli, such as taps or pokes, and studied a handful of behaviors, such as whether or not a worm stops moving or backs up. This limits the conclusions it has been possible to draw.</p><p>Liu et al. therefore set out to determine how the worm’s nervous system responds to more complex stimuli. These included physical stimuli, such as taps on the side of the dish containing the worms, as well as simulated stimuli. To generate the latter, Liu et al. used a technique called optogenetics to directly activate the neurons in the worm’s body that would normally detect information from the senses, by simply shining a light on the worms. Doing so gives the worm the sensation of a physical stimulus, even though none was present. Liu et al. then used mathematics to examine the relationships between the stimuli and the worms’ responses.</p><p>The results confirmed that worms usually respond to simple stimuli, such as taps on the side of their dish, by backing up. But they also revealed more advanced forms of stimulus processing. The worms responded differently to stimuli that increased over time versus decreased, for example. A worm's response to a stimulus also varied depending on what the worm was doing at the time. Worms that were in the middle of turns, for instance, ignored stimuli to which they would normally respond. This suggests that an animal’s current behavior influences how its nervous system interprets sensory information.</p><p>The discovery of relatively sophisticated responses to sensory stimuli in <italic>C. elegans</italic> indicates that even simple nervous systems are capable of flexible sensory processing. This lays a foundation for understanding how neural circuits interpret sensory signals. Building on this work will ultimately help us understand how more complicated nervous systems interpret and respond to the world.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>mechanosensation</kwd><kwd>behavior</kwd><kwd>reverse correlation</kwd><kwd>sensory processing</kwd><kwd>optogenetics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>C. elegans</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>National Human Genome Research Institute Award Number T32HG003284</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Mochi</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006734</institution-id><institution>Princeton University</institution></institution-wrap></funding-source><award-id>Dean for Research Innovation Fund</award-id><principal-award-recipient><name><surname>Shaevitz</surname><given-names>Joshua W</given-names></name><name><surname>Leifer</surname><given-names>Andrew M</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1734030</award-id><principal-award-recipient><name><surname>Shaevitz</surname><given-names>Joshua W</given-names></name><name><surname>Leifer</surname><given-names>Andrew M</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>SCGB #324285</award-id><principal-award-recipient><name><surname>Leifer</surname><given-names>Andrew M</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>SCGB #543003</award-id><principal-award-recipient><name><surname>Leifer</surname><given-names>Andrew M</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value><bold><italic>Caenorhabditis</italic></bold> <italic>elegans</italic> behavioral response to a mechanosensory signal depends on both the temporal properties of the signal, such as its rate of change, and the animal's current behavior state.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>An animal’s nervous system interprets sensory signals to guide behavior, including behaviors that are involved in evading predation. Investigating how the nervous system processes these signals is a critical step towards understanding neural function.</p><p>Mechanosensation in the nematode <italic>Caenorhabditis elegans</italic> is an attractive platform for investigating sensorimotor processing. Six soft-touch mechanosensory neurons arranged throughout the body detect mechanical stimuli including those delivered either by a small probe in what is called a touch or by striking the petri dish containing the animal in what is called a tap (<xref ref-type="bibr" rid="bib6">Chalfie and Sulston, 1981</xref>). Despite decades of investigation, however, the behavioral response to dynamic time-varying mechanosensory signals has not been fully explored.</p><p>Here we provide new details about the mechanosensory response system by quantitatively exploring the animal’s detailed behavioral response to rich, dynamically varying signals. We find that the animal responds to the temporal features of signals in its mechanosensory neurons, such as its time-derivative (i.e. rate of change), that extend over many seconds. Moreover, we find evidence that the animal’s sensorimotor response depends on the animal’s current behavior state. That we find evidence of temporal processing and context dependency, even in the nematode’s relatively simple touch circuit, raises the possibility that these features could be ubiquitous across sensory systems. Finally, we present a simple quantitative model that predicts the animal’s response to novel mechanosensory signals.</p><p>Mechanosensation is important for <italic>C. elegans</italic> survival. <italic>Caenorhabditis elegans</italic> are preyed upon by nematophagous fungi, and touch-defective animals fail to detect and escape from the fungus (<xref ref-type="bibr" rid="bib40">Maguire et al., 2011</xref>). Much is already known about this critical circuit. The six soft-touch mechanosensory neurons detect both spatially localized and non-localized stimuli. Anterior touches are detected by anterior neurons ALML, ALMR and AVM and evoke reversal behaviors whereas posterior touches are detected by posterior neurons PLML and PLMR and evoke forward sprints (<xref ref-type="bibr" rid="bib6">Chalfie and Sulston, 1981</xref>; <xref ref-type="bibr" rid="bib7">Chalfie et al., 1985</xref>; <xref ref-type="bibr" rid="bib42">McClanahan et al., 2017</xref>; <xref ref-type="bibr" rid="bib41">Mazzochette et al., 2018</xref>). Non-spatially localized plate taps are detected by both anterior and posterior soft-touch neurons and evoke reversals in young adult animals (<xref ref-type="bibr" rid="bib6">Chalfie and Sulston, 1981</xref>; <xref ref-type="bibr" rid="bib56">Rankin et al., 1990</xref>); on rare occasions, they also evoke forward acceleration (<xref ref-type="bibr" rid="bib70">Wicks and Rankin, 1995</xref>; <xref ref-type="bibr" rid="bib10">Chiba and Rankin, 1990</xref>). Owing in part to its ease of delivery and its inherent compatibility with high-throughput methods (<xref ref-type="bibr" rid="bib67">Swierczek et al., 2011</xref>), plate tap emerged early on as an assay for studying sensitization and habituation (<xref ref-type="bibr" rid="bib56">Rankin et al., 1990</xref>). Plate tap has been used in concert with the touch assay to study the development, circuitry (<xref ref-type="bibr" rid="bib6">Chalfie and Sulston, 1981</xref>), genes, molecules and receptors (<xref ref-type="bibr" rid="bib59">Sanyal et al., 2004</xref>; <xref ref-type="bibr" rid="bib32">Kindt et al., 2007</xref>) of the mechanosensory system.</p><p>When the animal interacts with its environment or brushes up against a nematophagous fungi’s constricting ring, it necessarily receives time-varying stimuli. The response of an individual touch receptor neuron to force (<xref ref-type="bibr" rid="bib50">O'Hagan et al., 2005</xref>), including to time-varying stimuli, is well characterized (<xref ref-type="bibr" rid="bib22">Eastwood et al., 2015</xref>). The onset and offset of an applied force evokes strong excitatory currents that adapt with a timescale of a few tens of milliseconds (<xref ref-type="bibr" rid="bib50">O'Hagan et al., 2005</xref>) and have a frequency response thought to peak in the 100 to 500 Hz range (<xref ref-type="bibr" rid="bib22">Eastwood et al., 2015</xref>). Intracellular calcium activity in individual soft touch neurons has also been well characterized in response to touch and this activity exhibits slower transients that occur with a timescale of seconds (<xref ref-type="bibr" rid="bib66">Suzuki et al., 2003</xref>; <xref ref-type="bibr" rid="bib13">Cho et al., 2018</xref>). In contrast to this detailed understanding at the single neuron level, the animal’s downstream response to rich temporally varying mechanosensory signals has been less well characterized.</p><p>The animal’s behavior response to mechanosensory stimuli has primarily been studied using impulse stimuli. Specifically, the stimuli were either a brief application of touch, tap or optogenetic stimulation, and the most salient feature of these stimuli was their amplitude, not their temporal profile (<xref ref-type="bibr" rid="bib51">Petzold et al., 2013</xref>; <xref ref-type="bibr" rid="bib64">Stirman et al., 2011</xref>; <xref ref-type="bibr" rid="bib42">McClanahan et al., 2017</xref>; <xref ref-type="bibr" rid="bib41">Mazzochette et al., 2018</xref>). In the classical touch assay, for example, a saturating force that lasts just a few tenths of a second is applied (<xref ref-type="bibr" rid="bib48">Nekimken et al., 2017</xref>). Tap stimuli are even shorter in duration.</p><p>To our knowledge, the only temporally varying stimuli used to investigate behavioral responses to mechanosensation are: trains of taps or touches (<xref ref-type="bibr" rid="bib10">Chiba and Rankin, 1990</xref>; <xref ref-type="bibr" rid="bib33">Kitamura et al., 2001</xref>), trains of optogenetic pulses (<xref ref-type="bibr" rid="bib53">Porto et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Leifer et al., 2011</xref>), trains of ultrasound pulses (<xref ref-type="bibr" rid="bib35">Kubanek et al., 2018</xref>), the delivery of 100 Hz or 1 kHz acoustic vibration (<xref ref-type="bibr" rid="bib45">Nagy et al., 2014a</xref><xref ref-type="bibr" rid="bib46">, 2014b</xref>; <xref ref-type="bibr" rid="bib65">Sugi et al., 2016</xref>), and the delivery of sustained acoustic vibrations of different frequencies lasting many minutes to hours (<xref ref-type="bibr" rid="bib8">Chen and Chalfie, 2014</xref>).</p><p>The following behaviors have been extensively studied in response to mechanosensory stimulation. Early work scored the animal’s reversals (<xref ref-type="bibr" rid="bib10">Chiba and Rankin, 1990</xref>) and more recent work includes reversal distance (<xref ref-type="bibr" rid="bib33">Kitamura et al., 2001</xref>), rate of reversals (<xref ref-type="bibr" rid="bib67">Swierczek et al., 2011</xref>) or pauses, reversal duration and reversal latency (<xref ref-type="bibr" rid="bib1">Ardiel et al., 2017</xref>). The effect of mechanosensory stimulation on accelerations has also been studied (<xref ref-type="bibr" rid="bib70">Wicks and Rankin, 1995</xref>). Recent work, however, shows that the animal’s repertoire of behavior is larger (<xref ref-type="bibr" rid="bib63">Stephens et al., 2008</xref>; <xref ref-type="bibr" rid="bib4">Brown et al., 2013</xref>).</p><p>Over short timescales, reversals or accelerations depend on the set of neurons stimulated and the stimulus strength. The location of an applied force determines which touch receptor neurons are activated and thus whether the animal accelerates or reverses, while the amplitude of the applied stimulus determines the probability that the animal responds at all (<xref ref-type="bibr" rid="bib21">Driscoll, 1997</xref>; <xref ref-type="bibr" rid="bib64">Stirman et al., 2011</xref>; <xref ref-type="bibr" rid="bib51">Petzold et al., 2013</xref>; <xref ref-type="bibr" rid="bib42">McClanahan et al., 2017</xref>; <xref ref-type="bibr" rid="bib41">Mazzochette et al., 2018</xref>).</p><p>Over longer timescales of minutes to hours, however, the picture has been shown to be more complicated. Habituation (<xref ref-type="bibr" rid="bib56">Rankin et al., 1990</xref>), quiescence (<xref ref-type="bibr" rid="bib54">Raizen et al., 2008</xref>; <xref ref-type="bibr" rid="bib13">Cho et al., 2018</xref>), and exposure to prolonged vibrations, salt or hypoxia, all modulate the animal’s sensitivity to mechanical stimuli (<xref ref-type="bibr" rid="bib8">Chen and Chalfie, 2014</xref>, <xref ref-type="bibr" rid="bib9">2015</xref>).</p><p>More recently, evidence has also emerged that short timescale properties of the stimulus may also play a role in modulating the animal’s behavioral response. <xref ref-type="bibr" rid="bib53">Porto et al. (2017</xref>) reported the use of reverse correlation and a binary optogenetic stimulus to present evidence that temporal processing is important for the animal’s behavioral response over a timescale of seconds. In our work here, we show that the nervous system does indeed process signals from the mechanosensory neurons over timeseries of many seconds. We find that the animal’s behavior response depends on higher-order temporal features such as the derivative of those mechanosensory signals, in addition to the stimulus amplitude and the animal’s own behavioral context.</p><p>Here, we revisit the animal’s behavioral response to mechanosensory stimulation armed with high-throughput optogenetic methods for delivering time-varying stimuli and improved techniques for measuring animal posture (<xref ref-type="bibr" rid="bib63">Stephens et al., 2008</xref>) and behavior (<xref ref-type="bibr" rid="bib3">Berman et al., 2014</xref>). Using reverse correlation (<xref ref-type="bibr" rid="bib58">Ringach and Shapley, 2004</xref>; <xref ref-type="bibr" rid="bib61">Schwartz et al., 2006</xref>; <xref ref-type="bibr" rid="bib25">Gepner et al., 2015</xref>), we analyze over 8000 animal-hours of recordings and find new insights into the interplay between sensory processing and behavior.</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.003</object-id><label>Figure 1.</label><caption><title><italic>Caenorhabditis elegans</italic> behavior quantification.</title><p>(<bold>a</bold>) Behavior map showing the probability density of posture dynamics observed during 2284 animal-hours of behavior, including stimulus and control conditions (‘Random Noise’ row in <xref ref-type="table" rid="table2">Table 2</xref>). Posture dynamics have many dimensions but are projected down into a low-dimensional space using the t-SNE method used by <xref ref-type="bibr" rid="bib3">Berman et al. (2014</xref>). Peaks indicate stereotyped postures. Discrete behavior states are defined by dividing the posture map into nine regions by using a watershedding algorithm. (<bold>b</bold>) Human-readable behavior names are provided by the experimenters. (<bold>c</bold>) Mean center of mass velocities of animals in each region. Positive velocity is in the direction of the animal’s head. (<bold>d</bold>) Probability of transitioning between behaviors. Thickness of lines scales with probability. Transition probabilities &lt; 2% were omitted.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig1-v2"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Analysis pipeline for classifying behavior.</title><p>Behavior is mapped and classified according to the animal’s posture dynamics, similar to the mapping described in <xref ref-type="bibr" rid="bib3">Berman et al. (2014</xref>). Images of <italic>C. elegans</italic> are segmented to extract the animal’s centerline. Each centerline is projected into a linear combination of posture modes. The animal’s time-varying posture is represented as a time-series of corresponding weights. Spectrograms of these time-series describe the animal’s postural dynamics at each point in time. Posture dynamics are mapped into a two-dimensional plane using t-distributed stochastic neighbor embedding (t-SNE). The animal occupies a different point on the behavior map depending on its postural dynamics, and its placement in this map determines the behavioral classification.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig1-figsupp1-v2"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.005</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Behavior maps were generated from 2284 animal-hours of behavior recorded from P<italic>mec-4::Chrimson</italic> worms during optogenetic stimulation and control conditions.</title><p>Distance between two points on the map is related to the Kullback-Leibler (KL) divergence of the respective posture dynamics spectra (<xref ref-type="bibr" rid="bib3">Berman et al., 2014</xref>), but for our purposes here the <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula> axes can be taken as arbitrary. (<bold>a</bold>) The sign of the animal’s velocity is shown for 55,000 time-points uniformily selected from the recordings. Distinct regions in the map correspond to forward or backward locomotion. (<bold>b</bold>) Probability density plot showing the likelihood that the animal exhibits different behaviors. Peaks in the probability density correspond to stereotyped behaviors. (<bold>c</bold>) Natural boundaries that separate stereotyped worm behaviors are found using watershedding. Same as in <xref ref-type="fig" rid="fig1">Figure 1</xref>. These regions define distinct behavior states. (<bold>d</bold>) The probability of occupying a given behavior is shown for animals in an unstimulated condition. Circle area scales with occupancy probability.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig1-figsupp2-v2"/></fig><media id="fig1video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-36419-fig1-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.36419.006</object-id><label>Figure 1—video 1.</label><caption><title>Video of tracked animals undergoing optogenetic stimulation.</title><p>Movie showing worms undergoing random noise optogenetic stimulation. Image frames have been median filtered. Center of mass trajectories from the first step of the behavioral analysis are also shown. Trajectory colors are arbitrary. Inset shows the individual video of a single animal used for behavioral analysis. The red dot in the corner indicates the intensity of the optogenetic stimulus.</p></caption></media><media id="fig1video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-36419-fig1-video2.mp4"><object-id pub-id-type="doi">10.7554/eLife.36419.007</object-id><label>Figure 1—video 2.</label><caption><title>Videos of randomly selected animals performing each of the nine behaviors.</title><p>Randomly selected 3 s long examples of animals performing each of the nine behaviors.</p></caption></media><media id="fig1video3" mime-subtype="mp4" mimetype="video" xlink:href="elife-36419-fig1-video3.mp4"><object-id pub-id-type="doi">10.7554/eLife.36419.008</object-id><label>Figure 1—video 3.</label><caption><title>Video showing the path of an animal through behavior space.</title><p>(Right)Video of an example animal. The detected centerline (green) is overlaid. A dot denotes the head. The animal is kept centered in the video, even though it is moving. (Left) Animal’s instantaneous behavior is shown (yellow ring) on the behavioral map.</p></caption></media></fig-group></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Mechanosensation evokes a range of behavioral responses</title><p>We first investigated the animal's response to plate tap, a spatially non-localized mechanosensory stimulus generated by tapping the dish containing the animals. Plate taps had previously been reported to evoke reverse locomotion (<xref ref-type="bibr" rid="bib56">Rankin et al., 1990</xref>) and rarely forward accelerations (<xref ref-type="bibr" rid="bib70">Wicks and Rankin, 1995</xref>) in the young adult animals used here. A solenoid repeatedly delivered a tap stimulus every 60 s for 30 min to a plate of many young adult wild-type (N2) worms, repeated across 22 plates, resulting in 40,409 total animal-tap presentations. The inter-stimulus interval was chosen to minimize the effects of habituation (<xref ref-type="bibr" rid="bib57">Rankin and Wicks, 2000</xref>). The animal’s behavior was continuously measured and classified using a behavior-mapping technique similar to that described in <xref ref-type="bibr" rid="bib3">Berman et al. (2014)</xref>. Briefly, statistical inference was performed on all of the animal’s posture dynamics to generate a single behavior map. Stereotyped posture dynamics that emerged from this map were defined as behaviors. Each individual animal’s posture dynamics were projected into this map at each point in time and automatically classified into one of nine behavior states, which were assigned labels such as 'Turn.' See <xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplements 1</xref> and <xref ref-type="fig" rid="fig1s2">2</xref> and methods for a complete description of the behavior mapping. Also see example videos of behavioral mapping in <xref ref-type="video" rid="fig1video2">Figure 1—video 2</xref> and <xref ref-type="video" rid="fig1video3">Figure 1—video 3</xref>.</p><p>Consistent with previous reports, we observed that taps most dramatically evoked the animal to transition to the 'Fast Reverse' state. Tap stimulus induced a 14-fold increase in the fraction of animals exhibiting 'Fast Reverse' immediately post stimuli, see <xref ref-type="fig" rid="fig2">Figure 2a</xref> and <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>. In addition, animals that continued in forward locomotion exhibited an overall slowing down, transitioning from fast locomotion states to slower locomotion states, which to our knowledge had not been reported previously. We also observed a 4.5-fold increase in the fraction of animals exhibiting 'Turn' behavior approximately 5 s post stimulus. The fraction of animals exhibiting 'Slow Reverse' also increased slightly upon stimulation. These measurements suggest that plate tap evokes a wide-range of behavioral responses in the animal.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.009</object-id><label>Figure 2.</label><caption><title>Stimulation evokes a diverse range of behavior responses.</title><p>(<bold>a</bold>) Fractions of animals occupying each behavior state in response to a plate tap (40,409 stimulus-animal presentations) and (<bold>b</bold>) in response to a 1 s optogenetic light stimulation of the six soft touch mechanosensory neurons (2,444 stimulus-animal presentations, 20 μW mm<sup>–2</sup>). Note the similarity in the behavior responses to light and tap. The gray shaded window indicates inherent temporal uncertainty in behavior classification. See 'Materials and methods'. (<bold>c</bold>) Response to optogenetic stimulation depends on light intensity. Peak fraction of animals in the 'Fast Reverse' state in a 6 s window post stimulus are shown for different-intensity light pulses. More than 2,000 stimulus-animal presentations were recorded for each point plotted. Arrow indicates the light intensity used in (B). Pink shaded region indicates light range used for subsequent continuous light stimulation experiments, as in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig2-v2"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.010</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Diagram of high-throughput stimulation and behavior assay.</title><p>Worm behavior is recorded while delivering optogenetic or tap stimulation to a plate containing <inline-formula><mml:math id="inf2"><mml:mrow><mml:mn>63</mml:mn><mml:mo>±</mml:mo><mml:mn>40</mml:mn></mml:mrow></mml:math></inline-formula> animals (mean <inline-formula><mml:math id="inf3"><mml:mo>±</mml:mo></mml:math></inline-formula> standard deviation). Optogenetic stimulation is delivered by modulating the light intensity of three 625 nm LEDs (only one is shown in the diagram). Taps are delivered to the plate via a computer-controlled solenoid. Recordings last 30 min per plate, and each experimental series consists of many plates, see <xref ref-type="table" rid="table2">Table 2</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig2-figsupp1-v2"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.011</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Transition rates for tap and light stimulation.</title><p>The rate of transitions into each behavior is shown aligned to a tap or 1 s optogenetic light stimulus. Panels (<bold>a</bold>) and (<bold>b</bold>) correspond to the occupancy plots in <xref ref-type="fig" rid="fig2">Figure 2a and b</xref>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig2-figsupp2-v2"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.012</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Control animals grown without ATR are light insensitive.</title><p>Fractions of control AML67 animals occupying each behavior state are shown in response to a light-pulse stimulus. Animals grown without the co-factor all-trans-retinal (– ATR) do not respond to light even at a light intensity level of 80 μW mm<sup>–2</sup>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig2-figsupp3-v2"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.013</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Tap sensitivity of transgenic animals is reduced compared to that of wild-type animals.</title><p>Fractions of AML67 animals occupying each behavior state and transition rates into each behavior are shown in response to a mechanical tap stimulus. Recordings from both ATR+ and ATR– conditions are pooled together. AML67 animals show decreased responsiveness to tap stimulation compared to wild-type, presumably because exogenous mec-4 promoter sequences deplete the transcription of endogenous MEC-4.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig2-figsupp4-v2"/></fig></fig-group><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.014</object-id><label>Figure 3.</label><caption><title>Transitions into behavior states are tuned to higher-order temporal features of the stimulus such as the derivative.</title><p>(<bold>a</bold>) Random noise time-varying light stimulus is delivered to a population of animals. Behavior-triggered averages (also referred to as kernels) are calculated for transitions into each behavior state from 1,784 animal-hours of recordings. Each behavior-triggered average describes features of the stimulus that correlate with that behavior transition. Only those behavior-triggered averages that pass a significance test in which they are compared to a shuffled stimuli are shown. The shape of the behavior-triggered average depends on the behavior. Note that some behaviors have Gaussian-like shapes, whereas others have biphasic shapes that act like derivatives. The numbers of observed transitions, <inline-formula><mml:math id="inf4"><mml:mi>n</mml:mi></mml:math></inline-formula>, in each behavior are listed. (<bold>b</bold>) Similar behaviors have similar behavior-triggered averages. Dendrogram showing hierarchical clustering of the euclidian distance of the scaled behavior-triggered averages. The two reversal states, for example, form a cluster.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig3-v2"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.015</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Change in behavioral occupancy evoked by random noise stimulation.</title><p>The change in occupancy during random noise optogenetic light stimulation (1,784 animal hours) compared to no-retinal (ATR–) control (500 animal-hours). Baseline occupancy during no-retinal control is shown in <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2d</xref>.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig3-figsupp1-v2"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.016</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Behavior-triggered averages and non-linearities for all behaviors.</title><p>Behavior-triggered averages and associated non-linearities for transitions into all nine behavior states. Those behavior-triggered averages that fail to pass a shuffled significance threshold are shown in light gray. Non-linearities are only calculated for behaviors whose behavior-triggered averages pass our shuffled significance test. Note that the observed non-linearites (circles) are mostly well-approximated by a line (fitted line shown), consistent with the observation in <xref ref-type="fig" rid="fig2">Figure 2c</xref> that the animal responds roughly linearly in our stimulus regime.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig3-figsupp2-v2"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.017</object-id><label>Figure 3—figure supplement 3.</label><caption><title>Behavior-triggered averages for control animals grown without ATR.</title><p>Behavior-triggered averages are shown for transitions into all nine behavior states for control animals grown without the required cofactor all-trans retinal (ATR–). As expected, none of the kernels pass a shuffled significance threshold. Consequently non-linearities were not calculated.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig3-figsupp3-v2"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.018</object-id><label>Figure 3—figure supplement 4.</label><caption><title>Power spectra of a single instantiation of the random noise stimulus.</title><p>The MATLAB periodogram function is used to generate the power spectra of the random noise stimulus for a 30 min experiment.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig3-figsupp4-v2"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.019</object-id><label>Figure 3—figure supplement 5.</label><caption><title>Light-intensity histogram for random noise stimulus.</title><p>A histogram of the light intensity at each time point for all random noise stimulus experiments.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig3-figsupp5-v2"/></fig></fig-group></sec><sec id="s2-2"><title>Optogenetic stimulation mimics a tap</title><p>We sought to activate the mechanosensory circuit optogenetically because optogenetic stimulation is more amenable to modulation and control. Optogenetic stimulation of the six mechanosensory neurons had previously been shown to evoke reversals and accelerations, similar to the response to tap (<xref ref-type="bibr" rid="bib44">Nagel et al., 2005</xref>). We wondered whether the details of the behavior response to tap that we observed are also present in response to optogenetic activation. Animals expressing the light-gated ion channel Chrimson in their soft touch mechanosensory neurons (strain AML67 [P<italic>mec-4::Chrimson::SL2::mCherry::unc-54</italic>]) were illuminated with red light for 1 s with a 60 s inter-stimulus interval (2,444 stimulus-animal presentations, 20 <underline>μW mm</underline><underline><sup>–2</sup></underline>, selected to be in a region of high behavior sensitivity, see <xref ref-type="fig" rid="fig2">Figure 2c</xref>). Consistent with previous reports, light stimulation evoked a behavior response that was quantitatively similar to that of the plate tap (see <xref ref-type="fig" rid="fig2">Figure 2b</xref>) and required the cofactor all-trans retinal (ATR), see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>. For both light and tap, the most salient response was a dramatic increase in animals in the 'Fast Reverse' state. Both light and tap also evoked an increase in 'Forward 3' behaviors and both evoked similar decreases in 'Forward 4', '5' and '6' behaviors. Both light and tap also evoked an increase in 'Turn' behavior that peaked 5 s post-stimulus. Hence, optogenetic stimulation of mechanosensory neurons evoke detailed behavior responses similar to those resulting from a mechanical stimulus. This suggests that our optogenetic stimulation generates physiologically reasonable signals in the mechanosensory neurons and we therefore proceeded to explore the animal’s response to optogenetic stimulation.</p></sec><sec id="s2-3"><title>Behavioral responses are correlated to temporal features such as the derivative</title><p>When the animal explores its natural environment, crawls through crevices, and interacts with other organisms, it probably experiences time-varying mechanical stimuli. Therefore, we sought to investigate the animal’s response to random temporally varying optogenetic stimulation. We find that the animal’s specific behavioral response correlates with higher-order temporal features of the stimulus, not merely the amplitude.</p><p>To deliver rich temporally varying stimuli, we continuously presented a plate of transgenic animals with light modulated by broad frequency noise (7 Hz nyquist limit, 0.5 s correlation time, 25 μW mm<sup>–2</sup> average intensity, min 0, max 50 μW mm<sup>–2</sup>, see power spectra in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, and video in <xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref>).</p><p>Modulating light intensity has been shown to elicit graded potentials during optogenetic activation of other <italic>C. elegans</italic> neurons (<xref ref-type="bibr" rid="bib38">Liu et al., 2009</xref>; <xref ref-type="bibr" rid="bib47">Narayan et al., 2011</xref>), therefore we expect the time-varying light stimuli to result in a membrane potential that varies smoothly over time. Noise stimulation evoked a wide range of behavioral responses (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). We used reverse correlation to identify the salient features of the stimulus that correlates with transitions into each behavior. Reverse correlation yields kernels that describe how a behavior is tuned to a stimulus. Kernels are particularly powerful in the context of the linear non-linear (LN) model, a simple and ubiquitous model in neuroscience that can be used to predict a neuron’s or animal’s response to stimulus (<xref ref-type="bibr" rid="bib58">Ringach and Shapley, 2004</xref>; <xref ref-type="bibr" rid="bib61">Schwartz et al., 2006</xref>; <xref ref-type="bibr" rid="bib17">Coen et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Gepner et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Hernandez-Nunez et al., 2015</xref>; <xref ref-type="bibr" rid="bib5">Calhoun and Murthy, 2017</xref>; <xref ref-type="bibr" rid="bib16">Clemens and Murthy, 2017</xref>). See in particular (<xref ref-type="bibr" rid="bib25">Gepner et al., 2015</xref>). Briefly, the LN model treats the response to a stimulus as a stochastic process involving two steps: first the stimulus timeseries <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> is convolved with a kernel <inline-formula><mml:math id="inf6"><mml:mi>A</mml:mi></mml:math></inline-formula> (linear operation), and then it is transformed into a response probability <inline-formula><mml:math id="inf7"><mml:mi>P</mml:mi></mml:math></inline-formula> via a non-linear look-up function <inline-formula><mml:math id="inf8"><mml:mi>f</mml:mi></mml:math></inline-formula> (non-linear operation), such that,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>P</mml:mi><mml:mo>[</mml:mo><mml:mtext>behavior</mml:mtext><mml:mo>]</mml:mo><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo>[</mml:mo><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup></mml:mrow></mml:mstyle><mml:mtext> </mml:mtext><mml:mi>A</mml:mi><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo><mml:mi>d</mml:mi><mml:mi>τ</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The shapes of the kernel and the non-linearity describe how a behavior response is tuned to the stimulus.</p><p>Kernels can be estimated by finding the behavior-triggered average. Briefly, the stimulus in a time window centered on a behavior transition is averaged across all such behavior transitions. The mean subtracted and time-reversed behavior-triggered average is an estimate of the kernel, and so henceforth, we use the terms behavior-triggered average and kernel interchangeably. Once the kernels <inline-formula><mml:math id="inf9"><mml:mi>A</mml:mi></mml:math></inline-formula> are calculated, it is straightforward to estimate the non-linearities <inline-formula><mml:math id="inf10"><mml:mi>f</mml:mi></mml:math></inline-formula> from the observed behavior responses (see 'Materials and methods'). Kernels and associated non-linearities were computed for transitions into each of the nine behavior states from over 50,000 behavior transition events per behavior (see <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Kernels for six of the nine behaviors were found to be significant compared to a shuffled stimuli (see 'Materials and methods'). By contrast, kernels computed from control animals grown without the necessary cofactor ATR all failed to pass our significance threshold (see <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Non-linearities calculated for the six behaviors were found to be mostly linear, suggesting that in our case the kernels themselves capture most of the information about how the nervous system responds to our stimulus.</p><p>Our prior understanding of the mechanosensory circuit makes strong predictions about the shape of the kernels that we should expect. If the behavior depends only on which neurons are activated, then all kernels should have the same shape, scaled linearly, because we are always activating the same set of neurons. (This assumes that all six neurons are activated in a linear regime, which seems reasonable given the approximately linear response observed in <xref ref-type="fig" rid="fig2">Figure 2c</xref>). Moreover, if the probability of response depends only on instantaneous stimulus amplitude, then we further expect all kernels to be narrow Gaussians. In contrast to these predictions, we see a wide diversity of kernels. Forward-locomotion kernels have biphasic waveforms, not at all like Gaussians. 'Forward 6', for example, has the shape of a differentiator, suggesting that the transitions into 'Forward 6' correlate with decreasing stimuli on a 7 s timescale. Kernels for 'Slow Reverse' and 'Fast Reverse', on the other hand, do look like Gaussians, consistent with prior reports that <italic>reversals</italic> do depend on the stimulus amplitude. Interestingly, the Gaussians are wide, which suggests that the animal may integrate the sensory signal over approximately 3 s in determining to reverse.</p><p>Taken together, we conclude that the animal’s behavior response is not merely correlated with which neurons are stimulated and the stimulus amplitude. Instead different behaviors correlate with different temporal features of signals in the mechanosensory neurons, even though the same six neurons were always activated. The behavioral response correlates with properties of the stimulus such as the derivative or the integral, not just the amplitude.</p></sec><sec id="s2-4"><title>Similar behavioral responses are tuned to similar stimuli</title><p>We wondered about the organization of the behavioral responses with respect to the stimuli to which they are tuned. One might expect animals to have evolved their behavioral response so that similar behaviors are tuned to similar stimuli. Indeed, we find that similar behaviors have quantitatively similar kernels. Hierarchical clustering was performed on the euclidian distance of the scaled kernels (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). The two reverse locomotion states have similar kernels and were clustered together. Forward velocity states fell into two clusters that were based on speed: 'Forward 3' and 'Forward 4' are slower and clustered together, whereas 'Forward 5' and 'Forward 6' are faster and clustered together. That similarities in the kernels reflect the similarities in their associated behaviors, provides additional confidence in our reverse correlation analysis.</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.020</object-id><label>Figure 4.</label><caption><title>Stimuli can be tailored to elicit specific behavioral responses, and the LN model predicts such responses.</title><p>(<bold>a</bold>) Animals are presented with stimuli shaped like the kernels in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Predicted (black bar) and observed (color bar) changes in transition rate are shown for transitions into each kernel-shaped stimulus’ corresponding behavior. For example, a 'Forward 3'-shaped stimulus increases transitions into 'Forward 3' (mustard bar). For five of the six behaviors, stimulation evoked increased transitions into their corresponding behaviors, as predicted. Transition rate changes are measured with respect to baseline (see 'Materials and methods'). Significance was estimated via a t-test and error bars show the standard error of the mean. The number of stimulus-animal presentations, from left to right, were 14,238, 13,612, 14,699, 14,424, 14,194 and 13,708. Of these, the number of timely transitions observed were 14,00, 1,428, 1,692, 944, 191 and 513. The p-values were 2.2e–1, 5.6e–6, 1e–4, 3.4e–5, 7.5e–2, 9.5e–1. (b) The LN model predicts details of the animal’s behavioral response. For each point in time, the LN model predicts the change from baseline of transition rates for all nine behaviors in response to a stimulus. Detailed responses to 'Forward 4'- and 'Forward 5'-kernel-shaped stimuli are shown (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for the rest). Raw transitions rates (light colored shading), smoothed transition rates (colored line) and LN prediction (solid black line) are shown. For stimuli that are shaped like 'Forward 4', the LN model correctly predicts not only that transitions into 'Forward 4' increase but also that transitions into 'Forward 5' and '6' decrease. Light gray shading indicates the 2 s time window used to calculate transition rates for the transitions shown in (A) (orange and pink arrows). Of 13,612 and 14,699 presentations for 'Forward 4'- and '5'-kernel shaped stimuli, respectively, the following number of transitions were observed in the 20 s window: by row for 'Forward 4'-shaped 1,265, 1,330, 12,312, 11,962, 13,436, 6,861, 1,735, 4,934 and 2,864, and for 'Forward 5'-shaped 1,198, 1,437, 13,657, 13,538, 14,656, 7,295, 1,673, 5,506 and 3,118.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig4-v2"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.021</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Behavioral responses to all kernel-shaped stimuli.</title><p>The LN model predicts the transition rate change from baseline for the nine behaviors in response to six stimuli constructed from statistically significant behavior-triggered averages. <inline-formula><mml:math id="inf11"><mml:mi>n</mml:mi></mml:math></inline-formula> refers to the number of transitions of the corresponding behavior observed during the 20 s window. Presentation numbers refer to stimulus-animal presentations. The 'Forward 4' and 'Forward 5' columns are the same as those in <xref ref-type="fig" rid="fig4">Figure 4b</xref>.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig4-figsupp1-v2"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.022</object-id><label>Figure 4—figure supplement 2.</label><caption><title>Control animals grown without ATR do not respond to kernel-shaped stimuli.</title><p>Kernel-shaped stimuli are delivered to AML67 control animals grown without the required co-factor ATR. The change in transition rate into the kernel-shaped stimuli’s corresponding behavior is shown, as in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. Control animals do not exhibit a significant increase in transitions into the expected behavior states. Error bars show standard error of the mean. Black bars show LN predictions for light-sensitive animals. The number of stimulus-animal presentations, from left to right, were 3,474, 3,880, 3,988, 3,639, 4,351, and 3534. Of these, the number of timely transitions were 355, 225, 396, 162, 68, and 95. The p-values from a t-test were 0.63, 0.97, 0.92, 0.87, 0.33, and 0.68.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig4-figsupp2-v2"/></fig></fig-group></sec><sec id="s2-5"><title>Stimuli can be tailored to generate specific behavioral responses</title><p>To test causally whether specific signals in the mechanosensory neurons can bias the animal towards specific behaviors as predicted, we generated stimuli that were tailored to elicit specific behavioral responses. The kernels found in <xref ref-type="fig" rid="fig3">Figure 3</xref> purport to describe how each behavioral response is tuned to the stimuli. Therefore, stimuli shaped like one of the kernels should drive an <italic>increase</italic> in transitions into its respective behavior. If, however, the behavioral response is tuned differently, then the kernel-shaped stimulus may evoke <italic>decreases</italic> in transitions to that behavior. (We already know that the animal can respond to some stimuli by decreasing transitions to certain behaviors because we saw this with tap and 'Forward 6', for example [see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>]).</p><p>We tested whether stimuli that are shaped like the kernels in <xref ref-type="fig" rid="fig3">Figure 3</xref> increased transitions into their associated behaviors. Kernel waveforms were presented to a plate of animals in a randomized order (six kernels, <inline-formula><mml:math id="inf12"><mml:mo>&gt;</mml:mo></mml:math></inline-formula>13,500 animal-stimulus presentations per kernel; 40 s inter-stimulus interval). Five of six kernels elicited increased transitions to their respective behaviors as predicted, three of the six significantly so (see <xref ref-type="fig" rid="fig4">Figure 4a</xref>). None significantly decreased transitions to their respective behaviors. We therefore conclude that the kernels correctly depict tuning of the behavioral responses. Consequently, we conclude that mechanosensory signals (even in the same neurons) can be tailored to evoke specific behaviors just by altering the stimulus waveform.</p></sec><sec id="s2-6"><title>LN model predicts behavioral response, including response to novel stimuli</title><p>The LN model provides an analytical framework to predict how an animal responds to a stimulus. The LN model correctly predicted that kernel-shaped waveforms should increase transitions into each kernel’s associated behavior state (see <xref ref-type="fig" rid="fig4">Figure 4a</xref>). The kernel-shaped waveforms also evoked other behavioral responses. For example, stimuli that were shaped like the 'Forward 4' kernel increased transitions to both 'Forward 4' and 'Forward 3'; but decreased transitions to 'Forward 5' and 'Forward 6' (see <xref ref-type="fig" rid="fig4">Figure 4b</xref>). How well, we wondered, does the LN model predict those responses? We compared the observed behavioral responses (colored lines) to detailed time-dependent predictions made by the LN model (black lines). To the resolution at which we could observe, we were reassured to find that the LN model correctly predicted the sign and temporal profile of changes in transition rates for all nine behavior states in response to each of the six kernel stimuli (see <xref ref-type="fig" rid="fig4">Figure 4b</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), suggesting that the LN model captures myriad details of the animal’s behavioral response.</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.023</object-id><label>Figure 5.</label><caption><title>Novel stimuli can be constructed to enrich specific mechanosensory responses.</title><p>A novel triangle-wave optogenetic light stimulus was repeatedly presented to animals. Change in transition rates are shown for transitions into each behavior (raw, light color shaded; smoothed, solid color line). Changes to transition rate as predicted by the LN model are also shown (black line). Increasing light intensity increases transitions into 'Forward 3'and 'Forward 4', while decreasing light intensity increases transitions into 'Forward 5' and 'Forward 6'. Transitions into 'Slow Reverse' and 'Fast Reverse' are highest during greatest stimulus intensity. The LN model predicts these trends (though not all the details) even though the LN model was fitted using the random noise experiments and therefore was not exposed to this particular stimulus. In response to the 340,757 animal-stimulus presentations, the following number of transitions were observed (by row, from top to bottom): 33,315, 31,243, 298,400, 343,474, 327,509, 160,332, 43,909, 106,743, and 57,439.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig5-v2"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.024</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Control animals grown without ATR do not respond to triangle wave.</title><p>A novel triangle-wave optogenetic light stimulus, such as that in <xref ref-type="fig" rid="fig5">Figure 5</xref>, was repeatedly presented to control animals grown without the required co-factor retinal. Control animals do not respond to the stimulus. The observed response is shown as well as the LN predicted response. In reposnse to 142,461 animal-stimulus presentations, the following number of transitions were observed (by row, from top to bottom): 14,575, 15,886, 146,149, 82,216, 131,060, 42,080, 16,871, 18,581, and 28,318.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig5-figsupp1-v2"/></fig></fig-group><p>We further challenged our understanding of the animal’s behavioral response to stimulus by presenting an entirely novel stimulus, a triangle-wave (340,757 stimulus-animal presentations) (see <xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). How well does the LN model predict the animal’s behavior response to this novel stimulus? The LN model captured the sign and general trend (though not all features) of the time-dependent change in the transition rate to all nine behaviors in response to the triangle wave. Moreover, the LN model provides a framework for understanding the animal’s response by inspecting features of the kernel waveform. For example, the 'Fast Reverse' kernel is symmetric in time and its mean-subtracted integral is positive. Therefore the shape of the 'Fast Reverse' kernel suggests that 'Fast Reverse' should be tuned to the overall stimulus intensity but not its derivative. Indeed we observe a very slight increase in the rate of transitions to 'Fast Reverse' during peak stimulus intensity. Conversely, the 'Forward 6' kernel is asymmetric in time and its biphasic waveform resembles that of the negative derivative of a Gaussian. Therefore, 'Forward 6' should be tuned to decreases in stimulus intensity, as we observe.</p><p>Taken together, our experiments show that the animal can be driven to transition into different specific behavior states by modulating the temporal profile of signals in the same mechanosensory neurons, and that the LN model predicts the animal’s response.</p></sec><sec id="s2-7"><title>Sensory processing is context dependent</title><p><italic>Caenorhabditis elegans</italic> are known to respond differently to the same stimuli when they are in different long-lived behavior states such as hunger (<xref ref-type="bibr" rid="bib26">Ghosh et al., 2016</xref>), quiescence (<xref ref-type="bibr" rid="bib54">Raizen et al., 2008</xref>; <xref ref-type="bibr" rid="bib62">Schwarz et al., 2011</xref>; <xref ref-type="bibr" rid="bib46">Nagy et al., 2014b</xref>; <xref ref-type="bibr" rid="bib13">Cho et al., 2018</xref>) or arousal (<xref ref-type="bibr" rid="bib11">Cho and Sternberg, 2014</xref>), or while undergoing Dauer formation (<xref ref-type="bibr" rid="bib8">Chen and Chalfie, 2014</xref><xref ref-type="bibr" rid="bib9">, 2015</xref>). We wondered whether mechanosensory processing might also be influenced by short-lived behavior states, like the 'Turn', 'Reverse' or 'Forward' locomotory states measured here. To investigate tuning of the animal’s behavioral response conditional on its current behavior state, we calculated context-dependent kernels, one for each pairwise transition (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Of 72 possible pairwise transitions, 27 had kernels that passed our shuffled significance threshold (compared to only four for our off-retinal control (see <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). Transitions to some behavior states, such as 'Forward 4', had kernels that changed dramatically depending on which behavior the animal originated from (see columns in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). The pairwise-specific kernels provided evidence of two types of context-dependent sensory processing in <italic>C. elegans</italic> that occur within short-time scales. In both cases, the animal appears to respond to the same stimuli differently depending on its current behavior. In the first, the animal responds to certain mechanosensory signals by speeding up or slowing down. In the second type, the animal suppresses its response to mechanosensory stimuli during turning behavior. These two types of context-dependency are described below.</p></sec><sec id="s2-8"><title>There are mechanosensory signals for speeding up or slowing down</title><p>Behavior transitions that involve slowing down have similar tuning. For example, the 'Forward 5'<inline-formula><mml:math id="inf13"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 4' kernel has a similar shape to the 'Forward 4'<inline-formula><mml:math id="inf14"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 3' kernel (see <xref ref-type="fig" rid="fig6">Figure 6</xref>, left column). Likewise, transitions involving speeding up also have similar kernels. For example, 'Forward 3'<inline-formula><mml:math id="inf15"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 4' and 'Forward 4'<inline-formula><mml:math id="inf16"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 5' have similar kernels (see <xref ref-type="fig" rid="fig6">Figure 6</xref>, right column). Moreover, the two classes of kernels appear to be reflections of one another about the line of mean stimulus intensity. The stereotypy of the speed up and slow down kernels suggests that these nematodes have evolved to respond to certain stimuli by slowing down or speeding up in a relative way instead of transitioning to a stimulus-defined velocity. This is of interest because it implies a form of context dependency: it suggests that the same stimulus will drive the animal into forward locomotory states of different speeds depending on the animal’s current state.</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.025</object-id><label>Figure 6.</label><caption><title>Behavior transitions that involve slowing down and speeding up have stereotyped tuning.</title><p>Selected context-dependent kernels are shown for transitions amongst forward locomotory states, where higher numbered states have higher velocities. Kernels for slowing transitions (left column) are all similar, whereas kernels for speeding up transitions (right column) are also similar. Slowing and speeding-up kernels resemble horizontal reflections of one another.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-36419-fig6-v2"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.026</object-id><label>Figure 6—figure supplement 1.</label><caption><title>All 72 pairwise context-dependent behavior-triggered averages.</title><p>Pairwise behavior-triggered averages (also referred to as kernels) are shown for transitions from one specified behavior to another. Kernels are calculated from 1,784 animal-hours of continuous random noise stimulation (same as in <xref ref-type="fig" rid="fig3">Figure 3</xref>). For transitions into a given behavior (column), the kernel waveforms differ depending on the behavior that the animal originated in (rows). This suggests that the animal’s behavioral response to stimulus depends on the animal’s current behavior state. For each kernel, the vertical axis spans 23 to 27 μW mm<sup>–2</sup> and the horizontal axis spans −10 to 10 s. <inline-formula><mml:math id="inf17"><mml:mi>n</mml:mi></mml:math></inline-formula> indicates the number of transitions observed. Kernels that fail to pass a shuffled significance threshold are grayed out (see 'Materials and methods').</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig6-figsupp1-v2"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.027</object-id><label>Figure 6—figure supplement 2.</label><caption><title>All 72 pairwise context-dependent behavior-triggered averages for control animals grown without ATR.</title><p>Pairwise behavior-triggered averages (also referred to as kernels) are shown for transitions from one specified behavior to another for control animals. For each kernel, the vertical axis spans 23 to 27 μW mm<sup>–2</sup> and the horizontal axis spans −10 to 10 s. <inline-formula><mml:math id="inf18"><mml:mi>n</mml:mi></mml:math></inline-formula> indicates the number of transitions observed. Kernels that fail to pass a shuffled significance threshold are grayed out (see 'Materials and methods').</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig6-figsupp2-v2"/></fig></fig-group><p>To determine whether the stereotyped speed-up or slow-down stimulus does indeed cause the animal to speed up or slow down, we again inspected the animal’s response to the kernel-shaped stimuli or the triangle-wave stimulus. Indeed, we found that the same stimulus drives the animal into a different forward locomotory state depending on the animal’s current state (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). For example, animals in the slower 'Forward 4' state responded to a 'Forward 4' kernel-shaped stimulus by <italic>decreasing</italic> their transitions to 'Forward 5'. By contrast, animals in the faster 'Forward 6' state responded to the same stimulus by <italic>increasing</italic> their transitions into 'Forward 5'. This was one of multiple instances in which we observed the animal responding to the same stimuli with opposite responses depending on its current behavior. During triangle wave stimulation, for example, an increasing ramp causes slowing down, whereas a decreasing ramp causes speeding up (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). We therefore conclude that stereotyped mechanosensory signals drive the animal to speed up or slow down.</p><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.028</object-id><label>Figure 7.</label><caption><title>Animals respond to the same stimuli differently depending on their current behavior state.</title><p>The change in transition rate from baseline is shown for transitions into 'Forward 5' from either 'Forward 4 '(middle row) or 'Forward 6' (bottom row) in response to four different stimuli (columns). Observed transition rates (colored bars) are compared to LN model predictions (black bars). The stimulus affects the rate of transitions into 'Forward 5' differently depending on whether the animal was in 'Forward 4' or 'Forward 6' at the time of stimulus. For example, consistent with the animal responding to a slowing-down signal, the 'Forward 4'-shaped stimulus decreases 'Forward 4'<inline-formula><mml:math id="inf19"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 5' transitions, but increases 'Forward 6'<inline-formula><mml:math id="inf20"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 5' transitions. A star indicates a significant change in transition rate from baseline. Gray shaded regions indicate the time windows over which the transition rate is calculated. Baseline is defined slightly differently for the kernel-shaped stimuli compared to the triangle waves (see 'Materials and methods'). Of 13,612 and 14,699 stimulus-animal presentations for 'Forward 4' and 'Forward 5' kernel-shaped stimuli, and 340,757 stimulus-animal presentations for the triangle wave, the following number of transitions were observed: 26, 24, 2,604 and 2,634 for 'Forward 4'<inline-formula><mml:math id="inf21"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 5' (top row) and 6, 7, 713 and 791 for 'Forward 6'<inline-formula><mml:math id="inf22"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 5' (bottom row). A t-test was used to test for signifiant changes from baseline and the following p-values were observed: 5.5e–5, 6.9e–6, 1.8e–19 and 5.1e–48 for 'Forward 4<inline-formula><mml:math id="inf23"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 5' (top row) and 6.3e–2, 8.7e–1, 3.9e–2 and 6.7e–5 for 'Forward 6'<inline-formula><mml:math id="inf24"><mml:mo>→</mml:mo></mml:math></inline-formula>'Forward 5' (bottom row). Error bars show the standard error of the mean.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig7-v2"/></fig></sec><sec id="s2-9"><title>Attention to mechanosensory signals depends on the animal’s current behavior</title><p>When the animal turns, it ignores all tested mechanosensory signals. This surprising observation is predicted by reverse-correlation analysis and confirmed by optogenetic and tap stimulation. Transitions out of 'Turn' are uncorrelated with stimulus, and kernels for those transitions all fail to pass our shuffled significance threshold (see bottom row in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Consequently, the kernels predict that the animal should ignore mechanosensory stimuli during turns. By contrast, for every other behavior state, there is always at least one (and often many) transitions exiting out of the state whose kernels pass our significance threshold (all rows other than 'Turn' have at least one significant kernel).</p><p>To further test whether the animal does indeed ignore stimuli during turns, we investigated the animal’s context-dependent response to light pulses or tap. When the animal was in the 'Turn' state, neither a light pulse nor a tap evoked a significant change in the rate of transitions into any other behavior (see bottom row <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplements 1</xref> and <xref ref-type="fig" rid="fig8s2">2</xref>) (multiple-hypothesis corrected E-test, see 'Materials and methods'). By contrast, when the animal was in other states, such as 'Forward 5', both a tap and light pulses evoked significant changes in the transition rate into other behaviors. In fact, every other behavior state except for 'Forward 2' had at least one behavior transition exiting the state whose transition rate was significantly affected by either light or a tap. The 'Turn' behavior state was unique in that none of the kernels for transitions originating in 'Turn' passed the shuffled significance threshold, and no transition rates changed significantly in response to either light or a tap, (see <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplements 1</xref> and <xref ref-type="fig" rid="fig8s2">2</xref>). We therefore conclude that in 'Turn, but not other states, the animal ignores mechanosensory stimuli.</p><p>Transitions into 'Fast Reverse' provide an illustrative example (see <xref ref-type="fig" rid="fig8">Figure 8</xref>). When the animal is in the 'Turn' state, there is no significant difference in the rate of 'Turn'<inline-formula><mml:math id="inf25"><mml:mo>→</mml:mo></mml:math></inline-formula>'Fast Reverse' transition between shuffled and stimuli. But when the animal is in 'Forward 5', light and taps caused a significant increase in 'Forward 5'<inline-formula><mml:math id="inf26"><mml:mo>→</mml:mo></mml:math></inline-formula>'Fast Reverse'. Taken together, we conclude that the animal attends to mechanosensory signals during most behavior states, such as 'Forward 5', but ignores them during turns.</p><fig-group><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.029</object-id><label>Figure 8.</label><caption><title>Attention to mechanosensory signals depends on behavior.</title><p>When the animal is in the 'Turn' state, it ignores mechanosensory stimuli. (<bold>a</bold>) Kernels are shown for two context-dependent transitions into 'Fast Reverse'. Transitions into 'Fast Reverse' originating from 'Forward 5' are correlated with stimulus and have a significant kernel, whereas those originating from 'Turn' are not correlated with stimulus and fail our shuffled significance threshold (see methods'). The kernels shown are same as those in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>. (<bold>b</bold>) Transition rate in response to light and tap are shown. Animals in the 'Turn' state show no significant change in transition rates in response to light or tap, whereas animals in other states, such as 'Forward 5', do show a response. The 2 s post-stimulus mean transition rate into 'Fast Reverse' is shown in response to a 1 s light stimulation (+), mechanical tap (+) or a mock control (–). A star indicates significance, calculated using an E-test (see 'Materials and methods'). Error bars show the standard error of the mean. 2,487 and 37,000 stimulus-animal presentations were analyzed for light (+) and tap (+) respectively, and 2,427 and 40,012 mock controls(–) for light and tap. The following number of transitions were observed: 1, 2, 11 and 15 for 'Turns'<inline-formula><mml:math id="inf27"><mml:mo>→</mml:mo></mml:math></inline-formula>'Fast Reverse' (top row) and 9, 55, 18 and 160 for 'Forward 5'<inline-formula><mml:math id="inf28"><mml:mo>→</mml:mo></mml:math></inline-formula>'Fast Reverse' (bottom row). P-values for the E-test are 0.68 and 0.34 for 'Turn'<inline-formula><mml:math id="inf29"><mml:mo>→</mml:mo></mml:math></inline-formula>'Fast Reverse' (top row) and 1.96e-9 and 0 for 'Forward 5'<inline-formula><mml:math id="inf30"><mml:mo>→</mml:mo></mml:math></inline-formula>'Fast Reverse'(bottom row).</p><p><supplementary-material id="fig8sdata1"><object-id pub-id-type="doi">10.7554/eLife.36419.032</object-id><label>Figure 8—source data 1.</label><caption><title>P-values for transition rates in response to a light pulse for all pairwise transitions.</title><p>P-values are listed for the multiple hypothesis corrected E-tests performed in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>. Row specifies ‘transition from’ and column specifies ‘transition into’.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-36419-fig8-data1-v2.xlsx"/></supplementary-material></p><p><supplementary-material id="fig8sdata2"><object-id pub-id-type="doi">10.7554/eLife.36419.033</object-id><label>Figure 8—source data 2.</label><caption><title>P-values for transition rates in response to a tap for all pairwise transitions.</title><p>P-values are listed for the multiple hypothesis corrected E-tests performed in <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>. Row specifies ‘transition from’ and column specifies ‘transition into’.</p></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-36419-fig8-data2-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig8-v2"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.030</object-id><label>Figure 8—figure supplement 1.</label><caption><title>Transition rates in response to a light pulse for all pairwise transitions.</title><p>Transition rate is shown for all observed pairwise transitions in response to a 1 s light pulse (+, right bar, 2,487 stimulus-animal presentations) and mock control (–, left bar, 2,427 stimulus-animal presentations). The number of observed transitions <inline-formula><mml:math id="inf31"><mml:mi>n</mml:mi></mml:math></inline-formula> for each bar is listed. No bars are shown for pairwise transitions that were not observed. The red boxes and stars indicate significance, calculated by a multiple hypothesis corrected E-test (see (Materials and methods'). P-values are listed in <xref ref-type="supplementary-material" rid="fig8sdata1">Figure 8—source data 1</xref>. Note that the <inline-formula><mml:math id="inf32"><mml:mi>y</mml:mi></mml:math></inline-formula> axis range is 0 to 2 transitions animal<sup>–1</sup> min<sup>–1</sup> for all cases except for 'Forward 3'<inline-formula><mml:math id="inf33"><mml:mo>→</mml:mo></mml:math></inline-formula>'Fast Reverse', where it is 0 to 6 transitions animal<sup>–1</sup> min<sup>–1</sup>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig8-figsupp1-v2"/></fig><fig id="fig8s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.36419.031</object-id><label>Figure 8—figure supplement 2.</label><caption><title>Transition rates in response to a tap for all pairwise transitions.</title><p>Transition rate is shown for all observed pairwise transitions in response to tap (+, right bar, 37,000 stimulus-animal presentations) and mock control (–, left bar, 40,012 stimulus-animal presentations). The number of observed transitions <inline-formula><mml:math id="inf34"><mml:mi>n</mml:mi></mml:math></inline-formula> for each bar is listed. No bars are shown for pairwise transitions that were not observed. Red boxes and stars indicate significance, calculated by a multiple hypothesis corrected E-test (see 'Materials and methods'). P-values are listed in <xref ref-type="supplementary-material" rid="fig8sdata2">Figure 8—source data 2</xref>. The <inline-formula><mml:math id="inf35"><mml:mi>y</mml:mi></mml:math></inline-formula> axis range is always 0 to 2 transitions animal<sup>–1</sup> min<inline-formula><mml:math id="inf36"><mml:mrow><mml:msup><mml:mrow/><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula><sup>–1</sup>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-36419-fig8-figsupp2-v2"/></fig></fig-group></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>This work provides new insights into <italic>C. elegans</italic> sensory processing. First, we show that the animal’s behavioral response is tuned to the temporal properties of mechanosensory signals, such as the derivative, that extend over many seconds in time. Moreover, by adjusting the waveform of a stimulus, mechanosensory signals in the same neurons can be tailored to elicit different behavioral responses. Second, mechanosensory signals influence a broad set of behaviors. Mechanosensation not only drives reversals and accelerations but can also evoke the animal to slow down. Third, even short timescale behavior states can influence the animal’s sensory processing. Earlier work has reported context-dependent sensory processing for behaviors with timescales of minutes to hours, such as hunger-satiety (<xref ref-type="bibr" rid="bib26">Ghosh et al., 2016</xref>), quiescence (<xref ref-type="bibr" rid="bib54">Raizen et al., 2008</xref>; <xref ref-type="bibr" rid="bib62">Schwarz et al., 2011</xref>; <xref ref-type="bibr" rid="bib46">Nagy et al., 2014b</xref>; <xref ref-type="bibr" rid="bib13">Cho et al., 2018</xref>), arousal (<xref ref-type="bibr" rid="bib11">Cho and Sternberg, 2014</xref>) or Dauer formation (<xref ref-type="bibr" rid="bib8">Chen and Chalfie, 2014</xref><xref ref-type="bibr" rid="bib9">, 2015</xref>). Here, we show that seconds-long timescale behaviors can also profoundly alter how the animal responds to a stimulus. Most dramatically, when the animal turns, it appears to ignore mechanosensory signals completely.</p><p>A high throughput approach was crucial in revealing these new findings. Previously, we had probed the behavior response to mechanosensation using a targeted illumination system that allowed us to probe individual mechanosensory neuron pairs (<xref ref-type="bibr" rid="bib36">Leifer et al., 2011</xref>). That approach, however, is impractical for collecting the thousands of animal-hours of recordings needed here. In this work, we instead activate all mechanosensory neurons simultaneously, which allows us to study many animals in parallel. The set of neurons that is activated is determined by the opsin’s expression pattern. If opsins were expressed only in a single neuron, the current approach would also achieve single-neuron resolution. Although single-cell promoters are not known for any of the soft-touch mechanosensory neurons, intersectional approaches may allow the targeting of subsets (<xref ref-type="bibr" rid="bib69">Wei et al., 2012</xref>; <xref ref-type="bibr" rid="bib60">Schmitt et al., 2012</xref>). Future work is needed to explore the role of individual mechanosensory neurons in temporal processing.</p><p>Automated behavior mapping was also critical for interpretation of the thousands of hours of animal behavior. We chose to classify behavior into discrete states, which are a natural description of discrete behaviors such as turns or reversal events. Alternatively, one could have chosen to use continuous description of behaviors, such as velocity, angular velocity or acceleration, which might be a more natural description of forward locomotion and speeding up or slowing down.</p><p>The linear-nonlinear (LN) model was used to map out the relationship between sensory signals and behavior, and it predicts the animal’s response to stimuli satisfactorily. The LN model was chosen largely because of its ubiquity in neuroscience and simplicity of interpretation. We suspect that other models would yield similar findings. The LN model assumes a particular structure of linear and non-linear processing that is not inherently motivated by the biology, and it fails to take into account longer-timescale effects such as habituation. By contrast, the Gated Recurrent Unit (GRU) neural network model is one example of a model that is entirely non-linear and known to handle multi-timescale dependencies (<xref ref-type="bibr" rid="bib12">Cho et al., 2014</xref>). GRUs are just one of many alternative models with varying degrees of complexity and interpretability that could be used to probe temporal processing (<xref ref-type="bibr" rid="bib27">Glaser et al., 2017</xref>).</p><p>In more complex sensory systems such as the retina, we have come to expect that the nervous system is carefully tuned to the temporal properties of sensory signals (<xref ref-type="bibr" rid="bib43">Meister and Berry, 1999</xref>). Recently, it was shown that in drosophila, temporal processing is important for behavioral responses to odor, light and sound (<xref ref-type="bibr" rid="bib2">Behnia et al., 2014</xref>; <xref ref-type="bibr" rid="bib17">Coen et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Gepner et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Hernandez-Nunez et al., 2015</xref>). And in the much simpler <italic>C. elegans</italic>, temporal processing within timescales in the order of seconds has been observed in thermosensation (<xref ref-type="bibr" rid="bib14">Clark et al., 2006</xref><xref ref-type="bibr" rid="bib15">, 2007</xref>), as well as in chemosensation (<xref ref-type="bibr" rid="bib31">Kato et al., 2014</xref>) where it is known to be crucial for guiding thermotaxis or chemotaxis. In the <italic>C. elegans</italic> mechanosensory circuit, it had been shown previously that temporal processing occurs at the receptor level in order to convert applied forces into evoked currents, with a timescale of tens of milliseconds (<xref ref-type="bibr" rid="bib22">Eastwood et al., 2015</xref>), but it had remained unclear whether the nervous system used temporal information downstream to detemine the animal’s behavioral response. In this work, we now see evidence of temporal processing on seconds-long behavior-relevant timescales that guides the animal’s behavioral response. This temporal processing may arise from recurrent activity in the neural network downstream of the touch receptor neurons. The observation of such behavior-relevant temporal processing even in the simple mechanosensory circuit raises the possibility that temporal processing may be ubiquitous across sensory systems for driving behavior.</p><p>Why might it be beneficial for the <italic>C. elegans</italic> nervous system to have evolved to tune its behavioral response to the temporal properties of mechanosensory signals, such as the derivative, over seconds? The natural ecology of <italic>C. elegans</italic> is not well understood (<xref ref-type="bibr" rid="bib24">Félix and Braendle, 2010</xref>) and the statistics of the forces that it encounters in its natural environment are not known. We speculate that it could be useful for the worm to react differently if mechanosensory signals are increasing or decreasing, instead of making decisions solely on the overall stimulus strength. Note that we have characterized temporal processing to optogenetic signals, thus bypassing the animal’s mechanoelectro transduction machinery. Further work is needed to characterize the temporal processing of applied forces directly.</p><p>It is is striking and surprising that the animal ignores mechanosensory inputs during turning. Why might the animal have evolved to ignore such signals during turns? The turn is part of the <italic>C. elegans</italic> escape response, an avoidance behavior that shares some similarities with escape responses in other organisms, such as crayfish, mollusks or goldfish (<xref ref-type="bibr" rid="bib52">Pirri and Alkema, 2012</xref>). <italic>Caenorhabditis elegans</italic> escape consists of reverse locomotion, followed by a turn and then forward locomotion in a new direction. The turn allows the animal to reorient and navigate away from a predator, and defects in this circuit have been shown to decrease survivability (<xref ref-type="bibr" rid="bib40">Maguire et al., 2011</xref>). Failing to complete the turn could inadvertently cause the animal to retrace its steps and return to danger.</p><p>Ultimately, we see evidence of two kinds of internal processes that govern how the animal interprets sensory signals. First, the animal integrates mechanosensory information over a timescale of seconds. Second, the animal interprets these signals differently depending on the animal’s behavior state. An exciting future direction will be to identify the neural circuit mechanisms that allow the worm’s nervous system to integrate mechanosensory signals over time; and to alter its response rapidly depending on behavior state. This could shed insight into how internal brain states rapidly modulate sensory processing in a simple model system.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Strains</title><p>The two strains used in this study were wild-type N2 Bristol animals (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/WB-STRAIN:N2_">WB-STRAIN:N2_</ext-link>(ancestral)) and AML67 (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/WB-STRAIN:AML67">WB-STRAIN:AML67</ext-link>) (wtfIs46[p<italic>mec-4::Chrimson::SL2::mCherry</italic>::<italic>unc-54</italic>]), a transgenic strain that expresses the light-gated ion channel Chrimson and a fluorescent protein mCherry in mechanosensory neurons. To generate AML67, 40 ng of plasmid (pAL::p<italic>mec-4::Chrimson::SL2::mCherry::unc-54</italic>) were injected into N2 animals and integrated via UV irradiation (<xref ref-type="bibr" rid="bib23">Evans, 2006</xref>). These animals were outcrossed with N2 six times. AML67 has been deposited in the public Caenorhabditis Gentics Center repository at the University of Minnesota. Plasmid pAL::p<italic>mec-4::Chrimson::SL2::mCherry::unc-54</italic> (<ext-link ext-link-type="uri" xlink:href="https://www.addgene.org/107745/https">https://www.addgene.org/107745/</ext-link>) was engineered using a HiFi Cloning Kit (NEB). Chrimson was a kind gift from Ed Boyden of MIT. mCherry and backbone was amplified from pJIM20, a gift from John Murray of the University of Pennsylvania. The promoter sequence (mec-4), splicing sequence (SL2) and 3<inline-formula><mml:math id="inf37"><mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>-utr sequence (<italic>unc-54</italic>) were amplified using primers as listed in <xref ref-type="table" rid="table1">Table 1</xref>. The construct was sequenced confirmed before injection.</p><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.034</object-id><label>Table 1.</label><caption><title>Forward and reverse primer sequences used to generate pAL::p<italic>mec-4::Chrimson::SL2::mCherry::unc-54</italic>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Primer</th><th valign="top">Sequence</th></tr></thead><tbody><tr><td valign="top">mec-4_fwd</td><td valign="top">AAGCTTCAATACAAGCTC</td></tr><tr><td valign="top">mec-4_rev</td><td valign="top">TAACTTGATAGCGATAAAAAAAATAG</td></tr><tr><td valign="top">CHRIMSON_fwd</td><td valign="top">ATGGCTGAGCTTATTTCATC</td></tr><tr><td valign="top">CHRIMSON_rev</td><td valign="top">AACAGTATCTTCATCTTCC</td></tr><tr><td valign="top">SL2_fwd</td><td valign="top">GGTACCGCTGTCTCATCC</td></tr><tr><td valign="top">SL2_rev</td><td valign="top">GATGCGTTGAAGCAGTTTC</td></tr><tr><td valign="top">mCherry_fwd</td><td valign="top">ATGGTCTCAAAGGGTGAAG</td></tr><tr><td valign="top">mCherry_rev</td><td valign="top">TTATACAATTCATCCATGCC</td></tr><tr><td valign="top">U54_fwd</td><td valign="top">GCGCCGGTCGCTACCATTAC</td></tr><tr><td valign="top">U54_rev</td><td valign="top">AAGGGCCCGTACGGCCGA</td></tr></tbody></table></table-wrap><p>Transgenic animals exhibited reduced sensitivity to a tap or touch compared to wild-type animals, presumably because Chrimson competes with endogenous MEC-4 protein for transcription (see <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). From the alleles we had generated, we selected AML67 for use in this study because it was the most sensitive to tap and touch, despite being reduced compared to wild-type.</p></sec><sec id="s4-2"><title>Nematode handling</title><p>Strains were maintained on 9 cm NGM agar plates seeded with OP50 <italic>Escherichia coli</italic> food at 20° C . Worms were bleached 3 days prior to the experiment to provide 1-day-old adults. For optogenetic experiments, bleached worms were placed on plates seeded with 1 ml of 0.5 mM all-trans-retinal (ATR) mixed with OP50. Control plate lacked ATR. To avoid inadvertent optogenetic activation, plates were wrapped in aluminum foil, handled in the dark, and viewed under dissection microscopes using dim blue light.</p><p>To harvest worms for high-throughput experiments, roughly 100 to 200 worms were cut from agar, washed and then spun-down in a 1.5 ml micro centrifuge tube. Worms at the bottom of the tube were placed on an unseeded 9 cm NGM agar plate via a micropipette. Excess liquid on the plate was carefully wicked away using tissue paper. Worms were allowed to adapt to their new environment for 25 min before recordings or stimulation were carried out.</p></sec><sec id="s4-3"><title>High-throughput imaging</title><p>Experiments were conducted in a custom-built high-throughput imaging rig (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Plates of animals were recorded while undergoing 30 min of optogenetic or tap stimulation. Imaging was performed as follows: the agar plate was illuminated by a ring of 850 nm infrared LEDs (irrf850-5050-60-reel, environmentallights.com). A 2592 × 1944 pixel CMOS camera (ACA2500-14um, Basler) recorded worm movements at 14 frames per second and a magnification of 20 μm per pixel, so as to provide sufficient spatiotemporal resolution to capture posture dynamics. The field of view of the camera was centered on the plate and included approximately 50% of the plate surface. Custom LabVIEW software acquired images from the camera and controlled stimulus delivery as described below.</p></sec><sec id="s4-4"><title>Tap delivery</title><p>Taps were delivered to the side of 9 cm plates containing the animals by means of a solenoid, following a method similar to that described by <xref ref-type="bibr" rid="bib67">Swierczek et al. (2011</xref>). An electric solenoid tapper (Small Push-Pull Solenoid, Adafruit) was driven with a 70 ms, 24 V, DC pulse under Labview control via a LabJack DAQ and a solid-state relay. During tap experiments, taps were delivered to the plate once per minute for 30 min (see <xref ref-type="table" rid="table2">Table 2</xref>). The 1 min inter-stimulus interval was chosen to minimize habituation (<xref ref-type="bibr" rid="bib68">Timbers et al., 2013</xref>).</p><table-wrap id="table2" position="float"><object-id pub-id-type="doi">10.7554/eLife.36419.035</object-id><label>Table 2.</label><caption><title>Summary of experimental conditions.</title><p>Each experimental series consisted of recordings of multiple plates usually spread across multiple days, as indicated. Recordings were all 30 mins in duration for each plate. Note that two methods were used to tally the number of stimulus-animal presentations (see 'Materials and methods'). Here, a stimulus presentation is counted even if the track was interrupted mid-presentation.</p></caption><table frame="hsides" rules="groups"><thead><tr valign="top"><th>Experiment <break/>series</th><th>Strain</th><th>Stim</th><th>ATR</th><th>Number of <break/>plates</th><th>Number <break/>of <break/>days</th><th>Interstimulus <break/>interval <break/>(s)</th><th>Stimulus <break/>duration <break/>(s)</th><th>Total <break/>animal- <break/>stimulus <break/>presentations</th><th>Cumulative <break/>Recording <break/>Length <break/>(animal-hours)</th><th>Animals <break/>per frame <break/>(Mean ± <break/>Stdev)</th><th>Figures</th></tr></thead><tbody><tr valign="top"><td rowspan="2">Random noise</td><td rowspan="2">AML67</td><td rowspan="2">Light</td><td>+</td><td>58</td><td>3</td><td>n/a</td><td>n/a</td><td>n/a</td><td>1,784</td><td>62 ± 34</td><td><xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>, <xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref>, <xref ref-type="video" rid="fig1video2">Figure 1—video 2</xref>, <xref ref-type="video" rid="fig1video3">Figure 1—video 3</xref>, <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>, <xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, <xref ref-type="fig" rid="fig8">Figure 8</xref></td></tr><tr valign="top"><td>−</td><td>20</td><td>3</td><td>n/a</td><td>n/a</td><td>n/a</td><td>500</td><td>50 ± 23</td><td><xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>, <xref ref-type="video" rid="fig1video2">Figure 1—video 2</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>, <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref></td></tr><tr valign="top"><td rowspan="2">Triangle <break/>wave</td><td rowspan="2">AML67</td><td rowspan="2">Light</td><td>+</td><td>62</td><td>3</td><td>0</td><td>20</td><td>340,757</td><td>1,912</td><td>62 ± 42</td><td><xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig7">Figure 7</xref></td></tr><tr valign="top"><td>−</td><td>20</td><td>3</td><td>0</td><td>20</td><td>142,461</td><td>800</td><td>80 ± 55</td><td><xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref></td></tr><tr valign="top"><td rowspan="2">Kernel- <break/>shaped <break/>Stimuli</td><td rowspan="2">AML67</td><td rowspan="2">Light</td><td>+</td><td>44</td><td>3</td><td>40</td><td>20</td><td>84,875</td><td>1,453</td><td>66 ± 40</td><td><xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig7">Figure 7</xref></td></tr><tr valign="top"><td>−</td><td>12</td><td>3</td><td>40</td><td>20</td><td>22,866</td><td>392</td><td>65 ± 33</td><td><xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 1</xref></td></tr><tr valign="top"><td rowspan="2">Light pulse</td><td rowspan="2">AML67</td><td rowspan="2">Light</td><td>+</td><td>12</td><td>1</td><td>59</td><td>1</td><td>15,128</td><td>260</td><td>43 ± 24</td><td><xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig8">Figure 8</xref></td></tr><tr valign="top"><td>−</td><td>6</td><td>1</td><td>59</td><td>1</td><td>8107</td><td>139</td><td>46 ± 18</td><td><xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref></td></tr><tr valign="top"><td rowspan="3">Plate tap</td><td rowspan="2">AML67</td><td rowspan="2">Tap</td><td>+</td><td>7</td><td>2</td><td>60</td><td>Impulse</td><td>21,117</td><td>366</td><td>105 ± 60</td><td rowspan="2"><xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref></td></tr><tr valign="top"><td>−</td><td>8</td><td>2</td><td>60</td><td>Impulse</td><td>14,646</td><td>254</td><td>64 ± 46</td></tr><tr valign="top"><td>N2</td><td>Tap</td><td>−</td><td>22</td><td>3</td><td>60</td><td>Impulse</td><td>40,409</td><td>695</td><td>63 ± 25</td><td><xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig8">Figure 8</xref>, <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref></td></tr><tr valign="top"><td>Total</td><td/><td/><td/><td>271</td><td/><td/><td/><td/><td>8,554</td><td>63 ± 40</td><td/></tr></tbody></table></table-wrap></sec><sec id="s4-5"><title>Optogenetic stimulation</title><p>Experiments involving optogenetic stimulation are summarized in <xref ref-type="table" rid="table2">Table 2</xref>. Optogenetic stimulation was delivered by three 625 nm LEDs (M625L3, Thorlabs) positioned such that their light approximately tiles the agar plate visible in the camera’s field of view. LED’s were driven by a diode driver (L2C210C, Thorlabs) under the control of LabVIEW via an analog signal from a LabJack DAQ (Model U3-HV with LJTick-DAC). The range of the light intensity for optogenetic stimulation averaged at the plate spanned from 0 to 80 μW mm<sup>–2</sup>. Small spatial inhomogeneities in light intensity were characterized and accounted for in software so as to calculate the precise light intensity delivered to each animal. An infared long pass filter (FEL0800, Thorlabs) in front of the camera blocked light from the stimulus LEDs and only permitted light from the infrared behavior LEDs.</p><sec id="s4-5-1"><title>Optogenetic pulse stimulus</title><p>For optogenetic pulse experiments, as in <xref ref-type="fig" rid="fig2">Figure 2</xref>, a 1 s light pulse was delivered once per minute for 30 min. Initial experiments measured the behavioral responses to pulses of different light intensities. In those experiments, shown in <xref ref-type="fig" rid="fig2">Figure 2c</xref>, the light intensity of the pulse was randomly shuffled such that five pulses each of 2, 5, 10, 50, and 80 μW mm<sup>–2</sup> were delivered during the 30 min recording.</p></sec><sec id="s4-5-2"><title>Random noise optogenetic stimulus</title><p>Experiments involving reverse correlation all used a light stimulus with intensity modulated by random broad-spectrum noise. The random noise stimulus was generated according to,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>rand</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>A</mml:mi><mml:mo>≡</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>period</mml:mtext></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf39"><mml:mrow><mml:mi>B</mml:mi><mml:mo>≡</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>rms</mml:mtext></mml:mrow></mml:msub><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>. Here <inline-formula><mml:math id="inf40"><mml:mrow><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> is the stimulus intensity at the next time-point, <inline-formula><mml:math id="inf41"><mml:mi>A</mml:mi></mml:math></inline-formula> is the weighting of the previous stimulus <inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf43"><mml:mi>B</mml:mi></mml:math></inline-formula> is the weighting of a random number, <inline-formula><mml:math id="inf44"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>rand</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, drawn from a Gaussian distribution with standard deviation given by <inline-formula><mml:math id="inf45"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>rms</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf46"><mml:mi>C</mml:mi></mml:math></inline-formula> is a constant offset that sets the average stimulus intensity. The weighting <inline-formula><mml:math id="inf47"><mml:mi>A</mml:mi></mml:math></inline-formula> is related to correlation time <inline-formula><mml:math id="inf48"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the duration of our time step <inline-formula><mml:math id="inf49"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>period</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Because in our setup the stimulus is updated with each image acquisition, the time step <inline-formula><mml:math id="inf50"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>period</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the inverse of the image acquisition rate, or approximately 0.07 s for 14 Hz.</p><p>Both <inline-formula><mml:math id="inf51"><mml:mi>C</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf52"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mtext>rms</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> were chosen to be 25 μW mm<sup>–2</sup> so that the function generated intensities that mostly fell in the intensity range of 0–50 μW mm<sup>–2</sup>, a regime that appeared to be most sensitive to behavior response (see <xref ref-type="fig" rid="fig2">Figure 2c</xref>). <inline-formula><mml:math id="inf53"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> was chosen to be 0.5 s as this roughly matched our intuition about the timescale of temporally varying mechanical stimuli that the animal might encounter while navigating its natural environment. Finally, the stimulus was clipped and forced to stay in the range of 0–50 μW mm<sup>–2</sup>. Frequency spectra of our stimuli are shown in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>.</p></sec><sec id="s4-5-3"><title>Triangle wave optogenetic stimulus</title><p>Triangle wave stimuli were also generated. Triangle waves were linearly increasing ramps of light intensity from 0 μW mm<sup>–2</sup> to 50 μW mm<sup>–2</sup> for 10 s followed by linearly decreasing ramps of 50 μW mm<sup>–2</sup> to 0 μW mm<sup>–2</sup> for 10 s, repeated continuously for 30 min.</p></sec><sec id="s4-5-4"><title>Kernel-shaped (tailored) stimulus</title><p>In the tailored stimulation experiments, stimuli were generated from the behavior-triggered averages found using reverse correlation. The six behavior-triggered averages from <xref ref-type="fig" rid="fig3">Figure 3</xref> were scaled in intensity until either their minimum was at 0 μW mm<sup>–2</sup> or the maximum was at 50 μW mm<sup>–2</sup>. These were then shuffled and played back one per minute such that each behavior-triggered average was delivered 5 times per 30 min experiment. 25 μW mm<sup>–2</sup> of constant light intensity was delivered between stimulus presentation.</p></sec></sec><sec id="s4-6"><title>Measuring animal behavior</title><p>The unsupervised behavior mapping approach used in this work is adapted from work in drosophila (<xref ref-type="bibr" rid="bib3">Berman et al., 2014</xref>) and is similar in spirit to work in rodents (<xref ref-type="bibr" rid="bib71">Wiltschko et al., 2015</xref>). It also builds upon decades of methodological advances quantifying <italic>C. elegans</italic> behavior (<xref ref-type="bibr" rid="bib18">Croll, 1975</xref>; <xref ref-type="bibr" rid="bib63">Stephens et al., 2008</xref>; <xref ref-type="bibr" rid="bib55">Ramot et al., 2008</xref>; <xref ref-type="bibr" rid="bib4">Brown et al., 2013</xref>; <xref ref-type="bibr" rid="bib72">Yemini et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Gyenes and Brown, 2016</xref>; <xref ref-type="bibr" rid="bib28">Gomez-Marin et al., 2016</xref>).</p><p>Animal behavior was measured and classified using an analysis pipeline, summarized in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. First, the worms were located and tracked, then their posture was extracted, and finally their posture dynamics were clustered and classified. Details of the pipeline are described below. The pipeline was written in MATLAB and run on the Princeton University’s high-performance parallel computing cluster. Source code is available at (<ext-link ext-link-type="uri" xlink:href="https://github.com/leiferlab/liu-temporal-processing">https://github.com/leiferlab/liu-temporal-processing</ext-link>) (Liu and Leifer, 2018; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/liu-temporal-processing">https://github.com/elifesciences-publications/liu-temporal-processing</ext-link>).</p><sec id="s4-6-1"><title>Animal location tracking</title><p>To first identify animals and to track their location, raw video of animals on plates was analyzed using a modified version of the Parallel Worm Tracker (<xref ref-type="bibr" rid="bib55">Ramot et al., 2008</xref>). Animal’s were found via binary thresholding and centroid tracking (<xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref>).</p></sec><sec id="s4-6-2"><title>Animal posture extraction</title><p>The animal’s posture was found by extracting the animal’s centerline from the video using custom MATLAB scripts. Videos of each individual worm were first generated by cropping a 70 × 70 pixel region around the worm’s centroid in every frame. A centerline with 20 points was fitted to the image at each frame using an active contour model similar to that used by <xref ref-type="bibr" rid="bib49">Nguyen et al., 2017</xref>), which was inspired by the one described by <xref ref-type="bibr" rid="bib20">Deng et al. (2013</xref>). The algorithm for fitting the centerline was specifically optimized to measure the posture of the worm in a variety of conditions, including when the animal crossed over itself during turns. The active contour model fits the centerline by relaxing contiguous points along a gradient defined by four forces: (1) an image force that fits the contour to the image of the worm; (2) a tip force that guides the beginning and end of the contour to the worm’s presumptive head and tail; (3) a spring force that guides the contour to be similar lengths; (4) and a repel force that makes sure that the contour does not stick to itself. To ensure continuity in time, the active contour of the following frame is initialized by the relaxed contour of the previous frame. The head and the tail of the worm were determined by assuming that the worm moves forward the majority of the time. A quality score was calculated to estimate how well the centerline fit the image and how much it displaced from the previous centerline. On the rare occasion when the quality score of a frame fell below threshold, that frame was dropped, and the track was split into two.</p></sec><sec id="s4-6-3"><title>Posture dimensionality reduction</title><p>To interpret the animal’s posture more efficiently, the dimensionality of the animal’s centerline was reduced from 20 position <inline-formula><mml:math id="inf54"><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> coordinates to five posture coefficients using principle component analysis (PCA), following the method of <xref ref-type="bibr" rid="bib63">Stephens et al. (2008</xref>). Principle components of posture were extracted from recordings of approximately 2 million animal-frames of freely behaving N2 worms. Centerlines were converted into a series of angles oriented such that the mean angle is 0. The first five principle components explain &gt;98% of the posture variance. The animal’s posture dynamics were thus represented as a time-series of five coefficients, one for each of the five principle posture modes.</p></sec><sec id="s4-6-4"><title>Generating spectrograms of posture dynamics</title><p>To characterize posture dynamics, a spectrogram was generated for each of the posture mode coefficients (as in <xref ref-type="bibr" rid="bib3">Berman et al. [2014</xref>]). A Morlet continuous wavelet transform was performed on each of the five coefficient time series at 25 frequencies dyadically spaced between 0.3 Hz and 7 Hz. The low-frequency bound was chosen to reflect our intuition regarding the timescale of <italic>C. elegans</italic> behavior and the high-frequency bound was set by the Nyquist sampling frequency of our image acquisition. The spectrogram provides information about the frequency spectra of the animal’s posture dynamics but it lacks information about the phase of the animal’s posture, which is important for discerning forward from backward locomotion. To preserve forward and backward information, we introduced a binary ‘directionality’ vector that is 2 when the worm centroid is moving forward, and 1 when the worm centroid is backwards. Directionality was calculated by taking the sign of the dot product of the head vector with a tangent vector of the animal’s centroid trajectory. Together, the five spectrograms and directionality vector provide a 126 dimensional feature vector that describe the animal’s behavior at each time point. It is this feature vector that is clustered, as described below.</p></sec><sec id="s4-6-5"><title>Defining the behavioral map and behavior states</title><p>To classify behavior into discrete stereotyped behavior states that emerge naturally from our recordings, we followed a behavior-mapping strategy described in <xref ref-type="bibr" rid="bib3">Berman et al. (2014</xref>). A single behavior map was generated so that behaviors were defined consistently across all experiments. To generate the behavior map, 50,000 animal-time points were uniformly sampled from the 2,284 animal-hours of behavior recordings made during random-noise optogenetic stimulation. Each animal-time point contributes a 126-dimensional feature vector describing the animal’s instantaneous behavior. We generated a two-dimensional map of these feature vectors by embedding the 126-dimensional space in a plane using a non-linear dimensionality reduction technique called t-distributed stochastic neighbor embedding (t-SNE) (<xref ref-type="bibr" rid="bib39">Lvd and Hinton, 2008</xref>). Under t-SNE, each feature vector is embedded such that the local distance between feature vectors is conserved but long distance scales are distorted (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2a</xref>).</p><p>We then generated a probability density histogram of behavior by projecting all 10<sup>8 </sup>behavior time points from the 2,284 animal-hours of random noise optogenetic stimulation (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2b</xref>) into the 2D map. Clusters of high probability in this density map corresponded to a distinct stereotyped behavior. Stereotype behaviors were defined by water-shedding the probability density map (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2c</xref>) and each region was assigned a name such as ‘Forward 3’ (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Videos showing examples of worms exhibiting behaviors in each region are shown in <xref ref-type="video" rid="fig1video2">Figure 1—video 2</xref>. Time points from subsequent recordings were similarly projected into this map for the purposes of classifying animal behavior.</p></sec><sec id="s4-6-6"><title>Identifying behavioral transitions</title><p>At each time point, the worm belongs to a point in the 2D behavior map described above (see <xref ref-type="video" rid="fig1video3">Figure 1—video 3</xref>). Animals that dwelled in one behavior region for at least 0.5 s were classified as exhibiting that behavior during all contiguous time points in that behavior region. Animal’s inhabiting a behavior region for less than 0.5 s were classified as ‘in transition’.</p><p>A transition into behavior <inline-formula><mml:math id="inf55"><mml:mi>X</mml:mi></mml:math></inline-formula> is defined to occur on the first time point that the animal is classified as in <inline-formula><mml:math id="inf56"><mml:mi>X</mml:mi></mml:math></inline-formula>. Transitions from behavior <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>W</mml:mi><mml:mo>→</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula> were defined to occur on the first time point the animal is classified as in <inline-formula><mml:math id="inf58"><mml:mi>X</mml:mi></mml:math></inline-formula> provided that: (i) the animal transitioned directly from <inline-formula><mml:math id="inf59"><mml:mi>W</mml:mi></mml:math></inline-formula> to <inline-formula><mml:math id="inf60"><mml:mi>X</mml:mi></mml:math></inline-formula>; or (ii) the animal had previously been classified as in <inline-formula><mml:math id="inf61"><mml:mi>W</mml:mi></mml:math></inline-formula>, was then classified as ‘in transition’, and then was classified as in state <inline-formula><mml:math id="inf62"><mml:mi>X</mml:mi></mml:math></inline-formula>. Cases where the animal was in <inline-formula><mml:math id="inf63"><mml:mi>X</mml:mi></mml:math></inline-formula>, then ‘in transition’ and then returned to <inline-formula><mml:math id="inf64"><mml:mi>X</mml:mi></mml:math></inline-formula>, were ignored.</p></sec><sec id="s4-6-7"><title>Ambiguities in temporal definition of behavior</title><p>The wavelet spectrogram introduces an inherent uncertainty in the precise timing of a behavior transition. This ultimately arises from the uncertainty principle: behavior dynamics that have low-frequency components provide less temporal resolution than higher-frequency dynamics. An equivalent view is that the spectrogram feature vector at any given moment is influenced by temporally adjacent postural dynamics in the past and future, and this influence is stronger at lower frequencies than at higher ones.</p><p>This temporal uncertainty or ‘bleeding over’ of future behavior, causes the animal occasionally to appear to respond (but not actually respond) to a stimulus prior to its delivery. In the worst case, the time-scale of this leakage is set by our choice of the lowest frequency wavelet, which is 0.3 Hz (i.e. 2.7 s). Behaviors with strong higher-frequency components have shorter timescale uncertainties. We take large time windows of 20 s to define our kernels; in part, so that a few second time-shift does not result in any loss of information.</p></sec></sec><sec id="s4-7"><title>Reverse correlation</title><p>Reverse correlation was used to find a linear kernel and non-linearity that describe the relationship between the animal’s behavior transitions and an applied stimulus.</p><sec id="s4-7-1"><title>Calculating kernels</title><p>Linear kernels for each behavior were estimated by computing the behavior-triggered average of the stimulus,<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the time of <italic>n</italic>th behavioral transition, <inline-formula><mml:math id="inf66"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> is a vector representing the stimuli presented during a 20 s temporal window around <inline-formula><mml:math id="inf67"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf68"><mml:mi>N</mml:mi></mml:math></inline-formula> is the total number of behavioral transitions (<xref ref-type="bibr" rid="bib61">Schwartz et al., 2006</xref>). The linear kernel was estimated to be the mean-subtracted, time-reversed behavior-triggered average.</p></sec><sec id="s4-7-2"><title>Kernel significance</title><p>Behavior-triggered averages (also referred to as kernels) were deemed significant if their magnitude (L2 norm) exceeded the top 1 percent of a distribution of random kernels found by shuffling the stimulus in time. Shuffling was performed in such a way as to preserve the temporal properties of the transition train while completely decorrelating it from the stimulus. Specifically, shuffling was performed by circle-shifting the transition timings within every track by a randomly selected integer between one and the number of time points in the track. Shuffled kernel distributions for each behavior were generated by recalculating the behavior-triggered average 100 times, each with different circle-shifted timings.</p></sec><sec id="s4-7-3"><title>Estimating the non-linearity</title><p>The non-linearity <inline-formula><mml:math id="inf69"><mml:mi>f</mml:mi></mml:math></inline-formula> allows the probability of a behavior transition to be estimated from the filtered signal, namely the stimulus convolved with the linear kernel (<xref ref-type="bibr" rid="bib25">Gepner et al., 2015</xref>). Non-linearities were estimated from the ratio of two histograms: the first is a histogram of time-point counts versus filtered signal given a behavioral transition at that time-point, and the second is a histogram of time-point counts versus filtered signal for all time-points (<xref ref-type="bibr" rid="bib61">Schwartz et al., 2006</xref>). Histograms were tabulated with 10 equally spaced bins spanning the range of the filtered signal. Bin-wise division of the two histograms yielded 10 points relating probability of behavior to filtered signals (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). For each point, we calculate a propagated error, <inline-formula><mml:math id="inf70"><mml:mi>E</mml:mi></mml:math></inline-formula>, assuming Poisson counting statistics,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>(</mml:mo><mml:mi>F</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mn>4</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p> where <inline-formula><mml:math id="inf71"><mml:mi>T</mml:mi></mml:math></inline-formula> is the number of behavioral transitions in that bin, and <inline-formula><mml:math id="inf72"><mml:mi>F</mml:mi></mml:math></inline-formula> is the number of filtered signal time-points in that bin. We then fitted a two parameter exponential to the 10 points, weighing each point by the inverse of the error in order to reduce the influence of noise. This fitted exponential function is our estimate of the non-linearity.</p></sec></sec><sec id="s4-8"><title>Calculating transition rates</title><p>When presented as a timeseries of rates, as in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, transition rates were calculated according to the following: behavior timeseries from all recordings were cropped in a time window around each stimulus, commingled, and then time aligned to the stimulus. The fraction of all animals undergoing a transition was calculated at each time step. The fractions of animal were directly converted into a rate of transitions per animal per minute, yielding the timeseries of rates.</p><sec id="s4-8-1"><title>Calculating transition rate changes</title><p>Transition rate change, as in <xref ref-type="fig" rid="fig4">Figure 4b</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig5">Figure 5</xref>, and <xref ref-type="fig" rid="fig7">Figure 7</xref>, were calculated as follows: an average transition rate was found in a time window during a stimulus (as described above), and then a baseline was subtracted off. For kernel-shaped stimuli experiments (<xref ref-type="fig" rid="fig4">Figure 4a</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), the baseline is defined as the average transition rate in a 20 s time window prior to each stimulus. For the triangle wave in <xref ref-type="fig" rid="fig5">Figure 5</xref>, the baseline was defined to be the overall mean transition rate throughout the recording.</p><p>In cases where a bar is shown (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, <xref ref-type="fig" rid="fig7">Figure 7</xref>), a change in transition rate was calculated by averaging the timeseries of rates over a time window (indicated in the those figures by gray shading).</p></sec><sec id="s4-8-2"><title>Measuring transition rates for context-dependent tap or light-induced experiments</title><p>Transition rates were calculated slightly differently in <xref ref-type="fig" rid="fig8">Figure 8</xref> and <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplements 1</xref> and <xref ref-type="fig" rid="fig8s2">2</xref> to facilitate significance testing via the E-test (<xref ref-type="bibr" rid="bib34">Krishnamoorthy and Thomson, 2004</xref>). The transition rate in a 2 s time window immediately following light pulse or tap (+) was compared to a transition rate in a 2 s window immediately following a mock control (–). Mock controls were set to occur at the mid point between consecutive stimuli.</p><p>Instead of calculating the transition rates at each time bin and then averaging across time, as described previously, we instead calculated a single transition rate for the entire 2 s time window by comingling transitions from all time bins, as follows. We 1) selected tracks that were uninterrupted for the 2 s, (2) counted the first transition (if it occurred) within 2 s after stimulus onset across all of our experiments, (3) divided by the total number of tracked time points, and (4) converted the value to transitions per animal per minute. The number of stimulus-animal presentations differs slightly from those in <xref ref-type="fig" rid="fig2">Figure 2</xref> because now tracks are required to be contiguous for 2 s after stimulus presentation, which was not a requirement previously.</p><p>P-values were attained using an E-test (<xref ref-type="bibr" rid="bib34">Krishnamoorthy and Thomson, 2004</xref>). To account for testing 72 behavior transitions concurrently, we use the Bonferroni multiple-hypothesis correction. Only p-values less than <inline-formula><mml:math id="inf73"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn><mml:mo>/</mml:mo><mml:mn>72</mml:mn><mml:mo>=</mml:mo><mml:mn>7</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are considered significant.</p><p>In our analysis of light-pulse response, we grouped all stimulation light intensities together.</p></sec></sec><sec id="s4-9"><title>Data</title><p>Behavioral analysis and stimulation data for all tracked animals in all experiments in <xref ref-type="table" rid="table2">Table 2</xref> are available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5956348.">https://doi.org/10.6084/m9.figshare.5956348.</ext-link> See dataset README for details. All recorded data, including raw images (2 TB), will be available at <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.21227/H27944.">http://dx.doi.org/10.21227/H27944.</ext-link></p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Marc Gershow (NYU) and Gordon Berman (Emory) for productive discussions and troubleshooting. We also thank Mala Murthy and Jonathan Pillow, both of Princeton University, for productive discussions and feedback. Alicia Castillo Bahena and Tayla Duarte contributed to preliminary studies of this work. This work was supported by grants from the Simons Foundation (SCGB #324285 and SCGB #543003, to AML). This work was also supported by Princeton University’s Dean for Research Innovation Fund (to AML and JWS). Research reported in this publication was supported by the National Human Genome Research Institute of the National Institutes of Health under Award Number T32HG003284. Some strains were provided by the CGC, which is funded by NIH Office of Research Infrastructure Programs (P40 OD010440). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Investigation, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Resources, Methodology, Writing—review and editing, Performed all transgenics</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Writing—original draft, Project administration, Writing—review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.36419.036</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-36419-transrepform-v2.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Stimulus and behavior data have been made publicly available on Figshare <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5956348">https://doi.org/10.6084/m9.figshare.5956348</ext-link>. Raw imaging data (2TB) have been made publicly available on IEEE DataPorts <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.21227/H27944">http://dx.doi.org/10.21227/H27944</ext-link>.</p><p>The following datasets were generated:</p><p><related-object content-type="generated-dataset" id="dataset1" source-id="https://doi.org/10.21227/H27944" source-id-type="uri"><collab collab-type="author">Liu M</collab><collab collab-type="author">Sharma AK</collab><collab collab-type="author">Shaevitz JW</collab><collab collab-type="author">Leifer AM</collab><year>2018</year><source>Temporal processing and context dependency in C. elegans mechanosensation dataset</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.21227/H27944">https://doi.org/10.21227/H27944</ext-link><comment>Publicly available on IEEE DataPorts (DOI: 10.21227/H27944)</comment></related-object></p><p><related-object content-type="generated-dataset" id="dataset2" source-id="https://doi.org/10.6084/m9.figshare.5956348" source-id-type="uri"><collab collab-type="author">Liu M</collab><collab collab-type="author">Sharma AK</collab><collab collab-type="author">Shaevitz JW</collab><collab collab-type="author">Leifer AM</collab><year>2018</year><source>Temporal processing and context dependency in C. elegans mechanosensation stimulus and behavior dataset</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.5956348">https://doi.org/10.6084/m9.figshare.5956348</ext-link><comment>Available at figshare under a CC0 Public Domain licence (https://figshare.com/)</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ardiel</surname> <given-names>EL</given-names></name><name><surname>Yu</surname> <given-names>AJ</given-names></name><name><surname>Giles</surname> <given-names>AC</given-names></name><name><surname>Rankin</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Habituation as an adaptive shift in response strategy mediated by neuropeptides</article-title><source>Npj Science of Learning</source><volume>2</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1038/s41539-017-0011-8</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behnia</surname> <given-names>R</given-names></name><name><surname>Clark</surname> <given-names>DA</given-names></name><name><surname>Carter</surname> <given-names>AG</given-names></name><name><surname>Clandinin</surname> <given-names>TR</given-names></name><name><surname>Desplan</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Processing properties of ON and OFF pathways for <italic>Drosophila</italic> motion detection</article-title><source>Nature</source><volume>512</volume><fpage>427</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1038/nature13427</pub-id><pub-id pub-id-type="pmid">25043016</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname> <given-names>GJ</given-names></name><name><surname>Choi</surname> <given-names>DM</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mapping the stereotyped behaviour of freely moving fruit flies</article-title><source>Journal of the Royal Society Interface</source><volume>11</volume><elocation-id>20140672</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2014.0672</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname> <given-names>AE</given-names></name><name><surname>Yemini</surname> <given-names>EI</given-names></name><name><surname>Grundy</surname> <given-names>LJ</given-names></name><name><surname>Jucikas</surname> <given-names>T</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A dictionary of behavioral motifs reveals clusters of genes affecting Caenorhabditis elegans locomotion</article-title><source>PNAS</source><volume>110</volume><fpage>791</fpage><lpage>796</lpage><pub-id pub-id-type="doi">10.1073/pnas.1211447110</pub-id><pub-id pub-id-type="pmid">23267063</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calhoun</surname> <given-names>AJ</given-names></name><name><surname>Murthy</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Quantifying behavior to solve sensorimotor transformations: advances from worms and flies</article-title><source>Current Opinion in Neurobiology</source><volume>46</volume><fpage>90</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.08.006</pub-id><pub-id pub-id-type="pmid">28850885</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chalfie</surname> <given-names>M</given-names></name><name><surname>Sulston</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Developmental genetics of the mechanosensory neurons of Caenorhabditis elegans</article-title><source>Developmental Biology</source><volume>82</volume><fpage>358</fpage><lpage>370</lpage><pub-id pub-id-type="doi">10.1016/0012-1606(81)90459-0</pub-id><pub-id pub-id-type="pmid">7227647</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chalfie</surname> <given-names>M</given-names></name><name><surname>Sulston</surname> <given-names>JE</given-names></name><name><surname>White</surname> <given-names>JG</given-names></name><name><surname>Southgate</surname> <given-names>E</given-names></name><name><surname>Thomson</surname> <given-names>JN</given-names></name><name><surname>Brenner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The neural circuit for touch sensitivity in Caenorhabditi<italic>s</italic> elegan<italic>s</italic></article-title><source>The Journal of Neuroscience</source><volume>5</volume><fpage>956</fpage><lpage>964</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.05-04-00956.1985</pub-id><pub-id pub-id-type="pmid">3981252</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>X</given-names></name><name><surname>Chalfie</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Modulation of C. elegans touch sensitivity is integrated at multiple levels</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>6522</fpage><lpage>6536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0022-14.2014</pub-id><pub-id pub-id-type="pmid">24806678</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>X</given-names></name><name><surname>Chalfie</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Regulation of mechanosensation in C. elegans through ubiquitination of the MEC-4 mechanotransduction channel</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>2200</fpage><lpage>2212</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4082-14.2015</pub-id><pub-id pub-id-type="pmid">25653375</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiba</surname> <given-names>CM</given-names></name><name><surname>Rankin</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A developmental analysis of spontaneous and reflexive reversals in the nematode Caenorhabditis elegans</article-title><source>Journal of Neurobiology</source><volume>21</volume><fpage>543</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1002/neu.480210403</pub-id><pub-id pub-id-type="pmid">2376729</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname> <given-names>JY</given-names></name><name><surname>Sternberg</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multilevel modulation of a sensory motor circuit during C. elegans sleep and arousal</article-title><source>Cell</source><volume>156</volume><fpage>249</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2013.11.036</pub-id><pub-id pub-id-type="pmid">24439380</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cho</surname> <given-names>K</given-names></name><name><surname>van Merrienboer</surname> <given-names>B</given-names></name><name><surname>Gulcehre</surname> <given-names>C</given-names></name><name><surname>Bahdanau</surname> <given-names>D</given-names></name><name><surname>Bougares</surname> <given-names>F</given-names></name><name><surname>Schwenk</surname> <given-names>H</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning phrase representations using RNN Encoder-Decoder for statistical machine translation</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1406.1078">https://arxiv.org/abs/1406.1078</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname> <given-names>Y</given-names></name><name><surname>Oakland</surname> <given-names>DN</given-names></name><name><surname>Lee</surname> <given-names>SA</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name><name><surname>Lu</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On-chip functional neuroimaging with mechanical stimulation in Caenorhabditis elegans larvae for studying development and neural circuits</article-title><source>Lab on a Chip</source><volume>18</volume><fpage>601</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1039/C7LC01201B</pub-id><pub-id pub-id-type="pmid">29340386</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>DA</given-names></name><name><surname>Biron</surname> <given-names>D</given-names></name><name><surname>Sengupta</surname> <given-names>P</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The AFD sensory neurons encode multiple functions underlying thermotactic behavior in Caenorhabditis elegans</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>7444</fpage><lpage>7451</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1137-06.2006</pub-id><pub-id pub-id-type="pmid">16837592</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>DA</given-names></name><name><surname>Gabel</surname> <given-names>CV</given-names></name><name><surname>Gabel</surname> <given-names>H</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Temporal activity patterns in thermosensory neurons of freely moving Caenorhabditis elegans encode spatial thermal gradients</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>6083</fpage><lpage>6090</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1032-07.2007</pub-id><pub-id pub-id-type="pmid">17553981</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Clemens</surname> <given-names>J</given-names></name><name><surname>Murthy</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><chapter-title>The Use of Computational Modeling to Link Sensory Processing with Behavior in Drosophila</chapter-title><source>Decoding Neural Circuit Structure and Function</source><publisher-loc>Cham</publisher-loc><publisher-name>Springer</publisher-name><fpage>241</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-57363-2_9</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Clemens</surname> <given-names>J</given-names></name><name><surname>Weinstein</surname> <given-names>AJ</given-names></name><name><surname>Pacheco</surname> <given-names>DA</given-names></name><name><surname>Deng</surname> <given-names>Y</given-names></name><name><surname>Murthy</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dynamic sensory cues shape song structure in <italic>Drosophila</italic></article-title><source>Nature</source><volume>507</volume><fpage>233</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1038/nature13131</pub-id><pub-id pub-id-type="pmid">24598544</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Croll</surname> <given-names>NA</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Behavioural analysis of nematode movement</article-title><source>Advances in Parasitology</source><volume>13</volume><fpage>71</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1016/S0065-308X(08)60319-X</pub-id><pub-id pub-id-type="pmid">1169872</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>CROLL</surname> <given-names>NA</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Components and patterns in the behaviour of the nematode Caenorhabditis elegans</article-title><source>Journal of Zoology</source><volume>176</volume><fpage>159</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7998.1975.tb03191.x</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname> <given-names>Y</given-names></name><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Sun</surname> <given-names>M</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Efficient multiple object tracking using mutually repulsive active membranes</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e65769</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0065769</pub-id><pub-id pub-id-type="pmid">23799046</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Driscoll</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><chapter-title>Mechanotransduction</chapter-title><person-group person-group-type="editor"><name><surname>Riddle</surname> <given-names>D. L</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Blumenthal</surname> <given-names>T</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Meyer</surname> <given-names>B. J</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Priess</surname> <given-names>J. R</given-names></name></person-group><source>C. Elegans II</source><edition>2nd ed</edition><publisher-loc>Cold Spring Harbor (NY)</publisher-loc><publisher-name>Cold Spring Harbor Laboratory Press</publisher-name></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eastwood</surname> <given-names>AL</given-names></name><name><surname>Sanzeni</surname> <given-names>A</given-names></name><name><surname>Petzold</surname> <given-names>BC</given-names></name><name><surname>Park</surname> <given-names>S-J</given-names></name><name><surname>Vergassola</surname> <given-names>M</given-names></name><name><surname>Pruitt</surname> <given-names>BL</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Tissue mechanics govern the rapidly adapting and symmetrical response to touch</article-title><source>PNAS</source><volume>112</volume><fpage>E6955</fpage><lpage>E6963</lpage><pub-id pub-id-type="doi">10.1073/pnas.1514138112</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Transformation and microinjection</article-title><source>WormBook</source><pub-id pub-id-type="doi">10.1895/wormbook.1.108.1</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Félix</surname> <given-names>MA</given-names></name><name><surname>Braendle</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The natural history of Caenorhabditis elegans</article-title><source>Current Biology</source><volume>20</volume><fpage>R965</fpage><lpage>R969</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.09.050</pub-id><pub-id pub-id-type="pmid">21093785</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gepner</surname> <given-names>R</given-names></name><name><surname>Mihovilovic Skanata</surname> <given-names>M</given-names></name><name><surname>Bernat</surname> <given-names>NM</given-names></name><name><surname>Kaplow</surname> <given-names>M</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Computations underlying Drosophila photo-taxis, odor-taxis, and multi-sensory integration</article-title><source>eLife</source><volume>4</volume><elocation-id>e06229</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06229</pub-id><pub-id pub-id-type="pmid">25945916</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghosh</surname> <given-names>DD</given-names></name><name><surname>Sanders</surname> <given-names>T</given-names></name><name><surname>Hong</surname> <given-names>S</given-names></name><name><surname>McCurdy</surname> <given-names>LY</given-names></name><name><surname>Chase</surname> <given-names>DL</given-names></name><name><surname>Cohen</surname> <given-names>N</given-names></name><name><surname>Koelle</surname> <given-names>MR</given-names></name><name><surname>Nitabach</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural architecture of Hunger-Dependent multisensory decision making in C. elegans</article-title><source>Neuron</source><volume>92</volume><fpage>1049</fpage><lpage>1062</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.030</pub-id><pub-id pub-id-type="pmid">27866800</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Glaser</surname> <given-names>JI</given-names></name><name><surname>Chowdhury</surname> <given-names>RH</given-names></name><name><surname>Perich</surname> <given-names>MG</given-names></name><name><surname>Miller</surname> <given-names>LE</given-names></name><name><surname>Kording</surname> <given-names>KP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Machine learning for neural decoding</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1708.00909">https://arxiv.org/abs/1708.00909</ext-link></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Marin</surname> <given-names>A</given-names></name><name><surname>Stephens</surname> <given-names>GJ</given-names></name><name><surname>Brown</surname> <given-names>AE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Hierarchical compression of Caenorhabditis elegans locomotion reveals phenotypic differences in the organization of behaviour</article-title><source>Journal of The Royal Society Interface</source><volume>13</volume><elocation-id>20160466</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2016.0466</pub-id><pub-id pub-id-type="pmid">27581484</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gyenes</surname> <given-names>B</given-names></name><name><surname>Brown</surname> <given-names>AE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deriving Shape-Based features for C. elegans locomotion using dimensionality reduction methods</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>10</volume><pub-id pub-id-type="doi">10.3389/fnbeh.2016.00159</pub-id><pub-id pub-id-type="pmid">27582697</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernandez-Nunez</surname> <given-names>L</given-names></name><name><surname>Belina</surname> <given-names>J</given-names></name><name><surname>Klein</surname> <given-names>M</given-names></name><name><surname>Si</surname> <given-names>G</given-names></name><name><surname>Claus</surname> <given-names>L</given-names></name><name><surname>Carlson</surname> <given-names>JR</given-names></name><name><surname>Samuel</surname> <given-names>ADT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reverse-correlation analysis of navigation dynamics in Drosophila larva using optogenetics</article-title><source>eLife</source><volume>4</volume><elocation-id>e06225</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06225</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname> <given-names>S</given-names></name><name><surname>Xu</surname> <given-names>Y</given-names></name><name><surname>Cho</surname> <given-names>CE</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Bargmann</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Temporal responses of C. elegans chemosensory neurons are preserved in behavioral dynamics</article-title><source>Neuron</source><volume>81</volume><fpage>616</fpage><lpage>628</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.020</pub-id><pub-id pub-id-type="pmid">24440227</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kindt</surname> <given-names>KS</given-names></name><name><surname>Quast</surname> <given-names>KB</given-names></name><name><surname>Giles</surname> <given-names>AC</given-names></name><name><surname>De</surname> <given-names>S</given-names></name><name><surname>Hendrey</surname> <given-names>D</given-names></name><name><surname>Nicastro</surname> <given-names>I</given-names></name><name><surname>Rankin</surname> <given-names>CH</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dopamine mediates context-dependent modulation of sensory plasticity in C. elegans</article-title><source>Neuron</source><volume>55</volume><fpage>662</fpage><lpage>676</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.07.023</pub-id><pub-id pub-id-type="pmid">17698017</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitamura</surname> <given-names>KI</given-names></name><name><surname>Amano</surname> <given-names>S</given-names></name><name><surname>Hosono</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Contribution of neurons to habituation to mechanical stimulation in Caenorhabditis elegans</article-title><source>Journal of Neurobiology</source><volume>46</volume><fpage>29</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1002/1097-4695(200101)46:1&lt;29::AID-NEU3&gt;3.0.CO;2-8</pub-id><pub-id pub-id-type="pmid">11108613</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishnamoorthy</surname> <given-names>K</given-names></name><name><surname>Thomson</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A more powerful test for comparing two Poisson means</article-title><source>Journal of Statistical Planning and Inference</source><volume>119</volume><fpage>23</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/S0378-3758(02)00408-1</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kubanek</surname> <given-names>J</given-names></name><name><surname>Shukla</surname> <given-names>P</given-names></name><name><surname>Das</surname> <given-names>A</given-names></name><name><surname>Baccus</surname> <given-names>SA</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Ultrasound elicits behavioral responses through mechanical effects on neurons and ion channels in a simple nervous system</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>3081</fpage><lpage>3091</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1458-17.2018</pub-id><pub-id pub-id-type="pmid">29463641</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leifer</surname> <given-names>AM</given-names></name><name><surname>Fang-Yen</surname> <given-names>C</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Optogenetic manipulation of neural activity in freely moving Caenorhabditis elegans</article-title><source>Nature Methods</source><volume>8</volume><fpage>147</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1554</pub-id><pub-id pub-id-type="pmid">21240279</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>M</given-names></name><name><surname>Sharma</surname> <given-names>AK</given-names></name><name><surname>Shaevitz</surname> <given-names>J</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Temporal processing and context dependency in C. elegans response to mechanosensation</article-title><source>eLife</source><volume>7</volume><elocation-id>e36419</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.36419</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>Q</given-names></name><name><surname>Hollopeter</surname> <given-names>G</given-names></name><name><surname>Jorgensen</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Graded synaptic transmission at the Caenorhabditis elegans neuromuscular junction</article-title><source>PNAS</source><volume>106</volume><fpage>10823</fpage><lpage>10828</lpage><pub-id pub-id-type="doi">10.1073/pnas.0903570106</pub-id><pub-id pub-id-type="pmid">19528650</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lvd</surname> <given-names>M</given-names></name><name><surname>Hinton</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Visualizing data using t-SNE</article-title><source>Journal of Machine Learning Research</source><volume>9</volume><fpage>2579</fpage><lpage>2605</lpage></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maguire</surname> <given-names>SM</given-names></name><name><surname>Clark</surname> <given-names>CM</given-names></name><name><surname>Nunnari</surname> <given-names>J</given-names></name><name><surname>Pirri</surname> <given-names>JK</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The C. elegans touch response facilitates escape from predacious fungi</article-title><source>Current Biology</source><volume>21</volume><fpage>1326</fpage><lpage>1330</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.06.063</pub-id><pub-id pub-id-type="pmid">21802299</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mazzochette</surname> <given-names>EA</given-names></name><name><surname>Nekimken</surname> <given-names>AL</given-names></name><name><surname>Loizeau</surname> <given-names>F</given-names></name><name><surname>Whitworth</surname> <given-names>J</given-names></name><name><surname>Huynh</surname> <given-names>B</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name><name><surname>Pruitt</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The tactile receptive fields of freely moving Caenorhabditis elegans Nematodes</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1039/C8IB00045J</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClanahan</surname> <given-names>PD</given-names></name><name><surname>Xu</surname> <given-names>JH</given-names></name><name><surname>Fang-Yen</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Comparing Caenorhabditis elegans gentle and harsh touch response behavior using a multiplexed hydraulic microfluidic device</article-title><source>Integrative Biology</source><volume>9</volume><fpage>800</fpage><lpage>809</lpage><pub-id pub-id-type="doi">10.1039/C7IB00120G</pub-id><pub-id pub-id-type="pmid">28914311</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meister</surname> <given-names>M</given-names></name><name><surname>Berry</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The neural code of the retina</article-title><source>Neuron</source><volume>22</volume><fpage>435</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80700-X</pub-id><pub-id pub-id-type="pmid">10197525</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagel</surname> <given-names>G</given-names></name><name><surname>Brauner</surname> <given-names>M</given-names></name><name><surname>Liewald</surname> <given-names>JF</given-names></name><name><surname>Adeishvili</surname> <given-names>N</given-names></name><name><surname>Bamberg</surname> <given-names>E</given-names></name><name><surname>Gottschalk</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Light activation of channelrhodopsin-2 in excitable cells of Caenorhabditis elegans triggers rapid behavioral responses</article-title><source>Current Biology</source><volume>15</volume><fpage>2279</fpage><lpage>2284</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2005.11.032</pub-id><pub-id pub-id-type="pmid">16360690</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagy</surname> <given-names>S</given-names></name><name><surname>Raizen</surname> <given-names>DM</given-names></name><name><surname>Biron</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Measurements of behavioral quiescence in Caenorhabditis elegans</article-title><source>Methods</source><volume>68</volume><fpage>500</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.ymeth.2014.03.009</pub-id><pub-id pub-id-type="pmid">24642199</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagy</surname> <given-names>S</given-names></name><name><surname>Tramm</surname> <given-names>N</given-names></name><name><surname>Sanders</surname> <given-names>J</given-names></name><name><surname>Iwanir</surname> <given-names>S</given-names></name><name><surname>Shirley</surname> <given-names>IA</given-names></name><name><surname>Levine</surname> <given-names>E</given-names></name><name><surname>Biron</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Homeostasis in C. elegans sleep is characterized by two behaviorally and genetically distinct mechanisms</article-title><source>eLife</source><volume>3</volume><elocation-id>e04380</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.04380</pub-id><pub-id pub-id-type="pmid">25474127</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narayan</surname> <given-names>A</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name><name><surname>Sternberg</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Transfer characteristics of a thermosensory synapse in Caenorhabditis elegans</article-title><source>PNAS</source><volume>108</volume><fpage>9667</fpage><lpage>9672</lpage><pub-id pub-id-type="doi">10.1073/pnas.1106617108</pub-id><pub-id pub-id-type="pmid">21606366</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nekimken</surname> <given-names>AL</given-names></name><name><surname>Mazzochette</surname> <given-names>EA</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name><name><surname>Pruitt</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Forces applied during classical touch assays for Caenorhabditis elegans</article-title><source>PLoS One</source><volume>12</volume><elocation-id>e0178080</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0178080</pub-id><pub-id pub-id-type="pmid">28542494</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname> <given-names>JP</given-names></name><name><surname>Linder</surname> <given-names>AN</given-names></name><name><surname>Plummer</surname> <given-names>GS</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automatically tracking neurons in a moving and deforming brain</article-title><source>PLoS Computational Biology</source><volume>13</volume><elocation-id>e1005517</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005517</pub-id><pub-id pub-id-type="pmid">28545068</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Hagan</surname> <given-names>R</given-names></name><name><surname>Chalfie</surname> <given-names>M</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The MEC-4 DEG/ENaC channel of Caenorhabditis elegans touch receptor neurons transduces mechanical signals</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1038/nn1362</pub-id><pub-id pub-id-type="pmid">15580270</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petzold</surname> <given-names>BC</given-names></name><name><surname>Park</surname> <given-names>SJ</given-names></name><name><surname>Mazzochette</surname> <given-names>EA</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name><name><surname>Pruitt</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MEMS-based force-clamp analysis of the role of body stiffness in C. elegans touch sensation</article-title><source>Integrative Biology</source><volume>5</volume><fpage>853</fpage><lpage>864</lpage><pub-id pub-id-type="doi">10.1039/c3ib20293c</pub-id><pub-id pub-id-type="pmid">23598612</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pirri</surname> <given-names>JK</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The neuroethology of C. elegans escape</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>187</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2011.12.007</pub-id><pub-id pub-id-type="pmid">22226513</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Porto</surname> <given-names>DA</given-names></name><name><surname>Giblin</surname> <given-names>J</given-names></name><name><surname>Zhao</surname> <given-names>Y</given-names></name><name><surname>Lu</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reverse-Correlation analysis of mechanosensation circuit in C. elegans reveals temporal and spatial encoding</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/147363</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raizen</surname> <given-names>DM</given-names></name><name><surname>Zimmerman</surname> <given-names>JE</given-names></name><name><surname>Maycock</surname> <given-names>MH</given-names></name><name><surname>Ta</surname> <given-names>UD</given-names></name><name><surname>You</surname> <given-names>YJ</given-names></name><name><surname>Sundaram</surname> <given-names>MV</given-names></name><name><surname>Pack</surname> <given-names>AI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Lethargus is a <italic>Caenorhabditis elegans</italic> sleep-like state</article-title><source>Nature</source><volume>451</volume><fpage>569</fpage><lpage>572</lpage><pub-id pub-id-type="doi">10.1038/nature06535</pub-id><pub-id pub-id-type="pmid">18185515</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramot</surname> <given-names>D</given-names></name><name><surname>Johnson</surname> <given-names>BE</given-names></name><name><surname>Berry</surname> <given-names>TL</given-names></name><name><surname>Carnell</surname> <given-names>L</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The Parallel Worm Tracker: a platform for measuring average speed and drug-induced paralysis in nematodes</article-title><source>PLoS One</source><volume>3</volume><elocation-id>e2208</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0002208</pub-id><pub-id pub-id-type="pmid">18493300</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rankin</surname> <given-names>CH</given-names></name><name><surname>Beck</surname> <given-names>CD</given-names></name><name><surname>Chiba</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Caenorhabditis elegans: a new model system for the study of learning and memory</article-title><source>Behavioural Brain Research</source><volume>37</volume><fpage>89</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1016/0166-4328(90)90074-O</pub-id><pub-id pub-id-type="pmid">2310497</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rankin</surname> <given-names>CH</given-names></name><name><surname>Wicks</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Mutations of the caenorhabditis elegans brain-specific inorganic phosphate transporter eat-4 affect habituation of the tap-withdrawal response without affecting the response itself</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>4337</fpage><lpage>4344</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-11-04337.2000</pub-id><pub-id pub-id-type="pmid">10818169</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringach</surname> <given-names>D</given-names></name><name><surname>Shapley</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Reverse correlation in neurophysiology</article-title><source>Cognitive Science</source><volume>28</volume><fpage>147</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog2802_2</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanyal</surname> <given-names>S</given-names></name><name><surname>Wintle</surname> <given-names>RF</given-names></name><name><surname>Kindt</surname> <given-names>KS</given-names></name><name><surname>Nuttley</surname> <given-names>WM</given-names></name><name><surname>Arvan</surname> <given-names>R</given-names></name><name><surname>Fitzmaurice</surname> <given-names>P</given-names></name><name><surname>Bigras</surname> <given-names>E</given-names></name><name><surname>Merz</surname> <given-names>DC</given-names></name><name><surname>Hébert</surname> <given-names>TE</given-names></name><name><surname>van der Kooy</surname> <given-names>D</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name><name><surname>Culotti</surname> <given-names>JG</given-names></name><name><surname>Van Tol</surname> <given-names>HH</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Dopamine modulates the plasticity of mechanosensory responses in Caenorhabditis elegans</article-title><source>The EMBO Journal</source><volume>23</volume><fpage>473</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1038/sj.emboj.7600057</pub-id><pub-id pub-id-type="pmid">14739932</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmitt</surname> <given-names>C</given-names></name><name><surname>Schultheis</surname> <given-names>C</given-names></name><name><surname>Pokala</surname> <given-names>N</given-names></name><name><surname>Husson</surname> <given-names>SJ</given-names></name><name><surname>Liewald</surname> <given-names>JF</given-names></name><name><surname>Bargmann</surname> <given-names>CI</given-names></name><name><surname>Gottschalk</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Specific expression of channelrhodopsin-2 in single neurons of Caenorhabditis elegans</article-title><source>PLoS One</source><volume>7</volume><elocation-id>e43164</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0043164</pub-id><pub-id pub-id-type="pmid">22952643</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname> <given-names>O</given-names></name><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Rust</surname> <given-names>NC</given-names></name><name><surname>Simoncelli</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spike-triggered neural characterization</article-title><source>Journal of Vision</source><volume>6</volume><fpage>13</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1167/6.4.13</pub-id><pub-id pub-id-type="pmid">16889482</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname> <given-names>J</given-names></name><name><surname>Lewandrowski</surname> <given-names>I</given-names></name><name><surname>Bringmann</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Reduced activity of a sensory neuron during a sleep-like state in Caenorhabditis elegans</article-title><source>Current Biology</source><volume>21</volume><fpage>R983</fpage><lpage>R984</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.10.046</pub-id><pub-id pub-id-type="pmid">22192827</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephens</surname> <given-names>GJ</given-names></name><name><surname>Johnson-Kerner</surname> <given-names>B</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>Ryu</surname> <given-names>WS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dimensionality and dynamics in the behavior of C. elegans</article-title><source>PLoS Computational Biology</source><volume>4</volume><elocation-id>e1000028</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000028</pub-id><pub-id pub-id-type="pmid">18389066</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stirman</surname> <given-names>JN</given-names></name><name><surname>Crane</surname> <given-names>MM</given-names></name><name><surname>Husson</surname> <given-names>SJ</given-names></name><name><surname>Wabnig</surname> <given-names>S</given-names></name><name><surname>Schultheis</surname> <given-names>C</given-names></name><name><surname>Gottschalk</surname> <given-names>A</given-names></name><name><surname>Lu</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Real-time multimodal optical control of neurons and muscles in freely behaving Caenorhabditis elegans</article-title><source>Nature Methods</source><volume>8</volume><fpage>153</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1555</pub-id><pub-id pub-id-type="pmid">21240278</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugi</surname> <given-names>T</given-names></name><name><surname>Okumura</surname> <given-names>E</given-names></name><name><surname>Kiso</surname> <given-names>K</given-names></name><name><surname>Igarashi</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Nanoscale mechanical stimulation method for quantifying <italic>C. elegans</italic> Mechanosensory Behavior and Memory</article-title><source>Analytical Sciences</source><volume>32</volume><fpage>1159</fpage><lpage>1164</lpage><pub-id pub-id-type="doi">10.2116/analsci.32.1159</pub-id><pub-id pub-id-type="pmid">27829619</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suzuki</surname> <given-names>H</given-names></name><name><surname>Kerr</surname> <given-names>R</given-names></name><name><surname>Bianchi</surname> <given-names>L</given-names></name><name><surname>Frøkjaer-Jensen</surname> <given-names>C</given-names></name><name><surname>Slone</surname> <given-names>D</given-names></name><name><surname>Xue</surname> <given-names>J</given-names></name><name><surname>Gerstbrein</surname> <given-names>B</given-names></name><name><surname>Driscoll</surname> <given-names>M</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>In vivo imaging of C. elegans mechanosensory neurons demonstrates a specific role for the MEC-4 channel in the process of gentle touch sensation</article-title><source>Neuron</source><volume>39</volume><fpage>1005</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2003.08.015</pub-id><pub-id pub-id-type="pmid">12971899</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swierczek</surname> <given-names>NA</given-names></name><name><surname>Giles</surname> <given-names>AC</given-names></name><name><surname>Rankin</surname> <given-names>CH</given-names></name><name><surname>Kerr</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>High-throughput behavioral analysis in <italic>C. elegans</italic></article-title><source>Nature Methods</source><volume>8</volume><elocation-id>592</elocation-id><lpage>598</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1625</pub-id><pub-id pub-id-type="pmid">21642964</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timbers</surname> <given-names>TA</given-names></name><name><surname>Giles</surname> <given-names>AC</given-names></name><name><surname>Ardiel</surname> <given-names>EL</given-names></name><name><surname>Kerr</surname> <given-names>RA</given-names></name><name><surname>Rankin</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Intensity discrimination deficits cause habituation changes in middle-aged Caenorhabditis elegans</article-title><source>Neurobiology of Aging</source><volume>34</volume><fpage>621</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2012.03.016</pub-id><pub-id pub-id-type="pmid">22575357</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname> <given-names>X</given-names></name><name><surname>Potter</surname> <given-names>CJ</given-names></name><name><surname>Luo</surname> <given-names>L</given-names></name><name><surname>Shen</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Controlling gene expression with the Q repressible binary expression system in Caenorhabditis elegans</article-title><source>Nature Methods</source><volume>9</volume><fpage>391</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1929</pub-id><pub-id pub-id-type="pmid">22406855</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wicks</surname> <given-names>SR</given-names></name><name><surname>Rankin</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Integration of mechanosensory stimuli in Caenorhabditis elegans</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>2434</fpage><lpage>2444</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-03-02434.1995</pub-id><pub-id pub-id-type="pmid">7891178</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname> <given-names>AB</given-names></name><name><surname>Johnson</surname> <given-names>MJ</given-names></name><name><surname>Iurilli</surname> <given-names>G</given-names></name><name><surname>Peterson</surname> <given-names>RE</given-names></name><name><surname>Katon</surname> <given-names>JM</given-names></name><name><surname>Pashkovski</surname> <given-names>SL</given-names></name><name><surname>Abraira</surname> <given-names>VE</given-names></name><name><surname>Adams</surname> <given-names>RP</given-names></name><name><surname>Datta</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mapping Sub-Second structure in mouse behavior</article-title><source>Neuron</source><volume>88</volume><fpage>1121</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.031</pub-id><pub-id pub-id-type="pmid">26687221</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yemini</surname> <given-names>E</given-names></name><name><surname>Jucikas</surname> <given-names>T</given-names></name><name><surname>Grundy</surname> <given-names>LJ</given-names></name><name><surname>Brown</surname> <given-names>AE</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A database of Caenorhabditis elegans behavioral phenotypes</article-title><source>Nature Methods</source><volume>10</volume><fpage>877</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2560</pub-id><pub-id pub-id-type="pmid">23852451</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.36419.042</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>O'Leary</surname><given-names>Timothy</given-names></name><role>Reviewing Editor</role><aff id="aff5"><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Temporal processing and context dependency in <italic>C. elegans</italic> mechanosensation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Eve Marder as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission. We hope you will be able to submit the revised version within two months.</p><p>Summary:</p><p>Using a combination of optogenetics and high-throughput automated behavioral segmentation in freely behaving <italic>C. elegans</italic>, this study demonstrates that temporal properties of mechanosensory neuron stimulation is relevant for behavior. Behavioral context (e.g. turning) affects the integration of mechanosensory signals. Together the technical approach as well as the findings provide a clear and quantitative account of how mechanosensory signals influence, and are influenced by, swimming behavior in an intact animal.</p><p>Essential revisions:</p><p>The reviewers commented on how the findings are presented in the context of what is known in the field. Specifically, the presentation gives the impression that prior studies have somehow gotten most everything wrong and that the current study completely overturns previous work. The manuscript should be tempered and more even-handed about the treatment of previous work, emphasizing important connections as well as key differences. The authors should also be more self-critical about the limitations of their approach, e.g. all of the stimuli delivered (both mechanical 'tap' stimulation and optical stimuli) are expected to simultaneously activate the entire ensemble of touch receptor neurons. Claims about ethological relevance of the experiments should also be more circumspect and spell out possible confounds.</p><p>Reviewers felt that more should be done to justify the use of the LN model – other models that can account for stochasticity may be more appropriate and should be considered/rejected explicitly.</p><p>The authors should comment on what can account for the seconds-long effects of stimulation, because direct measurements of the mechanosensory neurons show that their response occurs on a millisecond timescale.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.36419.043</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Summary:</p><p>Using a combination of optogenetics and high-throughput automated behavioral segmentation in freely behaving C. elegans, this study demonstrates that temporal properties of mechanosensory neuron stimulation is relevant for behavior. Behavioral context (e.g. turning) affects the integration of mechanosensory signals. Together the technical approach as well as the findings provide a clear and quantitative account of how mechanosensory signals influence, and are influenced by, swimming behavior in an intact animal.</p><p>Agreed. Thank you.</p><p>Essential revisions:</p><p>The reviewers commented on how the findings are presented in the context of what is known in the field. Specifically, the presentation gives the impression that prior studies have somehow gotten most everything wrong and that the current study completely overturns previous work. The manuscript should be tempered and more even-handed about the treatment of previous work, emphasizing important connections as well as key differences.</p></disp-quote><p>We have revised the text to be more reserved. We have softened or outright removed contrasts between our work and the literature and we now highlight more positive connections. Many of these changes are in the Introduction and Discussion section, while others are sprinkled throughout the manuscript. To more easily identify textual changes, we have uploaded a separate “track-changes&quot;-like document that shows removed text in red. We have also added in references to highlight additional work in the area. We added references exploring long time-scale modulation of touch response for example due to vibration or Dauer formation (Chen and Chalfie, 2014, Chen and Chalfie, 2015) and lethargus (Raizen et al., 2008), to the Introduction. We also now point to additional recent work probing spatial tuning to touch (McClanahan et al., 2017) and response to ultrasound (Kubanek et al., 2018), to the Introduction. We highlight work showing the slow intracellular calcium response observed in the touch neurons, (Suzuki et al., 2013; Cho et al., 2018). And we point to (Liu et al., 2009) and (Narayan et al., 2011) to justify why we expect modulating light intensity will elicit smooth time-varying membrane potentials.</p><disp-quote content-type="editor-comment"><p>The authors should also be more self-critical about the limitations of their approach, e.g. all of the stimuli delivered (both mechanical 'tap' stimulation and optical stimuli) are expected to simultaneously activate the entire ensemble of touch receptor neurons.</p></disp-quote><p>We have added text to the Discussion section that highlights some of the design decisions we made in our experiment and the inherent trade-offs that arise from those decisions. For example, we further emphasize that all neurons are activated simultaneously, and that future work is needed to probe the role of individual neurons in temporal processing. We also now remind the reader once more that we have characterized temporal processing in response to optogenetic stimulation, thus bypassing the animal's natural mechanoelectric transduction machinery. “Further work,” we write, “is necessary to probe temporal processing of applied forces directly.” And we highlight our choice to classify behavior as discrete states and we write that we suspect continuous descriptions of behavior would likely also reveal similar results.</p><disp-quote content-type="editor-comment"><p>Claims about ethological relevance of the experiments should also be more circumspect and spell out possible confounds.</p></disp-quote><p>We have removed explicit claims of ethological relevance. In the Discussion section we explain that the natural ecology of <italic>C. elegans</italic> is not well understood (Felix and Braendle, 2010) and the statistics of force stimuli in its natural environment are not known. We have, however, left intact the paragraph, in the Discussion section, describing turning and prey avoidance because that is well documented in the literature.</p><disp-quote content-type="editor-comment"><p>Reviewers felt that more should be done to justify the use of the LN model – other models that can account for stochasticity may be more appropriate and should be considered/rejected explicitly.</p></disp-quote><p>We have added a paragraph to the Discussion section to clarify our motivation in choosing the LN model. We now explain that the LN model was chosen primarily for its “simplicity and ubiquity in neuroscience” and that “we suspect that other models would yield similar findings.” In the same paragraph we now point to specific assumptions and limitations of the LN model and point to a radically different model, a GRU neural network, as one of many potential alternative models to explore.</p><p>The goal of this work is not to claim that the LN model is somehow the most appropriate, or indeed even that it is better than others. Rather, the LN model is one model that seems to work well enough. We now better convey this sentiment to the reader and we therefore would argue that further detailed comparisons to other models are unnecessary.</p><disp-quote content-type="editor-comment"><p>The authors should comment on what can account for the seconds-long effects of stimulation, because direct measurements of the mechanosensory neurons show that their response occurs on a millisecond timescale.</p></disp-quote><p>In the Discussion section, we now state that recurrent activity in the network downstream of the touch receptor neurons could plausibly give rise to temporal processing on a seconds scale.</p></body></sub-article></article>