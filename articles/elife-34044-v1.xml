<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">34044</article-id><article-id pub-id-type="doi">10.7554/eLife.34044</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>First spikes in visual cortex enable perceptual discrimination</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-102398"><name><surname>Resulaj</surname><given-names>Arbora</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9886-1380</contrib-id><email>aresulaj@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-102399"><name><surname>Ruediger</surname><given-names>Sarah</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-73112"><name><surname>Olsen</surname><given-names>Shawn R</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-102278"><name><surname>Scanziani</surname><given-names>Massimo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5331-9686</contrib-id><email>massimo@ucsf.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">Center for Neural Circuits and Behavior, Neurobiology Section</institution><institution>University of California, San Diego</institution><addr-line><named-content content-type="city">San Diego</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Department of Neuroscience</institution><institution>University of California, San Diego</institution><addr-line><named-content content-type="city">San Diego</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">Department of Physiology</institution><institution>University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution>Allen Institute for Brain Science</institution><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>Howard Hughes Medical Institute, University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-17567"><name><surname>Slutsky</surname><given-names>Inna</given-names></name><role>Reviewing Editor</role><aff id="aff6"><institution>Tel Aviv University</institution><country>Israel</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>16</day><month>04</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e34044</elocation-id><history><date date-type="received" iso-8601-date="2017-12-02"><day>02</day><month>12</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2018-03-09"><day>09</day><month>03</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Resulaj et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Resulaj et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-34044-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.34044.001</object-id><p>Visually guided perceptual decisions involve the sequential activation of a hierarchy of cortical areas. It has been hypothesized that a brief time window of activity in each area is sufficient to enable the decision but direct measurements of this time window are lacking. To address this question, we develop a visual discrimination task in mice that depends on visual cortex and in which we precisely control the time window of visual cortical activity as the animal performs the task at different levels of difficulty. We show that threshold duration of activity in visual cortex enabling perceptual discrimination is between 40 and 80 milliseconds. During this time window the vast majority of neurons discriminating the stimulus fire one or no spikes and less than 16% fire more than two. This result establishes that the firing of the first visually evoked spikes in visual cortex is sufficient to enable a perceptual decision.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>perceptual discrimination</kwd><kwd>primary visual cortex</kwd><kwd>electrophysiology</kwd><kwd>optogenetics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Scanziani</surname><given-names>Massimo</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000324</institution-id><institution>Gatsby Charitable Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Scanziani</surname><given-names>Massimo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A brief time window of visually evoked activity in mouse primary visual cortex is sufficient for perceptual discrimination.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Perceptual decisions involve the sequential activation of several, hierarchically organized cortical areas beginning with early sensory areas and ending with associational and motor areas. Based on the number of areas likely involved in the processing of sensory stimuli it has been hypothesized that in each area a relatively brief time window of activity may be sufficient to enable a perceptual decision (<xref ref-type="bibr" rid="bib6">Fabre-Thorpe et al., 1998</xref>). Yet, this time window has never been directly measured for any specific area. By determining these lower limits and analyzing neuronal activity over this time window within a given area we can establish the minimal output of individual neurons in enabling perceptual decisions and reveal how the stimulus is represented within this time frame in that area. Furthermore, this time window defines the time that an area has to be active such that downstream areas can extract sufficient information to enable a perceptual decision. How this time window relates to the time window for an outside observer to extract sufficient information (<xref ref-type="bibr" rid="bib4">Celebrini et al., 1993</xref>; <xref ref-type="bibr" rid="bib20">Mazurek and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib38">Shadlen and Newsome, 1998</xref>) is not clear.</p><p>The lack of answers to these questions is largely due to technical limitations. One key issue is to demonstrate that the visual area of interest is necessary for the sensory discrimination task at hand. Even though activity in a given area may carry relevant stimulus information, that area may not be required for the perceptual decision. A second challenge is to precisely control the duration of the sensory evoked response of that visual area. Answering this question has been technically difficult since the duration of visually evoked activity in the brain cannot be precisely controlled by the duration of the sensory stimulus. Even a stimulus as brief as 16 ms triggers a response that lasts hundreds of milliseconds in visual cortex (<xref ref-type="bibr" rid="bib34">Rolls et al., 1999</xref>). Presentation of a visual mask at various delays following the stimulus has been used to perturb the long lasting neuronal response to a visual stimulus (<xref ref-type="bibr" rid="bib14">Kovács et al., 1995</xref>; <xref ref-type="bibr" rid="bib15">Lamme et al., 2002</xref>; <xref ref-type="bibr" rid="bib19">Macknik and Livingstone, 1998</xref>; <xref ref-type="bibr" rid="bib33">Rolls et al., 1994</xref>) and study the effects on perception. However, whether the impact on perception is due to the suppression of the neuronal response to the stimulus or to the generation of the neuronal activity by the mask (<xref ref-type="bibr" rid="bib19">Macknik and Livingstone, 1998</xref>) is difficult to disambiguate. Further, visual masks are not area specific but involve the entire visual system and thus cannot address the minimal duration of activity of a specific visual area. In the mouse, optogenetic approaches make it possible to selectively, rapidly and completely silence neuronal activity of a given brain area (<xref ref-type="bibr" rid="bib17">Lien and Scanziani, 2013</xref>; <xref ref-type="bibr" rid="bib23">Olsen et al., 2012</xref>) at any arbitrary delay after stimulus presentation (<xref ref-type="bibr" rid="bib30">Reinhold et al., 2015</xref>). With optogenetic silencing we do not add activity but instead prevent activity from exiting the silenced area. With this approach we can precisely control the duration of visually evoked activity in a cortical area during a discrimination task.</p><p>Here we developed a simple visual discrimination task in mice that depends on visual cortex. By completely and rapidly silencing primary visual cortex at well-defined intervals after the stimulus appeared in the task, we demonstrate that this cortical area is required only during the initial 80 ms from the onset of stimulus evoked response for a reliable decision to be made. Importantly, during this period, most neurons in primary visual cortex fire one or no action potentials. Thus, we establish the minimal time window of activity in primary visual cortex sufficient to enable a perceptual discrimination and provide direct evidence for a key role of the first action potentials fired by individual neurons in the execution of the task.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A visually guided behavior that depends on visual cortex</title><p>To determine the minimal duration of activity in visual cortex necessary for accurate visual discrimination by the animal, we needed to develop a perceptual task that requires visual cortex. We developed a visual discrimination task in which mice are head-fixed yet free to run on a treadmill (<xref ref-type="fig" rid="fig1">Figure 1A</xref> and <xref ref-type="video" rid="video1">Video 1</xref>) Visual stimuli (circular patches of gratings,~30 degrees, oriented at different angles) shown on a monitor placed on the right side of the animal moved horizontally from the anterior to the posterior end of the monitor at a speed that was proportional to the running speed of the animal. One of the stimuli (a grating oriented at 90 degrees) was the target stimulus, while the other stimulus (a grating oriented at 45 degrees) was the distractor. Mice were rewarded with water for bringing the target stimulus to the center of the monitor, the reward zone, and holding it there for a minimum time set by the experimenter (~1 s; a trial in which the stimulus is held in the reward zone for at least the minimum time is called a ‘stop trial’; see Materials and methods). To start the next trial mice had to bring the stimulus out of the posterior end of the monitor and continue running for some distance. To be most efficient in this task, mice had to continue running when the distractors appeared (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). To ensure that mice did not solve the task by using local differences in contrast between the two gratings, we varied the position of the stripes in the circular patch, i.e. the spatial phase of the grating, randomly. At the beginning of each trial the stimulus appeared at the anterior end of the monitor and was frozen (i.e. insensitive to the rotation of the treadmill) for 350 ms, after which time the stimulus could be moved by the locomotion of the mouse. This ensured reproducibility of stimulus position across trials in the initial 350 ms. Further, during the task the position of the eye varied little trial to trial during the initial 350 ms (the standard deviation of the position of the right eye over this interval across trials was 2.4 ± 0.6 degrees; mean ±std across five mice; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Mice learned to perform the task with accuracy above 85% correct in 23 ± 7 days (mean ±std; n = 15 wild type mice; <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>; accuracy is defined as the average of the percentage of stop trials upon target presentation and the percentage of non-stop trials upon distractor presentation; chance level is 50%) completing on average 200 ± 30 trials each day (transgenic mice, VGat-ChR2-EYFP, learned the task in 50 ± 20 days, n = 8 mice; difference in learning rates was significant: p=0.0096, Wilcoxon ranksum test, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.34044.002</object-id><label>Figure 1.</label><caption><title>A virtual foraging behavior that depends on visual cortex.</title><p>(<bold>A</bold>) Behavioral setup. The mouse is rewarded for stabilizing the target at the center of the monitor for about a second. (<bold>B</bold>) Example session for a trained mouse. <italic>Top.</italic> Grey lines are individual stimulus trajectories. Orange shaded area is the reward zone. Note different trajectories of target versus distractor stimuli. <italic>Bottom left</italic>. Distribution of the times spent in the reward zone for target (filled bars) and distractor stimuli (empty bars). <italic>Bottom right.</italic> The probability that mice place the object in the reward zone for at least the minimal time for reward (stop probability) depends on the identity of the grating. Here and further, error bars are 95% confidence intervals. (<bold>C</bold>) Behavioral setup as above but visual cortex (VC) is silenced before the appearance of the stimulus and for the duration of the trial on a randomly interleaved fraction of trials. (<bold>D</bold>) Behavioral performance depends on contralateral VC. Same conventions as in (<bold>B</bold>). <italic>Top.</italic> Example mouse. Stimulus trajectories during cortical silencing are in blue. This particular mouse systematically overshot the reward zone when centering the target and subsequently moved backwards to bring the target back in the reward zone. <italic>Bottom left.</italic> Distribution of times spent in reward zone. Black: control; Blue: VC silencing. <italic>Bottom right</italic>. Stop probability under control conditions (black) and during VC silencing (blue). Individual lines are individual mice (n = 3). (<bold>E</bold>) Behavioral performance is not affected by silencing ipsilateral VC. Same conventions as in (<bold>D</bold>). (<bold>F</bold>) V1 is not required to express the decision in a detection task. Mice trained with one stimulus only (the target) are rewarded for stabilizing it at the center of the monitor. <italic>Top, Bottom left.</italic> Example mouse. Stimulus trajectories during cortical silencing are in blue. Same conventions as (<bold>B</bold>). A blank is defined as the absence of a target at regularly spaced distances. <italic>Bottom right.</italic> Stop probability for two mice (individual lines).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig1-v1"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34044.003</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Eye movements in trained mice.</title><p>(<bold>A</bold>) Behavioral setup as in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. (<bold>B</bold>) Eye positions in an example session in a trained mouse. <italic>Top</italic>. Grey lines are individual stimulus trajectories. <italic>Bottom.</italic> Grey lines are horizontal positions of the right eye (pupil center) during individual stimulus presentations (<italic>Top</italic>). Zero degrees is the mean eye position. Note that the animal does not follow the stimulus with their gaze (following the initial 350 ms, when the stimulus was movable by the animal, the mean eye position remained very similar to the initial 350 ms: difference in medians: 0.3±0.4 degrees, mean ± std across 5 mice). (<bold>C</bold>) <italic>Top</italic>. Distribution of eye positions across trials during the task for the example session in A. Each trial, eye position was quantified as the average position over 0–350 ms relative to stimulus onset. Bin size is two degrees. <italic>Bottom</italic>. Distribution of eye positions outside of the task, during stimulus presentation used for receptive field mapping (measured immediately following the task; see Methods). Eye position was quantified as the average position over 350 ms time bins. Zero degrees corresponds to the same position as during the task. Note that, while eye position is more variable during receptive field mapping, the average eye position is similar. (<bold>D</bold>) Variability of eye positions in individual mice: variability of eye position during the task (SD Task), difference in the median eye position during receptive field mapping and during the task (Δ Median), and difference in variability of eye position during receptive field mapping and during the task (Δ SD). Different colors indicate different mice (n = 5, one session per mouse). Grey indicates example mouse in (<bold>B</bold>) and (<bold>C</bold>). Red circle and line indicates mean and SD across mice.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig1-figsupp1-v1"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34044.004</object-id><label>Figure 1—figure supplement 2.</label><caption><title>Learning curves for wild type and transgenic mice.</title><p>(<bold>A</bold>) Behavioral setup. (<bold>B</bold>) Probability of a correct choice for the different behavior sessions over the course of training for wild type mice (left, subset of mice trained for subsequent electrophysiology recordings, all mice shown in the main figures are included) and transgenic mice (right, subset of mice trained for subsequent optogenetic silencing or electrophysiology recordings, 8/9 mice shown in the main figures are included; for 1/9 mice the initial training data was corrupted). Sessions lasting &lt;10 min were excluded. Probability of a correct choice for a given session is the average of the probability of a correct choice in a 3-session sliding window centered on the shown trial. Individual lines are individual mice. (<bold>C</bold>) Distribution of the number of training sessions that it takes mice to reach an overall accuracy of 85% correct.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig1-figsupp2-v1"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34044.005</object-id><label>Figure 1—figure supplement 3.</label><caption><title>Reversible, rapid and complete silencing of V1.</title><p>(<bold>A</bold>) Experimental set up as in <xref ref-type="fig" rid="fig1">Figure 1C</xref>. (<bold>B</bold>) Distribution of the time from trough to peak in the average waveform of the action potential across single units (n = 3 mice). Single units are labelled as regular spiking (RS, black lines) or fast spiking (FS, red lines) depending on their time of trough to peak. (<bold>C</bold>) Reversible and complete silencing of V1. Top. Raster plots (each dot is an action potential) for three mice including all isolated single units (all layers) for trials under control conditions (no LED) aligned at stimulus onset. Bottom. Same as above but for trials with LED illumination. LED and control trials were randomly interleaved. LED onset was approximately at 120 ms after stimulus onset. (<bold>D</bold>) Firing rate of individual RS units computed from 130 ms to 1 s following stimulus onset under control conditions plotted against firing rate during LED illumination. (<bold>E</bold>) Rapid silencing of V1. Top. Raster plot (each dot is an action potential) for all RS units from all three mice for trials with LED illumination aligned at the time of LED onset. Bottom. Peri-event time histogram from all isolated single units (2 ms bins) for trials with LED illumination. Arrow indicates time when the firing rate drops to zero.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig1-figsupp3-v1"/></fig></fig-group><p>To determine whether visual cortex (VC) is required for this visual discrimination task, we used two approaches: optogenetic silencing to determine the impact of an acute and reversible perturbation and surgical lesions to establish the effect of an irreversible ablation. We silenced cortical activity by optogenetically activating cortical inhibitory neurons (<xref ref-type="bibr" rid="bib1">Atallah et al., 2012</xref>; <xref ref-type="bibr" rid="bib17">Lien and Scanziani, 2013</xref>; <xref ref-type="bibr" rid="bib23">Olsen et al., 2012</xref>) with a 1 mm optic fiber placed over the left primary visual cortex (V1) (i.e. contralateral to the visual stimulus) in transgenic mice (VGAT-mhChR2-YFP) that selectively express the microbial light activated cation channel Channelrhodopsin2 (ChR2) in inhibitory neurons (<xref ref-type="bibr" rid="bib41">Zhao et al., 2011</xref>) (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). In these mice, V1 activity could be completely, rapidly and reversibly silenced (see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>) with a delay of 8 ms after the onset of illumination by a blue LED (450–490 nm, <xref ref-type="bibr" rid="bib17">Lien and Scanziani, 2013</xref>; <xref ref-type="bibr" rid="bib23">Olsen et al., 2012</xref>). Cortical silencing started 76 ± 6 ms before the stimulus appeared (mean ±std across mice) and ended just after the stimulus had exited the monitor, and was performed on a third of the trials interleaved randomly. During silencing trials, the behavioral performance of mice was severely disrupted (51 ± 3% accuracy; n = 3 mice; <xref ref-type="fig" rid="fig1">Figure 1D</xref>). On these trials, mice either kept on running no matter whether the target or distractor was presented (e.g. <xref ref-type="fig" rid="fig1">Figure 1D</xref>) or, on a fraction of trials, they sufficiently slowed down to center the grating (i.e. stop trial) but did so indiscriminately for both stimuli (p&gt;0.16, Wilcoxon rank sum test on choice data; e.g. <xref ref-type="fig" rid="fig1">Figure 1D</xref>). Because the distinction between stop and non-stop trials is binary, i.e. based on a threshold duration that the stimulus spends in the reward zone, it is conceivable that while performing at or close to chance when silencing cortex, mice may still hold the target for a longer time than the distractor in the reward zone. For example, targets and distractors may both spend less than the threshold time in the reward zone and hence be categorized as non-stop trials yet the targets may spend a longer time than the distractor in the reward zone. This would imply the ability of the mouse to discriminate despite performing at chance according to the criteria of the task. An advantage of our task is that it can reveal differences in the animal’s behavior for target versus distractor that are not captured by the binary classification of stop versus non-stop trials. We thus verified that an ideal observer could not disambiguate the target from the distractor based on times spent by each of the two stimuli in the reward zone using receiver operating characteristic (ROC) analysis (see methods). The discrimination accuracy of the ideal observer was 55 ± 6% (mean ±std, n = 3 mice), hence very close to the actual performance of the task. (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). To exclude the possibility that the optogenetic silencing simply distracted the mice from performing the task, we silenced the right visual cortex (i.e. ipsilateral to the visual stimulus) (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). This manipulation resulted in no substantial impairment in the behavioral performance (88 ± 6% accuracy for LED trials versus 89 ± 6% for no LED trials; <xref ref-type="fig" rid="fig1">Figure 1E</xref>), thus showing that the impairment was specific to the visual cortex processing visual information in the contralateral hemifield.</p><p>We verified that silencing visual cortex did not affect the ability of mice to express the decision, that is, to place the stimulus at the center of the monitor. Mice were trained as above but with the target stimulus only. In other words, mice where trained to perform a simple detection rather than a discrimination task. The distance that mice had to run to start the next trial was randomly varied. On trials where the contralateral V1 was silenced, mice centered the target image almost as frequently as in control trials (<xref ref-type="fig" rid="fig1">Figure 1F</xref>) demonstrating that contralateral V1 is not required to express the decision.</p><p>Behavioral deficits resulting from acute perturbations of the activity of a given brain area may lead to incorrect interpretations relative to the actual role of that area for behavior (<xref ref-type="bibr" rid="bib24">Otchy et al., 2015</xref>), since following permanent lesions of said area animal’s behavior can recover without additional training (<xref ref-type="bibr" rid="bib13">Kawai et al., 2015</xref>). To further assess the necessity of VC in visual discrimination we trained mice to perform the visual discrimination task and, after they had reached proficiency (accuracy of 93 ± 7%, n = 4 mice), we surgically removed VC contralateral to the side of stimulus presentation (e.g. <xref ref-type="fig" rid="fig2">Figure 2A</xref>) and allowed the animals to recover for ten days post-surgery before behavioral testing. Lesioned animals performed at chance (p&gt;0.3, Wilcoxon rank sum test on choice data, n = 4 mice, <xref ref-type="fig" rid="fig2">Figure 2B</xref>). The impairment in behavioral performance was not due to the ten day interval from the last behavioral session because trained control animals experiencing even longer intervals between behavioral sessions remained proficient (accuracy of 80 ± 10%, <xref ref-type="fig" rid="fig2">Figure 2C</xref>). Furthermore the behavioral impairment was not due to either anesthesia or to some unspecific impact of surgery because proficiency was preserved after removing the ipsilateral VC (accuracy of 85%, n = 1 mouse, <xref ref-type="fig" rid="fig2">Figure 2B</xref>) or following anesthesia to perform craniotomy for physiological recordings (80 ± 10%, see results below). Taken together, these results show that this visual discrimination task requires visual cortex.</p><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.34044.006</object-id><label>Figure 2.</label><caption><title>Lesion of visual cortex disrupts behavior.</title><p>(<bold>A</bold>) Coronal brain sections showing the extent of lesion for an example mouse (black in (<bold>B</bold>) and (<bold>C</bold>), 100 µm sections, images of background fluorescence, see Methods for summary of all mice). Outline of the different brain areas is from the Paxinos and Franklin brain atlas (<xref ref-type="bibr" rid="bib25">Paxinos and Franklin, 2007</xref>). Distances are relative to bregma. The retinotopic location in V1 corresponding to the stimulus in the initial 350 ms is ~3 mm from bregma and 2.3 mm from midline. Note the absence of V1 (black). (<bold>B</bold>) Stop probability for the target and distractor stimulus when mice performed the task (<italic>left</italic>) just before the lesion of visual cortex (day 0) or the previous day (day −1) and (<italic>right</italic>) when mice performed the task 10 days after the lesion of visual cortex. Individual lines are individual mice. Each color represents the same mouse in all panels. All mice except the one displayed in grey had lesions in the left visual cortex (contralateral to the stimulus); the one in grey had a lesion in the right visual cortex. Error bars are 95% confidence intervals. (<bold>C</bold>) Stop probability for 3 of the mice in (<bold>B</bold>), (<italic>left</italic>) just before the gap in training (day 0), and (<italic>right</italic>) after the gap in training (day 17 or day 19 without training).</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig2-v1"/></fig></sec><sec id="s2-2"><title>Neurons in primary visual cortex report stimulus identity by 80 ms</title><p>To determine over what time interval stimulus evoked spiking activity in individual V1 neurons can be used to disambiguate the target from the distractor stimulus we recorded extracellular action potentials while the animals performed the task (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). We inserted a multichannel probe in V1 at the beginning of a behavioral session in trained mice (performance accuracy during recordings: 80 ± 10%, mean ± std; n = 9 mice). To ensure that the units were maximally excited by the stimulus, we placed the monitor so that the position of the stimulus in the initial 350 ms, when the stimulus is stationary, was superimposed on the multiunit spatial receptive field (center of stimulus was 2 ± 1 degrees from center of receptive field, mean ± std, n = 8 mice). Further, we compared the eye position during receptive field mapping (performed outside of the task) with the eye position during the task. While the animals moved their eyes more outside of the task than during the task (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), the median eye position during receptive field mapping and during the task was very similar (difference of 3 ± 1 degrees; mean ±std across five mice; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). For comparison, the size of the receptive field of an individual cortical neuron is 12–20 degrees (<xref ref-type="bibr" rid="bib21">Niell and Stryker, 2008</xref>). Thus, the position of the stimulus was well aligned with respect to the center of the receptive field. The cortical response to the visual stimulus began 40 ± 5 ms after stimulus onset (mean ±std across mice, <xref ref-type="fig" rid="fig3">Figure 3C</xref>) consistent with previous reports (<xref ref-type="bibr" rid="bib21">Niell and Stryker, 2008</xref>). The onset of cortical response was quantified as the earliest deflection in the local field potential that exceeded three standard deviations from baseline. We verified that the earliest deflection corresponded to layer 4 of V1, the major thalamo-recipient layer, based on current source density analysis (<xref ref-type="bibr" rid="bib21">Niell and Stryker, 2008</xref>) (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.34044.007</object-id><label>Figure 3.</label><caption><title>Individual neurons can discriminate within 80 ms from onset of cortical response.</title><p>(<bold>A</bold>) Experimental setup as in <xref ref-type="fig" rid="fig1">Figure 1A</xref> but with recording from primary visual cortex. (<bold>B</bold>) Responses of two example units recorded simultaneously. <italic>Top.</italic> Raster plot. Black dots are action potentials. <italic>Bottom.</italic> Peristimulus time histogram (PSTH). The number of action potentials per trial is calculated in 25 ms bins. (<bold>C</bold>) Estimation of the onset of cortical response. The onset of cortical response is defined for each mouse as the earliest deflection in the local field potential following stimulus onset. Dashed lines indicate three standard deviations from baseline. Black circles indicate onset of cortical response in nine mice. Red circle and line are the mean and standard deviation across mice. (<bold>D</bold>) Receiver operating characteristic (ROC) analysis for the two example units in (<bold>B</bold>). <italic>Top.</italic> Distribution of action potentials across trials for target (black bars) and distractor stimuli (white bars) at three different intervals after the onset of cortical response. <italic>Bottom.</italic> ROC curve for each graph on top. (<bold>E</bold>) Summary of areas under ROC for 72 units. Area under ROC for individual units (individual lines) depends on the interval from cortical onset. Black: example units in (<bold>C</bold>) and (<bold>D</bold>). For each unit at each interval starting at cortical response onset, statistical significance for the separation of the distributions of the number of action potentials for the target versus distractor was assessed using Wilcoxon ranksum test and the Benjamini-Hochberg correction for multiple comparisons (p&lt;0.012). (<bold>F</bold>) The fraction of discriminating units discriminating at a particular interval increases with increasing time from cortical response onset. A unit is defined as discriminating if by 300 ms p&lt;0.012. (<bold>G</bold>) Experimental set up as in (<bold>A</bold>) but stimulus position is always fixed, mouse is not rewarded, and the grating is drifting. Grey lines are orientation tuning curves for individual discriminating units preferring the target (top) or the distractor (bottom) during the task. Colored line is the mean across units. (<bold>H</bold>) The area under ROC over the initial 80 ms after cortical onset during the task is plotted against the difference in the number of action potentials in response to passively viewed stimuli of 45° and 90°. Circles are individual discriminating units (p&lt;0.012, Wilcoxon ranksum test) that prefer target (red) or distractor (black). R<sup>2</sup> is the fraction of the variance explained by the linear fit to the data.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34044.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Characterization of V1 recordings during behavior.</title><p>(<bold>A</bold>) Experimental setup as in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. (<bold>B</bold>) Average current source density for five mice (see Methods). Blue indicates current sinks; red indicates current sources. The top sink is layer 4. 40 ms indicates the average onset of the cortical response across mice (see <xref ref-type="fig" rid="fig3">Figure 3C</xref>). (<bold>C</bold>) Fraction of stimulus elicited spikes at different time intervals relative to 300 ms following onset of cortical response. Grey lines are individual discriminating units; black line is the mean. If a unit was suppressed below baseline, the value for spikes above baseline was set to zero. Vertical dotted line marks 80 ms. Right. Distribution of the fraction of stimulus elicited spikes at 80 ms following onset of cortical response for all discriminating units. By 80 ms discriminating units fire 25 ± 4% of the total spikes. (<bold>D</bold>) Distribution of the number of action potentials fired over the initial 80 ms following onset of the cortical response for discriminating units recorded from wild type mice (top, n = 5 mice) or VGAT-ChR2 mice (bottom, n = 4 mice). The two distributions are not significantly different (p=0.95, Wilcoxon rank sum test). Red circle and line through it indicate median and sem, respectively.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig3-figsupp1-v1"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34044.009</object-id><label>Figure 3—figure supplement 2.</label><caption><title>Tuning curves for units that do not discriminate.</title><p>(<bold>A</bold>) Experimental set up as in <xref ref-type="fig" rid="fig3">Figure 3A</xref> but the stimulus position is always fixed, mouse is not rewarded, and the grating is drifting. (<bold>B</bold>) Example hypothetical tuning curves for units that do not discriminate. Left. Peak of tuning curve is in the middle of distractor (45°) and target (90°; i.e. 67.5° and 157.5°).Middle. Narrow tuning curve with peak away from 45° and 90°. Right. Flat tuning curve. (<bold>C</bold>) Population tuning curves. Individual units (grey lines) were grouped according to their orientation selectivity index (OSI). Blue lines are the population mean.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig3-figsupp2-v1"/></fig></fig-group><p>To determine whether the spiking of an individual neuron allows an ideal observer to discriminate the target from the distractor stimulus we performed ROC analysis (<xref ref-type="bibr" rid="bib39">Tolhurst et al., 1983</xref>) on 72 well isolated units in nine behaving animals (<xref ref-type="fig" rid="fig3">Figure 3B,D–E</xref>; see Materials and methods for cell type and layer distribution). About half of the neurons (46%) discriminated the target from the distractor when their activity was integrated over a time window of 300 ms, starting at the onset the cortical response and ending just before the stimulus could be moved by the animal (<xref ref-type="fig" rid="fig3">Figure 3E</xref>) (p&lt;0.012, Wilcoxon ranksum test on spike counts across trials, Benjamini-Hochberg correction for multiple comparisons). Below we refer to these units as ‘discriminating units’. How early do discriminating units start discriminating? We performed ROC analysis at various intervals from the onset of the cortical response (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). The fraction of discriminating units increased rapidly between 40 and 80 ms (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). While at 40 ms after the onset of the cortical response only ~20% of the discriminating units discriminated the target from the distractor above chance, by 80 ms already ~50% of units did so with a median discrimination accuracy of 66% (range: 58–79%). The fraction of discriminating units discriminating increased more slowly following these initial 80 ms. By 300 ms (when, per definition, 100% of discriminating units are discriminating) they reached a median discrimination accuracy of 74% (range: 58–96%). Thus, already by 80 ms following the onset of the cortical response ~50% of discriminating units discriminate the target from the distractor.</p><p>To determine how well the orientation tuning curve of a neuron predicts its ability to discriminate we measured the tuning properties of discriminating neurons after the end of the behavioral session. We presented drifting gratings of twelve different orientations that had the same size and spatial frequency and were presented at the same location as the stimuli used during the task, yet they were not rewarded and their location was insensitive to the movement of the wheel (passive viewing; stimulus properties: 20°/s; 0.5 s; 15° steps; chosen in a random order; drifting in either of the two directions perpendicular to the grating’s orientation). Most discriminating units that preferred the target during the task showed a peak response to orientations larger than 90 degrees (109 ± 8 degrees, median ±SEM; n = 9, four mice; <xref ref-type="fig" rid="fig3">Figure 3G</xref>). Furthermore most discriminating units that preferred the distractor during the task, showed a peak response to orientations less than 45 degrees (30 ± 20 degrees, median ±SEM; <xref ref-type="fig" rid="fig3">Figure 3G</xref>; n = 8, four mice). Non-discriminating neurons had either very sharp tuning curves peaking far away from target and distractor orientations, or flat tuning curves, or tuning curves peaking in between the target and distractor orientation (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). We compared the difference in spike number in response to grating presented at 45 and 90 degrees during passive viewing with how well discriminating units distinguish the target from the distractor during the task. The difference in spike number during passive viewing correlated with the value obtained from ROC analysis over the initial 80 ms following the onset of cortical response during the task (R<sup>2</sup> based on linear fit: 0.35; <xref ref-type="fig" rid="fig3">Figure 3H</xref>).</p></sec><sec id="s2-3"><title>The threshold duration of V1 activity for perceptual discrimination limits most neurons’ firing to one or no spikes</title><p>What is the minimal duration of activity in visual cortex necessary for accurate visual discrimination? And how many action potentials are fired by individual neurons during this time? If by 80 ms from the onset of visually evoked cortical activity information about stimulus identity is available to an independent observer, it may also be available to the mouse. Thus, the minimal duration of visual cortical activity enabling discrimination may be around 80 ms.</p><p>To control the duration of the visually evoked cortical response we optogenetically silenced visual cortex, as described above, at varying intervals after the onset of the response (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). In each experiment we ensured that the LED intensity was sufficiently high such that performance accuracy was at chance when the illumination started before the stimulus appeared (p&gt;0.05, Wilcoxon ranksum test on choice data, n = 8 mice). Furthermore, as above, for each animal we verified that despite chance performance the hold times of the stimulus in the reward zone of the monitor did not differ between target and distractor stimulus (p&gt;0.05, Wilcoxon ranksum test on stimulus centering times in the reward zone). We verified this again at the very end after testing all LED onset intervals.</p><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.34044.010</object-id><label>Figure 4.</label><caption><title>It takes visual cortex 80 ms to enable perceptual discriminations.</title><p>(<bold>A</bold>) <italic>Left</italic>: Experimental setup. <italic>Right</italic>: Arrows indicate the onset of LED illumination. Each interval was tested in separate behavioral sessions. (<bold>B</bold>) Example mouse. Stimulus trajectories during cortical silencing (blue) and under control conditions (gray) for three different LED illumination onset latencies (40 ms; 80 ms; 300 ms) relative to the onset of the cortical response. Individual lines are individual trials. (<bold>C</bold>) Summary of stopping probability for eight mice. Black: control; Blue: cortical silencing. Times indicate the LED illumination onset after onset of the cortical response. Individual lines are individual mice. Error bars are 95% confidence intervals. Note that behavioral performance during cortical silencing increases with increasing LED onset. (<bold>D</bold>) Probability of a correct choice during cortical silencing (blue) depends on the onset of LED illumination relative to the onset of the cortical response. Individual lines are individual mice. Black circles indicate probability correct for individual mice for trials with no cortical silencing.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig4-v1"/></fig><p>The accuracy of the behavior increased with increasing interval between the onset of the cortical response to the stimulus and the onset of cortical silencing (<xref ref-type="fig" rid="fig4">Figure 4B,C</xref>). When cortical silencing followed the onset of cortical response by 44 ± 6 ms the performance was close to chance (54 ± 5%; mean ±std across mice, <xref ref-type="fig" rid="fig4">Figure 4D</xref>), similar to when the LED onset preceded stimulus presentation (51 ± 3%; mean ±std across mice). Strikingly, however, when cortical silencing was delayed by a further 40 ms, hence with a latency of 80 ms after the onset of the cortical response, performance accuracy of the animals sharply increased to 76 ± 7% (mean ±std across mice). Performance accuracy continued to increase, yet less sharply, over the longer intervals tested reaching 92 ± 5% when the LED onset followed the onset of the cortical response by 300 ms (mean ±std across mice). With this interval the animals performed similarly to control conditions, in the absence of LED illumination (94 ± 2%; mean ±std across mice). Thus, there is a sharp increase in performance when visual cortex is allowed to function between 44 and 80 ms after the onset of the cortical response. As above, we used ROC analysis to compare behavioral performance with the ability of an ideal observer to disambiguate the target from the distractor based on times spent by each stimulus in the reward zone when silencing cortex at 44 ms following the onset of the cortical response. The discrimination accuracy of the ideal observer was 54 ± 7%, hence very close to the actual performance of the task at 44 ms (54 ± 5%). These results show that the minimal duration of visually evoked activity in V1 for an animal to perform the present task above chance lies between 40 and 80 ms.</p><p>If the estimated time window indeed approximates the threshold duration of V1 activity for perceptual discrimination, performance accuracy in trials when V1 is active for only 80 ms should be very sensitive to the difficulty of the task. We thus trained mice to discriminate a narrower angle difference between target and distractor, namely 15 degrees. Mice were first trained to perform the standard 45 degrees discrimination task and their behavioral performance measured across various intervals of cortical silencing, as above. We then re-trained those same animals to discriminate a target from a distractor separated by 15 degrees until they reached a similar level of proficiency as for the 45 degrees task (accuracy of 90 ± 4% for 15 degrees versus accuracy of 93 ± 2% for 45 degrees, mean ±std, n = 3 mice, <xref ref-type="fig" rid="fig5">Figure 5B</xref>). We silenced the cortex of these animals at various intervals following the onset of the cortical response and compared the decrease in performance between the 45 and the 15 degrees discrimination tasks. Silencing cortex at 80 ms after the onset of the cortical response reduced performance significantly more for the 15 degrees as compared to the 45 degrees discrimination task in all animals (p&lt;0.05, Wilcoxon ranksum test on choice data, n = 3 mice <xref ref-type="fig" rid="fig5">Figure 5B,C</xref>). While silencing V1 80 ms following the onset of the cortical response still enabled the 15 degrees discrimination to occur above chance (p&lt;0.02, Wilcoxon ranksum test on choice data, n = 3 mice), the accuracy was significantly lower than for 45 degrees discrimination (p&lt;0.02, Wilcoxon ranksum test on choice data, n = 3 mice, <xref ref-type="fig" rid="fig5">Figure 5B,C</xref>). This difference cannot be accounted for simply by a difference in motivation or in control performance because in two out of three mice, non-LED trials during the 15 degrees discrimination task were as accurate as non-LED trials during the 45 degrees discrimination task (Wilcoxon ranksum test on choice data, p=0.65 and 0.67, <xref ref-type="fig" rid="fig5">Figure 5B</xref>). Thus, these experiments demonstrate that the time between 40–80 ms following the onset of the cortical response indeed captures the threshold duration of V1 activity for a simple perceptual discrimination.</p><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.34044.011</object-id><label>Figure 5.</label><caption><title>Discrimination accuracy when V1 is active for only 80 ms is sensitive to the difficulty of the task.</title><p>(<bold>A</bold>) Experimental setup as in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. (<bold>B</bold>) Probability of a correct choice for (<italic>top</italic>) control trials and for (<italic>bottom</italic>) trials with cortical silencing for three mice first trained in the main task (blue, target: 90°, distractor: 45°) and then in the harder discrimination task (red, target: 60°, distractor: 45°). Error bars are 95% confidence intervals. Asterisks indicate significant difference in the choice accuracies in the two tasks (p=0.001–0.018, Wilcoxon ranksum test on choice data). (<bold>C</bold>) Stop probability for the target stimulus (<bold>T</bold>) and the distractor stimulus (<bold>D</bold>) for two intervals from (<bold>B</bold>), <italic>left,</italic> when cortex is silenced at 80 ms or, <italic>right</italic>, 140 ms following onset of cortical response.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig5-v1"/></fig><p>Over these initial 80 ms from the onset of the cortical response discriminating units in primary visual cortex fired only 25 ± 4% of all the spikes fired above baseline during the 300 ms window (mean ±sem across units, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1D</xref>). During this 80 ms interval discriminating units fired 0.6 ± 0.1 (median ±SEM across units) action potentials in response to their preferred stimulus (<xref ref-type="fig" rid="fig6">Figure 6F</xref>, response not different for the wild type and the transgenic mice as shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>), corresponding to a firing rate of 7.5 Hz, and 0.22 ± 0.06 action potentials for their non-preferred stimulus. Furthermore, in response to their preferred stimulus, discriminating units fired only one or no action potential in 80% of the trials and two action potentials in only 11% of the trials (<xref ref-type="fig" rid="fig6">Figure 6E</xref>), similar to what is expected by Poisson statistics (% of variance explained across units: R<sup>2</sup> = 97 ± 5%, median ±SEM; median time until first action potential: 70 ± 10 ms and 80 ± 20 ms from the onset of the cortical response for the preferred and non-preferred stimulus, respectively (median ±SEM across units; analysis performed over the initial 300 ms from the onset of the cortical response, <xref ref-type="fig" rid="fig6">Figure 6C</xref>); mean latency difference: 12 ± 6 ms (mean ±sem across units; p=0.03; t-test; <xref ref-type="fig" rid="fig6">Figure 6D</xref>)). Thus, over the initial 80 ms from the onset of the cortical response the vast majority of discriminating units in primary visual cortex get to fire either one or no action potentials.</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.34044.012</object-id><label>Figure 6.</label><caption><title>Neurons usually fire only their first action potential in the initial 80 ms.</title><p>(<bold>A</bold>) Experimental setup as in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. (<bold>B</bold>) Raster plot (APs, black dots) for an example unit for preferred (<italic>left</italic>) versus the non-preferred stimulus (<italic>right</italic>). Red circles indicate the first AP in each trial after the onset of the cortical response. (<bold>C</bold>) The distribution of times of the first AP for individual discriminating units (grey circles, time bins of 20 ms) for those trials in which the first AP occurred within the initial 300 ms following the onset of the cortical response, for (<italic>left</italic>) the preferred and (<italic>right</italic>) the non-preferred stimulus. Black line is the mean across units. Red circle and line through are the median and SEM, respectively. (<bold>D</bold>) Mean of times of the first AP across trials for individual discriminating units (circles; same trials and window as in C) plotted for the preferred stimulus versus the non-preferred stimulus. <italic>Top.</italic> Distribution of the mean times for the preferred stimulus. <italic>Right</italic>. Distribution of the mean times for the non-preferred stimulus. Red circle and line through are the median and SEM, respectively. <italic>Right panel.</italic> Distribution of the difference in the mean time of the first AP for the preferred and the non-preferred stimulus for all discriminating units. Red circle and line through are the median and SEM, respectively. (<bold>E</bold>) The distribution of the number of APs across trials for the preferred stimulus for the initial 80 ms after cortical onset for (<italic>left</italic>) the example unit in (<bold>B</bold>) and for (<italic>right</italic>) all discriminating units approximates a Poisson distribution predicted from the mean number of APs (red line). (<bold>F</bold>) <italic>Left panel.</italic> The distribution of the number of action potentials (mean across trials) across discriminating units is shown for the preferred stimulus over the initial 80 ms (black) and 300 ms (grey). Last bin also includes units that fired more than 5 APs. Circle and line through are the median and SEM, respectively. <italic>Right panel.</italic> The number of APs (mean across trials) for individual discriminating units (circles) for the preferred versus the non-preferred stimulus over the initial 80 ms (black) and the initial 300 ms (grey). (<bold>G</bold>) Area under ROC for individual units (individual lines), based only on the first AP after cortical onset on each trial plotted against the interval from the onset of the cortical response. Statistical significance was assessed same as in <xref ref-type="fig" rid="fig3">Figure 3E</xref>. (<bold>H</bold>) Fraction of discriminating units discriminating depends on the interval from cortical onset. A unit is defined as discriminating if by 300 ms p&lt;0.013.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig6-v1"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.34044.013</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Comparison of neural and behavior discrimination.</title><p>(<bold>A</bold>) Experimental setup as in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. (<bold>B</bold>) Area under ROC curve as a function of time from cortical onset for a 'pooling neuron', which for each trial has all the spikes of N units that are randomly drawn from a pool of all discriminating units (see Methods). Each line is the average of the areas under ROC for 10 different pools of discriminating units. Errorbars are sem. For each area under ROC curve, at each interval, statistical significance for the separation in the distribution of number of action potentials for the target versus the distractor was assessed using Wilcoxon ranksum test (p&lt;0.05). f is at each time interval the fraction of 'pooling neurons' with p&lt;0.05. Blue line is the average probability of a correct choice for all the mice in <xref ref-type="fig" rid="fig4">Figure 4D</xref>. (<bold>C</bold>). Same as B but for all units.</p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-34044-fig6-figsupp1-v1"/></fig></fig-group><p>To determine whether indeed the first action potential in response to a stimulus is sufficient to discriminate the target from the distractor we performed ROC analysis (<xref ref-type="fig" rid="fig6">Figure 6G</xref>) after removing from each unit all but the first action potential after the onset of the cortical response. As above we performed this analysis for various intervals from the onset of the cortical response. The first action potential was sufficient for ~33% of units to discriminate by 300 ms (compared to 46% if all the action potentials were available), and more than half of those units (54%) could discriminate above chance at 80 ms (<xref ref-type="fig" rid="fig6">Figure 6H</xref>). Thus for most units the first action potential substantially contributes to their ability to discriminate within the initial 80 ms after the onset of the cortical response.</p><p>Finally, the accuracy of the behavioral response during the initial 80 ms can be explained by pooling the activity of ~5 discriminating neurons on average (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref>), or ~20 neurons if non-discriminating neurons are also included in the pool (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C</xref>).</p><p>Taken together, these results show that the threshold duration of visually evoked cortical activity for a simple visual discrimination lies between 40 and 80 ms, a time window during which most individual cortical neurons get to fire one or no spike.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have developed a visual discrimination task that necessitates visual cortex because both acute cortical silencing and permanent ablation reduces performance of the task to chance. By silencing visual cortex at various intervals following the onset of the cortical response we show that the lower temporal limits of visually evoked activity for a perceptual discrimination lie within 40–80 ms. The impact on behavioral performance when silencing visual cortex during this time window is particularly sensitive to the difficulty of the task. Importantly, during this initial 80 ms window, most of the neurons in primary visual cortex that disambiguate the identity of the stimulus fire either none or one action potential.</p><p>The simple detection of a stimulus can be reported by an animal in response to direct cortical stimulation eliciting not more than one action potential in individual neurons (<xref ref-type="bibr" rid="bib10">Histed and Maunsell, 2014</xref>). Stimulus discrimination via cortical stimulation, on the other hand has been reported only in response to repetitive stimulation eliciting series of action potentials (<xref ref-type="bibr" rid="bib35">Romo et al., 1998</xref>). We show that mice can discriminate visual stimuli even when most neurons in visual cortex are prevented from firing more than their first action potential. Thus, the first sensory evoked spikes of mouse visual cortical neurons are sufficient to drive downstream areas for a reliable execution of the task. This highlights the ability of cortical areas to instruct downstream targets with only a fraction of their neurons firing a single spike. Similar findings about the essential role of the first spikes have been reported in the early olfactory system (<xref ref-type="bibr" rid="bib31">Resulaj and Rinberg, 2015</xref>; <xref ref-type="bibr" rid="bib40">Wilson et al., 2017</xref>). However, our data also clearly show that extending this time window increases (i) the animal’s behavioral performance, (ii) the ability of an ideal observer to disambiguate the stimulus based on the spiking of individual neurons, and (iii) the fraction of neurons that can be used to disambiguate. Extending the time window not only gives more neurons the opportunity to fire their first spike (<xref ref-type="fig" rid="fig6">Figure 6C,D</xref>), but also enables second and third visually evoked spikes to contribute to the discriminability of the stimulus (compare <xref ref-type="fig" rid="fig6">Figure 6G</xref> with <xref ref-type="fig" rid="fig3">Figure 3E</xref>). The extent of this time window for sensory processing is consistent with observations in somatosensory cortex performed during cortical silencing in a detection task (<xref ref-type="bibr" rid="bib36">Sachidhanandam et al., 2013</xref>).</p><p>The ability for a neuron to disambiguate two stimuli with only one or no spike depends on how distinct the response of that neuron is for those stimuli and on the trial to trial variability of its responses (<xref ref-type="fig" rid="fig3">Figure 3G,H</xref>). In mice, visual cortical neurons have orientation tuning functions with relatively broad half widths at half max averaging 30–40 degrees. Given the large trial to trial variability of visually evoked responses in cortical neurons, one may expect that as the difference in orientation between the target and distractor stimuli become narrower, and the overlap in the responses of individual neurons to different stimuli increases, more spikes per neurons, or more neurons spiking may be necessary to disambiguate the stimuli. As a consequence visual cortex may need longer than 80 ms. Consistent with this, our results show that animals trained to perform equally well on a 45 and 15 degrees difference discrimination task, are significantly more impaired on the 15 degrees discrimination task when limiting V1 activity to 80 ms.</p><p>Prior work has investigated the minimal time window needed by an outside observer to extract stimulus information from the neuronal activity of an area (<xref ref-type="bibr" rid="bib4">Celebrini et al., 1993</xref>; <xref ref-type="bibr" rid="bib20">Mazurek and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib38">Shadlen and Newsome, 1998</xref>). How does the minimal time window needed by an outside observer relate to the minimal time window that is sufficient to enable a perceptual discrimination? Our analysis shows that an independent observer accumulating spikes from around 100 neurons preferring the same stimulus would reliably discriminate the target from the distractor within the initial 30 ms from the onset of the cortical response (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref>). Because mice discriminate at chance when visual cortex is only active for 40 ms, the minimal time window that downstream areas necessitate to extract sufficient stimulus information is longer than the minimal time window necessitated by an independent observer. This suggests that downstream areas integrate spikes over longer periods than strictly necessary which may either be due to having to overcome noise (<xref ref-type="bibr" rid="bib20">Mazurek and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib38">Shadlen and Newsome, 1998</xref>) or unrelated changes, or having to first reconfigure population activity before stimulus information can be integrated. Yet other explanations are possible. Investigating these possibilities will require future identification of downstream areas involved in the task and recordings of neural activity from these areas while visual cortex is silenced. It must also be stated that the time window for the independent observer might be slightly underestimated because neurons were pooled from different experiments and thus the weak correlated noise which exists in simultaneously active neurons, and cannot be averaged out by pooling to increase the signal to noise ratio (<xref ref-type="bibr" rid="bib42">Zohary et al., 1994</xref>), is slightly reduced.</p><p>What is the role of visual cortex in perceptual discrimination? Visual cortex is not necessary for all visually guided behaviors in rodents. Several experiment have demonstrated that animals can still perform visually guided behavior even following the silencing or ablation of visual cortex suggesting the involvement of subcortical areas (<xref ref-type="bibr" rid="bib8">Glickfeld et al., 2013</xref>; <xref ref-type="bibr" rid="bib16">Liang et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Petruno et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Prusky and Douglas, 2004</xref>). These behaviors however, are either innate or, when learned, enable simple stimulus detection rather than discrimination tasks. Some of these subcortical visual areas may indeed enable our mice to place the stimulus in the center of the monitor while the cortex is silenced, yet other strategies are also possible. At a finer scale, some of our mice showed a bias in the fine positioning of the stimulus within the center of the monitor while the cortex was silenced compared to the non-silenced trials (<xref ref-type="fig" rid="fig1">Figure 1F</xref> and <xref ref-type="fig" rid="fig4">Figure 4B</xref>). The reason for this effect is unclear and may depend on the strategy used by our mice to place the stimulus in the center of the monitor while contralateral V1 is silenced. Although we show that visual cortex is required to enable discrimination, consistent with recent work (<xref ref-type="bibr" rid="bib12">Jurjut et al., 2017</xref>; <xref ref-type="bibr" rid="bib28">Poort et al., 2015</xref>), one may debate whether visual cortex plays an instructive role by providing information disambiguating the target from the distractor to downstream areas or simply a permissive role by regulating the overall excitability of those downstream areas (<xref ref-type="bibr" rid="bib24">Otchy et al., 2015</xref>). We show that permanent ablation of V1 in trained animals reduces task performance to chance levels even ten days following the lesion. This result differs from what is observed after lesioning motor cortical areas on specific motor tasks (<xref ref-type="bibr" rid="bib13">Kawai et al., 2015</xref>). While acute silencing of these motor cortical areas impairs behavior, following permanent ablation of these same areas behavior is regained within a few days without further training (<xref ref-type="bibr" rid="bib24">Otchy et al., 2015</xref>). As a consequence these motor areas are considered permissive rather than instructive for the execution of the behavior (<xref ref-type="bibr" rid="bib24">Otchy et al., 2015</xref>). Instead, given the absence of recovery, our ablation results are consistent with an instructive role of V1. Clearly, we cannot exclude the possibility that the hypothetical area downstream of V1 simply does not recover its original excitability without V1. However, the fact that on the one hand the animal behaves at chance upon silencing cortex before the stimulus presentation, rather than being only partially impaired, and on the other hand that just 80 ms of activity are sufficient to almost completely recover the behavior is further evidence, in our opinion, for an instructive role of visual cortex. The sufficiency of a sensory cortical area to elicit a perceptual decision has been demonstrated for the somatosensory (<xref ref-type="bibr" rid="bib22">O'Connor et al., 2013</xref>; <xref ref-type="bibr" rid="bib35">Romo et al., 1998</xref>) and taste (<xref ref-type="bibr" rid="bib26">Peng et al., 2015</xref>) systems and controlled perturbations of visual areas has been shown to affect decision (<xref ref-type="bibr" rid="bib37">Salzman et al., 1990</xref>) in a predictable manner. The ability to artificially recapitulate the pattern of cortical activity elicited by a visual stimulus through direct cortical activation will eventually provide a definite answer (<xref ref-type="bibr" rid="bib11">Häusser and Smith, 2007</xref>).</p><p>It is not clear whether our findings may generalize to the phenomenon of visual masking in which a second stimulus presented shortly after the first may render the first stimulus less visible or invisible. The neural mechanisms underlying visual masking, that is how added activity from two stimuli generates the perceptual illusion of masking, are not well understood (<xref ref-type="bibr" rid="bib3">Breitmeyer, 2008</xref>; <xref ref-type="bibr" rid="bib19">Macknik and Livingstone, 1998</xref>). In the current study we address the simpler and more basic question of the minimal duration of activity in response to a single stimulus still able of triggering a perceptual decision. Indeed there are clear differences between visual masking and the optogenetic approach used here: First, our approach silences neuronal activity while visual masking adds activity (<xref ref-type="bibr" rid="bib19">Macknik and Livingstone, 1998</xref>). Second, our approach is area specific while visual masking impacts the whole visual system. Finally, we can silence visual cortex after most neurons have fired one or no spikes in response to the visual stimulus while, during visual masking experiments, even the just perceivable stimuli elicit multiple spikes (<xref ref-type="bibr" rid="bib14">Kovács et al., 1995</xref>; <xref ref-type="bibr" rid="bib15">Lamme et al., 2002</xref>; <xref ref-type="bibr" rid="bib34">Rolls et al., 1999</xref>). Future experiments using optogenetic approaches may help us understand the neuronal mechanisms underlying the perceptual illusion of visual masking.</p><p>We have provided direct evidence for the minimal amount of time that it takes visual cortex to process visual information in order to enable a perceptual decision and determined the neuronal activity that occurs during that period. The speed at which humans are able to discriminate visual stimuli has led to the suggestion that processing of the visual stimuli can be accomplished with individual neurons in each of the relevant brain areas firing either none or one action potential. This work demonstrates that a period of activity in mouse primary visual cortex during which most neurons fire none or one action potential is indeed sufficient to enable perceptual discrimination. Future work will elucidate which downstream brain areas read out these first essential spikes generated in V1.</p><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-34044-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.34044.014</object-id><label>Video 1.</label><caption><title>Video of a trained mouse performing the task.</title><p>The mouse is rewarded with water for stabilizing the target (90 degree grating) in the center of the monitor. There is no reward or punishment for the distractor (45 degree grating). The speed of the stimulus is proportional to the running speed. Note that the stimulus is frozen (i.e. insensitive to the rotation of the treadmill) for 350 ms following its appearance.</p></caption></media></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>All experimental procedures were approved by the University of California San Diego Animal Care and Use Committee (protocol number S02160M). Mice were on a 12 hr light/dark cycle, lights on at eight pm. Training and experiments were performed during the dark cycle. Mice were single-housed. Data were collected from C57BL6 mice (Charles River Laboratories) or for optogenetic silencing, VGat-ChR2-EYFP mice, which have ChR2 targeted to the <italic>Slc32a1</italic> locus (Jackson Laboratories; stock number: 014548). All mice were male and adults (2–5 months old) at the start of experiments.</p></sec><sec id="s4-2"><title>Surgery</title><p> <italic>Headbar implantation:</italic> Each animal was implanted with a custom made headbar for head-fixation. Briefly, animals were anesthetized with 2.5% isoflurane. Body temperature was controlled by a thermal blanket connected to a rectal thermometer (FHC; DC Temperature Controller). To expose the skull, the skin and periosteum were removed. The gap between the edge of the skull and skin was sealed with Vetbond (Fisher Scientific). The headbar was affixed to the skull with Krazy glue. Dental cement (Lang Dental; Ortho-Jet BCA) was mixed with black ink and applied to reinforce the affixation of the headbar. Animals were allowed to recover for at least 3 days before the start of water restriction (1 ml/day). <italic>Craniotomy</italic>: On the day before the extracellular recording, animals were anesthetized as above and a craniotomy was made over V1 (size: 400 µm x 1 mm, anterioposterior x mediolateral, center approximately 2.3 mm from midline and 1.3 mm from lambdoid suture). At the end of the craniotomy, to protect the brain the craniotomy was covered with a drop of artificial cerebrospinal fluid (ACSF; 142 mM NaCl, 5 mM KCl, 10 mM D-glucose, 10 mM Hepes, 3.1 mM CaCl2, 1.3 mM MgCl2) and Kwik-Cast (WPI). <italic>Cortical Ablation:</italic> The animals were anesthetized as above. Using stereotaxic coordinates the outline of visual cortex (from Paxinos and Franklin mouse brain atlas (<xref ref-type="bibr" rid="bib25">Paxinos and Franklin, 2007</xref>)) was marked at the surface of the skull. Using a dental drill (700 µm) the area of visual cortex was thinned and removed. Sterile PBS was used to hydrate the exposed brain area. A cut of 1 mm depth was performed around the outline of VC using a microsurgical blade (FST). The cortical tissue was removed using a spoon shaped microsurgical blade (FST 10317–14). The area was washed with PBS to remove blood and consequently covered with Silicon Kwik-Cast (WPI). Upon polymerization a layer of cyanoacrylate glue was applied to cover the lesioned area. An additional layer of dental cement was applied to permanently cover the lesioned site.</p></sec><sec id="s4-3"><title>Behavioral setup</title><p>A schematic of the setup is shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. Mice ran on a custom made flat transparent disc, or wheel (diameter: 15 cm). The wheel was mounted on the shaft of a rotary encoder (MA3-A10-125-B, US Digital), which provided an analog output voltage proportional to the absolute shaft position. The encoder was mounted via an adaptor to a small Noga arm (MSC; part number: 09560459). Data were acquired with a National Instruments data acquisition board (NI USB-6009). To deliver water (~10 µl/reward) we used gravitational flow under the control of a solenoid valve (NResearch; Model 161K011; valve driver: CoolDrive). The valve was connected to a lickspout (hypodermic tubing; gauge 14) via Tygon tubing (1/16 inch ID).</p><p>Visual stimulation. Visual stimuli were presented on an LCD monitor (20.5 × 11.5 inches, 1920 × 1080 pixels, 60 Hz refresh rate, gamma corrected mean background luminance: 47 cd/m<sup>2</sup> for optogenetic silencing for 6 mice and 120 cd/m<sup>2</sup> for two mice, and 110 cd/m<sup>2</sup> for electrophysiology). The anterior edge of the monitor was positioned 25 cm from the right eye and the monitor subtended 50 degrees to 150 degrees of the visual field. The monitor was placed on the right side of the animal such that the antero-posterior body axis had a 15 degrees angle relative to the horizontal axis of the monitor with the axes converging rostrally. During the recording, the monitor was moved slightly so that the stimulus when stationary, i.e. in the first 350 ms (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), overlapped with the multiunit spatial receptive field (see ‘Extracellular Electrophysiology’). To quantify how well the stimulus was centered relative to the center of the receptive field, at the end of the recording session we presented black and white squares of 3.6° in a grid of 9 × 9 locations (one stimulus at a time) covering the whole stimulus area for four mice and squares of 6° in a 5 × 5 grid for four mice. The stimuli were generated using PsychToolbox (<xref ref-type="bibr" rid="bib2">Brainard, 1997</xref>) and custom written software in Matlab (Mathworks; code written by Shawn Olsen and available at <ext-link ext-link-type="uri" xlink:href="https://github.com/aresulaj/ResRueOlsSca18">https://github.com/aresulaj/ResRueOlsSca18</ext-link>; Behavior visual stimulation code and Passive visual stimulation code; <xref ref-type="bibr" rid="bib32">Resulaj, 2018</xref>. Copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/ResRueOlsSca18">https://github.com/elifesciences-publications/ResRueOlsSca18</ext-link>).</p><p>For the behavioral task, stimuli were circular patches of static sinusoidal gratings (spatial frequency: 0.146 cycles/degree, diameter: ~30°, contrast: 50%). On each trial, the spatial phase of the grating was chosen randomly out of 7 evenly spaced phases. We monitored the timing of stimulus onset by placing a photodiode (response time 15 ns; PDB-C156-ND; Digikey) at the bottom anterior part of the monitor, where a white square appeared concurrently with the stimulus after a 5 ms delay (accounted for in our analysis). The horizontal motion of the stimulus was controlled by the running of the animal, and updated at ~20 Hz (monitor refresh rate: 60 Hz). The gain, defined as stimulus displacement on the monitor (cm)/running distance (cm) varied from 0.3 to 0.6 across animals depending on how fast each animal ran (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). The distance between two consecutive stimuli in the track was 1.25 times the width of the monitor.</p><p>For the recording sessions, the spatial phase of the grating was constant and did not vary trial to trial. During passive viewing (<xref ref-type="fig" rid="fig3">Figure 3G,H</xref> and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), the stimuli had the same size and spatial frequency and were presented at the same location as the stimuli used during the task during the initial 350 ms, yet the stimuli were not rewarded and their location was insensitive to the movement of the wheel (passive viewing). We presented drifting gratings of twelve different orientations (3 Hz thus 20 degrees/s; 0.5 s; 15<sup>o</sup> steps; chosen in a random order; drifting in either of the two directions perpendicular to the grating’s orientation). The duration of the inter trial grey screen was 0.75 s. We presented ~30 repetitions/direction. The size and spatial frequency of the stimulus as projected on the retina will vary depending on its position on the monitor. However data on electrophysiological recordings only report activity for a specific position of the stimulus on the monitor, when the stimulus is fixed. This position is the same for stimuli presented during the task and during passive viewing.</p></sec><sec id="s4-4"><title>Monitoring of eye movements using infrared video-oculography</title><p>Eye movements were monitored as previously described (<xref ref-type="bibr" rid="bib18">Liu et al., 2016</xref>). Briefly, we used a high speed infrared (IR) camera (Imperx IPX-VGA 210; 200 Hz) to capture the reflection of the right eye on an IR mirror (Edmund Optics #64–471). Images were acquired using National Instruments PCI-6036E and custom written software in LabVIEW (National Instruments). Requests for eye tracking code should be addressed to Satoru Miura (Satoru.Miura@ucsf.edu), who wrote the code and kindly shared it with us. The pupil was identified by thresholding the pixel values. The eye position was quantified as the distance between the center of the pupil and the center of the corneal reflection of a reference IR LED placed above the camera along the optical axis of the camera. The position was calibrated by swinging the IR LED and the camera by ±10 degrees along a circumference centered on the image of the eye. Because eye movements impair the calibration and our mice move their eyes less during the task than outside of the task, (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) the calibration was performed for each mouse during the behavioral task the day before the measurement were taken. Following calibration, the camera was locked in place.</p></sec><sec id="s4-5"><title>Photo-activation of cortical interneurons to silence V1</title><p>An optical fiber (1 mm) coupled to a blue LED (470 nm; Doric Lenses) was placed over V1 above the intact skull covered with a thin layer of Krazy glue. The fiber was placed at approximately the retinotopic location corresponding to the stimulus during the initial 350 ms in the task: ~2.3 mm from midline and ~1.3 mm from lambdoid suture. To find these coordinates, we recorded multiunit activity in V1 with the monitor in the same position as during optogenetic silencing (monitor was moved &lt;15 degrees to center the spatial receptive field of the multiunit activity). We used these same approximate coordinates for all of our recordings.</p><p>For each animal, the total power was increased until the performance was at chance level when the LED illumination started before the stimulus appeared (3.3–20 mW across animals; p&gt;0.05; Wilcoxon ranksum test on stimulus centering times in the reward zone). To turn the LED on at specific delays after stimulus onset, the photodiode signal detecting the onset of the stimulus was sent to an amplifier (Newark; TWLUX - TW-MF2CAB) and then to an external microprocessor (Mega 1280; Arduino). The microprocessor waited for the amplified photodiode signal to cross a threshold before sending out a digital trigger to the LED driver (Thorlabs). The jitter (s.d.) of the LED onset was 4 ms.</p></sec><sec id="s4-6"><title>Behavioral training</title><p>Training began after animals had been on water restriction for at least 7 days (~1 ml water/day). During training, mice were kept at 80% or above of their initial body weight. Additional water was provided if the body weight fell below 80% of the initial weight. The initial behavioral parameters were: 100% contrast, gain (gain = stimulus displacement in the monitor (cm)/running distance (cm)): 0.6, hold time (minimal time in reward zone for a reward): 0.2 s. With these parameters, mice would get a water reward every time a new target stimulus would pass the reward zone, that is, as long as they kept running. After mice began to run consistently (one to a few sessions), the gain was decreased to 0.45 and the hold time was initially increased to 0.4 s to get the first ~10 rewards each session (i.e. during the warm up period) and then increased to 0.9 s. Mice learned to perform the task, that is to hold the target in the reward zone for at least the minimal hold time for a reward, but not the distractor, with accuracy &gt;85% in 23 ± 7 days (mean ±std; n = 15 wild type mice) completing on average 200 ± 30 trials each day (transgenic mice learned the task in 50 ± 20 days, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Over this period, if mice were running too fast and not stopping on a substantial fraction of targets, the gain was decreased (lowest value: 0.3). Conversely, if mice were stopping on a substantial fraction of distractors, the hold time was increased (up to a value of 1.5 s). After mice achieved ~85% accuracy, stimulus contrast was decreased to 50%. Mice easily generalized to stimuli of 50% contrast.</p><p>The animal’s discrimination accuracy based on the binary classification of stop versus non-stop trials could be lower than that of an ideal observer monitoring the time that the stimulus spends in the reward zone. This could be the case if, for example, on some target trials the mouse slows down more than it would for a distractor trial but not sufficiently so for the target to spend the minimal amount of time in the reward zone and hence be classified as a stop trial. This scenario would lead to an underestimate of the animal’s ability to discriminate. For cortical silencing, when the LED illumination started before the stimulus appeared, the animal’s discrimination accuracy was similar to that of an ideal observer based on ROC analysis of the stimulus centering times in the reward zone. However, when the LED illumination started after the stimulus appeared, particularly for intervals longer than 80 ms from onset of the cortical response, the animal’s discrimination accuracy was usually noticeably lower than that of an ideal observer (&gt;10% difference). This difference would often occur because on some target trials mice would not slow down sufficiently for the trial to be a ‘stop trial’ but they would slow down more than they would for distractor trials. Thus, an advantage of our task is that it revealed differences in the animal’s behavior for target versus distractor that were not captured by the binary classification of stop versus non-stop trials.</p><p>To motivate mice to make choices with similar accuracy to that of an ideal observer monitoring the time that the stimulus spends in the reward zone, we adjusted the probability that an image would be a target and the minimum time that the target had to be centered for a reward (hold time). Decreasing target probability increases the gap between rewards. With decreasing probability of the image being a target, any miss is accompanied by a longer average time interval until the next target arrives. Similarly, as the probability of the image being a distractor increases, a given false alarm rate increases the average time until the next target is available. The parameters were adjusted until for LED illuminations starting 301 ms after cortical onset (<xref ref-type="fig" rid="fig3">Figure 3</xref>) mice made choices that had an accuracy similar to that of an ideal observer (difference did not exceed 7%). Adjusting parameters for the longest interval between the onset of the cortical response and the LED illumination (301 ms) was usually sufficient for the discrimination accuracy by the animal to be similar to that of an ideal observer for shorter intervals too. For data collection, parameters were kept constant across different intervals. For a list of final parameters for all mice included in the main experiments see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. The probability that a stimulus would be a target varied from 25–50% across mice, and the hold time varied from 0.6 s – 1.0 s across mice. Each interval was tested for 1–3 sessions totaling 130 ± 70 trials (range: 42–372 trials per interval), and data were pooled together for analysis.</p></sec><sec id="s4-7"><title>Extracellular electrophysiology</title><p>On the day of the recording the Kwik-Cast was removed, ACSF was added and, before the recording electrode penetrated the brain, a drop of 1% agarose (Type IIIA; Sigma-Aldrich) was added to reduce movement artifacts. The recording electrode was a NeuroNexus 32 channel linear probe (A1 × 32-Edge-5mm-20–177) that span 620 µm in depth across cortical layers. The probe was inserted approximately perpendicular to pia and lowered to a depth of ~850–900 µm (the curvature of the V1 surface was estimated using the Franklin and Paxinos brain atlas (<xref ref-type="bibr" rid="bib25">Paxinos and Franklin, 2007</xref>)). The probe was connected with a Plexon adaptor to two 16-channel A-M Systems headstages (gain 20x) and then connected to two 16 channel A-M Systems amplifiers (Model 3600; gain: 500x, high pass filter: 0.3 Hz, low pass filter: 5 kHz). The voltage signals were acquired with a National Instruments data acquisition board and extracted with custom written software in Matlab (code written by Shawn Olsen and included in <ext-link ext-link-type="uri" xlink:href="https://github.com/aresulaj/ResRueOlsSca18">https://github.com/aresulaj/ResRueOlsSca18</ext-link>; Electrophysiology Acquisition; <xref ref-type="bibr" rid="bib32">Resulaj, 2018</xref>. Copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/ResRueOlsSca18">https://github.com/elifesciences-publications/ResRueOlsSca18</ext-link>).</p><p>Data collection began at least 30 min after insertion of the probe. We first presented black or white squares of ~10° to map the location of the receptive field across all channels of the probe. To ensure that all receptive fields overlapped with the stimulus position during the behavior in the first 350 ms of a trial (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), we either moved the monitor slightly if the movement was approximately &lt;15°, or reinserted the probe at a different location mediolaterally. We mapped the receptive field at a higher spatial resolution at the end of the recording for eight mice (for same units and same stimulus and monitor position, see ‘Visual Stimulation’).</p></sec><sec id="s4-8"><title>Histology</title><p>Mice were transcardially perfused with 4% paraformaldehyde (PFA) in PBS. The brain was post-fixed in 4% PFA overnight in 4°C and then cut in 100 μm thick coronal sections using a vibratome. To estimate the extent of the lesion, consecutive sections were used. All mice had lesions in V1 and surrounding V2 areas. The lesion extended slightly into the following areas (as outlined in the Paxinos and Franklin mouse brain atlas (<xref ref-type="bibr" rid="bib25">Paxinos and Franklin, 2007</xref>)): hippocampus (2/5 mice), retrosplenial cortex (2/5 mice), primary somatosensory cortex (2/5 mice), primary and secondary auditory cortex (1/5 mice), temporal association cortex (1/5 mice), parietal association cortex (2/5 mice), dorsal subiculum (1/5 mice), postsubiculum (2/5 mice).</p></sec><sec id="s4-9"><title>Data analysis: behavior</title><p>We visualized the positioning of the stimulus on the monitor by plotting the position of the leading (caudal) edge of the stimulus (<xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig3">3</xref>). A stop trial is defined as the stimulus spending ≥the minimal time for reward in the reward zone (500 pixels wide). Error bars in stop probability (<xref ref-type="fig" rid="fig1">Figures 1</xref>, <xref ref-type="fig" rid="fig2">2</xref>, <xref ref-type="fig" rid="fig4">4</xref> and <xref ref-type="fig" rid="fig5">5</xref>) indicate 95% confidence intervals assuming a binomial distribution of stops and non-stops at each orientation (data pooled from all sessions that each condition was tested). Accuracy for the target stimulus is defined as the percentage of stop trials upon target presentation; accuracy for the distractor stimulus is defined as the percentage of non-stop trials upon distractor presentation. Overall accuracy is taken as the average of these two choice accuracies; chance level is 50% correct.</p></sec><sec id="s4-10"><title>Data analysis: spike sorting</title><p>We used UltraMegaSort (<xref ref-type="bibr" rid="bib7">Fee et al., 1996</xref>; <xref ref-type="bibr" rid="bib9">Hill et al., 2011</xref>) to sort spike waveforms into clusters. We then manually sorted the clusters into putative units. Units were accepted as well isolated according to the following criteria. First, the spike waveform across four channels had to be different than that of neighboring units in the cluster. If there were similarities, the orientation tuning curves had to be different otherwise the units were merged. Second, the refractory period violations for each unit did not exceed 0.1% (except for <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref> where threshold was 0.2%). To reach this criteria, we occasionally removed outliers (<xref ref-type="bibr" rid="bib9">Hill et al., 2011</xref>) identified using the distribution of the Mahalanbois distance of spike waveforms from the cluster center. Third, for each unit, the fraction of spikes with amplitudes below detection threshold (4 s.d. of high frequency noise) did not exceed 15% (including any removed outliers) as estimated by a Gaussian fit to the distribution of spike amplitudes. Finally, we ensured that the spike waveform was stable for the duration of trials in our analysis.</p><p>Out of 98 well isolated units (n = 9 mice, one recording/animal), 12 units (12%) were putative inhibitory units based on spike waveform (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). Isolated units spanned all cortical layers.</p></sec><sec id="s4-11"><title>Data analysis: electrophysiology</title><p>To estimate the onset of the cortical response (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), we first averaged for each channel the raw voltage traces across trials. We then filtered the averaged trace (fourth order Butterworth filter, low pass frequency cutoff: 300 Hz, applied bidirectionally) to get the local field potential. The filtered trace was almost indistinguishable from the raw trace (blue versus black, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). The onset of the cortical response was defined as the earliest deflection in the filtered traces exceeding 3 s.d. from baseline. The baseline was computed for each channel as the average over the interval −80 ms to 20 ms from stimulus onset.</p><p>The current source density analysis based on the averaged traces was computed as described before (<xref ref-type="bibr" rid="bib21">Niell and Stryker, 2008</xref>; <xref ref-type="bibr" rid="bib30">Reinhold et al., 2015</xref>). For the average CSD across mice in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1B</xref>, three mice were excluded because either the recording electrode did not span the same depth of cortex as other recordings (n = 1 mouse) or there was noise in a few channels (n = 2 mice); both cases would lead to discontinuities in the average CSD if included.</p><p>To quantify for each recording how far the center of the receptive field was from the center of the stimulus, at each stimulus location (black or white squares in a 9 × 9 grid in 4 mice and 5 × 5 grid in four mice covering the whole stimulus area; see 'Extracellular Electrophysiology') and for each channel we calculated the baseline subtracted response over a window of 170 ms (stimulus duration: 120 ms), and then normalized the responses to the peak response. After, for each location we averaged the responses across all channels. We then computed for each location the average of the average response to the white squares and the average response to the black squares. Lastly, we estimated the center of the receptive field by calculating the center of mass from the average responses at different locations. The distance from the center of the receptive field to the center of the stimulus was 2 ± 1 degrees (mean ±std, n = 8 mice).</p><p>We computed the area under the receiver operating characteristic (ROC) using function <italic>perfcurve</italic> in Matlab. To exclude the possibility that this analysis was not sensitive enough for low firing units, out of 98 well isolated units, 13 (all regular spiking) were excluded because they fired &lt;1 spike every six trials over the initial 300 ms. This threshold was chosen because units firing at rates just above this threshold could discriminate (p&lt;0.012; Wilcoxon ranksum test comparing the distributions of the number of action potentials for target versus distractor). We confirmed that the distribution of running speeds for the two stimuli was not significantly different in the initial 350 ms and thus did not affect our ROC analysis (p&gt;0.02, Wilcoxon ranksum test using the Benjamini-Hochberg correction for multiple comparisons, n = 9 mice).</p><p>To determine how many neurons are needed to explain behavior, we first artificially increased the number of units by randomly shuffling the trials of each unit to get six new units. We increased the total number of units to 231 units for the pool containing discriminating units only and 504 units for the pool containing both discriminating and non-discriminating units. We then randomly picked N units, where N was 2, 5, 10, 20, 50, 100, or 200. For all units preferring the distractor, we switched the target responses with the distractor responses. Next we created a 'pooling neuron' that had for each trial all the spikes of all N neurons. We then performed ROC analysis on the spikes of this pooling neuron. We repeated the random sampling step 1000 times and averaged the resulting areas under the ROC curve. We repeated the whole procedure 10 times. Error bars in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> are sem from these 10 repetitions.</p><p>To compute the time of the first spike for the preferred versus the non-preferred stimulus (<xref ref-type="fig" rid="fig6">Figure 6B–D</xref>) we quantified for each unit the time of the first spike for each trial over the initial 300 ms following the onset of the cortical response. For each unit we then normalized the distribution of these spike times (total number of spikes = 1) and then averaged across units the fraction of spikes in each time bin (20 ms bins, <xref ref-type="fig" rid="fig6">Figure 6C</xref>). We also show the mean of the spike times for each unit and the distribution of these means across units (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). To assess whether the first spike occurred earlier for the preferred versus the non-preferred stimulus, for each unit we computed the difference in the mean time of the first spike for the preferred versus the non-preferred stimulus and tested whether the mean of the differences from all units was different than zero (Student’s t-test).</p><p>To compute orientation tuning curves, the firing rate for each orientation was calculated over the initial 330 ms following cortical onset (i.e. the first cycle of presentation), averaged across repetitions, and normalized by the maximal firing rate across orientations.</p><p>To compute the preferred orientation for each unit, we used the following equation (<xref ref-type="bibr" rid="bib17">Lien and Scanziani, 2013</xref>):<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mo>∑</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo><mml:mspace width="2em"/><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mo>∑</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mtext> </mml:mtext></mml:mrow></mml:msub><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>180</mml:mn><mml:mo>+</mml:mo><mml:mi>arctan</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We computed orientation selectivity index (OSI) using the equation (<xref ref-type="bibr" rid="bib17">Lien and Scanziani, 2013</xref>):<disp-formula id="equ4"><mml:math id="m4"><mml:mi>O</mml:mi><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msqrt><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mrow><mml:mrow><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>To evaluate the dependence of the area under the ROC curve over the initial 80 ms after cortical onset during the task versus the difference in the number of action potentials in response to passively viewed stimuli of 45° and 90°, we fitted a linear function using least squares estimation (<xref ref-type="bibr" rid="bib5">Dobson and Barnett, 2008</xref>). The standard errors of the slope and offset parameters of the fit were based on the inverse of the information matrix (<xref ref-type="bibr" rid="bib5">Dobson and Barnett, 2008</xref>). The slope was significantly larger than 0 (p&lt;0.05; t-test).</p></sec><sec id="s4-12"><title>Statistical analysis</title><p>The stated p-values are the results of the Wilcoxon ranksum test unless otherwise noted. For medians, we report standard errors calculated using bootstrapping.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank J Evora for help with mouse husbandry, Jeffery Isaacson, Lindsey Glickfeld and Michael Shadlen for comments on the manuscript, Maria Dadarlat and members of the Scanziani lab and Isaacson lab for helpful discussions, Satoru Miura, Guy Bouvier and Baohua Li for help with headbar implantations and eye tracking, and Yi Li for help with behavioral training and histology. We are grateful to the undergraduate students that helped with training of the mice. This project was supported by the Gatsby Charitable Foundation and the Howard Hughes Medical Institute.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Writing—original draft, Writing—review and editing, Performed experiments</p></fn><fn fn-type="con" id="con2"><p>Writing—review and editing, Performed lesions of visual cortex</p></fn><fn fn-type="con" id="con3"><p>Writing—review and editing, Developed the behavioral task</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All experimental procedures were approved by the University of California San Diego Animal Care and Use Committee. (protocol number S02160M).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><object-id pub-id-type="doi">10.7554/eLife.34044.015</object-id><label>Supplementary file 1.</label><caption><title>Parameters for the behavioral task for each of the mice included in the main experiments.</title><p>Hold time is the minimal time that the target stimulus has to spend in the reward zone for a reward to be available. Track gain is the stimulus displacement on the monitor (cm)/running distance (cm). Target probability is the fraction of stimuli that are the target stimulus (stimuli are randomly interleaved).</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-34044-supp1-v1.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atallah</surname> <given-names>BV</given-names></name><name><surname>Bruns</surname> <given-names>W</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Parvalbumin-expressing interneurons linearly transform cortical responses to visual stimuli</article-title><source>Neuron</source><volume>73</volume><fpage>159</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.013</pub-id><pub-id pub-id-type="pmid">22243754</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breitmeyer</surname> <given-names>BG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Visual masking: past accomplishments, present status, future developments</article-title><source>Advances in Cognitive Psychology</source><volume>3</volume><fpage>9</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.2478/v10053-008-0010-7</pub-id><pub-id pub-id-type="pmid">20517494</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Celebrini</surname> <given-names>S</given-names></name><name><surname>Thorpe</surname> <given-names>S</given-names></name><name><surname>Trotter</surname> <given-names>Y</given-names></name><name><surname>Imbert</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Dynamics of orientation coding in area V1 of the awake primate</article-title><source>Visual Neuroscience</source><volume>10</volume><fpage>811</fpage><lpage>825</lpage><pub-id pub-id-type="doi">10.1017/S0952523800006052</pub-id><pub-id pub-id-type="pmid">8217934</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dobson</surname> <given-names>AJ</given-names></name></person-group><person-group person-group-type="author"><name><surname>Barnett</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>An Introduction to Generalized Linear Models</source><edition>Third Edition</edition><publisher-name>Chapman &amp; Hall/CRC</publisher-name></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fabre-Thorpe</surname> <given-names>M</given-names></name><name><surname>Richard</surname> <given-names>G</given-names></name><name><surname>Thorpe</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Rapid categorization of natural images by rhesus monkeys</article-title><source>NeuroReport</source><volume>9</volume><fpage>303</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1097/00001756-199801260-00023</pub-id><pub-id pub-id-type="pmid">9507973</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fee</surname> <given-names>MS</given-names></name><name><surname>Mitra</surname> <given-names>PP</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Automatic sorting of multiple unit neuronal signals in the presence of anisotropic and non-Gaussian variability</article-title><source>Journal of Neuroscience Methods</source><volume>69</volume><fpage>175</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(96)00050-7</pub-id><pub-id pub-id-type="pmid">8946321</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickfeld</surname> <given-names>LL</given-names></name><name><surname>Histed</surname> <given-names>MH</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Mouse primary visual cortex is used to detect both orientation and contrast changes</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>19416</fpage><lpage>19422</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3560-13.2013</pub-id><pub-id pub-id-type="pmid">24336708</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname> <given-names>DN</given-names></name><name><surname>Mehta</surname> <given-names>SB</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Quality metrics to accompany spike sorting of extracellular signals</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>8699</fpage><lpage>8705</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0971-11.2011</pub-id><pub-id pub-id-type="pmid">21677152</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Histed</surname> <given-names>MH</given-names></name><name><surname>Maunsell</surname> <given-names>JHR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical neural populations can guide behavior by integrating inputs linearly, independent of synchrony</article-title><source>PNAS</source><volume>111</volume><fpage>E178</fpage><lpage>E187</lpage><pub-id pub-id-type="doi">10.1073/pnas.1318750111</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Häusser</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>SL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neuroscience: controlling neural circuits with light</article-title><source>Nature</source><volume>446</volume><fpage>617</fpage><lpage>619</lpage><pub-id pub-id-type="doi">10.1038/446617a</pub-id><pub-id pub-id-type="pmid">17410162</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jurjut</surname> <given-names>O</given-names></name><name><surname>Georgieva</surname> <given-names>P</given-names></name><name><surname>Busse</surname> <given-names>L</given-names></name><name><surname>Katzner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Learning enhances sensory processing in mouse V1 before improving behavior</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>6460</fpage><lpage>6474</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3485-16.2017</pub-id><pub-id pub-id-type="pmid">28559381</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawai</surname> <given-names>R</given-names></name><name><surname>Markman</surname> <given-names>T</given-names></name><name><surname>Poddar</surname> <given-names>R</given-names></name><name><surname>Ko</surname> <given-names>R</given-names></name><name><surname>Fantana</surname> <given-names>AL</given-names></name><name><surname>Dhawale</surname> <given-names>AK</given-names></name><name><surname>Kampff</surname> <given-names>AR</given-names></name><name><surname>Ölveczky</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Motor cortex is required for learning but not for executing a motor skill</article-title><source>Neuron</source><volume>86</volume><fpage>800</fpage><lpage>812</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.024</pub-id><pub-id pub-id-type="pmid">25892304</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kovács</surname> <given-names>G</given-names></name><name><surname>Vogels</surname> <given-names>R</given-names></name><name><surname>Orban</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Cortical correlate of pattern backward masking</article-title><source>PNAS</source><volume>92</volume><fpage>5587</fpage><lpage>5591</lpage><pub-id pub-id-type="doi">10.1073/pnas.92.12.5587</pub-id><pub-id pub-id-type="pmid">7777553</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname> <given-names>VA</given-names></name><name><surname>Zipser</surname> <given-names>K</given-names></name><name><surname>Spekreijse</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Masking interrupts figure-ground signals in V1</article-title><source>Journal of Cognitive Neuroscience</source><volume>14</volume><fpage>1044</fpage><lpage>1053</lpage><pub-id pub-id-type="doi">10.1162/089892902320474490</pub-id><pub-id pub-id-type="pmid">12419127</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname> <given-names>F</given-names></name><name><surname>Xiong</surname> <given-names>XR</given-names></name><name><surname>Zingg</surname> <given-names>B</given-names></name><name><surname>Ji</surname> <given-names>XY</given-names></name><name><surname>Zhang</surname> <given-names>LI</given-names></name><name><surname>Tao</surname> <given-names>HW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sensory cortical control of a visually induced arrest behavior via corticotectal projections</article-title><source>Neuron</source><volume>86</volume><fpage>755</fpage><lpage>767</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.048</pub-id><pub-id pub-id-type="pmid">25913860</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lien</surname> <given-names>AD</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Tuned thalamic excitation is amplified by visual cortical circuits</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1315</fpage><lpage>1323</lpage><pub-id pub-id-type="doi">10.1038/nn.3488</pub-id><pub-id pub-id-type="pmid">23933748</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>BH</given-names></name><name><surname>Huberman</surname> <given-names>AD</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cortico-fugal output from visual cortex promotes plasticity of innate motor behaviour</article-title><source>Nature</source><volume>538</volume><fpage>383</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1038/nature19818</pub-id><pub-id pub-id-type="pmid">27732573</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macknik</surname> <given-names>SL</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Neuronal correlates of visibility and invisibility in the primate visual system</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>144</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1038/393</pub-id><pub-id pub-id-type="pmid">10195130</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazurek</surname> <given-names>ME</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Limits to the temporal fidelity of cortical spike rate signals</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>463</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1038/nn836</pub-id><pub-id pub-id-type="pmid">11976706</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connor</surname> <given-names>DH</given-names></name><name><surname>Hires</surname> <given-names>SA</given-names></name><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Yu</surname> <given-names>J</given-names></name><name><surname>Sun</surname> <given-names>QQ</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural coding during active somatosensation revealed using illusory touch</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>958</fpage><lpage>965</lpage><pub-id pub-id-type="doi">10.1038/nn.3419</pub-id><pub-id pub-id-type="pmid">23727820</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname> <given-names>SR</given-names></name><name><surname>Bortone</surname> <given-names>DS</given-names></name><name><surname>Adesnik</surname> <given-names>H</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Gain control by layer six in cortical circuits of vision</article-title><source>Nature</source><volume>483</volume><fpage>47</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1038/nature10835</pub-id><pub-id pub-id-type="pmid">22367547</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otchy</surname> <given-names>TM</given-names></name><name><surname>Wolff</surname> <given-names>SB</given-names></name><name><surname>Rhee</surname> <given-names>JY</given-names></name><name><surname>Pehlevan</surname> <given-names>C</given-names></name><name><surname>Kawai</surname> <given-names>R</given-names></name><name><surname>Kempf</surname> <given-names>A</given-names></name><name><surname>Gobes</surname> <given-names>SM</given-names></name><name><surname>Ölveczky</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Acute off-target effects of neural circuit manipulations</article-title><source>Nature</source><volume>528</volume><fpage>358</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/nature16442</pub-id><pub-id pub-id-type="pmid">26649821</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paxinos</surname> <given-names>G</given-names></name></person-group><person-group person-group-type="author"><name><surname>Franklin</surname> <given-names>KBJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>The Mouse Brain in Stereotaxic Coordinates</source><edition>3rd edn</edition><publisher-name>Elsevier Academic</publisher-name></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname> <given-names>Y</given-names></name><name><surname>Gillis-Smith</surname> <given-names>S</given-names></name><name><surname>Jin</surname> <given-names>H</given-names></name><name><surname>Tränkner</surname> <given-names>D</given-names></name><name><surname>Ryba</surname> <given-names>NJ</given-names></name><name><surname>Zuker</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sweet and bitter taste in the brain of awake behaving animals</article-title><source>Nature</source><volume>527</volume><fpage>512</fpage><lpage>515</lpage><pub-id pub-id-type="doi">10.1038/nature15763</pub-id><pub-id pub-id-type="pmid">26580015</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petruno</surname> <given-names>SK</given-names></name><name><surname>Clark</surname> <given-names>RE</given-names></name><name><surname>Reinagel</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Evidence that primary visual cortex is required for image, orientation, and motion discrimination by rats</article-title><source>PLoS One</source><volume>8</volume><elocation-id>e56543</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0056543</pub-id><pub-id pub-id-type="pmid">23441202</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poort</surname> <given-names>J</given-names></name><name><surname>Khan</surname> <given-names>AG</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Nemri</surname> <given-names>A</given-names></name><name><surname>Orsolic</surname> <given-names>I</given-names></name><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Keller</surname> <given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning enhances sensory and multiple non-sensory representations in primary visual cortex</article-title><source>Neuron</source><volume>86</volume><fpage>1478</fpage><lpage>1490</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.037</pub-id><pub-id pub-id-type="pmid">26051421</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prusky</surname> <given-names>GT</given-names></name><name><surname>Douglas</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Characterization of mouse cortical spatial vision</article-title><source>Vision Research</source><volume>44</volume><fpage>3411</fpage><lpage>3418</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2004.09.001</pub-id><pub-id pub-id-type="pmid">15536009</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinhold</surname> <given-names>K</given-names></name><name><surname>Lien</surname> <given-names>AD</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct recurrent versus afferent dynamics in cortical visual processing</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1789</fpage><lpage>1797</lpage><pub-id pub-id-type="doi">10.1038/nn.4153</pub-id><pub-id pub-id-type="pmid">26502263</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname> <given-names>A</given-names></name><name><surname>Rinberg</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Novel behavioral paradigm reveals lower temporal limits on mouse olfactory decisions</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>11667</fpage><lpage>11673</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4693-14.2015</pub-id><pub-id pub-id-type="pmid">26290243</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Resulaj</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>ResRueOlsSca18</data-title><source>Github</source><version designator="59a6772">59a6772</version><ext-link ext-link-type="uri" xlink:href="https://github.com/aresulaj/ResRueOlsSca18">https://github.com/aresulaj/ResRueOlsSca18</ext-link></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname> <given-names>ET</given-names></name><name><surname>Tovee</surname> <given-names>MJ</given-names></name><name><surname>Purcell</surname> <given-names>DG</given-names></name><name><surname>Stewart</surname> <given-names>AL</given-names></name><name><surname>Azzopardi</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>The responses of neurons in the temporal cortex of primates, and face identification and detection</article-title><source>Experimental Brain Research</source><volume>101</volume><fpage>473</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1007/BF00227340</pub-id><pub-id pub-id-type="pmid">7851514</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname> <given-names>ET</given-names></name><name><surname>Tovée</surname> <given-names>MJ</given-names></name><name><surname>Panzeri</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The neurophysiology of backward visual masking: information analysis</article-title><source>Journal of Cognitive Neuroscience</source><volume>11</volume><fpage>300</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1162/089892999563409</pub-id><pub-id pub-id-type="pmid">10402257</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romo</surname> <given-names>R</given-names></name><name><surname>Hernández</surname> <given-names>A</given-names></name><name><surname>Zainos</surname> <given-names>A</given-names></name><name><surname>Salinas</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Somatosensory discrimination based on cortical microstimulation</article-title><source>Nature</source><volume>392</volume><fpage>387</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1038/32891</pub-id><pub-id pub-id-type="pmid">9537321</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sachidhanandam</surname> <given-names>S</given-names></name><name><surname>Sreenivasan</surname> <given-names>V</given-names></name><name><surname>Kyriakatos</surname> <given-names>A</given-names></name><name><surname>Kremer</surname> <given-names>Y</given-names></name><name><surname>Petersen</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Membrane potential correlates of sensory perception in mouse barrel cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1671</fpage><lpage>1677</lpage><pub-id pub-id-type="doi">10.1038/nn.3532</pub-id><pub-id pub-id-type="pmid">24097038</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salzman</surname> <given-names>CD</given-names></name><name><surname>Britten</surname> <given-names>KH</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Cortical microstimulation influences perceptual judgements of motion direction</article-title><source>Nature</source><volume>346</volume><fpage>174</fpage><lpage>177</lpage><pub-id pub-id-type="doi">10.1038/346174a0</pub-id><pub-id pub-id-type="pmid">2366872</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The variable discharge of cortical neurons: implications for connectivity, computation, and information coding</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>3870</fpage><lpage>3896</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-10-03870.1998</pub-id><pub-id pub-id-type="pmid">9570816</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolhurst</surname> <given-names>DJ</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name><name><surname>Dean</surname> <given-names>AF</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The statistical reliability of signals in single neurons in cat and monkey visual cortex</article-title><source>Vision Research</source><volume>23</volume><fpage>775</fpage><lpage>785</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(83)90200-6</pub-id><pub-id pub-id-type="pmid">6623937</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>CD</given-names></name><name><surname>Serrano</surname> <given-names>GO</given-names></name><name><surname>Koulakov</surname> <given-names>AA</given-names></name><name><surname>Rinberg</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A primacy code for odor identity</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>1477</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-01432-4</pub-id><pub-id pub-id-type="pmid">29133907</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname> <given-names>S</given-names></name><name><surname>Ting</surname> <given-names>JT</given-names></name><name><surname>Atallah</surname> <given-names>HE</given-names></name><name><surname>Qiu</surname> <given-names>L</given-names></name><name><surname>Tan</surname> <given-names>J</given-names></name><name><surname>Gloss</surname> <given-names>B</given-names></name><name><surname>Augustine</surname> <given-names>GJ</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Luo</surname> <given-names>M</given-names></name><name><surname>Graybiel</surname> <given-names>AM</given-names></name><name><surname>Feng</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cell type–specific channelrhodopsin-2 transgenic mice for optogenetic dissection of neural circuitry function</article-title><source>Nature Methods</source><volume>8</volume><fpage>745</fpage><lpage>752</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1668</pub-id><pub-id pub-id-type="pmid">21985008</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zohary</surname> <given-names>E</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title><source>Nature</source><volume>370</volume><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1038/370140a0</pub-id><pub-id pub-id-type="pmid">8022482</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.34044.017</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Slutsky</surname><given-names>Inna</given-names></name><role>Reviewing Editor</role><aff id="aff7"><institution>Tel Aviv University</institution><country>Israel</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;First spikes in visual cortex enable perceptual discrimination&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by Inna Slutsky as the Reviewing Editor and Eve Marder as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Ilan Lampl (Reviewer #1); Carl CH Petersen (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This outstanding paper shows that animals can discriminate between simple visual stimuli based on the early response in the visual cortex, during which neurons fire zero or one spikes at the most. Since cortical response even to brief stimuli lasts far beyond the duration of the stimulus, the time-window which is sufficient for perception of the stimulus has been unclear. Many attempts were made in previous studies to address this question, mostly using computational approaches and psychophysics. However, the question was never directly addressed due to the lack of adequate methods to precisely control the duration of cortical activity. Briefly, Rsulaj at al., used optogenetic inactivation of V1 in mice that performed a novel discrimination task in order to find the minimal time-window of V1 activity that is required for discrimination. By controlling the time of cortical inactivation with respect to the onset of visual stimuli, they show that V1 activity during the first 80 milliseconds from the onset of stimulation is sufficient for discrimination. Extracellular recordings indicated that during this period most cells in V1 fired no more than one spike.</p><p>The authors did a superb job in designing the study and the experiments were conducted with the highest standards. The data clearly support the conclusions of this study. The authors thought carefully on their study and included very important controls, which strengthened the conclusions. The presentation of the results is remarkably good and the discussion is clear. Overall, this is a very important study that puts forward clear evidence for the speed of cortical processing that is involved in perception of simple visual stimuli that animals use for making decisions.</p><p>Here are our suggestions to strengthen the manuscript:</p><p>Essential revisions:</p><p>1) The optogenetic inactivation of the contra V1 during detection task is a very important and nice experiment, but it may require additional experiments or changing the statements that appear in the results. Unlike in cats and primates, many LGN cells in mice are driven by both eyes (Howarth et al., 2014, Rompani et al., 2017). Hence, neurons in the ipsilateral V1 are likely to respond to the visual stimulation that was used in this specific detection task and contribute to the animal's decision. Thus, it is well possible that the primary visual cortex is required for detection. To fully address this issue additional recordings from the ipsilateral V1 and bilateral silencing is needed. Yet, since revealing the underlying mechanisms of detection is not a crucial part of this study the alternative way to overcome this difficulty is simply by changing their statements to say that the contralateral V1 is not required for detection in their experimental design. See also the following comment.</p><p>2) Moreover, in monkeys LGN cells directly project to higher cortical areas (Sincich et al., 2004). Since such organization might also exist in mice, the authors can only conclude that in the detection task the contralateral V1 is not required. See first comment.</p><p>3) It is not clear why in the detection task, inactivation of contra V1 biased the distribution of 'fraction of monitor' towards smaller values compared to the non-inactivated trials. This clearly suggests that inactivation of the contralateral V1 in detection task affects the behavior and should be discussed.</p><p>4) The conclusions of this study are somewhat dependent on the assumption that the position of the stimulus relative to the receptive field of the recorded cells is well aligned. However, if the animal makes strong eye movements during the task (when the stimulation appears) other (non-recorded) cells could be activated. Thus, it will be important to check the position of the eyes during this task. While such data will have no effect on the strong conclusion regarding the duration of cortical activity that is needed for discrimination, it is important for the APs data.</p><p>5) We think the authors should discuss two closely-related studies from the mouse whisker system in which the timing of neuronal activity in wS1 was studied. Sachidhanandam et al., (2013) found strong suppression of performance when wS1 was inactivated simultaneously with sensory stimulus, and a reduced effect when inactivation was delayed by 100 milliseconds (although both were significant). Guo et al., (2014) found that inactivation of wS1 during whisker-object sampling was more effective than inactivation of wS1 during a delay period (although both were significant). Here, in the current study, the authors report strong behavioural impairment when V1 is inactivated within ~100 milliseconds of the visual stimulus, with 76% performance for optogenetic inactivation starting at 80 milliseconds after visual cortical response (latency 40 milliseconds) recovering to 92% performance when inactivation is started at 300 milliseconds after onset of the cortical response. The authors results are therefore consistent with previous reports, which would seem appropriate to discuss.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.34044.018</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>The authors did a superb job in designing the study and the experiments were conducted with the highest standards. The data clearly support the conclusions of this study. The authors thought carefully on their study and included very important controls, which strengthened the conclusions. The presentation of the results is remarkably good and the discussion is clear. Overall, this is a very important study that puts forward clear evidence for the speed of cortical processing that is involved in perception of simple visual stimuli that animals use for making decisions.</p><p>Here are our suggestions to strengthen the manuscript:</p><p>Essential revisions:</p><p>1) The optogenetic inactivation of the contra V1 during detection task is a very important and nice experiment, but it may require additional experiments or changing the statements that appear in the results. Unlike in cats and primates, many LGN cells in mice are driven by both eyes (Howarth et al., 2014, Rompani et al., 2017). Hence, neurons in the ipsilateral V1 are likely to respond to the visual stimulation that was used in this specific detection task and contribute to the animal's decision. Thus, it is well possible that the primary visual cortex is required for detection. To fully address this issue additional recordings from the ipsilateral V1 and bilateral silencing is needed. Yet, since revealing the underlying mechanisms of detection is not a crucial part of this study the alternative way to overcome this difficulty is simply by changing their statements to say that the contralateral V1 is not required for detection in their experimental design. See also the following comment.</p></disp-quote><p>The reviewers are correct that many LGN cells in the mouse are driven by both eyes (Howarth et al., 2014, Rompani et al., 2017). However, these LGN cells respond to the binocular part of the visual field that encompasses -30 to +30 degrees along the azimuth relative to the central meridian (Howarth et al., 2014). Because in our task the monitor is placed on the right side of the animal in the monocular part of the visual field, it is unlikely that these LGN cells are activated during the detection task. Yet, as requested by the reviewers, we have changed our statement to say that the contralateral V1 is not required for detection in response to the reviewers' comment #2 (please see below).</p><disp-quote content-type="editor-comment"><p>2) Moreover, in monkeys LGN cells directly project to higher cortical areas (Sincich et al., 2004). Since such organization might also exist in mice, the authors can only conclude that in the detection task the contralateral V1 is not required. See first comment.</p></disp-quote><p>We thank the reviewers for the comment. In the mouse it is known that anterograde tracers injected in the LGN label faintly the V2 area lateral to V1 (Antonini et al., 1999, Oh et al., 2014). Further, Sanderson et al., showed using retrograde tracing that V2 areas receive &lt;5% of their thalamic input from LGN (compared with 95% for V1; Sanderson et al., 1991). These studies support the conclusion that the LGN projection to higher visual cortical areas is unlikely to play a major role in the detection task. Yet, other subcortical pathways to higher cortical areas also exist (Glickfeld and Olsen, 2017). Thus, we agree with the reviewers that, in the absence of optogenetic silencing of higher visual cortical areas during the detection task, we can only conclude that in the detection task the contralateral V1 is not required. We have modified our conclusion in the text accordingly.</p><disp-quote content-type="editor-comment"><p>3) It is not clear why in the detection task, inactivation of contra V1 biased the distribution of 'fraction of monitor' towards smaller values compared to the non-inactivated trials. This clearly suggests that inactivation of the contralateral V1 in detection task affects the behavior and should be discussed.</p></disp-quote><p>The reviewers are correct that, for the example mouse shown in Figure 1, inactivation of contra V1 biased the distribution of 'fraction of monitor' towards smaller values in the reward zone compared to the non‐inactivated trials. For the other mouse used for the detection task (not shown), inactivation of contra V1 biased the distribution of 'fraction of monitor' towards larger values in the reward zone compared to the non‐inactivated trials. Similarly, for the example mouse shown in Figure 4, inactivation of contra V1 starting at 80 milliseconds following the onset of cortical response biased the distribution of 'fraction of monitor' towards larger values compared to the non‐inactivated trials. In general, we saw a bias within the reward zone in either direction in some of our mice. Therefore, we agree with the reviewers that this clearly suggests that the inactivation of the contralateral V1 affects the fine positioning of the stimulus within the reward zone. We now mention this in Discussion section. The reason for this affect is unclear and probably depends on the exact strategy used by the animal to position the stimulus in the reward zone while contralateral V1 is silenced.</p><disp-quote content-type="editor-comment"><p>4) The conclusions of this study are somewhat dependent on the assumption that the position of the stimulus relative to the receptive field of the recorded cells is well aligned. However, if the animal makes strong eye movements during the task (when the stimulation appears) other (non-recorded) cells could be activated. Thus, it will be important to check the position of the eyes during this task. While such data will have no effect on the strong conclusion regarding the duration of cortical activity that is needed for discrimination, it is important for the APs data.</p></disp-quote><p>We agree with the reviewers that for our conclusion regarding the number of APs, it is important that the position of the stimulus relative to the receptive field of the recorded cells is well aligned. We have now monitored the eye position during the task in 5 mice and found that the position of the eye varied little: the standard deviation of the position of the eye across trials during a window of 80 ms was 2.4 ± 0.6 degrees (mean ± std across 5 mice; Figure 1—figure supplement 1). For comparison, the size of the receptive field of an individual cortical neuron is 12-20 degrees (upper – deeper layers in V1, Niell and Stryker, 2008). Niell and Stryker quantified size as full width at half maximal response of a fitted Gaussian, and thus at the edges of the receptive field a neuron still fires on average half of the spikes relative to maximal activation. We also compared the eye position during receptive field mapping (performed outside of the task) with the eye position during the task. While the animals moves its eyes more outside of the task than during the task the median eye position during receptive field mapping and during the task was very similar (difference of 2.7 ± 0.9 degrees; mean ± std across 5 mice; Figure 1—figure supplement 1). Therefore, given the small difference in median eye position during receptive field mapping and during the task, the position of the stimulus remains on average relatively well aligned during the task.</p><disp-quote content-type="editor-comment"><p>5) We think the authors should discuss two closely-related studies from the mouse whisker system in which the timing of neuronal activity in wS1 was studied. Sachidhanandam et al., (2013) found strong suppression of performance when wS1 was inactivated simultaneously with sensory stimulus, and a reduced effect when inactivation was delayed by 100 milliseconds (although both were significant). Guo et al., (2014) found that inactivation of wS1 during whisker-object sampling was more effective than inactivation of wS1 during a delay period (although both were significant). Here, in the current study, the authors report strong behavioural impairment when V1 is inactivated within ~100 milliseconds of the visual stimulus, with 76% performance for optogenetic inactivation starting at 80 milliseconds after visual cortical response (latency 40 milliseconds) recovering to 92% performance when inactivation is started at 300 milliseconds after onset of the cortical response. The authors results are therefore consistent with previous reports, which would seem appropriate to discuss.</p></disp-quote><p>Indeed, our data are consistent with observations in somatosensory cortex performed during cortical silencing in a detection task by Sachidhanandam et al., (2013). This is now stated and cited in the Discussion. The work by Guo et al., on the other hand addresses time windows that are an order of magnitude longer and hence not directly comparable with the present work.</p></body></sub-article></article>