<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">40868</article-id><article-id pub-id-type="doi">10.7554/eLife.40868</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Attention periodically samples competing stimuli during binocular rivalry</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-118208"><name><surname>Davidson</surname><given-names>Matthew J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2088-040X</contrib-id><email>mjd070@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-119249"><name><surname>Alais</surname><given-names>David</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0411-940X</contrib-id><email>david.alais@sydney.edu.au</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-72947"><name><surname>van Boxtel</surname><given-names>Jeroen JA</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2643-0474</contrib-id><email>jeroen.van.boxtel@monash.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-28525"><name><surname>Tsuchiya</surname><given-names>Naotsugu</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4216-8701</contrib-id><email>Naotsugu.Tsuchiya@monash.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">School of Psychological Sciences, Faculty of Medicine, Nursing, and Health Sciences</institution><institution>Monash University</institution><addr-line><named-content content-type="city">Melbourne</named-content></addr-line><country>Australia</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Monash Institute of Cognitive and Clinical Neurosciences</institution><institution>Monash University</institution><addr-line><named-content content-type="city">Melbourne</named-content></addr-line><country>Australia</country></aff><aff id="aff3"><label>3</label><institution content-type="dept">School of Psychology</institution><institution>The University of Sydney</institution><addr-line><named-content content-type="city">Camperdown</named-content></addr-line><country>Australia</country></aff><aff id="aff4"><label>4</label><institution content-type="dept">School of Psychology, Faculty of Health</institution><institution>University of Canberra</institution><addr-line><named-content content-type="city">Canberra</named-content></addr-line><country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Carrasco</surname><given-names>Marisa</given-names></name><role>Reviewing Editor</role><aff><institution>New York University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>03</day><month>12</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e40868</elocation-id><history><date date-type="received" iso-8601-date="2018-08-08"><day>08</day><month>08</month><year>2018</year></date><date date-type="accepted" iso-8601-date="2018-11-19"><day>19</day><month>11</month><year>2018</year></date></history><permissions><copyright-statement>© 2018, Davidson et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Davidson et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-40868-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.40868.001</object-id><p>The attentional sampling hypothesis suggests that attention rhythmically enhances sensory processing when attending to a single (~8 Hz), or multiple (~4 Hz) objects. Here, we investigated whether attention samples sensory representations that are not part of the conscious percept during binocular rivalry. When crossmodally cued toward a conscious image, subsequent changes in consciousness occurred at ~8 Hz, consistent with the rates of undivided attentional sampling. However, when attention was cued toward the suppressed image, changes in consciousness slowed to ~3.5 Hz, indicating the division of attention away from the conscious visual image. In the electroencephalogram, we found that at attentional sampling frequencies, the strength of inter-trial phase-coherence over fronto-temporal and parieto-occipital regions correlated with changes in perception. When cues were not task-relevant, these effects disappeared, confirming that perceptual changes were dependent upon the allocation of attention, and that attention can flexibly sample away from a conscious image in a task-dependent manner.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>visual attention</kwd><kwd>periodic sampling</kwd><kwd>binocular rivalry</kwd><kwd>crossmodal stimulation</kwd><kwd>EEG</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>FT120100619</award-id><principal-award-recipient><name><surname>Tsuchiya</surname><given-names>Naotsugu</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DP130100194</award-id><principal-award-recipient><name><surname>Tsuchiya</surname><given-names>Naotsugu</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DP150101731</award-id><principal-award-recipient><name><surname>Alais</surname><given-names>David</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A combined behavioural and electroencephalographic approach investigating the covert allocation of attention shows evidence for distributed periodic sampling away from a conscious visual image.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Recent behavioral and electrophysiological evidence suggests that despite our seamless visual experience, incoming visual information is periodically enhanced for analysis in the visual system (<xref ref-type="bibr" rid="bib110">VanRullen, 2016a</xref>; <xref ref-type="bibr" rid="bib111">VanRullen, 2016b</xref>; <xref ref-type="bibr" rid="bib119">Zoefel and VanRullen, 2017</xref>). This periodic sampling mechanism is proposed to result from the allocation of visual attention (<xref ref-type="bibr" rid="bib13">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib37">Dugué et al., 2016</xref>; <xref ref-type="bibr" rid="bib38">Dugué and VanRullen, 2017a</xref>; <xref ref-type="bibr" rid="bib107">VanRullen et al., 2007</xref>; <xref ref-type="bibr" rid="bib119">Zoefel and VanRullen, 2017</xref>), wherein alternating windows of high- and low-attentional resources operate to parcel incoming visual information, similar to the sequential frames that capture film within a video camera (<xref ref-type="bibr" rid="bib16">Chakravarthi and Vanrullen, 2012</xref>; <xref ref-type="bibr" rid="bib108">Vanrullen and Dubois, 2011</xref>). Whether stimuli are presented at the appropriate phase (<xref ref-type="bibr" rid="bib12">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib79">Mathewson et al., 2009</xref>; <xref ref-type="bibr" rid="bib107">VanRullen et al., 2007</xref>) or location (<xref ref-type="bibr" rid="bib36">Dugué et al., 2015</xref>; <xref ref-type="bibr" rid="bib37">Dugué et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Dugué and Vanrullen, 2014</xref>; <xref ref-type="bibr" rid="bib38">Dugué and VanRullen, 2017a</xref>; <xref ref-type="bibr" rid="bib39">Dugué et al., 2017b</xref>; <xref ref-type="bibr" rid="bib57">Huang et al., 2015</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>; <xref ref-type="bibr" rid="bib93">Song et al., 2014</xref>) of this sampling mechanism has been shown to modulate the accurate detection of a visual stimulus, in stark contrast to our experience of an uninterrupted visual environment.</p><p>To date, primary neural evidence for the rhythmic gating of visual processing stems from the dependence of target detection on the pre-target phase of neural oscillations at approximately 7–8 Hz (<xref ref-type="bibr" rid="bib12">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib13">Busch and VanRullen, 2010</xref>). These spontaneous fluctuations in detection may result from the allocation of visual attention toward a single location (<xref ref-type="bibr" rid="bib13">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib36">Dugué et al., 2015</xref>; <xref ref-type="bibr" rid="bib94">Spaak et al., 2014</xref>; <xref ref-type="bibr" rid="bib111">VanRullen, 2016b</xref>; <xref ref-type="bibr" rid="bib119">Zoefel and VanRullen, 2017</xref>), and support the assumption that neural excitability cycles gate and filter incoming information for further processing (<xref ref-type="bibr" rid="bib91">Schroeder and Lakatos, 2009</xref>; <xref ref-type="bibr" rid="bib109">VanRullen, 2013</xref>; <xref ref-type="bibr" rid="bib119">Zoefel and VanRullen, 2017</xref>).</p><p>This periodic gating of visual perception is also prominent behaviorally in the time-course of detection accuracy. Spectral analyses applied to high temporal resolution behavioral measures reveal 7–8 Hz modulations in performance following cues to reorient attention (<xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>), which slow proportionately when attention is divided between two or more locations (e.g. <xref ref-type="bibr" rid="bib17">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib56">Holcombe and Chen, 2013</xref>; <xref ref-type="bibr" rid="bib57">Huang et al., 2015</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>; <xref ref-type="bibr" rid="bib68">Landau et al., 2015</xref>; <xref ref-type="bibr" rid="bib109">VanRullen, 2013</xref>). For example, <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref> observed that following a cue to reorient attention to either the left or right visual hemifield, target detection oscillated at a 4 Hz counterphase rhythm depending on whether cues were congruent or incongruent with the target location. Critically, this counterphase sampling of visual information persisted at ~4 Hz when attention was directed to two locations on a single object (<xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>), and when cues to reorient attention were incongruent with target location – requiring a subsequent shift in the allocation of attention to a second location (<xref ref-type="bibr" rid="bib57">Huang et al., 2015</xref>). These successive fluctuations in target detection and counterphase sampling between locations have led to the suggestion that an intrinsic ~7–8 Hz attentional rhythm can be allocated over space and time in a sequential manner (<xref ref-type="bibr" rid="bib37">Dugué et al., 2016</xref>; <xref ref-type="bibr" rid="bib38">Dugué and VanRullen, 2017a</xref>; <xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib56">Holcombe and Chen, 2013</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>; <xref ref-type="bibr" rid="bib109">VanRullen, 2013</xref>; <xref ref-type="bibr" rid="bib119">Zoefel and VanRullen, 2017</xref>).</p><p>Here, we tested if rhythmic attentional sampling is at play during binocular rivalry. During binocular rivalry, incompatible images are presented to each eye which results in stochastic perceptual alternations, with one image visible at a time while the other is suppressed (<xref ref-type="bibr" rid="bib2">Alais, 2012</xref>; <xref ref-type="bibr" rid="bib1">Alais and Blake, 2005</xref>; <xref ref-type="bibr" rid="bib77">Maier et al., 2012</xref>). In an experiment designed to induce or delay these transitions using auditory and tactile cues, we found that changes in consciousness were occurring rhythmically after the reorientation of attention. These fluctuations occurred depending on whether the crossmodal cue directed attention toward either the dominant or suppressed visual image, resulting in ~8 Hz and ~3.5 Hz oscillations, respectively. Critically, these rhythms were observed in both behavior and the electroencephalogram (EEG), and were absent when cues were not task-relevant. This approximate halving of frequency suggests that when non-visual input is inconsistent with the ongoing visual percept, attentional sampling can flexibly orient away from a consciously perceived image, seemingly ‘searching for’ alternative sensory information to resolve the conflict.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Attending to low-frequency crossmodal stimulation promotes the perceptual dominance of low-frequency flicker during binocular rivalry</title><p>We manipulated the conscious visibility of images across two sessions of 24 × 3 min binocular rivalry blocks. Subjects (<italic>N</italic> = 34) continuously reported the content of their visual consciousness via button press to indicate which image they currently perceived, while neural activity was simultaneously recorded via 64-channel EEG (see Materials and methods). Rivalry stimuli were orthogonal sinusoidal gratings, which underwent sinusoidal contrast modulation, one at 4.5 Hz and the other at 20 Hz (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In each 3 min block, we intermittently presented 12 crossmodal cues (mean duration 2.6 s), which were sinusoidally amplitude-modulated signals presented in the auditory and/or tactile modality (auditory, tactile, or combined auditory and tactile) at a frequency congruent with one of the visual stimuli (4.5 or 20 Hz). Three null cues (visual-only periods) without any crossmodal stimulation were also presented to increase the uncertainty of stimulus timing. The visual-only periods also served as a baseline to compare the behavioral effects of crossmodal cues (see below). We separated all cue periods by jittering the ISI between 7–10 s. As a result, the timing of crossmodal cues was completely independent to perceptual reports, and cues were presented at any point relative to the onset of the currently dominant percept (i.e., no closed-loop control).</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.40868.002</object-id><label>Figure 1.</label><caption><title>Experimental paradigm.</title><p>A schematic time course showing stimulus presentation and reported visual percept. Each eye was presented with a 4.5 or 20 Hz sinusoidal flicker throughout 3 min blocks. Subjects reported their perceptual state through button-press. Crossmodal cues (also 4.5 or 20 Hz; 2, 3.1 or 4 s in duration) or visual-only periods (2.6 s in duration) were separated by inter-stimulus intervals of 7–10 s.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig1-v2.tif"/></fig><p>In order to investigate whether the allocation of attention to crossmodal cues alters the contents of visual consciousness during binocular rivalry, we varied attentional instructions over two sessions of the experiment. For one of their two sessions (day 1 for <italic>n</italic> = 16, day 2 for <italic>n</italic> = 18), we asked subjects to count the number of times that the temporal frequency of crossmodal cues coincided with their conscious visual percept at crossmodal cue offset (see Materials and methods). For their other session, subjects were instructed to focus on reporting their visual percept alone – ignoring any crossmodal cues.</p><p>Following the onset of a crossmodal cue, the probability of perceiving a congruent visual image increased only during attended low-frequency cues compared to all other cue types, during the period 0.68 to 3.97 s after cue onset (repeated measures ANOVAs followed by planned comparisons, FDR q = 0.05, <xref ref-type="fig" rid="fig2">Figure 2a</xref>). There was no difference in this effect when comparing the three types of crossmodal cues (auditory, tactile, and combined auditory tactile, data not shown). To confirm that this effect was due to attention, we performed a correlation-based behavioral analysis. First, we computed the Pearson's correlation coefficient (x-axis in <xref ref-type="fig" rid="fig2">Figure 2b</xref>), between each subject’s verbally reported number of congruent cues (i.e., their attentional task during attend conditions), to the actual number of cues that were congruent with their visual percepts based on button-press data. Second, we defined the strength of the crossmodal cueing effect for attended low-frequency cues compared to other cue types (y-axis in <xref ref-type="fig" rid="fig2">Figure 2b</xref>), as the difference in the probability of seeing the congruent visual flicker during 1 to 4 s after cue onset. We call this the perceptual switch index (PSI), as it reflects the degree of perceptual switch after cue onset. The magnitude of these two variables displayed a strong positive correlation (<italic>r</italic>(32) = 0.46, <italic>p</italic> = 0.006, two-tailed), suggesting that the cross-modal cueing effect was indeed mediated by attention.</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.40868.003</object-id><label>Figure 2.</label><caption><title>Behavioral results.</title><p>(<bold>a</bold>) Button-press data, aligned at cue onset, were averaged over all crossmodal cue and visual-only periods per subject, then averaged over subjects for each cue condition. Y-axis represents the proportion of button-presses reporting congruent crossmodal and visual flicker at each time point, sampled at 60 Hz (or every 16.7 ms). Colored lines and their shading show mean ± 1 standard error across 34 subjects during attended and ignored cues (thick and thin lines) for low- and high-frequency (green and red colors). Black lines represent the equivalent probability for visual-only periods, serving as baseline (Materials and methods). Asterisks indicate a significant difference between cues at each time point (repeated-measures ANOVA followed by planned comparisons). We use FDR q = 0.05 for the statistical threshold unless noted otherwise. (<bold>b</bold>) Crossmodal effects are mediated by task-relevant attention. Our measure of crossmodal effects, the perceptual switch index (PSI, y-axis), is defined as the mean difference for the probability of seeing congruent flicker during 1–4 s after the cue onset for attended-low-frequency cues (thick green in panel a) compared to other cue types. Attention-task performance (x-axis) is the correlation coefficient between the reported and actual congruent stimuli when comparing between rivalry percepts and crossmodal cues at offset (See Materials and methods for details). The across-subject correlation between the two variables was strong (<italic>r</italic>(32) = .46, <italic>p</italic> = 0.006, two-tailed), demonstrating the crossmodal effects were strongly dependent on performance during the attention task. (<bold>c</bold>) and (<bold>d</bold>) Button-press data aligned at cue onset, with lines and shading as in panel (<bold>a</bold>). Y-axis showing the proportion of button-presses reporting the mismatched flicker at each time point, after (<bold>c</bold>) visual-crossmodal mismatch, or (<bold>d</bold>) visual-crossmodal match at cue onset. Only the data of the attended low-frequency condition differed significantly from visual-only periods.</p><p><supplementary-material id="fig2sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.008</object-id><label>Figure 2—source data 1.</label><caption><title>Attended low-frequency cues alter rivalry dynamics.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40868-fig2-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40868.004</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Across all experimental periods, the average duration of mixed periods per switch per subject was less than 16.7 ms (our binning width), thus showing that mixed percepts are unlikely to have contributed to an increase in the variance of perceptual report timing.</title><p>Switches happened instantly, with zero or one mixed frame (16.7 ms) on average.</p><p><supplementary-material id="fig2s1sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.005</object-id><label>Figure 2—figure supplement 1—source data 1.</label><caption><title>Mean mixed periods per switch per participant.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40868-fig2-figsupp1-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40868.006</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Definition of ‘attention to cues’ in <xref ref-type="fig" rid="fig1">Figure 1c</xref>.</title><p>Y- and x-axes of this figure are the subjective and actual congruent crossmodal and visual stimuli in the attended sessions from one exemplary subject. We defined the correlation coefficient between the two (here, <italic>r</italic> = 0.55) as the ‘attention to cue’ index used as x-axis in <xref ref-type="fig" rid="fig1">Figure 1c</xref>.</p><p><supplementary-material id="fig2s2sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.007</object-id><label>Figure 2—figure supplement 2—source data 1.</label><caption><title>Examplary subject 'attention to cues'.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40868-fig2-figsupp2-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig2-figsupp2-v2.tif"/></fig></fig-group><p>Due to the ongoing dynamics of binocular rivalry, this cueing effect can be calculated when visual and crossmodal information mismatched or matched at cue onset. When crossmodal cues mismatched with the visual percept at cue onset, the likelihood of switching to the previously suppressed, yet matched visual stimuli significantly increased for attended low-frequency cues compared to all other cue types over a time period from 0.62 to 4.12 s (FDR q = 0.05, <xref ref-type="fig" rid="fig2">Figure 2c</xref>). By contrast, when visual and crossmodal cues matched at cue onset, the effect of attending to low-frequency crossmodal cues delayed changes to the previously suppressed visual percept compared to all other cue types, over the period from 1.05 to 3.58 s (FDR q = 0.05, <xref ref-type="fig" rid="fig2">Figure 2d</xref>). Comparison against the visual-only cue period yielded the same conclusion, confirming that the attended low-frequency cues significantly influenced rivalry dynamics, while other cue types did not. As the overall crossmodal effects were unique to the attended low-frequency condition, we focused our subsequent attentional sampling and EEG analysis on this condition.</p></sec><sec id="s2-2"><title>Binocular rivalry dynamics during attended low-frequency crossmodal cues</title><p>Our previous analysis showed that during attended low-frequency crossmodal cues, mismatched crossmodal cues lead to more perceptual switches, as the visually perceived image changed from high-frequency to low-frequency to become congruent with the crossmodal input. In the context of the attentional sampling hypothesis, we directly tested if these changes were occurring rhythmically after the reorientation of attention, and specifically investigated the timing of the first switch, defined as the first change in button-state after cue onset.</p><p>To determine if cues affected the timing of first switches, we calculated the cumulative density function of each subject’s first switches after cue onset (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). Compared to visual-only cue periods, first-switches after cue onset occurred earlier for mismatched cues, indicating an earlier change to the congruent, previously suppressed, visual flicker. By contrast, following matched cues first-switches during rivalry were delayed, indicating an extended maintenance of the congruent visual percept when matched with attended low-frequency crossmodal cues. The facilitation of switches by mismatched cues was observed from 0.63 to 2.45 s and 3.78 to 6.87 s relative to cue onset, with matched cues delaying switches from 1.27 to 3.77 s after onset (paired samples <italic>t</italic>-tests, FDR q = 0.05, in <xref ref-type="fig" rid="fig3">Figure 3b</xref>).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.40868.009</object-id><label>Figure 3.</label><caption><title>Binocular rivalry dynamics during mismatched and matched cues.</title><p>(<bold>a</bold>) The cumulative density function (CDF) of the time to first-switch. Mismatched, matched, and visual-only conditions are colored in magenta, blue, and grey in all panels a–f. Lines and shading show mean and standard error across subjects (<italic>N</italic> = 34) for a and b. (<bold>b</bold>) The difference in CDFs between conditions. Asterisks mark statistical significance (paired-samples <italic>t</italic>-tests) comparing mismatched or matched cues to visual-only periods. FDR q = 0.05. (<bold>c–e</bold>) The time course of the proportion of first switches made after cue onset in (<bold>c</bold>) mismatched, (<bold>d</bold>) matched, and (<bold>e</bold>) visual-only conditions. Thin lines show the mean proportion of first-switches, binned in 16.7 ms increments and averaged across subjects. Thick lines show the smoothed data for visualization. Grey-shaded regions show the time window used for spectral analysis in (<bold>f</bold>). (<bold>f</bold>) The amplitude spectra for the time course of switches in conditions in (<bold>c-e</bold>). Asterisks indicate significant clusters (at least two neighboring frequency bins) after permutation and cluster-based corrections for multiple comparisons (see Materials and methods). The permuted null distribution and critical value for the identified clusters in f) are shown in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>.</p><p><supplementary-material id="fig3sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.013</object-id><label>Figure 3—source data 1.</label><caption><title>Source data for FIgure 3</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40868-fig3-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40868.010</object-id><label>Figure 3—figure supplement 1.</label><caption><title>First switches for any cues, and outside of cue periods.</title><p>The time course of the proportion of first switches made at each time point; following any crossmodal cue onset (<bold>a</bold>), and following crossmodal cue offset (<bold>b</bold>). An analysis of the time-course of perceptual switches reveals no significant spectral peaks at 3.5 or 8 Hz. Y-axis scaled as per <xref ref-type="fig" rid="fig3">Figure 3f</xref>. The presence of an early peak (0–0.5 s) in the proportion of first switches suggests that these changes may be due to stimulus transients, rather than the cue-conditional allocation of attention. As such this early time-window was omitted from subsequent analysis.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40868.011</object-id><label>Figure 3—figure supplement 2.</label><caption><title>The null-distributions for the surrogate datasets generated by the randomization procedure, and the actually observed values of second-stage statistics (i.e., maximum and its highest neighbor’s summed Fourier amplitude).</title><p>After satisfying first-level criteria (p&lt;0.005 uncorrected for two neighboring frequencies), we proceeded to this second-stage statistical test. The observed second-stage statistics (red line) were regarded as significant after cluster corrections for multiple comparisons at p&lt;0.05 level; exceeding the top 95% of the null distribution.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40868.012</object-id><label>Figure 3—figure supplement 3.</label><caption><title>Cumulative Density Functions for remaing crossmodal cue types</title><p>Left column) The cumulative density function (CDF) of the time to first-switch for all conditions other than attended low-frequency. Mismatched, matched, and visual-only conditions are colored in magenta, blue, and grey in all panels. Lines and shading show mean and standard error across subjects (<italic>N</italic> = 34). Right column) the difference in CDF between conditions, each of which failed to exhibit any significant crossmodal effects on perceptual switches compared to visual-only periods (FDR q = 0.05). Thus, we did not pursue further spectral or neural analyses of these conditions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig3-figsupp3-v2.tif"/></fig></fig-group><p>After cue onset, the time-course for the probability of first switches displayed rhythmic oscillatory patterns for mismatched and matched conditions (<xref ref-type="fig" rid="fig3">Figure 3c and d</xref>), but not the visual-only condition (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). Each data point represents the proportion of first switches, which occurred at each time bin (16.7 ms intervals), calculated first per individual subject, and then averaged across subjects.</p><p>To quantify these patterns, we applied the Fourier transform to the period 0.5 to 2 s after cue onset (skipping the first 0.5 s to avoid an onset transient, see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) as performed by previous investigations of attentional sampling (<xref ref-type="bibr" rid="bib36">Dugué et al., 2015</xref>; <xref ref-type="bibr" rid="bib37">Dugué et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>). For this analyses, we corrected for multiple comparisons by using non-parametric cluster-based permutations (<xref ref-type="bibr" rid="bib78">Maris and Oostenveld, 2007</xref>), with thresholds set to <italic>p</italic> &lt; .005 (<xref ref-type="bibr" rid="bib7">Benjamin et al., 2018</xref>) for identification within a cluster, and a final critical value for significance set to <italic>p</italic> = 0.05, cluster corrected (see Materials and methods).</p><p>Strikingly, when the temporal frequency of the cue matched the conscious visual flicker at cue onset, the first perceptual switches followed a 7.5–8 Hz rhythm (<italic>p<sub>cluster</sub></italic> &lt; 0.001, <xref ref-type="fig" rid="fig3">Figure 3f</xref> blue), consistent with suggestions that attention samples sensory stimulation at a rate of approximately 7–8 Hz (<xref ref-type="bibr" rid="bib38">Dugué and VanRullen, 2017a</xref>; <xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib109">VanRullen, 2013</xref>). However, when crossmodal cues were mismatched with the dominant visual image at cue onset, the amplitude spectrum of perceptual switches peaked between 3.3 and 3.75 Hz (<italic>p<sub>cluster</sub></italic> &lt; 0.001, <xref ref-type="fig" rid="fig3">Figure 3f</xref> magenta). This slower rhythm of perceptual changes is consistent with findings that show attention samples two locations at a rate of approximately 3.5–4 Hz (<xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>; <xref ref-type="bibr" rid="bib68">Landau et al., 2015</xref>). No significant peaks were detected for the visual-only condition (<xref ref-type="fig" rid="fig3">Figure 3f</xref>, gray). As to the remaining three cue combinations (attended high-, ignored low- and ignored high-frequency cues), all failed to exhibit any significant crossmodal effects on perceptual switches compared to visual-only periods (shown <xref ref-type="fig" rid="fig2">Figure 2a,c,d</xref>, and <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Thus, we did not pursue further spectral or neural analyses of these conditions. We note that this analysis was performed on the averaged time-course, consistent with previous behavioral investigations of attentional sampling (e.g. <xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>). The pattern in individual participants is similar, though is not present for each individual. This is because the number of switches per condition when separating by attention/mismatch/frequency type was low, and the strength of attentional effects themselves varied across participants (<xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p></sec><sec id="s2-3"><title>The neural correlates of divided and focused attentional sampling</title><p>We hypothesized that at our behaviorally observed attentional sampling frequencies (3.5 and 8 Hz), we should be able to identify the neural correlates of attentional sampling in the EEG signal using an inter-trial phase coherence (ITPC) measure. Previously, the phase of ongoing cortical oscillations have been shown to be reset by external crossmodal events (<xref ref-type="bibr" rid="bib44">Frey et al., 2015</xref>; <xref ref-type="bibr" rid="bib65">Lakatos et al., 2009</xref>; <xref ref-type="bibr" rid="bib89">Romei et al., 2012</xref>; <xref ref-type="bibr" rid="bib99">van Atteveldt et al., 2014</xref>) and to modulate the probability of target detection (<xref ref-type="bibr" rid="bib12">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib68">Landau et al., 2015</xref>; <xref ref-type="bibr" rid="bib79">Mathewson et al., 2009</xref>; <xref ref-type="bibr" rid="bib96">Thorne and Debener, 2014</xref>; <xref ref-type="bibr" rid="bib107">VanRullen et al., 2007</xref>). To isolate the specific neural correlates of attentional sampling, we compared the evoked ITPC, the increase in ITPC during 0 to 2 s after onset compared to −2 to 0 s before onset, in mismatched and matched cue conditions at the attentional sampling frequencies (3.5 and 8 Hz). Importantly, in these conditions, the physical sensory input was identical (i.e., attending low-frequency cues during binocular rivalry), with the only difference between conditions being the subject’s percept at cue onset. Thus, any differences between conditions reflect differences due to the subjective visual percept matching or not with crossmodal cues.</p><p>For this analysis, we retained electrodes only after identification of a significant effect (<italic>p</italic> &lt; 0.05, uncorrected) which also satisfied a spatial cluster-based criterion for selection and used non-parametric permutation distributions to control for multiple comparisons (<xref ref-type="bibr" rid="bib78">Maris and Oostenveld, 2007</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We found that the mismatched cues induced stronger ITPC than the matched cues, at 3.5 Hz over right fronto-central-temporal electrodes [FT8, C6] (<xref ref-type="fig" rid="fig4">Figure 4a</xref>) and at 8 Hz over right parietal-occipital electrodes [P6, PO8] (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). <xref ref-type="fig" rid="fig4">Figures 4b</xref> and <xref ref-type="fig" rid="fig5">5b</xref> compare the evoked ITPC spectra in these regions based on mismatched and matched subjective percepts at cue onset, and confirm that our time window was long enough to distinguish the 3.5 from 4.5 Hz stimulus response (with half bandwidth = 0.5 Hz to resolve the frequency of interest).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.40868.014</object-id><label>Figure 4.</label><caption><title>Evoked ITPC at 3.5 Hz mediates the probability of switches during mismatched and matched cues.</title><p>(<bold>a</bold>) Significant differences in evoked ITPC between mismatched and matched cue conditions (multiple comparisons corrected using a cluster-based criterion; Materials and methods). Non-significant electrodes after spatial-cluster-based corrections are masked. (<bold>b</bold>) Evoked ITPC spectra at significant regions in (<bold>a</bold>). The magenta and blue lines and their shading show mean ±1 standard error of the mean across 34 subjects for mismatched and matched cues, respectively. Solid and dotted vertical black lines mark the behaviorally observed attentional sampling frequency at 3.5 Hz, stimulus frequency at 4.5 Hz respectively. (<bold>c, d</bold>): Stronger 3.5 Hz nITPC correlates with increased PSI during (<bold>c</bold>) mismatched and (<bold>d</bold>) matched conditions. The x and y-axes represent the normalized ITPC and perceptual switch index, respectively (see text for definitions). Straight lines represent least-squares regression predicting PSI from nITPC.</p><p><supplementary-material id="fig4sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.017</object-id><label>Figure 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-40868-fig4-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40868.015</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Displayed are the regions selected for correlation analysis after satisfying our two-stage statistical tests on evoked ITPC, comparing mismatched and matched conditions at 3.5 Hz.</title><p>The right panels display the resulting null distributions obtained after the permutation of condition labels (mismatched vs matched) and performing t-tests across subjects on the mean evoked ITPC for each electrode after upsampling (see Materials and methods). The maximum clustered t-scores per shuffle were retained to create the null distributions. The observed sum of t-scores is displayed as a vertical red line, while the top 95% of the distribution is marked with a vertical dotted back line.</p><p><supplementary-material id="fig4s1sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.016</object-id><label>Figure 4—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40868-fig4-figsupp1-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig4-figsupp1-v2.tif"/></fig></fig-group><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.40868.018</object-id><label>Figure 5.</label><caption><title>Evoked ITPC at 8 Hz mediates the probability of switches during matched cues only.</title><p>(<bold>a</bold>) Significant differences in evoked ITPC between mismatched and matched cue conditions (multiple comparisons corrected using a cluster-based criterion; Methods). Non-significant electrodes after spatial-cluster-based corrections are masked. (<bold>b</bold>) Evoked ITPC spectra at significant regions in (<bold>a</bold>). The magenta and blue lines and their shading show mean ±1 standard error of the mean across 34 subjects for mismatched and matched cues, respectively. Solid and dotted vertical black lines mark in (<bold>b</bold>) the 8 Hz sampling frequency observed behaviorally and stimulus harmonic, respectively. (<bold>c,d</bold>): Stronger 8 Hz nITPC correlates with a decreased PSI for (<bold>d</bold>) matched, but not the (<bold>c</bold>) mismatched condition. The x and y-axes represent the normalized ITPC and perceptual switch index, respectively (see text for definitions). Straight lines represent least-squares regression predicting PSI from nITPC.</p><p><supplementary-material id="fig5sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.021</object-id><label>Figure 5—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-40868-fig5-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.40868.019</object-id><label>Figure 5—figure supplement 1.</label><caption><title>Displayed are the regions selected for correlation analysis after satisfying our two-stage statistical tests on evoked ITPC, comparing mismatched and matched conditions at 8 Hz.</title><p>All conventions as in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</p><p><supplementary-material id="fig5s1sdata1"><object-id pub-id-type="doi">10.7554/eLife.40868.020</object-id><label>Figure 5—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-40868-fig5-figsupp1-data1-v2.mat"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig5-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Attentional-sampling ITPC strength predicts perceptual outcome</title><p>Next, we investigated whether the evoked ITPC at the attentional sampling frequencies in the above-identified regions (<xref ref-type="fig" rid="fig4">Figures 4a</xref> and <xref ref-type="fig" rid="fig5">5a</xref>) predicted the magnitude of behavioral effects across subjects, shown in <xref ref-type="fig" rid="fig2">Figure 2c–d</xref>. We again computed the difference in behavioral effects when comparing attended low-frequency to all other cue types (PSI; 2 to 4 s after cue onset), as a measure for the degree of perceptual change following mismatched and matched cues. Note that when considering a wider time-window (0 to 4 s for behavioral effects, data not shown) a similar pattern of results was obtained, though weaker due to the lack of differences between cue types in early cue periods (i.e. 0 to 1 s, cf. <xref ref-type="fig" rid="fig2">Figure 2c–d</xref>). We used the evoked ITPC from 0 to 2 s after cue onset to restrict our analysis to within attended crossmodal cueing periods (which were 2, 3.1 and 4 s in duration), and to capture the period where the majority of first switches were made after cue onset (<xref ref-type="fig" rid="fig2">Figure 2c and d</xref>). Similar to the PSI, we also subtracted the evoked ITPC across all other conditions from those in the attended low-frequency condition, and abbreviate this as the normalized ITPC (nITPC) below.</p><p>In the right fronto-central-temporal electrodes ([FT8, C6]), which significantly differed in 3.5 Hz ITPC based on mismatched or matched percepts (<xref ref-type="fig" rid="fig4">Figure 4a</xref>), we found that 3.5 Hz nITPC and PSI were positively correlated for both mismatched (<italic>r</italic>(32) = .38, <italic>p</italic> = 0.027, two-tailed, <xref ref-type="fig" rid="fig4">Figure 4c</xref>), and matched cue types (<italic>r</italic>(32) = .34, <italic>p</italic> = 0.049, two-tailed, <xref ref-type="fig" rid="fig4">Figure 4d</xref>). Indicating that for both mismatched and matched cues, increases in 3.5 Hz nITPC facilitated a change in visual consciousness across subjects (<xref ref-type="fig" rid="fig4">Figure 4c–d</xref>).</p><p>In the parieto-occipital electrodes ([P6, PO8]), we found that 8 Hz nITPC was not correlated with the PSI for mismatched cues (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). However, 8 Hz ITPC was negatively correlated with the PSI during matched cues (<italic>r</italic>(32) = −0.39, <italic>p</italic> = 0.023, two-tailed, <xref ref-type="fig" rid="fig5">Figure 5c</xref>), demonstrating that increased 8 Hz nITPC resulted in fewer perceptual switches across subjects (<xref ref-type="fig" rid="fig5">Figure 5d</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our findings provide novel evidence that attentional sampling exists during binocular rivalry, demonstrated in both behavior and the electroencephalogram (EEG). Behaviorally, we replicated previous evidence that stimulus-driven cues can cause a switch to previously suppressed visual stimuli when mismatched with the current percept (to bring about congruence), as well as increase the maintenance of a dominant visual image if cues matched perception (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="bibr" rid="bib30">Dieter et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Lunghi and Alais, 2015</xref>; <xref ref-type="bibr" rid="bib75">Lunghi et al., 2014</xref>). Critically, we found distinct attentional sampling frequencies evident in the time-course of first switches during these cues (<xref ref-type="fig" rid="fig3">Figure 3</xref>). When crossmodal cues were incongruent in temporal frequency with the dominant visual stimulus, switches in visual consciousness occurred earlier, and within a distinct ~3.5 Hz rhythm. This 3.5 Hz rhythm is consistent with previous reports of divided attentional sampling between two locations (<xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>; <xref ref-type="bibr" rid="bib68">Landau et al., 2015</xref>). However, when crossmodal cues were matched in temporal frequency to the dominant visual stimulus, changes in visual consciousness demonstrated an ~8 Hz rhythm, consistent with periodicities in behavioral measures observed when attending to a single visual location (<xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>), and suggestions that a cortical 7–8 Hz attentional rhythm may gate visual processing (<xref ref-type="bibr" rid="bib13">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib38">Dugué and VanRullen, 2017a</xref>; <xref ref-type="bibr" rid="bib45">Fries, 2015</xref>). In the EEG (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>), distinct correlates of these divided and focused attentional sampling frequencies emerged over right fronto-temporal and right parieto-occipital sites, respectively, with ITPC strength at these frequencies correlating with the behaviorally reported change in consciousness across subjects.</p><p>Traditionally, top-down, voluntary attention has been thought to have limited control over perceptual dynamics during binocular rivalry; attention may alter dominance durations, but cannot halt the process of perceptual reversals entirely (<xref ref-type="bibr" rid="bib20">Chong and Blake, 2006</xref>; <xref ref-type="bibr" rid="bib19">Chong et al., 2005</xref>; <xref ref-type="bibr" rid="bib21">Chopin and Mamassian, 2010</xref>; <xref ref-type="bibr" rid="bib32">Dieter et al., 2016b</xref>; <xref ref-type="bibr" rid="bib30">Dieter et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Dieter et al., 2016b</xref>; <xref ref-type="bibr" rid="bib81">Mitchell et al., 2004</xref>; <xref ref-type="bibr" rid="bib85">Paffen and Alais, 2011</xref>; for bottom-up control, including crossmodal stimulation, see <xref ref-type="bibr" rid="bib23">Conrad et al., 2010</xref>; <xref ref-type="bibr" rid="bib27">Deroy et al., 2014</xref>; <xref ref-type="bibr" rid="bib49">Guzman-Martinez et al., 2012</xref>; <xref ref-type="bibr" rid="bib62">Kang and Blake, 2005</xref>; <xref ref-type="bibr" rid="bib74">Lunghi and Alais, 2013</xref>; <xref ref-type="bibr" rid="bib73">Lunghi et al., 2010</xref>; <xref ref-type="bibr" rid="bib75">Lunghi et al., 2014</xref>; <xref ref-type="bibr" rid="bib106">van Ee et al., 2009</xref>). Our results clearly show additional dependence on the top-down deployment of attention, as without explicit instruction to attend to crossmodal signals, no facilitatory crossmodal effects emerged (see also <xref ref-type="bibr" rid="bib60">Jack and Hacker, 2014</xref>; <xref ref-type="bibr" rid="bib95">Talsma et al., 2010</xref>; <xref ref-type="bibr" rid="bib106">van Ee et al., 2009</xref>). This interaction between low-level stimulus features (temporal frequency) and the allocation of attention indicates the facilitative role of both crossmodal stimuli (<xref ref-type="bibr" rid="bib27">Deroy et al., 2014</xref>; <xref ref-type="bibr" rid="bib28">Deroy et al., 2016</xref>) and attention for perceptual transitions during binocular rivalry (<xref ref-type="bibr" rid="bib31">Dieter et al., 2016a</xref>; <xref ref-type="bibr" rid="bib30">Dieter et al., 2015</xref>; <xref ref-type="bibr" rid="bib29">Dieter and Tadin, 2011</xref>; <xref ref-type="bibr" rid="bib85">Paffen and Alais, 2011</xref>; <xref ref-type="bibr" rid="bib117">Zhang et al., 2011b</xref>). Our results are consistent with previous research, which has shown that exogenous feature-based cues can bias rivalry dynamics (<xref ref-type="bibr" rid="bib30">Dieter et al., 2015</xref>; <xref ref-type="bibr" rid="bib106">van Ee et al., 2009</xref>) and extend these reports by revealing an oscillatory basis to these changes in visual perception.</p><p>Our demonstration of these oscillatory changes in visual consciousness, which have been evoked by attended crossmodal cues, are also relevant to current computational models of binocular rivalry (e.g. <xref ref-type="bibr" rid="bib64">Laing and Chow, 2002</xref>; <xref ref-type="bibr" rid="bib70">Li et al., 2017</xref>; <xref ref-type="bibr" rid="bib115">Wilson, 2003</xref>). No current model has accounted for the interaction we observe between attentional allocation and crossmodal stimuli, nor attention as an oscillatory process. Most recently, <xref ref-type="bibr" rid="bib70">Li et al., 2017</xref> have described a model for binocular rivalry incorporating attention and mutual inhibition. In their model, attentional modulation is dealt to the sensory representation that has the stronger sensory responses, by providing feedback to monocular-excitatory drives that otherwise increase monotonically with stimulus contrast. Building on our findings, future models could incorporate an oscillatory increase in excitatory drive as a result of periodic, rather than sustained attentional modulation (<xref ref-type="bibr" rid="bib43">Fiebelkorn et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Helfrich et al., 2018</xref>; <xref ref-type="bibr" rid="bib112">VanRullen, 2018</xref>).</p><p>Previous behavioral investigations of attentional sampling have relied upon a brief cue to reorient attention, before estimating the time-course of target detection by densely sampling subject responses over closely spaced target-presentation intervals. Our design is unique in that ‘target-detection’ here is operationalized as the first reported change in visual consciousness for a continuously presented stimulus, resolved at 16.7 ms (or 60 Hz) from 500 ms to 2000 ms following cue-onset.</p><p>Past researchers have demonstrated approximately 7–8 Hz fluctuations in perceptual performance following the allocation of visual attention (<xref ref-type="bibr" rid="bib36">Dugué et al., 2015</xref>; <xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib109">VanRullen, 2013</xref>; <xref ref-type="bibr" rid="bib107">VanRullen et al., 2007</xref>; <xref ref-type="bibr" rid="bib119">Zoefel and VanRullen, 2017</xref>), commensurate with suggestions that cortical oscillations at approximately 7–8 Hz gate the content of visual perception (<xref ref-type="bibr" rid="bib13">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib38">Dugué and VanRullen, 2017a</xref>; <xref ref-type="bibr" rid="bib50">Hanslmayr et al., 2013</xref>). In our binocular rivalry paradigm, we also observed changes in visual consciousness occurring within an 8 Hz rhythm, yet unique to when cues were congruent with the dominant visual percept at cue onset. By contrast, perceptual sampling has previously been observed at ~4 Hz when cues have encouraged dividing attention between two objects or locations (<xref ref-type="bibr" rid="bib37">Dugué et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Huang et al., 2015</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>; <xref ref-type="bibr" rid="bib68">Landau et al., 2015</xref>; <xref ref-type="bibr" rid="bib93">Song et al., 2014</xref>). As such, the ~3.5 Hz rhythm we observed when crossmodal cues mismatched with the conscious visual percept extends the evidence for divided attentional sampling to binocular rivalry.</p><p>From our data alone, we cannot infer whether during conventional binocular rivalry, attention samples at 8 or 4 Hz. We surmise that increased attention to stimulus competition may be required to observe the attentional sampling rhythms we report here. Indeed outside of attended cue periods we did not observe periodic behavioral responses (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), suggesting that attentional sampling is commensurate with sustained and goal-directed attention, instead of persisting throughout rivalry. We also note that the issue of trial-to-trial variability when reporting on perceptual changes cannot be completely avoided in binocular rivalry research, and is important to consider. Here, one might argue that variable timing in perceptual reports may blur any effects of temporal periodicity. However, our results clearly demonstrate that a change in perceptual state occurred for attended low-frequency cues that were unique in changing visual consciousness compared to visual-only baseline, at or near frequencies of attentional sampling that have been reported in previous literature. By comparison, the time-course of visual switches during visual-only periods did not exhibit periodic sampling, nor did the first-switches during non-attended, or high-frequency cues.</p><p>Distinct neural correlates of these attentional sampling rhythms were also found in the EEG. We found significantly greater 3.5 Hz ITPC strength for mismatched compared to matched cue types over right fronto-centro-temporal electrodes [FT8 and C6], suggesting this region may be a candidate neural correlate for divided periodic attentional sampling (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). Accordingly, following both mismatched and matched cues, increased 3.5 Hz ITPC in this region also positively correlated with the likelihood of switching to the previously suppressed visual image across subjects (<xref ref-type="fig" rid="fig4">Figure 4c–d</xref>). Using visual-only stimulation, previous research has identified a pre-target ~4 Hz phase-dependency for peri-threshold perception when attention is divided across visual hemifields (<xref ref-type="bibr" rid="bib68">Landau et al., 2015</xref>). While our right fronto-temporal region is different to those previously implicated in attentional-sampling (e.g. <xref ref-type="bibr" rid="bib68">Landau et al., 2015</xref>), we note that in our paradigm, attention was not divided between visual hemifields, but between competing stimuli during binocular rivalry. Right fronto-temporal regions have previously been implicated in the reorientation of attention to unattended locations (<xref ref-type="bibr" rid="bib24">Corbetta and Shulman, 2002</xref>; <xref ref-type="bibr" rid="bib33">Downar et al., 2000</xref>; <xref ref-type="bibr" rid="bib88">Proskovec et al., 2018</xref>), and most recently, <xref ref-type="bibr" rid="bib52">Helfrich et al., 2018</xref> have demonstrated that the phase of ~4 Hz dependent sampling in frontal and parietal areas determines visual perception. Taken together, our results support previous research indicating that a periodic attentional sampling mechanism modulates visual perception, here extending this finding into binocular rivalry when visual stimuli spatially overlap and compete for perceptual dominance.</p><p>We also found behavioral and neural correlates of focused attentional sampling during binocular rivalry when cues were consistent with the prevailing visual percept. Specifically, 8 Hz ITPC over parieto-occipital electrodes was negatively correlated with the likelihood of switching to the incongruent perceptual outcome (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). Previously, phase-dependent peri-threshold perception has been reported for focused attention tasks in the visual domain (<xref ref-type="bibr" rid="bib12">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib13">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="bib50">Hanslmayr et al., 2013</xref>; <xref ref-type="bibr" rid="bib79">Mathewson et al., 2009</xref>), and has primarily implicated an approximately 7 Hz component located over fronto-central electrodes (<xref ref-type="bibr" rid="bib12">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib13">Busch and VanRullen, 2010</xref>). Given the differences between paradigms, it is unsurprising that our identified region for focused attentional sampling does not coincide with those reported in previous research regarding phase-dependent perception. Particularly as our right-lateralized response may be due to the left-lateralized tactile input used to investigate crossmodal attentional sampling (though ITPC was not different among the three crossmodal stimulation types, data not shown). While promising, future experiments that control for this lateralization are needed to characterize the contributions of fronto-centro-temporal and parieto-occipital regions to this effect, particularly as activity over each of these regions has previously been implicated in the reorienting of visuo-spatial attention (<xref ref-type="bibr" rid="bib24">Corbetta and Shulman, 2002</xref>; <xref ref-type="bibr" rid="bib33">Downar et al., 2000</xref>; <xref ref-type="bibr" rid="bib40">Dugué et al., 2018</xref>; <xref ref-type="bibr" rid="bib88">Proskovec et al., 2018</xref>), and for the integration of multisensory stimuli into a coherent percept (<xref ref-type="bibr" rid="bib6">Beauchamp, 2005</xref>; <xref ref-type="bibr" rid="bib14">Bushara et al., 2003</xref>; <xref ref-type="bibr" rid="bib15">Calvert and Thesen, 2004</xref>; <xref ref-type="bibr" rid="bib34">Driver and Noesselt, 2008</xref>; <xref ref-type="bibr" rid="bib116">Zhang et al., 2011a</xref>). Increases in right parieto-occipital theta power (4–8 Hz) have also been shown when attending to visual stimuli in the presence of auditory distractors (<xref ref-type="bibr" rid="bib105">van Driel et al., 2014</xref>), with the phase of right parieto-occipital alpha (8–10 Hz) or theta (6–7 Hz) oscillations determining the perceptual outcome of bistable stimuli (<xref ref-type="bibr" rid="bib90">Ronconi et al., 2017</xref>). As such, the present modulation for 8 Hz parieto-occipital ITPC is consistent with the idea that right-parietal networks may preferentially represent temporal information in the visual modality (<xref ref-type="bibr" rid="bib5">Battelli et al., 2007</xref>; <xref ref-type="bibr" rid="bib48">Guggisberg et al., 2011</xref>).</p><p>Reporting binocular rivalry switches involves both a change in perception, and a decision to press the button. Accordingly, the attentional sampling in binocular rivalry we report here may reflect the fluctuation of perception or of decision criterion. Recent studies of behavioral oscillations that have employed signal detection theory have reported that sensitivity and response criterion both exhibit oscillations (at distinct frequencies) in the high theta/low alpha band, for both vision (<xref ref-type="bibr" rid="bib118">Zhang et al., 2018</xref>) and audition (<xref ref-type="bibr" rid="bib53">Ho et al., 2017</xref>). Consequently, whether our oscillations reflect perceptual or decision-level effects must be clarified (<xref ref-type="bibr" rid="bib53">Ho et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Iemi and Busch, 2018</xref>; <xref ref-type="bibr" rid="bib58">Iemi et al., 2017</xref>; <xref ref-type="bibr" rid="bib71">Limbach and Corballis, 2016</xref>). Our paradigm cannot resolve this as it is, although a future investigation using our paradigm combined with signal detection theory could do so.</p><p>Our analysis has so far revealed that when crossmodal cues mismatched with the dominant binocular rivalry stimulus, that rates of attentional sampling slowed to ~3.5 Hz – implicating the division of attention over multiple locations. However, our exogenous cues oriented attention toward the congruency of visual and crossmodal stimuli, prompting the question: between what was attentional sampling divided? One possibility is that attentional sampling during mismatched cues was divided between two sensory modalities, as the brain tried to resolve a conflict between concurrent auditory/tactile and visual information. <xref ref-type="fig" rid="fig6">Figure 6a</xref> provides a schematic of this multisensory interpretation. If the neural activity in our identified region is representative of divided sampling between modalities, it constitutes the first evidence that an attentional sampling mechanism can flexibly orient between temporally co-modulating crossmodal stimuli. Although the facilitative role of attention in multisensory integration remains controversial (<xref ref-type="bibr" rid="bib51">Hartcher-O’Brien et al., 2016</xref>; <xref ref-type="bibr" rid="bib95">Talsma et al., 2010</xref>), we see it as a viable possibility that this mechanism resolved perceptual ambiguity through a visual perceptual switch to the competing image, rendering the multisensory stimuli congruent.</p><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.40868.022</object-id><label>Figure 6.</label><caption><title>Two possible interpretations of attentional sampling during mismatched crossmodal cues. Schematic representation of attentional sampling and perceptual oscillations during binocular rivalry.</title><p>(<bold>a</bold>) Crossmodal sampling hypothesis: While perceiving the high-frequency visual flicker, an attended low-frequency crossmodal cue mobilises attention to sample between the dominant image and mismatched crossmodal cue at ~3.5 Hz. As a consequence, the likelihood of the first perceptual switch is modulated at ~3.5 Hz. (<bold>b</bold>) Conscious-nonconscious sampling hypothesis: The onset of a mismatched cue prompts attention to sample between separate visual features, which in our paradigm consists of dominant and suppressed visual images. We do not suggest that these are the only mechanisms of attentional sampling during binocular rivalry, and only illustrate the interpretations discussed.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-40868-fig6-v2.tif"/></fig><p>As only attended, low-frequency modulated cues enabled a change in visual consciousness, we must consider whether the lack of a high-frequency effect reflects an upper limit in temporal frequency on crossmodal interactions or attention. Such a limit on crossmodal interactions may explain why we observed low- but not high-frequency behavioral effects in the present task, and is supported by previous investigations regarding the binding of multisensory stimulus attributes (<xref ref-type="bibr" rid="bib46">Fujisaki and Nishida, 2005</xref>; <xref ref-type="bibr" rid="bib47">Fujisaki and Nishida, 2010</xref>; <xref ref-type="bibr" rid="bib75">Lunghi et al., 2014</xref>; <xref ref-type="bibr" rid="bib113">Vroomen and Keetels, 2010</xref>), and the limits of crossmodal temporal judgments (<xref ref-type="bibr" rid="bib46">Fujisaki and Nishida, 2005</xref>; <xref ref-type="bibr" rid="bib47">Fujisaki and Nishida, 2010</xref>; <xref ref-type="bibr" rid="bib55">Holcombe, 2009</xref>; <xref ref-type="bibr" rid="bib113">Vroomen and Keetels, 2010</xref>). For example, <xref ref-type="bibr" rid="bib46">Fujisaki and Nishida, 2005</xref> have shown that judgments of temporal synchrony between rhythmic sensory streams degrade above ~4 Hz. It is plausible that the ineffective crossmodal cueing that we found is related to the above-mentioned findings, reflecting a limit on crossmodal integration processes, rather than attention.</p><p>Having said that, one previous study using a similar design to ours was successful in eliciting a high-frequency crossmodal effect (15–20 Hz; <xref ref-type="bibr" rid="bib75">Lunghi et al., 2014</xref>), and notably, in the absence of explicit attentional demands. However, these differences are not wholly unexpected, as to optimize the present task for EEG recordings we used larger (6.5° visual angle) luminance-modulated sinusoidal gratings to facilitate subsequent steady-state visually evoked potential analyses. While in comparison, Lunghi et al. succeeded in showing a high-frequency effect with rivalry stimuli that were contrast-modulated narrow-band random noise patterns (3.2° visual angle), and did so under conditions analogous to our non-attend conditions. This difference in the composition of visual stimuli is noteworthy, as stimulus size is known to strongly affect rivalry dynamics (<xref ref-type="bibr" rid="bib9">Blake et al., 1992</xref>). To our knowledge, whether stimulus size impacts upon crossmodal effects during binocular rivalry is unknown. However, given the strength of our results for attended low-frequency flicker (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), we note that the low- and high-frequency effects observed by <xref ref-type="bibr" rid="bib75">Lunghi et al., 2014</xref> are not generalizable to the larger and attended-rivalry stimuli employed here. Similarly, whether the type of stimuli (e.g., gratings vs random noise patterns) also impacts upon crossmodal effects during rivalry represents a fruitful endeavor for research, particularly given the novel possibility of distinguishing between crossmodal and attentional limits on attentional sampling.</p><p>An alternate possibility to crossmodal attentional sampling is that the 3.5 Hz rhythm in our paradigm reflects divided attentional sampling between dominant and suppressed visual images during binocular rivalry (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). The frequency of divided attentional sampling that we observed is consistent with those obtained when visual attention has been divided between two objects or locations (<xref ref-type="bibr" rid="bib42">Fiebelkorn et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>). As our binocular rivalry stimuli necessarily occupied the same spatial location, attention in our paradigm was likely divided between either features or objects, instead of locations. Indeed, feature-based attention has already been shown to modulate neural processes when an attended target is suppressed during continuous flash suppression (<xref ref-type="bibr" rid="bib61">Kanai et al., 2006</xref>). During binocular rivalry, perceptual dominance is also influenced by object-based attention (<xref ref-type="bibr" rid="bib81">Mitchell et al., 2004</xref>), with unconscious selection mechanisms argued to mediate perceptual transitions (<xref ref-type="bibr" rid="bib72">Lin and He, 2009</xref>). This second alternative is also indirectly supported by the temporal limits of binocular rivalry when conflicting visual stimuli are presented asynchronously, without temporal overlap between the two eyes (<xref ref-type="bibr" rid="bib84">O'Shea and Blake, 1986</xref>; <xref ref-type="bibr" rid="bib102">van Boxtel et al., 2008b</xref>; <xref ref-type="bibr" rid="bib100">van Boxtel et al., 2007</xref>). The maximum stimulus onset asynchrony that can sustain this type of rivalry is approximately 350 <italic>± </italic>50 ms, beyond which alternating stimuli introduced to one eye are perceived immediately, without rivalry occurring (<xref ref-type="bibr" rid="bib101">van Boxtel et al., 2008a</xref>). This limit is consistent with a 7–8 Hz attentional sampling rhythm distributed between the two conflicting stimuli (each sampled at ~3–4 Hz). When stimuli are presented rapidly enough they are temporally bound together and can engage in ongoing rivalry; when stimuli are presented slower than at 3–4 Hz, they are temporally individuated by attention, and rivalry ceases. A recent computational model that explicitly modeled time-varying attention could indeed reproduce this finding (<xref ref-type="bibr" rid="bib70">Li et al., 2017</xref>), suggesting that attention is the process that temporally binds the successive stimulus presentations together. Based on our findings, we propose the persistence of percepts may also be modeled using an oscillatory, and feature-selective attentional mechanism (<xref ref-type="bibr" rid="bib69">Li et al., 2015</xref>; <xref ref-type="bibr" rid="bib70">Li et al., 2017</xref>).</p><p>The suggestion that attention can sample between conscious and nonconscious vision is also consistent with a view that the underlying neuronal processes for attention and consciousness are supported by distinct neural mechanisms (<xref ref-type="bibr" rid="bib3">Bahrami et al., 2007</xref>; <xref ref-type="bibr" rid="bib114">Watanabe et al., 2011</xref>); for review see <xref ref-type="bibr" rid="bib63">Koch and Tsuchiya, 2007</xref>). We note that while attentional sampling of a suppressed image suggests that attention is not sufficient for consciousness (<xref ref-type="bibr" rid="bib26">Dehaene et al., 2006</xref>; <xref ref-type="bibr" rid="bib63">Koch and Tsuchiya, 2007</xref>; <xref ref-type="bibr" rid="bib66">Lamme, 2003</xref>; <xref ref-type="bibr" rid="bib103">van Boxtel et al., 2010a</xref>; <xref ref-type="bibr" rid="bib104">van Boxtel et al., 2010b</xref>), this interpretation remains consistent with a view that attention may still be necessary for conscious perception (<xref ref-type="bibr" rid="bib18">Chica and Bartolomeo, 2012</xref>; <xref ref-type="bibr" rid="bib22">Cohen and Dennett, 2011</xref>; <xref ref-type="bibr" rid="bib80">Merikle and Joordens, 1997</xref>; <xref ref-type="bibr" rid="bib83">O'Regan and Noë, 2001</xref>; <xref ref-type="bibr" rid="bib86">Posner, 1994</xref>; <xref ref-type="bibr" rid="bib87">Posner, 2012</xref>).</p><p>Whether attributable to conscious-nonconscious, or visual-crossmodal attentional sampling, the present results also complement the ‘active-sensing’ hypothesis (<xref ref-type="bibr" rid="bib92">Schroeder et al., 2010</xref>), whereby perceptual selection is determined by routine exploratory behaviors. According to the active-sensing hypothesis, attention is critical to search for task-relevant information from the environment (<xref ref-type="bibr" rid="bib92">Schroeder et al., 2010</xref>), particularly via the rhythmic coordination of multisensory information (<xref ref-type="bibr" rid="bib92">Schroeder et al., 2010</xref>; <xref ref-type="bibr" rid="bib96">Thorne and Debener, 2014</xref>). Intriguingly, early contributions from multi-sensory (non-visual) information have been shown to modulate perception (<xref ref-type="bibr" rid="bib82">Morillon et al., 2014</xref>; <xref ref-type="bibr" rid="bib92">Schroeder et al., 2010</xref>; <xref ref-type="bibr" rid="bib99">van Atteveldt et al., 2014</xref>). The rhythmic modulation of visual performance has also been demonstrated to follow the onset of both voluntary (<xref ref-type="bibr" rid="bib54">Hogendoorn, 2016</xref>), and preparatory motor behaviors (<xref ref-type="bibr" rid="bib98">Tomassini et al., 2017</xref>; <xref ref-type="bibr" rid="bib97">Tomassini et al., 2015</xref>). Here, in further support of the active-sensing hypothesis, we have shown that task-relevant crossmodal information can change the rhythmic modulations of perceptual selection during competition for perceptual dominance.</p><p>In summary, here we have provided novel evidence in support of attentional sampling during binocular rivalry through the use of crossmodal cues matched to either a conscious or nonconscious visual stimulus. As the attention sampling hypothesis continues to garner traction from various psychophysical and neuronal paradigms (<xref ref-type="bibr" rid="bib43">Fiebelkorn et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Helfrich et al., 2018</xref>; <xref ref-type="bibr" rid="bib110">VanRullen, 2016a</xref>; <xref ref-type="bibr" rid="bib111">VanRullen, 2016b</xref>; <xref ref-type="bibr" rid="bib112">VanRullen, 2018</xref>), future targeted experimentation can confirm whether attention can indeed sample across modalities (<xref ref-type="fig" rid="fig6">Figure 6a</xref>), as well as if attention can sample between conscious and nonconscious neural representations during binocular rivalry (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). The interactions between crossmodal stimuli and conscious perception represent a fruitful avenue for experimentation (<xref ref-type="bibr" rid="bib41">Faivre et al., 2017</xref>), here uncovering the previously unknown dependence of attention and consciousness on rhythmic neural dynamics of the human brain.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>A total of 34 healthy individuals (21 females, 1 left-handed, average age 23 ± 4.7) were recruited via convenience sampling at Monash University, Melbourne, Australia. All had normal or corrected-to-normal vision and gave written informed consent prior to participation. Monash University Human Research and Ethics Committee approved this study, and subjects were paid 15 AUD per hour of their time, over an approximate total of 5 hours.</p></sec><sec id="s4-2"><title>Apparatus and stimuli</title><p>Stimuli were generated using Psychtoolbox (<xref ref-type="bibr" rid="bib11">Brainard, 1997</xref>); RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_002881">SCR_002881</ext-link>) and custom MATLAB scripts (<ext-link ext-link-type="uri" xlink:href="https://github.com/Davidson-MJ/BRproject-attentionsampling">https://github.com/Davidson-MJ/BRproject-attentionsampling</ext-link>; RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_001622">SCR_001622</ext-link>; <xref ref-type="bibr" rid="bib25">Davidson, 2018</xref>). Each visual stimulus was viewed through a mirror stereoscope placed at an approximate viewing distance of 55 cm from computer screen (29 × 51 cm, 1080 × 1920 pixels, 60 Hz refresh rate) with the subject’s head stabilized via chin rest. Rivalry stimuli were red and green gratings displayed on a black background, with a white frame to aid binocular fusion, embedded within the wider gray background of the remaining portions of the screen. Beside each white framed image, colored arrows indicated the direction for button-press (e.g., right for red, left for green). Gratings were sinusoidal with spatial frequency of 0.62 cycles per degree, oriented ±45<bold>°</bold> from vertical, and subtended 6.5<bold>°</bold> visual angle (240 × 240 pixels on the display). Visual stimuli were sinusoidally contrast-modulated at either 4.5 or 20 Hz using a temporal sinusoidal envelope. The phase of each grating was static throughout each 3 min binocular rivalry block, yet shifted after each block to reduce the effects of visual adaptation. The stimulus size was chosen after piloting the largest images that could support minimal incidences of piecemeal rivalry. The very low spatial frequency of 0.6 cycles per degree and the rapid temporal modulations both favor neurons with large receptive fields and thus reduce the incidence of piecemeal rivalry. In addition, by rivaling red and green stimuli, each image had a consistent color which helps group rivalry alternations and maintain perceptual coherence rather than piecemeal switching. We explained to participants that piecemeal percepts may occur and in such cases they should indicate the stimulus that was most predominant (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>For crossmodal stimuli 50 Hz carrier tones were amplitude modulated by 4.5 or 20 Hz sine waves to create digital waveforms, which were either 2, 3.1 or 4 s in duration. For tactile stimulation, subjects clasped a wooden ball with their left hand attached to a Clark Synthesis Tactile Sound Transducer (TST429 platinum) housed in a custom sound insulated box (<xref ref-type="bibr" rid="bib75">Lunghi et al., 2014</xref>). Auditory stimulation was delivered binaurally through Etymotic HD5 noise reduction headphones, with ACCU-Fit foam ear tips to reduce ambient noise.</p></sec><sec id="s4-3"><title>Stimulus timing</title><p>Accurate stimulus timing of synchronous visual and crossmodal stimuli was ensured with a WDM-compatible, hardware-independent, low-latency ASIO driver (<ext-link ext-link-type="uri" xlink:href="http://www.asio4all.com">www.asio4all.com</ext-link>), which was necessary to minimize audio buffer duration to sub-millisecond intervals and reduce latency compensation. The time-course of stimulus presentation was also physically recorded in the EEG for offline analysis. Photodiodes were used to record the flicker-envelope of visual stimuli and stored as separate channels in the ongoing EEG. The waveforms for crossmodal stimulation were simultaneously sent to both the presentation hardware and external electrode channels using a digital splitter (Redback A2630 4 Channel Headphone Distribution Amplifier). Stimulus presentation lag was assessed by computing the difference between the recorded frames of trigger-codes and actual physical trace within the EEG as part of data pre-processing. We adjusted the relative timing of behavioral and EEG data accordingly as part of this analysis. In most cases, no adjustment was necessary, requiring a maximum change of 3 frames in duration on &lt;1% of blocks across all subjects.</p></sec><sec id="s4-4"><title>Calibration of visual stimuli</title><p>A maximum of 10 one-minute binocular rivalry blocks were performed prior to experimentation on the first day for all subjects. These blocks served to familiarize subjects with reporting their visual percepts during binocular rivalry, and to calibrate approximately equal dominance durations for the flickering stimuli in each eye. Contrast values for left/right eye, green/red color, and low/high frequency stimulus combinations (in total, eight combinations) were adjusted on a logarithmic scale until approximately equivalent total dominance durations were reached (between 1:1 and 1:1.5), with the additional requirement that the average perceptual duration for each stimulus was longer than 1 s. As there were 24 unique 3 min binocular rivalry blocks on each day of experimentation, each of the 8 combinations of visual parameters were balanced across all three crossmodal conditions.</p></sec><sec id="s4-5"><title>Calibration of auditory stimuli</title><p>Prior to experimentation, subjects were also tasked with equating the perceptual intensity of tactile and auditory stimulation for each low- and high-frequency condition, to achieve approximately equal phenomenological intensity across subjects and stimulus conditions. For all subjects, the amplitude of tactile vibrations was set to the same comfortable, supra-threshold level (approximately equivalent to 65 dB SPL). In the absence of visual stimulation, simultaneous auditory and tactile stimuli were then presented in a staircase procedure, with subjects adjusting the amplitude of auditory tones to match the perceived intensity of simultaneous tactile vibrations. They performed the matching task separately within low-frequency auditory tones and tactile vibrations and within high-frequency auditory tones and tactile vibrations. This calibration procedure was performed on each day of testing, to account for differences in the insertion depth of inner-ear headphones across separate days.</p></sec><sec id="s4-6"><title>Experimental procedure and behavioral analysis</title><p>A total of 24 three-minute binocular rivalry blocks were presented on each of the two separate days of testing. In each block, subjects reported their dominant visual percept during rivalry while receiving occasional crossmodal cues, which were either auditory, tactile, or simultaneous auditory and tactile. In a given three-minute block, we presented only one of the three types of crossmodal cues. The order of these blocks were randomized for each subject and each day of experimentation. In each block, 12 trials of crossmodal cues were presented. Each cue was either low (4.5 Hz) or high (20 Hz) frequency auditory and/or tactile stimulation. Six cues were presented for each frequency, with durations composed of three x 2 s, two x 3.1 s, and one x 4 s cues. To increase uncertainty for the timing of the cues, we inserted three null cues (which we call visual-only periods, <xref ref-type="fig" rid="fig1">Figure 1</xref>) without any crossmodal stimulation for a duration of 2.6 s (the average duration of crossmodal cues). We also used these visual-only periods as a baseline for behavioral analyses (<xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>). We randomized the order of all cues, which were separated with uniform jittering by 7–10 s ISI within each block.</p><p>Across all sessions, subjects were told to focus on accurately reporting their dominant visual percept at all times via button-press. As the state of the button-press was sampled at 60 Hz, the same rate as the video refresh rate, we were able to estimate the probability and time-course of binocular rivalry dynamics over 16.7 ms intervals.</p><p>Over two sessions on separate days, subjects distributed attention between visual rivalry and crossmodal cues based on separate task instructions. On day 1 for <italic>n</italic> = 18 or day 2 for <italic>n</italic> = 16, subjects were instructed to ignore the crossmodal cues and to focus on reporting only visual rivalry. For the other session, subjects were instructed to distribute attention across both visual rivalry and crossmodal cues. To ensure their attention was on task, these alternate days included task instructions for subjects to silently tally the number of times the temporal frequency of an attended crossmodal cue matched that of their dominant visual percept at the time of crossmodal cue’s offset. Due to the varied duration of crossmodal cues, this task ensured that attention was allocated consistently throughout the presentation of crossmodal cues. To familiarize subjects with these task demands, an additional two practice blocks (3 minutes each) were included during the calibration procedure on the relevant day of experimentation. Although 34 subjects were retained for final analysis, five others were recruited and began the experiment, yet failed to complete their second day of experimentation. One other subject was removed due to their failure in following task instructions and excessive movement during EEG recording.</p></sec><sec id="s4-7"><title>Evaluation of attention-on-task</title><p>To evaluate the attentional allocation to both visual and crossmodal stimuli, at the end of each 3 min block we asked subjects to verbally report their subjective estimate of the number of crossmodal stimuli which were matched in temporal frequency to the flicker of their dominant visual percept at the point of attended crossmodal cue offset. Then, we defined an index, ‘attention to cues’ (<xref ref-type="fig" rid="fig2">Figure 2b,x</xref>-axis) as the correlation coefficient between 24 subjective estimates (one per attended block) and the actual recorded occurrences of congruent stimuli. <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> displays the correlation between subjective and actual congruent stimuli for an exemplary subject.</p></sec><sec id="s4-8"><title>Behavioral data analysis</title><p>We preprocessed the button-press data to accurately estimate the timing of changes in visual consciousness during binocular rivalry. First, we categorised each time-point according to the flicker frequency of the dominant visual stimulus reported. To analyze the time-course of the probability of a button-press state (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), we categorized button-presses (which could correspond to either low- or high-frequency) as either congruent or incongruent with the ongoing crossmodal stimulus frequency. Then, we obtained the probability of a congruent button-press state as a function of time per subject, by averaging responses at each time point across all 144 trials per attention x frequency cue subtype.</p><p>For visual-only periods, the left button (corresponding to left-eye dominance) was arbitrarily set to congruent prior to the averaging of probability traces within subjects. As visual parameters were balanced across all blocks, this selection necessarily balanced across visual frequency and color parameters, and we note that the identical analysis performed using right-eye congruence produced equivalent results. Mismatched (<xref ref-type="fig" rid="fig2">Figure 2c</xref>) or matched (<xref ref-type="fig" rid="fig2">Figure 2d</xref>) condition comparisons were then defined by whether the congruent button (left-eye dominant) was pressed at cue onset.</p><p>In <xref ref-type="fig" rid="fig2">Figure 2c and d</xref>, we set the y-axis for ‘Probability of seeing mismatched flicker’, to reflect the probability of perceptual states that differ in temporal frequency from the crossmodal cue. In <xref ref-type="fig" rid="fig2">Figure 2a,c and d</xref>, we compared among six conditions with one-way repeated-measures ANOVAs: 1, visual-only on attend days; 2, visual-only on non-attend days; 3, attended low-frequency; 4, attended high-frequency; 5, unattended low-frequency; and 6, unattended high-frequency. We defined significant differences among conditions at those time points that survived corrections for multiple comparisons with planned comparisons between cue types and the visual-only baseline, using FDR at q = 0.05 (<xref ref-type="bibr" rid="bib8">Benjamini and Yekutieli, 2001</xref>).</p></sec><sec id="s4-9"><title>Perceptual switch index (PSI)</title><p>To quantify crossmodal effects during binocular rivalry, we defined the perceptual switch index (PSI). PSI is the difference in the probability of a change in percept when comparing attended low-frequency to four other crossmodal cues. For the y-axis in <xref ref-type="fig" rid="fig2">Figure 2b</xref>, we calculated the PSI as the difference in the probability of viewing a congruent visual flicker over the period 1–4 s after stimulus onset. The same subtraction was used to compare the probability of viewing the previously suppressed visual flicker following mismatched (<xref ref-type="fig" rid="fig4">Figures 4c</xref> and <xref ref-type="fig" rid="fig5">5c</xref>) and matched cues (<xref ref-type="fig" rid="fig4">Figures 4d</xref> and <xref ref-type="fig" rid="fig5">5d</xref>), for the period 2–4 s after onset. This shorter time window was selected to capture when the crossmodal effects on binocular rivalry emerged for mismatched and matched cues. A similar pattern to the results displayed in <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref> was shown when a wider window was used (e.g. 0–4 s, data not shown).</p></sec><sec id="s4-10"><title>Spectral analysis of first switches</title><p>For our spectral analysis (<xref ref-type="fig" rid="fig3">Figure 3</xref>), we focused on the first perceptual switches, which were the first time-point recording a change in button-press state after cue onset. To account for individual variation in the amount of overall switches, the proportion of switches at each time point was first calculated at the subject level, before averaging across all subjects. We sampled button-presses at 60 Hz (or every 16.7 ms). For the spectral analysis of perceptual switches (<xref ref-type="fig" rid="fig3">Figure 3f</xref>), we applied a single-taper fast Fourier transform (FFT) to the period 0.5–2 s after cue onset (Nyquist = 30 Hz, a half bandwidth = 0.67 Hz). This window was selected to restrict the analysis so that all the analyzed trials occurred during an attended cueing period (as the minimum crossmodal cue duration was 2 s), and to remove transient button presses occurring early in the cue period, which were unlikely to be caused by crossmodal match or mismatch (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). We display the frequency range of 0–15 Hz for all conditions, as no higher frequencies (above 9 Hz) were significant after our two-stage statistical criteria.</p></sec><sec id="s4-11"><title>Statistics on spectra of first switch timing</title><p>To assess the statistical significance of behavioral spectra we used a two-stage statistical testing procedure as applied in previous investigations of attentional sampling (<xref ref-type="bibr" rid="bib67">Landau and Fries, 2012</xref>) and electrophysiological research (<xref ref-type="bibr" rid="bib78">Maris and Oostenveld, 2007</xref>). At the first stage, we first detected significant frequencies (at <italic>p </italic>&lt; 0.005 uncorrected) through a non-parametric randomization procedure. In this procedure, after obtaining the spectral amplitude for the observed data across subjects, we generated a null distribution of first switches during the same cue period by randomly shifting switch-times within each subject, while keeping the number of perceptual switches the same. We generated 5000 surrogate datasets in this way, to test the null hypothesis that there were no temporal effects on the timing of perceptual switches. We then compared the amplitude of the Fourier transform from the observed and the surrogate data at each frequency. We regarded the spectral amplitude at a certain frequency to be significantly above chance, if the observed spectral amplitude exceeded the top 99.5% of the null-distribution of amplitudes at each frequency generated by surrogate data.</p><p>At the second stage, we applied a cluster criterion, which corrects for multiple comparisons across multiple frequencies through a permutation procedure (<xref ref-type="bibr" rid="bib78">Maris and Oostenveld, 2007</xref>). We required that the first-level significance (p&lt;0.005 uncorrected) be sustained for at least two neighboring frequencies, and retained the sum of their clustered test-statistics (amplitudes in this case) as our observed data. Then, from our surrogate dataset, we calculated the maximum cluster-based amplitudes per surrogate (maximum spectral amplitude excluding 0–1 Hz and nearest neighbor), which we retained as the null-distribution to compare against our observed data. Candidate clusters survived this second order analysis when their observed cluster-based test-statistics exceeded the top 95% of the null distribution, or corrected to <italic>p<sub>cluster</sub></italic> &lt;0.05 if testing across multiple clusters. The null-distributions obtained for our frequencies of interest in <xref ref-type="fig" rid="fig3">Figure 3f</xref> are shown in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>.</p></sec><sec id="s4-12"><title>EEG recording and analysis</title><p>EEG was recorded at a sampling rate of 1000 Hz using three BrainAmp amplifiers and 64-channel ActiCap (BrainProducts; RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_009443">SCR_009443</ext-link>), with the impedance of each electrode kept below 10 kΩ. Ground and reference electrodes were AFz and FCz at recording, respectively. After re-referencing the data to the average of all channels, we performed linear detrending and bandpass filtering (0.1–60 Hz with a Hamming-windowed finite impulse response filter) and down-sampled the data to 250 Hz before time-frequency analysis.</p><p>We performed all time-frequency analyses using the Chronux toolbox ((<ext-link ext-link-type="uri" xlink:href="http://chronux.org"><underline>http://chronux.org</underline></ext-link>; <xref ref-type="bibr" rid="bib10">Bokil et al., 2010</xref>); RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_005547">SCR_005547</ext-link>), and custom MATLAB scripts. To resolve our frequencies of interest (especially between 3.5 and 4.5 Hz), we used a single-taper Fourier transform with a time-window of 2 s, which resulted in a half bandwidth (<italic>W</italic>) of 0.5 Hz (<italic>W</italic> = 1/2). This half bandwidth is consequently capable of resolving differences between 3.5 and 4.5 Hz, as demonstrated in <xref ref-type="fig" rid="fig4">Figures 4b</xref> and <xref ref-type="fig" rid="fig5">5b</xref>.</p></sec><sec id="s4-13"><title>ITPC analysis</title><p>To assess the neural correlates of attentional sampling (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>), we analyzed the inter-trial phase coherence (ITPC) within electrodes, over multiple time-frequency points (<xref ref-type="bibr" rid="bib4">Bastos and Schoffelen, 2015</xref>). ITPC is an amplitude-normalized measure of the degree to which EEG responses are phase-locked to the onset of an exogenous cue, ranging between 0 (random phase over trials) and 1 (perfect phase consistency over trials). To compute ITPC, the consistency of phase angles is computed as the length of the average of unit phase vectors in the complex plane over trials. For a given time, <italic>t</italic>, and frequency, <italic>f</italic>,<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mo>∗</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>N</italic> is the number of trials, and <italic>θ</italic> is the phase angle at time <italic>t</italic>, frequency <italic>f</italic>, and trial <italic>n</italic>.</p><p>Due to the stochastic nature of perceptual alternations during binocular rivalry, the number of available trials for analysis in each mismatched and matched cue type ranged from 12 to 36 trials across subjects (after averaging first across subjects, the mean number of trials was 24 (±1.5) trials across matched/mismatched and attention conditions). Because the bias level (or expected chance level for pure noise data) of ITPC is strongly influenced by the number of trials, we took additional measures to equate the number of mismatched and matched cue types for the analysis. To achieve this aim, the minimum number of trials recorded for a given cue combination was identified across subjects. Following this, subjects with greater numbers of trials had their observed number of trials supplemented by downsampling with replacement from their recorded trials, equating them to the predefined minimum for each condition. Upon this resampled dataset, the ITPC was computed, and this process repeated 100 times. As the difference in ITPC between auditory, tactile, and combined auditory and tactile cues was not significant, we proceeded by combining crossmodal cue types within each subject.</p></sec><sec id="s4-14"><title>ITPC statistics</title><p>To investigate the neural correlates of attentional sampling, we analysed evoked ITPC, the increase in ITPC during 0 to 2 s after onset compared to −2 to 0 s before onset. Similar to our statistical approach for the behavioral spectral analysis described above, we used a two-stage statistical testing procedure for this analysis. At the first stage, we performed a <italic>t</italic>-test (two-tailed) comparing whether evoked 3.5 and 8 Hz ITPC differed between mismatched and matched conditions across subjects at each electrode. At each electrode, we used the mean evoked ITPC value obtained from the downsampling method described above. As a result of the <italic>t</italic>-tests, if we found a cluster of at least two neighboring electrodes with the same <italic>t</italic>-score polarity at <italic>p </italic>&lt; 0.05 (uncorrected), where inter-electrode distance did not exceed 3.5 cm, we proceeded using this cluster in the second stage of statistics. As a result of this cluster criterion, we always identified a minimum size of 2-electrode clusters (<xref ref-type="fig" rid="fig4">Figures 4a</xref> and <xref ref-type="fig" rid="fig5">5a</xref>).</p><p>At the second stage, we first computed the absolute value of the sum of observed <italic>t</italic>-scores within the identified cluster, which we retained as our observed test-statistic (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). To create the null distribution, condition labels (mismatch and match) were randomly shuffled for each electrode within each subject, to create two surrogate datasets the same size as our original mismatch and match conditions. Then the <italic>t</italic>-scores were computed for each electrode based on our surrogate datasets, and the electrode with the maximum <italic>t</italic>-score and the maximum <italic>t</italic>-score of its neighbors retained. The sum of these <italic>t</italic>-scores were then retained per shuffle, and this procedure repeated 2000 times to obtain a null distribution of the sum of <italic>t</italic>-scores around the maximum electrode for each shuffle of our surrogate data. Against this distribution, the sum of observed <italic>t</italic>-scores for the candidate cluster was then compared. When the observed sum of <italic>t</italic>-scores was within the top 5% (or cluster corrected to <italic>p </italic>&lt; 0.05) then we concluded that there was a significant difference between mismatch and match conditions. The null-distributions and observed test-statistics produced by this analysis are shown in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>.</p></sec><sec id="s4-15"><title>Data availability</title><p>The raw data in this study are available via the Monash University Figshare repository (<ext-link ext-link-type="uri" xlink:href="https://figshare.com/projects/Crossmodal_binocular_rivalry_attention_sampling_project/56252">https://figshare.com/projects/Crossmodal_binocular_rivalry_attention_sampling_project/56252</ext-link>). Analysis code is available via GitHub (<xref ref-type="bibr" rid="bib25">Davidson, 2018</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/BRproject-attentionsampling">https://github.com/elifesciences-publications/BRproject-attentionsampling</ext-link>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>MJD was supported by an Australian Government Research Training Program Scholarship. DA was funded by an Australian Research Council Discovery Project (DP150101731). NT was funded by an Australian Research Council Future Fellowship (FT120100619) and Discovery Project (DP130100194). The authors thank Bryan Paton and Claudia Lunghi for technical advice, and Brandon Lam for early piloting of the experimental paradigm.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Software, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: This research involved human subjects. Participants gave their written informed consent to participate in the experiment. Experimental procedures were approved by the Monash University Human Research Ethics Committee (CF12/2542 - 2012001375)</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.40868.023</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-40868-transrepform-v2.docx"/></supplementary-material><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The raw data in this study are available via the Monash University Figshare repository (<ext-link ext-link-type="uri" xlink:href="https://figshare.com/projects/Crossmodal_binocular_rivalry_attention_sampling_project/56252">https://figshare.com/projects/Crossmodal_binocular_rivalry_attention_sampling_project/56252</ext-link>). Analysis code is available via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/Davidson-MJ/BRproject-attentionsampling">https://github.com/Davidson-MJ/BRproject-attentionsampling</ext-link>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/BRproject-attentionsampling">https://github.com/elifesciences-publications/BRproject-attentionsampling</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Matthew</surname><given-names>J Davidson</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Crossmodal binocular rivalry, attention sampling project</data-title><source>figshare</source><pub-id assigning-authority="figshare" pub-id-type="archive" xlink:href="https://figshare.com/projects/Crossmodal_binocular_rivalry_attention_sampling_project/56252">Crossmodal_binocular_rivalry_attention_sampling_project/56252</pub-id></element-citation></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Alais</surname> <given-names>D</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>Binocular rivalry</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alais</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Binocular rivalry: competition and inhibition in visual perception</article-title><source>Wiley Interdisciplinary Reviews: Cognitive Science</source><volume>3</volume><fpage>87</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1002/wcs.151</pub-id><pub-id pub-id-type="pmid">26302474</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bahrami</surname> <given-names>B</given-names></name><name><surname>Lavie</surname> <given-names>N</given-names></name><name><surname>Rees</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Attentional load modulates responses of human primary visual cortex to invisible stimuli</article-title><source>Current Biology</source><volume>17</volume><fpage>509</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2007.01.070</pub-id><pub-id pub-id-type="pmid">17346967</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname> <given-names>AM</given-names></name><name><surname>Schoffelen</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Tutorial Review of Functional Connectivity Analysis Methods and Their Interpretational Pitfalls</article-title><source>Frontiers in Systems Neuroscience</source><volume>9</volume><elocation-id>175</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2015.00175</pub-id><pub-id pub-id-type="pmid">26778976</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battelli</surname> <given-names>L</given-names></name><name><surname>Pascual-Leone</surname> <given-names>A</given-names></name><name><surname>Cavanagh</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The 'when' pathway of the right parietal lobe</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>204</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.03.001</pub-id><pub-id pub-id-type="pmid">17379569</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beauchamp</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>See me, hear me, touch me: multisensory integration in lateral occipital-temporal cortex</article-title><source>Current Opinion in Neurobiology</source><volume>15</volume><fpage>145</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2005.03.011</pub-id><pub-id pub-id-type="pmid">15831395</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamin</surname> <given-names>DJ</given-names></name><name><surname>Berger</surname> <given-names>JO</given-names></name><name><surname>Johannesson</surname> <given-names>M</given-names></name><name><surname>Nosek</surname> <given-names>BA</given-names></name><name><surname>Wagenmakers</surname> <given-names>E-J</given-names></name><name><surname>Berk</surname> <given-names>R</given-names></name><name><surname>Bollen</surname> <given-names>KA</given-names></name><name><surname>Brembs</surname> <given-names>B</given-names></name><name><surname>Brown</surname> <given-names>L</given-names></name><name><surname>Camerer</surname> <given-names>C</given-names></name><name><surname>Cesarini</surname> <given-names>D</given-names></name><name><surname>Chambers</surname> <given-names>CD</given-names></name><name><surname>Clyde</surname> <given-names>M</given-names></name><name><surname>Cook</surname> <given-names>TD</given-names></name><name><surname>De Boeck</surname> <given-names>P</given-names></name><name><surname>Dienes</surname> <given-names>Z</given-names></name><name><surname>Dreber</surname> <given-names>A</given-names></name><name><surname>Easwaran</surname> <given-names>K</given-names></name><name><surname>Efferson</surname> <given-names>C</given-names></name><name><surname>Fehr</surname> <given-names>E</given-names></name><name><surname>Fidler</surname> <given-names>F</given-names></name><name><surname>Field</surname> <given-names>AP</given-names></name><name><surname>Forster</surname> <given-names>M</given-names></name><name><surname>George</surname> <given-names>EI</given-names></name><name><surname>Gonzalez</surname> <given-names>R</given-names></name><name><surname>Goodman</surname> <given-names>S</given-names></name><name><surname>Green</surname> <given-names>E</given-names></name><name><surname>Green</surname> <given-names>DP</given-names></name><name><surname>Greenwald</surname> <given-names>AG</given-names></name><name><surname>Hadfield</surname> <given-names>JD</given-names></name><name><surname>Hedges</surname> <given-names>LV</given-names></name><name><surname>Held</surname> <given-names>L</given-names></name><name><surname>Hua Ho</surname> <given-names>T</given-names></name><name><surname>Hoijtink</surname> <given-names>H</given-names></name><name><surname>Hruschka</surname> <given-names>DJ</given-names></name><name><surname>Imai</surname> <given-names>K</given-names></name><name><surname>Imbens</surname> <given-names>G</given-names></name><name><surname>Ioannidis</surname> <given-names>JPA</given-names></name><name><surname>Jeon</surname> <given-names>M</given-names></name><name><surname>Jones</surname> <given-names>JH</given-names></name><name><surname>Kirchler</surname> <given-names>M</given-names></name><name><surname>Laibson</surname> <given-names>D</given-names></name><name><surname>List</surname> <given-names>J</given-names></name><name><surname>Little</surname> <given-names>R</given-names></name><name><surname>Lupia</surname> <given-names>A</given-names></name><name><surname>Machery</surname> <given-names>E</given-names></name><name><surname>Maxwell</surname> <given-names>SE</given-names></name><name><surname>McCarthy</surname> <given-names>M</given-names></name><name><surname>Moore</surname> <given-names>DA</given-names></name><name><surname>Morgan</surname> <given-names>SL</given-names></name><name><surname>Munafó</surname> <given-names>M</given-names></name><name><surname>Nakagawa</surname> <given-names>S</given-names></name><name><surname>Nyhan</surname> <given-names>B</given-names></name><name><surname>Parker</surname> <given-names>TH</given-names></name><name><surname>Pericchi</surname> <given-names>L</given-names></name><name><surname>Perugini</surname> <given-names>M</given-names></name><name><surname>Rouder</surname> <given-names>J</given-names></name><name><surname>Rousseau</surname> <given-names>J</given-names></name><name><surname>Savalei</surname> <given-names>V</given-names></name><name><surname>Schönbrodt</surname> <given-names>FD</given-names></name><name><surname>Sellke</surname> <given-names>T</given-names></name><name><surname>Sinclair</surname> <given-names>B</given-names></name><name><surname>Tingley</surname> <given-names>D</given-names></name><name><surname>Van Zandt</surname> <given-names>T</given-names></name><name><surname>Vazire</surname> <given-names>S</given-names></name><name><surname>Watts</surname> <given-names>DJ</given-names></name><name><surname>Winship</surname> <given-names>C</given-names></name><name><surname>Wolpert</surname> <given-names>RL</given-names></name><name><surname>Xie</surname> <given-names>Y</given-names></name><name><surname>Young</surname> <given-names>C</given-names></name><name><surname>Zinman</surname> <given-names>J</given-names></name><name><surname>Johnson</surname> <given-names>VE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Redefine statistical significance</article-title><source>Nature Human Behaviour</source><volume>2</volume><fpage>6</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1038/s41562-017-0189-z</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Yekutieli</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The Control of the False Discovery Rate in Multiple Testing under Dependency</article-title><source>The Annals of Statistics</source><volume>29</volume><fpage>1165</fpage><lpage>1188</lpage><pub-id pub-id-type="doi">10.1214/aos/1013699998</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blake</surname> <given-names>R</given-names></name><name><surname>O'Shea</surname> <given-names>RP</given-names></name><name><surname>Mueller</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Spatial zones of binocular rivalry in central and peripheral vision</article-title><source>Visual Neuroscience</source><volume>8</volume><fpage>469</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1017/S0952523800004971</pub-id><pub-id pub-id-type="pmid">1586647</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bokil</surname> <given-names>H</given-names></name><name><surname>Andrews</surname> <given-names>P</given-names></name><name><surname>Kulkarni</surname> <given-names>JE</given-names></name><name><surname>Mehta</surname> <given-names>S</given-names></name><name><surname>Mitra</surname> <given-names>PP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Chronux: a platform for analyzing neural signals</article-title><source>Journal of Neuroscience Methods</source><volume>192</volume><fpage>146</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.06.020</pub-id><pub-id pub-id-type="pmid">20637804</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname> <given-names>NA</given-names></name><name><surname>Dubois</surname> <given-names>J</given-names></name><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The phase of ongoing EEG oscillations predicts visual perception</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>7869</fpage><lpage>7876</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0113-09.2009</pub-id><pub-id pub-id-type="pmid">19535598</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname> <given-names>NA</given-names></name><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spontaneous EEG oscillations reveal periodic sampling of visual attention</article-title><source>PNAS</source><volume>107</volume><fpage>16048</fpage><lpage>16053</lpage><pub-id pub-id-type="doi">10.1073/pnas.1004801107</pub-id><pub-id pub-id-type="pmid">20805482</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bushara</surname> <given-names>KO</given-names></name><name><surname>Hanakawa</surname> <given-names>T</given-names></name><name><surname>Immisch</surname> <given-names>I</given-names></name><name><surname>Toma</surname> <given-names>K</given-names></name><name><surname>Kansaku</surname> <given-names>K</given-names></name><name><surname>Hallett</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neural correlates of cross-modal binding</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>190</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1038/nn993</pub-id><pub-id pub-id-type="pmid">12496761</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calvert</surname> <given-names>GA</given-names></name><name><surname>Thesen</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Multisensory integration: methodological approaches and emerging principles in the human brain</article-title><source>Journal of Physiology-Paris</source><volume>98</volume><fpage>191</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2004.03.018</pub-id><pub-id pub-id-type="pmid">15477032</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chakravarthi</surname> <given-names>R</given-names></name><name><surname>Vanrullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Conscious updating is a rhythmic process</article-title><source>PNAS</source><volume>109</volume><fpage>10599</fpage><lpage>10604</lpage><pub-id pub-id-type="doi">10.1073/pnas.1121622109</pub-id><pub-id pub-id-type="pmid">22689974</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>A</given-names></name><name><surname>Wang</surname> <given-names>A</given-names></name><name><surname>Wang</surname> <given-names>T</given-names></name><name><surname>Tang</surname> <given-names>X</given-names></name><name><surname>Zhang</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Behavioral Oscillations in Visual Attention Modulated by Task Difficulty</article-title><source>Frontiers in Psychology</source><volume>8</volume><elocation-id>1630</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2017.01630</pub-id><pub-id pub-id-type="pmid">29018373</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chica</surname> <given-names>AB</given-names></name><name><surname>Bartolomeo</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attentional routes to conscious perception</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00001</pub-id><pub-id pub-id-type="pmid">22279440</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chong</surname> <given-names>SC</given-names></name><name><surname>Tadin</surname> <given-names>D</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Endogenous attention prolongs dominance durations in binocular rivalry</article-title><source>Journal of Vision</source><volume>5</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.1167/5.11.6</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chong</surname> <given-names>SC</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Exogenous attention and endogenous attention influence initial dominance in binocular rivalry</article-title><source>Vision Research</source><volume>46</volume><fpage>1794</fpage><lpage>1803</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2005.10.031</pub-id><pub-id pub-id-type="pmid">16368126</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chopin</surname> <given-names>A</given-names></name><name><surname>Mamassian</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Task usefulness affects perception of rivalrous images</article-title><source>Psychological Science</source><volume>21</volume><fpage>1886</fpage><lpage>1893</lpage><pub-id pub-id-type="doi">10.1177/0956797610389190</pub-id><pub-id pub-id-type="pmid">21106886</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>MA</given-names></name><name><surname>Dennett</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Consciousness cannot be separated from function</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>358</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.06.008</pub-id><pub-id pub-id-type="pmid">21807333</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conrad</surname> <given-names>V</given-names></name><name><surname>Bartels</surname> <given-names>A</given-names></name><name><surname>Kleiner</surname> <given-names>M</given-names></name><name><surname>Noppeney</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Audiovisual interactions in binocular rivalry</article-title><source>Journal of Vision</source><volume>10</volume><elocation-id>27</elocation-id><pub-id pub-id-type="doi">10.1167/10.10.27</pub-id><pub-id pub-id-type="pmid">20884492</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corbetta</surname> <given-names>M</given-names></name><name><surname>Shulman</surname> <given-names>GL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title><source>Nature Reviews Neuroscience</source><volume>3</volume><fpage>201</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1038/nrn755</pub-id><pub-id pub-id-type="pmid">11994752</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Davidson</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>BRproject-attentionsampling</data-title><source>GitHub</source><version designator="dfa6de4">dfa6de4</version><ext-link ext-link-type="uri" xlink:href="https://github.com/Davidson-MJ/BRproject-attentionsampling">https://github.com/Davidson-MJ/BRproject-attentionsampling</ext-link></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Changeux</surname> <given-names>JP</given-names></name><name><surname>Naccache</surname> <given-names>L</given-names></name><name><surname>Sackur</surname> <given-names>J</given-names></name><name><surname>Sergent</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Conscious, preconscious, and subliminal processing: a testable taxonomy</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>204</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.03.007</pub-id><pub-id pub-id-type="pmid">16603406</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deroy</surname> <given-names>O</given-names></name><name><surname>Chen</surname> <given-names>Y-C</given-names></name><name><surname>Spence</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multisensory constraints on awareness</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><elocation-id>20130207</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0207</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deroy</surname> <given-names>O</given-names></name><name><surname>Faivre</surname> <given-names>N</given-names></name><name><surname>Lunghi</surname> <given-names>C</given-names></name><name><surname>Spence</surname> <given-names>C</given-names></name><name><surname>Aller</surname> <given-names>M</given-names></name><name><surname>Noppeney</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The Complex Interplay Between Multisensory Integration and Perceptual Awareness</article-title><source>Multisensory Research</source><volume>29</volume><fpage>585</fpage><lpage>606</lpage><pub-id pub-id-type="doi">10.1163/22134808-00002529</pub-id><pub-id pub-id-type="pmid">27795942</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dieter</surname> <given-names>KC</given-names></name><name><surname>Tadin</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Understanding attentional modulation of binocular rivalry: a framework based on biased competition</article-title><source>Frontiers in Human Neuroscience</source><volume>5</volume><elocation-id>155</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00155</pub-id><pub-id pub-id-type="pmid">22144958</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dieter</surname> <given-names>KC</given-names></name><name><surname>Melnick</surname> <given-names>MD</given-names></name><name><surname>Tadin</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>When can attention influence binocular rivalry?</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>77</volume><fpage>1908</fpage><lpage>1918</lpage><pub-id pub-id-type="doi">10.3758/s13414-015-0905-6</pub-id><pub-id pub-id-type="pmid">25898898</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dieter</surname> <given-names>KC</given-names></name><name><surname>Brascamp</surname> <given-names>J</given-names></name><name><surname>Tadin</surname> <given-names>D</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Does visual attention drive the dynamics of bistable perception?</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>78</volume><fpage>1861</fpage><lpage>1873</lpage><pub-id pub-id-type="doi">10.3758/s13414-016-1143-2</pub-id><pub-id pub-id-type="pmid">27230785</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dieter</surname> <given-names>KC</given-names></name><name><surname>Melnick</surname> <given-names>MD</given-names></name><name><surname>Tadin</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Perceptual training profoundly alters binocular rivalry through both sensory and attentional enhancements</article-title><source>PNAS</source><volume>113</volume><fpage>12874</fpage><lpage>12879</lpage><pub-id pub-id-type="doi">10.1073/pnas.1602722113</pub-id><pub-id pub-id-type="pmid">27791061</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downar</surname> <given-names>J</given-names></name><name><surname>Crawley</surname> <given-names>AP</given-names></name><name><surname>Mikulis</surname> <given-names>DJ</given-names></name><name><surname>Davis</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A multimodal cortical network for the detection of changes in the sensory environment</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>277</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1038/72991</pub-id><pub-id pub-id-type="pmid">10700261</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driver</surname> <given-names>J</given-names></name><name><surname>Noesselt</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Multisensory interplay reveals crossmodal influences on 'sensory-specific' brain regions, neural responses, and judgments</article-title><source>Neuron</source><volume>57</volume><fpage>11</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.12.013</pub-id><pub-id pub-id-type="pmid">18184561</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname> <given-names>L</given-names></name><name><surname>Vanrullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The dynamics of attentional sampling during visual search revealed by Fourier analysis of periodic noise interference</article-title><source>Journal of Vision</source><volume>14</volume><fpage>11</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1167/14.2.11</pub-id><pub-id pub-id-type="pmid">24525262</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname> <given-names>L</given-names></name><name><surname>McLelland</surname> <given-names>D</given-names></name><name><surname>Lajous</surname> <given-names>M</given-names></name><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Attention searches nonuniformly in space and in time</article-title><source>PNAS</source><volume>112</volume><fpage>15214</fpage><lpage>15219</lpage><pub-id pub-id-type="doi">10.1073/pnas.1511331112</pub-id><pub-id pub-id-type="pmid">26598671</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname> <given-names>L</given-names></name><name><surname>Roberts</surname> <given-names>M</given-names></name><name><surname>Carrasco</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Attention reorients periodically</article-title><source>Current Biology</source><volume>26</volume><fpage>1595</fpage><lpage>1601</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.04.046</pub-id><pub-id pub-id-type="pmid">27265395</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname> <given-names>L</given-names></name><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Transcranial Magnetic Stimulation Reveals Intrinsic Perceptual and Attentional Rhythms</article-title><source>Frontiers in Neuroscience</source><volume>11</volume><elocation-id>154</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2017.00154</pub-id><pub-id pub-id-type="pmid">28396622</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname> <given-names>L</given-names></name><name><surname>Xue</surname> <given-names>AM</given-names></name><name><surname>Carrasco</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Distinct perceptual rhythms for feature and conjunction searches</article-title><source>Journal of Vision</source><volume>17</volume><elocation-id>22</elocation-id><pub-id pub-id-type="doi">10.1167/17.3.22</pub-id><pub-id pub-id-type="pmid">28362897</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dugué</surname> <given-names>L</given-names></name><name><surname>Merriam</surname> <given-names>EP</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name><name><surname>Carrasco</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Specific Visual Subregions of TPJ Mediate Reorienting of Spatial Attention</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>2375</fpage><lpage>2390</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx140</pub-id><pub-id pub-id-type="pmid">28981585</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faivre</surname> <given-names>N</given-names></name><name><surname>Arzi</surname> <given-names>A</given-names></name><name><surname>Lunghi</surname> <given-names>C</given-names></name><name><surname>Salomon</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Consciousness is more than meets the eye: a call for a multisensory study of subjective experience†</article-title><source>Neuroscience of Consciousness</source><volume>2017</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1093/nc/nix003</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname> <given-names>IC</given-names></name><name><surname>Saalmann</surname> <given-names>YB</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rhythmic sampling within and between objects despite sustained attention at a cued location</article-title><source>Current Biology</source><volume>23</volume><fpage>2553</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.10.063</pub-id><pub-id pub-id-type="pmid">24316204</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiebelkorn</surname> <given-names>IC</given-names></name><name><surname>Pinsk</surname> <given-names>MA</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A Dynamic interplay within the frontoparietal network underlies rhythmic spatial attention</article-title><source>Neuron</source><volume>99</volume><fpage>842</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.038</pub-id><pub-id pub-id-type="pmid">30138590</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname> <given-names>JN</given-names></name><name><surname>Ruhnau</surname> <given-names>P</given-names></name><name><surname>Weisz</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Not so different after all: The same oscillatory processes support different types of attention</article-title><source>Brain Research</source><volume>1626</volume><fpage>183</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2015.02.017</pub-id><pub-id pub-id-type="pmid">25721788</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fries</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rhythms for Cognition: Communication through Coherence</article-title><source>Neuron</source><volume>88</volume><fpage>220</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.034</pub-id><pub-id pub-id-type="pmid">26447583</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujisaki</surname> <given-names>W</given-names></name><name><surname>Nishida</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Temporal frequency characteristics of synchrony-asynchrony discrimination of audio-visual signals</article-title><source>Experimental Brain Research</source><volume>166</volume><fpage>455</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1007/s00221-005-2385-8</pub-id><pub-id pub-id-type="pmid">16032402</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujisaki</surname> <given-names>W</given-names></name><name><surname>Nishida</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A common perceptual temporal limit of binding synchronous inputs across different sensory attributes and modalities</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>277</volume><fpage>2281</fpage><lpage>2290</lpage><pub-id pub-id-type="doi">10.1098/rspb.2010.0243</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guggisberg</surname> <given-names>AG</given-names></name><name><surname>Dalal</surname> <given-names>SS</given-names></name><name><surname>Schnider</surname> <given-names>A</given-names></name><name><surname>Nagarajan</surname> <given-names>SS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neural basis of event-time introspection</article-title><source>Consciousness and Cognition</source><volume>20</volume><fpage>1899</fpage><lpage>1915</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2011.03.008</pub-id><pub-id pub-id-type="pmid">21498087</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guzman-Martinez</surname> <given-names>E</given-names></name><name><surname>Ortega</surname> <given-names>L</given-names></name><name><surname>Grabowecky</surname> <given-names>M</given-names></name><name><surname>Mossbridge</surname> <given-names>J</given-names></name><name><surname>Suzuki</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Interactive coding of visual spatial frequency and auditory amplitude-modulation rate</article-title><source>Current Biology</source><volume>22</volume><fpage>383</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.01.004</pub-id><pub-id pub-id-type="pmid">22326023</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname> <given-names>S</given-names></name><name><surname>Volberg</surname> <given-names>G</given-names></name><name><surname>Wimber</surname> <given-names>M</given-names></name><name><surname>Dalal</surname> <given-names>SS</given-names></name><name><surname>Greenlee</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Prestimulus oscillatory phase at 7 Hz gates cortical information flow and visual perception</article-title><source>Current Biology</source><volume>23</volume><fpage>2273</fpage><lpage>2278</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.09.020</pub-id><pub-id pub-id-type="pmid">24184106</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartcher-O’Brien</surname> <given-names>J</given-names></name><name><surname>Talsma</surname> <given-names>D</given-names></name><name><surname>Adam</surname> <given-names>R</given-names></name><name><surname>Vercillo</surname> <given-names>T</given-names></name><name><surname>Macaluso</surname> <given-names>E</given-names></name><name><surname>Noppeney</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The Curious Incident of Attention in Multisensory Integration: Bottom-up vs. Top-down</article-title><source>Multisensory Research</source><volume>29</volume><fpage>557</fpage><lpage>583</lpage><pub-id pub-id-type="doi">10.1163/22134808-00002528</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich</surname> <given-names>RF</given-names></name><name><surname>Fiebelkorn</surname> <given-names>IC</given-names></name><name><surname>Szczepanski</surname> <given-names>SM</given-names></name><name><surname>Lin</surname> <given-names>JJ</given-names></name><name><surname>Parvizi</surname> <given-names>J</given-names></name><name><surname>Knight</surname> <given-names>RT</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural Mechanisms of Sustained Attention Are Rhythmic</article-title><source>Neuron</source><volume>99</volume><fpage>854</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.032</pub-id><pub-id pub-id-type="pmid">30138591</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ho</surname> <given-names>HT</given-names></name><name><surname>Leung</surname> <given-names>J</given-names></name><name><surname>Burr</surname> <given-names>DC</given-names></name><name><surname>Alais</surname> <given-names>D</given-names></name><name><surname>Morrone</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Auditory Sensitivity and Decision Criteria Oscillate at Different Frequencies Separately for the Two Ears</article-title><source>Current Biology : CB</source><volume>27</volume><fpage>3643</fpage><lpage>3649</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.10.017</pub-id><pub-id pub-id-type="pmid">29153327</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hogendoorn</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Voluntary Saccadic Eye Movements Ride the Attentional Rhythm</article-title><source>Journal of Cognitive Neuroscience</source><volume>28</volume><fpage>1625</fpage><lpage>1635</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00986</pub-id><pub-id pub-id-type="pmid">27243615</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holcombe</surname> <given-names>AO</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Seeing slow and seeing fast: two limits on perception</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>216</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.02.005</pub-id><pub-id pub-id-type="pmid">19386535</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holcombe</surname> <given-names>AO</given-names></name><name><surname>Chen</surname> <given-names>WY</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Splitting attention reduces temporal resolution from 7 Hz for tracking one object to &lt;3 Hz when tracking three</article-title><source>Journal of Vision</source><volume>13</volume><fpage>12</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1167/13.1.12</pub-id><pub-id pub-id-type="pmid">23302215</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>Y</given-names></name><name><surname>Chen</surname> <given-names>L</given-names></name><name><surname>Luo</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Behavioral oscillation in priming: competing perceptual predictions conveyed in alternating theta-band rhythms</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>2830</fpage><lpage>2837</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4294-14.2015</pub-id><pub-id pub-id-type="pmid">25673869</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iemi</surname> <given-names>L</given-names></name><name><surname>Chaumon</surname> <given-names>M</given-names></name><name><surname>Crouzet</surname> <given-names>SM</given-names></name><name><surname>Busch</surname> <given-names>NA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spontaneous Neural Oscillations Bias Perception by Modulating Baseline Excitability</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>807</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1432-16.2016</pub-id><pub-id pub-id-type="pmid">28123017</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iemi</surname> <given-names>L</given-names></name><name><surname>Busch</surname> <given-names>NA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Moment-to-Moment fluctuations in neuronal excitability bias subjective perception rather than strategic decision-making</article-title><source>Eneuro</source><volume>5</volume><elocation-id>ENEURO.0430-17.2018</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0430-17.2018</pub-id><pub-id pub-id-type="pmid">29911179</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jack</surname> <given-names>BN</given-names></name><name><surname>Hacker</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Predictive coding explains auditory and tactile influences on vision during binocular rivalry</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>6423</fpage><lpage>6424</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1040-14.2014</pub-id><pub-id pub-id-type="pmid">24806668</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanai</surname> <given-names>R</given-names></name><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Verstraten</surname> <given-names>FA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The scope and limits of top-down attention in unconscious visual processing</article-title><source>Current Biology</source><volume>16</volume><fpage>2332</fpage><lpage>2336</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2006.10.001</pub-id><pub-id pub-id-type="pmid">17141615</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname> <given-names>M-S</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Perceptual synergy between seeing and hearing revealed during binocular rivalry</article-title><source>Psichologija</source><volume>32</volume><fpage>7</fpage><lpage>15</lpage></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Tsuchiya</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Attention and consciousness: two distinct brain processes</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>16</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.10.012</pub-id><pub-id pub-id-type="pmid">17129748</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laing</surname> <given-names>CR</given-names></name><name><surname>Chow</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A spiking neuron model for binocular rivalry</article-title><source>Journal of Computational Neuroscience</source><volume>12</volume><fpage>39</fpage><lpage>53</lpage><pub-id pub-id-type="pmid">11932559</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>O'Connell</surname> <given-names>MN</given-names></name><name><surname>Barczak</surname> <given-names>A</given-names></name><name><surname>Mills</surname> <given-names>A</given-names></name><name><surname>Javitt</surname> <given-names>DC</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The leading sense: supramodal control of neurophysiological context by attention</article-title><source>Neuron</source><volume>64</volume><fpage>419</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.10.014</pub-id><pub-id pub-id-type="pmid">19914189</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname> <given-names>VAF</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Why visual attention and awareness are different</article-title><source>Trends in Cognitive Sciences</source><volume>7</volume><fpage>12</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(02)00013-X</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landau</surname> <given-names>AN</given-names></name><name><surname>Fries</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attention samples stimuli rhythmically</article-title><source>Current Biology</source><volume>22</volume><fpage>1000</fpage><lpage>1004</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.03.054</pub-id><pub-id pub-id-type="pmid">22633805</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landau</surname> <given-names>AN</given-names></name><name><surname>Schreyer</surname> <given-names>HM</given-names></name><name><surname>van Pelt</surname> <given-names>S</given-names></name><name><surname>Fries</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distributed Attention Is Implemented through Theta-Rhythmic Gamma Modulation</article-title><source>Current Biology</source><volume>25</volume><fpage>2332</fpage><lpage>2337</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.07.048</pub-id><pub-id pub-id-type="pmid">26279231</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>HH</given-names></name><name><surname>Carrasco</surname> <given-names>M</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deconstructing Interocular Suppression: Attention and Divisive Normalization</article-title><source>PLoS Computational Biology</source><volume>11</volume><elocation-id>e1004510</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004510</pub-id><pub-id pub-id-type="pmid">26517321</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>HH</given-names></name><name><surname>Rankin</surname> <given-names>J</given-names></name><name><surname>Rinzel</surname> <given-names>J</given-names></name><name><surname>Carrasco</surname> <given-names>M</given-names></name><name><surname>Heeger</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attention model of binocular rivalry</article-title><source>PNAS</source><volume>114</volume><fpage>E6192</fpage><lpage>E6201</lpage><pub-id pub-id-type="doi">10.1073/pnas.1620475114</pub-id><pub-id pub-id-type="pmid">28696323</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Limbach</surname> <given-names>K</given-names></name><name><surname>Corballis</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Prestimulus alpha power influences response criterion in a detection task</article-title><source>Psychophysiology</source><volume>53</volume><fpage>1154</fpage><lpage>1164</lpage><pub-id pub-id-type="doi">10.1111/psyp.12666</pub-id><pub-id pub-id-type="pmid">27144476</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>Z</given-names></name><name><surname>He</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Seeing the invisible: the scope and limits of unconscious processing in binocular rivalry</article-title><source>Progress in Neurobiology</source><volume>87</volume><fpage>195</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2008.09.002</pub-id><pub-id pub-id-type="pmid">18824061</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunghi</surname> <given-names>C</given-names></name><name><surname>Binda</surname> <given-names>P</given-names></name><name><surname>Morrone</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Touch disambiguates rivalrous perception at early stages of visual analysis</article-title><source>Current Biology</source><volume>20</volume><fpage>R143</fpage><lpage>R144</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.12.015</pub-id><pub-id pub-id-type="pmid">20178754</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunghi</surname> <given-names>C</given-names></name><name><surname>Alais</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Touch interacts with vision during binocular rivalry with a tight orientation tuning</article-title><source>PLoS ONE</source><volume>8</volume><elocation-id>e58754</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0058754</pub-id><pub-id pub-id-type="pmid">23472219</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunghi</surname> <given-names>C</given-names></name><name><surname>Morrone</surname> <given-names>MC</given-names></name><name><surname>Alais</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Auditory and tactile signals combine to influence vision during binocular rivalry</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>784</fpage><lpage>792</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2732-13.2014</pub-id><pub-id pub-id-type="pmid">24431437</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lunghi</surname> <given-names>C</given-names></name><name><surname>Alais</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Congruent tactile stimulation reduces the strength of visual suppression during binocular rivalry</article-title><source>Scientific Reports</source><volume>5</volume><elocation-id>09413</elocation-id><pub-id pub-id-type="doi">10.1038/srep09413</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maier</surname> <given-names>A</given-names></name><name><surname>Panagiotaropoulos</surname> <given-names>TI</given-names></name><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Keliris</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Introduction to research topic - binocular rivalry: a gateway to studying consciousness</article-title><source>Frontiers in Human Neuroscience</source><volume>6</volume><elocation-id>263</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2012.00263</pub-id><pub-id pub-id-type="pmid">23055962</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname> <given-names>E</given-names></name><name><surname>Oostenveld</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathewson</surname> <given-names>KE</given-names></name><name><surname>Gratton</surname> <given-names>G</given-names></name><name><surname>Fabiani</surname> <given-names>M</given-names></name><name><surname>Beck</surname> <given-names>DM</given-names></name><name><surname>Ro</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>To see or not to see: prestimulus alpha phase predicts visual awareness</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>2725</fpage><lpage>2732</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3963-08.2009</pub-id><pub-id pub-id-type="pmid">19261866</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merikle</surname> <given-names>PM</given-names></name><name><surname>Joordens</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Parallels between perception without attention and perception without awareness</article-title><source>Consciousness and Cognition</source><volume>6</volume><fpage>219</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1006/ccog.1997.0310</pub-id><pub-id pub-id-type="pmid">9262410</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname> <given-names>JF</given-names></name><name><surname>Stoner</surname> <given-names>GR</given-names></name><name><surname>Reynolds</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Object-based attention determines dominance in binocular rivalry</article-title><source>Nature</source><volume>429</volume><fpage>410</fpage><lpage>413</lpage><pub-id pub-id-type="doi">10.1038/nature02584</pub-id><pub-id pub-id-type="pmid">15164062</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morillon</surname> <given-names>B</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Motor contributions to the temporal precision of auditory attention</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5255</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6255</pub-id><pub-id pub-id-type="pmid">25314898</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Regan</surname> <given-names>JK</given-names></name><name><surname>Noë</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A sensorimotor account of vision and visual consciousness</article-title><source>Behavioral and Brain Sciences</source><volume>24</volume><fpage>939</fpage><lpage>973</lpage><pub-id pub-id-type="doi">10.1017/S0140525X01000115</pub-id><pub-id pub-id-type="pmid">12239892</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Shea</surname> <given-names>RP</given-names></name><name><surname>Blake</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Dichoptic temporal frequency differences do not lead to binocular rivalry</article-title><source>Perception &amp; Psychophysics</source><volume>39</volume><fpage>59</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.3758/BF03207584</pub-id><pub-id pub-id-type="pmid">3703662</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paffen</surname> <given-names>CL</given-names></name><name><surname>Alais</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Attentional modulation of binocular rivalry</article-title><source>Frontiers in Human Neuroscience</source><volume>5</volume><elocation-id>105</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00105</pub-id><pub-id pub-id-type="pmid">22046156</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Attention: the mechanisms of consciousness</article-title><source>PNAS</source><volume>91</volume><fpage>7398</fpage><lpage>7403</lpage><pub-id pub-id-type="doi">10.1073/pnas.91.16.7398</pub-id><pub-id pub-id-type="pmid">8052596</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Attentional networks and consciousness</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>64</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00064</pub-id><pub-id pub-id-type="pmid">22416239</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Proskovec</surname> <given-names>AL</given-names></name><name><surname>Heinrichs-Graham</surname> <given-names>E</given-names></name><name><surname>Wiesman</surname> <given-names>AI</given-names></name><name><surname>McDermott</surname> <given-names>TJ</given-names></name><name><surname>Wilson</surname> <given-names>TW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Oscillatory dynamics in the dorsal and ventral attention networks during the reorienting of attention</article-title><source>Human Brain Mapping</source><volume>39</volume><fpage>2177</fpage><lpage>2190</lpage><pub-id pub-id-type="doi">10.1002/hbm.23997</pub-id><pub-id pub-id-type="pmid">29411471</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romei</surname> <given-names>V</given-names></name><name><surname>Gross</surname> <given-names>J</given-names></name><name><surname>Thut</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sounds reset rhythms of visual cortex and corresponding human visual perception</article-title><source>Current Biology</source><volume>22</volume><fpage>807</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.03.025</pub-id><pub-id pub-id-type="pmid">22503499</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ronconi</surname> <given-names>L</given-names></name><name><surname>Oosterhof</surname> <given-names>NN</given-names></name><name><surname>Bonmassar</surname> <given-names>C</given-names></name><name><surname>Melcher</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Multiple oscillatory rhythms determine the temporal organization of perception</article-title><source>PNAS</source><volume>114</volume><fpage>13435</fpage><lpage>13440</lpage><pub-id pub-id-type="doi">10.1073/pnas.1714522114</pub-id><pub-id pub-id-type="pmid">29203678</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Low-frequency neuronal oscillations as instruments of sensory selection</article-title><source>Trends in Neurosciences</source><volume>32</volume><fpage>9</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2008.09.012</pub-id><pub-id pub-id-type="pmid">19012975</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Wilson</surname> <given-names>DA</given-names></name><name><surname>Radman</surname> <given-names>T</given-names></name><name><surname>Scharfman</surname> <given-names>H</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dynamics of Active Sensing and perceptual selection</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>172</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.02.010</pub-id><pub-id pub-id-type="pmid">20307966</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname> <given-names>K</given-names></name><name><surname>Meng</surname> <given-names>M</given-names></name><name><surname>Chen</surname> <given-names>L</given-names></name><name><surname>Zhou</surname> <given-names>K</given-names></name><name><surname>Luo</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Behavioral oscillations in attention: rhythmic α pulses mediated through θ band</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>4837</fpage><lpage>4844</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4856-13.2014</pub-id><pub-id pub-id-type="pmid">24695703</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaak</surname> <given-names>E</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Local entrainment of α oscillations by visual stimuli causes cyclic modulation of perception</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>3536</fpage><lpage>3544</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4385-13.2014</pub-id><pub-id pub-id-type="pmid">24599454</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talsma</surname> <given-names>D</given-names></name><name><surname>Senkowski</surname> <given-names>D</given-names></name><name><surname>Soto-Faraco</surname> <given-names>S</given-names></name><name><surname>Woldorff</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The multifaceted interplay between attention and multisensory integration</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>400</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.06.008</pub-id><pub-id pub-id-type="pmid">20675182</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorne</surname> <given-names>JD</given-names></name><name><surname>Debener</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Look now and hear what's coming: on the functional role of cross-modal phase reset</article-title><source>Hearing Research</source><volume>307</volume><fpage>144</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2013.07.002</pub-id><pub-id pub-id-type="pmid">23856236</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomassini</surname> <given-names>A</given-names></name><name><surname>Spinelli</surname> <given-names>D</given-names></name><name><surname>Jacono</surname> <given-names>M</given-names></name><name><surname>Sandini</surname> <given-names>G</given-names></name><name><surname>Morrone</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rhythmic oscillations of visual contrast sensitivity synchronized with action</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>7019</fpage><lpage>7029</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4568-14.2015</pub-id><pub-id pub-id-type="pmid">25948254</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomassini</surname> <given-names>A</given-names></name><name><surname>Ambrogioni</surname> <given-names>L</given-names></name><name><surname>Medendorp</surname> <given-names>WP</given-names></name><name><surname>Maris</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Theta oscillations locked to intended actions rhythmically modulate perception</article-title><source>eLife</source><volume>6</volume><elocation-id>e25618</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.25618</pub-id><pub-id pub-id-type="pmid">28686161</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Atteveldt</surname> <given-names>N</given-names></name><name><surname>Murray</surname> <given-names>MM</given-names></name><name><surname>Thut</surname> <given-names>G</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multisensory integration: flexible use of general operations</article-title><source>Neuron</source><volume>81</volume><fpage>1240</fpage><lpage>1253</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.02.044</pub-id><pub-id pub-id-type="pmid">24656248</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Boxtel</surname> <given-names>JJ</given-names></name><name><surname>van Ee</surname> <given-names>R</given-names></name><name><surname>Erkelens</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dichoptic masking and binocular rivalry share common perceptual dynamics</article-title><source>Journal of Vision</source><volume>7</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.1167/7.14.3</pub-id><pub-id pub-id-type="pmid">18217798</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Boxtel</surname> <given-names>JJ</given-names></name><name><surname>Alais</surname> <given-names>D</given-names></name><name><surname>Erkelens</surname> <given-names>CJ</given-names></name><name><surname>van Ee</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008a</year><article-title>The role of temporally coarse form processing during binocular rivalry</article-title><source>PLoS ONE</source><volume>3</volume><elocation-id>e1429</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0001429</pub-id><pub-id pub-id-type="pmid">18197242</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Boxtel</surname> <given-names>JJ</given-names></name><name><surname>Knapen</surname> <given-names>T</given-names></name><name><surname>Erkelens</surname> <given-names>CJ</given-names></name><name><surname>van Ee</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008b</year><article-title>Removal of monocular interactions equates rivalry behavior for monocular, binocular, and stimulus rivalries</article-title><source>Journal of Vision</source><volume>8</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1167/8.15.13</pub-id><pub-id pub-id-type="pmid">19146297</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Boxtel</surname> <given-names>JJ</given-names></name><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010a</year><article-title>Consciousness and attention: on sufficiency and necessity</article-title><source>Frontiers in Psychology</source><volume>1</volume><elocation-id>217</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2010.00217</pub-id><pub-id pub-id-type="pmid">21833272</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Boxtel</surname> <given-names>JJ</given-names></name><name><surname>Tsuchiya</surname> <given-names>N</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010b</year><article-title>Opposing effects of attention and consciousness on afterimages</article-title><source>PNAS</source><volume>107</volume><fpage>8883</fpage><lpage>8888</lpage><pub-id pub-id-type="doi">10.1073/pnas.0913292107</pub-id><pub-id pub-id-type="pmid">20424112</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Driel</surname> <given-names>J</given-names></name><name><surname>Knapen</surname> <given-names>T</given-names></name><name><surname>van Es</surname> <given-names>DM</given-names></name><name><surname>Cohen</surname> <given-names>MX</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Interregional alpha-band synchrony supports temporal cross-modal integration</article-title><source>NeuroImage</source><volume>101</volume><fpage>404</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.07.022</pub-id><pub-id pub-id-type="pmid">25042447</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Ee</surname> <given-names>R</given-names></name><name><surname>van Boxtel</surname> <given-names>JJ</given-names></name><name><surname>Parker</surname> <given-names>AL</given-names></name><name><surname>Alais</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Multisensory congruency as a mechanism for attentional control over perceptual selection</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>11641</fpage><lpage>11649</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0873-09.2009</pub-id><pub-id pub-id-type="pmid">19759311</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanRullen</surname> <given-names>R</given-names></name><name><surname>Carlson</surname> <given-names>T</given-names></name><name><surname>Cavanagh</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The blinking spotlight of attention</article-title><source>PNAS</source><volume>104</volume><fpage>19204</fpage><lpage>19209</lpage><pub-id pub-id-type="doi">10.1073/pnas.0707316104</pub-id><pub-id pub-id-type="pmid">18042716</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanrullen</surname> <given-names>R</given-names></name><name><surname>Dubois</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The psychophysics of brain rhythms</article-title><source>Frontiers in Psychology</source><volume>2</volume><elocation-id>203</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2011.00203</pub-id><pub-id pub-id-type="pmid">21904532</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual attention: a rhythmic process?</article-title><source>Current Biology</source><volume>23</volume><fpage>R1110</fpage><lpage>R1112</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.11.006</pub-id><pub-id pub-id-type="pmid">24355791</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Perceptual Cycles</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>723</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.07.006</pub-id><pub-id pub-id-type="pmid">27567317</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016b</year><chapter-title>Perceptual Rhythms</chapter-title><person-group person-group-type="editor"><name><surname>Wixted</surname> <given-names>JT</given-names></name><name><surname>Serences</surname> <given-names>JT</given-names></name></person-group><source>Stevens’ Handbook of Experimental Psychology and Cognitive Neuroscience</source><edition>Fourth Edition</edition><publisher-loc>United States</publisher-loc><publisher-name>John Wiley and Sons, Inc</publisher-name><fpage>525</fpage><lpage>568</lpage></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attention Cycles</article-title><source>Neuron</source><volume>99</volume><fpage>632</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.08.006</pub-id><pub-id pub-id-type="pmid">30138586</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vroomen</surname> <given-names>J</given-names></name><name><surname>Keetels</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Perception of intersensory synchrony: a tutorial review</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>72</volume><fpage>871</fpage><lpage>884</lpage><pub-id pub-id-type="doi">10.3758/APP.72.4.871</pub-id><pub-id pub-id-type="pmid">20436185</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname> <given-names>M</given-names></name><name><surname>Cheng</surname> <given-names>K</given-names></name><name><surname>Murayama</surname> <given-names>Y</given-names></name><name><surname>Ueno</surname> <given-names>K</given-names></name><name><surname>Asamizuya</surname> <given-names>T</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name><name><surname>Logothetis</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Attention but not awareness modulates the BOLD signal in the human V1 during binocular suppression</article-title><source>Science</source><volume>334</volume><fpage>829</fpage><lpage>831</lpage><pub-id pub-id-type="doi">10.1126/science.1203161</pub-id><pub-id pub-id-type="pmid">22076381</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Computational evidence for a rivalry hierarchy in vision</article-title><source>PNAS</source><volume>100</volume><fpage>14499</fpage><lpage>14503</lpage><pub-id pub-id-type="doi">10.1073/pnas.2333622100</pub-id><pub-id pub-id-type="pmid">14612564</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>D</given-names></name><name><surname>Hong</surname> <given-names>B</given-names></name><name><surname>Gao</surname> <given-names>X</given-names></name><name><surname>Gao</surname> <given-names>S</given-names></name><name><surname>Röder</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2011">2011a</year><article-title>Exploring steady-state visual evoked potentials as an index for intermodal and crossmodal spatial attention</article-title><source>Psychophysiology</source><volume>48</volume><fpage>665</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2010.01132.x</pub-id><pub-id pub-id-type="pmid">20874752</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>P</given-names></name><name><surname>Jamison</surname> <given-names>K</given-names></name><name><surname>Engel</surname> <given-names>S</given-names></name><name><surname>He</surname> <given-names>B</given-names></name><name><surname>He</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011b</year><article-title>Binocular rivalry requires visual attention</article-title><source>Neuron</source><volume>71</volume><fpage>362</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.035</pub-id><pub-id pub-id-type="pmid">21791293</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>H</given-names></name><name><surname>Morrone</surname> <given-names>MC</given-names></name><name><surname>Alais</surname> <given-names>D.</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Behavioural oscillations in visual orientation discrimination reveal distinct modulation rates for both sensitivity and response bias</article-title><source>Scientific Reports</source><volume> in press</volume></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoefel</surname> <given-names>B</given-names></name><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Oscillatory Mechanisms of Stimulus Processing and Selection in the Visual and Auditory Systems: State-of-the-Art, Speculations and Suggestions</article-title><source>Frontiers in Neuroscience</source><volume>11</volume><elocation-id>296</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2017.00296</pub-id><pub-id pub-id-type="pmid">28603483</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.40868.035</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Carrasco</surname><given-names>Marisa</given-names></name><role>Reviewing Editor</role><aff><institution>New York University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Attention periodically samples competing stimuli during binocular rivalry&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal his identity: Daniel H Baker (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This is an innovative, interesting and timely study that reveals periodic switching dynamics during binocular rivalry, following cross-modal cues, and explores the rate of attentional sampling during dominance and suppression. Data from perceptual responses show that with relevant cross-modal cues attentional modulations are periodic. When the cue is congruent with the current visual percept, switches display an 8Hz periodicity; when the cue is incongruent, switches occur in about half of 8Hz, with a 3.5Hz frequency. This pattern of results fits well with the idea of attentional sampling, whereby attention samples a single target at around 8Hz, but for two competing targets the effective sampling rate is divided, i.e. about 4Hz. The presence of EEG correlates of these rhythmic dynamics at the same frequencies tends to support the authors' claims.</p><p>Addressing the following points will provide information regarding the validity of the claims and strengthen the manuscript.</p><p>Essential revisions:</p><p>Theoretical issues</p><p>1) You should discuss the Dieter, Melnick and Tadin, 2015 study, which shows that stimulus-driven cues can bias perceptual report. Exogenous feature-based cues were presented close to the rivalry stimuli; the cue congruent with the (currently) dominant percept lengthened its duration whereas the cue congruent with the suppressed percept hastened it to emerge back. The authors should stress the novelty of their study regarding the oscillatory nature of such process.</p><p>2) The authors should discuss whether they think that the oscillatory behavioral responses they found reflect an oscillation of perception or decision criteria, even though these two aspects cannot be distinguished in the perceptual report used in this study. Germane to this discussion is a recent study that using signal detection theory found that alpha oscillation modulates criterion, not sensitivity (Lemi et al., 2017).</p><p>3) The reported effects only occur for the 4.5-Hz modulated stimulus, and not for the 20Hz modulation. Does this imply an upper temporal limit for crossmodal interactions or for attention?</p><p>4) The authors should relate their findings to computational models of binocular rivalry. Many use mutual inhibition, adaptation and noise to describe the neural circuit underlying rivalry (e.g. Wilson, 1997; Laing and Chow, 2002). Some have explicitly implemented an attentional component (e.g. Li et al., 2017). None of the rivalry models have attempted to model oscillatory perceptual rhythms. Could the current results inform which model component(s) (e.g. input drive, mutual inhibition or attention) may be oscillatory?</p><p>5) The authors suggest that the 7-8 Hz oscillation reflects a single attentional focus, and the ~4Hz oscillation reflects attention that was split into two foci. Does that imply that without a mismatched cue, observers' attention would be predominantly allocated to the dominant image without oscillating between the two stimuli? Were that the case, how would this relate to the theory on rivalry. Are the authors suggesting that a mismatch cue allowed attention to start jumping across two items? And that such a process would not happen without a mismatched cue?</p><p>Methods, Analyses and Results</p><p>6) It is not clear that there are 3 types of cross-modal cues (auditory, tactile, and both combined) until the Materials and methods section; i.e., well after reading the Results and considering the figures. The existence of 3 cue types should be mentioned explicitly earlier. In addition, this begs the question of possible differences among the cue types: Do they affect the dynamics of switching and the results described in all figures?</p><p>7) It would be good to report the frequency tagged responses to the rivaling stimuli themselves. Are there increases in the response when a frequency-matched cross-modal cue is presented? Do the amplitudes correspond to participant button presses consistent with Brown and Norcia, 1997?</p><p>8) For computing Fourier amplitude spectrum, the authors analyzed the time window from 0.5 to 2s from the cue onset. However, Figure 3C and 3D also show oscillatory patterns in the first 0.5s time window. Include this time, narrow the window, or explain why this range was not analyzed. Note that previous studies have removed a shorter time window after the cue (e.g. Landau and Fries, 2012; Fiebelkorn et al., 2013).</p><p>9) It is unclear whether the authors performed FFT on the averaged (across subjects) time course, or on individual time courses, and then averaged the spectrum across subjects. If the former, the latter should also be reported. It is important to ensure that the effect does not merely result from the averaging procedure.</p><p>10) A technical issue regards the EEG ITPC calculation and the logic of upsampling. We agree that it is necessary to equate the number of mismatched and matched cue types for the analysis. However, the strategy of upsampling the lowest-trial-count condition up to the trial number in the highest-trial-count condition is questionable. We are not convinced that the authors' analysis confirmed that upsampling, compared to downsampling, reduced the bias introduced when equating ITPC values across subjects. Running the Matlab code below, the authors will see that the ITPC bias caused by a difference in trial count (first figure) is not reduced when upsampling the low-trial-count condition (second figure), but disappears when downsampling the high-trial-count condition (third figure). You should repeat the analysis with downsampling, ideally multiple times to avoid spurious results.</p><p>1.%% Matlab code</p><p>2. phases = 2*pi*rand(30,1000);% low trial count condition</p><p>3. otherphases = 2*pi*rand(90,1000);% high trial count condition</p><p>4. downsampled_otherphases = otherphases(1:30,:);% downsample high trial count</p><p>5. upsampled_phases = repmat(phases,3,1);% upsample low trial count</p><p>6. ITPC = abs(mean(exp(1i*phases),1));</p><p>7. otherITPC = abs(mean(exp(1i*otherphases),1));</p><p>8. downsampledITPC = abs(mean(exp(1i*downsampled_otherphases),1));</p><p>9. upsampledITPC = abs(mean(exp(1i*upsampled_phases),1));</p><p>10. figure;</p><p>11. subplot(2,1,1); hist(ITPC); title('Original phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>12. subplot(2,1,2); hist(otherITPC); title('Original phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>13. figure;</p><p>14. subplot(2,1,1); hist(upsampledITPC); title('Upsampled phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>15. subplot(2,1,2); hist(otherITPC); title('Original phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>16. figure;</p><p>17. subplot(2,1,1); hist(ITPC); title('Original phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>18. subplot(2,1,2); hist(downsampledITPC); title('Downsampled phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>19.% % End Matlab code</p><p>Figures</p><p>11) Figures 2A, 3A, 4B and 5B require figure legends so that the meaning of the colors is clear without reading the caption.</p><p>12) In Figures 4A and 5A it would be helpful to mark all electrode locations with small dots. We assume these plots are thresholded, such that electrodes with non-significant t-values are set to t=0, but this wasn't stated explicitly. Why not plot all t-values and indicate which are significant in some other way (e.g. with superimposed symbols).</p><p>13) The 9Hz difference in Figure 5B is somewhat unexpected. This is described as a 'stimulus harmonic', but if so, we wouldn't expect to see a difference between matched and mismatched trials. Do the authors have an explanation for this? Does the 9Hz response also correlate with the PSI measure?</p><p>14) The model diagrams in Figure 6 are somewhat confusing. For model (a), do the authors mean that the suppressed image emerges back because attention shifts to the mismatched cue first, and thus the mismatched cue enhances the suppressed image? For model (b), it seems surprising that the presence of the green-crossmodal cue would let the attention focus move from the dominant red image to the suppressed red image, before it moves to the dominant green image…</p><p>15) For correlation scatterplots, it would be helpful to include R and p values in the plot. Are the straight lines in these plots regression lines that predict the y-values using the x-values (i.e. minimizing the error in the y-direction)? Given that both of these are dependent variables with presumably no implied causation, we recommend using Deming regression lines instead, which minimize the absolute error between the line and each data point.</p><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Attention periodically samples competing stimuli during binocular rivalry&quot; for further consideration at <italic>eLife</italic>. Your revised article has been favorably evaluated by Michael Frank (Senior Editor), a Reviewing Editor, and three reviewers.</p><p>The three reviewers and I think that you have addressed all the issues raised satisfactorily, but one. The pending issues regards the ITPC calculations and down-sampling vs. up-sampling.</p><p>We note that there is a crucial difference in the definition of ITPC &quot;bias&quot;: You are talking about minimizing absolute bias (the fact that ITPC is always overestimated when using a finite number of trials, to an extent inversely related to the trial number, e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4D and 4E</xref>). Instead, the reviewers are worried about relative bias (the fact that two experimental conditions with equal &quot;true&quot; ITPC may produce very different ITPC values if the number of trials is not equated, e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4A and 4D</xref>).</p><p>Your upsampling method keeps the absolute bias as low as possible in each condition (given the trial number), but does not reduce relative bias (e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4C and 4D</xref>). Only downsampling can remove this relative bias (e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4A and 4E</xref>). This comes with the cost of an increase in absolute bias for the high N condition (compare <xref ref-type="fig" rid="respfig4">Author response image 4D and 4E</xref>), but given that your analysis relies on a comparison of the two conditions, the relative bias must be eradicated; absolute bias changes are just collateral damage.</p><p>To summarize:</p><p>1) The reviewer made the null assumption that the 2 experimental conditions (matched/mismatched) have the same true ITPC but different numbers of trials. (Here the true ITPC was assumed to be zero, which is the worst-case scenario: no actual phase-locking).</p><p>2) When comparing ITPC across the two conditions, a systematic difference was found (<xref ref-type="fig" rid="respfig4">Author response image 4A</xref> vs. 4D). This difference is necessarily a statistical artifact.</p><p>3) The reviewer applied the authors' upsampling method to equate trials; the systematic difference remained (<xref ref-type="fig" rid="respfig4">Author response image 4B</xref>/4C vs. 4D).</p><p>4) The reviewer applied a downsampling method to equate trials; the (artifactual) difference disappeared (<xref ref-type="fig" rid="respfig4">Author response image 4A</xref> vs. 4E).</p><p>5) Conclusion:</p><p>The authors are correct that upsampling can preserve the ITPC to have a similar value as that derived from the original dataset (without resampling). But, this is not the point here. The aim of resampling is to let the ITPCs from the two conditions comparable when performing statistical tests. When comparing ITPC from two conditions with unequal trial numbers, upsampling can produce false positives, downsampling will not. Thus, the authors should use downsampling instead of upsampling.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.40868.036</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Theoretical issues</p><p>1) You should discuss the Dieter, Melnick and Tadin, 2015 study, which shows that stimulus-driven cues can bias perceptual report. Exogenous feature-based cues were presented close to the rivalry stimuli; the cue congruent with the (currently) dominant percept lengthened its duration whereas the cue congruent with the suppressed percept hastened it to emerge back. The authors should stress the novelty of their study regarding the oscillatory nature of such process.</p></disp-quote><p>We thank the reviewers for this suggestion. We have now cited Dieter et al., 2015, in our Discussion. We have also positioned our findings in support of cue-based effects on rivalry, stressing the novel oscillatory nature of this process (Discussion, third paragraph).</p><disp-quote content-type="editor-comment"><p>2) The authors should discuss whether they think that the oscillatory behavioral responses they found reflect an oscillation of perception or decision criteria, even though these two aspects cannot be distinguished in the perceptual report used in this study. Germane to this discussion is a recent study that using signal detection theory found that alpha oscillation modulates criterion, not sensitivity (Lemi et al., 2017).</p></disp-quote><p>As the reviewers point out our study is unable to tell whether the oscillations in switch rates we have observed reflect changes in perceptual sensitivity or decision criteria. While the results of Iemi et al. support oscillations in decision criteria rather than sensitivity per se (Iemi et al., 2017), others show oscillations in both criterion and sensitivity (Ho et al., 2017; Zhang, Morrone, Alais, Sci Rep, In press) and perception rather than decision criteria (Iemi and Busch, 2018). We have included a short treatment of this distinction in our Discussion (ninth paragraph).</p><disp-quote content-type="editor-comment"><p>3) The reported effects only occur for the 4.5-Hz modulated stimulus, and not for the 20Hz modulation. Does this imply an upper temporal limit for crossmodal interactions or for attention?</p></disp-quote><p>We view it as possible that this difference reflects a temporal limit for crossmodal interactions or for attention. We have clarified our consideration of both alternatives in our Discussion (eleventh paragraph). Although high-frequency effects have been reported in other previous, similar designs (without attention), it is unclear whether our new crossmodal stimulus parameters, or the inclusion of an attentional instruction are responsible for the upper temporal limit we have observed. We believe that distinguishing between these alternatives will be a fruitful line of endeavour in future experimentation, and mention this in our Discussion also.</p><disp-quote content-type="editor-comment"><p>4) The authors should relate their findings to computational models of binocular rivalry. Many use mutual inhibition, adaptation and noise to describe the neural circuit underlying rivalry (e.g. Wilson, 1997; Laing and Chow, 2002). Some have explicitly implemented an attentional component (e.g. Li et al., 2017). None of the rivalry models have attempted to model oscillatory perceptual rhythms. Could the current results inform which model component(s) (e.g. input drive, mutual inhibition or attention) may be oscillatory?</p></disp-quote><p>We thank the reviewers for this suggestion, and have now incorporated a treatment of BR models in our Discussion (third paragraph). We suggest that the attention component of a rivalry model, such as the one that is modelled by Li et al., 2017, can be oscillatory. We have linked our previous discussion of van Boxtel et al., 2008; to an oscillatory model of BR more explicitly (Discussion, twelfth paragraph).</p><disp-quote content-type="editor-comment"><p>5) The authors suggest that the 7-8 Hz oscillation reflects a single attentional focus, and the ~4Hz oscillation reflects attention that was split into two foci. Does that imply that without a mismatched cue, observers' attention would be predominantly allocated to the dominant image without oscillating between the two stimuli? Were that the case, how would this relate to the theory on rivalry. Are the authors suggesting that a mismatch cue allowed attention to start jumping across two items? And that such a process would not happen without a mismatched cue?</p></disp-quote><p>We thank the reviewers for the opportunity to address this clarification, and would like to clarify two points: 1) We do not believe that switches in rivalry are caused only by an attentional sampling mechanism, and 2) nor that attentional switches are completely determined by an 8 / 3.5 Hz rhythm.</p><p>As to 1), there are many different types of attention (Koch and Tsuchiya, 2007), and in the context of rivalry, it is unclear the extent to which attention (or type thereof), may mediate perceptual outcome. If anything, both endogenous and exogenous effects of attention are rather limited (Alais and Blake, 2005; Maier, Panagiotaropoulos, Tsuchiya, and Keliris, 2012; Dieter et al., 2015).</p><p>As to 2), we view our results to be consistent with previous investigations of attentional sampling. Specifically, that attentional sampling rhythms modulate, but do not completely determine perceptual outcome. We have now clarified this nuance in our Discussion (sixth paragraph).</p><disp-quote content-type="editor-comment"><p>Methods, Analyses and Results</p><p>6) It is not clear that there are 3 types of cross-modal cues (auditory, tactile, and both combined) until the Materials and methods section; i.e., well after reading the Results and considering the figures. The existence of 3 cue types should be mentioned explicitly earlier. In addition, this begs the question of possible differences among the cue types: Do they affect the dynamics of switching and the results described in all figures?</p></disp-quote><p>Thank you for this suggestion. We now point out specifically that there were three crossmodal cue types more clearly (subsection “Attending to low-frequency crossmodal stimulation promotes the perceptual dominance of low-frequency flicker during binocular rivalry”, first paragraph).</p><p>We found no difference in the crossmodal cue effects based on cue type. That is to say, whether attending to low-frequency auditory, tactile, or combined auditory and tactile cues, the results were the same. We observed an increased probability of perceiving the congruent, low-frequency flicker. A new figure shows these individual time-series, separated by crossmodal modality (<xref ref-type="fig" rid="respfig1">Author response image 1</xref>). No significant difference between cue types emerged when comparing these time-series (repeated measures ANOVA at each time point, with FDR correction for multiple comparisons).</p><p>As the cue differences were not statistically significant, we continued by pooling them for our subsequent behavioural analyses. This had the advantage of increasing the number of trials available per mismatch x match condition, and improved our statistical power. Without pooling across cue types, the number of the trials per cue type are only ~33% of the total number of trials, and not enough to obtain significant results with our spectral analysis for first perceptual switches.</p><fig id="respfig1"><object-id pub-id-type="doi">10.7554/eLife.40868.025</object-id><label>Author response image 1.</label><caption><title>The effect of crossmodal cue modality on behavioural switch dynamics.</title><p>Crossmodal cue modalities are shown for auditory cues in magenta, tactile cues in black and auditory plus tactile in blue. The probability of perceiving congruent flicker during attended low-frequency cues (related to manuscript Figure 2A). No significant difference between cue modalities emerged when comparing the time-course of this effect (repeated measures ANOVA at each time-point followed by FDR correction for multiple comparisons).</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig1-v2"/></fig><p>We also compared the ITPC values obtained at attentional sampling frequencies between our three crossmodal cue types. No significant difference emerged when comparing the spatial topography of attentional sampling frequencies.</p><disp-quote content-type="editor-comment"><p>7) It would be good to report the frequency tagged responses to the rivaling stimuli themselves. Are there increases in the response when a frequency-matched cross-modal cue is presented? Do the amplitudes correspond to participant button presses consistent with Brown and Norcia, 1997?</p></disp-quote><p>We are hesitant to include additional SSVEP, SSAEP, or SSSEP analyses, as the additional analyses and explanation would significantly lengthen the manuscript – and it is already very dense. We would like to reiterate that attentional sampling has been proposed to be related to the optimum phase of sampling rhythms, rather than any modulation in SSVEP power.</p><p>Having said that, the answer is ‘yes’, amplitudes correspond with subject button presses consistent with previous research on frequency-tagging during rivalry (e.g. Brown and Norcia, 1997; Zhang et al., 2011; Tononi et al., 1998). We here provide an example of the change in 4.5 Hz frequency-tagged SSVEP strength with button press. The amplitudes correspond with perceptual contents, increasing when perceiving a low-frequency flicker, and decreasing when perceiving the high-frequency flicker. We also provide for the reviewer an example of increased 4.5 Hz SNR, during these perceptual switches, when accompanied by a steady-state crossmodal stimulus (<xref ref-type="fig" rid="respfig2">Author response image 2</xref>).</p><fig id="respfig2"><object-id pub-id-type="doi">10.7554/eLife.40868.026</object-id><label>Author response image 2.</label><caption><title>Changes in frequency-tagged power (in the unit of signal to noise ratio, log SNR) around the time of button presses for perceptual switches.</title><p>(a) In visual-only conditions, around the time of button presses, the time course of the power of EEG at the occipital areas (electrode P08) at 4.5 Hz tracks perceptual alternations, consistent with previous investigations using frequency-tagged binocular rivalry. For each subject, we computed the mean across trials, then took the average across subjects, with the error bars reflecting the standard error across subjects. The solid line is for the mean across the trials with perceptual changes from high-frequency (20 Hz) flicker to low-frequency (4.5 Hz) flicker. The dotted line is for the opposite direction (perception changing from low to high flicker). b) Comparison between the visual-only and crossmodal conditions in perceptual-switch related EEG power, but here only focusing on the trials when percepts change from a high flicker to low flicker. In crossmodal conditions, where low-frequency (4.5Hz) auditory and/or tactile stimuli were delivered to subjects, log SNR for 4.5 Hz increased compared to the perceptual switches that happened when no crossmodal stimuli were presented. Here we only used the segment around the first perceptual switch after the onset of crossmodal cue.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig2-v2"/></fig><disp-quote content-type="editor-comment"><p>8) For computing Fourier amplitude spectrum, the authors analyzed the time window from 0.5 to 2s from the cue onset. However, Figure 3C and 3D also show oscillatory patterns in the first 0.5s time window. Include this time, narrow the window, or explain why this range was not analyzed. Note that previous studies have removed a shorter time window after the cue (e.g. Landau and Fries, 2012; Fiebelkorn et al., 2013).</p></disp-quote><p>Regardless of the specific time windows suggested by the reviewers, our conclusions would not change.</p><p>Analyzing the spectra between 0.1 and 2 seconds after cue onset, demonstrates the same results, as shown in <xref ref-type="fig" rid="respfig3">Author response image 3</xref>. However, we reiterate our two reasons for avoiding this early time-window (0-0.5 seconds after stimulus onset):</p><p>1) Manuscript Figure 2A shows that the attentional effects in behavior emerge only beyond 0.5 seconds after cue onset, implying that the effects before 0.5 second are not due to crossmodal attentional effects.</p><p>2) Figure 3—figure supplement 1 has been included to show that a transient increase in the rate of first switches occurs within this window (between 0-0.5 s), regardless of attentional effects (i.e., in all cue types), as well as after cue offset, implying that the effects before 0.5 second are not cue dependent. Thus, we chose to avoid this early window and focus on cue-specific effects.</p><fig id="respfig3"><object-id pub-id-type="doi">10.7554/eLife.40868.027</object-id><label>Author response image 3.</label><caption><title>Adjusting the window for spectral analysis, from 0.5 to 2 seconds, to 0.1 to 2 seconds, produces equivalent results, with significant attentional sampling frequencies ~3.5 and 7-8 Hz.</title></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig3-v2"/></fig><disp-quote content-type="editor-comment"><p>9) It is unclear whether the authors performed FFT on the averaged (across subjects) time course, or on individual time courses, and then averaged the spectrum across subjects. If the former, the latter should also be reported. It is important to ensure that the effect does not merely result from the averaging procedure.</p></disp-quote><p>We would like to state that our evidence for periodic sampling cannot result from our averaging procedure. Although the same averaging procedure was used for all conditions, we observed a differentiation of periodicity only for mismatched vs matched cues, and not unattended, high-frequency, visual-only, or post-offset time-series.</p><p>The time-course of first switches we display (manuscript Figure 3) displays the proportion of all first switches after cue onset, at each time point averaged across subjects. Our FFT is performed on this average across subjects time-course.</p><p>The pattern in individual subjects is similar, though is not present for each individual. This is because the number of switches per each of 8 conditions (match vs. mismatch x low- vs. high- frequency x attended vs. unattended) is very small per subject, and the attentional effects themselves vary across subjects – as shown in manuscript Figure 2B. Furthermore, some FFT spectra from subjects with very few perceptual switches are extremely noisy, and disrupts any effects that could be observed at the group level if averaging individual spectra.</p><p>We have now stated that this effect is clearest in the across-subject time-course, and that this analysis was chosen to match with previous investigations of attentional sampling, which also analyzed the time-course of data at the across-subject level (e.g., Landau and Fries, 2012; Fiebelkorn et al., 2013). These revisions are in the last paragraph of the subsection “Binocular rivalry dynamics during attended low-frequency crossmodal cues”.</p><disp-quote content-type="editor-comment"><p>10) A technical issue regards the EEG ITPC calculation and the logic of upsampling. We agree that it is necessary to equate the number of mismatched and matched cue types for the analysis. However, the strategy of upsampling the lowest-trial-count condition up to the trial number in the highest-trial-count condition is questionable. We are not convinced that the authors' analysis confirmed that upsampling, compared to downsampling, reduced the bias introduced when equating ITPC values across subjects. Running the Matlab code below, the authors will see that the ITPC bias caused by a difference in trial count (first figure) is not reduced when upsampling the low-trial-count condition (second figure), but disappears when downsampling the high-trial-count condition (third figure). You should repeat the analysis with downsampling, ideally multiple times to avoid spurious results.</p><p>1.% % Matlab code</p><p>2. phases = 2*pi*rand(30,1000);% low trial count condition</p><p>3. otherphases = 2*pi*rand(90,1000);% high trial count condition</p><p>4. downsampled_otherphases = otherphases(1:30,:);% downsample high trial count</p><p>5. upsampled_phases = repmat(phases,3,1);% upsample low trial count</p><p>6. ITPC = abs(mean(exp(1i*phases),1));</p><p>7. otherITPC = abs(mean(exp(1i*otherphases),1));</p><p>8. downsampledITPC = abs(mean(exp(1i*downsampled_otherphases),1));</p><p>9. upsampledITPC = abs(mean(exp(1i*upsampled_phases),1));</p><p>10. figure;</p><p>11. subplot(2,1,1); hist(ITPC); title('Original phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>12. subplot(2,1,2); hist(otherITPC); title('Original phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>13. figure;</p><p>14. subplot(2,1,1); hist(upsampledITPC); title('Upsampled phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>15. subplot(2,1,2); hist(otherITPC); title('Original phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>16. figure;</p><p>17. subplot(2,1,1); hist(ITPC); title('Original phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>18. subplot(2,1,2); hist(downsampledITPC); title('Downsampled phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>19.% % End Matlab code</p></disp-quote><p>We thank the reviewers for providing Matlab code to compare upsampling and downsampling of ITPC. While the reviewers interpretation of their code appears to contradict with our original claim, in fact, it is consistent with what we have claimed: downsampling enhances the bias while upsampling does not. The discordance in interpretation comes from the way the reviewer contrasts the results (ITPC vs. otherITPC, upsampled ITPC vs. otherITPC, and ITPC vs. downsampled ITPC). As we explain in the following, we claim that the appropriate comparison is between ITPC vs upsampled ITPC and other ITPC vs. downsampled ITPC. The details in response to the reviewers’ code are as follows:</p><p>Explanation of the code:</p><p>Lines 2-5 prepare the data, in which the true ITPC is assumed as 0. We interpret <italic>phases</italic> to represent 30 trials sampled from 1000 channels (or subjects). Then, line 10-11 plots the expected “bias” distribution over 1000 channels where the true ITPC is 0 and sampled over 30 trials in each channel. (Reproduced as <xref ref-type="fig" rid="respfig4">Author response image 4A</xref>)</p><p>Now line 13-14 plots what the reviewers call <italic>upsampled_phases.</italic> But line 5 creates it by duplicating the same random distribution 3 times (<xref ref-type="fig" rid="respfig4">Author response image 4B</xref>, which is identical to <xref ref-type="fig" rid="respfig4">Author response image 4A</xref> by definition). This is different from what we did, which is upsampling with replacement. Our procedure would replace line 5 as follows:</p><p>for iChannel = 1:1000</p><p>upsampled_phasesv2 = phases(randi(30,1, 90), iChannell);</p><p>end</p><p>With this correction, upsampling minimally affects the distribution (<xref ref-type="fig" rid="respfig4">Author response image 4C</xref>) from the original distribution (<xref ref-type="fig" rid="respfig4">Author response image 4A</xref>). This was exactly our point. Upsampling does not introduce further bias into the ITPC estimated from all available 30 trials. From the originally sampled 30 trials, we cannot (and should not be able to) reduce the bias no matter how much upsampling we do.</p><p>Next, line 12 plots the expected ITPC distribution of <italic>otherphases</italic> defined in line 3, where now each channel is sampled with 90 trials. This proves the point that ITPC bias (when the true ITPC is 0) reduces as we increase the number of sample trials. (Reproduced as <xref ref-type="fig" rid="respfig4">Author response image 4D</xref>)</p><p>Line 4 downsamples 30 trials out of the 90 available trials in <italic>otherphases.</italic> Line 18 plots this downsampled distribution of the ITPC, which proves our point that downsampling introduces further bias (comparing 4D to 4E). This is the reason why we have not used downsampling.</p><p>The above code by the reviewer establishes that when the true ITPC is assumed to be 0, 1) we should sample more trials to reduce the bias in ITPC, 2) upsampling with replacement does not introduce much bias, and 3) downsampling introduces significant bias.</p><p>Given that our data consists of N=34 subjects, whose minimal number of trials is 12 and maximal is 36, and that the mean ITPC across subjects should be computed with an equal number of trials, we opted for upsampling to the maximum number of trials across subjects.</p><p>The revised code is reproduced here for convenience:</p><p>1.% % Matlab code</p><p>2, phases = 2*pi*rand(30,1000);% low trial count condition</p><p>3, otherphases = 2*pi*rand(90,1000);% high trial count condition</p><p>4, downsampled_otherphases = otherphases(1:30,:);% downsample high trial count</p><p>5. upsampled_phases = repmat(phases,3,1);% upsample low trial count</p><p>6. upsampled_phasesv2 =zeros(size(upsampled_phases));</p><p>7, for iChannel = 1:1000</p><p>8. upsampled_phasesv2(:,iChannel) = phases(randi(30,1, 90), iChannel);</p><p>9. end</p><p>10. ITPC = abs(mean(exp(1i*phases),1));</p><p>11. otherITPC = abs(mean(exp(1i*otherphases),1));</p><p>12. downsampledITPC = abs(mean(exp(1i*downsampled_otherphases),1));</p><p>13. upsampledITPC = abs(mean(exp(1i*upsampled_phases),1));</p><p>14. upsampledITPCv2 = abs(mean(exp(1i*upsampled_phasesv2),1));</p><p>15. figure;</p><p>16. subplot(5,1,1); hist(ITPC); title('Original phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>17.% figure;</p><p>18. subplot(5,1,2); hist(upsampledITPC); title('Upsampled phases (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>19. subplot(5,1,3); hist(upsampledITPCv2); title('Upsampled phases v2 (low N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>20. subplot(5,1,4); hist(otherITPC); title('Original phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>21. subplot(5,1,5); hist(downsampledITPC); title('Downsampled phases (high N)'); set(gca,'xlim',[0 0.4],'ylim',[0 250]); xlabel('ITPC');</p><p>22.% % End Matlab code</p><fig id="respfig4"><object-id pub-id-type="doi">10.7554/eLife.40868.028</object-id><label>Author response image 4.</label><caption><title>Results from Matlab code comparing downsampling and upsampling measures on ITPC bias.</title><p>The critical comparisons are between 4A and 4C, and 4D and 4E. Compared to the original ITPC values with a low trial count (4A), upsampling introduces a minimal bias (4C). Compared to original ITPC values with a high trial count (4D) downsampling introduces a large bias (4E).</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig4-v2"/></fig><p>As a sanity check, we performed a further analysis using our own data. <xref ref-type="fig" rid="respfig5">Author response image 5</xref> shows the results from an example subject, when the number of repetitions is sufficient (100 bootstraps in the example below), the statistical results using:</p><p>a) bootstrapping with replacement to retain the original number of trials (N=22 trials for this subject);</p><p>b) bootstrapping with replacement when downsampling the number of trials to N=12 (the minimum number across 34 subjects); and</p><p>c) bootstrapping with replacement when upsampling the number of trials to N=36 (the maximum across subjects),</p><p>All result in similar conclusions.</p><p>Critically however, the values for baseline ITPC (or lowest ITPC values) are highest (~0.35) with b) downsampling, compared to upsampling (~0.2) or 22 trials (~0.22), which is consistent with what we expect from the simulation code provided by the reviewer.</p><fig id="respfig5"><object-id pub-id-type="doi">10.7554/eLife.40868.029</object-id><label>Author response image 5.</label><caption><title>Subject level 3.5 Hz ITPC after bootstrapping with replacement for attended low-frequency auditory and tactile cues.</title><p>(a) The observed topographic ITPC after bootstrapping with replacement using the observed number of trials for this subject and cue-type (n = 22, bootstrapped 100 times). b and c) Topographic ITPC b) with downsampling (12 trials) and bootstrapping with replacement and c) with upsampling (36 trials) and bootstrapping with replacement.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig5-v2"/></fig><disp-quote content-type="editor-comment"><p>11) Figures 2A, 3A, 4B and 5B require figure legends so that the meaning of the colors is clear without reading the caption.</p></disp-quote><p>We have now added these figure legends.</p><disp-quote content-type="editor-comment"><p>12) In Figures 4A and 5A it would be helpful to mark all electrode locations with small dots. We assume these plots are thresholded, such that electrodes with non-significant t-values are set to t=0, but this wasn't stated explicitly. Why not plot all t-values and indicate which are significant in some other way (e.g. with superimposed symbols).</p></disp-quote><p>We had thresholded non-significant electrodes in these figures. We had elected not to superimpose electrodes onto our topoplots that would obscure significant t-scores, and similarly, to threshold all non-significant regions after our two-stage spatial cluster-based analysis. This is because isolated regions (single electrodes) were present in the topography, but did not survive our cluster-based corrections for statistical significance.</p><p>In <xref ref-type="fig" rid="respfig6">Author response image 6</xref> we display the non-thresholded version for the reviewers. However, we believe it is not a recommended statistical practice to show non-significant results (after corrections for multiple comparisons), thus we prefer to keep this figure only here. Having said that, we will follow the advice from <italic>eLife</italic> and the reviewers.</p><fig id="respfig6"><object-id pub-id-type="doi">10.7554/eLife.40868.030</object-id><label>Author response image 6.</label><caption><title>Alternate display of topoplots in manuscript Figures 4 and 5.</title><p>At the first stage of analysis, electrodes which are significant at p &lt;.05 uncorrected were identified (shown in grey). Those which survived our spatial cluster-based criterion to account for multiple comparisons across electrodes are shown in white.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig6-v2"/></fig><disp-quote content-type="editor-comment"><p>13) The 9Hz difference in Figure 5B is somewhat unexpected. This is described as a 'stimulus harmonic', but if so, we wouldn't expect to see a difference between matched and mismatched trials. Do the authors have an explanation for this? Does the 9Hz response also correlate with the PSI measure?</p></disp-quote><p>We are not surprised by the 9 Hz response, as our data also shows that the 9 Hz response (frequency-double of 4.5 Hz frequency tag) tracks perceptual alternations during binocular rivalry (<xref ref-type="fig" rid="respfig7">Author response image 7</xref>).</p><fig id="respfig7"><object-id pub-id-type="doi">10.7554/eLife.40868.031</object-id><label>Author response image 7.</label><caption><title>Frequency-tagged changes during binocular rivalry at PO8.</title><p>SNR at 9 Hz during visual-only conditions tracks the contents of consciousness during a change to the low-frequency (4.5 Hz) percept.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig7-v2"/></fig><p>During mismatched cues, predominantly, a change in percept is experienced, whereby a low frequency percept enters into conscious awareness (as shown in manuscript Figure 2C). These switches result in changes to the frequency-tagged SNR, and as a result, we see an increase in 9 Hz SNR after the onset of a mismatched cue in parieto-occipital regions.</p><p>Thus an increase in ITPC at 9 Hz is to be expected for mismatched relative to matched cues, given an increase in SNR at 9 Hz upon changes in visual percepts. Indeed, increases in SSVEP strength have been shown to result from increased ITPC (Kim et al., NatNeuro, 2007).</p><p>By contrast, during matched cues, usually no change in percept is experienced. As a result, there is no transient increase in the 9 Hz response.</p><p>Neither the 4.5 Hz response or the 9 Hz response correlates with our PSI measures.</p><disp-quote content-type="editor-comment"><p>14) The model diagrams in Figure 6 are somewhat confusing. For model (a), do the authors mean that the suppressed image emerges back because attention shifts to the mismatched cue first, and thus the mismatched cue enhances the suppressed image? For model (b), it seems surprising that the presence of the green-crossmodal cue would let the attention focus move from the dominant red image to the suppressed red image, before it moves to the dominant green image.</p></disp-quote><p>We included this figure to offer a schematic to emphasise the different foci of attention in our suggested interpretations, and not to provide a detailed model of how we think it works. We have clarified our intention in our revised figure legend, emphasizing that this scheme does not imply any detailed mechanisms of how attentional sampling during binocular rivalry should work. Our take-home message was to compare a) sampling between visual and crossmodal cues and b) sampling between dominant and suppressed visual stimuli. We could remove this figure if the editor and reviewers recommend.</p><disp-quote content-type="editor-comment"><p>15) For correlation scatterplots, it would be helpful to include R and p values in the plot. Are the straight lines in these plots regression lines that predict the y-values using the x-values (i.e. minimizing the error in the y-direction)? Given that both of these are dependent variables with presumably no implied causation, we recommend using Deming regression lines instead, which minimize the absolute error between the line and each data point.</p></disp-quote><p>We have now included r and p values in these plots.</p><p>The reviewer is correct, the straight lines are least-squares regression lines, predicting the change in PSI based on nITPC, while minimizing error in the y-direction (change in PSI). We do however have an implied causation (predicting the y-values from the x-values), as we are correlating the nITPC strength 0:2 s after stimulus onset to the change in PSI 2:4 s after cue onset.</p><p>As an alternative, we present (<xref ref-type="fig" rid="respfig8">Author response image 8</xref>) the original correlations, with three-regression lines, as per Huang et al. (<italic>eLife</italic>, 2013).</p><p>Given our prior expectation of the implied causality, we would prefer to stick with the linear regression lines, and have amended our figure captions to clarify these.</p><fig id="respfig8"><object-id pub-id-type="doi">10.7554/eLife.40868.032</object-id><label>Author response image 8.</label><caption><title>Differentiation between Deming (orthogonal) regression and linear least-squares regression for our critical comparisons, related to manuscript Figures 4 and 5.</title><p>In all panels, Deming regression lines are plotted in black. Regression lines for horizontal residuals are displayed in green.</p></caption><graphic mime-subtype="jpeg" mimetype="image" xlink:href="elife-40868-resp-fig8-v2"/></fig><p>[Editors' note: further revisions were requested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The three reviewers and I think that you have addressed all the issues raised satisfactorily, but one. The pending issues regards the ITPC calculations and down-sampling vs. up-sampling.</p><p>We note that there is a crucial difference in the definition of ITPC &quot;bias&quot;: You are talking about minimizing absolute bias (the fact that ITPC is always overestimated when using a finite number of trials, to an extent inversely related to the trial number, e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4D and 4E</xref>). Instead, the reviewers are worried about relative bias (the fact that two experimental conditions with equal &quot;true&quot; ITPC may produce very different ITPC values if the number of trials is not equated, e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4A and 4D</xref>).</p><p>Your upsampling method keeps the absolute bias as low as possible in each condition (given the trial number), but does not reduce relative bias (e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4C and 4D</xref>). Only downsampling can remove this relative bias (e.g. compare <xref ref-type="fig" rid="respfig4">Author response image 4A and 4E</xref>). This comes with the cost of an increase in absolute bias for the high N condition (compare <xref ref-type="fig" rid="respfig4">Author response image 4D and 4E</xref>), but given that your analysis relies on a comparison of the two conditions, the relative bias must be eradicated; absolute bias changes are just collateral damage.</p><p>To summarize:</p><p>1) The reviewer made the null assumption that the 2 experimental conditions (matched/mismatched) have the same true ITPC but different numbers of trials. (Here the true ITPC was assumed to be zero, which is the worst-case scenario: no actual phase-locking).</p><p>2) When comparing ITPC across the two conditions, a systematic difference was found (<xref ref-type="fig" rid="respfig4">Author response image 4A</xref> vs. 4D). This difference is necessarily a statistical artifact.</p><p>3) The reviewer applied the authors' upsampling method to equate trials; the systematic difference remained (<xref ref-type="fig" rid="respfig4">Author response image 4B</xref>/4C vs. 4D).</p><p>4) The reviewer applied a downsampling method to equate trials; the (artifactual) difference disappeared (<xref ref-type="fig" rid="respfig4">Author response image 4A</xref> vs. 4E).</p><p>5) Conclusion:</p><p>The authors are correct that upsampling can preserve the ITPC to have a similar value as that derived from the original dataset (without resampling). But, this is not the point here. The aim of resampling is to let the ITPCs from the two conditions comparable when performing statistical tests. When comparing ITPC from two conditions with unequal trial numbers, upsampling can produce false positives, downsampling will not. Thus, the authors should use downsampling instead of upsampling.</p></disp-quote><p>We are pleased to hear that our ITPC resampling procedure is the only remaining issue.</p><p>After reviewing your explanation, we are in agreement that reducing the relative bias in ITPC values is preferable in this case.</p><p>We have revised our analysis and proceeded by downsampling. Our overall conclusions have not changed, and we have adjusted the statistical values and figures accordingly.</p><p>These changes are in the revised manuscript, and include new data for Figures 4 and 5.</p><p>All associated source data and figure supplements have also been updated.</p><p>We have now addressed all of the reviewers’ concerns and hope our paper is now suitable for publication in <italic>eLife.</italic></p></body></sub-article></article>