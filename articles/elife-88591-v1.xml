<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">88591</article-id><article-id pub-id-type="doi">10.7554/eLife.88591</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.88591.4</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>MotorNet, a Python toolbox for controlling differentiable biomechanical effectors with artificial neural networks</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Codol</surname><given-names>Olivier</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0796-5457</contrib-id><email>codol.olivier@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Michaels</surname><given-names>Jonathan A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5179-3181</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Kashefi</surname><given-names>Mehrdad</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5981-5923</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0786-0081</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Gribble</surname><given-names>Paul L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1368-032X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Western Institute for Neuroscience, University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">Ontario</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Psychology, University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">Ontario</named-content></addr-line><country>Canada</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Physiology &amp; Pharmacology, Schulich School of Medicine &amp; Dentistry, University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">Ontario</named-content></addr-line><country>Canada</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Robarts Research Institute, University of Western Ontario</institution></institution-wrap><addr-line><named-content content-type="city">Ontario</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Makin</surname><given-names>Tamar R</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>30</day><month>07</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP88591</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-04-27"><day>27</day><month>04</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-02-23"><day>23</day><month>02</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.17.528969"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-06-23"><day>23</day><month>06</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88591.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-03-07"><day>07</day><month>03</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88591.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-16"><day>16</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88591.3"/></event></pub-history><permissions><copyright-statement>© 2023, Codol et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Codol et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-88591-v1.pdf"/><abstract><p>Artificial neural networks (ANNs) are a powerful class of computational models for unravelling neural mechanisms of brain function. However, for neural control of movement, they currently must be integrated with software simulating biomechanical effectors, leading to limiting impracticalities: (1) researchers must rely on two different platforms and (2) biomechanical effectors are not generally differentiable, constraining researchers to reinforcement learning algorithms despite the existence and potential biological relevance of faster training methods. To address these limitations, we developed MotorNet, an open-source Python toolbox for creating arbitrarily complex, differentiable, and biomechanically realistic effectors that can be trained on user-defined motor tasks using ANNs. MotorNet is designed to meet several goals: ease of installation, ease of use, a high-level user-friendly application programming interface, and a modular architecture to allow for flexibility in model building. MotorNet requires no dependencies outside Python, making it easy to get started with. For instance, it allows training ANNs on typically used motor control models such as a two joint, six muscle, planar arm within minutes on a typical desktop computer. MotorNet is built on PyTorch and therefore can implement any network architecture that is possible using the PyTorch framework. Consequently, it will immediately benefit from advances in artificial intelligence through PyTorch updates. Finally, it is open source, enabling users to create and share their own improvements, such as new effector and network architectures or custom task designs. MotorNet’s focus on higher-order model and task design will alleviate overhead cost to initiate computational projects for new researchers by providing a standalone, ready-to-go framework, and speed up efforts of established computational teams by enabling a focus on concepts and ideas over implementation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>motor control</kwd><kwd>motor learning</kwd><kwd>computational model</kwd><kwd>neural network</kwd><kwd>muscle model</kwd><kwd>biomechanical model</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN/05458-2018</award-id><principal-award-recipient><name><surname>Gribble</surname><given-names>Paul L</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001804</institution-id><institution>Canada Research Chairs</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010231</institution-id><institution>Banting Research Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Michaels</surname><given-names>Jonathan A</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><award-id>PJT-175010</award-id><principal-award-recipient><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN-2022-04421</award-id><principal-award-recipient><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><award-id>PJT-156241</award-id><principal-award-recipient><name><surname>Gribble</surname><given-names>Paul L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>MotorNet is a Python toolbox for training artificial neural networks to control arbitrarily complex, differentiable, and biomechanically realistic musculo-skeletal effectors on user-defined sensorimotor tasks.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Research on the neural control of movement has a long and fruitful history of complementing empirical studies with theoretical work (<xref ref-type="bibr" rid="bib33">Lindsay, 2022</xref>). Consequently, a wide variety of computational model classes have been proposed to explain empirical observations, such as equilibrium point control (<xref ref-type="bibr" rid="bib14">Feldman and Levin, 1995</xref>; <xref ref-type="bibr" rid="bib16">Flanagan et al., 1993</xref>; <xref ref-type="bibr" rid="bib23">Gribble and Ostry, 2000</xref>; <xref ref-type="bibr" rid="bib64">Won and Hogan, 1995</xref>), optimal control (<xref ref-type="bibr" rid="bib55">Shadmehr and Krakauer, 2008</xref>; <xref ref-type="bibr" rid="bib58">Todorov, 2004</xref>), and parallel distributed processing models (<xref ref-type="bibr" rid="bib15">Fetz, 1993</xref>; <xref ref-type="bibr" rid="bib21">Gomi and Kawato, 1993</xref>; <xref ref-type="bibr" rid="bib25">Jordan and Rumelhart, 1992</xref>; <xref ref-type="bibr" rid="bib30">Lillicrap and Scott, 2013</xref>), commonly known as artificial neural networks (ANNs). Although ANNs were formalized many decades ago, they gained in popularity only recently following their rise to prominence in machine learning (ML; <xref ref-type="bibr" rid="bib29">LeCun et al., 2015</xref>), as their greater explanatory power and biological realism provide significant advantages against alternative model classes (<xref ref-type="bibr" rid="bib19">Gershman and Ölveczky, 2020</xref>; <xref ref-type="bibr" rid="bib31">Lillicrap et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Richards et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Saxe et al., 2021</xref>).</p><p>For neural control of movement, production of theoretical work using ANN models may be viewed as a two-step effort: (1) building a realistic simulation environment that mimics the behaviour of bodily effectors and (2) implement the policy ANNs themselves to train on the environment. Many open-source platforms achieve each of these steps individually, such as MuJoCo (<xref ref-type="bibr" rid="bib59">Todorov et al., 2012</xref>) or OpenSim (<xref ref-type="bibr" rid="bib11">Delp et al., 2007</xref>; <xref ref-type="bibr" rid="bib53">Seth et al., 2018</xref>) for building environments, and JAX, PyTorch, or TensorFlow for building and training policy ANNs. However, approaches using these platforms lead to two important impracticalities.</p><p>First, the user must rely on two different software platforms, one for the environment and one for the policy ANN. Communication between platforms is not built-in, requiring users to produce custom code to link the policy ANN software with the software implementing the simulation of the environment. This forces significant overhead cost to initiate computational projects and creates barriers to research teams who lack the technical background to build those custom pipelines. A current remedy to this issue is <italic>gymnasium</italic> (<xref ref-type="bibr" rid="bib5">Chinnaiya et al., 2023</xref>), a Python toolbox that provides an interface between policies and environments.</p><p>However, <italic>gymnasium</italic> constrains the user to reinforcement learning algorithms (<xref ref-type="bibr" rid="bib18">Fujimoto et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Lillicrap et al., 2019</xref>; <xref ref-type="bibr" rid="bib38">Mnih et al., 2015</xref>) despite the existence and potential biological relevance of faster training methods such as backpropagation (<xref ref-type="bibr" rid="bib32">Lillicrap et al., 2020</xref>; <xref ref-type="bibr" rid="bib61">Whittington and Bogacz, 2017</xref>). The inability to use backpropagation to train policies represents the second impracticality. To date, this has been circumvented by training separate ANNs such as multi-layer perceptrons or recurrent neural networks (RNNs) as ‘forward models’ approximating the behaviour of effectors that are normally implemented in a separate software package (e.g., <xref ref-type="bibr" rid="bib30">Lillicrap and Scott, 2013</xref>; <xref ref-type="bibr" rid="bib63">Willett et al., 2021</xref>). This approach does not address the need for custom pipelines, and remains a slow, cumbersome process when iterating over many different policies and environments, because new approximator ANNs must be trained each time.</p><p>Solving the issues described above requires both the policy and environment to rely on the same software (no-dependency requirement), and for the environment to allow for backpropagation through itself (differentiability requirement) so that typical gradient-based algorithms may be employed. Ideally, the solution would also be open source, modular for flexibility of coding and focus on ideas, and have reasonable training speeds on commercially available computers.</p><p>We developed MotorNet with these principles in mind. MotorNet is a freely available open-source Python toolbox (<ext-link ext-link-type="uri" xlink:href="https://motornet.org">https://motornet.org</ext-link>) that allows for the training of ANNs to control arbitrarily complex and biomechanically realistic effectors to perform user-defined motor tasks. The toolbox requires no dependency besides standard Python toolboxes available on <italic>pip</italic> or Anaconda libraries. This greatly facilitates its use on remote computing servers as no third-party software needs to be installed. The environments are fully differentiable, enabling fast and efficient training of ANNs using standard gradient-based methods. It is designed with ease of installation and ease of use in mind, with a high-level and user-friendly application programming interface (API). Its programming architecture is modular to allow for flexibility in model building and task design. Finally, MotorNet is built on PyTorch, which makes innovation in ML readily available for use by MotorNet as they are implemented and released by the PyTorch Foundation. Here, we focus on illustrating the scientific use and relevance of the toolbox (the <italic>why</italic>), rather than the underlying API through coding snippets (the <italic>how</italic>), as the latter is more efficiently showcased via interactive, easily updatable online tutorials. The interested reader may consult the full API documentation, including interactive tutorials on the toolbox website at <ext-link ext-link-type="uri" xlink:href="https://motornet.org">https://motornet.org</ext-link>.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Training an ANN to perform a centre-out reaching task against a curl field</title><p>A canonical experimental paradigm in the study of neural control of movement is the centre-out reaching task with a ‘curl field’ applied at the arm’s endpoint by a robot arm (<xref ref-type="bibr" rid="bib10">Conditt et al., 1997</xref>; <xref ref-type="bibr" rid="bib54">Shadmehr and Mussa-Ivaldi, 1994</xref>). In this paradigm, visual targets are placed around a central starting position in a horizontal plane. Participants must move the handle of a robot arm from the starting position to the target that appears on a given trial. During the reaching movement, the robot applies forces at the handle that scale linearly with the velocity of the hand and push in a lateral direction. This leads the central nervous system to adapt by modifying neural control signals to muscles to apply opposite forces to counteract and nullify the lateral forces produced by the robot. Finally, removal of the curl field leaves an opposite after-effect (<xref ref-type="bibr" rid="bib54">Shadmehr and Mussa-Ivaldi, 1994</xref>). This paradigm is well suited to assess the functionality of MotorNet because it is well understood and extensively documented, and highlights physical, biomechanical, and control properties of human behaviour.</p><p>We specified a one-layer RNN composed of 50 gated recurrent units (GRUs; <xref ref-type="bibr" rid="bib6">Cho et al., 2014</xref>) to control a two degrees of freedom (DoF), six muscle planar arm model (<italic>arm26</italic>; <xref ref-type="fig" rid="fig1">Figure 1a</xref>; <xref ref-type="bibr" rid="bib27">Kistemaker et al., 2006</xref>; <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>). The muscles were rigid-tendon, Hill-type muscle models, with ‘shoulder’ mono-articular flexors/extensors, ‘elbow’ mono-articular flexors/extensors, and a bi-articular pair of muscles producing flexion or extension at both joints (see Methods sections ‘Arm26 model’ and ‘Model’).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Controlling an arm-like effector in a centre-out reaching task with a curl field.</title><p>(<bold>a</bold>) Schematic of the environment (containing the effector) and policy. (<bold>b</bold>) Endpoint trajectories of centre-out reaching movements in a null and curl field, for a policy recurrent neural network (RNN) that is untrained (naive) and then trained to reach in that curl field. The effector was as defined in <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>. (<bold>c</bold>) Different variables over time during a rightward reaching movement.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig1-v1.tif"/></fig><p>Training the model above took about 13 min on a 2022 Mac Studio with an M1 Max central processing unit (Apple Inc, Cupertino, CA, USA). Because the <italic>arm26</italic> effector and the centre-out reaching task are particularly common in the motor control literature, they are included in the toolbox as pre-built objects. Consequently, one can re-create the effector instance and the corresponding environment in one line of code for each. Note however that users can easily declare their own custom-made effector and environment objects if desired by subclassing the base <italic>Effector</italic> and <italic>Environment</italic> class, respectively (see below for more details on base classes and subclassing).</p><p>Including the implementation of the policy RNN and training routine, the above example can be reproduced with a few lines of code (see tutorial notebooks online), illustrating the ease of use of MotorNet’s API. Once the model is trained, it can produce validation results via a forward pass (<xref ref-type="fig" rid="fig1">Figure 1b, c</xref>), which can then be saved and analysed afterwards. The results the model produces include joint and cartesian states (positions, velocities), muscle states (lengths, velocities, activations, forces), musculo-tendon states (lengths, velocities), efferent actions (i.e., time-varying muscle drive), and afferent feedback responses (proprioceptive, visual), as well as any activity states from the network if applicable (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). Note that actions are different from muscle activations, in that they are input signals to the ordinary differential equation that produces muscle activation (see Methods; <xref ref-type="bibr" rid="bib37">Millard et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>).</p></sec><sec id="s2-2"><title>Structure of MotorNet</title><p>Functionally, a MotorNet model can be viewed as a differentiable environment that can directly employ outputs from a policy ANN as action signals. The environment contains an effector, which is actuated according to the action input and in turn outputs information that may be fed back to the ANN (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This closed-loop cycle repeats for each timestep. By default, ‘visual’ feedback consists of a vector indicating endpoint cartesian coordinates, while ‘proprioceptive’ feedback consists of a <inline-formula><mml:math id="inf1"><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:math></inline-formula>-element vector of muscle length and velocity, with <inline-formula><mml:math id="inf2"><mml:mi>m</mml:mi></mml:math></inline-formula> the number of muscles of the effector. Noise may be added in various parts of the model, such as on descending action signals or on feedback signals. Finally, time delays may be added to feedback signals before they reach the policy ANN. Importantly, the policy ANN may be any PyTorch network, and the MotorNet environments are designed to match standard <italic>gymnasium</italic> API conventions. That is, it is not necessary to create a policy by sub-classing a MotorNet <italic>Policy</italic> object.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Conceptual organization of a MotorNet model.</title><p>A policy artificial neural network (ANN) receives arbitrary input as well as recurrent connections from itself and sends action signals to an effector embedded in an environment, which in turn sends sensory feedback information. Typically, this feedback will be visual and proprioceptive, and can contain feedback-specific time delays Δ<sub>p</sub> and Δ<sub>v</sub>. Gaussian noise can be added to the recurrent connection, action signal, and proprioceptive and visual feedback, with specific standard deviation <italic>σ</italic><sub>h</sub>, <italic>σ</italic><sub>u</sub>, <italic>σ</italic><sub>p</sub>, and <italic>σ</italic><sub>v</sub>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig2-v1.tif"/></fig><sec id="s2-2-1"><title>Running flow</title><p>At runtime, a more detailed representation of the information flow best describes how a MotorNet model behaves (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). Models are based on five object classes: <italic>Skeleton</italic>, <italic>Muscle</italic>, <italic>Effector</italic>, <italic>Environment</italic>, and <italic>Policy</italic> objects (<xref ref-type="table" rid="table1">Table 1</xref>). Each object has its own base class, from which the user can create a custom subclass if desired. MotorNet comes with a set of pre-built subclasses for each, which implement commonly used computational model formalizations (<xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Overview of Python base classes and their respective pre-built subclasses in MotorNet.</title><p>GRU: gated recurrent unit.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom">Subclass</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="2"><bold>Skeleton</bold></td><td align="left" valign="bottom"><italic>PointMass</italic></td><td align="left" valign="bottom">A skeleton with one bone of null length evolving in a plane.</td></tr><tr><td align="left" valign="bottom"><italic>TwoJointArm</italic></td><td align="left" valign="bottom">A planar, two-segment skeleton with one hinge joint between the segments and the remaining end of one segment anchored to the world space.</td></tr><tr><td align="left" valign="middle" rowspan="4"><bold>Muscle</bold></td><td align="left" valign="bottom"><italic>ReluMuscle</italic></td><td align="left" valign="bottom">An actuator that produces forces according to a linear piece-wise function of activation. The lower bound of force production is 0.</td></tr><tr><td align="left" valign="bottom"><italic>RigidTendonHillMuscle</italic></td><td align="left" valign="bottom">A Hill-type muscle according to the formalization in <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>, adjusted for rigid-tendon dynamics.</td></tr><tr><td align="left" valign="bottom"><italic>RidigTendonHillMuscleThelen</italic></td><td align="left" valign="bottom">A Hill-type muscle according to the formalization in <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>, adjusted for rigid-tendon dynamics.</td></tr><tr><td align="left" valign="bottom"><italic>CompliantTendonHillMuscle</italic></td><td align="left" valign="bottom">A Hill-type muscle according to the formalization in <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>.</td></tr><tr><td align="left" valign="middle" rowspan="3"><bold>Effector</bold></td><td align="left" valign="bottom"><italic>ReluPointMass24</italic></td><td align="left" valign="bottom">A planar (2D) <italic>PointMass</italic> with four <italic>ReluMuscle</italic> actuators.</td></tr><tr><td align="left" valign="bottom"><italic>RigidTendonArm26</italic></td><td align="left" valign="bottom">A <italic>TwoJointArm</italic> with six <italic>RigidTendonHillMuscle</italic> actuators.</td></tr><tr><td align="left" valign="bottom"><italic>CompliantTendonArm26</italic></td><td align="left" valign="bottom">A <italic>TwoJointArm</italic> with six <italic>CompliantTendonArm26</italic> actuators.</td></tr><tr><td align="left" valign="middle" rowspan="3"><bold>Environment</bold></td><td align="left" valign="bottom"><italic>CentreOutReach</italic></td><td align="left" valign="bottom">A centre-out reaching task.</td></tr><tr><td align="left" valign="bottom"><italic>DelayedReach</italic></td><td align="left" valign="bottom">A reaching task where movement initiation is signified by the appearance of a ‘go’ cue.</td></tr><tr><td align="left" valign="bottom"><italic>DelayedMultiReach</italic></td><td align="left" valign="bottom">A reaching task where movement initiation is signified by the appearance of a ‘go’ cue, and several targets appear in sequence for each trial.</td></tr><tr><td align="left" valign="middle"><bold>Policy</bold></td><td align="left" valign="bottom"><italic>PolicyGRU</italic></td><td align="left" valign="bottom">An RNN network comprising a user-defined number of layers containing a user-defined number of GRUs.</td></tr></tbody></table></table-wrap><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Implementation of MotorNet.</title><p>(<bold>a</bold>) Information flow of a MotorNet model during runtime. (<bold>b</bold>) Declarative structure of a MotorNet object. Each object instance is held in memory as an attribute of another according to this hierarchical representation, except for the Muscle, and Skeleton instances.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig3-v1.tif"/></fig><p><italic>Environment</italic> objects are the entry point of the model (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). They take arbitrary action inputs, which are then passed on to the <italic>Effector</italic> object. <italic>Effector</italic> objects are essentially wrapper objects that hold the <italic>Muscle</italic> and <italic>Skeleton</italic> objects and handle coordination of information flow between them (<xref ref-type="fig" rid="fig3">Figure 3a, b</xref>), as well as concomitant numerical integration to ensure numerical stability. They pass the action signals to the <italic>Muscle</italic> object, which computes forces in return. The <italic>Effector</italic> will adjust those forces using geometry-dependent moment arms (see section ‘Biomechanical properties of the effector’ for details) and send the resulting generalized forces to the <italic>Skeleton</italic> object. These generalized forces will actualize the <italic>Skeleton</italic>’s joint state, which the <italic>Skeleton</italic> will return to the <italic>Effector</italic> object alongside the equivalent cartesian state. The <italic>Effector</italic> will then return the actuated states to the <italic>Environment</italic> object.</p><p>Finally, the <italic>Environment</italic> object will return an observation vector that contains arbitrarily processed information about the states of the <italic>Environment</italic> and <italic>Effector</italic> objects. These can usually be passed on to the policy ANN as input to perform the next forward pass. The <italic>Environment</italic> may maintain a delay buffer, which stores state information for a certain time (according to the Δ<sub>p</sub> and Δ<sub>v</sub> parameters, <xref ref-type="fig" rid="fig2">Figure 2</xref>), allowing the observation vector to be fed time-delayed state information. The <italic>Environment</italic> also outputs an information dictionary, which contains all the instantaneous (i.e., non-delayed) states from the <italic>Environment</italic>, <italic>Effector</italic>, <italic>Skeleton</italic>, and <italic>Muscle</italic> objects. This allows the user to monitor the true state of the MotorNet model at each timestep.</p></sec><sec id="s2-2-2"><title>Object structure</title><p>The classes presented above rely on each other to function correctly. Consequently, they must be declared in a sensible order, so that each object instance retains as attribute the object instances on which they rely. This leads to a hierarchical class structure, where each instance lives in the computer memory in a nested fashion with other instances, as laid out in <xref ref-type="fig" rid="fig3">Figure 3b</xref>. Note that this does not mean that each class is a subclass of the class that contains it, but that each contained class is saved as an attribute of the container class. The outermost class is an <italic>Environment</italic> object, which itself is a subclass of <italic>gymnasium</italic>’s <italic>Env</italic> class. The <italic>Environment</italic>, <italic>Effector</italic>, <italic>Skeleton</italic>, and <italic>Muscle</italic> objects are also <italic>torch.nn.Module</italic> subclasses. The <italic>Policy</italic> objects are distinct, in that they do not hold any other MotorNet object as attribute. This independence allows users to create their own neural networks without having to rely on MotorNet’s <italic>Policy</italic> object, which allows for more freedom for the user to design any policy that PyTorch can create.</p></sec></sec><sec id="s2-3"><title>Biomechanical properties of the effector</title><p>The modular structure detailed above allows MotorNet to flexibly compute detailed biomechanical properties of <italic>Effector</italic> objects, such as arbitrary muscle paths (<xref ref-type="bibr" rid="bib40">Nijhof and Kouwenhoven, 2000</xref>), geometry-dependent moment arms (<xref ref-type="bibr" rid="bib39">Murray et al., 1995</xref>; <xref ref-type="bibr" rid="bib56">Sherman et al., 2013</xref>), non-linear muscle activations, and passive force production from muscle stretch (<xref ref-type="bibr" rid="bib4">Cheng, 2000</xref>; <xref ref-type="bibr" rid="bib37">Millard et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>). This enables training ANNs on motor tasks whose dynamics are highly non-linear and close to biological reality. In this section, we illustrate some of these biomechanical properties implemented by MotorNet effectors using specific examples. These properties are well characterized in the biology and are often implemented in realistic biomechanical simulation software.</p><sec id="s2-3-1"><title>Assessing moment arms with a simple point-mass effector</title><p>The geometrical path – fixation body(s) and fixation point(s) on that body – of each <italic>Muscle</italic> object can be declared by the user, allowing for arbitrary linkage between muscles and bones (see Methods section ‘Biomechanical properties of the effector’, <xref ref-type="bibr" rid="bib40">Nijhof and Kouwenhoven, 2000</xref>). Using geometric first principles (<xref ref-type="bibr" rid="bib56">Sherman et al., 2013</xref>), the <italic>Effector</italic> object can then calculate the moment arm of forces produced, which is defined for each muscle as the change in value of the DoF of the skeleton for a given change in the muscle’s length (<xref ref-type="bibr" rid="bib39">Murray et al., 1995</xref>; <xref ref-type="bibr" rid="bib56">Sherman et al., 2013</xref>). In lay terms, this is the capacity of a muscle to produce a torque on a joint based on the muscle’s pulling angle on the bones forming that joint. The relationship between pull angle and torque can intuitively be understood using a door as an example: it is easier to push a door when pushing with an angle orthogonal to that door than in a near-parallel angle to that door.</p><p>Moment arms generally vary depending on the positional configuration of the <italic>Effector</italic>. To illustrate this, let us consider a simple case of a point-mass skeleton (one fixation body) with four muscles attached to it in a ‘X’ configuration (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). When the point-mass is positioned in the centre of the workspace space (red position in <xref ref-type="fig" rid="fig4">Figure 4a, b</xref>), any muscle pulling will change the position of the point-mass equally in the <inline-formula><mml:math id="inf3"><mml:mi>x</mml:mi></mml:math></inline-formula> dimension and in the <inline-formula><mml:math id="inf4"><mml:mi>y</mml:mi></mml:math></inline-formula> dimension. Note that <inline-formula><mml:math id="inf5"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf6"><mml:mi>y</mml:mi></mml:math></inline-formula> are the DoFs of the point-mass skeleton since they do not have hinge joints. In contrast, if the point-mass is positioned below the central position (<inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; black position in <xref ref-type="fig" rid="fig4">Figure 4a</xref>), a pull from for example, the lower left muscle will produce a greater change in the <inline-formula><mml:math id="inf8"><mml:mi>x</mml:mi></mml:math></inline-formula> dimension than in the <inline-formula><mml:math id="inf9"><mml:mi>y</mml:mi></mml:math></inline-formula> dimension because of the different muscle alignment (<xref ref-type="fig" rid="fig4">Figure 4b</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Geometrical properties of an Effector object.</title><p>(<bold>a</bold>) Schematic of a point-mass in two positional configurations within a square workspace. The point-mass Skeleton was linked to four muscles in a ‘X’ configuration. (<bold>b</bold>) Moment arm values for the lower left muscle for each of the positional configurations represented in (<bold>a</bold>), with respect to <italic>x</italic> and <italic>y</italic>. (<bold>c</bold>) Complete moment arm function over the position space for each muscle (columns) and with respect to each degrees of freedom (DoF). The upper and lower rows indicate the moment arm with respect to the <italic>x</italic> and <italic>y</italic> positions, respectively. (<bold>d</bold>) Moment arms of a mono-articular extensor muscle on an arm26. (<bold>e</bold>) Moment arms of a bi-articular flexor muscle on an arm26. (<bold>f</bold>) Passive drift in endpoint position of an arm26 similar to <xref ref-type="fig" rid="fig1">Figure 1c</xref> due to passive force developed by overstretch Hill-type muscles.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig4-v1.tif"/></fig><p>The moment arm can then be calculated for all possible positions in the workspace, as represented by the solid black square in <xref ref-type="fig" rid="fig4">Figure 4a</xref>. This can be done for each of the four muscles, and each of the two DoFs, resulting in eight moment arms (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). We can see that each moment arm forms a slightly bent hyperplane. Importantly, for each hyperplane the diagonal with constant moment arm lines up with the path formed by the muscle when the point-mass is at the centre of the workspace. For instance, the moment arm of the upper right muscle is identical when the point-mass is in position (<inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) and in position <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. This is true both with respect to the <inline-formula><mml:math id="inf12"><mml:mi>x</mml:mi></mml:math></inline-formula> DoF (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, upper row, leftmost axis) and with respect to the <inline-formula><mml:math id="inf13"><mml:mi>y</mml:mi></mml:math></inline-formula> DoF (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, lower row, leftmost axis). Note also that muscles whose shortening leads to an increase in the DoF considered – or inversely whose lengthening leads to a decrease in the DoF – express negative moment arms. For instance, a shortening of the lower right muscle would lead to an increase in the <inline-formula><mml:math id="inf14"><mml:mi>x</mml:mi></mml:math></inline-formula> DoF and a decrease in the <inline-formula><mml:math id="inf15"><mml:mi>y</mml:mi></mml:math></inline-formula> DoF. Or more plainly, a pull from the lower right muscle would bring the point-mass closer to the lower right corner of the workspace. This leads to the negative moment arm of that muscle with respect to <inline-formula><mml:math id="inf16"><mml:mi>x</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, upper row) and positive moment arm with respect to <inline-formula><mml:math id="inf17"><mml:mi>y</mml:mi></mml:math></inline-formula> (lower row).</p></sec><sec id="s2-3-2"><title>Moment arms with a two-joint arm</title><p>To consider a more complex effector, we assessed the moment arm of two muscles wrapping around a two-joint arm skeleton. We first assessed a mono-articular muscle, that is, a muscle that spans only one joint – here, the elbow. As expected, the moment arm of that muscle with respect to the shoulder joint is always null (black arrows, <xref ref-type="fig" rid="fig4">Figure 4d</xref>) regardless of the joint configuration since the muscle does not span that joint. In contrast, the moment arm with respect to the elbow joint varies as the elbow joint angle changes. Finally, as expected from an extensor muscle, the moment arm is positive, indicating that the elbow angle would decrease as the muscle shortens.</p><p>In comparison, a bi-articular muscle’s moment arm is non-zero with respect to both joints (<xref ref-type="fig" rid="fig4">Figure 4e</xref>). This also leads the moment arms with respect to each joint to show a small interaction as the other joint’s angle changes, as indicated by a slight ‘bend’ in the hyperplane (black arrows, <xref ref-type="fig" rid="fig4">Figure 4e</xref>). Finally, as expected for a bi-articular flexor muscle, the moment arms are negative with respect to both joints, indicating that muscle shortening would result in an increase in joint angle.</p></sec><sec id="s2-3-3"><title>Passive drift with Hill-type muscles</title><p>Finally, we assessed the positional drift induced by passive forces of Hill-type muscle models (<xref ref-type="bibr" rid="bib37">Millard et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>) in an <italic>arm26</italic> effector model. We initialized the model’s starting position at fixed intervals across the range of possible joint angles, resulting in a grid of 21-by-21 possible starts. We then simulated the effector with null inputs for 200 ms and plotted the drift in the arm’s endpoint position from its original position. Because the model received no input, all forces produced are due to the passive component of the Hill-type muscles, which occurs when the muscle is stretched beyond its slack length (<xref ref-type="bibr" rid="bib4">Cheng, 2000</xref>; <xref ref-type="bibr" rid="bib37">Millard et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>). We can see that drift is negligible at the centre of the joint space but starts to increase towards the edge (<xref ref-type="fig" rid="fig4">Figure 4f</xref>), indicating that the associated joint configurations lead to overstretched muscle lengths and resulting in passive force production. Note that since this phenomenon is dependent on the slack length value of each muscle, which is user-defined, the presence of passive drift is dependent on the user’s modelling choices.</p></sec></sec><sec id="s2-4"><title>Training ANNs to produce naturalistic behaviour</title><p>Now that we can implement biomechanically realistic effectors, we next assessed whether a policy ANN can learn a complex control policy to move those effectors using backpropagation (<xref ref-type="bibr" rid="bib25">Jordan and Rumelhart, 1992</xref>; <xref ref-type="bibr" rid="bib46">Rumelhart et al., 1986</xref>). A typical way to ensure the computation learnt by an ANN is functionally meaningful is to test its out-of-distribution generalization. To assess this, we trained a one-layer RNN with <inline-formula><mml:math id="inf18"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>110</mml:mn></mml:math></inline-formula> GRUs controlling an <italic>arm26</italic> model to perform reaching movements in 0.8 s simulations using the following paradigm. Starting positions and targets were randomly drawn from a uniform distribution across the full joint space. Movements were to be delayed until the occurrence of a visual ‘go’ cue randomly drawn from a uniform distribution spanning the full simulation window. The appearance of the go-cue reached the RNN as input after a delay corresponding to the visual feedback delay, which was set at <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>Δ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:math></inline-formula> ms (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="bibr" rid="bib12">Dimitriou et al., 2013</xref>; <xref ref-type="bibr" rid="bib42">Pruszynski et al., 2010</xref>). In half of trials, no go-cue was provided (catch trial), in which case the task effectively reduced to a postural control task. A 100-ms endpoint mechanical perturbation, whose orientation, magnitude, and time were also randomly drawn occurred in half of trials, independently of whether the trial was a catch trial or not. Importantly, the perturbation magnitude was drawn from a uniform distribution ranging between 0 and 4 N. If the perturbation occurred during a catch trial, the distribution ranged between 0 and 8 N. Therefore, the training protocol used for this task largely differed from section ‘Training an ANN to perform a centre-out reaching task against a curl field’ in that the networks are exposed to a wide range of mechanical perturbations with varying characteristics.</p><p>The network was trained using the following loss:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mi>β</mml:mi><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mi>γ</mml:mi><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>r</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext></mml:mtd><mml:mtd><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">⊤</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mi mathvariant="bold-italic">f</mml:mi><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><label>(1)</label><mml:math id="m5"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">⊤</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">κ</mml:mi></mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mover><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi mathvariant="bold">⊤</mml:mi></mml:mrow></mml:msup><mml:mover><mml:msub><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>With <inline-formula><mml:math id="inf20"><mml:mi>L</mml:mi></mml:math></inline-formula> the global loss including a kernel regularization term with penalty coefficient <inline-formula><mml:math id="inf21"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf22"><mml:mi mathvariant="bold-italic">W</mml:mi></mml:math></inline-formula> the kernel weight matrix of the RNN’s hidden layer. The operators <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mo>⋅</mml:mo><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mo>⋅</mml:mo><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> indicate the L1 and L2 vector norm, respectively. <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the instantaneous loss at time <inline-formula><mml:math id="inf26"><mml:mi>t</mml:mi></mml:math></inline-formula>, with coefficients <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the positional penalty at time <inline-formula><mml:math id="inf29"><mml:mi>t</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> the position and desired position (target) vector, respectively, and <inline-formula><mml:math id="inf31"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math></inline-formula> the target radius. <inline-formula><mml:math id="inf32"><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the muscle activation penalty at time <inline-formula><mml:math id="inf33"><mml:mi>t</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> two vectors representing muscle activations at time <inline-formula><mml:math id="inf35"><mml:mi>t</mml:mi></mml:math></inline-formula> and maximum isometric force, respectively. Finally, <inline-formula><mml:math id="inf36"><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the network hidden activity penalty at time <inline-formula><mml:math id="inf37"><mml:mi>t</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the <inline-formula><mml:math id="inf39"><mml:mi>n</mml:mi></mml:math></inline-formula>-elements vector of GRU hidden activity, <inline-formula><mml:math id="inf40"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:math></inline-formula> its time derivative, and <inline-formula><mml:math id="inf41"><mml:mi mathvariant="normal">κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula>. While superficially this loss appears complex, a direct relationship to biology can be drawn for all terms. Essentially, this loss enforces the control policy to be learned using a simple, straightforward rule (get to the target), while promoting low metabolic cost from network input connectivity (cost on kernel norm), from the muscles (cost on activation, scaled by muscle strength), and from network activity (cost on hidden activity and its derivative to discourage oscillatory regimes).</p><p>Behavioural performance on a training set can be seen in <xref ref-type="fig" rid="fig5">Figure 5a</xref>, with trials with a large perturbation (<inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>3</mml:mn><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) highlighted in blue. This illustrates the rich variability of the training set, encouraging the RNN to learn computationally potent and generalizable solutions to the control problem given the sensorimotor feedback provided (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Despite this variability, the loss value decreased smoothly (<xref ref-type="fig" rid="fig5">Figure 5b</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>A MotorNet model can learn a control policy that generalizes to out-of-distribution perturbations.</title><p>(<bold>a</bold>) Example endpoint trajectories produced by a network after training. (<bold>b</bold>) Loss function over training iterations, with a batch size of 1024. (<bold>c</bold>) Trajectories in a centre-out reaching task with mechanical perturbations applied at the arm’s endpoint 120 ms after the ‘go’ cue. The perturbations were orthogonal to the reaching axis passing from the starting position to the target. o.o.d.: out-of-distribution. (<bold>d</bold>) Same as (<bold>c</bold>) for a postural control task. In this task, the network was not provided with a target and therefore only had to remain in the starting position against the perturbations. Mechanical perturbations were in the vertical (left) or horizontal (right) axis. (<bold>e</bold>) Muscle activation over time for two trajectories in (<bold>c</bold>) (black and blue lines) and a trajectory in (<bold>g</bold>) (green line). BE: bi-articular extensor; BF: bi-articular flexor; EE: elbow extensor; EF: elbow flexor; SE: shoulder extensor; SF: shoulder flexor. (<bold>f</bold>) Reaching task as in (<bold>c</bold>) for a network never exposed to mechanical perturbations during training. (<bold>g</bold>) Postural task as in (<bold>d</bold>) for the same network as in (<bold>f</bold>). Perturbations were in the vertical (top) or horizontal (bottom) axis.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig5-v1.tif"/></fig><p>We tested the model’s behavioural output in 0.8 s simulations with a centre-out reaching task. Eight targets were positioned in 45 degrees increments and 10 cm away from a starting position corresponding to a shoulder and elbow angle of 45 and 90 degrees, respectively (<xref ref-type="fig" rid="fig5">Figure 5c</xref>). The RNN reached to each of these targets following a visual go-cue at 100 ms. 70 ms after the ‘go’ cue was ‘perceived’ (i.e., 70 ms plus the visual feedback delay), a mechanical perturbation was applied at the arm’s endpoint and orthogonally to the reaching direction. This perturbation could be either within-distribution (±3 N) or out-of-distribution (±6 N) or null (no perturbation). In all cases, the RNN could correct for the mechanical perturbation, reach to the target, and stabilize (<xref ref-type="fig" rid="fig5">Figure 5c</xref>).</p><p>Next, we tested the RNN in a postural control task, where it had to bring the arm’s endpoint back to the target following a mechanical perturbation (<xref ref-type="bibr" rid="bib43">Pruszynski et al., 2014</xref>). No go-cue was provided. We applied perturbations in either of the four cardinal directions (0°, 90°, 180°, and 270°) at 170 ms plus visual delay after the trial started. Again, the set of perturbations for testing outputs included within-distribution magnitudes (±6 N) and out-of-distribution magnitudes (±12 N). In all cases, the RNN could integrate the sensorimotor information to bring the arm’s endpoint back into the target (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). Interestingly, in some cases this led to an oscillatory trajectory (e.g., for a rightward +12 N perturbation, <xref ref-type="fig" rid="fig5">Figure 5d</xref>), indicating that perturbations beyond a given magnitude remain increasingly challenging to control for.</p><p>Finally, we compared muscle activations for an upward reach with no perturbation to that of an identical reach with a −6 N perturbation (<xref ref-type="fig" rid="fig5">Figure 5e</xref>). We can see that muscle activations are similar before the occurrence of the perturbation, and remain similar immediately after, indicating a time delay in the response. The fastest responses occurred for the bi-articular muscles and the shoulder extensor muscle. Other muscles, particularly the shoulder flexor, showed very delayed or non-existent changes in muscle activation. This illustrates that the RNN’s response to a perturbation is not a mere stimulus-driven reactive response, but an integrated response that can delay or withhold the production of counteracting forces if necessary. Note that for the non-perturbed movement (black line in <xref ref-type="fig" rid="fig5">Figure 5e</xref>), we can observe the canonical tri-phasic muscle activation pattern reported in empirical studies (<xref ref-type="bibr" rid="bib62">Wierzbicka et al., 1986</xref>).</p><p>To assess how the existence of sensorimotor feedback impacted the control policy acquired by the policy network, we trained a second, identical network to perform the same task but with no mechanical perturbation during training (perturbation-free). Interestingly, following the same amount of training, the model with a perturbation-free network can handle perturbations during reaching relatively well, even up to ±6 N (<xref ref-type="fig" rid="fig5">Figure 5f</xref>). We can compare muscle activations for an upward reach with a −6 N perturbation to that of the same movement in the network trained with perturbations (<xref ref-type="fig" rid="fig5">Figure 5f</xref>, green versus blue lines). Even though kinematics appeared superficially similar (<xref ref-type="fig" rid="fig5">Figure 5c, f</xref>), this comparison shows that muscle activations tend to differ in response to a perturbation (<xref ref-type="fig" rid="fig5">Figure 5e</xref>), suggesting that the perturbation-free network might learn a slightly different control policy. Testing the perturbation-free network on the postural task shown in <xref ref-type="fig" rid="fig5">Figure 5d</xref> emphasizes this difference (<xref ref-type="fig" rid="fig5">Figure 5g</xref>). The perturbation-free network is much less capable of stabilizing against the forces than its perturbation-trained counterpart.</p><p>Therefore, even though the mere existence of a sensorimotor feedback input can help handle simple perturbations (<xref ref-type="fig" rid="fig5">Figure 5f</xref>), exposing the model to perturbations during training does provide the network with additional information to learn a more robust control policy. Overall, these simulations show that MotorNet can train ANNs to reliably find a control policy for the effector. Importantly, the resulting networks learn generalizable control policies that integrate sensorimotor feedback into its computation. This also illustrates the importance of the training procedure to which the network is exposed to produce these control policies (<xref ref-type="bibr" rid="bib13">Driscoll et al., 2022</xref>).</p></sec><sec id="s2-5"><title>Effector geometry defines preference distribution of firing rates: a replication study</title><p>Finally, to assess MotorNet’s capacity to replicate established results in the literature, we sought to reproduce key observations from <xref ref-type="bibr" rid="bib30">Lillicrap and Scott, 2013</xref>. In that study, the authors show that training an RNN to perform a simple centre-out reaching task using an arm model similar to the arm26 in <xref ref-type="fig" rid="fig1">Figure 1a</xref> results in the RNN neurons displaying a preferential movement direction (PMD) where they are more likely to fire. The distribution of PMDs was asymmetrical, with a greater proportion of neurons firing for reaches around 135 and 325 degrees, matching empirical observations from non-human primate electrophysiological recordings in the primary motor cortex (<xref ref-type="bibr" rid="bib50">Scott et al., 2001</xref>). Next, they showed that this asymmetrical representation of PMDs during reaching movements did not occur when RNNs were trained to control an effector that lacked the geometrical properties of an arm such as illustrated in <xref ref-type="fig" rid="fig4">Figure 4c–e</xref> and section ‘Training an ANN to perform a centre-out reaching task against a curl field’. Specifically, they compared the PMD distribution of RNN neurons controlling a point-mass (no geometry) against that of an arm26 (geometry present).</p><p>We sought to reproduce the two results outlined above. First, we trained an RNN composed of 90 GRUs in a single layer to control for an arm26 (<xref ref-type="fig" rid="fig6">Figure 6a</xref> see Methods section ‘Effector geometry defines preference distribution of firing rates: a replication study’). Because our RNN employs GRUs instead of a multi-layer perceptron, 90 units were sufficient to efficiently train the network to perform the task, as opposed to up to 1000 perceptron nodes in the original study. We also increased the number of targets from 8 to 24 to obtain a finer resolution over movement direction in our analyses (<xref ref-type="fig" rid="fig6">Figure 6b</xref>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>The distribution of preferential movement direction (PMD) tuning is sensitive to the geometry of the effector.</title><p>(<bold>a</bold>) Schematic of the two models compared. The recurrent neural networks (RNNs) and their architecture were identical, but the effector differed, with one RNN controlling a two-joint arm26 (left) and the other controlling a point-mass (right). (<bold>b</bold>) Centre-out reaching trajectories to 24 targets for the arm26 (left) and point-mass (right) model. (<bold>c</bold>) Distribution of PMDs for the arm26 (left) and point-mass (right) model. The PMDs were determined by regression of each gated recurrent unit’s (GRU) hidden activity averaged over time against reach angle (see Methods for details). (<bold>d</bold>) Normalized muscle activations across reaching angles and for the 300 ms following the ‘go’ cue for the arm26 model. (<bold>e</bold>) Normalized <italic>β</italic> coefficients of the regression models used for (<bold>c</bold>). The GRUs were ordered according to the angle of their maximum <italic>β</italic> value. Note that the ‘ridge’ of maximum <italic>β</italic> yields roughly a straight line for the point-mass model, while it yields a crooked line for the arm26, indicative of a representation bias. (<bold>f</bold>) Hidden activity over time and across reaching angles for a random sample of GRUs in the arm26 model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig6-v1.tif"/></fig><p>Following training, we first ensured that muscle activation patterns in the arm26 effector were like those reported in the original study (<xref ref-type="fig" rid="fig6">Figure 6d</xref>). Regarding network activity, we observed a great variety of activation patterns over movement direction (<xref ref-type="fig" rid="fig6">Figure 6f</xref>). Some GRUs showed a preference for timing (e.g., neuron A4, C5), while others showed a strong preference for reaching direction that was sustained over time (neuron C3, A2). Finally, most neurons showed a mixed preference for encoding time and reaching direction (neuron C8, A8). This heterogeneous set of responses matches empirical observations in non-human primate primary motor cortex recordings (<xref ref-type="bibr" rid="bib7">Churchland and Shenoy, 2007</xref>; <xref ref-type="bibr" rid="bib35">Michaels et al., 2016</xref>) and replicate similar visualizations from previously published work (<xref ref-type="bibr" rid="bib17">Fortunato et al., 2024</xref>; <xref ref-type="bibr" rid="bib30">Lillicrap and Scott, 2013</xref>; <xref ref-type="bibr" rid="bib47">Safaie et al., 2023</xref>).</p><p>We then assessed each GRU’s PMD using linear regression (see methods) and sorted them based on their PMD before plotting the tuning curve of each neuron. The resulting colormap (<xref ref-type="fig" rid="fig6">Figure 6e</xref>, left panel) yields a ‘ridge’ of maximal activity whose peak varies across reach angle, forming a crooked line, illustrating a representational bias. This crooked ridge line was not observed in an RNN trained to control for a point-mass effector instead using an identical training procedure and analysis (<xref ref-type="fig" rid="fig6">Figure 6e</xref>, right panel). We replicated this procedure with seven more RNNs for each model, resulting in a total of eight RNNs trained on an arm26 and eight RNNs trained on a point-mass. We determined each GRU’s PMD and averaged the resulting polar histogram across each RNN (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). The same bias was reproduced invariably for the RNNs controlling an arm26 effector (<xref ref-type="fig" rid="fig4">Figure 4d, e</xref>, <xref ref-type="fig" rid="fig6">6a</xref>), while it failed to arise for those controlling a point-mass (<xref ref-type="fig" rid="fig4">Figure 4a–c</xref>, <xref ref-type="fig" rid="fig6">6a</xref>). Therefore, these results mimic the observations made in the original study (<xref ref-type="bibr" rid="bib30">Lillicrap and Scott, 2013</xref>), specifically, that RNNs controlling an effector with no arm-like geometrical properties will not result in the biased PMD representation during reaching movements commonly observed in non-human primate electrophysiological studies (<xref ref-type="bibr" rid="bib50">Scott et al., 2001</xref>; <xref ref-type="bibr" rid="bib49">Scott and Kalaska, 1997</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Iterating quickly through the model development cycle</title><p>In the field of ML, an established best practice is to iterate quickly around a cycle of (1) formulating an idea, (2) implementing that idea in functionally efficient code, and (3) testing the idea through running the simulations. The results of the simulations can then be leveraged to adjust the idea, thus closing the loop, and enabling iterative refinement of a model. This [idea → code → test → idea] cycle is reminiscent of the [hypothesis → design task → test → hypothesis] cycle in empirical work, also known as the hypothetico-deductive method. An important practice in ML is to ensure that one iteration of that cycle is quick enough, because producing an efficient model may require many such iterations. Based on this framework, a way to view MotorNet is to improve iteration speed through this cycle. The modular architecture of MotorNet enables users to alter specific aspects of the model while keeping everything else identical. Therefore, user capacity to proceed through the ‘implementation’ step is enhanced.</p></sec><sec id="s3-2"><title>Advantages</title><sec id="s3-2-1"><title>Expandability</title><p>MotorNet naturally allows users to create and tune objects to fit individual requirements. This makes the toolbox easily expandable to add novel models that are not pre-built in the original distribution. This flexibility will likely vary depending on the goal (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Some extensions only require adjusting parameter values of existing object classes, such as editing the Arm26 <italic>Skeleton</italic> class to match the arm of a non-human primate. Other extensions will require subclassing, such as creating an <italic>Effector</italic>for an eyeball, which might require special geometric properties building on the point-mass <italic>Skeleton</italic> object (<xref ref-type="table" rid="table1">Table 1</xref>). Conversely, effectors that stray away from typical vertebrate effectors will likely prove more challenging, such as an octopus arm, because they do not rely on bones. Importantly, while all these extensions vary in the difficulty of their implementation, each has the capacity to fit and work harmoniously within the framework of the MotorNet architecture.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>MotorNet is expandable.</title><p>MotorNet allows for new features to be implemented through subclassing.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig7-v1.tif"/></fig></sec><sec id="s3-2-2"><title>Open source</title><p>Typically, when motor control researchers want to create canonical models, they must implement their own version of said model based on methodological descriptions of previously published scientific articles. However, because MotorNet is open source, individual contributions can easily be shared online for the benefit of others. For instance, if a researcher creates a <italic>Muscle</italic> class with a parametrizable pennation angle (<xref ref-type="bibr" rid="bib37">Millard et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>), future researchers and team will not have to re-create their own implementation of the same object anymore. This also allows more dynamical peer-checking, avoiding dissemination of errors and improving consistency of model implementations. In other words, MotorNet will be able to benefit from community-driven incremental work through open-source practices.</p></sec><sec id="s3-2-3"><title>Innovation scalability</title><p>For the past several years, ML has been standing out as one of the most dynamic research fields, achieving breakthroughs and successfully scaling innovative work towards solving everyday problems. It would be challenging for MotorNet to keep up with the pace of ML innovation to provide users with implementations of the latest architectures and algorithms. Rather, we rely on PyTorch to build policies. This ensures that any innovation in model design quickly finds its way to a viable MotorNet implementation, because PyTorch capabilities allow for fast adaptation aligned with progress in ML. Generally, MotorNet is built with the following logic in mind: anything PyTorch can build, MotorNet should be able to use as a policy.</p></sec><sec id="s3-2-4"><title><italic>gymnasium</italic>-compliant interfacing</title><p>The MotorNet <italic>Environment</italic> class is a subclass of <italic>gymnasium</italic>’s <italic>Env</italic> base class and abides by its associated API (<xref ref-type="bibr" rid="bib5">Chinnaiya et al., 2023</xref>). Consequently, MotorNet environments are by design compatible with any Python toolbox that works with <italic>gymnasium</italic>, which is a standard and popular interfacing toolbox to link reinforcement learning agents with environments. It is very well documented and widely used, which will ensure that users who wish to employ reinforcement learning to control MotorNet environments will be able to do so relatively effortlessly.</p></sec></sec><sec id="s3-3"><title>Limitations</title><sec id="s3-3-1"><title>Collision physics</title><p>Typical biomechanical software distributions implement some form of collision physics in their physics engine (<xref ref-type="bibr" rid="bib11">Delp et al., 2007</xref>; <xref ref-type="bibr" rid="bib53">Seth et al., 2018</xref>; <xref ref-type="bibr" rid="bib59">Todorov et al., 2012</xref>). This is not the case for MotorNet.</p></sec><sec id="s3-3-2"><title>Complex biomechanical features</title><p>Some biomechanical software distributions such as OpenSim propose a large array of joint types such as hinge joints or rotational joints, and complex muscle paths such as wrap points that trigger only when the muscle collides with them (<xref ref-type="bibr" rid="bib11">Delp et al., 2007</xref>; <xref ref-type="bibr" rid="bib52">Seth et al., 2010</xref>; <xref ref-type="bibr" rid="bib53">Seth et al., 2018</xref>). While these features increase the realism of a biomechanical model, MotorNet does not yet implement these types of features. In practice, this constrains what types of effectors MotorNet can realistically implement and adding some of these features is under consideration.</p></sec></sec><sec id="s3-4"><title>Future considerations</title><p>As an open-source, freely available Python toolbox, MotorNet is subject to change over time. Some of the limitations outlined above are considered as future routes for improvement. Additionally, we hope that individual contributions will help refine and extend the capabilities of the toolbox as well. In this section, we outline prospective improvements for implementation and release in the main distribution.</p><sec id="s3-4-1"><title>Spinal Compartment</title><p>It is becoming increasingly evident that spinal contribution plays a prominent role in motor control beyond the typically considered spinal reflex (<xref ref-type="bibr" rid="bib44">Reschechtko and Pruszynski, 2020</xref>; <xref ref-type="bibr" rid="bib60">Weiler et al., 2019</xref>). One may consider that supraspinal control interacts with spinal contribution to define a motor control policy (<xref ref-type="bibr" rid="bib34">Loeb, 2021</xref>). Within MotorNet, this suggests that a policy’s latent dynamics will be significantly impacted by the presence of a spinal compartment. Consequently, it may be worthwhile to implement one such spinal compartment to explore the consequences of such biological design, especially with regard to upstream computation (<xref ref-type="bibr" rid="bib8">Cisek, 2019</xref>). Importantly, this compartment may be designed as a module within the controller downstream from the ANN, that instantiates arbitrarily detailed computation according to empirical studies. This could include processing of top–down and/or bottom–up information as a movement unfolds (<xref ref-type="bibr" rid="bib44">Reschechtko and Pruszynski, 2020</xref>) with appropriate time delays in place. Ultimately, the scientific question at hand will dictate the complexity desiderata for the spinal compartment implementation. Interestingly, this two-module design within the controller leans towards the more general concept of modular architectures, which can be powerful for understanding multi-region interactions within the central nervous system (<xref ref-type="bibr" rid="bib36">Michaels et al., 2020</xref>).</p></sec><sec id="s3-4-2"><title>Modular policies</title><p>A deeply established idea in neuroscience is that distinct regions will perform different computations, and thus that a complex system may not be considered as a uniform, fully connected network (<xref ref-type="bibr" rid="bib1">Abbott and Svoboda, 2020</xref>; <xref ref-type="bibr" rid="bib26">Keeley et al., 2020</xref>; <xref ref-type="bibr" rid="bib41">Pesaran et al., 2021</xref>; <xref ref-type="bibr" rid="bib51">Semedo et al., 2020</xref>). This is also true for the motor control system, where using a modular network architecture with controlled communication between each module has been shown to have more explanatory power than a non-modular system (<xref ref-type="bibr" rid="bib36">Michaels et al., 2020</xref>). Therefore, a potential development for MotorNet is to include a model class with a modular architecture to study how cross-region networks work to enable neural control of the body.</p></sec><sec id="s3-4-3"><title>Muscle models</title><p>Most published work in motor control relies either on Hill-type muscle models (<xref ref-type="bibr" rid="bib2">Bhushan and Shadmehr, 1999</xref>; <xref ref-type="bibr" rid="bib27">Kistemaker et al., 2006</xref>; <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>; <xref ref-type="bibr" rid="bib40">Nijhof and Kouwenhoven, 2000</xref>) or direct torque actuators (<xref ref-type="bibr" rid="bib30">Lillicrap and Scott, 2013</xref>) similar to the ReLu muscle that MotorNet provides. However, despite its popularity, even the more-detailed Hill-type muscle remains a phenomenological model of real muscle behaviour, which can easily show its limits when trying to understand how the brain controls movement (<xref ref-type="bibr" rid="bib3">Blum et al., 2020</xref>). Alternative muscle model formalizations exist, such as the Distribution-Moment muscle model (<xref ref-type="bibr" rid="bib65">Zahalak, 1981</xref>), which may be worth implementing within MotorNet as well.</p></sec></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>General modelling design</title><p>This section describes modelling elements that were used for several models in this study. For all models, the timestep size was 0.01 s, and a proprioceptive delay of <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> ms and visual delay of <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> ms were used (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Effectors were actuated using numerical integration with the Euler method.</p><sec id="s4-1-1"><title>Arm26 model</title><p>The arm26 model used in this study is available online on the open-source toolbox code under the <italic>RigidTendonArm26 Effector</italic> class. It is briefly described below for convenience.</p><p>The skeleton of the arm26 models are according to the formalization proposed in <xref ref-type="bibr" rid="bib22">Gomi and Kawato, 1997</xref>, <xref ref-type="disp-formula" rid="equ1 equ1 equ1 equ1 equ1">equations 1, 3, 5–7</xref>. Parameter values are as in <xref ref-type="table" rid="table2">Table 2</xref>.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Skeleton parameters for the arm26 model, taken from <xref ref-type="bibr" rid="bib40">Nijhof and Kouwenhoven, 2000</xref>.</title><p>The skeleton was actuated by six rigid-tendon versions of Hill-type muscle actuators: a shoulder flexor, a shoulder extensor, an elbow flexor, an elbow extensor, a bi-articular flexor, and a bi-articular extensor. Their parameter values are defined in <xref ref-type="table" rid="table3">Table 3</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Upper arm</th><th align="left" valign="bottom">Forearm</th></tr></thead><tbody><tr><td align="left" valign="bottom">Mass (kg)</td><td align="char" char="." valign="bottom">1.82</td><td align="char" char="." valign="bottom">1.43</td></tr><tr><td align="left" valign="bottom">Centre of gravity (m)</td><td align="char" char="." valign="bottom">0.135</td><td align="char" char="." valign="bottom">0.165</td></tr><tr><td align="left" valign="bottom">Inertia (kg·m<sup>2</sup>)</td><td align="char" char="." valign="bottom">0.051</td><td align="char" char="." valign="bottom">0.057</td></tr><tr><td align="left" valign="bottom">Length (m)</td><td align="char" char="." valign="bottom">0.309</td><td align="char" char="." valign="bottom">0.333</td></tr></tbody></table></table-wrap><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Parameters for the Hill-type muscle actuators used in the arm26, taken from <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Muscle</th><th align="left" valign="top">Maximum isometric force (N)</th><th align="left" valign="top">Tendon length (m)</th><th align="left" valign="top">Optimal muscle length (m)</th></tr></thead><tbody><tr><td align="left" valign="top">Shoulder flexor</td><td align="char" char="." valign="top">838</td><td align="char" char="." valign="top">0.039</td><td align="char" char="." valign="top">0.134</td></tr><tr><td align="left" valign="top">Shoulder extensor</td><td align="char" char="." valign="top">1207</td><td align="char" char="." valign="top">0.066</td><td align="char" char="." valign="top">0.140</td></tr><tr><td align="left" valign="top">Elbow flexor</td><td align="char" char="." valign="top">1422</td><td align="char" char="." valign="top">0.0172</td><td align="char" char="." valign="top">0.092</td></tr><tr><td align="left" valign="top">Elbow extensor</td><td align="char" char="." valign="top">1549</td><td align="char" char="." valign="top">0.187</td><td align="char" char="." valign="top">0.093</td></tr><tr><td align="left" valign="top">Bi-articular flexor</td><td align="char" char="." valign="top">414</td><td align="char" char="." valign="top">0.204</td><td align="char" char="." valign="top">0.137</td></tr><tr><td align="left" valign="top">Bi-articular extensor</td><td align="char" char="." valign="top">603</td><td align="char" char="." valign="top">0.217</td><td align="char" char="." valign="top">0.127</td></tr></tbody></table></table-wrap><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Parameters used to compute moment arms in the arm26 models with moment arm approximation, taken from <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Muscle</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf46"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf47"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="left" valign="bottom">Shoulder flexor</td><td align="char" char="." valign="bottom">0.151</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">−0.03</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="bottom">Shoulder extensor</td><td align="char" char="." valign="bottom">0.2322</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">0.03</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="bottom">Elbow flexor</td><td align="char" char="." valign="bottom">0.2859</td><td align="char" char="." valign="bottom">−0.014</td><td align="char" char="." valign="bottom">0</td><td align="char" char="hyphen" valign="bottom">−4.0e−3</td></tr><tr><td align="left" valign="bottom">Elbow extensor</td><td align="char" char="." valign="bottom">0.2355</td><td align="char" char="." valign="bottom">0.025</td><td align="char" char="." valign="bottom">0</td><td align="char" char="hyphen" valign="bottom">−2.2e−3</td></tr><tr><td align="left" valign="bottom">Bi-articular flexor</td><td align="char" char="." valign="bottom">0.3329</td><td align="char" char="." valign="bottom">−0.016</td><td align="char" char="." valign="bottom">−0.3</td><td align="char" char="hyphen" valign="bottom">−5.7e−3</td></tr><tr><td align="left" valign="bottom">Bi-articular extensor</td><td align="char" char="." valign="bottom">0.2989</td><td align="char" char="." valign="bottom">0.03</td><td align="char" char="." valign="bottom">0.03</td><td align="char" char="hyphen" valign="bottom">−3.2e−3</td></tr></tbody></table></table-wrap><p>The full formalization of the Hill-type muscles can be found in <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>, <xref ref-type="disp-formula" rid="equ1 equ1 equ1 equ1 equ1 equ1 equ1">equations 1–7</xref>, and with the parameter values used in that study. When different parameters were provided for young and old subjects, the values for young subjects were used (<xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>, <xref ref-type="table" rid="table1">Table 1</xref>). While in custom-made <italic>Effector</italic> objects the moment arms of each muscle are computed based on geometric first principles (<xref ref-type="fig" rid="fig4">Figure 4d–f</xref>; <xref ref-type="bibr" rid="bib56">Sherman et al., 2013</xref>), in the <italic>RigidTendonArm26</italic> class the moment arms are approximated as described in <xref ref-type="bibr" rid="bib28">Kistemaker et al., 2010</xref>, <xref ref-type="disp-formula" rid="equ1 equ1 equ1">equations A10–A12</xref>, with parameters for this study defined in <xref ref-type="table" rid="table4">Table 4</xref>.</p></sec><sec id="s4-1-2"><title>Point-mass model</title><p>The point-mass model used in this study is available online on the open-source toolbox code under the <italic>ReluPointMass24 Effector</italic> class. It is briefly described below for convenience.</p><p>The point-mass had a mass of <inline-formula><mml:math id="inf49"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> kg. Its actuation followed an ordinary differential equation such that <inline-formula><mml:math id="inf50"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>¨</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf51"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>¨</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi></mml:math></inline-formula> the two-element cartesian acceleration vector at time <inline-formula><mml:math id="inf52"><mml:mi>t</mml:mi></mml:math></inline-formula> and the two-element force vector applied at time <inline-formula><mml:math id="inf53"><mml:mi>t</mml:mi></mml:math></inline-formula>, respectively.</p><p>The forces were produced by four linear muscle actuators, whose formalization is available online on the open-source toolbox code under the <italic>ReluMuscle</italic> muscle class. Each muscle’s force production <inline-formula><mml:math id="inf54"><mml:mi>f</mml:mi></mml:math></inline-formula> is a linear piecewise function of its activation <inline-formula><mml:math id="inf55"><mml:mi>a</mml:mi></mml:math></inline-formula>, scaled by its maximum isometric force <inline-formula><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:math></inline-formula> N:<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi>a</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>a</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mi>a</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The activation function was the same as for the Hill-type muscles used in the arm26 model, and can be found in <xref ref-type="bibr" rid="bib57">Thelen, 2003</xref>, <xref ref-type="disp-formula" rid="equ1 equ1">equations 1 and 2</xref>.</p><p>The four muscles were fixed to the point-mass in a ‘X’ configuration (<xref ref-type="fig" rid="fig4">Figures 4a</xref> and <xref ref-type="fig" rid="fig6">6a</xref>) with the first fixation point for the upper right, lower right, lower left, and upper left muscle being, respectively <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. The second fixation point of each muscle was on the point-mass, therefore moving in general coordinates alongside the point-mass (<xref ref-type="fig" rid="fig4">Figure 4a</xref>).</p></sec><sec id="s4-1-3"><title>Policy network architecture</title><p>All policy networks used in this study consisted of one layer of GRUs with a sigmoid recurrent activation function and a <inline-formula><mml:math id="inf58"><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi></mml:math></inline-formula> activation function. Kernel and recurrent weights were initialized using Glorot initialization (<xref ref-type="bibr" rid="bib20">Glorot and Bengio, 2010</xref>) and orthogonal initialization (<xref ref-type="bibr" rid="bib24">Hu et al., 2020</xref>), respectively. Biases were initialized at 0.</p><p>The GRU layer was fully connected to an output layer of perceptron nodes with a sigmoid activation function. The output layer contains one node per descending action signal, or equivalently one node per muscle. The output layer’s kernel weights were initialized using a random normal distribution with a standard deviation of 0.003, and its bias was initialized at a constant value of −5. Because the output activation function is a sigmoid, this initial bias forces the output of the policy to be close to 0 at the start of initialization, ensuring a stable initialization state.</p><p>For all networks used in this study, a two-element vector of <inline-formula><mml:math id="inf59"><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> cartesian coordinates for the start position and target position were provided as input, alongside a go-cue, resulting in a five-element input vector. The go-cue was a ‘step’ signal whose value changed from 1 to 0 when the movement should be initiated.</p></sec><sec id="s4-1-4"><title>General training design</title><p>During training, the models reached from a starting position drawn from a random uniform distribution across the full joint space to a target position drawn from a random uniform distribution as well. The occurrence time of the go-cue was drawn from a random uniform distribution across the full simulation duration. In 50% of simulations, no go-cue was provided (i.e., a catch trial) to ensure the network learnt to wait for the go-cue and avoided any anticipatory activity. The desired position <inline-formula><mml:math id="inf60"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> was set to be the start position until the go-cue was provided, at which point <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> was defined as the target position. Note that the go-cue was treated as a visual signal. Therefore, while the desired position <inline-formula><mml:math id="inf62"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> was updated immediately as the go-cue was provided (with no time delay), the network was informed of the go-cue occurrence via a change in the target position input and go-cue input only following the visual feedback delay <inline-formula><mml:math id="inf63"><mml:msub><mml:mrow><mml:mi>Δ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Depending on the models, additional training manipulations were also applied, as described in the sections below.</p></sec></sec><sec id="s4-2"><title>Centre-out reaches task against a curl field</title><sec id="s4-2-1"><title>Model</title><p>The effector type used to learn to reach against a curl field was an arm26 model as described in section ‘Arm26 model’. The policy was as described in section ‘Policy network architecture’, with the GRU layer containing <inline-formula><mml:math id="inf64"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:math></inline-formula> units.</p></sec><sec id="s4-2-2"><title>Training</title><p>The model was trained according to the procedure in section ‘General training design’ with the loss described in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, using a kernel regularization <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, coefficients <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and target radius <inline-formula><mml:math id="inf67"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math></inline-formula> m. The model was trained on 7680 batches with a batch size of 64, on simulations of 1 s.</p><p>The model was trained according to section ‘General training design’, except that the go-cue time was fixed at 100 ms from the start of the simulation. Following initial training, the model was then tested against a null field and external forces to produce the ‘naive’ behaviour shown in <xref ref-type="fig" rid="fig1">Figure 1b, c</xref>. Following testing, training was then resumed, but employing the curl-field, fixed starting position, and set of eight targets used in testing. 50% simulations were still catch trials, as in the initial training session. This second training session lasted 768 batches with a batch size of 64. Finally, following this second training session, the model was tested again, to produce the ‘adapted’ behaviour of <xref ref-type="fig" rid="fig1">Figure 1b</xref>.</p></sec><sec id="s4-2-3"><title>Testing</title><p>The model was tested in 1 s simulations against a null field, and against external forces applied at the arm’s endpoint that produced a counter-clockwise curl field:<disp-formula id="equ7"><label>(2)</label><mml:math id="m7"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>With <inline-formula><mml:math id="inf68"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the two-element cartesian velocity vector at time <inline-formula><mml:math id="inf69"><mml:mi>t</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf70"><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:math></inline-formula> a scalar defining the strength of the curl field. In the null field, we have <inline-formula><mml:math id="inf71"><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>.</p><p>The testing procedure consisted of eight centre-out reaches from a fixed starting position at a shoulder and elbow angle of 45° and 90°, respectively, to eight target positions 10 cm away and distributed in increments of 45° around the starting position (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). This set of simulations were repeated against a null field and against the curl field in <xref ref-type="disp-formula" rid="equ1">Equation 2</xref>, resulting in a total of 16 reaches. For all testing simulations, the go-cue time was fixed at 100 ms from the start of the simulation and no catch trials were employed.</p></sec></sec><sec id="s4-3"><title>Biomechanical properties of the effector</title><p>The point-mass model used was as described in section ‘Point-mass model’. The arm26 model used was as described in section ‘Arm26 model’, except that the moment arms were not approximated based on the parameters of <xref ref-type="table" rid="table4">Table 4</xref>, but computed based on the geometry of the muscle paths (<xref ref-type="bibr" rid="bib40">Nijhof and Kouwenhoven, 2000</xref>; <xref ref-type="bibr" rid="bib52">Seth et al., 2010</xref>; <xref ref-type="bibr" rid="bib56">Sherman et al., 2013</xref>). Accordingly, the muscle paths were manually declared by defining how many fixation points each muscle has, and on which bone and where on each bone each point fixes.</p><p>MotorNet handles declaration of these paths using a relative reference frame for each fixation point (<xref ref-type="bibr" rid="bib52">Seth et al., 2010</xref>). Specifically, a fixation point on a bone will have two coordinates. The first coordinate defines how far along the bone the point is, from the bone’s origin, for example, the shoulder for the upper arm (<xref ref-type="fig" rid="fig8">Figure 8</xref>). The second coordinate defines how far the point deviates from the bone orthogonally. If the fixation point is an anchor point, that is, it is not fixed on a bone but on the world space, then general coordinates  <inline-formula><mml:math id="inf72"><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> are used (colour-coded in green in <xref ref-type="fig" rid="fig8">Figure 8</xref>). These anchor points are important to ensure that the effector can be actuated with respect to the environment. The full set of coordinates defining the model’s muscle paths are indicated in <xref ref-type="table" rid="table5">Table 5</xref> and are derived from <xref ref-type="bibr" rid="bib40">Nijhof and Kouwenhoven, 2000</xref>.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Coordinate frames for declaring muscle paths in MotorNet.</title><p>(<bold>a</bold>) MotorNet handle muscle paths using coordinate frames relative to the bone on which a fixation point is. The world space is indexed as the fixation body ‘0’ and its coordinate frame is the general coordinate system. (<bold>b</bold>) Schematic illustration of the muscle paths used for the arm26 model with no moment arm approximation described in section ‘Biomechanical properties of the effector’ and <xref ref-type="table" rid="table5">Table 5</xref>, for a shoulder and elbow angle of 45° and 90°, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88591-fig8-v1.tif"/></fig><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Muscle paths for the arm26 model with no moment arm approximation.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Muscle</th><th align="left" valign="bottom">Fixation point</th><th align="left" valign="bottom">Fixation body</th><th align="left" valign="bottom">First coordinate <inline-formula><mml:math id="inf73"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula> (m)</th><th align="left" valign="bottom">Second coordinate <inline-formula><mml:math id="inf74"><mml:mi mathvariant="bold-italic">y</mml:mi></mml:math></inline-formula> (m)</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="2">SF</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0 (world)</td><td align="char" char="." valign="bottom">−0.15</td><td align="char" char="." valign="bottom">0.03</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">1 (upper arm)</td><td align="char" char="." valign="bottom">0.094</td><td align="char" char="." valign="bottom">0.017</td></tr><tr><td align="left" valign="bottom" rowspan="3">SE</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0 (world)</td><td align="char" char="." valign="bottom">−0.013</td><td align="char" char="." valign="bottom">−0.07</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">0 (world)</td><td align="char" char="." valign="bottom">0.05</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="char" char="." valign="bottom">1 (upper arm)</td><td align="char" char="." valign="bottom">0.153</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="left" valign="bottom" rowspan="2">EF</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1 (upper arm)</td><td align="char" char="." valign="bottom">0.23</td><td align="char" char="." valign="bottom">0.001</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">2 (forearm)</td><td align="char" char="." valign="bottom">0.231</td><td align="char" char="." valign="bottom">0.01</td></tr><tr><td align="left" valign="bottom" rowspan="3">EE</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1 (upper arm)</td><td align="char" char="." valign="bottom">0.03</td><td align="char" char="." valign="bottom">0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">1 (upper arm)</td><td align="char" char="." valign="bottom">0.138</td><td align="char" char="." valign="bottom">−0.019</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="char" char="." valign="bottom">2 (forearm)</td><td align="char" char="." valign="bottom">−0.04</td><td align="char" char="." valign="bottom">−0.017</td></tr><tr><td align="left" valign="bottom" rowspan="2">BF</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0 (world)</td><td align="char" char="." valign="bottom">−0.052</td><td align="char" char="." valign="bottom">0.033</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">2 (forearm)</td><td align="char" char="." valign="bottom">0.044</td><td align="char" char="." valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom" rowspan="2">BE</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0 (world)</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">−0.028</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">2 (forearm)</td><td align="char" char="." valign="bottom">−0.04</td><td align="char" char="." valign="bottom">−0.017</td></tr></tbody></table></table-wrap></sec><sec id="s4-4"><title>Training ANNs to produce naturalistic behaviour</title><sec id="s4-4-1"><title>Model</title><p>The two models used to produce <xref ref-type="fig" rid="fig5">Figure 5</xref> were arm26 models as described in section ‘Arm26 model’. For both models, the policy was as described in section ‘Policy network architecture’, with the GRU layer containing <inline-formula><mml:math id="inf75"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>110</mml:mn></mml:math></inline-formula> units. In addition, excitation and GRU hidden activity noise were added, with values <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively.</p></sec><sec id="s4-4-2"><title>Training</title><p>The models were trained with the loss described in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, using a kernel regularization <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, coefficients <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and target radius <inline-formula><mml:math id="inf79"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math></inline-formula> cm. The model was trained on 27,000 batches of size 1024, on simulations of 800 ms.</p><p>In one of the two models, which we refer to as the ‘perturbation-free’ model, the training procedure was as described in section ‘General training design’. In the second model, which we refer to as the ‘perturbation-trained’ model, a 100-ms endpoint mechanical perturbation was added to the training procedure. The perturbation occurred in 50% of trials, independently of whether the trial was a catch trial or not, and its orientation and time were randomly drawn as well. The magnitude of the perturbation was drawn from a uniform distribution ranging between 0 and 4 N. If the perturbation occurred during a catch trial, the distribution ranged between 0 and 8 N.</p></sec><sec id="s4-4-3"><title>Testing</title><p>Both the perturbation-trained and -free models were tested in 800 ms simulations in two distinct tasks, a centre-out reaching task and a postural task.</p><p>In the centre-out reaching task, eight targets were positioned in 45 degrees increments and 10 cm away from a starting position corresponding to a shoulder and elbow angle of 45° and 90°, respectively (<xref ref-type="fig" rid="fig5">Figure 5c, g</xref>). The visual go-cue was provided at 100 ms following the simulation start. 70 ms after the go-cue was ‘perceived’ (i.e., 70 ms plus the visual feedback delay <inline-formula><mml:math id="inf80"><mml:msub><mml:mrow><mml:mi>Δ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), a mechanical perturbation was applied at the arm’s endpoint and orthogonally to the reaching direction. This perturbation could be either within-distribution (±3 N) or out-of-distribution (±6 N) or null (no perturbation).</p><p>In the postural control task, no go-cue was provided, and the arm’s endpoint was pushed away from the start position by the mechanical perturbation at 170 ms plus visual delay <inline-formula><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi>Δ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> after the simulation started. We applied perturbations in either of the four cardinal directions (0°, 90°, 180°, and 270°). Again, the set of perturbations for testing outputs included within-distribution magnitudes (±6 N) and out-of-distribution magnitudes (±12 N).</p></sec></sec><sec id="s4-5"><title>Effector geometry defines preference distribution of firing rates: a replication study</title><sec id="s4-5-1"><title>Models</title><p>All arm26 and point-mass effectors used to produce <xref ref-type="fig" rid="fig5">Figure 5</xref> were as described in sections ‘Arm26 model’ and ‘Point-mass model’, respectively. For all models, the policy was as described in section ‘Policy network architecture’, with the GRU layer containing <inline-formula><mml:math id="inf82"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>90</mml:mn></mml:math></inline-formula> units.</p></sec><sec id="s4-5-2"><title>Training</title><p>All models were trained with the loss described in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, using a kernel regularization <inline-formula><mml:math id="inf83"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, coefficients <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and target radius <inline-formula><mml:math id="inf85"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>. The models were trained on 38,400 batches of size 64, on simulations of 800 ms. The training procedure was as described in section ‘General training design’.</p></sec><sec id="s4-5-3"><title>Testing</title><p>The testing procedure consisted of eight centre-out reaches in 800 ms simulations. Simulations started from a fixed position at a shoulder and elbow angle of 45° and 90° for the arm26 models, and at an <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> cartesian position for the point-mass models. Reaches were to 24 target positions 10 cm away and distributed in increments of 15° around the starting position (<xref ref-type="fig" rid="fig6">Figure 6b</xref>). For all testing simulations, the go-cue time was fixed at 100 ms into the simulation and no catch trials were employed.</p></sec><sec id="s4-5-4"><title>Analysis</title><p>To obtain the PMD of each GRU, we averaged each unit’s hidden activity in a 150-ms time window starting when the go-cue was input to the network (i.e., following visual feedback delay <inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>Δ</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) for each reaching direction independently, and regressed that average to a diagonal design matrix encoding the reach direction. The absolute value of the resulting regression coefficients was then normalized between 0 and 1, and neurons were sorted according to these normalized coefficients to produce <xref ref-type="fig" rid="fig6">Figure 6e</xref>.</p><p>As mentioned in the results section, we trained eight networks to control an arm26 and eight networks to control a point-mass. For each network, we took the count of GRUs whose normalized regression coefficient is maximal for each target considered and averaged that count across all eight networks to produce <xref ref-type="fig" rid="fig6">Figure 6c</xref>.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Validation, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Resources, Supervision, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Methodology, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-88591-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Code and sample simulations are provided in a GitHub repository here: <ext-link ext-link-type="uri" xlink:href="https://github.com/OlivierCodol/MotorNet">https://github.com/OlivierCodol/MotorNet</ext-link> copy archived at <xref ref-type="bibr" rid="bib9">Codol, 2024</xref>. Documentation for MotorNet is provided here: <ext-link ext-link-type="uri" xlink:href="https://www.motornet.org">https://www.motornet.org</ext-link>.</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the Natural Science and Engineering Council of Canada (RGPIN-2018-05458 to PLG and RGPIN-2022-04421 to JAP) and the Canadian Institutes of Health Research (PJT-156241 to PLG, PJT-175010 to JAP). JAM was supported by a Banting Postdoctoral Fellowship, a BrainsCAN Postdoctoral Fellowship, and a Vector Institute Postgraduate Affiliate Program Stipend.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>L</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain-wide interactions between neural circuits</article-title><source>Current Opinion in Neurobiology</source><volume>65</volume><fpage>iii</fpage><lpage>v</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.12.012</pub-id><pub-id pub-id-type="pmid">33357763</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhushan</surname><given-names>N</given-names></name><name><surname>Shadmehr</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Computational nature of human adaptive control during learning of reaching movements in force fields</article-title><source>Biological Cybernetics</source><volume>81</volume><fpage>39</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1007/s004220050543</pub-id><pub-id pub-id-type="pmid">10434390</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blum</surname><given-names>KP</given-names></name><name><surname>Campbell</surname><given-names>KS</given-names></name><name><surname>Horslen</surname><given-names>BC</given-names></name><name><surname>Nardelli</surname><given-names>P</given-names></name><name><surname>Housley</surname><given-names>SN</given-names></name><name><surname>Cope</surname><given-names>TC</given-names></name><name><surname>Ting</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Diverse and complex muscle spindle afferent firing properties emerge from multiscale muscle mechanics</article-title><source>eLife</source><volume>9</volume><elocation-id>e55177</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55177</pub-id><pub-id pub-id-type="pmid">33370235</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Morphometry of <italic>Macaca mulatta</italic> forelimb: I shoulder and elbow muscles and segment inertial parameters</article-title><source>Journal of Morphology</source><volume>245</volume><fpage>206</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1002/1097-4687(200009)245:33.0.CO;2-U</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chinnaiya</surname><given-names>K</given-names></name><name><surname>Burbridge</surname><given-names>S</given-names></name><name><surname>Jones</surname><given-names>A</given-names></name><name><surname>Kim</surname><given-names>DW</given-names></name><name><surname>Place</surname><given-names>E</given-names></name><name><surname>Manning</surname><given-names>E</given-names></name><name><surname>Groves</surname><given-names>I</given-names></name><name><surname>Sun</surname><given-names>C</given-names></name><name><surname>Towers</surname><given-names>M</given-names></name><name><surname>Blackshaw</surname><given-names>S</given-names></name><name><surname>Placzek</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A neuroepithelial wave of BMP signalling drives anteroposterior specification of the tuberal hypothalamus</article-title><source>eLife</source><volume>12</volume><elocation-id>e83133</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.83133</pub-id><pub-id pub-id-type="pmid">36718990</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>van Merrienboer</surname><given-names>B</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Bahdanau</surname><given-names>D</given-names></name><name><surname>Bougares</surname><given-names>F</given-names></name><name><surname>Schwenk</surname><given-names>H</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning Phrase Representations Using RNN Encoder–Decoder for Statistical Machine Translation</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.3115/v1/D14-1179</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Temporal complexity and heterogeneity of single-neuron activity in premotor and motor cortex</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>4235</fpage><lpage>4257</lpage><pub-id pub-id-type="doi">10.1152/jn.00095.2007</pub-id><pub-id pub-id-type="pmid">17376854</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Resynthesizing behavior through phylogenetic refinement</article-title><source>Attention, Perception &amp; Psychophysics</source><volume>81</volume><fpage>2265</fpage><lpage>2287</lpage><pub-id pub-id-type="doi">10.3758/s13414-019-01760-1</pub-id><pub-id pub-id-type="pmid">31161495</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Codol</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>MotorNet</data-title><version designator="swh:1:rev:a07603f889cba37c160df4b2ba31cf062b4ee1d4">swh:1:rev:a07603f889cba37c160df4b2ba31cf062b4ee1d4</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:affb2487e3656d98451879f3b773bd96743434f0;origin=https://github.com/OlivierCodol/MotorNet;visit=swh:1:snp:6fa87131a8aecfc76f3c47e0e4bffe568063ddd6;anchor=swh:1:rev:a07603f889cba37c160df4b2ba31cf062b4ee1d4">https://archive.softwareheritage.org/swh:1:dir:affb2487e3656d98451879f3b773bd96743434f0;origin=https://github.com/OlivierCodol/MotorNet;visit=swh:1:snp:6fa87131a8aecfc76f3c47e0e4bffe568063ddd6;anchor=swh:1:rev:a07603f889cba37c160df4b2ba31cf062b4ee1d4</ext-link></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conditt</surname><given-names>MA</given-names></name><name><surname>Gandolfo</surname><given-names>F</given-names></name><name><surname>Mussa-Ivaldi</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The motor system does not learn the dynamics of the arm by rote memorization of past experience</article-title><source>Journal of Neurophysiology</source><volume>78</volume><fpage>554</fpage><lpage>560</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.78.1.554</pub-id><pub-id pub-id-type="pmid">9242306</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delp</surname><given-names>SL</given-names></name><name><surname>Anderson</surname><given-names>FC</given-names></name><name><surname>Arnold</surname><given-names>AS</given-names></name><name><surname>Loan</surname><given-names>P</given-names></name><name><surname>Habib</surname><given-names>A</given-names></name><name><surname>John</surname><given-names>CT</given-names></name><name><surname>Guendelman</surname><given-names>E</given-names></name><name><surname>Thelen</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>OpenSim: open-source software to create and analyze dynamic simulations of movement</article-title><source>IEEE Transactions on Bio-Medical Engineering</source><volume>54</volume><fpage>1940</fpage><lpage>1950</lpage><pub-id pub-id-type="doi">10.1109/TBME.2007.901024</pub-id><pub-id pub-id-type="pmid">18018689</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimitriou</surname><given-names>M</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Franklin</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The temporal evolution of feedback gains rapidly update to task demands</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>10898</fpage><lpage>10909</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5669-12.2013</pub-id><pub-id pub-id-type="pmid">23804109</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Driscoll</surname><given-names>L</given-names></name><name><surname>Shenoy</surname><given-names>K</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Flexible multitask computation in recurrent networks utilizes shared dynamical motifs</article-title><source>Neuroscience</source><volume>01</volume><elocation-id>e3870</elocation-id><pub-id pub-id-type="doi">10.1101/2022.08.15.503870</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>AG</given-names></name><name><surname>Levin</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The origin and use of positional frames of reference in motor control</article-title><source>Behavioral and Brain Sciences</source><volume>18</volume><fpage>723</fpage><lpage>744</lpage><pub-id pub-id-type="doi">10.1017/S0140525X0004070X</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fetz</surname><given-names>EE</given-names></name></person-group><year iso-8601-date="1993">1993</year><chapter-title>Dynamic recurrent neural network models of sensorimotor behavior</chapter-title><person-group person-group-type="editor"><name><surname>Fetz</surname><given-names>EE</given-names></name></person-group><source>The Neurobiology of Neural Networks</source><publisher-loc>MIT Press</publisher-loc><publisher-name>Cambridge MA</publisher-name><fpage>165</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.7551/mitpress/4941.003.0010</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flanagan</surname><given-names>JR</given-names></name><name><surname>Ostry</surname><given-names>DJ</given-names></name><name><surname>Feldman</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Control of trajectory modifications in target-directed reaching</article-title><source>Journal of Motor Behavior</source><volume>25</volume><fpage>140</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1080/00222895.1993.9942045</pub-id><pub-id pub-id-type="pmid">12581985</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Fortunato</surname><given-names>C</given-names></name><name><surname>Bennasar-Vázquez</surname><given-names>J</given-names></name><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Chang</surname><given-names>JC</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Dudman</surname><given-names>JT</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Gallego</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Nonlinear Manifolds Underlie Neural Population Activity during Behaviour</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.07.18.549575</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fujimoto</surname><given-names>S</given-names></name><name><surname>Hoof</surname><given-names>H</given-names></name><name><surname>Meger</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Addressing Function Approximation Error in Actor-Critic Methods</article-title><conf-name>Proceedings of the 35th International Conference on Machine Learning</conf-name><fpage>1587</fpage><lpage>1596</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Ölveczky</surname><given-names>BP</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The neurobiology of deep reinforcement learning</article-title><source>Current Biology</source><volume>30</volume><fpage>R629</fpage><lpage>R632</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.04.021</pub-id><pub-id pub-id-type="pmid">32516607</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Glorot</surname><given-names>X</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Understanding the difficulty of training deep feedforward neural networks</article-title><conf-name>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</conf-name><fpage>249</fpage><lpage>256</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomi</surname><given-names>H</given-names></name><name><surname>Kawato</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Neural network control for a closed-loop system using feedback-error-learning</article-title><source>Neural Networks</source><volume>6</volume><fpage>933</fpage><lpage>946</lpage><pub-id pub-id-type="doi">10.1016/S0893-6080(09)80004-X</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomi</surname><given-names>H</given-names></name><name><surname>Kawato</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Human arm stiffness and equilibrium-point trajectory during multi-joint movement</article-title><source>Biological Cybernetics</source><volume>76</volume><fpage>163</fpage><lpage>171</lpage><pub-id pub-id-type="doi">10.1007/s004220050329</pub-id><pub-id pub-id-type="pmid">9151414</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gribble</surname><given-names>PL</given-names></name><name><surname>Ostry</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Compensation for loads during arm movements using equilibrium-point control</article-title><source>Experimental Brain Research</source><volume>135</volume><fpage>474</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1007/s002210000547</pub-id><pub-id pub-id-type="pmid">11156311</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>W</given-names></name><name><surname>Xiao</surname><given-names>L</given-names></name><name><surname>Pennington</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Provable benefit of orthogonal initialization in optimizing</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2001.05992</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>MI</given-names></name><name><surname>Rumelhart</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Forward models: supervised learning with a distal teacher</article-title><source>Cognitive Science</source><volume>16</volume><fpage>307</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog1603_1</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keeley</surname><given-names>SL</given-names></name><name><surname>Zoltowski</surname><given-names>DM</given-names></name><name><surname>Aoi</surname><given-names>MC</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Modeling statistical dependencies in multi-region spike train data</article-title><source>Current Opinion in Neurobiology</source><volume>65</volume><fpage>194</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.11.005</pub-id><pub-id pub-id-type="pmid">33334641</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kistemaker</surname><given-names>DA</given-names></name><name><surname>Van Soest</surname><given-names>AJ</given-names></name><name><surname>Bobbert</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Is equilibrium point control feasible for fast goal-directed single-joint movements?</article-title><source>Journal of Neurophysiology</source><volume>95</volume><fpage>2898</fpage><lpage>2912</lpage><pub-id pub-id-type="doi">10.1152/jn.00983.2005</pub-id><pub-id pub-id-type="pmid">16436480</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kistemaker</surname><given-names>DA</given-names></name><name><surname>Wong</surname><given-names>JD</given-names></name><name><surname>Gribble</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The central nervous system does not minimize energy cost in arm movements</article-title><source>Journal of Neurophysiology</source><volume>104</volume><fpage>2985</fpage><lpage>2994</lpage><pub-id pub-id-type="doi">10.1152/jn.00483.2010</pub-id><pub-id pub-id-type="pmid">20884757</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deep learning</article-title><source>Nature</source><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Scott</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Preference distributions of primary motor cortex neurons reflect control solutions optimized for limb biomechanics</article-title><source>Neuron</source><volume>77</volume><fpage>168</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.041</pub-id><pub-id pub-id-type="pmid">23312524</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Hunt</surname><given-names>JJ</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Heess</surname><given-names>N</given-names></name><name><surname>Erez</surname><given-names>T</given-names></name><name><surname>Tassa</surname><given-names>Y</given-names></name><name><surname>Silver</surname><given-names>D</given-names></name><name><surname>Wierstra</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Continuous control with deep reinforcement learning</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1509.02971</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Marris</surname><given-names>L</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Backpropagation and the brain</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>335</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0277-3</pub-id><pub-id pub-id-type="pmid">32303713</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lindsay</surname><given-names>GW</given-names></name></person-group><year iso-8601-date="2022">2022</year><source>Models of the mind: how physics, engineering and mathematics have shaped our understanding of the brain</source><publisher-name>MIT press</publisher-name><pub-id pub-id-type="doi">10.5040/9781472966445</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loeb</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning to use Muscles</article-title><source>Journal of Human Kinetics</source><volume>76</volume><fpage>9</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.2478/hukin-2020-0084</pub-id><pub-id pub-id-type="pmid">33603922</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaels</surname><given-names>JA</given-names></name><name><surname>Dann</surname><given-names>B</given-names></name><name><surname>Scherberger</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural population dynamics during reaching are better explained by a dynamical system than representational tuning</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005175</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005175</pub-id><pub-id pub-id-type="pmid">27814352</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michaels</surname><given-names>JA</given-names></name><name><surname>Schaffelhofer</surname><given-names>S</given-names></name><name><surname>Agudelo-Toro</surname><given-names>A</given-names></name><name><surname>Scherberger</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A goal-driven modular neural network predicts parietofrontal neural dynamics during grasping</article-title><source>PNAS</source><volume>117</volume><fpage>32124</fpage><lpage>32135</lpage><pub-id pub-id-type="doi">10.1073/pnas.2005087117</pub-id><pub-id pub-id-type="pmid">33257539</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millard</surname><given-names>M</given-names></name><name><surname>Uchida</surname><given-names>T</given-names></name><name><surname>Seth</surname><given-names>A</given-names></name><name><surname>Delp</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Flexing computational muscle: modeling and simulation of musculotendon dynamics</article-title><source>Journal of Biomechanical Engineering</source><volume>135</volume><elocation-id>021005</elocation-id><pub-id pub-id-type="doi">10.1115/1.4023390</pub-id><pub-id pub-id-type="pmid">23445050</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mnih</surname><given-names>V</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Silver</surname><given-names>D</given-names></name><name><surname>Rusu</surname><given-names>AA</given-names></name><name><surname>Veness</surname><given-names>J</given-names></name><name><surname>Bellemare</surname><given-names>MG</given-names></name><name><surname>Graves</surname><given-names>A</given-names></name><name><surname>Riedmiller</surname><given-names>M</given-names></name><name><surname>Fidjeland</surname><given-names>AK</given-names></name><name><surname>Ostrovski</surname><given-names>G</given-names></name><name><surname>Petersen</surname><given-names>S</given-names></name><name><surname>Beattie</surname><given-names>C</given-names></name><name><surname>Sadik</surname><given-names>A</given-names></name><name><surname>Antonoglou</surname><given-names>I</given-names></name><name><surname>King</surname><given-names>H</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Wierstra</surname><given-names>D</given-names></name><name><surname>Legg</surname><given-names>S</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Human-level control through deep reinforcement learning</article-title><source>Nature</source><volume>518</volume><fpage>529</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/nature14236</pub-id><pub-id pub-id-type="pmid">25719670</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>WM</given-names></name><name><surname>Delp</surname><given-names>SL</given-names></name><name><surname>Buchanan</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Variation of muscle moment arms with elbow and forearm position</article-title><source>Journal of Biomechanics</source><volume>28</volume><fpage>513</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1016/0021-9290(94)00114-j</pub-id><pub-id pub-id-type="pmid">7775488</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nijhof</surname><given-names>EJ</given-names></name><name><surname>Kouwenhoven</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2000">2000</year><chapter-title>Simulation of multijoint arm movements</chapter-title><person-group person-group-type="editor"><name><surname>Winters</surname><given-names>JM</given-names></name><name><surname>Crago</surname><given-names>PE</given-names></name></person-group><source>Biomechanics and neural control of posture and movement</source><publisher-name>Springer</publisher-name><fpage>363</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1007/978-1-4612-2104-3_29</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pesaran</surname><given-names>B</given-names></name><name><surname>Hagan</surname><given-names>M</given-names></name><name><surname>Qiao</surname><given-names>S</given-names></name><name><surname>Shewcraft</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Multiregional communication and the channel modulation hypothesis</article-title><source>Current Opinion in Neurobiology</source><volume>66</volume><fpage>250</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.11.016</pub-id><pub-id pub-id-type="pmid">33358629</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>King</surname><given-names>GL</given-names></name><name><surname>Boisse</surname><given-names>L</given-names></name><name><surname>Scott</surname><given-names>SH</given-names></name><name><surname>Flanagan</surname><given-names>JR</given-names></name><name><surname>Munoz</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus-locked responses on human arm muscles reveal a rapid neural pathway linking visual input to arm motor output</article-title><source>The European Journal of Neuroscience</source><volume>32</volume><fpage>1049</fpage><lpage>1057</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2010.07380.x</pub-id><pub-id pub-id-type="pmid">20726884</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Omrani</surname><given-names>M</given-names></name><name><surname>Scott</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Goal-dependent modulation of fast feedback responses in primary motor cortex</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>4608</fpage><lpage>4617</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4520-13.2014</pub-id><pub-id pub-id-type="pmid">24672006</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reschechtko</surname><given-names>S</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Stretch reflexes</article-title><source>Current Biology</source><volume>30</volume><fpage>R1025</fpage><lpage>R1030</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.07.092</pub-id><pub-id pub-id-type="pmid">32961152</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Beaudoin</surname><given-names>P</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Christensen</surname><given-names>A</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Costa</surname><given-names>RP</given-names></name><name><surname>de Berker</surname><given-names>A</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Gillon</surname><given-names>CJ</given-names></name><name><surname>Hafner</surname><given-names>D</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name><name><surname>Lindsay</surname><given-names>GW</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Pack</surname><given-names>CC</given-names></name><name><surname>Poirazi</surname><given-names>P</given-names></name><name><surname>Roelfsema</surname><given-names>P</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Scellier</surname><given-names>B</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Zylberberg</surname><given-names>J</given-names></name><name><surname>Therien</surname><given-names>D</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A deep learning framework for neuroscience</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1761</fpage><lpage>1770</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0520-2</pub-id><pub-id pub-id-type="pmid">31659335</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Williams</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Learning representations by back-propagating errors</article-title><source>Nature</source><volume>323</volume><fpage>533</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1038/323533a0</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safaie</surname><given-names>M</given-names></name><name><surname>Chang</surname><given-names>JC</given-names></name><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Dudman</surname><given-names>JT</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Gallego</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Preserved neural dynamics across animals performing similar behaviour</article-title><source>Nature</source><volume>623</volume><fpage>765</fpage><lpage>771</lpage><pub-id pub-id-type="doi">10.1038/s41586-023-06714-0</pub-id><pub-id pub-id-type="pmid">37938772</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Nelli</surname><given-names>S</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>If deep learning is the answer, what is the question?</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>55</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-00395-8</pub-id><pub-id pub-id-type="pmid">33199854</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>SH</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Reaching movements with similar hand paths but different arm orientations i. activity of individual cells in motor cortex</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>826</fpage><lpage>852</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.2.826</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>SH</given-names></name><name><surname>Gribble</surname><given-names>PL</given-names></name><name><surname>Graham</surname><given-names>KM</given-names></name><name><surname>Cabel</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dissociation between hand motion and population vectors from neural activity in motor cortex</article-title><source>Nature</source><volume>413</volume><fpage>161</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1038/35093102</pub-id><pub-id pub-id-type="pmid">11557980</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semedo</surname><given-names>JD</given-names></name><name><surname>Gokcen</surname><given-names>E</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Statistical methods for dissecting interactions between brain areas</article-title><source>Current Opinion in Neurobiology</source><volume>65</volume><fpage>59</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.09.009</pub-id><pub-id pub-id-type="pmid">33142111</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>A</given-names></name><name><surname>Sherman</surname><given-names>M</given-names></name><name><surname>Eastman</surname><given-names>P</given-names></name><name><surname>Delp</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Minimal formulation of joint motion for biomechanisms</article-title><source>Nonlinear Dynamics</source><volume>62</volume><fpage>291</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1007/s11071-010-9717-3</pub-id><pub-id pub-id-type="pmid">21170173</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>A</given-names></name><name><surname>Hicks</surname><given-names>JL</given-names></name><name><surname>Uchida</surname><given-names>TK</given-names></name><name><surname>Habib</surname><given-names>A</given-names></name><name><surname>Dembia</surname><given-names>CL</given-names></name><name><surname>Dunne</surname><given-names>JJ</given-names></name><name><surname>Ong</surname><given-names>CF</given-names></name><name><surname>DeMers</surname><given-names>MS</given-names></name><name><surname>Rajagopal</surname><given-names>A</given-names></name><name><surname>Millard</surname><given-names>M</given-names></name><name><surname>Hamner</surname><given-names>SR</given-names></name><name><surname>Arnold</surname><given-names>EM</given-names></name><name><surname>Yong</surname><given-names>JR</given-names></name><name><surname>Lakshmikanth</surname><given-names>SK</given-names></name><name><surname>Sherman</surname><given-names>MA</given-names></name><name><surname>Ku</surname><given-names>JP</given-names></name><name><surname>Delp</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>OpenSim: Simulating musculoskeletal dynamics and neuromuscular control to study human and animal movement</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006223</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006223</pub-id><pub-id pub-id-type="pmid">30048444</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>R</given-names></name><name><surname>Mussa-Ivaldi</surname><given-names>FA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Adaptive representation of dynamics during learning of a motor task</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>3208</fpage><lpage>3224</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-05-03208.1994</pub-id><pub-id pub-id-type="pmid">8182467</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadmehr</surname><given-names>R</given-names></name><name><surname>Krakauer</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A computational neuroanatomy for motor control</article-title><source>Experimental Brain Research</source><volume>185</volume><fpage>359</fpage><lpage>381</lpage><pub-id pub-id-type="doi">10.1007/s00221-008-1280-5</pub-id><pub-id pub-id-type="pmid">18251019</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>MA</given-names></name><name><surname>Seth</surname><given-names>A</given-names></name><name><surname>Delp</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>What is a moment arm? calculating muscle effectiveness in biomechanical models using generalized coordinates</article-title><conf-name>ASME 2013 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference</conf-name><volume>2013</volume><elocation-id>V07BT10A052</elocation-id><pub-id pub-id-type="doi">10.1115/DETC2013-13633</pub-id><pub-id pub-id-type="pmid">25905111</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thelen</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Adjustment of muscle mechanics model parameters to simulate dynamic contractions in older adults</article-title><source>Journal of Biomechanical Engineering</source><volume>125</volume><fpage>70</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1115/1.1531112</pub-id><pub-id pub-id-type="pmid">12661198</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Optimality principles in sensorimotor control</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>907</fpage><lpage>915</lpage><pub-id pub-id-type="doi">10.1038/nn1309</pub-id><pub-id pub-id-type="pmid">15332089</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name><name><surname>Erez</surname><given-names>T</given-names></name><name><surname>Tassa</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>MuJoCo: a physics engine for model-based control</article-title><conf-name>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012</conf-name><fpage>5026</fpage><lpage>5033</lpage><pub-id pub-id-type="doi">10.1109/IROS.2012.6386109</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiler</surname><given-names>J</given-names></name><name><surname>Gribble</surname><given-names>PL</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spinal stretch reflexes support efficient hand control</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>529</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0336-0</pub-id><pub-id pub-id-type="pmid">30742115</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity</article-title><source>Neural Computation</source><volume>29</volume><fpage>1229</fpage><lpage>1262</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00949</pub-id><pub-id pub-id-type="pmid">28333583</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wierzbicka</surname><given-names>MM</given-names></name><name><surname>Wiegner</surname><given-names>AW</given-names></name><name><surname>Shahani</surname><given-names>BT</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Role of agonist and antagonist muscles in fast arm movements in man</article-title><source>Experimental Brain Research</source><volume>63</volume><fpage>331</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1007/BF00236850</pub-id><pub-id pub-id-type="pmid">3758250</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Willett</surname><given-names>F</given-names></name><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Michaels</surname><given-names>JA</given-names></name><name><surname>Henderson</surname><given-names>JM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Feedback control dynamics explain motor cortical activity</article-title><conf-name>50th Annual Meeting of the Society for Neuroscience</conf-name></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Won</surname><given-names>J</given-names></name><name><surname>Hogan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Stability properties of human reaching movements</article-title><source>Experimental Brain Research</source><volume>107</volume><fpage>125</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1007/BF00228024</pub-id><pub-id pub-id-type="pmid">8751070</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zahalak</surname><given-names>GI</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>A distribution-moment approximation for kinetic theories of muscular contraction</article-title><source>Mathematical Biosciences</source><volume>55</volume><fpage>89</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/0025-5564(81)90014-6</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88591.4.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Imperial College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Useful</kwd></kwd-group></front-stub><body><p>This work will be of interest to the motor control community as well as neuroAI researchers interested in how bodies constrain neural circuit function. The authors present &quot;MotorNet&quot;, a <bold>useful</bold> software package to train artificial neural networks to control a biomechanical model of an effector. The manuscript provides <bold>solid</bold> evidence that MotorNet is easy to use and can reproduce past results in the field, both at the neural and behavioural levels. Validation is limited to planar arm-like plants or point-masses, so future work exploring three-dimensional movements and other types of plants would strengthen the impact of the tool.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88591.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Codol et al. present a toolbox that allows simulating biomechanically realistic effectors and training Artificial Neural Networks (ANNs) to control them. The paper provides a detailed explanation of how the toolbox is structured and several examples demonstrating its utility.</p><p>Main comments:</p><p>(1) The paper is well-written and easy to follow. The schematics facilitate understanding of the toolbox's functionality, and the examples give insight into the potential results users can achieve.</p><p>(2) The toolbox's latest version, developed in PyTorch, is expected to offer greater benefits to the community.</p><p>(3) The new API, being compatible with Gymnasium, broadens the toolbox's application scope, enabling the use of Reinforcement Learning for training the ANNs.</p><p>Impact:</p><p>MotorNet is designed to simplify the process of simulating complex experimental setups, enabling the rapid testing of hypotheses on how the brain generates specific movements. Implemented in PyTorch and compatible with widely-used machine learning toolboxes, including Gymnasium, it offers an end-to-end pipeline for training ANNs on simulated setups. This can greatly assist experimenters in determining the focus of their subsequent efforts.</p><p>Additional context:</p><p>The main outcome of the work, a toolbox, is supplemented by a GitHub repository and a documentation webpage. Both the repository and the webpage are well-organized and user-friendly. The webpage guides users through the toolbox installation process, as well as the construction of effectors and Artificial Neural Networks (ANNs).</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88591.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>MotorNet aims to provide a unified interface where the trained RNN controller exists within the same TensorFlow environment as the end effectors being controlled. This architecture provides a much simpler interface for the researcher to develop and iterate through computational hypotheses. In addition, the authors have built a set of biomechanically realistic end effectors (e.g., a 2 joint arm model with realistic muscles) within TensorFlow that are fully differentiable.</p><p>MotorNet will prove a highly useful starting point for researchers interested in exploring the challenges of controlling movement with realistic muscle and joint dynamics. The architecture features a conveniently modular design and the inclusion of simpler arm models provides an approachable learning curve. Other state-of-the-art simulation engines offer realistic models of muscles and multi-joint arms and afford more complex object manipulation and contact dynamics than MotorNet. However, MotorNet's approach allows for direct optimization of the controller network via gradient descent rather than reinforcement learning, which is a compromise currently required when other simulation engines (as these engines' code cannot be differentiated through).</p><p>The paper has been reorganized to provide clearer signposts to guide the reader. Importantly, the software has been rewritten atop PyTorch which is increasingly popular in ML and computational neuroscience research.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88591.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Codol</surname><given-names>Olivier</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Michaels</surname><given-names>Jonathan</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Kashefi</surname><given-names>Mehrdad</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Gribble</surname><given-names>Paul L</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>Codol et al. present a toolbox that allows simulating biomechanically realistic effectors and training Artificial Neural Networks (ANNs) to control them. The paper provides a detailed explanation of how the toolbox is structured and several examples that demonstrate its usefulness.</p><p>Main comments:</p><p>(1) The paper is well written and easy to follow. The schematics help in understanding how the toolbox works and the examples provide an idea of the results that the user can obtain.</p></disp-quote><p>We thank the reviewer for this comment.</p><disp-quote content-type="editor-comment"><p>(2) As I understand it, the main purpose of the paper should be to facilitate the usage of the toolbox. For this reason, I have missed a more explicit link to the actual code. As I see it, researchers will read this paper to figure out whether they can use MotorNet to simulate their experiments, and how they should proceed if they decide to use it. I'd say the paper provides an answer to the first question and assures that the toolbox is very easy to install and use. Maybe the authors could support this claim by adding &quot;snippets&quot; of code that show the key steps in building an actual example.</p></disp-quote><p>This is an important point, which we also considered when writing this paper. We instead decided to focus on the first approach, because it is easier to illustrate the scientific use of the toolbox using code or interactive (Jupyter) notebooks than a publication format. We find the “how to proceed” aspect of the toolbox can more easily and comprehensively be covered using online, interactive tutorials. Additionally, this allows us to update these tutorials as the toolbox evolves over different versions, while it is more difficult to update a scientific article. Consequently, we explicitly avoided code snippets on the article itself. However, we appreciate that the paper would gain in clarity if this was more explicitly stated early. We have modified the paper to include a pointer to where to find tutorials online. We added this at the last paragraph of the introduction section:</p><p>The interested reader may consult the full API documentation, including interactive tutorials on the toolbox website at <ext-link ext-link-type="uri" xlink:href="https://motornet.org">https://motornet.org</ext-link>.</p><disp-quote content-type="editor-comment"><p>(3) The results provided in Figures 1, 4, 5 and 6 are useful, because they provide examples of the type of things one can do with the toolbox. I have a few comments that might help improving them:</p><p>a. The examples in Figures 1 and 5 seem a bit redundant (same effector, similar task). Maybe the authors could show an example with a different effector or task? (see point 4).</p></disp-quote><p>The effectors from figures 1 and 5 are indeed very similar. However, the tasks in figure 1 and 5 present some important differences. The training procedure in figure 1 never includes any perturbations, while the one from figure 5 includes a wide range of perturbations of different magnitudes, timing and directions. The evaluation procedure of figure 1 includes center-out reaches with permanent viscous (proportional to velocity) external dynamics, while that of figure 5 are fixed, transient, square-shaped perturbation orthogonal to the reach direction. Finally, the networks in figure 1 undergo a second training procedure after evaluation while the network of figure 5 do not.</p><p>While we agree that some variation of effectors would be beneficial, we do show examples of a point-mass effector in figure 6. Overall, figure 5 shows a task that is quite different from that of figure 1 with a similar effector, while the opposite is true for figure 6. We have modified the text to clarify this for the reader, by adding the following.</p><p>End of 1st paragraph, section 2.4.</p><p>Therefore, the training protocol used for this task largely differed from section 2.1 in that the networks are exposed to a wide range of mechanical perturbations with varying characteristics.</p><disp-quote content-type="editor-comment"><p>1st paragraph of section 2.5</p><p>[…] this asymmetrical representation of PMDs during reaching movements did not occur when RNNs were trained to control an effector that lacked the geometrical properties of an arm such as illustrated in Figure 4c-e and section 2.1.</p><p>b. I missed a discussion on the relevance of the results shown in Figure 4. The moment arms are barely mentioned outside section 2.3. Are these results new? How can they help with motor control research?</p></disp-quote><p>We thank the reviewer for this comment. This relates to a point from reviewer 2 indicating that the purpose of each section was sometimes difficult to grasp as one reads. Section 2.3 explains the biomechanical properties that the toolbox implements to improve realism of the effector. They are not new results in the sense that other toolboxes implement these features (though not in differentiable formats) and these properties of biological muscles are empirically well-established. However, they are important to understand what the toolbox provides, and consequently what constraints networks must accommodate to learn efficient control policies. An example of this is the results in figure 6, where a simple effector versus a more biomechanically complex effector will yield different neural representations.</p><p>Regarding the manuscript itself, we agree that more clarity on the goal of every paragraph may improve the reader’s experience. Consequently, we ensured to specify such goals at the start of each section. Particularly, we clarify the purpose of section 2.3 by adding several sentences on this at the end of the first paragraph in that section. We also now clearly state the purpose of section 2.3 with the results of figure 6 and reference figure 4 in that section.</p><disp-quote content-type="editor-comment"><p>c. The results in Figure 6 are important, since one key asset of ANNs is that they provide access to the activity of the whole population of units that produces a given behavior. For this reason, I think it would be interesting to show the actual &quot;empirical observations&quot; that the results shown in Fig. 6 are replicating, hence allowing a direct comparison between the results obtained for biological and simulated neurons.</p></disp-quote><p>These empirical observations are available from previous electrophysiological and modelling work. Particularly, polar histograms across reaching directions like panel C are displayed in figures 2 and 3 of Scott, Gribble, Graham, Cabel (2001, Nature). Colormaps of modelled unit activity across time and reaching directions like panel F are also displayed in figure 2 of Lillicrap, Scott (2013, Neuron). Electrophysiological recordings of M1 neurons during a similar task in non-human primates can also be seen on “Preserved neural population dynamics across animals performing similar behaviour” figure 2 B (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2022.09.26.509498">https://doi.org/10.1101/2022.09.26.509498</ext-link>) and “Nonlinear manifolds underlie neural population activity during behaviour” figure 2 B as well (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2023.07.18.549575">https://doi.org/10.1101/2023.07.18.549575</ext-link>). Note that these two pre-prints use the same dataset.</p><p>We have added these citations to the text and made it explicit that they contain visualizations of similar modelling and empirical data for comparison:</p><p>This heterogeneous set of responses matches empirical observations in non-human primate primary motor cortex recordings (Churchland &amp; Shenoy, 2007; Michaels et al., 2016) and replicate similar visualizations from previously published work (Fortunato et al., 2023; Lillicrap &amp; Scott, 2013; Safaie et al., 2023).</p><disp-quote content-type="editor-comment"><p>(4) All examples in the paper use the arm26 plant as effector. Although the authors say that &quot;users can easily declare their own custom-made effector and task objects if desired by subclassing the base Plant and Task class, respectively&quot;, this does not sound straightforward. Table 1 does not really clarify how to do it. Maybe an example that shows the actual code (see point 2) that creates a new plant (e.g. the 3-joint arm in Figure 7) would be useful.</p></disp-quote><p>Subclassing is a Python process more than a MotorNet process, as python is an object-oriented language. Therefore, there are many Python tutorials on subclassing in the general sense that would be beneficial for that purpose. We have amended the main text to ensure that this is clearer to the reader.</p><p>Subclassing a MotorNet object, in a more specific sense, requires overwriting some methods from the base MotorNet classes (e.g., Effector or Environment classes, which correspond to the original Plant and Task object, respectively). Since we made the decision (mentioned above) to not include code in the main text, we added tutorials to the online documentation, which include dedicated tutorials for MotorNet class subclassing. For instance, this tutorial showcases how to subclass Environment classes:</p><p><ext-link ext-link-type="uri" xlink:href="https://colab.research.google.com/github/OlivierCodol/MotorNet/blob/master/examples/3-environments.ipynb">https://colab.research.google.com/github/OlivierCodol/MotorNet/blob/master/examples/3-environments.ipynb</ext-link></p><disp-quote content-type="editor-comment"><p>(5) One potential limitation of the toolbox is that it is based on Tensorflow, when the field of Computational Neuroscience seems to be, or at least that's my impression, transitioning to pyTorch. How easy would it be to translate MotorNet to pyTorch? Maybe the authors could comment on this in the discussion.</p></disp-quote><p>We have received a significant amount of feedback asking for a PyTorch implementation of the toolbox. Consequently, we decided to enact this, and the next version of the toolbox will be exclusively in PyTorch. We will maintain the Application Programming Interface (API) and tutorial documentation for the TensorFlow version of the toolbox on the online website. However, going forward we will focus exclusively on bug-fixing and expanding from the latest version of MotorNet, which will be in PyTorch. We now believe that the greater popularity of PyTorch in the academic community makes that choice more sustainable while helping a greater proportion of research projects.</p><p>These changes led to a significant alteration of the MotorNet structure, which are reflected by changes made throughout the manuscript, notably in Figure 3 and Table 1.</p><disp-quote content-type="editor-comment"><p>(6) Supervised learning (SL) is widely used in Systems Neuroscience, especially because it is faster than reinforcement learning (RL). Thus providing the possibility of training the ANNs with SL is an important asset of the toolbox. However, SL is not always ideal, especially when the optimal strategy is not known or when there are different alternative strategies and we want to know which is the one preferred by the subject. For instance, would it be possible to implement a setup in which the ANN has to choose between 2 different paths to reach a target? (e.g. Kaufman et al. 2015 eLife). In such a scenario, RL seems to be a more natural option Would it be easy to extend MotorNet so it allows training with RL? Maybe the authors could comment on this in the discussion.</p></disp-quote><p>The new implementation of MotorNet that relies on PyTorch is already standardized to use an API that is compatible with Gymnasium. Gymnasium is a standard and popular interfacing toolbox used to link RL agents to environments. It is very well-documented and widely used, which will ensure that users who wish to employ RL to control MotorNet environments will be able to do so relatively effortlessly. We have added this point to accurately reflect the updated implementation, so users are aware that it is now a feature of the toolbox (new section 3.2.4.).</p><disp-quote content-type="editor-comment"><p>Impact:</p><p>MotorNet aims at simplifying the process of simulating complex experimental setups to rapidly test hypotheses about how the brain produces a specific movement. By providing an end-to-end pipeline to train ANNs on the simulated setup, it can greatly help guide experimenters to decide where to focus their experimental efforts.</p><p>Additional context:</p><p>Being the main result a toolbox, the paper is complemented by a GitHub repository and a documentation webpage. Both the repository and the webpage are well organized and easy to navigate. The webpage walks the user through the installation of the toolbox and the building of the effectors and the ANNs.</p><p><bold>Reviewer #2 (Public Review):</bold></p><p>MotorNet aims to provide a unified interface where the trained RNN controller exists within the same TensorFlow environment as the end effectors being controlled. This architecture provides a much simpler interface for the researcher to develop and iterate through computational hypotheses. In addition, the authors have built a set of biomechanically realistic end effectors (e.g., an 2 joint arm model with realistic muscles) within TensorFlow that are fully differentiable.</p><p>MotorNet will prove a highly useful starting point for researchers interested in exploring the challenges of controlling movement with realistic muscle and joint dynamics. The architecture features a conveniently modular design and the inclusion of simpler arm models provides an approachable learning curve. Other state-of-the-art simulation engines offer realistic models of muscles and multi-joint arms and afford more complex object manipulation and contact dynamics than MotorNet. However, MotorNet's approach allows for direct optimization of the controller network via gradient descent rather than reinforcement learning, which is a compromise currently required when other simulation engines (as these engines' code cannot be differentiated through).</p><p>The paper could be reorganized to provide clearer signposts as to what role each section plays (e.g., that the explanation of the moment arms of different joint models serves to illustrate the complexity of realistic biomechanics, rather than a novel discovery/exposition of this manuscript). Also, if possible, it would be valuable if the authors could provide more insight into whether gradient descent finds qualitatively different solutions to RL or other non gradient-based methods. This would strengthen the argument that a fully differentiable plant is useful beyond improving training time / computational power required (although this is a sufficiently important rationale per se).</p></disp-quote><p>We thank the reviewer for these comments. We agree that more clarity on the section goals may improve the reader’s experience and ensured this is the case throughout the manuscript. Particularly, we added the following on the first paragraph of section 2.3, for which an explicit goal was most missing:</p><p>In this section we illustrate some of these biomechanical properties displayed by MotorNet effectors using specific examples. These properties are well-characterised in the biology and are often implemented in realistic biomechanical simulation software.</p><p>Regarding the potential difference in solutions obtained from reinforcement or supervised learning, this would represent a non-trivial amount of work to do so conclusively and so may not be within the scope of the current article. We do appreciate however that in some situations RL may be a more fitting approach to a given task design. In relation to this point we now specify in the discussion that the new API can accommodate interfacing with reinforcement learning toolboxes for those who may want to pursue this type of policy training approach when appropriate (new section 3.2.4.).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Artificial neural networks have developed into a new research tool across various disciplines of neuroscience. However, specifically for studying neural control of movement it was extremely difficult to train those models, as they require not only simulating the neural network, but also the body parts one is interested in studying. The authors provide a solution to this problem which is built upon one of the main software packages used for deep learning (Tensorflow). This allows them to make use of state-of-the-art tools for training neural networks.</p><p>They show that their toolbox is able to (re-)produce several commonly studied experiments e.g., planar reaching with and without loads. The toolbox is described in sufficient detail to get an overview of the functionality and the current state of what can be done with it. Although the authors state that only a few lines of code can reproduce such an experiment, they unfortunately don't provide any source code to reproduce their results (nor is it given in the respective repository).</p></disp-quote><p>The possibility of adding code snippets to the article is something we originally considered, and which aligns with comment two from reviewer one (see above). Hopefully this provides a good overview of the motivation behind our choice not to add code to the article.</p><disp-quote content-type="editor-comment"><p>The modularity of the presented toolbox makes it easy to exchange or modify single parts of an experiment e.g., the task or the neural network used as a controller. Together with the open-source nature of the toolbox, this will facilitate sharing and reproducibility across research labs.</p><p>I can see how this paper can enable a whole set of new studies on neural control of movement and accelerate the turnover time for new ideas or hypotheses, as stated in the first paragraph of the Discussion section. Having such a low effort to run computational experiments will be definitely beneficial for the field of neural control of movement.</p></disp-quote><p>We thank the reviewer for these comments.</p></body></sub-article></article>