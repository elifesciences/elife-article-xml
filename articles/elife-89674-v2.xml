<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">89674</article-id><article-id pub-id-type="doi">10.7554/eLife.89674</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89674.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A neuronal least-action principle for real-time learning in cortical circuits</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Senn</surname><given-names>Walter</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3622-0497</contrib-id><email>walter.senn@unibe.ch</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Dold</surname><given-names>Dominik</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7626-9960</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Kungl</surname><given-names>Akos F</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Ellenberger</surname><given-names>Benjamin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4787-0471</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Jordan</surname><given-names>Jakob</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Bengio</surname><given-names>Yoshua</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Sacramento</surname><given-names>João</given-names></name><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2632-0427</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02k7v4d05</institution-id><institution>Department of Physiology, University of Bern</institution></institution-wrap><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/038t36y30</institution-id><institution>Kirchhoff-Institute for Physics, Heidelberg University</institution></institution-wrap><addr-line><named-content content-type="city">Heidelberg</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03h3jqn23</institution-id><institution>European Space Research and Technology Centre, European Space Agency</institution></institution-wrap><addr-line><named-content content-type="city">Noordwijk</named-content></addr-line><country>Netherlands</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01q9sj412</institution-id><institution>Insel Data Science Center, University Hospital Bern</institution></institution-wrap><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Electrical Engineering, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0161xgx34</institution-id><institution>MILA, University of Montreal</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05a28rw58</institution-id><institution>Department of Computer Science, ETH Zurich</institution></institution-wrap><addr-line><named-content content-type="city">Zurich</named-content></addr-line><country>Switzerland</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013cjyk83</institution-id><institution>École Normale Supérieure - PSL</institution></institution-wrap><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052rphn09</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution></institution-wrap><country>Greece</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>20</day><month>12</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP89674</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-06-05"><day>05</day><month>06</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-06-06"><day>06</day><month>06</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.25.534198"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-08-22"><day>22</day><month>08</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89674.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-04-12"><day>12</day><month>04</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89674.2"/></event></pub-history><permissions><copyright-statement>© 2023, Senn, Dold et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Senn, Dold et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-89674-v2.pdf"/><abstract><p>One of the most fundamental laws of physics is the principle of least action. Motivated by its predictive power, we introduce a neuronal least-action principle for cortical processing of sensory streams to produce appropriate behavioral outputs in real time. The principle postulates that the voltage dynamics of cortical pyramidal neurons prospectively minimizes the local somato-dendritic mismatch error within individual neurons. For output neurons, the principle implies minimizing an instantaneous behavioral error. For deep network neurons, it implies the prospective firing to overcome integration delays and correct for possible output errors right in time. The neuron-specific errors are extracted in the apical dendrites of pyramidal neurons through a cortical microcircuit that tries to explain away the feedback from the periphery, and correct the trajectory on the fly. Any motor output is in a moving equilibrium with the sensory input and the motor feedback during the ongoing sensory-motor transform. Online synaptic plasticity reduces the somatodendritic mismatch error within each cortical neuron and performs gradient descent on the output cost at any moment in time. The neuronal least-action principle offers an axiomatic framework to derive local neuronal and synaptic laws for global real-time computation and learning in the brain.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>computational neuroscience</kwd><kwd>theoretical brain research</kwd><kwd>sensory-motor learning</kwd><kwd>synaptic plasticity</kwd><kwd>cortical dynamics</kwd><kwd>error-minimization</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Mouse</kwd><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011102</institution-id><institution>European Union 7th Framework Programme</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/720270</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id><institution>Swiss National Science Foundation</institution></institution-wrap></funding-source><award-id>CRSII5180316</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001711</institution-id><institution>Swiss National Science Foundation</institution></institution-wrap></funding-source><award-id>PZ00P3_186027</award-id><principal-award-recipient><name><surname>Sacramento</surname><given-names>João</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011102</institution-id><institution>European Union 7th Framework Programme</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/785907</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011102</institution-id><institution>European Union 7th Framework Programme</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/945539</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011102</institution-id><institution>European Union 7th Framework Programme</institution></institution-wrap></funding-source><award-id>604102</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100018693</institution-id><institution>Horizon Europe</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.3030/101147319</award-id><principal-award-recipient><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name><name><surname>Jordan</surname><given-names>Jakob</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A principle from which the neuronal dynamics and synaptic plasticity in arbitrary network architectures can be inferred, so that output errors are online minimized while simultaneously processing sensory input streams.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Wigner’s remark about the ‘unreasonable effectiveness’ of mathematics in allowing us to understand physical phenomena <xref ref-type="bibr" rid="bib104">Wigner, 1960</xref> is famously contrasted by Gelfand’s quip about its ‘unreasonable ineffectiveness’ in doing the same for biology (<xref ref-type="bibr" rid="bib13">Borovik, 2021</xref>). Considering the component of randomness that is inherent to evolution, this may not be all that surprising. However, while this argument holds just as well for the brain at the cellular level, ultimately brains are computing devices. At the level of computation, machine learning, and neuroscience have revealed near-optimal strategies for information processing and storage, and evolution is likely to have found similar principles through trial and error (<xref ref-type="bibr" rid="bib41">Hassabis et al., 2017</xref>). Thus, we have reason to hope for the existence of fundamental principles of cortical computation that are similar to those we have found in the physical sciences. Eventually, it is important for such approaches to relate these principles back to brain phenomenology and connect function to structure and dynamics.</p><p>In physics, a fundamental measure of ‘effort’ is the action of a system, which nature seeks to ‘minimize.’ Given an appropriate description of interactions between the system’s constituents, the least-action principle can be used to derive the equations of motion of any physical system (<xref ref-type="bibr" rid="bib29">Feynman et al., 2011</xref>; <xref ref-type="bibr" rid="bib19">Coopersmith, 2017</xref>). Here, we suggest that in biological information processing, a similar principle holds for prediction errors, which are of obvious relevance for cognition and behavior.</p><p>Based on such errors, we formulate a neuronal least-action (NLA) principle which can be used to derive neuronal dynamics and map them to observed dendritic morphologies and cortical microcircuits. Within this framework, local synaptic plasticity at basal and apical dendrites can be derived by stochastic gradient descent on errors. The errors that are minimized refer to the errors in output neurons that are typically thought to represent motor trajectories, planned and encoded in cortical motor areas and ultimately in the spinal cord and muscles. In the context of motor control, a phenomenological ‘minimal action principle’ has previously been proposed that guides the planning and execution of movements (<xref ref-type="bibr" rid="bib28">Feldman and Levin, 2009</xref>). Our neuronal least-action principle reformulates and formalizes the classical equilibrium point hypothesis (<xref ref-type="bibr" rid="bib54">Latash, 2010</xref>) in a dynamical setting, linking it to optimality principles in sensory-motor control (<xref ref-type="bibr" rid="bib94">Todorov, 2004</xref>).</p><p>Other attempts exist to link biological information processing and neural networks with the least-action principle, for instance by directly learning to reproduce a given trajectory (<xref ref-type="bibr" rid="bib5">Amirikian and Lukashin, 1992</xref>), by minimizing the physical action for the muscle force generation by motor unit recruitment (<xref ref-type="bibr" rid="bib81">Senn et al., 1995</xref>), minimizing cognitive prediction errors (<xref ref-type="bibr" rid="bib4">Alonso et al., 2012</xref>), minimizing output errors with a weight-change regularization (<xref ref-type="bibr" rid="bib11">Betti and Gori, 2016</xref>), minimizing psychomotor work (<xref ref-type="bibr" rid="bib31">Fox and Kotelba, 2018</xref>), minimizing data transport through a network (<xref ref-type="bibr" rid="bib46">Karkar et al., 2021</xref>), minimizing the discrimination information (<xref ref-type="bibr" rid="bib89">Summers, 2021</xref>), or minimizing the free energy (<xref ref-type="bibr" rid="bib34">Friston, 2010</xref>; <xref ref-type="bibr" rid="bib35">Friston et al., 2022</xref>). Apart from the latter, however, these attempts remain far from the biology that seems to resist a formalization with the tool of physics – at least, when applied too strictly.</p><p>The fundamental novelty of our NLA principle is the way it deals with time. In physics, bodies interact based on where they are now, irrespective of what happens in the future. Living systems, instead, interact based on what could happen in the near future, and react early to stay alive. This difference is also mirrored in the way our NLA principle looks for an error-minimizing trajectory of brain states. We postulate that the brain trades with near-future states and seeks for a path that minimizes errors of these future states at any moment in time. Looking ahead towards what will likely happen allows the network for correcting the internal trajectory of deep neurons early enough so that the delayed output moves along the desired path. The notion of looking into the future to gate a dynamical system is also central in optimal control theory (as expressed by the Bellman equation, see e.g. <xref ref-type="bibr" rid="bib92">Todorov, 2006</xref>). Yet, starting with a neuronal action is more principled as it includes the derivation of the dynamical system itself that will be optimally controlled.</p><p>The insight into the time structure of biological information processing allows us to express a simple form of a total ‘mismatch energy’ for our cortical neuronal networks, from which we derive the dynamic neuronal and synaptic laws.In short, the mismatch energy within a single pyramidal neuron is the squared prediction error between basal dendrites and the soma, together with the apical dendrites receiving a top-down feedback. The apical dendrites calculate a local prospective prediction error that looks ahead in time and overcomes neuronal integration delays (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). As a consequence, the output neurons are corrected on the fly by the prospective error processing, pushing them in real time closer to the desired path. In addition, the prospective errors are suited for gradient learning of the sensory synapses on the basal dendrites. This gradient learning is proven to reduce the error in the output neurons at any moment in time.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Somato-dendritic mismatch energies and the neuronal least-action (NLA) principle.</title><p>(<bold>a1</bold>) Sketch of a cross-cortical network of pyramidal neurons described by NLA. (<bold>a2</bold>) Correspondence between elements of NLA and biological observables such as membrane voltages and synaptic weights. (<bold>b1</bold>) The NLA principle postulates that small variations <inline-formula><alternatives><mml:math id="inf1"><mml:mrow><mml:mi>δ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1">\begin{document}$\delta \boldsymbol{\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> (dashed) of the trajectories <inline-formula><alternatives><mml:math id="inf2"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover></mml:math><tex-math id="inft2">\begin{document}$\boldsymbol{\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> (solid) leave the action invariant, <inline-formula><alternatives><mml:math id="inf3"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft3">\begin{document}$\delta A = 0$\end{document}</tex-math></alternatives></inline-formula>. It is formulated in the look-ahead coordinates <inline-formula><alternatives><mml:math id="inf4"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover></mml:math><tex-math id="inft4">\begin{document}$\boldsymbol{\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> (symbolized by the spyglass) in which `hills' of the Lagrangian (shaded gray zones) are foreseen by the prospective voltage so that the trajectory can turn by early enough to surround them. (<bold>b2</bold>) In the absence of output nudging (<inline-formula><alternatives><mml:math id="inf5"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft5">\begin{document}$\beta = 0$\end{document}</tex-math></alternatives></inline-formula>), the trajectory <inline-formula><alternatives><mml:math id="inf6"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft6">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula> is solely driven by the sensory input, and prediction errors and energies vanish (<inline-formula><alternatives><mml:math id="inf7"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft7">\begin{document}$L = 0$\end{document}</tex-math></alternatives></inline-formula>, outer blue trajectory at bottom). When nudging the output neurons towards a target voltage (<inline-formula><alternatives><mml:math id="inf8"><mml:mrow><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft8">\begin{document}$\beta \gt 0$\end{document}</tex-math></alternatives></inline-formula>), somatodendritic prediction errors appear, the energy increases (red dashed arrows symbolising the growing ‘volcano’) and the trajectory <inline-formula><alternatives><mml:math id="inf9"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft9">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula> moves out of the <inline-formula><alternatives><mml:math id="inf10"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft10">\begin{document}$L = 0$\end{document}</tex-math></alternatives></inline-formula> hyperplanes, riding on top of the `volcano' (red trajectory). Synaptic plasticity <inline-formula><alternatives><mml:math id="inf11"><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft11">\begin{document}$\dot W$\end{document}</tex-math></alternatives></inline-formula> reduces the somatodendritic mismatch along the trajectory by optimally ‘shoveling down the volcano’ (blue dashed arrows) while the trajectory settles in a new place on the <inline-formula><alternatives><mml:math id="inf12"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft12">\begin{document}$L = 0$\end{document}</tex-math></alternatives></inline-formula> hyperplane (inner blue trajectory at bottom).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89674-fig1-v2.tif"/></fig><p>The NLA principle builds on and integrates various ingredients from existing work and theories. Output neurons, be they motor neurons or decision-making neurons, are postulated to be ‘nudged’ towards the desired target time course by additional synaptic input to the soma or the proximal apical dendrite, as described by <xref ref-type="bibr" rid="bib97">Urbanczik and Senn, 2014</xref>. The cortical microcircuit with lateral ‘inhibition’ that seeks to cancel the top-down feedback in order to extract the apical error is inspired by <xref ref-type="bibr" rid="bib78">Sacramento et al., 2018</xref> and <xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>. The energy-based approach for describing error-backpropagation for weak nudging is borrowed from the Equilibrium Propagation algorithm (<xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>) that we generalize from a steady-state algorithm to real-time computation in cross-cortical microcircuits. Our theory covers both cases of weak and strong output nudging. For strong nudging, it likewise generalizes the least-control principle (<xref ref-type="bibr" rid="bib64">Meulemans et al., 2022</xref>) and the prospective configuration algorithm (<xref ref-type="bibr" rid="bib86">Song et al., 2024</xref>) from a steady-state to a dynamic real-time version, linking to optimal feedback control (<xref ref-type="bibr" rid="bib93">Todorov and Jordan, 2002</xref>). Finally, the apical activity of our pyramidal neurons can be seen in the tradition of predictive coding (<xref ref-type="bibr" rid="bib74">Rao and Ballard, 1999</xref>), where cortical feedback connections try to explain away lower-level activities. Yet, different from classical predictive coding, our prediction errors are integrated with the soma, and these errors are prospective in time. The errors extrapolate from current to future activities, so that their integration improves the network output in real time. The combination of an energy-based model with prospective coding in which neuronal integration delays are compensated on the fly enters also in <xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>.</p><p>The paper is organized as follows: we first define the prospective somatodendritic mismatch error, construct out of this the mismatch energy of a network, and ‘minimize’ this energy to obtain the error-corrected, prospective voltage dynamics of the network neurons. We then show that the prospective error coding leads to an instantaneous and joint processing of low-pass filtered input signals and backpropagated errors. Applied to motor control, the instantaneous processing is interpreted as a moving equilibrium hypothesis according to which sensory inputs, network state, motor commands, and muscle feedback are in a self-consistent equilibrium at any point of the movement. We then derive a local learning rule that globally minimizes the somato-dendritic mismatch errors across the network, and show how this learning can be implemented through error-extracting cortical microcircuits and dendritic predictive plasticity.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Somato-dendritic mismatch errors and the Lagrangian of cortical circuits</title><p>We consider a network of neurons – identified as pyramidal cells – with firing rates <inline-formula><alternatives><mml:math id="inf13"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft13">\begin{document}$r_{i}(t)$\end{document}</tex-math></alternatives></inline-formula> in continuous time <inline-formula><alternatives><mml:math id="inf14"><mml:mi>t</mml:mi></mml:math><tex-math id="inft14">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>. The somatic voltage <inline-formula><alternatives><mml:math id="inf15"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft15">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula> of pyramidal neuron <inline-formula><alternatives><mml:math id="inf16"><mml:mi>i</mml:mi></mml:math><tex-math id="inft16">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> is driven by the close-by basal input current, <inline-formula><alternatives><mml:math id="inf17"><mml:mrow><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft17">\begin{document}${\textstyle\sum}_{j}{W_{ij}}r_{j}$\end{document}</tex-math></alternatives></inline-formula>, with presynaptic rates <inline-formula><alternatives><mml:math id="inf18"><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="inft18">\begin{document}$r_{j}$\end{document}</tex-math></alternatives></inline-formula> and synaptic weights <inline-formula><alternatives><mml:math id="inf19"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft19">\begin{document}${W_{ij}}$\end{document}</tex-math></alternatives></inline-formula>, and an additional distal apical input <inline-formula><alternatives><mml:math id="inf20"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft20">\begin{document}$e_{i}$\end{document}</tex-math></alternatives></inline-formula> that will be learned to represent a prospective prediction error at any moment in time (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). While in classical rate-based neuron models the firing rate <inline-formula><alternatives><mml:math id="inf21"><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft21">\begin{document}$r_{i}$\end{document}</tex-math></alternatives></inline-formula> of a neuron is a function of the somatic voltage, <inline-formula><alternatives><mml:math id="inf22"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft22">\begin{document}$\rho(u_{i})$\end{document}</tex-math></alternatives></inline-formula>, the NLA principle implies that the effective firing rate of a cortical neuron is prospective. More concretely, the formalism derives a firing rate that linearly extrapolates from <inline-formula><alternatives><mml:math id="inf23"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft23">\begin{document}$\rho(u_{i})$\end{document}</tex-math></alternatives></inline-formula> into the future with the temporal derivative, <inline-formula><alternatives><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft24">\begin{document}$r_{i}= \rho(u_{i}) + \tau \dot\rho(u_{i})$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf25"><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft25">\begin{document}$\dot\rho(u_{i})$\end{document}</tex-math></alternatives></inline-formula> represents the temporal derivative of <inline-formula><alternatives><mml:math id="inf26"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft26">\begin{document}$\rho(u_{i}(t))$\end{document}</tex-math></alternatives></inline-formula>. There is experimental evidence for such prospective coding in cortical pyramidal neurons where the instantaneous rate <inline-formula><alternatives><mml:math id="inf27"><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft27">\begin{document}$r_{i}$\end{document}</tex-math></alternatives></inline-formula> is in fact not only a function of the underlying voltage, but also a function of how quickly that voltage increases (see <xref ref-type="fig" rid="fig2">Figure 2a</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Prospective coding in cortical pyramidal neurons enables instantaneous voltage-to-voltage transfer.</title><p>(<bold>a1</bold>) The instantaneous spike rate of cortical pyramidal neurons (top) in response to sinusoidally modulated noisy input current (bottom) is phase-advanced with respect to the input adapted from <xref ref-type="bibr" rid="bib50">Köndgen et al., 2008</xref>. (<bold>a2</bold>) Similiarly, in neuronal least-action (NLA), the instantaneous firing rate of a model neuron (<inline-formula><alternatives><mml:math id="inf28"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft28">\begin{document}$r = \rho(u) + \tau \dot \rho (u)$\end{document}</tex-math></alternatives></inline-formula>, black) is phase-advanced with respect to the underlying voltage (<inline-formula><alternatives><mml:math id="inf29"><mml:mi>u</mml:mi></mml:math><tex-math id="inft29">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>, red, postulating that the low-pass filtered rate is a function of the voltage, <inline-formula><alternatives><mml:math id="inf30"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft30">\begin{document}$\bar r = \rho(u)$\end{document}</tex-math></alternatives></inline-formula>). (<bold>b</bold>) Dendritic input in the apical tree (here called <inline-formula><alternatives><mml:math id="inf31"><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft31">\begin{document}$\bar e$\end{document}</tex-math></alternatives></inline-formula>) is instantaneously causing a somatic voltage modulation (<inline-formula><alternatives><mml:math id="inf32"><mml:mi>u</mml:mi></mml:math><tex-math id="inft32">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>, modeling data from <xref ref-type="bibr" rid="bib96">Ulrich, 2002</xref>). The low-pass filtering with <inline-formula><alternatives><mml:math id="inf33"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft33">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> along the dendritic shaft is compensated by a lookahead mechanism in the dendrite (<inline-formula><alternatives><mml:math id="inf34"><mml:mrow><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft34">\begin{document}$e = \bar e + \tau \dot{\bar e}$\end{document}</tex-math></alternatives></inline-formula>). In (<xref ref-type="bibr" rid="bib96">Ulrich, 2002</xref>) a phase advance is observed even with respect to the dendritic input current, not only the dendritic voltage, although only for slow modulations (as here). (<bold>c</bold>) While the voltage of the first neuron (<inline-formula><alternatives><mml:math id="inf35"><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="inft35">\begin{document}$u_{1}$\end{document}</tex-math></alternatives></inline-formula>) integrates the input rates <inline-formula><alternatives><mml:math id="inf36"><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft36">\begin{document}$r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> from the past (bottom black upward arrows), the output rate <inline-formula><alternatives><mml:math id="inf37"><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="inft37">\begin{document}$r_{1}$\end{document}</tex-math></alternatives></inline-formula> of that first neuron looks ahead in time, <inline-formula><alternatives><mml:math id="inf38"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft38">\begin{document}$r_{1}= \rho(u_{1}) + \tau \dot \rho (u_{1})$\end{document}</tex-math></alternatives></inline-formula> (red dashed arrows pointing into the future). The voltage of the second neuron (<inline-formula><alternatives><mml:math id="inf39"><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><tex-math id="inft39">\begin{document}$u_{2}$\end{document}</tex-math></alternatives></inline-formula>) integrates the prospective rates <inline-formula><alternatives><mml:math id="inf40"><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="inft40">\begin{document}$r_{1}$\end{document}</tex-math></alternatives></inline-formula> (top black upwards arrows). By doing so, it inverts the lookahead operation, resulting in an instantaneous transfer from <inline-formula><alternatives><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft41">\begin{document}$u_{1}(t)$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft42">\begin{document}$u_{2}(t)$\end{document}</tex-math></alternatives></inline-formula> (blue arrow and circles).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89674-fig2-v2.tif"/></fig><p>The second central notion of the theory is the prospective error <inline-formula><alternatives><mml:math id="inf43"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft43">\begin{document}$e_{i}$\end{document}</tex-math></alternatives></inline-formula>, that we interpret as prospective somato-dendritic mismatch error in the individual network neurons, <inline-formula><alternatives><mml:math id="inf44"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft44">\begin{document}$e_{i}= (u_{i}+ \tau \dot u_{i}) -{\textstyle\sum}_{j}{W_{ij}}r_{j}$\end{document}</tex-math></alternatives></inline-formula> . It is defined as a mismatch between the prospective voltage, <inline-formula><alternatives><mml:math id="inf45"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft45">\begin{document}$u_{i}+ \tau \dot u_{i}$\end{document}</tex-math></alternatives></inline-formula>, and the weighted prospective input rates, <inline-formula><alternatives><mml:math id="inf46"><mml:mrow><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft46">\begin{document}${\textstyle\sum}_{j}{W_{ij}}r_{j}$\end{document}</tex-math></alternatives></inline-formula>. In the same way, as the firing rates <inline-formula><alternatives><mml:math id="inf47"><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="inft47">\begin{document}$r_{j}$\end{document}</tex-math></alternatives></inline-formula> linearly extrapolate into the future given the current-voltages <inline-formula><alternatives><mml:math id="inf48"><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="inft48">\begin{document}$u_{j}$\end{document}</tex-math></alternatives></inline-formula> of the presynaptic neurons <inline-formula><alternatives><mml:math id="inf49"><mml:mi>j</mml:mi></mml:math><tex-math id="inft49">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>, the postsynaptic error is based on the linear extrapolation of its current voltage <inline-formula><alternatives><mml:math id="inf50"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft50">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula> using its temporal derivative, <inline-formula><alternatives><mml:math id="inf51"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft51">\begin{document}$u_{i}+ \tau \dot u_{i}$\end{document}</tex-math></alternatives></inline-formula> . If the prospective error <inline-formula><alternatives><mml:math id="inf52"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft52">\begin{document}$e_{i}$\end{document}</tex-math></alternatives></inline-formula> is low-pass filtered with time constant <inline-formula><alternatives><mml:math id="inf53"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft53">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula>, it takes the form <inline-formula><alternatives><mml:math id="inf54"><mml:mrow><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft54">\begin{document}${\bar{e}}_{i}= u_{i}-{\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf55"><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="inft55">\begin{document}${\bar{r}}_{j}$\end{document}</tex-math></alternatives></inline-formula> is the corresponding low-pass filtered firing rate of the presynaptic neuron <inline-formula><alternatives><mml:math id="inf56"><mml:mi>j</mml:mi></mml:math><tex-math id="inft56">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> (that becomes a function of the presynaptic voltage, <inline-formula><alternatives><mml:math id="inf57"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft57">\begin{document}$\bar r_{j}= \rho(u_{j})$\end{document}</tex-math></alternatives></inline-formula> , see Methods, Sect. Euler-Lagrange equations as inverse low-pass filters). We refer to <inline-formula><alternatives><mml:math id="inf58"><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft58">\begin{document}${\bar{e}}_{i}$\end{document}</tex-math></alternatives></inline-formula> as a somato-dendritic mismatch error of neuron that, as compared to <inline-formula><alternatives><mml:math id="inf59"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft59">\begin{document}$e_{i}$\end{document}</tex-math></alternatives></inline-formula>, is non-prospective and instantaneous.</p><p>We next interpret the mismatch error <inline-formula><alternatives><mml:math id="inf60"><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft60">\begin{document}${\bar{e}}_{i}$\end{document}</tex-math></alternatives></inline-formula> in terms of the morphology and biophysics of pyramidal neurons with basal and apical dendrites. While the error <inline-formula><alternatives><mml:math id="inf61"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft61">\begin{document}$e_{i}$\end{document}</tex-math></alternatives></inline-formula> is formed in the apical dendrite, this error is low-pass filtered and added to the somatic voltage <inline-formula><alternatives><mml:math id="inf62"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft62">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula>, that is also driven by the low-pass filtered basal input <inline-formula><alternatives><mml:math id="inf63"><mml:mrow><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft63">\begin{document}${\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}$\end{document}</tex-math></alternatives></inline-formula>, so that  <inline-formula><alternatives><mml:math id="inf64"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft64">\begin{document}$u_{i}={\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}+{\bar{e}}_{i}$\end{document}</tex-math></alternatives></inline-formula>. From the perspective of the basal dendrites, the low-pass filtered apical error <inline-formula><alternatives><mml:math id="inf65"><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft65">\begin{document}${\bar{e}}_{i}$\end{document}</tex-math></alternatives></inline-formula> can be calculated as the difference between the somatic voltage and the own local low-pass filtered input, <inline-formula><alternatives><mml:math id="inf66"><mml:mrow><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft66">\begin{document}${\bar{e}}_{i}= u_{i}-{\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}$\end{document}</tex-math></alternatives></inline-formula>. The somatic voltage <inline-formula><alternatives><mml:math id="inf67"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft67">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula> is assumed to be sampled in the basal dendrite by the backpropagating acting potentials (<xref ref-type="bibr" rid="bib97">Urbanczik and Senn, 2014</xref>; <xref ref-type="bibr" rid="bib87">Spicher et al., 2017</xref>). The apical error now appears as a ‘somato-basal’ mismatch error, that both are summarized as a somato-dendritic mismatch error. It tells the difference between ‘what a neuron does,’ which is based on the somatic voltage <inline-formula><alternatives><mml:math id="inf68"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft68">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula>, and ‘what the basal inputs think it should do,’ which is based on its own input <inline-formula><alternatives><mml:math id="inf69"><mml:mrow><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft69">\begin{document}${\textstyle\sum}{W_{ij}}{\bar{r}}_{j}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1a2</xref>). The two quantities may deviate because neuron <inline-formula><alternatives><mml:math id="inf70"><mml:mi>i</mml:mi></mml:math><tex-math id="inft70">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> get additional ‘unpredicted’ apical inputs from higher-area neurons that integrate with the somatic voltage <inline-formula><alternatives><mml:math id="inf71"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft71">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula>. What cannot be predicted in <inline-formula><alternatives><mml:math id="inf72"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft72">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula> by the sensory-driven basal input remains as somato-basal (somato-dendritic) mismatch error <inline-formula><alternatives><mml:math id="inf73"><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft73">\begin{document}${\bar{e}}_{i}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Associated with this mismatch error is the somatodendritic mismatch energy defined for each network neuron <inline-formula><alternatives><mml:math id="inf74"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow></mml:math><tex-math id="inft74">\begin{document}$i\in{\mathcal{N}}$\end{document}</tex-math></alternatives></inline-formula> as the squared mismatch error,<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mo>∑</mml:mo></mml:mstyle></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  E^{M}_{i}= \tfrac{1}{2}{ {\bar{e}}_i }^{\,2}= \tfrac{1}{2}\left(u_{i}-{\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}\right)^{2}\; .$$\end{document}</tex-math></alternatives></disp-formula></p><p>On a subset of output neurons of the whole network, <inline-formula><alternatives><mml:math id="inf75"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi><mml:mo>⊆</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow></mml:math><tex-math id="inft75">\begin{document}${\mathcal{O}}\subseteq{\mathcal{N}}$\end{document}</tex-math></alternatives></inline-formula>, a cost is defined as a function of the somatic voltage and some instructive reference signal such as targets or a reward. When a target trajectory <inline-formula><alternatives><mml:math id="inf76"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft76">\begin{document}$u^{*}_{o}(t)$\end{document}</tex-math></alternatives></inline-formula> is available, the cost is defined at each time point as a squared target error,<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle C_{o}= \tfrac{1}{2}({\bar{e}}_{o}^{*})^{2}= \tfrac{1}{2}\left(u_{o}^{*}- u_{o}\right)^{2}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Much more general mismatch energies and cost functions are conceivable, for instance, errors of the form <inline-formula><alternatives><mml:math id="inf77"><mml:mrow><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft77">\begin{document}${\bar{e}}_{i}= u_{i}- f_{i}(\boldsymbol u,t)$\end{document}</tex-math></alternatives></inline-formula> for general functions <inline-formula><alternatives><mml:math id="inf78"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft78">\begin{document}$f_{i}$\end{document}</tex-math></alternatives></inline-formula> of the voltage vector <inline-formula><alternatives><mml:math id="inf79"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft79">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> and of time, encompassing conductance-based neurons, but also further dynamic variables can be included such as threshold adaptation (see Appendix 6). The cost represents a performance measure for the entire network that produces the output voltages <inline-formula><alternatives><mml:math id="inf80"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft80">\begin{document}$u_{o}(t)$\end{document}</tex-math></alternatives></inline-formula> in response to some input rates <inline-formula><alternatives><mml:math id="inf81"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft81">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>. The cost directly relates to behavioral or cognitive measures such as the ability of an animal or human to perform a particular task in real time. The target could be provided by explicit external supervision, for example, target movements in time encoded by <inline-formula><alternatives><mml:math id="inf82"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft82">\begin{document}$u_{o}^{*}(t)$\end{document}</tex-math></alternatives></inline-formula>, it could represent an expected reward signal, or it could arise via self-supervision from other internal prediction errors.</p><p>We define the Lagrangian (or ‘total energy’) of the network as a sum across all mismatch energies and costs, weighted by the nudging strength <inline-formula><alternatives><mml:math id="inf83"><mml:mi>β</mml:mi></mml:math><tex-math id="inft83">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> of the output neurons,<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">O</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mo>∑</mml:mo></mml:mstyle></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">O</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  L = \sum_{i\in{\mathcal{N}}}E^{M}_{i}+ \beta\sum_{o\in{\mathcal{O}}}C_{o}= \frac{1}{2}\sum_{i\in{\mathcal{N}}}\left(u_{i}-{\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}\right)^{2}+ \frac{\beta}{2}\sum_{o\in{\mathcal{O}}}\left (u_{o}^{*}- u_{o}\right)^{2}\,.$$\end{document}</tex-math></alternatives></disp-formula></p><p>The low-pass filtered presynaptic rates, <inline-formula><alternatives><mml:math id="inf84"><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="inft84">\begin{document}${\bar{r}}_{j}$\end{document}</tex-math></alternatives></inline-formula>, also encompass the external input neurons. While in classical energy-based approaches, <inline-formula><alternatives><mml:math id="inf85"><mml:mi>L</mml:mi></mml:math><tex-math id="inft85">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> is called the total energy, we call it the ‘Lagrangian’ because it will be integrated along real and virtual voltage trajectories as done in variational calculus (leading to the Euler-Lagrange equations, see below and Appendix 6). We ‘prospectively’ minimize <inline-formula><alternatives><mml:math id="inf86"><mml:mi>L</mml:mi></mml:math><tex-math id="inft86">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> locally across a voltage trajectory, so that, as a consequence, the local synaptic plasticity for <inline-formula><alternatives><mml:math id="inf87"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft87">\begin{document}$W_{ij}$\end{document}</tex-math></alternatives></inline-formula> will globally reduce the cost along the trajectory (Theorem 1 below).</p><p>Due to the prospective coding, the Lagrangian can be minimal at any moment in time while the network dynamics evolve. This is different from the classical predictive coding (<xref ref-type="bibr" rid="bib74">Rao and Ballard, 1999</xref>) and energy-based approaches (<xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>; <xref ref-type="bibr" rid="bib86">Song et al., 2024</xref>), where a stimulus needs to be fixed in time while the network relaxes to a steady state, and only there the prediction error is minimized (see Appendix 3).</p></sec><sec id="s2-2"><title>The least-action principle expressed for prospective firing rates</title><p>Motivated by the prospective firing in pyramidal neurons, we postulate that cortical networks strive to look into the future to prevent instantaneous errors. Each neuron tries to move along a trajectory that minimizes its own mismatch error <inline-formula><alternatives><mml:math id="inf88"><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft88">\begin{document}$\bar e_{i}$\end{document}</tex-math></alternatives></inline-formula> across time (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). The ‘neuronal currency’ with which each neuron ‘trades’ with others to choose its own error-minimizing trajectory is the future discounted membrane potential,<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle {\tilde{u}}(t) = \frac{1}{\tau}\int_{t}^{\infty}u(t')\;{\boldsymbol e}^{-\frac{t'-t}{\tau}}{\text{d}}t' \;. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The prospective voltages <inline-formula><alternatives><mml:math id="inf89"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft89">\begin{document}${\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> are the ‘canonical coordinates’ entering the NLA principle, and in these prospective coordinates the overall network searches for a ‘least-action trajectory’. Since from <inline-formula><alternatives><mml:math id="inf90"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft90">\begin{document}${\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> we can recover the instantaneous voltage via <inline-formula><alternatives><mml:math id="inf91"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft91">\begin{document}$u ={\tilde{u}}- \tau{\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula> (see Appendix 2), we can replace <inline-formula><alternatives><mml:math id="inf92"><mml:mi>u</mml:mi></mml:math><tex-math id="inft92">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> in the Lagrangian and obtain <inline-formula><alternatives><mml:math id="inf93"><mml:mi>L</mml:mi></mml:math><tex-math id="inft93">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> as a function of our new prospective coordinates <inline-formula><alternatives><mml:math id="inf94"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft94">\begin{document}${\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> and the ‘velocities’ <inline-formula><alternatives><mml:math id="inf95"><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft95">\begin{document}${\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>, i.e.,<inline-formula><alternatives><mml:math id="inf96"><mml:mrow><mml:mspace width="0.1667em"/><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo fence="true" form="prefix">[</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo fence="true" form="postfix">]</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft96">\begin{document}$\,L ={L}\left[ \boldsymbol{\tilde{u}}, \boldsymbol{\dot{{\tilde{u}}}}\right]$\end{document}</tex-math></alternatives></inline-formula>, where bold fonts represent vectors. Inspired by the least-action principle from physics, we define the neuronal action <inline-formula><alternatives><mml:math id="inf97"><mml:mi>A</mml:mi></mml:math><tex-math id="inft97">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> as a time-integral of the Lagrangian,<disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mo fence="true" form="prefix">[</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">]</mml:mo></mml:mrow><mml:mspace width="0.1667em"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t5">\begin{document}$$\displaystyle A = \int_{t_1}^{t_2}L \left[ \boldsymbol{\tilde{u}}(t), \boldsymbol{\dot{\tilde{u}}}(t) \right] \, \mathrm{d}t \; . $$\end{document}</tex-math></alternatives></disp-formula></p><p>The NLA principle postulates that the trajectory <inline-formula><alternatives><mml:math id="inf98"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft98">\begin{document}$\boldsymbol{\tilde{u}}(t)$\end{document}</tex-math></alternatives></inline-formula> keeps the action <inline-formula><alternatives><mml:math id="inf99"><mml:mi>A</mml:mi></mml:math><tex-math id="inft99">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> stationary with respect to small variations <inline-formula><alternatives><mml:math id="inf100"><mml:mrow><mml:mi>δ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft100">\begin{document}$\delta \boldsymbol{\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1b1</xref>). In other words, nature chooses a trajectory such that, when deviating a little bit from it, say by <inline-formula><alternatives><mml:math id="inf101"><mml:mrow><mml:mi>δ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft101">\begin{document}$\delta \tilde{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>, the value of <inline-formula><alternatives><mml:math id="inf102"><mml:mi>A</mml:mi></mml:math><tex-math id="inft102">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> will not change (or at most up to second order in the variation), formally <inline-formula><alternatives><mml:math id="inf103"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft103">\begin{document}$\delta A = 0$\end{document}</tex-math></alternatives></inline-formula>. The motivation to search for a trajectory that keeps the action stationary is borrowed from physics. The motivation to search for a stationary trajectory by varying the near-future voltages <inline-formula><alternatives><mml:math id="inf104"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover></mml:math><tex-math id="inft104">\begin{document}$\boldsymbol{\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula>, instead of <inline-formula><alternatives><mml:math id="inf105"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft105">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, is assigned to the evolutionary pressure in biology to ‘think ahead of time.’ To not react too late, internal delays involved in the integration of external feedback need to be considered and eventually need to be overcome. In fact, only for the ‘prospective coordinates’ defined by looking ahead into the future, even when only virtually, will a real-time learning from feedback errors become possible (as expressed by our Theorems below).</p><p>The equations of motion that keep the action stationary with respect to these prospective coordinates are known to satisfy the Euler-Lagrange equations.<disp-formula id="equ6"><label>(6)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle \frac{ \partial {L}}{\partial{\tilde{u}}_{i}}- \frac{{\text{d}}}{{\text{d}} t}\frac{ \partial {L}}{\partial{\dot{{\tilde{u}}}}_{i}}= 0.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Applying these equations to our Lagrangian yields a prospective version of the classical leaky integrator voltage dynamics, with rates <inline-formula><alternatives><mml:math id="inf106"><mml:mi>𝒓</mml:mi></mml:math><tex-math id="inft106">\begin{document}$\boldsymbol r$\end{document}</tex-math></alternatives></inline-formula> and errors <inline-formula><alternatives><mml:math id="inf107"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft107">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula> that are looking into the future (Methods, Sects. Euler-Lagrange equations as inverse low-pass filters, Deriving the network dynamics from the Euler-Lagrange equations),<disp-formula id="equ7"><label>(7a)</label><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle \tau \boldsymbol{\dot u}= - \boldsymbol u + \boldsymbol W \boldsymbol r + \boldsymbol e ,$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ8"><label>(7b)</label><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle {\bar{\boldsymbol{ e }}}={\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\cdot}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}+ \beta{\bar{\boldsymbol{ e }}}^{*}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>The ‘<inline-formula><alternatives><mml:math id="inf108"><mml:mrow><mml:mspace width="0.1667em"/><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft108">\begin{document}$\,{\!\cdot\!}\,$\end{document}</tex-math></alternatives></inline-formula>’ denotes the component-wise product, and the weight matrix splits into weights from input neurons and weights from network neurons, <inline-formula><alternatives><mml:math id="inf109"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft109">\begin{document}$\boldsymbol W = (\boldsymbol W_{{\text{in}}}, \boldsymbol W_{{{\!\text{net}}}})$\end{document}</tex-math></alternatives></inline-formula>. While for output neurons a target error can be defined, <inline-formula><alternatives><mml:math id="inf110"><mml:mrow><mml:msubsup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft110">\begin{document}${\bar{e}}^{*}_{o}= u_{o}^{*}- u_{o}$\end{document}</tex-math></alternatives></inline-formula>, for non-output neurons <italic>i</italic> no target exists and we hence set <inline-formula><alternatives><mml:math id="inf111"><mml:mrow><mml:msubsup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft111">\begin{document}${\bar{e}}^{*}_{i}= 0$\end{document}</tex-math></alternatives></inline-formula>. In a control theoretic framework, the neuronal dynamics (<xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>) represent the state trajectory, and the adjoint error dynamics <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref> represent the integrated costate trajectory (<xref ref-type="bibr" rid="bib92">Todorov, 2006</xref>).</p><p>From the point of view of theoretical physics, where the laws of motion derived from the least-action principle contain an acceleration term (as in Newton’s law of motion, like <inline-formula><alternatives><mml:math id="inf112"><mml:mrow><mml:mi>m</mml:mi><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math><tex-math id="inft112">\begin{document}$m \ddot x = - x + F$\end{document}</tex-math></alternatives></inline-formula> for a harmonic oscillator), one may wonder why no second-order time derivative appears in the NLA dynamics. As an intuitive example, consider driving into a bend. Looking ahead in time helps us to reduce the lateral acceleration by braking early enough, as opposed to braking only when the lateral acceleration is already present. This intuition is captured by minimizing the neuronal action <inline-formula><alternatives><mml:math id="inf113"><mml:mi>A</mml:mi></mml:math><tex-math id="inft113">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> with respect to the discounted future voltages <inline-formula><alternatives><mml:math id="inf114"><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft114">\begin{document}$\tilde u_{i}$\end{document}</tex-math></alternatives></inline-formula> instead of the instantaneous voltages <inline-formula><alternatives><mml:math id="inf115"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft115">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula>. Keeping up an internal equilibrium in the presence of a changing environment requires looking ahead and compensating early for the predicted perturbations. Technically, the acceleration disappears because the Euler-Lagrange operator (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>) turns into a lookahead-gradient operator, <inline-formula><alternatives><mml:math id="inf116"><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math><tex-math id="inft116">\begin{document}$\tfrac{ \partial }{\partial {\tilde{u}}_i}- \tfrac{{\text{d}}}{{\text{d}} t}\frac{ \partial }{\partial{\dot{{\tilde{u}}}}_{i}}= \big(1 + \tfrac{{\text{d}}}{{\text{d}} t}\big) \tfrac{ \partial }{\partial u_i}$\end{document}</tex-math></alternatives></inline-formula>, since the <inline-formula><alternatives><mml:math id="inf117"><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft117">\begin{document}$\ddot{\tilde{u}}_{i}$\end{document}</tex-math></alternatives></inline-formula> is absorbed via <inline-formula><alternatives><mml:math id="inf118"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft118">\begin{document}$\dot{\tilde{u}}_{i}- \tau \ddot{\tilde{u}}_{i}= \dot u_{i}$\end{document}</tex-math></alternatives></inline-formula> (see Methods, Sect. Euler-Lagrange equations as inverse low-pass filters, and Appendix 6 for the link to the least-action principle in physics).</p><p>Mathematically, the voltage dynamics in <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref> specifies an implicit differential equation since <inline-formula><alternatives><mml:math id="inf119"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft119">\begin{document}$\dot{\boldsymbol u}(t)$\end{document}</tex-math></alternatives></inline-formula> also appears on the right-hand side. This is because the prospective rates <inline-formula><alternatives><mml:math id="inf120"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft120">\begin{document}$\boldsymbol r = \rho(\boldsymbol u) + \tau \dot{\rho}(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> include <inline-formula><alternatives><mml:math id="inf121"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft121">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> through <inline-formula><alternatives><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft122">\begin{document}$\dot{\rho}(\boldsymbol u) = \rho'(\boldsymbol u){\cdot}\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>. Likewise, the prospective errors <inline-formula><alternatives><mml:math id="inf123"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft123">\begin{document}$\boldsymbol e ={\bar{\boldsymbol{ e }}}+ \tau \dot{{\bar{\boldsymbol{ e }}} }$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf124"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft124">\begin{document}${\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula> given in <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref> and plugged into <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, imply <inline-formula><alternatives><mml:math id="inf125"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft125">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> through <inline-formula><alternatives><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft126">\begin{document}$\dot{{\bar{\boldsymbol{ e }}} }(\boldsymbol u) ={\bar{\boldsymbol{ e }}}'(\boldsymbol u){\cdot}\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>. Nevertheless, the voltage dynamics can be stably run by replacing <inline-formula><alternatives><mml:math id="inf127"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft127">\begin{document}$\dot{\boldsymbol u}(t)$\end{document}</tex-math></alternatives></inline-formula> on the right-hand side of <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref> with the temporal derivative <inline-formula><alternatives><mml:math id="inf128"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft128">\begin{document}$\dot{\boldsymbol u}(t-dt)$\end{document}</tex-math></alternatives></inline-formula> from the previous time step (technically, the Hessian <inline-formula><alternatives><mml:math id="inf129"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:msup><mml:mi>𝝆</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft129">\begin{document}$(\boldsymbol 1 - \boldsymbol W \boldsymbol \rho' -{\bar{\boldsymbol{ e }}}')$\end{document}</tex-math></alternatives></inline-formula> is required to be strictly positive definite, see Methods Sect. From implicit to explicit differential equations and Appendix 3). This ensures that the voltage dynamics of <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref> can be implemented in cortical neurons with a prospective firing and a prospective dendritic error (see <xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><p>The error expression in <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref> is reminiscent of error backpropagation <xref ref-type="bibr" rid="bib77">Rumelhart et al., 1986</xref> and can in fact be related (Methods, Sect. Deriving the error backpropagation formula). Formally, the errors are backpropagated via transposed network matrix, <inline-formula><alternatives><mml:math id="inf130"><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup></mml:math><tex-math id="inft130">\begin{document}$\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula>, modulated by <inline-formula><alternatives><mml:math id="inf131"><mml:msubsup><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup></mml:math><tex-math id="inft131">\begin{document}$\bar{r}_{i}'$\end{document}</tex-math></alternatives></inline-formula>, the derivative of <inline-formula><alternatives><mml:math id="inf132"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft132">\begin{document}$\bar{r}_{i}= \rho(u_{i})$\end{document}</tex-math></alternatives></inline-formula> with respect to the underlying voltage. While the transpose can be constructed with various local methods see <xref ref-type="bibr" rid="bib3">Akrout et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Max et al., 2022</xref> in our simulations we mainly adhere to the phenomenon of feedback alignment (<xref ref-type="bibr" rid="bib58">Lillicrap et al., 2016</xref>) and consider fixed and randomized feedback weights <inline-formula><alternatives><mml:math id="inf133"><mml:mi>𝑩</mml:mi></mml:math><tex-math id="inft133">\begin{document}$\boldsymbol B$\end{document}</tex-math></alternatives></inline-formula> (unless stated differently). Recent control theoretical work is exploiting the same prospective coding technique as expressed in <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref> to tackle general time-varying optimization problems see <xref ref-type="bibr" rid="bib84">Simonetto et al., 2020</xref> for a review and Appendix 3 for the detailed connection.</p></sec><sec id="s2-3"><title>Prospective coding in neurons and instantaneous propagation</title><p>The prospective rates and errors entering via <inline-formula><alternatives><mml:math id="inf134"><mml:mi>𝒓</mml:mi></mml:math><tex-math id="inft134">\begin{document}$\boldsymbol r$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf135"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft135">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula> in the NLA (<xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>) are consistent with the prospective coding observed in cortical pyramidal neurons in vitro (<xref ref-type="bibr" rid="bib50">Köndgen et al., 2008</xref>). Upon sinusoidal current injection into the soma, the somatic firing rate is advanced with respect to its voltage (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), effectively compensating for the delay caused by the current integration. Likewise, sinusoidal current injection in the apical tree causes a lag-less voltage response in the soma (<xref ref-type="fig" rid="fig2">Figure 2b</xref>, <xref ref-type="bibr" rid="bib96">Ulrich, 2002</xref>). While the rates and errors in general can be reconstructed from their low-pass filterings via <inline-formula><alternatives><mml:math id="inf136"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft136">\begin{document}$\boldsymbol r ={\bar{\boldsymbol{ r }}}+ \tau \dot{{\bar{\boldsymbol{ r }}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf137"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft137">\begin{document}$\boldsymbol e ={\bar{\boldsymbol{ e }}}+ \tau \dot{{\bar{\boldsymbol{ e }}}}$\end{document}</tex-math></alternatives></inline-formula>, they become prospective in time because <inline-formula><alternatives><mml:math id="inf138"><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft138">\begin{document}${\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf139"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft139">\begin{document}${\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula> are themselves instantaneous functions of the voltage <inline-formula><alternatives><mml:math id="inf140"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft140">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, and hence <inline-formula><alternatives><mml:math id="inf141"><mml:mi>𝒓</mml:mi></mml:math><tex-math id="inft141">\begin{document}$\boldsymbol r$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf142"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft142">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula> depend on <inline-formula><alternatives><mml:math id="inf143"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft143">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>. The derivative of the membrane potential implicitly also appears in the firing mechanism of Hodgkin-Huxley-type conductances, with a quick depolarization leading to a stronger sodium influx due to the dynamics of the gating variables (<xref ref-type="bibr" rid="bib43">Hodgkin and Huxley, 1952</xref>). This advances the action potential as compared to a firing that would only depend on <inline-formula><alternatives><mml:math id="inf144"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft144">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, not <inline-formula><alternatives><mml:math id="inf145"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft145">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>, giving an intuition of how such a prospective coding may arise. A similar prospective coding has been observed for retinal ganglion cells (<xref ref-type="bibr" rid="bib69">Palmer et al., 2015</xref>) and cerebellar Purkinje cells (<xref ref-type="bibr" rid="bib68">Ostojic et al., 2015</xref>), making a link from the visual input to the motor control.</p><p>To understand the instantaneous propagation through the network, we low-pass filter the dynamic equation <inline-formula><alternatives><mml:math id="inf146"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:mo>+</mml:mo><mml:mi>𝒆</mml:mi></mml:mrow></mml:math><tex-math id="inft146">\begin{document}$\boldsymbol u + \tau \boldsymbol{\dot u}= \boldsymbol W \boldsymbol r + \boldsymbol e$\end{document}</tex-math></alternatives></inline-formula> (obtained by rearranging <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>), with <inline-formula><alternatives><mml:math id="inf147"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft147">\begin{document}${\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula> given by <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref>, to obtain the somatic voltage <inline-formula><alternatives><mml:math id="inf148"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑾</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft148">\begin{document}$\boldsymbol u = \boldsymbol W \,{\bar{\boldsymbol{ r }}}(\boldsymbol u) +{\bar{\boldsymbol{ e }}}(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>. At any point in time, the voltage is in a moving equilibrium between forward and backpropagating inputs. Independently of the network architecture, whether recurrent or not, the output is an instantaneous function of the low-pass filtered input and a putative correction towards the target, <inline-formula><alternatives><mml:math id="inf149"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft149">\begin{document}$\boldsymbol u_{\boldsymbol o}(t) = \boldsymbol F_{W}(\boldsymbol{\bar{r}}_{{\text{in}}}(t),{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}(t))$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="fig" rid="fig2">Figure 2C</xref> and Methods, Sect. Proving theorem 1 (rt-DeEP). The mapping again expresses an instantaneous propagation of voltages throughout the network in response to both, the low-pass filtered input <inline-formula><alternatives><mml:math id="inf150"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft150">\begin{document}$\boldsymbol{\bar{r}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> and feedback error <inline-formula><alternatives><mml:math id="inf151"><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft151">\begin{document}${\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula>. This instantaneity is independent of the network size, and in a feed-forward network is independent of its depths (see also <xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>, where the instantaneity is on the rates, not the voltages). In the absence of the look-ahead activity, each additional layer would slow down the network relaxation time.</p><p>Notice that an algorithmic implementation of the time-continuous dynamics of a <inline-formula><alternatives><mml:math id="inf152"><mml:mi>N</mml:mi></mml:math><tex-math id="inft152">\begin{document}$N$\end{document}</tex-math></alternatives></inline-formula>-layer feedforward network would still need <inline-formula><alternatives><mml:math id="inf153"><mml:mi>N</mml:mi></mml:math><tex-math id="inft153">\begin{document}$N$\end{document}</tex-math></alternatives></inline-formula> calculation steps until information from layer 1 reaches layer <inline-formula><alternatives><mml:math id="inf154"><mml:mi>N</mml:mi></mml:math><tex-math id="inft154">\begin{document}$N$\end{document}</tex-math></alternatives></inline-formula>. However, this does not imply that an analog implementation of the prospective dynamics will encounter delays. To see why, consider a finite step-change <inline-formula><alternatives><mml:math id="inf155"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft155">\begin{document}$\Delta \boldsymbol{u}_{1}$\end{document}</tex-math></alternatives></inline-formula> in the voltage of layer 1. In the absence of the look-ahead, <inline-formula><alternatives><mml:math id="inf156"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft156">\begin{document}$\Delta \boldsymbol{u}_{1}$\end{document}</tex-math></alternatives></inline-formula> was mapped within the infinitesimal time interval <inline-formula><alternatives><mml:math id="inf157"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft157">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula> to an infinitesimal change <inline-formula><alternatives><mml:math id="inf158"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft158">\begin{document}$d \boldsymbol{u}_{2}$\end{document}</tex-math></alternatives></inline-formula> in the voltages of layer 2. But with a prospective firing rate, <inline-formula><alternatives><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msup><mml:mi>ρ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft159">\begin{document}$\boldsymbol r_{1}= \rho({\boldsymbol u}_{1}) + \tau \rho'({\boldsymbol u}_{1}) \cdot \dot{\boldsymbol u}_{1}$\end{document}</tex-math></alternatives></inline-formula>, a step-change <inline-formula><alternatives><mml:math id="inf160"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft160">\begin{document}$\Delta \boldsymbol{u}_{1}$\end{document}</tex-math></alternatives></inline-formula> translates to a delta-function in <inline-formula><alternatives><mml:math id="inf161"><mml:msub><mml:mi>𝒓</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="inft161">\begin{document}$\boldsymbol r_{1}$\end{document}</tex-math></alternatives></inline-formula>, this in turn to a step-change in the low-pass filtered rates <inline-formula><alternatives><mml:math id="inf162"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft162">\begin{document}$\Delta{\bar{\boldsymbol{ r }}}_{1}$\end{document}</tex-math></alternatives></inline-formula>, and therefore within <inline-formula><alternatives><mml:math id="inf163"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft163">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula> to a step-change <inline-formula><alternatives><mml:math id="inf164"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft164">\begin{document}$\Delta \boldsymbol{u}_{2}$\end{document}</tex-math></alternatives></inline-formula> in the voltages <inline-formula><alternatives><mml:math id="inf165"><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><tex-math id="inft165">\begin{document}$\boldsymbol u_{2}$\end{document}</tex-math></alternatives></inline-formula> of the postsynaptic neurons (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). Iterating this argument, a step-change <inline-formula><alternatives><mml:math id="inf166"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft166">\begin{document}$\Delta \boldsymbol{u}_{1}$\end{document}</tex-math></alternatives></inline-formula> propagates ‘instantaneously’ through <inline-formula><alternatives><mml:math id="inf167"><mml:mi>N</mml:mi></mml:math><tex-math id="inft167">\begin{document}$N$\end{document}</tex-math></alternatives></inline-formula> layers within the ‘infinitesimal’ time interval <inline-formula><alternatives><mml:math id="inf168"><mml:mrow><mml:mi>N</mml:mi><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft168">\begin{document}$N \, dt$\end{document}</tex-math></alternatives></inline-formula> to a step-change <inline-formula><alternatives><mml:math id="inf169"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft169">\begin{document}$\Delta \boldsymbol{u}_{N}$\end{document}</tex-math></alternatives></inline-formula> in the last layer. When run in a biophysical device in continuous time that exactly implements the dynamical <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, the implementation becomes an instantaneous computation (since <inline-formula><alternatives><mml:math id="inf170"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>→</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft170">\begin{document}$dt\!\to\! 0$\end{document}</tex-math></alternatives></inline-formula>). Yet, in a biophysical device, information has to be moved across space. This typically introduces further propagation delays that may not be captured in our formalism where low-pass filtering and prospective coding cancel each other exactly. Nevertheless, analog computation in continuous time, as formalized here, offers an idea to ‘instantaneously’ realize an otherwise time-consuming numerical recipe run on time-discrete computing systems that operate with a finite clock cycle.</p></sec><sec id="s2-4"><title>Prospective control and the moving equilibrium hypothesis</title><p>Crucially, at the level of the voltage dynamics (<xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>) the correction is based on the prospective error <inline-formula><alternatives><mml:math id="inf171"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft171">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula>. This links our framework to optimal control theory and motor control where delays are also taken into account, so that a movement can be corrected early enough (<xref ref-type="bibr" rid="bib105">Wolpert and Ghahramani, 2000</xref>; <xref ref-type="bibr" rid="bib93">Todorov and Jordan, 2002</xref>; <xref ref-type="bibr" rid="bib94">Todorov, 2004</xref>). The link between energy-based models and optimal control was recently drawn for strong nudging (<inline-formula><alternatives><mml:math id="inf172"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft172">\begin{document}$\beta\to\infty$\end{document}</tex-math></alternatives></inline-formula>) to learn individual equilibrium states (<xref ref-type="bibr" rid="bib64">Meulemans et al., 2022</xref>). Our prospective error <inline-formula><alternatives><mml:math id="inf173"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft173">\begin{document}$\boldsymbol e(t)$\end{document}</tex-math></alternatives></inline-formula> appears as a ‘controller’ that, when looking at the output neurons, pushes the voltage trajectories toward the target trajectories. Depending on the nudging strength <inline-formula><alternatives><mml:math id="inf174"><mml:mi>β</mml:mi></mml:math><tex-math id="inft174">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>, the control is tighter or weaker. For infinitely large <inline-formula><alternatives><mml:math id="inf175"><mml:mi>β</mml:mi></mml:math><tex-math id="inft175">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>, the voltages of the output neurons are clamped to the time-dependent target voltages, <inline-formula><alternatives><mml:math id="inf176"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft176">\begin{document}$u_{o}= u_{o}^{*}$\end{document}</tex-math></alternatives></inline-formula> (implying <inline-formula><alternatives><mml:math id="inf177"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft177">\begin{document}$e^{*}_{o}=0$\end{document}</tex-math></alternatives></inline-formula>), while their errors, <inline-formula><alternatives><mml:math id="inf178"><mml:mrow><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft178">\begin{document}$\bar e_{o}= u_{o}- (\boldsymbol W{\bar{\boldsymbol{ r }}})_{o}$\end{document}</tex-math></alternatives></inline-formula>, instantaneously correct all network neurons. For small <inline-formula><alternatives><mml:math id="inf179"><mml:mi>β</mml:mi></mml:math><tex-math id="inft179">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>, the output voltages are only weakly controlled, and they are dominated by the forward input, <inline-formula><alternatives><mml:math id="inf180"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft180">\begin{document}$u_{o}\approx (W{\bar{\boldsymbol{ r }}})_{o}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>To show how the NLA principle with the prospective coding globally maps to cortico-spinal circuits we consider the example of motor control. In the context of motor control, our network mapping <inline-formula><alternatives><mml:math id="inf181"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft181">\begin{document}$\boldsymbol{u_o}= \boldsymbol F_{W}(\boldsymbol{\bar r}_{{\text{in}}},{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula> can be seen as a forward internal model that quickly calculates an estimate of the future muscle length <inline-formula><alternatives><mml:math id="inf182"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft182">\begin{document}$\boldsymbol{u_o}$\end{document}</tex-math></alternatives></inline-formula> based on some motor plans, sensory inputs, and the current proprioceptive feedback (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). Forward models help to overcome delays in the execution of the motor plan by predicting the outcome, so that the intended motor plans and commands can be corrected on the fly (<xref ref-type="bibr" rid="bib47">Kawato, 1999</xref>; <xref ref-type="bibr" rid="bib105">Wolpert and Ghahramani, 2000</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Moving equilibrium hypothesis for motor control and real-time learning of cortical activity.</title><p>(<bold>a</bold>) A voluntary movement trajectory can be specified by the target length of the muscles in time, <inline-formula><alternatives><mml:math id="inf183"><mml:msup><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:math><tex-math id="inft183">\begin{document}$\boldsymbol{u_o}^{*}$\end{document}</tex-math></alternatives></inline-formula>, encoded through the <inline-formula><alternatives><mml:math id="inf184"><mml:mi>γ</mml:mi></mml:math><tex-math id="inft184">\begin{document}$\gamma$\end{document}</tex-math></alternatives></inline-formula>-innervation of muscle spindles, and the deviation of the effective muscle lengths from the target, <inline-formula><alternatives><mml:math id="inf185"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft185">\begin{document}$\boldsymbol{u_o}- \boldsymbol{u_o}^{*}= -{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula>. The <inline-formula><alternatives><mml:math id="inf186"><mml:msub><mml:mi>I</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><tex-math id="inft186">\begin{document}$I_{a}$\end{document}</tex-math></alternatives></inline-formula>-afferents emerging from the spindles prospectively encode the error, so that their low-pass filtering is roughly proportional to the length deviation, truncated at zero (red). The moving equilibrium hypothesis states that the low-pass filtered input <inline-formula><alternatives><mml:math id="inf187"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft187">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>, composed of the movement plan <inline-formula><alternatives><mml:math id="inf188"><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext><mml:mrow><mml:mtext/><mml:mi>plan</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft188">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}^{\mathrm{plan}}$\end{document}</tex-math></alternatives></inline-formula> and the sensory input (here encoding the state of the plant e.g., through visual and proprioceptive input, <inline-formula><alternatives><mml:math id="inf189"><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext><mml:mrow><mml:mtext/><mml:mi>vis</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft189">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}^{\mathrm{vis}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf190"><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext><mml:mrow><mml:mtext/><mml:mi>prop</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft190">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}^{\mathrm{prop}}$\end{document}</tex-math></alternatives></inline-formula>), together with the low-pass filtered error feedback from the spindles, <inline-formula><alternatives><mml:math id="inf191"><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft191">\begin{document}${\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula>, instantaneously generate the muscle lengths, <inline-formula><alternatives><mml:math id="inf192"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft192">\begin{document}$\boldsymbol{u_o}= \boldsymbol F_{W}(\boldsymbol{\bar r}_{{\text{in}}},{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula>, and are thus at any point in time in an instantaneous equilibrium (defined by <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref>). (<bold>b1</bold>) Intracortical intracortical electroencephalogram (iEEG) activity recorded from 56 deep electrodes and projected to the brain surface. Red nodes symbolize the 56 iEEG recording sites modeled alternately as input or output neurons, and blue nodes symbolize the 40 ‘hidden’ neurons for which no data is available, but used to reproduce the iEEG activity. (<bold>b2</bold>) Corresponding NLA network. During training, the voltages of the output neurons were nudged by the iEEG targets (black input arrows, but for all red output neurons). During testing, nudging was removed for 14 out of these 56 neurons (here, represented by neurons 1, 2, 3). (<bold>c1</bold>) Voltage traces for the 3 example neurons in a2, before (blue) and after (red) training, overlaid with their iEEG target traces (gray). (<bold>c2</bold>) Total cost, integrated over a window of 8 s of the 56 output nodes during training with sequences of the same duration. The cost for the test sequences was evaluated on a 8 s window not used during training.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89674-fig3-v2.tif"/></fig><p>The observation that muscle spindles prospectively encode the muscle length and velocity (<xref ref-type="bibr" rid="bib24">Dimitriou and Edin, 2010</xref>) suggests that the prospective coding in the internal forward model mirrors the prospective coding in the effective forward pathway. This forward pathway leads from the motor plan to the spindle feedback, integrating also cerebellar and brainstem feedback (<xref ref-type="bibr" rid="bib47">Kawato, 1999</xref>). Based on the motor plans, the intended spindle lengths and the effective muscle innervation are communicated via a descending pathway to activate the <inline-formula><alternatives><mml:math id="inf193"><mml:mi>γ</mml:mi></mml:math><tex-math id="inft193">\begin{document}$\gamma$\end{document}</tex-math></alternatives></inline-formula>- and <inline-formula><alternatives><mml:math id="inf194"><mml:mi>α</mml:mi></mml:math><tex-math id="inft194">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula>-motoneurons, respectively (<xref ref-type="bibr" rid="bib57">Li et al., 2015</xref>). The mapping from the intended arm trajectory to the intended spindle lengths via <inline-formula><alternatives><mml:math id="inf195"><mml:mi>γ</mml:mi></mml:math><tex-math id="inft195">\begin{document}$\gamma$\end{document}</tex-math></alternatives></inline-formula>-innervation is mainly determined by the joint geometry. The mapping from the intended arm trajectory to the force-generating <inline-formula><alternatives><mml:math id="inf196"><mml:mi>α</mml:mi></mml:math><tex-math id="inft196">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula>-innervation, however, needs to also take account of the internal and external forces, and this is engaging our network <inline-formula><alternatives><mml:math id="inf197"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft197">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula>.</p><p>When we prepare an arm movement, spindles in antagonistic muscle pairs that measure the muscle length are tightened or relaxed before the movement starts (<xref ref-type="bibr" rid="bib70">Papaioannou and Dimitriou, 2021</xref>). According to the classical equilibrium-point hypothesis (<xref ref-type="bibr" rid="bib28">Feldman and Levin, 2009</xref>; <xref ref-type="bibr" rid="bib54">Latash, 2010</xref>), top-down input adjusts the activation threshold of the spindles through (<inline-formula><alternatives><mml:math id="inf198"><mml:mi>γ</mml:mi></mml:math><tex-math id="inft198">\begin{document}$\gamma$\end{document}</tex-math></alternatives></inline-formula>-) innervation from the spinal cord so that slight deviations from the equilibrium position can be signaled (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). We postulate that this <inline-formula><alternatives><mml:math id="inf199"><mml:mi>γ</mml:mi></mml:math><tex-math id="inft199">\begin{document}$\gamma$\end{document}</tex-math></alternatives></inline-formula>-innervation acts also during the movement, setting an instantaneous target <inline-formula><alternatives><mml:math id="inf200"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft200">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}(t)$\end{document}</tex-math></alternatives></inline-formula> for the spindle lengths. The effective lengths of the muscle spindles is <inline-formula><alternatives><mml:math id="inf201"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft201">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>, and the spindles are prospectively signaling back the deviation from the target through the <inline-formula><alternatives><mml:math id="inf202"><mml:msub><mml:mi>I</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><tex-math id="inft202">\begin{document}$I_{a}$\end{document}</tex-math></alternatives></inline-formula>-afferents (<xref ref-type="bibr" rid="bib24">Dimitriou and Edin, 2010</xref>; <xref ref-type="bibr" rid="bib26">Dimitriou, 2022</xref>). The low-pass filtered <inline-formula><alternatives><mml:math id="inf203"><mml:msub><mml:mi>I</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math><tex-math id="inft203">\begin{document}$I_{a}$\end{document}</tex-math></alternatives></inline-formula>-afferents may be approximated by a threshold-nonlinearity, <inline-formula><alternatives><mml:math id="inf204"><mml:mrow><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:msub><mml:mi>I</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mo form="prefix" stretchy="false">⌊</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:msup><mml:mo form="postfix" stretchy="false">⌋</mml:mo><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft204">\begin{document}$\overline{ I_a}= \beta \lfloor \boldsymbol{u_o}- \boldsymbol{u_o}^{*}\rfloor^{\!+}$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf205"><mml:mi>β</mml:mi></mml:math><tex-math id="inft205">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> being interpreted as spindle gain (<xref ref-type="bibr" rid="bib55">Latash, 2018</xref>). Combining the feedback from agonistic and antagonistic muscle pairs allows for extracting the scaled target error <inline-formula><alternatives><mml:math id="inf206"><mml:mrow><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft206">\begin{document}$\beta \,{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}= \beta (\boldsymbol{u_o}^{*}- \boldsymbol{u_o})$\end{document}</tex-math></alternatives></inline-formula>. Taking account of the prospective feedback, we postulate the <italic>moving equilibrium hypothesis</italic> according to which the instructional inputs, <inline-formula><alternatives><mml:math id="inf207"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft207">\begin{document}$\boldsymbol{\bar{r}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>, the spindle feedback, <inline-formula><alternatives><mml:math id="inf208"><mml:mrow><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft208">\begin{document}$\beta \,{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula>, and the muscle lengths, <inline-formula><alternatives><mml:math id="inf209"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft209">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>, are at any point of the movement in a dynamic equilibrium. The moving equilibrium hypothesis extends the classical equilibrium-point hypothesis from the spatial to the temporal domain (for a formal definition of a moving equilibrium see Methods, Sect. From implicit to explicit differential equations).</p><p>Prediction errors are also reduced when motor units within a muscle are recruited according to the size principle (<xref ref-type="bibr" rid="bib82">Senn et al., 1997</xref>), which itself was interpreted in terms of the physical least-action principle (<xref ref-type="bibr" rid="bib81">Senn et al., 1995</xref>). With regard to the interpretation of the prospective feedback error <inline-formula><alternatives><mml:math id="inf210"><mml:msubsup><mml:mi>𝒆</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft210">\begin{document}$\boldsymbol e_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula> as spindle activity, it is worth noticing that in humans the spindle activity is not only ahead of the muscle activation (<xref ref-type="bibr" rid="bib24">Dimitriou and Edin, 2010</xref>), but also share the property of a motor error (<xref ref-type="bibr" rid="bib25">Dimitriou, 2016</xref>). The experiments show that during the learning of a gated hand movement, spindle activity is initially stronger when making movement errors, and it returns back to baseline with the success of learning. This observation is consistent with the NLA principle, saying that the proprioceptive prediction errors are minimized through the movement learning. We next address how the synaptic strengths <inline-formula><alternatives><mml:math id="inf211"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft211">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> involved in producing the muscle length can be optimally adapted to capture this learning.</p></sec><sec id="s2-5"><title>Local plasticity at basal synapses minimizes the global cost in real time</title><p>The general learning paradigm starts with input time series <inline-formula><alternatives><mml:math id="inf212"><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>in</mml:mtext><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft212">\begin{document}$r_{{\text{in}}(t),i}$\end{document}</tex-math></alternatives></inline-formula> and target time series <inline-formula><alternatives><mml:math id="inf213"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft213">\begin{document}$u^{*}_{o}(t)$\end{document}</tex-math></alternatives></inline-formula>, while assuming that the target series are an instantaneous function of the low-pass filtered input series, <inline-formula><alternatives><mml:math id="inf214"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft214">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t) = \boldsymbol F^{*}(\overline{\boldsymbol r}_{{\text{in}}}(t))$\end{document}</tex-math></alternatives></inline-formula>. The low-pass filtering in the individual inputs could be with respect to any time constant <inline-formula><alternatives><mml:math id="inf215"><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>in</mml:mtext><mml:mo separator="true">,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft215">\begin{document}$\tau_{{\text{in}},i}^{*}$\end{document}</tex-math></alternatives></inline-formula> (that may also be learned, see Appendix 2). Yet, for simplicity, we assume the same time constant <inline-formula><alternatives><mml:math id="inf216"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft216">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> for low-pass filtering the rates of the network neurons and input neurons. The goal of learning is to adapt the synaptic strengths <inline-formula><alternatives><mml:math id="inf217"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft217">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> in the student network so that this moves towards the target mapping, <inline-formula><alternatives><mml:math id="inf218"><mml:mrow><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msup><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft218">\begin{document}$\boldsymbol F_{W}\to \boldsymbol F^{*}$\end{document}</tex-math></alternatives></inline-formula>. The local synaptic plasticity will also reduce the global cost <inline-formula><alternatives><mml:math id="inf219"><mml:mi>C</mml:mi></mml:math><tex-math id="inft219">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> defined on the output neurons <inline-formula><alternatives><mml:math id="inf220"><mml:mi>o</mml:mi></mml:math><tex-math id="inft220">\begin{document}$o$\end{document}</tex-math></alternatives></inline-formula> in terms of the deviation of the voltage from the target, <inline-formula><alternatives><mml:math id="inf221"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft221">\begin{document}$u^{*}_{o}- u_{o}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>).</p><p>The problem of changing synaptic weights to correct the behavior of downstream neurons, potentially multiple synapses away, is typically referred to as the credit assignment problem and is notoriously challenging in physical or biological substrates operating in continuous time. A core aspect of the NLA principle is how it relates the global cost <inline-formula><alternatives><mml:math id="inf222"><mml:mi>C</mml:mi></mml:math><tex-math id="inft222">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> to the Lagrangian <inline-formula><alternatives><mml:math id="inf223"><mml:mi>L</mml:mi></mml:math><tex-math id="inft223">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> and eventually to somato-dendritic prediction errors <inline-formula><alternatives><mml:math id="inf224"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft224">\begin{document}$\boldsymbol{\bar{e}}$\end{document}</tex-math></alternatives></inline-formula> that can be reduced through local synaptic plasticity <inline-formula><alternatives><mml:math id="inf225"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft225">\begin{document}$\boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula>. We define this synaptic plasticity as a partial derivative of the Lagrangian with respect to the weights, <inline-formula><alternatives><mml:math id="inf226"><mml:mrow><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>∝</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft226">\begin{document}$\boldsymbol{\dot W}\propto - \frac{\partial L}{\partial \boldsymbol W}={\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}$\end{document}</tex-math></alternatives></inline-formula>. Since the somatodendritic mismatch error is <inline-formula><alternatives><mml:math id="inf227"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft227">\begin{document}${\bar{\boldsymbol{ e }}}= \boldsymbol u - \boldsymbol W \boldsymbol{\bar{r}}$\end{document}</tex-math></alternatives></inline-formula>, this leads to the local learning rule of the form ‘postsynaptic error times low-pass filtered presynaptic rate’,<disp-formula id="equ9"><label>(8)</label><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle \boldsymbol{\dot{W}}= \eta \, (\boldsymbol{u}- \boldsymbol{W}\boldsymbol{\bar{r}}) \, \boldsymbol{\bar{r}}^{\text{T}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The plasticity rule runs simultaneously to the neuronal dynamics in the presence of a given nudging strength <inline-formula><alternatives><mml:math id="inf228"><mml:mi>β</mml:mi></mml:math><tex-math id="inft228">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> that tells how strongly the voltage of an output neuron is pushed towards the target, <inline-formula><alternatives><mml:math id="inf229"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft229">\begin{document}$u_{o}\to u^{*}_{o}$\end{document}</tex-math></alternatives></inline-formula>. The learning rule is local in space since <inline-formula><alternatives><mml:math id="inf230"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft230">\begin{document}$\boldsymbol W{\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula> is represented as a voltage of the basal dendrites, and the somatic voltage <inline-formula><alternatives><mml:math id="inf231"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft231">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> may be read out at the synaptic site on the basal dendrite from the backpropagating action potentials that sample <inline-formula><alternatives><mml:math id="inf232"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft232">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> at a given time (<xref ref-type="bibr" rid="bib97">Urbanczik and Senn, 2014</xref>). The basal voltage <inline-formula><alternatives><mml:math id="inf233"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft233">\begin{document}$\boldsymbol W{\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula> becomes the dendritic prediction of the somatic activity <inline-formula><alternatives><mml:math id="inf234"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft234">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, interpreting <xref ref-type="disp-formula" rid="equ9">Equation 8</xref> as ‘dendritic predictive plasticity’.</p><p>We have derived the neuronal dynamics as a path that keeps the action stationary. Without an external teaching signal, the errors vanish, and the voltage trajectory wriggles on the bottom of the energy landscape (<inline-formula><alternatives><mml:math id="inf235"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft235">\begin{document}$L=0$\end{document}</tex-math></alternatives></inline-formula>, <xref ref-type="fig" rid="fig1">Figure 1b2</xref>). If the external nudging is turned on, <inline-formula><alternatives><mml:math id="inf236"><mml:mrow><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft236">\begin{document}$\beta \gt 0$\end{document}</tex-math></alternatives></inline-formula>, errors emerge and hills grow out of the landscape. The trajectory still tries to locally minimize the action, but it is lifted upwards on the hills (<inline-formula><alternatives><mml:math id="inf237"><mml:mrow><mml:mi>L</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft237">\begin{document}$L \gt 0$\end{document}</tex-math></alternatives></inline-formula>, <xref ref-type="fig" rid="fig1">Figure 1b2</xref>). Synaptic plasticity reshapes the landscape so that, while keeping <inline-formula><alternatives><mml:math id="inf238"><mml:mi>β</mml:mi></mml:math><tex-math id="inft238">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> fixed, the errors are reduced and the landscape again flattens. The transformed trajectory settles anew in another place (inside the ‘volcano’ in 1b2). Formally, the local plasticity rule (<xref ref-type="disp-formula" rid="equ9">Equation 8</xref>) is shown to perform gradient descent on the Lagrangian and hence on the action. In the energy landscape picture, plasticity ‘shovels off’ energy along the voltage path so that this is lowered most efficiently. The error that is back-propagated through the network tells at any point on the voltage trajectory how much to ‘dig’ in each direction, i.e., how to adapt the basal input in each neuron in order to optimally lower the local error.</p><p>The following theorem tells that synaptic plasticity <inline-formula><alternatives><mml:math id="inf239"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft239">\begin{document}$\boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula> pushes the network mapping <inline-formula><alternatives><mml:math id="inf240"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft240">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol{F}_{W}(\boldsymbol{\bar{r}}_{{\text{in}}})$\end{document}</tex-math></alternatives></inline-formula> towards the target mapping <inline-formula><alternatives><mml:math id="inf241"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft241">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}= \boldsymbol F^{*}(\boldsymbol{\bar{r}}_{{\text{in}}})$\end{document}</tex-math></alternatives></inline-formula> at any moment in time. The convergence of the mapping is a consequence of the fact the plasticity reduces the Lagrangian <inline-formula><alternatives><mml:math id="inf242"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft242">\begin{document}$L ={E^\text{M}}+ \beta C$\end{document}</tex-math></alternatives></inline-formula> along its gradient.</p></sec><sec id="s2-6"><title>Theorem 1 (real-time dendritic error propagation, rt-DeEP)</title><p>Consider an arbitrary network <inline-formula><alternatives><mml:math id="inf243"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft243">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> with voltage and error dynamics following <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref>. Then the local plasticity rule <inline-formula><alternatives><mml:math id="inf244"><mml:mrow><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>∝</mml:mo><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft244">\begin{document}$\boldsymbol{\dot W}\propto \,{\bar{\boldsymbol{ e }}}\, \boldsymbol{\bar{r}}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> <xref ref-type="disp-formula" rid="equ9">Equation 8</xref>, acting at each moment along the voltage trajectories, is gradient descent</p><list list-type="simple" id="list1"><list-item><p>(i) on the Lagrangian <inline-formula><alternatives><mml:math id="inf245"><mml:mi>L</mml:mi></mml:math><tex-math id="inft245">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> for any nudging strength <inline-formula><alternatives><mml:math id="inf246"><mml:mrow><mml:mi>β</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>≥</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft246">\begin{document}$\beta \! \geq \! 0$\end{document}</tex-math></alternatives></inline-formula>, i.e., <inline-formula><alternatives><mml:math id="inf247"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>T</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft247">\begin{document}${\bar{\boldsymbol{ e }}}\, \boldsymbol{\bar{r}}^{{\text{T}}}= - \frac{{\mathrm{d}} L}{{\mathrm{d}} \boldsymbol W}$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf248"><mml:mrow><mml:munder><mml:mi>lim</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>T</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>∝</mml:mo><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft248">\begin{document}$\lim\limits_{\beta \to \infty}{\bar{\boldsymbol{ e }}}\, \boldsymbol{\bar{r}}^{{\text{T}}}= - \frac{{\mathrm{d}} {E^\text{M}}}{{\mathrm{d}} \boldsymbol W}\propto \boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p>(ii) on the cost <inline-formula><alternatives><mml:math id="inf249"><mml:mi>C</mml:mi></mml:math><tex-math id="inft249">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> for small nudging, <inline-formula><alternatives><mml:math id="inf250"><mml:mrow><mml:mi>β</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>→</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft250">\begin{document}$\beta \!\to\! 0$\end{document}</tex-math></alternatives></inline-formula>, while up-scaling the error to <inline-formula><alternatives><mml:math id="inf251"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft251">\begin{document}$\frac{1}{\beta}{\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula>, i.e., <inline-formula><alternatives><mml:math id="inf252"><mml:mrow><mml:munder><mml:mi>lim</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>T</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>∝</mml:mo><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft252">\begin{document}$\lim\limits_{\beta \to 0}\! \frac{1}{\beta}{\bar{\boldsymbol{ e }}}\, \boldsymbol{\bar{r}}^{{\text{T}}}= - \frac{{\mathrm{d}} C}{{\mathrm{d}} \boldsymbol W}\propto \boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item></list><p>The gradient statements hold at any point in time (long enough after initialization), even if the input trajectories <inline-formula><alternatives><mml:math id="inf253"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft253">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> contain delta functions and the target trajectories <inline-formula><alternatives><mml:math id="inf254"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft254">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t)$\end{document}</tex-math></alternatives></inline-formula> contain step functions.</p><p>Loosely speaking, the NLA enables the network to localize in space and time an otherwise global problem: what is good for a single neuron (the local plasticity) becomes good for the entire network (the gradient on the global cost). Learning is possible at any point in time along the trajectory because the NLA inferred a prospective voltage dynamics expressed in prospective firing rates <inline-formula><alternatives><mml:math id="inf255"><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft255">\begin{document}$r_{i}$\end{document}</tex-math></alternatives></inline-formula> and prospective errors <inline-formula><alternatives><mml:math id="inf256"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft256">\begin{document}$e_{i}$\end{document}</tex-math></alternatives></inline-formula> of the network neurons. In the limit of strong nudging (<inline-formula><alternatives><mml:math id="inf257"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft257">\begin{document}$\beta \to \infty$\end{document}</tex-math></alternatives></inline-formula>), the learning rule performs gradient descent on the mismatch energies <inline-formula><alternatives><mml:math id="inf258"><mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft258">\begin{document}${E^\text{M}}_{i}$\end{document}</tex-math></alternatives></inline-formula> in the individual neurons. If the network architecture is powerful enough so that after learning all the mismatch energies vanish, <inline-formula><alternatives><mml:math id="inf259"><mml:mrow><mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft259">\begin{document}${E^\text{M}}_{i}=0$\end{document}</tex-math></alternatives></inline-formula>, then the cost will also vanish, <inline-formula><alternatives><mml:math id="inf260"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>‖</mml:mi><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft260">\begin{document}$C=\tfrac{1}{2}\| \boldsymbol u_{\boldsymbol o}^{*}- \boldsymbol u_{\boldsymbol o}\|^{2}= 0$\end{document}</tex-math></alternatives></inline-formula>. This is because for the output neurons, the mismatch error includes the target error (<xref ref-type="disp-formula" rid="equ8">Equation 7b</xref>). In the limit of weak nudging (<inline-formula><alternatives><mml:math id="inf261"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft261">\begin{document}$\beta \to 0$\end{document}</tex-math></alternatives></inline-formula>), the learning rule performs gradient descent on <inline-formula><alternatives><mml:math id="inf262"><mml:mi>C</mml:mi></mml:math><tex-math id="inft262">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula>, and with this also finds a local minimum of the mismatch energies.</p><p>In the case of weak nudging and a single steady-state equilibrium, the NLA algorithm reduces to the Equilibrium Propagation algorithm (<xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>) that minimizes the cost <inline-formula><alternatives><mml:math id="inf263"><mml:mi>C</mml:mi></mml:math><tex-math id="inft263">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> for a constant input and a constant target. In the case of strong nudging and a single steady-state equilibrium, the NLA principle reduces to the Least-Control Principle (<xref ref-type="bibr" rid="bib64">Meulemans et al., 2022</xref>) that minimizes the mismatch energy <inline-formula><alternatives><mml:math id="inf264"><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:math><tex-math id="inft264">\begin{document}${E^\text{M}}$\end{document}</tex-math></alternatives></inline-formula> for a constant input and a constant target, with the apical prediction error becoming the prediction error from standard predictive coding (<xref ref-type="bibr" rid="bib74">Rao and Ballard, 1999</xref>). While in the Least-Control Principle, the inputs and outputs are clamped to fixed values, the output errors are backpropagated and the network equilibrates in a steady state where the corrected network activities reproduce the clamped output activities. This state is called the ‘prospective configuration’ in <xref ref-type="bibr" rid="bib86">Song et al., 2024</xref> because neurons deep in the network are informed about the distal target already during the inference, and are correspondingly adapted to be consistent with this distal target. In the NLA principle, after an initial transient, the network always remains in the moving equilibrium due to the prospective coding. While inputs and targets dynamically change, the network moves along a continuous sequence of prospective configurations.</p><p>In the motor control example, the theorem tells that a given target motor trajectory <inline-formula><alternatives><mml:math id="inf265"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft265">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}(t)$\end{document}</tex-math></alternatives></inline-formula> is learned to be reproduced with the forward model <inline-formula><alternatives><mml:math id="inf266"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft266">\begin{document}$\boldsymbol u_{\boldsymbol o}(t) = \boldsymbol{F}_{W}(\boldsymbol{\bar{r}}_{{\text{in}}}(t))$\end{document}</tex-math></alternatives></inline-formula>, by applying the dendritic predictive plasticity for the network neurons (<xref ref-type="disp-formula" rid="equ9">Equation 8</xref>). We next exemplify the theory by looking into the brain, reproducing cortical activity, and showing how a multi-layer cortical network can learn a sensory-motor mapping while staying in a moving equilibrium throughout the training.</p></sec><sec id="s2-7"><title>Reproducing intracortical EEG recordings and recognizing handwritten digits</title><p>As an illustration, we consider a recurrently connected network that learns to represent intracortical electroencephalogram (iEEG) data from epileptic patients (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). For each electrode, we assign a neuron within this network to represent the activity of the cell cluster recorded in the corresponding iEEG signal via its membrane potential. During learning, a randomly selected subset of electrode neurons are nudged towards the target activity from recorded data while learning to be reproduced by the other neurons. After learning, we can present only a subset of electrode neurons with previously unseen recordings and observe how the activity of the other neurons closely matches the recordings of their respective electrodes (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). The network derived from NLA is thus able to learn complex correlations between signals evolving in real-time by embedding them in a recurrent connectivity structure.</p><p>As an example of sensory-motor processing in the NLA framework, we next consider a well-studied image recognition task, here reformulated in a challenging time-continuous setting, and interpreted as a motor task where 1 out of 10 fingers has to be bent upon seeing a corresponding visual stimulus (see <xref ref-type="fig" rid="fig3">Figure 3</xref>). In the context of our moving equilibrium hypothesis, we postulate that during the learning phase, but not the testing phase, an auditory signal identifies the correct finger and sets the target spindle lengths of 10 finger flexors, <inline-formula><alternatives><mml:math id="inf267"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft267">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}(t)$\end{document}</tex-math></alternatives></inline-formula>. The target spindle length encodes the desired contraction of a flexor muscle in the correct finger upon the visual input <inline-formula><alternatives><mml:math id="inf268"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft268">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>, and a corresponding relaxation for the nine incorrect fingers.</p><p>We train a hierarchical three-layer network on images of handwritten digits (MNIST, <xref ref-type="bibr" rid="bib56">LeCun, 1998</xref>), with image presentation times between <inline-formula><alternatives><mml:math id="inf269"><mml:mrow><mml:mn>0.5</mml:mn><mml:mi>τ</mml:mi></mml:mrow></mml:math><tex-math id="inft269">\begin{document}$0.5\tau$\end{document}</tex-math></alternatives></inline-formula> (=5 ms) and <inline-formula><alternatives><mml:math id="inf270"><mml:mrow><mml:mn>20</mml:mn><mml:mi>τ</mml:mi></mml:mrow></mml:math><tex-math id="inft270">\begin{document}$20\tau$\end{document}</tex-math></alternatives></inline-formula> (=200 ms, with <inline-formula><alternatives><mml:math id="inf271"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>=</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>10</mml:mn><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft271">\begin{document}$\tau\!=\!10\,$\end{document}</tex-math></alternatives></inline-formula> the membrane time constant). <xref ref-type="fig" rid="fig4">Figure 4a-c</xref> depict the most challenging scenario with the shortest presentation time. Synaptic plasticity is continuously active, despite the network never reaching a temporal steady state (<xref ref-type="fig" rid="fig4">Figure 4b1</xref>). Due to the lookahead firing rates in the NLA, the mismatch errors <inline-formula><alternatives><mml:math id="inf272"><mml:mrow><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft272">\begin{document}$\bar e_{i}(t)$\end{document}</tex-math></alternatives></inline-formula> represent the correct gradient and propagate without lag throughout the network. As a consequence, our mismatch errors are almost equal to the errors obtained from classical error backpropagation applied at each time step to the purely forward network (i.e. the network that suppresses the error-correction <inline-formula><alternatives><mml:math id="inf273"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft273">\begin{document}${\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula> of the voltage and instead considers the ‘classical’ voltage <inline-formula><alternatives><mml:math id="inf274"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>−</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft274">\begin{document}$\boldsymbol u_{l}= \boldsymbol W_{l}\, \rho(\boldsymbol u_{{{l\!-\!1}}})$\end{document}</tex-math></alternatives></inline-formula> only, see blue dots in <xref ref-type="fig" rid="fig4">Figure 4b2</xref>). The network eventually learned to implement the mapping <inline-formula><alternatives><mml:math id="inf275"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft275">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol F_{W}({\bar{\boldsymbol{ r }}}_{{\text{in}}}) \approx \boldsymbol u_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula> with a performance comparable to error-backpropagation at each <inline-formula><alternatives><mml:math id="inf276"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft276">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula>, despite the short presentation time of only 5 ms (<xref ref-type="fig" rid="fig4">Figure 4c1</xref>). The approximation is due to the fact that the NLA learns an instantaneous mapping from the low-pass filtered input rates <inline-formula><alternatives><mml:math id="inf277"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft277">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> to the output voltage <inline-formula><alternatives><mml:math id="inf278"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft278">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>, while the mapping from the original input rates <inline-formula><alternatives><mml:math id="inf279"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft279">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> to the voltages <inline-formula><alternatives><mml:math id="inf280"><mml:msub><mml:mi>𝒖</mml:mi><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle></mml:msub></mml:math><tex-math id="inft280">\begin{document}$\boldsymbol u_{\boldsymbol 1}$\end{document}</tex-math></alternatives></inline-formula> of the first-layer neurons (and hence also to the output voltages <inline-formula><alternatives><mml:math id="inf281"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft281">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>) is delayed by <inline-formula><alternatives><mml:math id="inf282"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft282">\begin{document}$\tau_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>. Since in the simulations, the target voltages <inline-formula><alternatives><mml:math id="inf283"><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft283">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula> were switched instantaneously with <inline-formula><alternatives><mml:math id="inf284"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft284">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> (and not with <inline-formula><alternatives><mml:math id="inf285"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft285">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>), however, a mismatch error between <inline-formula><alternatives><mml:math id="inf286"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft286">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf287"><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft287">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula> remains for stimulus presentation times shorter than <inline-formula><alternatives><mml:math id="inf288"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft288">\begin{document}$\tau_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4c2</xref>). The Latent Equilibrium (<xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>) avoids these temporal limitations by implementing an instantaneous mapping on the rates instead on the voltages (Methods, Sect. From implicit to explicit differential equations).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>On-the-fly learning of finger responses to visual input with real-time dendritic error propagation (rt-DeEP).</title><p>(<bold>a</bold>) Functionally feedforward network with handwritten digits as visual input (<inline-formula><alternatives><mml:math id="inf289"><mml:mrow><mml:msubsup><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft289">\begin{document}$\boldsymbol r_{{\text{in}}}^{(2)}(t)$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="fig" rid="fig3">Figure 3a</xref>, here from the MNIST data set, 5 ms presentation time per image), backprojections enabling credit assignment, and activity of the 10 output neurons interpreted as commands for the 10 fingers (forward architecture: 784×500×10 neurons). (<bold>b</bold>) Example voltage trace (<bold>b1</bold>) and local error (<bold>b2</bold>) of a hidden neuron in neuronal least-action (NLA) (red) compared to an equivalent network without lookahead rates (orange). Note that neither network achieves a steady state due to the extremely short input presentation times. Errors are calculated via exact backpropagation, i.e., by using the error backpropagation algorithm on a pure feedforward NLA network at every simulation time step (with output errors scaled by <inline-formula><alternatives><mml:math id="inf290"><mml:mi>β</mml:mi></mml:math><tex-math id="inft290">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>), shown for comparison (blue dots). (<bold>c</bold>) Comparison of network models during and after learning. Color scheme as in (<bold>b</bold>). (<bold>c1</bold>) The test error under NLA evolves during learning on par with classical error backpropagation performed each Euler <inline-formula><alternatives><mml:math id="inf291"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft291">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula> based on the feedforward activities. In contrast, networks without lookahead rates are incapable of learning such rapidly changing stimuli. (<bold>c2</bold>) With increasing presentation time, the performance under NLA further improves, while networks without lookahead rates stagnate at high error rates. This is caused by transient, but long-lasting misrepresentation of errors following stimulus switches: when plasticity is turned off during transients and is only active in the steady state, comparably good performance can be achieved (dashed orange). (<bold>d</bold>) Receptive fields of 6 hidden-layer neurons after training, demonstrating that even for very brief image presentation times (5ms), the combined neuronal and synaptic dynamics are capable of learning useful feature extractors such as edge filters.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89674-fig4-v2.tif"/></fig><p>The instantaneous voltage propagation relieves an essential constraint of previous models of bio-plausible error backpropagation (e.g. <xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>; <xref ref-type="bibr" rid="bib102">Whittington and Bogacz, 2017</xref>; <xref ref-type="bibr" rid="bib78">Sacramento et al., 2018</xref>), with reviews (<xref ref-type="bibr" rid="bib76">Richards et al., 2019</xref>; <xref ref-type="bibr" rid="bib103">Whittington and Bogacz, 2019</xref>; <xref ref-type="bibr" rid="bib59">Lillicrap et al., 2020</xref>): without lookahead firing rates, networks need much longer to correctly propagate errors across layers, with each layer roughly adding another membrane time constant of 10 ms, and thus cannot cope with realistic input presentation times. In fact, in networks without lookahead output, learning is only successful if plasticity is switched off while the network dynamics did not reach a stationary state during a stimulus presentation interval (<xref ref-type="fig" rid="fig4">Figure 4c2</xref>). Notice also that the prospective coding is necessary to keep the network activity stable for an instantaneous processing of the sensory input. If, in the absence of prospective coding, we would only shrink the membrane time constant to 0, the recurrent error processing would become unstable (see Appendix 3).</p></sec><sec id="s2-8"><title>Implementation in cortical microcircuits</title><p>So far, we did not specify how errors <inline-formula><alternatives><mml:math id="inf292"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft292">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula> appearing in the differential equation for the voltage (<xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>) are transmitted across the network in a biologically plausible manner. Building on <xref ref-type="bibr" rid="bib78">Sacramento et al., 2018</xref>, we propose a cortical microcircuit to enable this error transport, with all neuron dynamics evolving according to the NLA principle. Although the idea applies to arbitrarily connected networks, we use the simpler case of functionally feedforward networks to illustrate the flow of information in these microcircuits (<xref ref-type="fig" rid="fig5">Figure 5a</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Hierarchical plastic microcircuits implement real-time dendritic error learning (rt-DeEL).</title><p>(<bold>a</bold>) Microcircuit with ‘top-down’ input (originating from peripheral motor activity, blue line) that is explained away by the lateral input via interneurons (dark red), with the remaining activity representing the error <inline-formula><alternatives><mml:math id="inf293"><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft293">\begin{document}$\bar e_{l}$\end{document}</tex-math></alternatives></inline-formula>. Plastic connections are denoted with a small red arrow and nudging with a dashed line. (<bold>b1</bold>) Simulated network with 784-300-10 pyramidal-neurons and a population of 40 interneurons in the hidden layer used for the MNIST learning task where the handwritten digits have to be associated with the 10 fingers. (<bold>b2</bold>) Test errors for rt-DeEL with joint tabula rasa learning of the forward and lateral weights of the microcircuit. A similar performance is reached as with classical error backpropagation. For comparability, we also show the performance of a shallow network (dashed line). (<bold>b3</bold>) Angle derived from the Frobenius norm between the lateral pathway <inline-formula><alternatives><mml:math id="inf294"><mml:mrow><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft294">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}\boldsymbol{W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> and the feedback pathway <inline-formula><alternatives><mml:math id="inf295"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft295">\begin{document}$\boldsymbol B_{l}\boldsymbol W_{l+1}$\end{document}</tex-math></alternatives></inline-formula>. During training, both pathways align to allow correct credit assignment throughout the network. Indices are dropped in the axis label for readability.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89674-fig5-v2.tif"/></fig><p>For such an architecture, pyramidal neurons in area <inline-formula><alternatives><mml:math id="inf296"><mml:mi>l</mml:mi></mml:math><tex-math id="inft296">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> (that is a ‘layer’ of the feedforward network) are accompanied by a pool of interneurons in the same layer (area). The dendrites of the interneurons integrate in time (with time constant <inline-formula><alternatives><mml:math id="inf297"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft297">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula>) lateral input from pyramidal neurons of the same layer (<inline-formula><alternatives><mml:math id="inf298"><mml:msub><mml:mi>𝒓</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft298">\begin{document}$\boldsymbol r_{l}$\end{document}</tex-math></alternatives></inline-formula>) through plastic weights <inline-formula><alternatives><mml:math id="inf299"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft299">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>. Additionally, interneurons receive ‘top-down nudging’ from pyramidal neurons in the next layer through randomly initialized and fixed back projecting synapses <inline-formula><alternatives><mml:math id="inf300"><mml:msub><mml:msup><mml:mi>𝑩</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft300">\begin{document}$\boldsymbol{B^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> targeting the somatic region, and interneuron nudging strength <inline-formula><alternatives><mml:math id="inf301"><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup></mml:math><tex-math id="inft301">\begin{document}${\beta^\text{I}}$\end{document}</tex-math></alternatives></inline-formula>. The notion of ‘top-down’ originates from the functionally feed-forward architecture leading from sensory to ‘higher cortical areas.’ In the context of motor control, the highest ‘area’ is the last stage controlling the muscle lengths, being at the same time the first stage for the proprioceptive input (<xref ref-type="fig" rid="fig3">Figure 3a</xref>).</p><p>According to the biophysics of the interneuron, the somatic membrane potential becomes a convex combination of the two types of afferent input (<xref ref-type="bibr" rid="bib97">Urbanczik and Senn, 2014</xref>),<disp-formula id="equ10"><label>(9)</label><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup></mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle \boldsymbol{u^{\text{I}}}_{l}= (1 -{\beta^\text{I}}) \boldsymbol{W^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{l}+{\beta^\text{I}}\boldsymbol{B^{\text{IP}}}_{l}\boldsymbol u_{{{l\!+\!1}}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>In the biological implementation, the feedback input is mediated by the low-pass filtered firing rates <inline-formula><alternatives><mml:math id="inf302"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft302">\begin{document}${\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}= \rho(\boldsymbol u_{{{l\!+\!1}}})$\end{document}</tex-math></alternatives></inline-formula>, not by <inline-formula><alternatives><mml:math id="inf303"><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft303">\begin{document}$\boldsymbol u_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> as expressed in the above equation. Yet, we argue that for a threshold-linear <inline-formula><alternatives><mml:math id="inf304"><mml:mi>ρ</mml:mi></mml:math><tex-math id="inft304">\begin{document}$\rho$\end{document}</tex-math></alternatives></inline-formula> the ‘top-down nudging’ by the rate <inline-formula><alternatives><mml:math id="inf305"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft305">\begin{document}${\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> is effectively reduced to a nudging by the voltage <inline-formula><alternatives><mml:math id="inf306"><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft306">\begin{document}$\boldsymbol u_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>. This is because errors are only backpropagated when the slope of the transfer function is positive, <inline-formula><alternatives><mml:math id="inf307"><mml:mrow><mml:msubsup><mml:mi>𝒓</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft307">\begin{document}$\boldsymbol r'_{{{l\!+\!1}}} \gt 0$\end{document}</tex-math></alternatives></inline-formula>, and hence when the upper-layer voltage is in the linear regime. For more general transfer functions, we argue that short-term synaptic depression may invert the low-pass filtered presynaptic rate back to the presynaptic membrane potential, <inline-formula><alternatives><mml:math id="inf308"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft308">\begin{document}${\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}\to \boldsymbol u_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>, provided that the recovery time constant <inline-formula><alternatives><mml:math id="inf309"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft309">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> matches the membrane time constant (see end of Results and Appendix 1).</p><p>Apical dendrites of pyramidal neurons in each layer receive top-down input from the pyramidal population in the upper layer through synaptic weights <inline-formula><alternatives><mml:math id="inf310"><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft310">\begin{document}$\boldsymbol B_{l}$\end{document}</tex-math></alternatives></inline-formula>. These top-down weights could be learned to predict the lower-layer activity (<xref ref-type="bibr" rid="bib74">Rao and Ballard, 1999</xref>) or to become the transposed of the forward weight matrix (<inline-formula><alternatives><mml:math id="inf311"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup></mml:mrow></mml:math><tex-math id="inft311">\begin{document}$\boldsymbol B_{l}= \boldsymbol W_{l\!+\!1}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula>, <xref ref-type="bibr" rid="bib61">Max et al., 2022</xref>), but for simplicity, we randomly initialized them and keep them fixed (<xref ref-type="bibr" rid="bib59">Lillicrap et al., 2020</xref>). Besides the top-down projections, the apical dendrites also receive lateral input via an interneuron population in the same layer through synaptic weights <inline-formula><alternatives><mml:math id="inf312"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft312">\begin{document}$-\boldsymbol{W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> that are plastic and will be learned to obtain suitable dendritic errors. The ‘-’ sign is suggestive of these interneurons to subtract away the top-down input entering through <inline-formula><alternatives><mml:math id="inf313"><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft313">\begin{document}$\boldsymbol B_{l}$\end{document}</tex-math></alternatives></inline-formula> (while the weights can still be positive or negative). Assuming again a conversion of rates to voltages, also for the inhibitory neurons that may operate in a linear regime, the overall apical voltage becomes<disp-formula id="equ11"><label>(10)</label><alternatives><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle \bar{\boldsymbol{e}}_{l}^{A}= \boldsymbol B_{l}\boldsymbol u_{{{l\!+\!1}}}- \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{u^{\text{I}}}_{l}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>What cannot be explained away from the top-down input <inline-formula><alternatives><mml:math id="inf314"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft314">\begin{document}$\boldsymbol B_{l}\boldsymbol u_{l+1}$\end{document}</tex-math></alternatives></inline-formula> by the lateral feedback, <inline-formula><alternatives><mml:math id="inf315"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft315">\begin{document}$- \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{u^{\text{I}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, remains as dendritic prediction error <inline-formula><alternatives><mml:math id="inf316"><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:math><tex-math id="inft316">\begin{document}${\bar{\boldsymbol{ e }}}_{l}^{A}$\end{document}</tex-math></alternatives></inline-formula> in the apical tree (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). If the top-down and lateral feedback weights are learned as outlined next, these apical prediction errors take the role of the backpropagated errors in the classical backprop algorithm.</p><p>To adjust the interneuron circuit in each layer (‘area’), the synaptic strengths from pyramidal-to-interneurons, <inline-formula><alternatives><mml:math id="inf317"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft317">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, are learned to minimize the interneuron mismatch energy, <inline-formula><alternatives><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">P</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft318">\begin{document}$E^{\mathrm{IP}}_{l}= \frac{1}{2}\| \boldsymbol{u^{\text{I}}_{l}}- \boldsymbol{W^{\text{IP}}_{l}}\boldsymbol{\bar{r}_{l}}\|^{2}$\end{document}</tex-math></alternatives></inline-formula>. The interneurons, while being driven by the lateral inputs <inline-formula><alternatives><mml:math id="inf319"><mml:mrow><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft319">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}\boldsymbol{\bar{r}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, learn to reproduce the upper-layer activity that also nudges the interneuron voltage. Learning is accomplished if the upper-layer activity, in the absence of an additional error on the upper layer, is fully reproduced in the interneurons by the lateral input.</p><p>Once the interneurons learn to represent the ‘error-free’ upper-layer activity, they can be used to explain away the top-down activities that also project to the apical trees. The synaptic strengths from the inter-to-pyramidal neurons, <inline-formula><alternatives><mml:math id="inf320"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft320">\begin{document}$\boldsymbol{W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, are learned to minimize the apical mismatch energy, <inline-formula><alternatives><mml:math id="inf321"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft321">\begin{document}$E^{\mathrm{PI}}_{l}= \frac{1}{2}\| \bar{\boldsymbol{e}}_{l}^{A}\|^{2}= \frac{1}{2}\| \boldsymbol B_{l}\boldsymbol u_{l+1}- \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{u^{\text{I}}}_{l}\|^{2}$\end{document}</tex-math></alternatives></inline-formula>. While in the absence of an upper-layer error, the top-down activity <inline-formula><alternatives><mml:math id="inf322"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft322">\begin{document}$\boldsymbol B_{l}\boldsymbol u_{l+1}$\end{document}</tex-math></alternatives></inline-formula> can be fully cancelled by the interneuron activity <inline-formula><alternatives><mml:math id="inf323"><mml:mrow><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft323">\begin{document}$\boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{u^{\text{I}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, a neuron-specific error will remain in the apical dendrites of the lower-level pyramidal neurons if there is an error endowed in the upper-layer neurons. Gradient descent learning on these two energies results in the learning rules for the P-to-I and I-to-P synapses,<disp-formula id="equ12"><label>(11)</label><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mtext>I</mml:mtext><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle \boldsymbol{\dot{W}}^{\text{IP}}_{l}= \eta^{\text{IP}}\left(\boldsymbol{u}^{\text{I}}_{l}- \boldsymbol{W}^{\text{IP}}_{l}\boldsymbol{\bar{r}}_{l}\right) \, \bar{\boldsymbol{r}}_{l}^{\text{T}}\quad \text{and}\quad \boldsymbol{\dot{W}}^{\text{PI}}_{l}= \eta^{\text{PI}}\left(\boldsymbol{B}_{l}\boldsymbol{u}_{l+1}- \boldsymbol{W}^{\text{PI}}_{l}\boldsymbol{u}^{\text{I}}_{l}\right) \boldsymbol{u}^{\text I^{\text T}}_{l}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>The following theorem on dendritic error learning tells that the plasticity in the lateral feedback loop leads to an appropriate error representation in the apical dendrites of pyramidal neurons.</p></sec><sec id="s2-9"><title>Theorem 2 (real-time dendritic error learning, rt-DeEL)</title><p>Consider a cortical microcircuit composed of pyramidal and interneurons, as illustrated in <xref ref-type="fig" rid="fig5">Figure 5a</xref>, with more interneurons in layer (‘cortical area’) <inline-formula><alternatives><mml:math id="inf324"><mml:mi>l</mml:mi></mml:math><tex-math id="inft324">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> than pyramidal neurons in layer <inline-formula><alternatives><mml:math id="inf325"><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft325">\begin{document}$l\!+\!1$\end{document}</tex-math></alternatives></inline-formula>, and with adaptable pyramidal-to-inhibitory weights <inline-formula><alternatives><mml:math id="inf326"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft326">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> within the same layer that are nudged through top-down weights <inline-formula><alternatives><mml:math id="inf327"><mml:msub><mml:msup><mml:mi>𝑩</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft327">\begin{document}$\boldsymbol{B^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, see Methods, Sect. Proving theorem 2 (rt-DeEL). Then, for suitable top-down nudging, learning rates, and initial conditions, the inhibitory-to-pyramidal synapses <inline-formula><alternatives><mml:math id="inf328"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft328">\begin{document}$\boldsymbol{W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> within each layer <inline-formula><alternatives><mml:math id="inf329"><mml:mi>l</mml:mi></mml:math><tex-math id="inft329">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="equ12">Equation 11</xref>) evolve such that the lateral feedback circuit aligns with the bottom-up-top-down feedback circuit,<disp-formula id="equ13"><label>(12)</label><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{W^{\text{IP}}}_{l}= \boldsymbol B_{l}\boldsymbol W_{{{l\!+\!1}}}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>After this horizontal-to-vertical circuit alignment, the apical voltages <inline-formula><alternatives><mml:math id="inf330"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft330">\begin{document}$\bar{\boldsymbol{e}}_{l}^{A}= \boldsymbol B_{l}\boldsymbol u_{{{l\!+\!1}}}- \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{u^{\text{I}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> of the layer-<inline-formula><alternatives><mml:math id="inf331"><mml:mi>l</mml:mi></mml:math><tex-math id="inft331">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> pyramidal neurons (<xref ref-type="disp-formula" rid="equ14">Equation 13</xref>) represent the ‘<inline-formula><alternatives><mml:math id="inf332"><mml:mi>B</mml:mi></mml:math><tex-math id="inft332">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula>-backpropagated’ errors, <inline-formula><alternatives><mml:math id="inf333"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft333">\begin{document}$\bar{\boldsymbol{e}}_{l}^{A}= \boldsymbol B_{l}\, \bar{\boldsymbol{e}}_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>. When modulated by the postsynaptic rate derivatives, <inline-formula><alternatives><mml:math id="inf334"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>𝝆</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft334">\begin{document}$\bar{\boldsymbol{r}}'_{l}= \boldsymbol \rho' ({\bar{\boldsymbol{ u }}}_{l})$\end{document}</tex-math></alternatives></inline-formula>, the apical voltages yield the appropriate error signals<disp-formula id="equ14"><label>(13)</label><alternatives><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>⋅</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="t14">\begin{document}$$\displaystyle \bar{\boldsymbol{e}}_{l}= \boldsymbol{u}_{l}- \boldsymbol{W}_{l}\boldsymbol{\bar{r}}_{l-1}= \bar{\boldsymbol{r}}'_{l}\cdot \bar{\boldsymbol{e}}_{l}^{A}= \bar{\boldsymbol{r}}'_{l}\cdot \boldsymbol{B}_{l}\, \bar{\boldsymbol{e}}_{l+1}$$\end{document}</tex-math></alternatives></disp-formula></p><p>for learning the forward weights <inline-formula><alternatives><mml:math id="inf335"><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft335">\begin{document}$\boldsymbol W_{l}$\end{document}</tex-math></alternatives></inline-formula> according to <inline-formula><alternatives><mml:math id="inf336"><mml:mrow><mml:msub><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>∝</mml:mo><mml:mspace width="0.1667em"/><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>−</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft336">\begin{document}$\boldsymbol{\dot W}_{l}\propto \,{\bar{\boldsymbol{ e }}}_{l}\, \boldsymbol{\bar{r}}_{l\!-\!1}^{{\text{T}}}\,$\end{document}</tex-math></alternatives></inline-formula> <xref ref-type="disp-formula" rid="equ9">Equation 8</xref>.</p><p>The back projecting weights can also be learned by a local real-time learning rule to become transpose of the forward weights, <inline-formula><alternatives><mml:math id="inf337"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup></mml:mrow></mml:math><tex-math id="inft337">\begin{document}$\boldsymbol B_{l}= \boldsymbol W_{l\!+\!1}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="bibr" rid="bib61">Max et al., 2022</xref>). In this case, the error signals <inline-formula><alternatives><mml:math id="inf338"><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft338">\begin{document}$\bar{\boldsymbol{e}}_{l}$\end{document}</tex-math></alternatives></inline-formula> learned in the apical dendrites according to the above Theorem (<xref ref-type="disp-formula" rid="equ14">Equation 13</xref>) represent the gradient errors <inline-formula><alternatives><mml:math id="inf339"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft339">\begin{document}$\bar{\boldsymbol{e}}$\end{document}</tex-math></alternatives></inline-formula> appearing in the real-time dendritic error propagation (rt-DeEP, Theorem 1). There, the errors <inline-formula><alternatives><mml:math id="inf340"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft340">\begin{document}$\bar{\boldsymbol{e}}$\end{document}</tex-math></alternatives></inline-formula> drive the gradient plasticity of the general weight matrix <inline-formula><alternatives><mml:math id="inf341"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft341">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula>, split up here into the forward weights <inline-formula><alternatives><mml:math id="inf342"><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft342">\begin{document}$\boldsymbol W_{l}$\end{document}</tex-math></alternatives></inline-formula> to a layer <inline-formula><alternatives><mml:math id="inf343"><mml:mi>l</mml:mi></mml:math><tex-math id="inft343">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> (for <inline-formula><alternatives><mml:math id="inf344"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><tex-math id="inft344">\begin{document}$l=1,..,N$\end{document}</tex-math></alternatives></inline-formula>).</p></sec><sec id="s2-10"><title>Simultaneously learning apical errors and basal signals</title><p>Microcircuits following these neuronal and synaptic dynamics are able to learn the classification of hand-written digits from the MNIST dataset while learning the apical signal representation (<xref ref-type="fig" rid="fig5">Figure 5b1, b2</xref>). In this case, feedforward weights <inline-formula><alternatives><mml:math id="inf345"><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft345">\begin{document}$\boldsymbol W_{l}$\end{document}</tex-math></alternatives></inline-formula> and lateral weights <inline-formula><alternatives><mml:math id="inf346"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft346">\begin{document}$\boldsymbol{W^{PI}}_{l}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf347"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft347">\begin{document}$\boldsymbol{W^{IP}}_{l}$\end{document}</tex-math></alternatives></inline-formula> are all adapted simultaneously. Including the <inline-formula><alternatives><mml:math id="inf348"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:msubsup><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft348">\begin{document}$\boldsymbol{\dot {W^{IP}_{l}}}$\end{document}</tex-math></alternatives></inline-formula>-plasticity (by turning on the interneuron nudging from the upper layer, <inline-formula><alternatives><mml:math id="inf349"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>&gt;</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft349">\begin{document}${\beta^\text{I}}\! \gt \!0$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="equ10">Equation 9</xref>), greatly speeds up the learning.</p><p>With and without <inline-formula><alternatives><mml:math id="inf350"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:msubsup><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft350">\begin{document}$\boldsymbol{\dot{W^{IP}_{l}}}$\end{document}</tex-math></alternatives></inline-formula>-plasticity, the lateral feedback via interneurons (with effective weight <inline-formula><alternatives><mml:math id="inf351"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft351">\begin{document}$\boldsymbol{W^{{IP}}}_{l}\boldsymbol{W^{{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>) learns to align with the forward-backward feedback via upper layer pyramidal neurons (with effective weight <inline-formula><alternatives><mml:math id="inf352"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft352">\begin{document}$\boldsymbol B_{l}\boldsymbol W_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>, <xref ref-type="fig" rid="fig5">Figure 5b3</xref>). The microcircuit extracts the gradient-based errors (<xref ref-type="disp-formula" rid="equ14">Equation 13</xref>), while the forward weights use these errors to reduce these errors to first minimize the neuron-specific mismatch errors, and eventually the output cost.</p><p>Since the apical voltage <inline-formula><alternatives><mml:math id="inf353"><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:math><tex-math id="inft353">\begin{document}$\bar{\boldsymbol{e}}_{l}^{A}$\end{document}</tex-math></alternatives></inline-formula> appears as a postsynaptic factor in the plasticity rule for the interneurons (<inline-formula><alternatives><mml:math id="inf354"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">I</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft354">\begin{document}$\boldsymbol{\dot {W^{{PI}}_{l}}}$\end{document}</tex-math></alternatives></inline-formula>), this I-to-P plasticity can be interpreted as Hebbian plasticity of inhbitory neurons, consistent with earlier suggestions (<xref ref-type="bibr" rid="bib101">Vogels et al., 2011</xref>; <xref ref-type="bibr" rid="bib7">Bannon et al., 2020</xref>). The plasticity <inline-formula><alternatives><mml:math id="inf355"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft355">\begin{document}$\boldsymbol{\dot {W^{{IP}}_{l}}}$\end{document}</tex-math></alternatives></inline-formula> of the P-to-I synapses, in the same way as the plasticity for the forward synapses <inline-formula><alternatives><mml:math id="inf356"><mml:msub><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft356">\begin{document}$\boldsymbol{\dot W}_{l}$\end{document}</tex-math></alternatives></inline-formula>, can be interpreted as learning from the dendritic prediction of somatic activity (<xref ref-type="bibr" rid="bib97">Urbanczik and Senn, 2014</xref>).</p><p>Crucially, by choosing a large enough interneuron population, the simultaneous learning of the lateral microcircuit and the forward network can be accomplished without fine-tuning of parameters. As an instance in case, all weights shared the same learning rate. Such stability bolsters the biophysical plausibility of our NLA framework and improves over the previous, more heuristic approach (<xref ref-type="bibr" rid="bib78">Sacramento et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Mesnard et al., 2019</xref>). The stability may be related to the nested gradient descent learning according to which somatic and apical mismatch errors in pyramidal neurons, and somatic mismatch errors in inhibitory neurons are minimized.</p><p>Finally, since errors are defined at the level of membrane voltages (<xref ref-type="disp-formula" rid="equ12">Equation 11</xref>), synapses need a mechanism by which they can recover the presynaptic voltage errors from their afferent firing rates. While for threshold-linear transfer functions the backpropagated voltage errors translate into rate errors (Appendix 1), more general neuronal nonlinearities must be matched by corresponding synaptic nonlinearities. <xref ref-type="bibr" rid="bib72">Pfister et al., 2010</xref> have illustrated how spiking neurons can leverage short-term synaptic depression to estimate the membrane potential of their presynaptic partners. Here, we assume a similar mechanism in the context of our rate-based neurons. The monotonically increasing neuronal activation function, <inline-formula><alternatives><mml:math id="inf357"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft357">\begin{document}${\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}= \rho(\boldsymbol u_{{{l\!+\!1}}})$\end{document}</tex-math></alternatives></inline-formula>, can be approximately compensated by a vesicle release probability that monotonically decreases with the low-pass filtered presynaptic rate <inline-formula><alternatives><mml:math id="inf358"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft358">\begin{document}${\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> (see Appendix 1 and <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). If properly matched, this leads to a linear relationship between the presynaptic membrane potential <inline-formula><alternatives><mml:math id="inf359"><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft359">\begin{document}$\boldsymbol u_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> and the postsynaptic voltage contribution.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We introduced a least-action principle to neuroscience for deriving the basic laws of the voltage and synaptic dynamics in networks of cortical neurons. The approach is inspired by the corresponding principle in physics where basic laws of motion are derived across the various scales. While in physics the action is defined as the time-integral of the kinetic minus potential energy, we define the action as the time-integral of instantaneous somatodendritic mismatch errors across network neurons plus a behavioral error. The ‘kinetics’ of a voltage trajectory only arises because we postulate that the action along a trajectory is minimized with respect to future voltages, not the instantaneous voltage, as would be done in physics. The postulate implies a prospective voltage dynamics that look ahead in time, together with prospective local errors, in order to minimize the action and hence the somatodendritic mismatch errors. The prospective errors nudge the firing of pyramidal neurons deep in the brain, so that motor neurons improve the output of the network right in time. A putative behavioral error, encoded in the motor feedback, propagates back through the network and produces prospective corrections of the pyramidal neuron activities that effectively manifest in instantaneous corrections of the motor trajectory. Through this prospective coding, the sensory stream, the deep network activity, and the motor feedback are in sync at any moment in time. We formulated the dynamic synchronization as a ‘moving equilibrium hypothesis’, referring to the classical equilibrium point hypothesis for motor control (<xref ref-type="bibr" rid="bib28">Feldman and Levin, 2009</xref>; <xref ref-type="bibr" rid="bib54">Latash, 2010</xref>). More generally, the brain activity formed by the prospective firing of cortical pyramidal neurons is in a moving equilibrium while converting sensory input streams into motor outputs, consistent with prospective sensory processing in the human cortex (<xref ref-type="bibr" rid="bib12">Blom et al., 2020</xref>).</p><p>Because the neuronal dynamics derived from the global NLA principle is in a moving equilibrium, the prospective dendritic errors that globally correct the output trajectory are also suited to instruct local synapatic plasticity in the dendrites. In fact, working down the apical errors by adapting the sensory-driven synapses on the basal dendrites reduces the global output errors in real time. The apical errors are extracted from the top-down feedback via lateral ‘inhibition’ that tries to cancel the top-down signal. This top-down feedback includes activity from a putative erroneous motor output that was not foreseen by the local inhibition and thus survives as a local apical error. Given the prospective coding of the pyramidal neurons, the dendritic errors are also prospective and thus able to induce the correct error-minimizing plasticity online, while stimuli and targets continuously change.</p><sec id="s3-1"><title>The NLA principle as a bottom-up theory from neurons to behavior</title><p>To show that the NLA principle offers a viable program for a formalization of neuroscience following the example of physics, we exemplified its ramifications in dendritic computation, cortical microcircuits, synaptic plasticity, motor control, and sensory-based decision-making. The crucial point of our axiomatization is that it connects the local neuronal errors to the global behavioral errors right in the formulation of the principle, eventually leading to local gradient-based plasticity rules. Because the formulation builds upon computations that can be realized in single neurons and dendrites to produce a behavioral output, the NLA principle can be seen as a bottom-up theory of behavior. It is articulated in terms of apical and basal dendrites, somatic firing, network connectivity and behavioral outputs that jointly minimize their errors. This contrasts the related free energy principle, for instance, that leads to a top-down theory of behavior by starting with the statistical, but the more universal, notion of a free energy. It postulates that any self-organizing system, that is at a statistical equilibrium with its environment, must minimize its free energy (<xref ref-type="bibr" rid="bib34">Friston, 2010</xref>; <xref ref-type="bibr" rid="bib35">Friston et al., 2022</xref>), and from there work down its way to neurons and dendrites (<xref ref-type="bibr" rid="bib9">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Kiebel and Friston, 2011</xref>).</p><p>Starting with a single Lagrangian function that specifies the form of the somatodendritic prediction errors leaves some freedom for the interpretation and the implementation of the emerging dynamical equations for the voltages. We interpret errors to be represented in the apical dendrites of pyramidal neurons while sensory input targets the basal dendrites, but other dendritic configurations are conceivable (<xref ref-type="bibr" rid="bib66">Mikulasch et al., 2023</xref>) that apply also to non-pyramidal neurons. We have chosen a specific interneuron circuitry to extract our apical errors, but other microcircuits or error representations might also be considered (<xref ref-type="bibr" rid="bib48">Keller and Mrsic-Flogel, 2018</xref>). On the other hand, the derived gradient-based synaptic plasticity is tightly linked to the specific form of the somatodendritic prediction errors expressed in the Lagrangian and its interpretation, making specific predictions for synaptic plasticity (as outlined below). The ‘external’ feedback entering through the cost function offers additional freedom to model behavioral interactions. We considered an explicit time course of a target voltage in motor neurons, for instance imposed by the feedback from muscle spindles that are themselves innervated by a prospective top-down signal to control muscle lengths (<xref ref-type="bibr" rid="bib70">Papaioannou and Dimitriou, 2021</xref>; <xref ref-type="bibr" rid="bib26">Dimitriou, 2022</xref>). But the cost may also link to reinforcement learning and express a delayed reward feedback delivered upon a behavioral decision of an agent acting in a changing environment (<xref ref-type="bibr" rid="bib32">Friedrich et al., 2011</xref>; <xref ref-type="bibr" rid="bib33">Friedrich and Senn, 2012</xref>).</p><p>A fundamental difficulty arises when the neuronal implementation of the Euler-Lagrange equations requires an additional microcircuit with its own dynamics. This is the case for the suggested microcircuit extracting the local errors. Formally, the representation of the apical feedback errors first needs to be learned before the errors can teach the feedforward synapses on the basal dendrites. We showed that this error learning can itself be formulated as minimizing an apical mismatch energy. What the lateral feedback through interneurons cannot explain away from the top-down feedback remains an apical prediction error. Ideally, while the network synapses targetting the basal tree are performing gradient descent on the global cost, the microcircuit synapses involved in the lateral feedback are performing gradient descent on local error functions, both at any moment in time. The simulations show that this intertwined system can in fact learn simultaneously with a common learning rate that is properly tuned. The cortical model network of inter- and pyramidal neurons learned to classify handwritten digits on the fly, with 10-digit samples presented per second. Yet, the overall learning is more robust if the error learning in the apical dendrites operates in phases without output teaching but with corresponding sensory activity, as may arise during sleep (see e.g., <xref ref-type="bibr" rid="bib22">Deperrois et al., 2022</xref>; <xref ref-type="bibr" rid="bib23">Deperrois et al., 2024</xref>).</p></sec><sec id="s3-2"><title>The NLA principle integrates classical theories for cortical processing and learning</title><p>The prospective variational principle introduced with the NLA allows for integrating previous ideas on formalizing the processing and learning in cortical networks. Four such classical lines of theories come together. (<inline-formula><alternatives><mml:math id="inf360"><mml:mi>i</mml:mi></mml:math><tex-math id="inft360">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula>) The first line refers to the use of an energy function to jointly infer the neuronal dynamics and synaptic plasticity, originally formulated for discrete-time networks (<xref ref-type="bibr" rid="bib44">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="bib2">Ackley et al., 1985</xref>), and recently extended to continuous-time networks (<xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>). (<inline-formula><alternatives><mml:math id="inf361"><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:math><tex-math id="inft361">\begin{document}$ii$\end{document}</tex-math></alternatives></inline-formula>) The second line refers to understanding error-backpropagation in the brain (<xref ref-type="bibr" rid="bib77">Rumelhart et al., 1986</xref>; <xref ref-type="bibr" rid="bib106">Xie and Seung, 2003</xref>; <xref ref-type="bibr" rid="bib102">Whittington and Bogacz, 2017</xref>; <xref ref-type="bibr" rid="bib103">Whittington and Bogacz, 2019</xref>; <xref ref-type="bibr" rid="bib59">Lillicrap et al., 2020</xref>). (<inline-formula><alternatives><mml:math id="inf362"><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:math><tex-math id="inft362">\begin{document}$iii$\end{document}</tex-math></alternatives></inline-formula>) The third line refers to dendritic computation and the use of dendritic compartmentalization for various functions such as nonlinear processing (<xref ref-type="bibr" rid="bib80">Schiess et al., 2016</xref>; <xref ref-type="bibr" rid="bib73">Poirazi and Papoutsi, 2020</xref>) and deep learning (<xref ref-type="bibr" rid="bib39">Guerguiev et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Sacramento et al., 2018</xref>; <xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>). (<inline-formula><alternatives><mml:math id="inf363"><mml:mrow><mml:mi>i</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:math><tex-math id="inft363">\begin{document}$iv$\end{document}</tex-math></alternatives></inline-formula>) The fourth line refers to <italic>predictive coding</italic> (<xref ref-type="bibr" rid="bib74">Rao and Ballard, 1999</xref>) and active inference (<xref ref-type="bibr" rid="bib71">Pezzulo et al., 2022</xref>) to improve the sensory representation and motor output, respectively.</p><list list-type="simple" id="list2"><list-item><p>(i) With regard to <italic>energy functions</italic>, the NLA principle adds a variational approach to characterize continuous-time neuronal trajectories and plasticity. Variational approaches are studied in the context of optimal control theory where a cost integral is minimized across time, constrained to some network dynamics (<xref ref-type="bibr" rid="bib93">Todorov and Jordan, 2002</xref>; <xref ref-type="bibr" rid="bib63">Meulemans et al., 2021</xref>). The NLA represents a unifying notion that allows us to infer both, the network dynamics and its optimal control from a single Lagrangian. The error we derive represents prospective control variables that are applied to the voltages of each network neuron so that they push the output neurons towards their target trajectory. The full expression power of this control theoretic framework has yet to be proven when it is extended to genuine temporal processing that includes longer time constants, for instance, inherent in a slow threshold adaptation (<xref ref-type="bibr" rid="bib10">Bellec et al., 2020</xref>). The NLA principle can also treat the case of strong feedback studied so far in relaxation networks only (<xref ref-type="bibr" rid="bib64">Meulemans et al., 2022</xref>; <xref ref-type="bibr" rid="bib86">Song et al., 2024</xref>). Our rt-DeEP Theorem makes a statement for real-time gradient descent learning while the network is in a moving equilibrium, linking to motor learning in the presence of perturbing force fields (<xref ref-type="bibr" rid="bib42">Herzfeld et al., 2014</xref>) or perturbing visual inputs (<xref ref-type="bibr" rid="bib25">Dimitriou, 2016</xref>).</p></list-item><list-item><p>(ii) With regard to <italic>error-backpropagation</italic>, the NLA principle infers a local error that originates from the error in the output neurons. In the current version, the NLA relies on feedback alignment (<xref ref-type="bibr" rid="bib58">Lillicrap et al., 2016</xref>) to obtain a local apical error without postulating plasticity in the top-down synapses. Other works have explored learning the feedback weights (<xref ref-type="bibr" rid="bib3">Akrout et al., 2019</xref>; <xref ref-type="bibr" rid="bib51">Kunin et al., 2020</xref>), notably within a phase-less real-time learning framework as considered here (<xref ref-type="bibr" rid="bib61">Max et al., 2022</xref>). It would be promising to combine these ideas to obtain a fully plastic microcircuit that adjusts from scratch to various real-time learning tasks.</p></list-item><list-item><p>(iii) With regard to <italic>dendritic computation</italic>, the NLA principle extends the idea of dendritic error representation (<xref ref-type="bibr" rid="bib78">Sacramento et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Mesnard et al., 2019</xref>) by the prospective coding of both errors and firing rates (<xref ref-type="fig" rid="fig2">Figure 2</xref>). As a consequence, the various dendritic delays are compensated and synaptic plasticity can operate at any moment, without need to wait for network relaxations (<xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>; <xref ref-type="bibr" rid="bib86">Song et al., 2024</xref>). In the present framework, the input rates are low-pass filtered by variable input time constants (<inline-formula><alternatives><mml:math id="inf364"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft364">\begin{document}$\tau_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>) before the induced voltages are instantaneously processed in the network. While this offers the possibilities for a temporal processing of the inputs, step changes in the input rates cannot instantaneously propagate as made possible in <xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>. The dendritic error representation has also been applied to spike-based learning in recurrent networks (<xref ref-type="bibr" rid="bib65">Mikulasch et al., 2021</xref>).</p></list-item><list-item><p><italic>(</italic>iv) With regard to the principle of <italic>predictive coding</italic> (<xref ref-type="bibr" rid="bib74">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="bib71">Pezzulo et al., 2022</xref>), the NLA offers a form of predictive error-coding in the apical tree of sensory pyramidal neurons that shapes the sensory representation. Both the predictive coding and the NLA principle imply an error-based adaptation of the lower and higher cortical representations. However, while predictive coding is based on propagating errors, the NLA principle directly propagates the error-corrected representations. Based on the backpropagated activities, it extracts in each area the prospective errors to reshape the local representations and induce synaptic plasticity. Otherwise, the freedom in defining the cost function in the NLA, and the inclusion of active inference in predictive coding (<xref ref-type="bibr" rid="bib71">Pezzulo et al., 2022</xref>), make the two frameworks equally powerful. Both frameworks can explain the learning from motor and sensory prediction errors. In fact, our example of motor control minimizes the proprioceptive error formed by the target muscle lengths minus the effective muscle lengths. Active inference likewise minimizes the mismatch between an internal motor target and the proprioceptive inputs caused by the own actions. In turn, the cost function in the NLA principle may also capture the sensory prediction errors, where the ground truth lies in the external inputs that are learned to be matched by the sensory expectation. Hence, while being functionally equivalent, the neuronal interpretations are different: predictive coding focuses on the propagation of errors using the sensory- and motor representations as local auxiliary quantities, and the NLA principle directly integrates errors in ‘auxiliary dendrites’ to propagate sensory or motor representations.</p></list-item></list></sec><sec id="s3-3"><title>The NLA integrates and predicts features of synapses, dendrites, and circuits</title><p>Motivated by the predictive power of the least-action principle in physics, we ask about experimental confirmation and predictions of the NLA principle. Given its axiomatic approach, it appears astonishing to find various preliminary matches at the dendritic, somatic, interneuron, synaptic, and even behavioral levels. Some of these are:</p><list list-type="order" id="list3"><list-item><p>the prospective coding of pyramidal neuron firing (<xref ref-type="bibr" rid="bib50">Köndgen et al., 2008</xref>);</p></list-item><list-item><p>the prospective processing of apical signals while propagating to the soma (<xref ref-type="bibr" rid="bib96">Ulrich, 2002</xref>);</p></list-item><list-item><p>the basal synaptic plasticity on pyramidal neurons and synaptic plasticity on interneurons, driven by the postsynaptic activity that is ‘unexplained’ by the distal dendritic voltage (<xref ref-type="bibr" rid="bib97">Urbanczik and Senn, 2014</xref>) – while partly consistent with spike-timing dependent plasticity (<xref ref-type="bibr" rid="bib85">Sjöström et al., 2001</xref>; <xref ref-type="bibr" rid="bib87">Spicher et al., 2017</xref>), the postulated dendritic voltage-dependence of the plasticity rules still awaits an experimental inspection;</p></list-item><list-item><p>the Hebbian homeostatic plasticity of interneurons targeting the apical dendritic tree of pyramidal neurons (<xref ref-type="bibr" rid="bib7">Bannon et al., 2020</xref>);</p></list-item><list-item><p>the short-term synaptic depression at top-down synapses targetting inhibitory neurons and apical dendrites (akin to <xref ref-type="bibr" rid="bib1">Abbott et al., 1997</xref>), but with a faster recovery time constant that invert the presynaptic activation function (see also <xref ref-type="bibr" rid="bib72">Pfister et al., 2010</xref>);</p></list-item><list-item><p>the modulation of the apical contribution to the somatic voltage by the slope of the somatic activation function for instance by downregulating apical NMDA receptors with increasing rate of backpropagating action potentials, <xref ref-type="bibr" rid="bib91">Theis et al., 2018</xref>; and</p></list-item><list-item><p>the involvement of muscle spindles in the prospective encoding of motor errors during motor learning, with the <inline-formula><alternatives><mml:math id="inf365"><mml:mi>γ</mml:mi></mml:math><tex-math id="inft365">\begin{document}$\gamma$\end{document}</tex-math></alternatives></inline-formula>-innervation setting the target length of the spindles (<xref ref-type="bibr" rid="bib25">Dimitriou, 2016</xref>; <xref ref-type="bibr" rid="bib70">Papaioannou and Dimitriou, 2021</xref>; <xref ref-type="bibr" rid="bib99">Vargas et al., 2023</xref>).</p></list-item></list><p>More experimental and theoretical work is required to substantiate these links and test specific predictions, such as the apical error representation in cortical pyramidal neurons.</p><p>Overall, our approach adapts the least-action principle from physics to be applied to neuroscience, and couples it with a normative perspective on the prospective processing of neurons and synapses in global cortical networks and local microcircuits. Given its physical underpinnings, the approach may inspire the rebuilding of computational principles of cortical neurons and circuits in neuromorphic hardware (<xref ref-type="bibr" rid="bib8">Bartolozzi et al., 2022</xref>). A step in this direction, building on the instantaneous computational capabilities by slowly integrating neurons, has made done by <xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>. Given its aspiration for a theoretical framework in neurobiology, a next challenge would be to generalize the NLA principle to spiking neurons (<xref ref-type="bibr" rid="bib36">Gerstner and Kistler, 2002</xref>; <xref ref-type="bibr" rid="bib14">Brendel et al., 2020</xref>) with their potential for hardware implementation (<xref ref-type="bibr" rid="bib107">Zenke and Ganguli, 2018</xref>; <xref ref-type="bibr" rid="bib37">Göltz et al., 2021</xref>; <xref ref-type="bibr" rid="bib21">Cramer et al., 2022</xref>), to include attentional mechanisms in terms of dendritic gain modulation (<xref ref-type="bibr" rid="bib53">Larkum et al., 2004</xref>) with a putative link to self-attention in artificial intelligence (<xref ref-type="bibr" rid="bib100">Vaswani et al., 2017</xref>), to add second-order errors to cope with certainties (<xref ref-type="bibr" rid="bib38">Granier et al., 2023</xref>), and to incorporate longer temporal processing as, for instance, offered by neuronal adaptation processes (<xref ref-type="bibr" rid="bib52">La Camera et al., 2006</xref>) or realistically modelled dendrites (<xref ref-type="bibr" rid="bib18">Chavlis and Poirazi, 2021</xref>).</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Euler-Lagrange equations as inverse low-pass filters</title><p>The theory is based on the look-ahead of neuronal quantities. In general, the look-ahead of a trajectory <inline-formula><alternatives><mml:math id="inf366"><mml:mrow><mml:mi>x</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft366">\begin{document}$x(t)$\end{document}</tex-math></alternatives></inline-formula> is defined via lookahead operator applied to <inline-formula><alternatives><mml:math id="inf367"><mml:mi>x</mml:mi></mml:math><tex-math id="inft367">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ15"><label>(14)</label><alternatives><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t15">\begin{document}$$\displaystyle {\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}x = x + \tau \dot x. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The lookahead operator is the inverse of the low-pass filter operator denoted by a bar,<disp-formula id="equ16"><label>(15)</label><alternatives><mml:math id="m16"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mi>x</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t16">\begin{document}$$\displaystyle \bar x(t) = \frac{1}{\tau}\int_{-\infty}^{t}\! x(t') e^{-\frac{t-t'}{\tau}}\mathrm{d}t' \;. $$\end{document}</tex-math></alternatives></disp-formula></p><p>This low-pass filtering can also be characterized by the differential equation <inline-formula><alternatives><mml:math id="inf368"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>x</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft368">\begin{document}$\tau \dot{\bar{x}}(t) = - \bar{x}(t) + x(t)$\end{document}</tex-math></alternatives></inline-formula>, see Appendix 2. Hence, applying the low-pass filtering to <inline-formula><alternatives><mml:math id="inf369"><mml:mi>x</mml:mi></mml:math><tex-math id="inft369">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula> and then the lookahead operator <inline-formula><alternatives><mml:math id="inf370"><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow></mml:math><tex-math id="inft370">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf371"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft371">\begin{document}$\bar x(t)$\end{document}</tex-math></alternatives></inline-formula>, and using the Leibnitz rule for differentiating an integral, we calculate <inline-formula><alternatives><mml:math id="inf372"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft372">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\bar{x}(t) = x(t)$\end{document}</tex-math></alternatives></inline-formula>. In turn, applying first the lookahead, and then the low-pass filtering, also yields the original trace back, <inline-formula><alternatives><mml:math id="inf373"><mml:mrow><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math><tex-math id="inft373">\begin{document}$\overline{{\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)} x}= \bar x + \tau \dot{\bar{x}}= x$\end{document}</tex-math></alternatives></inline-formula>.</p><p>We consider an arbitrary network architecture with network neurons that are recurrently connected and that receive external input through an overall weight matrix <inline-formula><alternatives><mml:math id="inf374"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft374">\begin{document}$\boldsymbol W = (\boldsymbol W_{{\text{in}}}, \boldsymbol W_{{{\!\text{net}}}})$\end{document}</tex-math></alternatives></inline-formula>, aggregated column-wise. The instantaneous presnyaptic firing rates are <inline-formula><alternatives><mml:math id="inf375"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft375">\begin{document}$\boldsymbol r = (\boldsymbol r_{{\text{in}}}, \boldsymbol r_{{{\!\text{net}}}})^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula>, interpreted as a single-column vector. A subset of network neurons are output neurons, <inline-formula><alternatives><mml:math id="inf376"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi><mml:mo>⊆</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow></mml:math><tex-math id="inft376">\begin{document}${\mathcal{O}}\subseteq{\mathcal{N}}$\end{document}</tex-math></alternatives></inline-formula>, for which target voltages <inline-formula><alternatives><mml:math id="inf377"><mml:msup><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:math><tex-math id="inft377">\begin{document}$\boldsymbol u^{*}$\end{document}</tex-math></alternatives></inline-formula> may be imposed. Rates and voltages may change in time <inline-formula><alternatives><mml:math id="inf378"><mml:mi>t</mml:mi></mml:math><tex-math id="inft378">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>. Network neurons are assigned a voltage <inline-formula><alternatives><mml:math id="inf379"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft379">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, generating the low-pass filtered rate <inline-formula><alternatives><mml:math id="inf380"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft380">\begin{document}${\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}= \rho(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, and a low-pass filtered error <inline-formula><alternatives><mml:math id="inf381"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft381">\begin{document}${\bar{\boldsymbol{ e }}}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula>. We further define output errors <inline-formula><alternatives><mml:math id="inf382"><mml:mrow><mml:msubsup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft382">\begin{document}${\bar{e}}^{*}_{o}= u^{*}_{o}- u_{o}$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf383"><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi></mml:mrow></mml:math><tex-math id="inft383">\begin{document}$o\in{\mathcal{O}}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf384"><mml:mrow><mml:msubsup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft384">\begin{document}${\bar{e}}^{*}_{i}= 0$\end{document}</tex-math></alternatives></inline-formula> for non-output neurons <inline-formula><alternatives><mml:math id="inf385"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo>∖</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi></mml:mrow></mml:math><tex-math id="inft385">\begin{document}$i \in{\mathcal{N}}\setminus{\mathcal{O}}$\end{document}</tex-math></alternatives></inline-formula>. With this, the Lagrangian from <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> takes the form<disp-formula id="equ17"><label>(16)</label><alternatives><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t17">\begin{document}$$\displaystyle L= \frac{1}{2}\|{\bar{\boldsymbol{ e }}}\|^{2}+ \frac{\beta}{2}\|{\bar{\boldsymbol{ e }}}^{*}\|^{2}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>We next use that <inline-formula><alternatives><mml:math id="inf386"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft386">\begin{document}$\boldsymbol u = \boldsymbol{\tilde{u}}- \tau \boldsymbol{\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>, with the <inline-formula><alternatives><mml:math id="inf387"><mml:mover><mml:mi>.</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft387">\begin{document}$\tilde .$\end{document}</tex-math></alternatives></inline-formula> operator defined in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>, to write out the Lagrangian <inline-formula><alternatives><mml:math id="inf388"><mml:mi>L</mml:mi></mml:math><tex-math id="inft388">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> in the canonical coordinates <inline-formula><alternatives><mml:math id="inf389"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft389">\begin{document}$(\boldsymbol{\tilde{u}},\boldsymbol{\dot{{\tilde{u}}}})$\end{document}</tex-math></alternatives></inline-formula> as (see also <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>)<disp-formula id="equ18"><label>(17)</label><alternatives><mml:math id="m18"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:msup><mml:mrow><mml:mo fence="true" form="prefix">[</mml:mo><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mstyle scriptlevel="0" displaystyle="false"><mml:mo movablelimits="false" lspace="0em" rspace="0em">∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:msup><mml:mrow><mml:mo fence="true" form="prefix">[</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>o</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>o</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t18">\begin{document}$$\displaystyle  {L}= \frac{1}{2}\sum_{i\in{\mathcal{N}}}\left[{\tilde{u}}_{i}- \tau{\dot{{\tilde{u}}}}_{i}-{\textstyle\sum}_{j}{W_{ij}}\rho({\tilde{u}}_{j}- \tau{\dot{{\tilde{u}}}}_{j}) \right]^{2}+ \frac{\beta}{2}\sum_{o\in{\mathcal{O}}}\left[ u_{o}^{*}- ({\tilde{u}}_{o}- \tau{\dot{{\tilde{u}}}}_{o}) \right]^{2}\,. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The neuronal dynamics is derived from requiring a stationary action (see <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>), which is generally solved by the Euler-Lagrange equations <inline-formula><alternatives><mml:math id="inf390"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft390">\begin{document}$\frac{ \partial {L}}{\partial{\tilde{u}}_{i}}- \frac{{\text{d}}}{{\text{d}} t}\frac{ \partial {L}}{\partial{\dot{{\tilde{u}}}}_{i}}= 0$\end{document}</tex-math></alternatives></inline-formula> (see <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>). Because <inline-formula><alternatives><mml:math id="inf391"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft391">\begin{document}${\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> only arises in <inline-formula><alternatives><mml:math id="inf392"><mml:mi>L</mml:mi></mml:math><tex-math id="inft392">\begin{document}${L}$\end{document}</tex-math></alternatives></inline-formula> in the compound <inline-formula><alternatives><mml:math id="inf393"><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft393">\begin{document}${\tilde{u}}- \tau{\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>, the derivative of <inline-formula><alternatives><mml:math id="inf394"><mml:mi>L</mml:mi></mml:math><tex-math id="inft394">\begin{document}${L}$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf395"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft395">\begin{document}${\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> is identical to the derivative with respect to <inline-formula><alternatives><mml:math id="inf396"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft396">\begin{document}$\tau{\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ19"><label>(18)</label><alternatives><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t19">\begin{document}$$\displaystyle \frac{\partial {L}}{\partial{\dot{{\tilde{u}}}}_{i}}= -\tau \frac{\partial {L}}{\partial{\tilde{u}}_{i}}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Using the lookahead operator <xref ref-type="disp-formula" rid="equ15">Equation 14</xref>, the Euler-Lagrange equations can then be rewritten as<disp-formula id="equ20"><label>(19)</label><alternatives><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow></mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t20">\begin{document}$$\displaystyle \frac{\partial {L}}{\partial{\tilde{u}}_{i}}+ \tau \frac{{\text{d}}}{{\text{d}} t}\frac{\partial {L}}{\partial{\tilde{u}}_{i}}={\Big(1 + \tau \frac{{\text{d}}}{{\text{d}} t} \Big)}\frac{\partial {L}}{\partial{\tilde{u}}_{i}}= 0. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Since <inline-formula><alternatives><mml:math id="inf397"><mml:mrow><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft397">\begin{document}${L}(\boldsymbol{\tilde{u}},\boldsymbol{\dot{{\tilde{u}}}}) = L(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf398"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft398">\begin{document}$\boldsymbol u = \boldsymbol{\tilde{u}}- \tau \boldsymbol{\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>, the derivative of <inline-formula><alternatives><mml:math id="inf399"><mml:mi>L</mml:mi></mml:math><tex-math id="inft399">\begin{document}${L}$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf400"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover></mml:math><tex-math id="inft400">\begin{document}$\boldsymbol{\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> is the same as the derivative of <inline-formula><alternatives><mml:math id="inf401"><mml:mi>L</mml:mi></mml:math><tex-math id="inft401">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf402"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft402">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ21"><alternatives><mml:math id="m21"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:math><tex-math id="t21">\begin{document}$$\displaystyle \frac{\partial {L}}{\partial{\tilde{u}}_{i}}= \frac{\partial L}{\partial u_{i}}\,.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Plugging this into <xref ref-type="disp-formula" rid="equ20">Equation 19</xref>, the Euler-Lagrange equations become a function of <inline-formula><alternatives><mml:math id="inf403"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft403">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf404"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft404">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ22"><label>(20)</label><alternatives><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow></mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t22">\begin{document}$$\displaystyle {\Big(1 + \tau \frac{{\text{d}}}{{\text{d}} t} \Big)}\frac{\partial L}{\partial u_{i}}= 0. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Notice that, if we had directly calculated <inline-formula><alternatives><mml:math id="inf405"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft405">\begin{document}$\frac{ \partial {L}}{\partial{\tilde{u}}_{i}}- \frac{{\text{d}}}{{\text{d}} t}\frac{ \partial {L}}{\partial{\dot{{\tilde{u}}}}_{i}}= 0$\end{document}</tex-math></alternatives></inline-formula>, the second-order time derivative <inline-formula><alternatives><mml:math id="inf406"><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft406">\begin{document}$\ddot{\tilde{u}}_{i}$\end{document}</tex-math></alternatives></inline-formula> of the discounted future voltage would be absorbed in a first-order time derivative of the voltage. The reason is that <inline-formula><alternatives><mml:math id="inf407"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft407">\begin{document}$\dot{\tilde{u}}_{i}- \tau \ddot{\tilde{u}}_{i}= \dot u_{i}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf408"><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft408">\begin{document}$\ddot{\tilde{u}}_{i}$\end{document}</tex-math></alternatives></inline-formula> only arises in this combination because the Lagrangian <inline-formula><alternatives><mml:math id="inf409"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft409">\begin{document}$L=L(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> is only a function of <inline-formula><alternatives><mml:math id="inf410"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft410">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> and not of <inline-formula><alternatives><mml:math id="inf411"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft411">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>. Hence, the acceleration term <inline-formula><alternatives><mml:math id="inf412"><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft412">\begin{document}$\ddot{\tilde{u}}_{i}$\end{document}</tex-math></alternatives></inline-formula> disappears, while a voltage derivative <inline-formula><alternatives><mml:math id="inf413"><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft413">\begin{document}$\dot u_{i}$\end{document}</tex-math></alternatives></inline-formula> appears.</p><p>The solution of this differential <xref ref-type="disp-formula" rid="equ22">Equation 20</xref> is <inline-formula><alternatives><mml:math id="inf414"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft414">\begin{document}$\frac{\partial L}{\partial u_{i}}= c_{i}\, e^{-\frac{t-t_{0}}{\tau}}$\end{document}</tex-math></alternatives></inline-formula>, and hence any trajectory <inline-formula><alternatives><mml:math id="inf415"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft415">\begin{document}$(\tilde u_{i}, \dot{\tilde u}_{i})$\end{document}</tex-math></alternatives></inline-formula> which satisfy the Euler-Lagrange equations will hence cause <inline-formula><alternatives><mml:math id="inf416"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><tex-math id="inft416">\begin{document}$\frac{\partial L}{\partial u_{i}}$\end{document}</tex-math></alternatives></inline-formula> to converge to zero with a characteristic time scale of <inline-formula><alternatives><mml:math id="inf417"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft417">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula>. Since we require that the initialisation is at <inline-formula><alternatives><mml:math id="inf418"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>=</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft418">\begin{document}$t_{0}\!=\! -\infty$\end{document}</tex-math></alternatives></inline-formula>, we conclude that <inline-formula><alternatives><mml:math id="inf419"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft419">\begin{document}$\frac{\partial L}{\partial u_{i}}= 0$\end{document}</tex-math></alternatives></inline-formula>, as required in the rt-DeEP Theorem. For a table with all the mathematical abbreviations see Methods-<xref ref-type="table" rid="table1">Table 1</xref>.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Mathematical symbols.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Mathematical expression</th><th align="left" valign="bottom">Naming</th><th align="left" valign="bottom">Comment</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf420"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft420">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Instantaneous (somatic) voltage</td><td align="left" valign="bottom">only for network neurons</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf421"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft421">\begin{document}$r_{i}=\rho(u_{i})+\tau\dot{\rho}(u_{i})$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Instantaneous firing rate of neuron <italic>i</italic></td><td align="left" valign="bottom">that looks linearly ahead in time</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf422"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mpadded width="-1.7pt"><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msubsup></mml:mpadded><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">d</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft422">\begin{document}$\bar{r}(t)=\frac{1}{\tau}\int_{-\infty}^{t}\!r(t^{\prime})e^{-\frac{t-t^{\prime}}{\tau}}\mathrm{d}t^{\prime}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Definition of low-pass filtering</td><td align="left" valign="bottom">See <xref ref-type="disp-formula" rid="equ16">Equation 15</xref></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf423"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>τ</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft423">\begin{document}$\bar{r}_{i}=\rho(u_{i})=\overline{r_{i}+\tau\,\dot{r}_{i}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Low-pass filtered firing rate</td><td align="left" valign="bottom">postulated to be a function of <inline-formula><alternatives><mml:math id="inf424"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft424">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf425"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft425">\begin{document}$\bm{r}=\bm{\bar{r}}+\tau\bm{\dot{\bar{r}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Self-consistency eq.</td><td align="left" valign="bottom">for low-pass filtered rate</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf426"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft426">\begin{document}$\bm{r}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Input rate vector, column</td><td align="left" valign="bottom">projects to selected neurons</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf427"><mml:msub><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft427">\begin{document}$\bar{\bm{r}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Low-pass filter input rates</td><td align="left" valign="bottom">instantaneously propagates</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf428"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mo>∑</mml:mo></mml:mstyle></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft428">\begin{document}$ e_{i}=(u_{i}+\tau\dot{u}_{i})-{\textstyle\sum}_{j}{W_{ij}}r_{j}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Prospective error of neuron<italic>i</italic></td><td align="left" valign="bottom">in apical dendrite</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf429"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mo>∑</mml:mo></mml:mstyle></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft429">\begin{document}$ {\bar{e}}_{i}=u_{i}-{\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Error of neuron<italic>i</italic></td><td align="left" valign="bottom">in soma</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf430"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mo>∑</mml:mo></mml:mstyle></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft430">\begin{document}$ {E^{\text{M}}}_{i}=\tfrac{1}{2}{{\bar{e}}_{i}}^{\,2}=\tfrac{1}{2}\big{(}u_{i}-{\textstyle\sum}_{j}{W_{ij}}{\bar{r}}_{j}\big{)}^{2}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Mismatch energy in neuron <italic>i</italic></td><td align="left" valign="bottom">between soma and basal dendrite</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf431"><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:math><tex-math id="inft431">\begin{document}$u_{o}^{*}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Target voltage for output neuron <italic>o</italic></td><td align="left" valign="bottom">could impose target on <inline-formula><alternatives><mml:math id="inf432"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft432">\begin{document}$r_{o}$\end{document}</tex-math></alternatives></inline-formula> <break/>or <inline-formula><alternatives><mml:math id="inf433"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft433">\begin{document}$\bar{r}_{o}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf434"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>o</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math><tex-math id="inft434">\begin{document}${\bar{e}}_{o}^{*}=u_{o}^{*}-u_{o}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Error of output neuron <italic>o</italic></td><td align="left" valign="bottom">also called target error</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf435"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>o</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math><tex-math id="inft435">\begin{document}$C_{o}=\tfrac{1}{2}({\bar{e}}_{o}^{*})^{2}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Cost contribution of output neuron <italic>o</italic></td><td align="left" valign="bottom">between soma and basal dendrite</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf436"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">O</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft436">\begin{document}$L=\sum_{i\in{\mathcal{N}}}{E^{\text{M}}}_{i}+\beta\sum_{o\in{\mathcal{O}}}C_{o}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Lagrangian</td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf437"><mml:mrow><mml:mrow><mml:mtext>output </mml:mtext><mml:mo>⁢</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi></mml:mrow><mml:mo>⊂</mml:mo><mml:mrow><mml:mtext>network </mml:mtext><mml:mo>⁢</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft437">\begin{document}$\text{output }{\mathcal{O}}\subset\text{network }{\mathcal{N}}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf438"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mi>t</mml:mi><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝒆</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mtext>d</mml:mtext><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft438">\begin{document}${\tilde{u}}(t)=\frac{1}{\tau}\int_{t}^{\infty}u(t^{\prime}){\bm{e}}^{(t-t^{\prime})/\tau}{\text{d}}t^{\prime}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Discounted future voltage</td><td align="left" valign="bottom">prospective coordinates for NLA</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf439"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold" stretchy="false">~</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold" stretchy="false">~</mml:mo></mml:mover><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft439">\begin{document}$\bm{u}=\bm{\tilde{u}}-\tau\bm{\dot{\tilde{u}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Self-consistency eq.</td><td align="left" valign="bottom">for discounted future voltage</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf440"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msubsup><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold" stretchy="false">~</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold" stretchy="false">~</mml:mo></mml:mover><mml:mo mathvariant="bold">˙</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mtext>d</mml:mtext><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft440">\begin{document}$A=\int_{t_{1}}^{t_{2}}{L}\left[\bm{\tilde{u}}(t),\bm{\dot{{\tilde{u}}}}(t)\right]{\text{d}}t$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Neuronal Least Action (NLA)</td><td align="left" valign="bottom">expressed in prospect. coordinates</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf441"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mover accent="true"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mfrac><mml:mo>∂</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft441">\begin{document}$\frac{\partial{L}}{\partial{\tilde{u}}_{i}}-\frac{{\text{d}}}{{\text{d}}t}\frac{\partial{L}}{\partial{\dot{{\tilde{u}}}}_{i}}=\big{(}1+\tfrac{{\text{d}}}{{\text{d}}t}\big{)}\tfrac{\partial}{\partial u_{i}}L=0$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Euler-Lagrange equations</td><td align="left" valign="bottom">turned into lookahead operator</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf442"><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft442">\begin{document}$\bm{W}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">weights from input neurons <inline-formula><alternatives><mml:math id="inf443"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft443">\begin{document}$\bm{r}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="char" char="." valign="bottom"><inline-formula><alternatives><mml:math id="inf444"><mml:mrow><mml:mrow><mml:mrow><mml:mtext>dim</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mtext>dim</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft444">\begin{document}$\text{dim}({\mathcal{N}})\times\text{dim}(\bm{r}_{{\text{in}}})$\end{document}</tex-math></alternatives></inline-formula><break/>, most0</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf445"><mml:msub><mml:mi>𝑾</mml:mi><mml:mpadded lspace="-1.7pt" width="-1.7pt"><mml:mtext>net</mml:mtext></mml:mpadded></mml:msub></mml:math><tex-math id="inft445">\begin{document}$\bm{W}_{{{\!\text{net}}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">weights between network neurons</td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf446"><mml:mrow><mml:mrow><mml:mrow><mml:mtext>dim</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mtext>dim</mml:mtext></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft446">\begin{document}$\text{dim}({\mathcal{N}})\times\text{dim}({\mathcal{N}})$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf447"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mpadded lspace="-1.7pt" width="-1.7pt"><mml:mtext>net</mml:mtext></mml:mpadded></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft447">\begin{document}$\bm{W}=(\bm{W}_{{\text{in}}},\bm{W}_{{{\!\text{net}}}})$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">total weight matrix</td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf448"><mml:mrow><mml:mrow><mml:mtext>dim</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:mtext>dim</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mtext>dim</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft448">\begin{document}$\text{dim}({\mathcal{N}})\times\big{(}\text{dim}(\bm{r}_{{\text{in}}})+\text{dim}({\mathcal{N}})\big{)}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf449"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mpadded lspace="-1.7pt" width="-1.7pt"><mml:mtext>net</mml:mtext></mml:mpadded></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft449">\begin{document}$\bm{r}=(\bm{r}_{{\text{in}}},\bm{r}_{{{\!\text{net}}}})^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">instantaneous firing rate vector</td><td align="left" valign="bottom">column (indicated by transpose)</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf450"><mml:mrow><mml:mover accent="true"><mml:mi>𝑾</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover><mml:mo>∝</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mover accent="true"><mml:mi>𝒆</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:mrow></mml:math><tex-math id="inft450">\begin{document}$\bm{\dot{W}}\propto{\bar{\bm{e}}}\,{\bar{\bm{r}}}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Plasticity of <inline-formula><alternatives><mml:math id="inf451"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft451">\begin{document}$\bm{W}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf452"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft452">\begin{document}$\bar{\mathbf{e}}$\end{document}</tex-math></alternatives></inline-formula> <break/>is a column, <inline-formula><alternatives><mml:math id="inf453"><mml:msup><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>T</mml:mtext></mml:msup></mml:math><tex-math id="inft453">\begin{document}${\bar{\bm{r}}}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> a row vector</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf454"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>𝑭</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft454">\begin{document}$\bm{u}^{*}_{\bm{o}}(t)=\bm{F}^{*}(\overline{\bm{r}}_{{\text{in}}}(t))$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Target function formulated for <inline-formula><alternatives><mml:math id="inf455"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft455">\begin{document}$\overline{{r}}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">a functional of <inline-formula><alternatives><mml:math id="inf456"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft456">\begin{document}$\bm{r}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf457"><mml:mrow><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>𝒆</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft457">\begin{document}$\bm{u}_{\bm{o}}(t)=\bm{F}_{W}(\bm{\bar{r}}_{{\text{in}}}(t),{\bar{\bm{e}}}_{\bm{o}}^{*}(t))$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Func. implemented by forward network</td><td align="left" valign="bottom">instant. func. of <inline-formula><alternatives><mml:math id="inf458"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft458">\begin{document}$\bm{\bar{r}}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula><break/> , not <inline-formula><alternatives><mml:math id="inf459"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft459">\begin{document}$\bm{r}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf460"><mml:mi>N</mml:mi></mml:math><tex-math id="inft460">\begin{document}$N$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Layers in forward network, w/o <inline-formula><alternatives><mml:math id="inf461"><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft461">\begin{document}$r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Last-layer voltages:<inline-formula><alternatives><mml:math id="inf462"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft462">\begin{document}$\bm{u}_{N}=\bm{u_{o}}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf463"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft463">\begin{document}$W^{IP}_{l}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Weights from pyr to interneurons</td><td align="left" valign="bottom">lateral, within layer <italic>l</italic></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf464"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft464">\begin{document}$W^{PI}_l$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Weights from inter- to pyr’neurons</td><td align="left" valign="bottom">lateral, within layer <italic>l</italic></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf465"><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft465">\begin{document}$\bm{W}_{l}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Bottom-up weights from layerl–1<break/> to<italic>l</italic></td><td align="left" valign="bottom">between pyramidal neurons</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf466"><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft466">\begin{document}$\bm{B}_{l}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Top-down weights from layerl+1<break/> to<italic>l</italic></td><td align="left" valign="bottom">between pyramidal neurons</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf467"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft467">\begin{document}$\bar{{e}}_{l}^{A}={B}_{l}{u}_{{{l\!+\!1}}}-{W^{\text{PI}}}_{l}{u^{\text{I}}}_{l}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Low-pass filtered apical error in layer<italic>l</italic></td><td align="left" valign="bottom">top-down minus lateral feedback</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf468"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft468">\begin{document}$\bar{{e}}_{l}=\bar{{r}}^{\prime}_{l}{\cdot}\bar{{e}}_{l}^{A}=\bar{{r}}^{\prime}_{l}{\cdot}{B}_{l}\,\bar{{e}}_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Somato-basal prediction error</td><td align="left" valign="bottom">is correct error for learning</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf469"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">P</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft469">\begin{document}$E^{\mathrm{IP}}_{l}=\frac{1}{2}\|\boldsymbol{u^{\text{I}}}_{l}-\boldsymbol{W^{\text{IP}}}_{l}\boldsymbol{\bar{r}}_{l}\|^{2}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Interneuron mismatch energy</td><td align="left" valign="bottom">minimized to learn <inline-formula><alternatives><mml:math id="inf470"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft470">\begin{document}$W^{IP}_{l}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf471"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft471">\begin{document}$E^{\mathrm{PI}}_{l}=\frac{1}{2}\|{B}_{l}{u}_{l+1}-{W^{\text{PI}}}_{l}{u^{\text{I}}}_{l}\|^{2}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Apical mismatch energy</td><td align="left" valign="bottom">minimized to learn <inline-formula><alternatives><mml:math id="inf472"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft472">\begin{document}$W^{PI}_{l}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf473"><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo rspace="5.3pt">,</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>η</mml:mi><mml:mtext>IP</mml:mtext></mml:msup></mml:mpadded><mml:mo rspace="5.3pt">,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mtext>PI</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft473">\begin{document}$\eta\,,\;{\eta^{\text{IP}}}\,,\;{\eta^{\text{PI}}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Learning rates for plasticity of…</td><td align="left" valign="bottom">…<inline-formula><alternatives><mml:math id="inf474"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo>;</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>;</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft474">\begin{document}${W}_{l}\,;{W^{IP}_{l}}\,;{W^{PI}_{l}}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf475"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msup><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mn>𝟏</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>𝑾</mml:mi><mml:mpadded lspace="-1.7pt" width="-1.7pt"><mml:mtext>net</mml:mtext></mml:mpadded></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝝆</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>𝒆</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math><tex-math id="inft475">\begin{document}$\bm{H}=\frac{\partial^{2}L}{\partial\bm{u}^{2}}=\bm{1}-\bm{W}_{{{\!\text{net}}}}\bm{\rho}^{\prime}-{\bar{\bm{e}}}^{\prime}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Hessian,<inline-formula><alternatives><mml:math id="inf476"><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:msup><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft476">\begin{document}$\frac{\partial^{2}L}{\partial\bm{u}^{2}}=\frac{\partial\bm{f}}{\partial\bm{u}}$\end{document}</tex-math></alternatives></inline-formula>. If pos. definite</td><td align="left" valign="bottom">⇒ stable dynamics</td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf477"><mml:mrow><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>𝒓</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>𝒆</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft477">\begin{document}$\bm{f}(\bm{u},t)=\frac{\partial L}{\partial\bm{u}}=\bm{u}-\bm{W}{\bar{\bm{r}}}(\bm{u})-{\bar{\bm{e}}}(\bm{u})$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Corrected error</td><td align="left" valign="bottom">becomes 0<break/> with <inline-formula><alternatives><mml:math id="inf478"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft478">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf479"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>𝒇</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft479">\begin{document}$\bm{f}(\bm{u},t)+\tau\bm{\dot{f}}(\bm{u},t)=0$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Euler-Lagrange equations</td><td align="left" valign="bottom">satisfy <inline-formula><alternatives><mml:math id="inf480"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft480">\begin{document}${f}({u},t)={f}_{0}\,e^{-(t-t_{0})/\tau}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf481"><mml:mrow><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft481">\begin{document}$\bm{f}(\bm{u},t)=0$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Always the case after transient</td><td align="left" valign="bottom">exponentially decaying with <inline-formula><alternatives><mml:math id="inf482"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft482">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf483"><mml:mrow><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝑯</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft483">\begin{document}$\bm{\dot{u}}=-\frac{1}{\tau}\bm{H}^{-1}(\bm{u})\left(\bm{f}(\bm{u})+\tau\frac{\partial\bm{f}}{\partial t}\right)$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Explicit diff. eq.</td><td align="left" valign="bottom">obtained by solving for <inline-formula><alternatives><mml:math id="inf484"><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:math><tex-math id="inft484">\begin{document}$\dot{\bm{u}}$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf485"><mml:mrow><mml:mrow><mml:mi>𝒈</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝑯</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft485">\begin{document}$\bm{g}(\bm{u},t)=-\frac{1}{\tau}\bm{H}^{-1}(\bm{u})\left(\bm{f}(\bm{u})+\tau\frac{\partial\bm{f}}{\partial t}\right)$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Used to write the explicit diff. eq.</td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf486"><mml:mrow><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mi>𝒈</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft486">\begin{document}$\bm{\dot{u}}=\bm{g}(\bm{u},t)$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf487"><mml:mrow><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝒚</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mo>⁡</mml:mo><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>𝒇</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft487">\begin{document}$\bm{G}(\bm{y},\dot{\bm{u}})={\big{(}1+\tau\tfrac{{\text{d}}}{{\text{d}}t}\big{)}}\frac{\partial L}{\partial\bm{u}}=\bm{f}+\tau\dot{\bm{f}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Used for contraction anaylsis, <xref ref-type="disp-formula" rid="equ61">Equation 53</xref></td><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf488"><mml:mrow><mml:mi>𝒚</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft488">\begin{document}$\bm{y}=(\bm{r}_{{\text{in}}},\bm{u}_{\bm{o}}^{*},\bm{u})$\end{document}</tex-math></alternatives></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf489"><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>𝑴</mml:mi></mml:mpadded><mml:mo rspace="5.3pt">,</mml:mo><mml:mi>𝑲</mml:mi></mml:mrow></mml:math><tex-math id="inft489">\begin{document}$\bm{M}\,,\;\bm{K}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Used to iteratively converge to<inline-formula><alternatives><mml:math id="inf490"><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:math><tex-math id="inft490">\begin{document}$\bm{\dot{u}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">see <xref ref-type="disp-formula" rid="equ54">Equation 46</xref></td></tr><tr><td align="left" valign="bottom"><inline-formula><alternatives><mml:math id="inf491"><mml:mrow><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold">˘</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>𝒖</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="inft491">\begin{document}$\bm{\breve{u}}=\bm{u}+\tau\bm{\dot{u}}$\end{document}</tex-math></alternatives></inline-formula></td><td align="left" valign="bottom">Linear lookahead voltage</td><td align="left" valign="bottom">Latent Equilibrium, Appendix 4</td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>Deriving the network dynamics from the Euler-Lagrange equations</title><p>We now derive the equations of motion from the Euler-Lagrange equations. Noticing that <inline-formula><alternatives><mml:math id="inf492"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft492">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> enters in <inline-formula><alternatives><mml:math id="inf493"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft493">\begin{document}${\bar{\boldsymbol{ e }}}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}\,$\end{document}</tex-math></alternatives></inline-formula> twice, directly and through <inline-formula><alternatives><mml:math id="inf494"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft494">\begin{document}${\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}= \rho(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, and once in the output error <inline-formula><alternatives><mml:math id="inf495"><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:math><tex-math id="inft495">\begin{document}${\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, we calculate from 16, using <inline-formula><alternatives><mml:math id="inf496"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft496">\begin{document}$\boldsymbol{\bar{r}}(\boldsymbol u) =({\bar{\boldsymbol{ r }}}_{{\text{in}}}, \rho(\boldsymbol u))^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf497"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft497">\begin{document}$\boldsymbol W = (\boldsymbol W_{{\text{in}}}, \boldsymbol W_{{{\!\text{net}}}})$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ23"><label>(21)</label><alternatives><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:mtext> with </mml:mtext><mml:mspace width="thickmathspace"/><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t23">\begin{document}$$\displaystyle \frac{\partial L}{\partial \boldsymbol u}={\bar{\boldsymbol{ e }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}\;, \; \text{ with }\;{\bar{\boldsymbol{ \epsilon }}}={\bar{\boldsymbol{ r }}}'_{{{\!\text{net}}}}{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Remember that for non-output neurons <italic>i</italic> no target exists, and for those we set <inline-formula><alternatives><mml:math id="inf498"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft498">\begin{document}${\bar{\boldsymbol{ e }}}^{*}_{i}= 0$\end{document}</tex-math></alternatives></inline-formula>. Next, we apply the lookahead operator to this expression, as required by the Euler-Lagrange <xref ref-type="disp-formula" rid="equ20">Equation 19</xref>. In general <inline-formula><alternatives><mml:math id="inf499"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math><tex-math id="inft499">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}{\bar{\boldsymbol{ x }}}={\bar{\boldsymbol{ x }}}+ \tau \dot{{\bar{\boldsymbol{ x }}}}= x$\end{document}</tex-math></alternatives></inline-formula>, and we set for <inline-formula><alternatives><mml:math id="inf500"><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft500">\begin{document}${\bar{\boldsymbol{ x }}}$\end{document}</tex-math></alternatives></inline-formula> the expression on the right-hand side of <xref ref-type="disp-formula" rid="equ23">Equation 21</xref>, <inline-formula><alternatives><mml:math id="inf501"><mml:mrow><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft501">\begin{document}${\bar{\boldsymbol{ x }}}={\bar{\boldsymbol{ e }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, which at the same time is <inline-formula><alternatives><mml:math id="inf502"><mml:mrow><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft502">\begin{document}${\bar{\boldsymbol{ x }}}= \frac{\partial L}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>. Hence, the Euler-Lagrange equations in the form of <xref ref-type="disp-formula" rid="equ22">Equation 20</xref>, <inline-formula><alternatives><mml:math id="inf503"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft503">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\bar x = 0$\end{document}</tex-math></alternatives></inline-formula>, translate into<disp-formula id="equ24"><label>(22)</label><alternatives><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟺</mml:mo><mml:mspace width="thickmathspace"/><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thickmathspace"/><mml:mo stretchy="false">⟺</mml:mo><mml:mspace width="thickmathspace"/><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t24">\begin{document}$$\displaystyle \Big(1 + \tau \frac{\text{d}}{\text{d} t}\Big) \frac{\partial L}{\partial \boldsymbol{u}}= 0 \; \Longleftrightarrow \; \boldsymbol{e}- \boldsymbol{\epsilon}- \beta \boldsymbol{e}^{*}= 0 \; \Longleftrightarrow \; \tau \boldsymbol{\dot{u}}= - \boldsymbol{u}+ \boldsymbol{W}\boldsymbol{r}+ \boldsymbol{e}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>To move from the middle to the last equality we replaced <inline-formula><alternatives><mml:math id="inf504"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft504">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula> with  <inline-formula><alternatives><mml:math id="inf505"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi></mml:mrow></mml:math><tex-math id="inft505">\begin{document}$\boldsymbol e ={\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}{\bar{\boldsymbol{ e }}}= \boldsymbol u + \tau \boldsymbol{\dot u}- \boldsymbol W \boldsymbol r$\end{document}</tex-math></alternatives></inline-formula>. In the last equality we interpret <inline-formula><alternatives><mml:math id="inf506"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft506">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula> as the sum of the two errors, <inline-formula><alternatives><mml:math id="inf507"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo>=</mml:mo><mml:mi>𝝐</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi>𝒆</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft507">\begin{document}$\boldsymbol e = \boldsymbol \epsilon + \beta \boldsymbol e^{*}$\end{document}</tex-math></alternatives></inline-formula>, again using the middle equality. This proves <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref>.</p><p>Notice that the differential equation <inline-formula><alternatives><mml:math id="inf508"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi></mml:mrow></mml:math><tex-math id="inft508">\begin{document}$\tau \boldsymbol{\dot u}= ...$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="equ24">Equation 22</xref> represents an implicit ordinary differential equation as on the right-hand side not only <inline-formula><alternatives><mml:math id="inf509"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft509">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, but also <inline-formula><alternatives><mml:math id="inf510"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft510">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula> appears (in <inline-formula><alternatives><mml:math id="inf511"><mml:mi>𝒓</mml:mi></mml:math><tex-math id="inft511">\begin{document}$\boldsymbol r$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf512"><mml:mi>𝒆</mml:mi></mml:math><tex-math id="inft512">\begin{document}$\boldsymbol e$\end{document}</tex-math></alternatives></inline-formula>). The uniqueness of the solution <inline-formula><alternatives><mml:math id="inf513"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft513">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula> for a given initial condition is only guaranteed if it can be converted into an explicit ordinary differential equation (see Sect. Appendix 3).</p><p>In taking the temporal derivative we assumed small learning rates such that terms including <inline-formula><alternatives><mml:math id="inf514"><mml:msub><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft514">\begin{document}$\dot{W}_{ij}$\end{document}</tex-math></alternatives></inline-formula> can be neglected. The derived dynamics for the membrane potential of a neuron <inline-formula><alternatives><mml:math id="inf515"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft515">\begin{document}$u_{i}$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="equ24">Equation 22</xref> show the usual leaky behavior of biological neurons. However, both presynaptic rates <inline-formula><alternatives><mml:math id="inf516"><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft516">\begin{document}$\bar{r}_{i}$\end{document}</tex-math></alternatives></inline-formula> and prediction errors <inline-formula><alternatives><mml:math id="inf517"><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft517">\begin{document}$\bar{e}_{i}$\end{document}</tex-math></alternatives></inline-formula> enter the equation of motion with lookaheads, i.e., they are advanced (<inline-formula><alternatives><mml:math id="inf518"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft518">\begin{document}$r_{i}= \bar{r}_{i}+ \tau \dot{\bar{r}}_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf519"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft519">\begin{document}$e_{i}= \bar{e}_{i}+ \tau \dot{\bar{e}}_{i}$\end{document}</tex-math></alternatives></inline-formula>), cancelling the low-pass filtering. Since <inline-formula><alternatives><mml:math id="inf520"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft520">\begin{document}$\dot{\bar{r}}_{i}= \rho'(u_{i}) \, \dot u_{i}$\end{document}</tex-math></alternatives></inline-formula>, the rate and error, <inline-formula><alternatives><mml:math id="inf521"><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft521">\begin{document}$r_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf522"><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft522">\begin{document}$e_{i}$\end{document}</tex-math></alternatives></inline-formula>, can also be seen as nonlinear extrapolations from the voltage and its derivative into the future.</p><p>The instantaneous transmission of information throughout the network at the level of the voltages can now be seen by low-pass filtering <xref ref-type="disp-formula" rid="equ24">Equation 22</xref> with initialization far back in the past,<disp-formula id="equ25"><label>(23)</label><alternatives><mml:math id="m25"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;"><mml:mi>𝒖</mml:mi></mml:mtd><mml:mtd class="tml-left" style="padding:0.7ex 0em 0.7ex 0em;"><mml:mrow><mml:mo>=</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:mo>+</mml:mo><mml:mi>𝒆</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mspace width="0.2778em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t25">\begin{document}$$\displaystyle \boldsymbol{u}= \overline{\boldsymbol{u} + \tau \boldsymbol{\dot{u}}}= \overline{\boldsymbol{W} \boldsymbol{r} + \boldsymbol{e}}= \boldsymbol{W}\boldsymbol{\bar{r}}(\boldsymbol{u}) + \boldsymbol{\bar{e}}\; ,$$\end{document}</tex-math></alternatives></disp-formula></p><p>with column vector <inline-formula><alternatives><mml:math id="inf523"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft523">\begin{document}$\boldsymbol{\bar{r}}(\boldsymbol u) =({\bar{\boldsymbol{ r }}}_{{\text{in}}}, \rho(\boldsymbol u))^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf524"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft524">\begin{document}$\boldsymbol{\bar{e}}={\bar{\boldsymbol{ r }}}'_{{{\!\text{net}}}}{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}+ \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>. Hence, solving the voltage dynamics for <inline-formula><alternatives><mml:math id="inf525"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft525">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>), with apical voltage <inline-formula><alternatives><mml:math id="inf526"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft526">\begin{document}$\boldsymbol e ={\bar{\boldsymbol{ e }}}+ \tau \dot{{\bar{\boldsymbol{ e }}}}$\end{document}</tex-math></alternatives></inline-formula> derived from <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref>, yields the somatic voltage <inline-formula><alternatives><mml:math id="inf527"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft527">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> satisfying the self-consistency <xref ref-type="disp-formula" rid="equ25">Equation 23</xref> at any time. In other words, <inline-formula><alternatives><mml:math id="inf528"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft528">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf529"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft529">\begin{document}$\boldsymbol{\bar{e}}$\end{document}</tex-math></alternatives></inline-formula>‘propagate instantaneously’.</p></sec><sec id="s4-3"><title>Deriving the error backpropagation formula</title><p>For clarity, we derive the error backpropagation algorithm for layered networks here. These can be seen as a special case of a general network with membrane potentials <inline-formula><alternatives><mml:math id="inf530"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft530">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> and all-to-all weight matrix <inline-formula><alternatives><mml:math id="inf531"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft531">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> (as introduced in Appendix 8), where the membrane potentials decompose into layerwise membrane potential vectors <inline-formula><alternatives><mml:math id="inf532"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft532">\begin{document}$\boldsymbol u_{l}$\end{document}</tex-math></alternatives></inline-formula> and the weight matrix into according to block diagonal matrices <inline-formula><alternatives><mml:math id="inf533"><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft533">\begin{document}$\boldsymbol W_{l}$\end{document}</tex-math></alternatives></inline-formula> (with <inline-formula><alternatives><mml:math id="inf534"><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft534">\begin{document}$\boldsymbol W_{l}$\end{document}</tex-math></alternatives></inline-formula> being the weights that project into layer <inline-formula><alternatives><mml:math id="inf535"><mml:mi>l</mml:mi></mml:math><tex-math id="inft535">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula>).</p><p>Assuming a network with <inline-formula><alternatives><mml:math id="inf536"><mml:mi>N</mml:mi></mml:math><tex-math id="inft536">\begin{document}$N$\end{document}</tex-math></alternatives></inline-formula> layers, by low-pass filtering the equations of motion we get<disp-formula id="equ26"><label>(24)</label><alternatives><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t26">\begin{document}$$\displaystyle \boldsymbol u_{l}= \boldsymbol W_{l}{\bar{\boldsymbol{ r }}}_{{{l\!-\!1}}}+{\bar{\boldsymbol{ e }}}_{l},$$\end{document}</tex-math></alternatives></disp-formula></p><p>for all <inline-formula><alternatives><mml:math id="inf537"><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><tex-math id="inft537">\begin{document}$l \in 1,..,N$\end{document}</tex-math></alternatives></inline-formula>, with the output error <inline-formula><alternatives><mml:math id="inf538"><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft538">\begin{document}${\bar{\boldsymbol{ e }}}_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> of the general recurrent network becoming the error in the last layer, that itself is the target error, <inline-formula><alternatives><mml:math id="inf539"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>N</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft539">\begin{document}${\bar{\boldsymbol{ e }}}_{\boldsymbol o}={\bar{\boldsymbol{ e }}}_{N}= \beta{\bar{\boldsymbol{ e }}}^{*}= \beta \left(\boldsymbol u^{*}_{N}- \boldsymbol u_{N}\right)$\end{document}</tex-math></alternatives></inline-formula>. The error <inline-formula><alternatives><mml:math id="inf540"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft540">\begin{document}${\bar{\boldsymbol{ e }}}={\bar{\boldsymbol{ \epsilon }}}+ \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, that we obtain from the general dynamics with <inline-formula><alternatives><mml:math id="inf541"><mml:mrow><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft541">\begin{document}${\bar{\boldsymbol{ \epsilon }}}={\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ23 equ24">Equations 21 and 22</xref>, translates to an iterative formula for the error at the current layer <inline-formula><alternatives><mml:math id="inf542"><mml:mi>l</mml:mi></mml:math><tex-math id="inft542">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> given the error at the downstream layer <inline-formula><alternatives><mml:math id="inf543"><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft543">\begin{document}${{l\!+\!1}}$\end{document}</tex-math></alternatives></inline-formula>, inherited from the drive <inline-formula><alternatives><mml:math id="inf544"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft544">\begin{document}${\bar{\boldsymbol{ r }}}_{l}= \rho(\boldsymbol u_{l})$\end{document}</tex-math></alternatives></inline-formula> of that downstream layer via <inline-formula><alternatives><mml:math id="inf545"><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft545">\begin{document}$\boldsymbol W_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ27"><label>(25)</label><alternatives><mml:math id="m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>l</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>N</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t27">\begin{document}$$\displaystyle {\bar{\boldsymbol{ e }}}_{l}={\bar{\boldsymbol{ r }}}'_{l}{\!\cdot\!}\boldsymbol W_{{{l\!+\!1}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}_{{{l\!+\!1}}}\ \ \ \mathrm{for}\ \ \ l \lt N. $$\end{document}</tex-math></alternatives></disp-formula></p><p>and <inline-formula><alternatives><mml:math id="inf546"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft546">\begin{document}${\bar{\boldsymbol{ e }}}_{N}= \beta \,{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula> for the output layer. The learning rule that reduces <inline-formula><alternatives><mml:math id="inf547"><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft547">\begin{document}${\bar{\boldsymbol{ e }}}_{l}$\end{document}</tex-math></alternatives></inline-formula> by gradient descent is proportional to this error and the presynaptic rate, as stated by Theorem 1, is<disp-formula id="equ28"><label>(26)</label><alternatives><mml:math id="m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t28">\begin{document}$$\displaystyle \dot{\boldsymbol{W}}_{l}\propto \big(\boldsymbol u_{l}- \boldsymbol W_{l}\,{\bar{\boldsymbol{ r }}}_{{{l\!-\!1}}}\big) \,{\bar{\boldsymbol{ r }}}_{{{l\!-\!1}}}^{\mathrm{T}}={\bar{\boldsymbol{ e }}}_{l}\,{\bar{\boldsymbol{ r }}}_{{{l\!-\!1}}}^{\mathrm{T}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>for <inline-formula><alternatives><mml:math id="inf548"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:math><tex-math id="inft548">\begin{document}$l=1...N$\end{document}</tex-math></alternatives></inline-formula>. <xref ref-type="disp-formula" rid="equ27 equ28">Equations 25 and 26</xref> together take the form of the error backpropagation algorithm, where an output error is iteratively propagated through the network and used to adjust the weights in order to reduce the output cost <inline-formula><alternatives><mml:math id="inf549"><mml:mi>C</mml:mi></mml:math><tex-math id="inft549">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula>. From this, it is easy to see that without output nudging (i.e. <inline-formula><alternatives><mml:math id="inf550"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft550">\begin{document}$\beta = 0$\end{document}</tex-math></alternatives></inline-formula>), the output error vanishes and consequently all other prediction errors vanish as well, <inline-formula><alternatives><mml:math id="inf551"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft551">\begin{document}${\bar{\boldsymbol{ e }}}_{l}= \boldsymbol u_{l}- \boldsymbol W_{l}{\bar{\boldsymbol{ r }}}_{l}= 0$\end{document}</tex-math></alternatives></inline-formula> for all <inline-formula><alternatives><mml:math id="inf552"><mml:mrow><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><tex-math id="inft552">\begin{document}$l \leq N$\end{document}</tex-math></alternatives></inline-formula>. This also means that in the absence of nudging, no weight updates are performed by the plasticity rule.</p><p>The learning rule for arbitrary connectivities is obtained in the same way by dropping the layer-wise notation. In this case, low-pass filtering the equations of motion yields <inline-formula><alternatives><mml:math id="inf553"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft553">\begin{document}$\boldsymbol u = \boldsymbol W{\bar{\boldsymbol{ r }}}+{\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula>, as calculated in 23, and the low-pass filtered error <inline-formula><alternatives><mml:math id="inf554"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft554">\begin{document}${\bar{\boldsymbol{ e }}}={\bar{\boldsymbol{ \epsilon }}}+ \beta{\bar{\boldsymbol{ e }}}^{*}={\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}+ \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, as inferred from <xref ref-type="disp-formula" rid="equ23 equ24">Equations 21 and 22</xref>. Hence, the plasticity rule in general reads<disp-formula id="equ29"><label>(27)</label><alternatives><mml:math id="m29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:mtext> with </mml:mtext><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t29">\begin{document}$$\displaystyle \dot{\boldsymbol{W}}\propto \big(\boldsymbol u - \boldsymbol W \,{\bar{\boldsymbol{ r }}}\big) \,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}={\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}\;,\; \text{ with }{\bar{\boldsymbol{ e }}}={\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}+ \beta{\bar{\boldsymbol{ e }}}^{*}. $$\end{document}</tex-math></alternatives></disp-formula></p></sec><sec id="s4-4"><title>Proving theorem 1 (rt-DeEP)</title><p>The implicit assumption in Theorem 1 is that <inline-formula><alternatives><mml:math id="inf555"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft555">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> exists in the distributional sense for <inline-formula><alternatives><mml:math id="inf556"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft556">\begin{document}$t \gt -\infty$\end{document}</tex-math></alternatives></inline-formula>, which is the case for delta-functions in <inline-formula><alternatives><mml:math id="inf557"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft557">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> and step-functions in <inline-formula><alternatives><mml:math id="inf558"><mml:msup><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:math><tex-math id="inft558">\begin{document}$\boldsymbol u^{*}$\end{document}</tex-math></alternatives></inline-formula>. Both parts (i) and (ii) of the Theorem are based on the requirement of stationary action <inline-formula><alternatives><mml:math id="inf559"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft559">\begin{document}$\delta A = 0$\end{document}</tex-math></alternatives></inline-formula>, and hence on <inline-formula><alternatives><mml:math id="inf560"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft560">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> satisfying the Euler-Lagrange equations in the form of <xref ref-type="disp-formula" rid="equ24">Equation 22</xref>, <inline-formula><alternatives><mml:math id="inf561"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft561">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>. From the solution <inline-formula><alternatives><mml:math id="inf562"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mspace width="0.1667em"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft562">\begin{document}$\frac{\partial L}{\partial u_{i}}= c \, e^{-\frac{t-t_{0}}{\tau}}$\end{document}</tex-math></alternatives></inline-formula> we conclude that for initialization at <inline-formula><alternatives><mml:math id="inf563"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft563">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula> we have <inline-formula><alternatives><mml:math id="inf564"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft564">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> for all <inline-formula><alternatives><mml:math id="inf565"><mml:mi>t</mml:mi></mml:math><tex-math id="inft565">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>. It is the latter stronger condition that we require in the proof. With this, the main ingredient of the proof follows is the mathematical argument of <xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>, according to which the total and partial derivative of <inline-formula><alternatives><mml:math id="inf566"><mml:mi>L</mml:mi></mml:math><tex-math id="inft566">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf567"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft567">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> are identical, and this in our case is true for any time <inline-formula><alternatives><mml:math id="inf568"><mml:mi>t</mml:mi></mml:math><tex-math id="inft568">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ30"><label>(28)</label><alternatives><mml:math id="m30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t30">\begin{document}$$\displaystyle \frac{{\mathrm{d}} L}{{\mathrm{d}} \boldsymbol W}= \frac{\partial L}{ \partial \boldsymbol u}^{{\text{T}}}\frac{{\mathrm{d}} \boldsymbol u}{{\mathrm{d}} \boldsymbol W}+ \frac{\partial L}{\partial \boldsymbol W}= \frac{\partial L}{\partial \boldsymbol W}, $$\end{document}</tex-math></alternatives></disp-formula></p><p>For convenience we considered <inline-formula><alternatives><mml:math id="inf569"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft569">\begin{document}$\frac{\partial L}{ \partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> to be a column vector, deviating from the standard notations (see tutorial end of sec:Integration). Analogously to <xref ref-type="disp-formula" rid="equ30">Equation 28</xref>, we infer <inline-formula><alternatives><mml:math id="inf570"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft570">\begin{document}$\frac{{\mathrm{d}} L}{{\mathrm{d}} \beta}= \frac{\partial L}{\partial \beta}$\end{document}</tex-math></alternatives></inline-formula>. Reading <xref ref-type="disp-formula" rid="equ30">Equation 28</xref> from the right to the left, we conclude that the learning rule <inline-formula><alternatives><mml:math id="inf571"><mml:mrow><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>∝</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft571">\begin{document}$\dot{\boldsymbol W}\propto - \frac{\partial L}{\partial \boldsymbol W}={\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}$\end{document}</tex-math></alternatives></inline-formula> for all <inline-formula><alternatives><mml:math id="inf572"><mml:mrow><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft572">\begin{document}$\beta \gt 0$\end{document}</tex-math></alternatives></inline-formula> is gradient descent on <inline-formula><alternatives><mml:math id="inf573"><mml:mi>L</mml:mi></mml:math><tex-math id="inft573">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula>, i.e., <inline-formula><alternatives><mml:math id="inf574"><mml:mrow><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>∝</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft574">\begin{document}$\dot{\boldsymbol W}\propto - \frac{{\mathrm{d}} L}{{\mathrm{d}} \boldsymbol W}$\end{document}</tex-math></alternatives></inline-formula>. This total derivative of <inline-formula><alternatives><mml:math id="inf575"><mml:mi>L</mml:mi></mml:math><tex-math id="inft575">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> can be analyzed for large and small <inline-formula><alternatives><mml:math id="inf576"><mml:mi>β</mml:mi></mml:math><tex-math id="inft576">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>.</p><p>(i) We show that in the limit of large <inline-formula><alternatives><mml:math id="inf577"><mml:mi>β</mml:mi></mml:math><tex-math id="inft577">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf578"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft578">\begin{document}$\dot{\boldsymbol W}$\end{document}</tex-math></alternatives></inline-formula> becomes gradient descent on the mismatch energy <inline-formula><alternatives><mml:math id="inf579"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft579">\begin{document}${E^\text{M}}=\frac{1}{2}\|{\bar{\boldsymbol{ e }}}\|^{2}$\end{document}</tex-math></alternatives></inline-formula>. For this we first show that there is a solution of the self-consistency equation <inline-formula><alternatives><mml:math id="inf580"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft580">\begin{document}$\boldsymbol u = \boldsymbol F (\boldsymbol u) = \boldsymbol W{\bar{\boldsymbol{ r }}}+{\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}+ \beta \,{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula> that is uniformly bounded for all <inline-formula><alternatives><mml:math id="inf581"><mml:mi>t</mml:mi></mml:math><tex-math id="inft581">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf582"><mml:mi>β</mml:mi></mml:math><tex-math id="inft582">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>. For this we assume that the transfer function <inline-formula><alternatives><mml:math id="inf583"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft583">\begin{document}$\rho(u)$\end{document}</tex-math></alternatives></inline-formula> is non-negative, monotonically increasing, and bounded, that its derivative <inline-formula><alternatives><mml:math id="inf584"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft584">\begin{document}$\rho'(u)$\end{document}</tex-math></alternatives></inline-formula> is bounded too, and that the input rates <inline-formula><alternatives><mml:math id="inf585"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft585">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> and the target potentials <inline-formula><alternatives><mml:math id="inf586"><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo style="font-weight:bold;">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft586">\begin{document}$\boldsymbol{u_o^*}$\end{document}</tex-math></alternatives></inline-formula> are also uniformly bounded. To show that under these conditions we always find a uniformly bounded solution <inline-formula><alternatives><mml:math id="inf587"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft587">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula>, we first consider the case where the output voltages are clamped to the target, <inline-formula><alternatives><mml:math id="inf588"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo style="font-weight:bold;">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft588">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol{u_{\boldsymbol o}^*}$\end{document}</tex-math></alternatives></inline-formula> such that <inline-formula><alternatives><mml:math id="inf589"><mml:mrow><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft589">\begin{document}${\bar{\boldsymbol{ e }}}^{*}= 0$\end{document}</tex-math></alternatives></inline-formula>. For simplicity, we assume that <inline-formula><alternatives><mml:math id="inf590"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft590">\begin{document}$\rho'(u) = 0$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf591"><mml:mrow><mml:mi>|</mml:mi><mml:mi>u</mml:mi><mml:mi>|</mml:mi><mml:mo>≥</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft591">\begin{document}$| u| \geq c_{0}$\end{document}</tex-math></alternatives></inline-formula>. For voltages <inline-formula><alternatives><mml:math id="inf592"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft592">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf593"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft593">\begin{document}$\boldsymbol u_{i}\leq c_{0}$\end{document}</tex-math></alternatives></inline-formula> the recurrent input current <inline-formula><alternatives><mml:math id="inf594"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft594">\begin{document}$\boldsymbol W{\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula> is bounded, say <inline-formula><alternatives><mml:math id="inf595"><mml:mrow><mml:mi>|</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>|</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft595">\begin{document}$| (\boldsymbol W{\bar{\boldsymbol{ r }}})_{j}| \leq c_{1}$\end{document}</tex-math></alternatives></inline-formula> for some <inline-formula><alternatives><mml:math id="inf596"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft596">\begin{document}$c_{1} \gt c_{0}$\end{document}</tex-math></alternatives></inline-formula>. When including the error term <inline-formula><alternatives><mml:math id="inf597"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft597">\begin{document}${\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula>, the total current still remains uniformly bounded, say <inline-formula><alternatives><mml:math id="inf598"><mml:mrow><mml:mi>|</mml:mi><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>|</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft598">\begin{document}$| \boldsymbol F (\boldsymbol u)_{j}| \leq c_{2}$\end{document}</tex-math></alternatives></inline-formula> for all <inline-formula><alternatives><mml:math id="inf599"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft599">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf600"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft600">\begin{document}$\boldsymbol u_{i}\leq c_{0}$\end{document}</tex-math></alternatives></inline-formula>. Because for larger voltages <inline-formula><alternatives><mml:math id="inf601"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft601">\begin{document}$\boldsymbol u_{i} \gt c_{0}$\end{document}</tex-math></alternatives></inline-formula> the error term vanishes due to a vanishing derivative <inline-formula><alternatives><mml:math id="inf602"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft602">\begin{document}$\rho'(\boldsymbol u_{i}) = 0$\end{document}</tex-math></alternatives></inline-formula>, the mapping <inline-formula><alternatives><mml:math id="inf603"><mml:mrow><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft603">\begin{document}$\boldsymbol F (\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> maps the <inline-formula><alternatives><mml:math id="inf604"><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><tex-math id="inft604">\begin{document}$c_{2}$\end{document}</tex-math></alternatives></inline-formula>-box <inline-formula><alternatives><mml:math id="inf605"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft605">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> (for which <inline-formula><alternatives><mml:math id="inf606"><mml:mrow><mml:mi>|</mml:mi><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>|</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft606">\begin{document}$|\boldsymbol u_{i}| \leq c_{2}$\end{document}</tex-math></alternatives></inline-formula>) onto itself. Brouwer’s fixed point theorem then tells us that there is a fixed point <inline-formula><alternatives><mml:math id="inf607"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft607">\begin{document}$\boldsymbol u = \boldsymbol F (\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> within the <inline-formula><alternatives><mml:math id="inf608"><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><tex-math id="inft608">\begin{document}$c_{2}$\end{document}</tex-math></alternatives></inline-formula>-box. The theorem requires the continuity of <inline-formula><alternatives><mml:math id="inf609"><mml:mi>𝑭</mml:mi></mml:math><tex-math id="inft609">\begin{document}$\boldsymbol F$\end{document}</tex-math></alternatives></inline-formula>, and this is assured if the neuronal transfer function <inline-formula><alternatives><mml:math id="inf610"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft610">\begin{document}$\bar r = \rho (u)$\end{document}</tex-math></alternatives></inline-formula> is continuous.</p><p>We next relax the voltages of the output neurons from their clamped stage, <inline-formula><alternatives><mml:math id="inf611"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo style="font-weight:bold;">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft611">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol{u_{\boldsymbol o}^*}$\end{document}</tex-math></alternatives></inline-formula>. Remember that these voltages satisfy <inline-formula><alternatives><mml:math id="inf612"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>𝒐</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft612">\begin{document}$\boldsymbol u_{\boldsymbol o}= (\boldsymbol W{\bar{\boldsymbol{ r }}}+{\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}+ \beta \,{\bar{\boldsymbol{ e }}}^{*})_{\boldsymbol o}= \boldsymbol F (\boldsymbol u)_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> at any time <inline-formula><alternatives><mml:math id="inf613"><mml:mi>t</mml:mi></mml:math><tex-math id="inft613">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>. We determine the correction term <inline-formula><alternatives><mml:math id="inf614"><mml:mrow><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft614">\begin{document}$\beta \,{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula> such that in the limit <inline-formula><alternatives><mml:math id="inf615"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft615">\begin{document}$\beta\to\infty$\end{document}</tex-math></alternatives></inline-formula> we get <inline-formula><alternatives><mml:math id="inf616"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft616">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol F (\boldsymbol u)_{\boldsymbol o}= \boldsymbol u_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula>. The correction remains finite, and in the limit must be equal to <inline-formula><alternatives><mml:math id="inf617"><mml:mrow><mml:munder><mml:mi>lim</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>𝒐</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft617">\begin{document}$\lim_{\beta\to\infty}\beta \,{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}= \boldsymbol u_{\boldsymbol o}^{*}- (\boldsymbol W{\bar{\boldsymbol{ r }}}+{\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}})_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>. For arbitrary large nudging strength <inline-formula><alternatives><mml:math id="inf618"><mml:mi>β</mml:mi></mml:math><tex-math id="inft618">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>, the output voltage <inline-formula><alternatives><mml:math id="inf619"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft619">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> deviates arbitrary little from the target voltage, <inline-formula><alternatives><mml:math id="inf620"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo style="font-weight:bold;">*</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft620">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol{u_{\boldsymbol o}^*}+ o(1 /\beta)$\end{document}</tex-math></alternatives></inline-formula>, with target error <inline-formula><alternatives><mml:math id="inf621"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:msub><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>𝒐</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft621">\begin{document}${\bar{\boldsymbol{ e }}}^{*}_{\boldsymbol o}= \frac{1}{\beta}\left(\boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}\right)_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> shrinking like <inline-formula><alternatives><mml:math id="inf622"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>/</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math><tex-math id="inft622">\begin{document}$c_{2}/\beta$\end{document}</tex-math></alternatives></inline-formula>. Likewise, also for non-output neurons <italic>i</italic>, the self-consistency solution <inline-formula><alternatives><mml:math id="inf623"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft623">\begin{document}$\boldsymbol u_{i}= \boldsymbol F (\boldsymbol u)_{i}$\end{document}</tex-math></alternatives></inline-formula> deviates arbitrarily little from the solution of the clamped state. To ensure the smooth drift of the fixed point while <inline-formula><alternatives><mml:math id="inf624"><mml:mrow><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math><tex-math id="inft624">\begin{document}$1/\beta$\end{document}</tex-math></alternatives></inline-formula> deviates from 0 we require that the Jacobian of <inline-formula><alternatives><mml:math id="inf625"><mml:mi>𝑭</mml:mi></mml:math><tex-math id="inft625">\begin{document}$\boldsymbol F$\end{document}</tex-math></alternatives></inline-formula> at the fixed point is invertible.</p><p>Because the output <inline-formula><alternatives><mml:math id="inf626"><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft626">\begin{document}${\bar{\boldsymbol{ e }}}^{*}_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> shrinks with <inline-formula><alternatives><mml:math id="inf627"><mml:mrow><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math><tex-math id="inft627">\begin{document}$1/\beta$\end{document}</tex-math></alternatives></inline-formula>, the cost shrinks quadratically with increasing nudging strength, <inline-formula><alternatives><mml:math id="inf628"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mi>o</mml:mi><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow></mml:math><tex-math id="inft628">\begin{document}$C = \frac{1}{2}\|{\bar{\boldsymbol{ e }}}^{*}\|^{2}= o\big(\frac{1}{\beta^{2}}\big)$\end{document}</tex-math></alternatives></inline-formula>, and hence the cost term <inline-formula><alternatives><mml:math id="inf629"><mml:mrow><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft629">\begin{document}$\frac{\beta}{2}\|{\bar{\boldsymbol{ e }}}^{*}\|^{2}$\end{document}</tex-math></alternatives></inline-formula> that enters in <inline-formula><alternatives><mml:math id="inf630"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft630">\begin{document}$L={E^\text{M}}+ \frac{\beta}{2}\|{\bar{\boldsymbol{ e }}}^{*}\|^{2}$\end{document}</tex-math></alternatives></inline-formula> vanishes in the limit <inline-formula><alternatives><mml:math id="inf631"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft631">\begin{document}$\beta\to\infty$\end{document}</tex-math></alternatives></inline-formula>. In this large <inline-formula><alternatives><mml:math id="inf632"><mml:mi>β</mml:mi></mml:math><tex-math id="inft632">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> limit, where <inline-formula><alternatives><mml:math id="inf633"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft633">\begin{document}${\bar{\boldsymbol{ e }}}^{*}_{\boldsymbol o}= 0$\end{document}</tex-math></alternatives></inline-formula> and hence the outputs are clamped, <inline-formula><alternatives><mml:math id="inf634"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft634">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol u^{*}_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>, the Lagrangian reduces to the mismatch energy, <inline-formula><alternatives><mml:math id="inf635"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft635">\begin{document}$L={E^\text{M}}$\end{document}</tex-math></alternatives></inline-formula>. Along the least-action trajectories, we, therefore, get <inline-formula><alternatives><mml:math id="inf636"><mml:mrow><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>∝</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft636">\begin{document}$\dot{\boldsymbol W}\propto - \frac{\partial L}{\partial \boldsymbol W}= - \frac{d L}{d \boldsymbol W}= - \frac{{\mathrm{d}} {E^\text{M}}}{{\mathrm{d}} \boldsymbol W}\,$\end{document}</tex-math></alternatives></inline-formula>. The first equality uses <xref ref-type="disp-formula" rid="equ30">Equation 28</xref>, and the second uses <inline-formula><alternatives><mml:math id="inf637"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft637">\begin{document}$L={E^\text{M}}$\end{document}</tex-math></alternatives></inline-formula> just derived for <inline-formula><alternatives><mml:math id="inf638"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft638">\begin{document}$\beta=\infty$\end{document}</tex-math></alternatives></inline-formula>. This is a statement (<inline-formula><alternatives><mml:math id="inf639"><mml:mi>i</mml:mi></mml:math><tex-math id="inft639">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula>) of Theorem 1. In the case of successful learning, <inline-formula><alternatives><mml:math id="inf640"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft640">\begin{document}${E^\text{M}}=0$\end{document}</tex-math></alternatives></inline-formula>, we also conclude that the cost vanishes, <inline-formula><alternatives><mml:math id="inf641"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft641">\begin{document}$C=0$\end{document}</tex-math></alternatives></inline-formula>. This is the case because <inline-formula><alternatives><mml:math id="inf642"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft642">\begin{document}${E^\text{M}}=0$\end{document}</tex-math></alternatives></inline-formula> implies <inline-formula><alternatives><mml:math id="inf643"><mml:mrow><mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft643">\begin{document}${E^\text{M}}_{o}=0$\end{document}</tex-math></alternatives></inline-formula> for all output neurons <inline-formula><alternatives><mml:math id="inf644"><mml:mi>o</mml:mi></mml:math><tex-math id="inft644">\begin{document}$o$\end{document}</tex-math></alternatives></inline-formula>. Since <inline-formula><alternatives><mml:math id="inf645"><mml:mrow><mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>o</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>o</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math><tex-math id="inft645">\begin{document}${E^\text{M}}_{o}= \frac{1}{2}{\bar{\boldsymbol{ e }}}_{o}^{2}= \frac{1}{2}({\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}+ \beta \,{\bar{\boldsymbol{ e }}}^{*})_{o}^{2}$\end{document}</tex-math></alternatives></inline-formula>, we conclude that <inline-formula><alternatives><mml:math id="inf646"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>o</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft646">\begin{document}${\bar{\boldsymbol{ e }}}_{o}= 0$\end{document}</tex-math></alternatives></inline-formula>, and if the output neurons do not feed back to the network (which we can assume without loss of generality), we conclude that <inline-formula><alternatives><mml:math id="inf647"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>o</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft647">\begin{document}${\bar{\boldsymbol{ e }}}^{*}_{o}= 0$\end{document}</tex-math></alternatives></inline-formula>.</p><p>(ii) To consider the case of small <inline-formula><alternatives><mml:math id="inf648"><mml:mi>β</mml:mi></mml:math><tex-math id="inft648">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula>, we use that the cost <inline-formula><alternatives><mml:math id="inf649"><mml:mi>C</mml:mi></mml:math><tex-math id="inft649">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> can be expressed as <inline-formula><alternatives><mml:math id="inf650"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft650">\begin{document}$C = \frac{\partial L}{\partial \beta}$\end{document}</tex-math></alternatives></inline-formula>. This is a direct consequence of how <inline-formula><alternatives><mml:math id="inf651"><mml:mi>C</mml:mi></mml:math><tex-math id="inft651">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> enters in <inline-formula><alternatives><mml:math id="inf652"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft652">\begin{document}$L= \frac{1}{2}\|{\bar{\boldsymbol{ e }}}\|^{2}+ \frac{\beta}{2}C$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ17">Equation 16</xref> and <xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>. We now put this together with <xref ref-type="disp-formula" rid="equ30">Equation 28</xref> and the finding that <inline-formula><alternatives><mml:math id="inf653"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft653">\begin{document}$\frac{\partial L}{\partial \beta}= \frac{{\mathrm{d}} L}{{\mathrm{d}} \beta}$\end{document}</tex-math></alternatives></inline-formula>. Since for the Lipschitz continuous function <inline-formula><alternatives><mml:math id="inf654"><mml:mi>L</mml:mi></mml:math><tex-math id="inft654">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> in <inline-formula><alternatives><mml:math id="inf655"><mml:mi>u</mml:mi></mml:math><tex-math id="inft655">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf656"><mml:mi>W</mml:mi></mml:math><tex-math id="inft656">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf657"><mml:mi>β</mml:mi></mml:math><tex-math id="inft657">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> (<inline-formula><alternatives><mml:math id="inf658"><mml:mi>L</mml:mi></mml:math><tex-math id="inft658">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> is even smooth in these arguments), the total derivatives interchange (which is a consequence of the Moore-Osgood theorem applied to the limits of the difference quotients), we then get at any <inline-formula><alternatives><mml:math id="inf659"><mml:mi>t</mml:mi></mml:math><tex-math id="inft659">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ31"><label>(29)</label><alternatives><mml:math id="m31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t31">\begin{document}$$\displaystyle \frac{{\mathrm{d}} C}{{\mathrm{d}} \boldsymbol W}= \frac{{\mathrm{d}} }{{\mathrm{d}} \boldsymbol W}\frac{\partial L}{ \partial \beta}= \frac{{\mathrm{d}} }{{\mathrm{d}} \boldsymbol W}\frac{{\mathrm{d}} L}{ {\mathrm{d}} \beta}= \frac{{\mathrm{d}} }{ {\mathrm{d}} \beta}\frac{{\mathrm{d}} L}{{\mathrm{d}} \boldsymbol W}= \frac{{\mathrm{d}} }{ {\mathrm{d}} \beta}\frac{\partial L}{\partial \boldsymbol W}= - \frac{{\mathrm{d}} }{ {\mathrm{d}} \beta}{\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The last expression is calculated from the specific form of the Lagrangian <xref ref-type="disp-formula" rid="equ18">Equation 17</xref>, using that by definition <inline-formula><alternatives><mml:math id="inf660"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft660">\begin{document}${\bar{\boldsymbol{ e }}}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Finally, in the absence of output nudging, <inline-formula><alternatives><mml:math id="inf661"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft661">\begin{document}$\beta = 0$\end{document}</tex-math></alternatives></inline-formula>, we can assume vanishing errors, <inline-formula><alternatives><mml:math id="inf662"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft662">\begin{document}${\bar{\boldsymbol{ e }}}= 0$\end{document}</tex-math></alternatives></inline-formula>, as they solve the self-consistency equation, <inline-formula><alternatives><mml:math id="inf663"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft663">\begin{document}${\bar{\boldsymbol{ e }}}={\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}'{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula> for all <inline-formula><alternatives><mml:math id="inf664"><mml:mi>t</mml:mi></mml:math><tex-math id="inft664">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ29">Equation 27</xref>. For these solutions we have <inline-formula><alternatives><mml:math id="inf665"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true" form="prefix"/><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup><mml:mo fence="true" form="postfix">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft665">\begin{document}$\left.{\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}\right|_{\beta=0}= 0$\end{document}</tex-math></alternatives></inline-formula>. Writing out the total derivative of the function <inline-formula><alternatives><mml:math id="inf666"><mml:mrow><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft666">\begin{document}${\boldsymbol g}(\beta) ={\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf667"><mml:mi>β</mml:mi></mml:math><tex-math id="inft667">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> at <inline-formula><alternatives><mml:math id="inf668"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft668">\begin{document}$\beta=0$\end{document}</tex-math></alternatives></inline-formula> as limit of the difference quotient, <inline-formula><alternatives><mml:math id="inf669"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true" form="prefix"/><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mi>lim</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mi>lim</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft669">\begin{document}$\left . \frac{{\mathrm{d}} {\boldsymbol g}(\beta)}{ {\mathrm{d}} \beta}\right|_{\beta=0}= \lim_{\beta \to 0}\frac{1}{\beta}\left({\boldsymbol g}(\beta) -{\boldsymbol g}(0) \right) = \lim_{\beta \to 0}\frac{1}{\beta}{\boldsymbol g}(\beta)$\end{document}</tex-math></alternatives></inline-formula>, using that <inline-formula><alternatives><mml:math id="inf670"><mml:mrow><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>=</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft670">\begin{document}${\boldsymbol g}(0) \!=\! 0$\end{document}</tex-math></alternatives></inline-formula>, we calculate at any <inline-formula><alternatives><mml:math id="inf671"><mml:mi>t</mml:mi></mml:math><tex-math id="inft671">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ32"><label>(30)</label><alternatives><mml:math id="m32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t32">\begin{document}$$\displaystyle \left. \frac{{\mathrm{d}}\,{\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}}{ {\mathrm{d}} \beta}\right|_{\beta=0}= \lim_{\beta \to 0}\frac{1}{\beta}\left({\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}- \left.{\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}\right|_{\beta=0}\right) = \lim_{\beta \to 0}\frac{1}{\beta}{\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, we assume that <inline-formula><alternatives><mml:math id="inf672"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft672">\begin{document}${\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}$\end{document}</tex-math></alternatives></inline-formula> is evaluated at <inline-formula><alternatives><mml:math id="inf673"><mml:mrow><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft673">\begin{document}$\beta \gt 0$\end{document}</tex-math></alternatives></inline-formula> (that itself approaches 0), while <inline-formula><alternatives><mml:math id="inf674"><mml:msub><mml:mrow><mml:mo fence="true" form="prefix"/><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup><mml:mo fence="true" form="postfix">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft674">\begin{document}$\left.{\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}\right|_{\beta=0}$\end{document}</tex-math></alternatives></inline-formula> is evaluated at <inline-formula><alternatives><mml:math id="inf675"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft675">\begin{document}$\beta=0$\end{document}</tex-math></alternatives></inline-formula>. Combining <xref ref-type="disp-formula" rid="equ31 equ32">Equations 29 and 30</xref> yields the cost gradient at any <inline-formula><alternatives><mml:math id="inf676"><mml:mi>t</mml:mi></mml:math><tex-math id="inft676">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ33"><label>(31)</label><alternatives><mml:math id="m33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mspace width="negativethinmathspace"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t33">\begin{document}$$\displaystyle -\frac{{\mathrm{d}} C}{{\mathrm{d}} \boldsymbol W}= \lim_{\beta \to 0}\! \frac{1}{\beta}\,{\bar{\boldsymbol{ e }}}\,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>This justifies the gradient learning rule <inline-formula><alternatives><mml:math id="inf677"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft677">\begin{document}$\dot{\boldsymbol W}$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="equ29">Equation 27</xref>. Learning is stochastic gradient descent on the expected cost, where stochasticity enters in the randomization of the stimulus and target sequences <inline-formula><alternatives><mml:math id="inf678"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft678">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf679"><mml:mrow><mml:msup><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft679">\begin{document}$\boldsymbol u^{*}(t)$\end{document}</tex-math></alternatives></inline-formula>. For the regularity statement, see ‘From implicit to explicit differential equations’ in the sec:Integration. Notice that this proof works for a very general form of the Lagrangian <inline-formula><alternatives><mml:math id="inf680"><mml:mi>L</mml:mi></mml:math><tex-math id="inft680">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula>, until the specific expression for <inline-formula><alternatives><mml:math id="inf681"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft681">\begin{document}$\frac{\partial L}{\partial \boldsymbol W}$\end{document}</tex-math></alternatives></inline-formula>. For a proof in terms of partial derivatives only, see Appendix 8, and for a primer on partial and total derivatives see Appendix 7.</p></sec><sec id="s4-5"><title>Instantaneous gradient descent on <inline-formula><alternatives><mml:math id="inf682"><mml:mrow><mml:mi>C</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo separator="true">,</mml:mo><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft682">\begin{document}$C(\boldsymbol u_{\boldsymbol o}^{*}, \overline{\boldsymbol r}_{{\text{in}}})$\end{document}</tex-math></alternatives></inline-formula></title><p>The cost <inline-formula><alternatives><mml:math id="inf683"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft683">\begin{document}$C = \frac{1}{2}\| \boldsymbol u_{\boldsymbol o}^{*}- \boldsymbol u_{\boldsymbol o}\|^{2}$\end{document}</tex-math></alternatives></inline-formula> at each time <inline-formula><alternatives><mml:math id="inf684"><mml:mi>t</mml:mi></mml:math><tex-math id="inft684">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> is a function of the voltage <inline-formula><alternatives><mml:math id="inf685"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft685">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> of the output neurons and the corresponding targets. In a feedforward network, due to the instantaneity of the voltage propagation <xref ref-type="disp-formula" rid="equ25">Equation 23</xref>, <inline-formula><alternatives><mml:math id="inf686"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft686">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> is in the absence of output nudging (<inline-formula><alternatives><mml:math id="inf687"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft687">\begin{document}$\beta=0$\end{document}</tex-math></alternatives></inline-formula>) an instantaneous function of the voltage at the first layer, <inline-formula><alternatives><mml:math id="inf688"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft688">\begin{document}$\boldsymbol u_{1}(t) = \boldsymbol W_{{\text{in}}}\overline{\boldsymbol r}_{{\text{in}}}(t) + \boldsymbol u_{1}(t_{0}) \, e^{ -\frac{t - t_{0}}{\tau} }$\end{document}</tex-math></alternatives></inline-formula>. For initialisation at <inline-formula><alternatives><mml:math id="inf689"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft689">\begin{document}$t_{0}= - \infty$\end{document}</tex-math></alternatives></inline-formula>, the second term vanishes for all <inline-formula><alternatives><mml:math id="inf690"><mml:mi>t</mml:mi></mml:math><tex-math id="inft690">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> and hence <inline-formula><alternatives><mml:math id="inf691"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft691">\begin{document}$\boldsymbol u_{1}(t) = \boldsymbol W_{{\text{in}}}\overline{\boldsymbol r}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>. The output voltage <inline-formula><alternatives><mml:math id="inf692"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft692">\begin{document}$\boldsymbol u_{\boldsymbol o}(t)$\end{document}</tex-math></alternatives></inline-formula>, therefore, becomes a function <inline-formula><alternatives><mml:math id="inf693"><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:math><tex-math id="inft693">\begin{document}$\boldsymbol F_{W}$\end{document}</tex-math></alternatives></inline-formula> of the low-pass filtered input rate <inline-formula><alternatives><mml:math id="inf694"><mml:mrow><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft694">\begin{document}$\overline{\boldsymbol r}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> that captures the instantaneous network mapping, <inline-formula><alternatives><mml:math id="inf695"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft695">\begin{document}$\boldsymbol u_{\boldsymbol o}(t) ={\boldsymbol F}_{W}(\overline{\boldsymbol r}_{{\text{in}}}(t))$\end{document}</tex-math></alternatives></inline-formula>, and with this the cost also becomes an instantaneous function of <inline-formula><alternatives><mml:math id="inf696"><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft696">\begin{document}$\overline{\boldsymbol r}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf697"><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft697">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula>, namely <inline-formula><alternatives><mml:math id="inf698"><mml:mrow><mml:mi>C</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft698">\begin{document}$C(t) = \frac{1}{2}\| \boldsymbol u_{\boldsymbol o}^{*}(t) - \boldsymbol u_{\boldsymbol o}(t) \|^{2}= \frac{1}{2}\| \boldsymbol u_{\boldsymbol o}^{*}(t) -{\boldsymbol F}_{W}(\overline{\boldsymbol r}_{{\text{in}}}(t)) \|^{2}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>For a general network, again assuming <inline-formula><alternatives><mml:math id="inf699"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft699">\begin{document}$t_{0}= - \infty$\end{document}</tex-math></alternatives></inline-formula>, the voltage is determined by the vanishing gradient <inline-formula><alternatives><mml:math id="inf700"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft700">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol f(\boldsymbol u, t) = \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}(\boldsymbol u) -{\bar{\boldsymbol{ e }}}(\boldsymbol u) = 0$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf701"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft701">\begin{document}${\bar{\boldsymbol{ e }}}={\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ23">Equation 21</xref>. For the inclusive treatment of the initial transient see Appendix 3 and Appendix 4. Remember that <inline-formula><alternatives><mml:math id="inf702"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mtext>T</mml:mtext></mml:msup></mml:mrow></mml:math><tex-math id="inft702">\begin{document}${\bar{\boldsymbol{ r }}}= ({\bar{\boldsymbol{ r }}}_{{\text{in}}},{\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}(\boldsymbol u))^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf703"><mml:mrow><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft703">\begin{document}${\bar{\boldsymbol{ e }}}^{*}= \boldsymbol u_{\boldsymbol o}^{*}- \boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>. For a given <inline-formula><alternatives><mml:math id="inf704"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft704">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf705"><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft705">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula> at time <inline-formula><alternatives><mml:math id="inf706"><mml:mi>t</mml:mi></mml:math><tex-math id="inft706">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, the equation <inline-formula><alternatives><mml:math id="inf707"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft707">\begin{document}$\boldsymbol f(\boldsymbol u, t) = 0$\end{document}</tex-math></alternatives></inline-formula> can be locally solved for <inline-formula><alternatives><mml:math id="inf708"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft708">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> if the Hessian <inline-formula><alternatives><mml:math id="inf709"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mi>𝝆</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft709">\begin{document}$\boldsymbol H = \frac{\partial^{2}L}{\partial \boldsymbol u^{2}}= \frac{\partial \boldsymbol f}{\partial \boldsymbol u}= \boldsymbol 1 - \boldsymbol W_{{{\!\text{net}}}}\boldsymbol \rho' -{\bar{\boldsymbol{ e }}}'$\end{document}</tex-math></alternatives></inline-formula> is invertible, <inline-formula><alternatives><mml:math id="inf710"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft710">\begin{document}$\boldsymbol u = \boldsymbol F ({\bar{\boldsymbol{ r }}}_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula>. This mapping can be restricted to the output voltages <inline-formula><alternatives><mml:math id="inf711"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft711">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> on the left-hand side, while replacing <inline-formula><alternatives><mml:math id="inf712"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft712">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}= \boldsymbol u_{\boldsymbol o}+{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula> in the argument on the right-hand side (even if this again introduces <inline-formula><alternatives><mml:math id="inf713"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft713">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> there). With this, we obtain the instantaneous mapping <inline-formula><alternatives><mml:math id="inf714"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft714">\begin{document}$\boldsymbol u_{\boldsymbol o}(t) ={\boldsymbol F}_{W}(\overline{\boldsymbol r}_{{\text{in}}}(t),{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}(t))$\end{document}</tex-math></alternatives></inline-formula> from the low-pass filtered input and the output error to the output itself. Notice that for functional feedforward network, the network weight matrix <inline-formula><alternatives><mml:math id="inf715"><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:math><tex-math id="inft715">\begin{document}$\boldsymbol W_{{{\!\text{net}}}}$\end{document}</tex-math></alternatives></inline-formula> is lower triangular, and for small enough <inline-formula><alternatives><mml:math id="inf716"><mml:mi>β</mml:mi></mml:math><tex-math id="inft716">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> the Hessian <inline-formula><alternatives><mml:math id="inf717"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft717">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> is, therefore, always positive definite (see also Methods, Sect. From implicit to explicit differential equations).</p></sec><sec id="s4-6"><title>Proving theorem 2 (rt-DeEL)</title><p>Here, we restrict ourselves to layered network architectures. To prove Theorem 2 first assume that interneurons receive no nudging (<inline-formula><alternatives><mml:math id="inf718"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft718">\begin{document}$\beta^{\mathrm{I}}= 0$\end{document}</tex-math></alternatives></inline-formula>) and only the lateral interneuron-to-pyramidal weights <inline-formula><alternatives><mml:math id="inf719"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft719">\begin{document}$\boldsymbol{W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> are plastic. This is already sufficient to prove the rt-DeEL theorem. Yet, simulations showed that learning the lateral pyramidal-to-interneuron weights <inline-formula><alternatives><mml:math id="inf720"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft720">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> via top-down nudging, so that the interneuron activity mimics the upper layer pyramidal neuron activity, helps in learning a correct error representation. We consider this case of learning <inline-formula><alternatives><mml:math id="inf721"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft721">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> later.</p><p>If the microcircuits is ought to correctly implement error backpropagation, all local prediction errors <inline-formula><alternatives><mml:math id="inf722"><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft722">\begin{document}${\bar{\boldsymbol{ e }}}_{l}$\end{document}</tex-math></alternatives></inline-formula> must vanish in the absence of output nudging (<inline-formula><alternatives><mml:math id="inf723"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft723">\begin{document}$\beta=0$\end{document}</tex-math></alternatives></inline-formula>) as there is no target error. Consequently, any remaining errors in the network are caused by a misalignment of the lateral microcircuit. We show how learning the interneuron-to-pyramidal weights <inline-formula><alternatives><mml:math id="inf724"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft724">\begin{document}$\boldsymbol{W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> corrects for such misalignments.</p><p>To define the gradient descent plasticity of the weights <inline-formula><alternatives><mml:math id="inf725"><mml:msub><mml:msup><mml:mi>W</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft725">\begin{document}${W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> from the interneurons to the pyramidal neurons, we consider the apical error formed by the difference of top-down input and interneuron input, <inline-formula><alternatives><mml:math id="inf726"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft726">\begin{document}$\bar{\boldsymbol{e}}_{l}^{A}= \boldsymbol B_{l}\boldsymbol u_{l+1}- \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{u^{\text{I}}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, and define the apical mismatch energy as <inline-formula><alternatives><mml:math id="inf727"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mtext/><mml:mi>PI</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>A</mml:mi></mml:msubsup><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft727">\begin{document}$E^{\mathrm{PI}}_{l}= \frac{1}{2}\|{\bar{\boldsymbol{ e }}}^{A}_{l}\|^{2}$\end{document}</tex-math></alternatives></inline-formula>. Gradient descent along this energy with respect to <inline-formula><alternatives><mml:math id="inf728"><mml:msub><mml:msup><mml:mi>W</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft728">\begin{document}${W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> yields<disp-formula id="equ34"><label>(32)</label><alternatives><mml:math id="m34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext><mml:mspace width="thinmathspace"/><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext><mml:mspace width="thinmathspace"/><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/></mml:mrow></mml:mstyle></mml:math><tex-math id="t34">\begin{document}$$\displaystyle \boldsymbol{\dot{W}}^{\text{PI}}_{l}= \eta^{\text{PI}}e^{A}_{l}\boldsymbol{u}^{\text{I}\, \text{T}}_{l}= \eta^{\text{PI}}\left(\boldsymbol{B}_{l}\boldsymbol{u}_{l+1}- \boldsymbol{W}^{\text{PI}}_{l}\boldsymbol{u}^{\text{I}}_{l}\right) \boldsymbol{u}^{\text{I}\, \text{T}}_{l}\,$$\end{document}</tex-math></alternatives></disp-formula></p><p>evaluated online while presenting input patterns from the data distribution to the network. We assume that the apical contribution to the somatic voltage is further modulated by the somatic spike rate, <inline-formula><alternatives><mml:math id="inf729"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>A</mml:mi></mml:msubsup></mml:mrow></mml:math><tex-math id="inft729">\begin{document}$\bar{\boldsymbol{r}}_{l}'{\!\cdot\!}\bar{\boldsymbol{e}}_{l}^{A}$\end{document}</tex-math></alternatives></inline-formula>. After successful learning, the top-down input <inline-formula><alternatives><mml:math id="inf730"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft730">\begin{document}$\boldsymbol B_{l}\boldsymbol u_{l+1}$\end{document}</tex-math></alternatives></inline-formula> is fully subtracted away by the lateral input in the apical compartment, and we have<disp-formula id="equ35"><label>(33)</label><alternatives><mml:math id="m35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t35">\begin{document}$$\displaystyle \boldsymbol B_{l}\boldsymbol u_{l+1}= \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{u^{\text{I}}}_{l}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Once this condition is reached, the network achieves a state where, over the activity space spanned by the data, top-down prediction errors throughout the network vanish,<disp-formula id="equ36"><label>(34)</label><alternatives><mml:math id="m36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t36">\begin{document}$$\displaystyle \bar{\boldsymbol{e}}_{l}= \bar{\boldsymbol{r}}_{l}'{\!\cdot\!}\bar{\boldsymbol{e}}_{l}^{A}= \bar{\boldsymbol{r}}_{l}'{\!\cdot\!}\left(\boldsymbol B_{l}\boldsymbol u_{{{l\!+\!1}}}- \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol u_{l}^{{\mathrm{I}}}\right) = 0. $$\end{document}</tex-math></alternatives></disp-formula></p><p>We show that this top-down prediction error, after the successful learning of the microcircuit, shares the properties of error-backpropagation for a suitable backprojection weights <inline-formula><alternatives><mml:math id="inf731"><mml:mi>𝑩</mml:mi></mml:math><tex-math id="inft731">\begin{document}$\boldsymbol B$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Due to the vanishing prediction errors, pyramidal cells only receive bottom-up input <inline-formula><alternatives><mml:math id="inf732"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft732">\begin{document}$\boldsymbol u_{{{l\!+\!1}}}= \boldsymbol W_{{{l\!+\!1}}}\bar{\boldsymbol{r}}_{l}$\end{document}</tex-math></alternatives></inline-formula>. Using this expression as well as the expression for interneuron membrane potentials without top-down nudging (<inline-formula><alternatives><mml:math id="inf733"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft733">\begin{document}${\beta^\text{I}}= 0$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="equ10">Equation 9</xref>), <inline-formula><alternatives><mml:math id="inf734"><mml:mrow><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft734">\begin{document}$\boldsymbol{u^{\text{I}}}_{l}= \boldsymbol{W^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, and plugging both into <xref ref-type="disp-formula" rid="equ35">Equation 33</xref>, we get<disp-formula id="equ37"><label>(35)</label><alternatives><mml:math id="m37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t37">\begin{document}$$\displaystyle \boldsymbol B_{l}\boldsymbol W_{{{l\!+\!1}}}\bar{\boldsymbol{r}}_{l}= \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{W^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{l}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Assuming that <inline-formula><alternatives><mml:math id="inf735"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft735">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> has full rank, and the low-pass filtered rates <inline-formula><alternatives><mml:math id="inf736"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft736">\begin{document}$\bar{\boldsymbol{r}}_{l}$\end{document}</tex-math></alternatives></inline-formula> span the full <inline-formula><alternatives><mml:math id="inf737"><mml:msub><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft737">\begin{document}$n_{l}$\end{document}</tex-math></alternatives></inline-formula> dimensions of layer <inline-formula><alternatives><mml:math id="inf738"><mml:mi>l</mml:mi></mml:math><tex-math id="inft738">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> when sampled across the data set, we conclude that<disp-formula id="equ38"><label>(36)</label><alternatives><mml:math id="m38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t38">\begin{document}$$\displaystyle \boldsymbol B_{l}\boldsymbol W_{{{l\!+\!1}}}= \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{W^{\text{IP}}}_{l}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>In other words, the loop via upper layer and back is learned to be matched by a lateral loop through the interneurons.</p><p><xref ref-type="disp-formula" rid="equ38">Equation 36</xref> imposes a restriction on the minimal number of interneurons <inline-formula><alternatives><mml:math id="inf739"><mml:msubsup><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft739">\begin{document}$n_{l}^{\mathrm{I}}$\end{document}</tex-math></alternatives></inline-formula> at layer <inline-formula><alternatives><mml:math id="inf740"><mml:mi>l</mml:mi></mml:math><tex-math id="inft740">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula>. In fact, the matrix product <inline-formula><alternatives><mml:math id="inf741"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft741">\begin{document}$\boldsymbol B_{l}\boldsymbol W_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> maps a <inline-formula><alternatives><mml:math id="inf742"><mml:msub><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft742">\begin{document}$n_{l}$\end{document}</tex-math></alternatives></inline-formula>-dimensional space onto itself via <inline-formula><alternatives><mml:math id="inf743"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft743">\begin{document}$n_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>-dimensional space. The maximal rank of the this matrix product is limited by the smallest dimension, i.e., <inline-formula><alternatives><mml:math id="inf744"><mml:mrow><mml:mrow><mml:mtext/><mml:mi>rank</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mrow><mml:mtext/><mml:mi>min</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft744">\begin{document}$\mathrm{rank}(\boldsymbol B_{l}\boldsymbol W_{{{l\!+\!1}}}) \leq \mathrm{min}(n_{l}, n_{{{l\!+\!1}}})$\end{document}</tex-math></alternatives></inline-formula>. Analogously, <inline-formula><alternatives><mml:math id="inf745"><mml:mrow><mml:mrow><mml:mtext/><mml:mi>rank</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mrow><mml:mtext/><mml:mi>min</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft745">\begin{document}$\mathrm{rank}(\boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{W^{\text{IP}}}_{l}) \leq \mathrm{min}(n_{l}, n_{l}^{{\mathrm{I}}})$\end{document}</tex-math></alternatives></inline-formula>. But since the two ranks are the same according to <xref ref-type="disp-formula" rid="equ38">Equation 36</xref>, we conclude that in general <inline-formula><alternatives><mml:math id="inf746"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup><mml:mo>≥</mml:mo><mml:mrow><mml:mtext/><mml:mi>min</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft746">\begin{document}$n_{l}^{{\mathrm{I}}}\geq \mathrm{min}(n_{l}, n_{{{l\!+\!1}}})$\end{document}</tex-math></alternatives></inline-formula> must hold, i.e., there should be at least as many interneurons at layer <inline-formula><alternatives><mml:math id="inf747"><mml:mi>l</mml:mi></mml:math><tex-math id="inft747">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> as the lowest number of pyramidal neurons at either layer <inline-formula><alternatives><mml:math id="inf748"><mml:mi>l</mml:mi></mml:math><tex-math id="inft748">\begin{document}$l$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf749"><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft749">\begin{document}${{l\!+\!1}}$\end{document}</tex-math></alternatives></inline-formula>. Note that by choosing <inline-formula><alternatives><mml:math id="inf750"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft750">\begin{document}$n_{l}^{{\mathrm{I}}}= n_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> as in <xref ref-type="bibr" rid="bib78">Sacramento et al., 2018</xref> (or <inline-formula><alternatives><mml:math id="inf751"><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft751">\begin{document}$n_{l}^{{\mathrm{I}}} \gt n_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> as in this work), the conditions is fulfilled.</p><p>With <inline-formula><alternatives><mml:math id="inf752"><mml:mrow><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft752">\begin{document}$\boldsymbol{u^{\text{I}}}_{l}= \boldsymbol{W^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{l}$\end{document}</tex-math></alternatives></inline-formula> and <xref ref-type="disp-formula" rid="equ38">Equation 36</xref>, the top-down prediction error from <xref ref-type="disp-formula" rid="equ36">Equation 34</xref>, in the presence of output nudging (<inline-formula><alternatives><mml:math id="inf753"><mml:mrow><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft753">\begin{document}$\beta \gt 0$\end{document}</tex-math></alternatives></inline-formula>), can be written in the backpropagation form<disp-formula id="equ39"><label>(37a)</label><alternatives><mml:math id="m39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t39">\begin{document}$$\displaystyle \bar{\boldsymbol{e}}_{l}= \bar{\boldsymbol{r}}'_{l}{\cdot}(\boldsymbol B_{l}\, \boldsymbol u_{{{l\!+\!1}}}- \boldsymbol{W^{\text{PI}}}_{l}\, \boldsymbol u^{{\mathrm{I}}}_{l}\,) = \bar{\boldsymbol{r}}'_{l}{\cdot}(\boldsymbol B_{l}\, \boldsymbol u_{{{l\!+\!1}}}- \boldsymbol{W^{\text{PI}}}_{l}\, \boldsymbol{W^{\text{IP}}}_{l}\bar{\boldsymbol{r}}_{l})$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ40"><label>(37b)</label><alternatives><mml:math id="m40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t40">\begin{document}$$\displaystyle =\bar{\boldsymbol{r}}'_{l}{\cdot}(\boldsymbol B_{l}\, \boldsymbol u_{{{l\!+\!1}}}- \boldsymbol B_{l}\, \boldsymbol W_{{{l\!+\!1}}}\bar{\boldsymbol{r}}_{l}\,) = \bar{\boldsymbol{r}}'_{l}{\cdot}\boldsymbol B_{l}\, \left(\boldsymbol u_{{{l\!+\!1}}}- \boldsymbol W_{{{l\!+\!1}}}\bar{\boldsymbol{r}}_{l}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ41"><label>(37c)</label><alternatives><mml:math id="m41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mspace width="2em"/><mml:mspace width="30pt"/><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t41">\begin{document}$$\displaystyle \qquad \hspace{30 pt} = \bar{\boldsymbol{r}}'_{l}{\!\cdot\!}\boldsymbol B_{l}\, \bar{\boldsymbol{e}}_{{{l\!+\!1}}}= \bar{\boldsymbol{r}}'_{l}{\cdot}\boldsymbol B_{l}\, \bar{\boldsymbol{r}}_{{{l\!+\!1}}}'{\cdot}\bar{\boldsymbol{e}}_{{{l\!+\!1}}}^{A}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Finally, the simulations showed that learning the lateral weights in the microcircuit greatly benefits from also adapting the pyramidal-to-interneuron weights <inline-formula><alternatives><mml:math id="inf754"><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup></mml:math><tex-math id="inft754">\begin{document}$\boldsymbol{W^{\text{IP}}}$\end{document}</tex-math></alternatives></inline-formula> by gradient descent on <inline-formula><alternatives><mml:math id="inf755"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext/><mml:mi>IP</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>l</mml:mi></mml:munder></mml:mrow><mml:mi>‖</mml:mi><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft755">\begin{document}$E^{\mathrm{IP}}= \frac{1}{2}\sum_{l}\|\boldsymbol{u^{\text{I}}}_{l}- \boldsymbol{W^{\text{IP}}}_{l}\boldsymbol{\bar{r}}_{l}\|^{2}$\end{document}</tex-math></alternatives></inline-formula>, using top-down nudging of the inhibitory neurons (<inline-formula><alternatives><mml:math id="inf756"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft756">\begin{document}${\beta^\text{I}} \gt 0$\end{document}</tex-math></alternatives></inline-formula>),<disp-formula id="equ42"><label>(38)</label><alternatives><mml:math id="m42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t42">\begin{document}$$\displaystyle \boldsymbol{\dot{W}}^{\text{IP}}_{l}= \eta^{\text{IP}}\left(\boldsymbol{u}^{\text{I}}_{l}- \boldsymbol{W}^{\text{IP}}_{l}\boldsymbol{\bar{r}}_{l}\right) \bar{\boldsymbol{r}}_{l}^{\text{T}}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>After learning we have <inline-formula><alternatives><mml:math id="inf757"><mml:mrow><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft757">\begin{document}$\boldsymbol{u^{\text{I}}}_{l}= \boldsymbol{W^{\text{IP}}}_{l}\boldsymbol{\bar{r}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, and plugging in <inline-formula><alternatives><mml:math id="inf758"><mml:mrow><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:msub><mml:msup><mml:mi>𝑩</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft758">\begin{document}$\boldsymbol{u^{\text{I}}}_{l}= (1 -{\beta^\text{I}}) \boldsymbol{W^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{l}+{\beta^\text{I}}\boldsymbol{B^{\text{IP}}}_{l}\boldsymbol u_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="equ10">Equation 9</xref>), we obtain <inline-formula><alternatives><mml:math id="inf759"><mml:mrow><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:msup><mml:mi>𝑩</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft759">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{l}= \boldsymbol{B^{\text{IP}}}_{l}\boldsymbol u_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>. Since <inline-formula><alternatives><mml:math id="inf760"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft760">\begin{document}$\boldsymbol u_{{{l\!+\!1}}}= \boldsymbol W_{{{l\!+\!1}}}{\bar{\boldsymbol{ r }}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, we conclude as before,<disp-formula id="equ43"><label>(39)</label><alternatives><mml:math id="m43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t43">\begin{document}$$\displaystyle \boldsymbol{W^{\text{IP}}}_{l}= \boldsymbol{B^{\text{IP}}}_{l}\, \boldsymbol W_{{{l\!+\!1}}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The top-down weights <inline-formula><alternatives><mml:math id="inf761"><mml:msub><mml:msup><mml:mi>B</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft761">\begin{document}${B^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> that nudge the lower-layer interneurons has randomized entries and may be considered as full rank. If there are less pyramidal neurons in the upper layer than interneurons in the lower layer, <inline-formula><alternatives><mml:math id="inf762"><mml:msub><mml:msup><mml:mi>B</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft762">\begin{document}${B^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> selects a subspace in the interneuron space of dimension <inline-formula><alternatives><mml:math id="inf763"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="inft763">\begin{document}$n_{{{l\!+\!1}}} \lt n_{l}^{{\mathrm{I}}}$\end{document}</tex-math></alternatives></inline-formula>. This seems to simplify the learning of the interneuron-to-pyramidal cell connections <inline-formula><alternatives><mml:math id="inf764"><mml:msup><mml:mi>W</mml:mi><mml:mtext>PI</mml:mtext></mml:msup></mml:math><tex-math id="inft764">\begin{document}${W^{\text{PI}}}$\end{document}</tex-math></alternatives></inline-formula>. In fact, this learning now has only to match the <inline-formula><alternatives><mml:math id="inf765"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft765">\begin{document}$n_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>-dimensional interneuron subspace embedded in <inline-formula><alternatives><mml:math id="inf766"><mml:msubsup><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft766">\begin{document}$n_{l}^{{\mathrm{I}}}$\end{document}</tex-math></alternatives></inline-formula> dimensions to an equal (<inline-formula><alternatives><mml:math id="inf767"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft767">\begin{document}$n_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>-)dimensional pyramidal cell subspace emedded in <inline-formula><alternatives><mml:math id="inf768"><mml:msub><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft768">\begin{document}$n_{l}$\end{document}</tex-math></alternatives></inline-formula> dimensions.</p><p>Learning of the interneuron-to-pyramidal cell connections works with the interneuron nudging as before, and combining <xref ref-type="disp-formula" rid="equ38 equ43">Equations 36 with 39</xref> yields the ‘loop consistency’<disp-formula id="equ44"><label>(40)</label><alternatives><mml:math id="m44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t44">\begin{document}$$\displaystyle \boldsymbol B_{l}\boldsymbol W_{{{l\!+\!1}}}= \boldsymbol{W^{\text{PI}}}_{l}\boldsymbol{B^{\text{IP}}}_{l}\, \boldsymbol W_{{{l\!+\!1}}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The learning of the microcircuit was described in the absence of output nudging. Conceptually, this is not a problem as one could introduce a pre-learning phase where the lateral connections are first correctly aligned before learning of the feedforward weights begins. In simulations we find that both the lateral connections as well as the forward connections can be trained simultaneously, without the need for such a pre-learning phase. We conjecture that this is due to the fact that our plasticity rules are gradient descent on the energy functions <inline-formula><alternatives><mml:math id="inf769"><mml:mi>L</mml:mi></mml:math><tex-math id="inft769">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf770"><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext/><mml:mi>PI</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft770">\begin{document}$E^{\mathrm{PI}}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf771"><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext/><mml:mi>IP</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft771">\begin{document}$E^{\mathrm{IP}}$\end{document}</tex-math></alternatives></inline-formula>, respectively.</p></sec><sec id="s4-7"><title>From implicit to explicit differential equations</title><p>The voltage dynamics is solved by a forward-Euler scheme <inline-formula><alternatives><mml:math id="inf772"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft772">\begin{document}$\boldsymbol u(t + dt) = \boldsymbol u (t) + \boldsymbol{\dot u}(t) \, dt$\end{document}</tex-math></alternatives></inline-formula>. The derivative <inline-formula><alternatives><mml:math id="inf773"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft773">\begin{document}$\boldsymbol{\dot u}(t)$\end{document}</tex-math></alternatives></inline-formula> is calculated either through (<italic>i</italic>) the implicit differential <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref> yielding <inline-formula><alternatives><mml:math id="inf774"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒉</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft774">\begin{document}$\tau \boldsymbol{\dot u}(t) = \boldsymbol h (\boldsymbol u(t), \boldsymbol{\dot u}(t - dt))$\end{document}</tex-math></alternatives></inline-formula>, or (<italic>ii</italic>) by isolating <inline-formula><alternatives><mml:math id="inf775"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft775">\begin{document}$\boldsymbol{\dot u}(t)$\end{document}</tex-math></alternatives></inline-formula> and solving for the explicit differential equation <inline-formula><alternatives><mml:math id="inf776"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft776">\begin{document}$\tau \, \dot{\boldsymbol{u}}(t) = \boldsymbol g(\boldsymbol u(t))$\end{document}</tex-math></alternatives></inline-formula>, as explained in Appendix 3 (after <xref ref-type="disp-formula" rid="equ59">Equation 51</xref>).</p><p>(i) The implicit differential equation, <inline-formula><alternatives><mml:math id="inf777"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>𝒆</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft777">\begin{document}$\tau \boldsymbol{\dot u}(t) = - \boldsymbol u(t) + \boldsymbol W \boldsymbol r(t) + \boldsymbol e(t)$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ24">Equation 22</xref>, is iteratively solved by assigning <inline-formula><alternatives><mml:math id="inf778"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft778">\begin{document}$\boldsymbol r(t) = \rho\big(\boldsymbol u(t)\big) + \rho'\big(\boldsymbol u(t)\big){\!\cdot\!}\boldsymbol{\dot u}(t-dt)$\end{document}</tex-math></alternatives></inline-formula> and calculating the error <inline-formula><alternatives><mml:math id="inf779"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft779">\begin{document}$\boldsymbol e(t) ={\bar{\boldsymbol{ e }}}(t) + \tau{\dot{{\bar{\boldsymbol{ e }}}}}(t)$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf780"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft780">\begin{document}${\bar{\boldsymbol{ e }}}(\boldsymbol u) = \rho'(\boldsymbol u){\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}\big(\boldsymbol u - \boldsymbol W_{{{\!\text{net}}}}\rho(\boldsymbol u) - \boldsymbol W_{{\text{in}}}{\bar{\boldsymbol{ r }}}_{{\text{in}}}\big) + \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf781"><mml:mrow><mml:mover><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft781">\begin{document}${\dot{{\bar{\boldsymbol{ e }}}}}(t) ={\bar{\boldsymbol{ e }}}'(\boldsymbol u(t)){\!\cdot\!}\boldsymbol{\dot u}(t-dt)$\end{document}</tex-math></alternatives></inline-formula>.</p><p>This iteration exponentially converges to a fixed point <inline-formula><alternatives><mml:math id="inf782"><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft782">\begin{document}${\dot u}(t)$\end{document}</tex-math></alternatives></inline-formula> on a time scale <inline-formula><alternatives><mml:math id="inf783"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft783">\begin{document}$\frac{dt}{1-k}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf784"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft784">\begin{document}$1-k \gt 0$\end{document}</tex-math></alternatives></inline-formula> is the smallest Eigenvalue of the Hessian <inline-formula><alternatives><mml:math id="inf785"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mi>𝝆</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft785">\begin{document}$\boldsymbol H = \frac{\partial^{2}L}{\partial \boldsymbol u^{2}}= \boldsymbol 1 - \boldsymbol W_{{{\!\text{net}}}}\boldsymbol \rho' -{\bar{\boldsymbol{ e }}}'$\end{document}</tex-math></alternatives></inline-formula>, see Appendix 3.</p><p>(ii) The explicit differential equation is obtained by eliminating the <inline-formula><alternatives><mml:math id="inf786"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft786">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> from the right-hand side of the implicit differential equation. Since <inline-formula><alternatives><mml:math id="inf787"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft787">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> enters linearly we get <inline-formula><alternatives><mml:math id="inf788"><mml:mrow><mml:mi>τ</mml:mi><mml:mi>𝑯</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>𝒇</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft788">\begin{document}$\tau \boldsymbol H \, \dot{\boldsymbol u}= -\boldsymbol f - \tau\frac{\partial \boldsymbol f}{\partial t}$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf789"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft789">\begin{document}$\boldsymbol f(\boldsymbol u, t) = \frac{\partial L}{\partial \boldsymbol u}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>. The explicit form is obtained by matrix inversion, <inline-formula><alternatives><mml:math id="inf790"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac></mml:mstyle><mml:msup><mml:mi>𝑯</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mi>𝒇</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft790">\begin{document}$\dot{\boldsymbol{u}}= \boldsymbol g(\boldsymbol u, t) = - \tfrac{1}{\tau}\boldsymbol H^{-1}\left(\boldsymbol f + \tau \frac{\partial \boldsymbol f}{\partial t}\right)$\end{document}</tex-math></alternatives></inline-formula>, as the Hessian is invertible if it is strictly positive definite (which is typically the case, see Appendix 3, after <xref ref-type="disp-formula" rid="equ56">Equation 48</xref>). The external input and the target enter through <inline-formula><alternatives><mml:math id="inf791"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mover><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msubsup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft791">\begin{document}$\frac{\partial \boldsymbol f}{\partial t}= \boldsymbol W_{{\text{in}}}\dot{ {\bar{\boldsymbol{ r }}}}_{{\text{in}}}+ \beta \, \dot{\boldsymbol u}^{*}_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>, where the derivative of the target voltage is only added for the output neurons <inline-formula><alternatives><mml:math id="inf792"><mml:mi>𝒐</mml:mi></mml:math><tex-math id="inft792">\begin{document}$\boldsymbol o$\end{document}</tex-math></alternatives></inline-formula>. This explicit differential equation is shown to be contractive in the sense that for each input trajectory <inline-formula><alternatives><mml:math id="inf793"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft793">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> and target trajectory <inline-formula><alternatives><mml:math id="inf794"><mml:mrow><mml:msup><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft794">\begin{document}$\boldsymbol u^{*}(t)$\end{document}</tex-math></alternatives></inline-formula>, the voltage trajectory <inline-formula><alternatives><mml:math id="inf795"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft795">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula> is locally attracting for neighbouring trajectories. This local attracting trajectory is the vanishing-gradient trajectory <inline-formula><alternatives><mml:math id="inf796"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft796">\begin{document}$\boldsymbol f(\boldsymbol u, t) = 0$\end{document}</tex-math></alternatives></inline-formula>, and the gradient remains 0 even if the input contains delta-functions, see Appendix 4.</p><sec id="s4-7-1"><title>Moving and latent equilibria: a formal definition</title><p>We showed that the motor output (<inline-formula><alternatives><mml:math id="inf797"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft797">\begin{document}$\boldsymbol{u_o}$\end{document}</tex-math></alternatives></inline-formula>), together with the low-pass filtered sensory input (<inline-formula><alternatives><mml:math id="inf798"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft798">\begin{document}$\boldsymbol{\bar{r}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>) and the motor feedback (<inline-formula><alternatives><mml:math id="inf799"><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft799">\begin{document}${\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*}$\end{document}</tex-math></alternatives></inline-formula>) is in a moving equilibrium, <inline-formula><alternatives><mml:math id="inf800"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft800">\begin{document}$\boldsymbol u_{\boldsymbol o}= \boldsymbol F_{W}(\boldsymbol{\bar{r}}_{{\text{in}}},{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="fig" rid="fig3">Figure 3a</xref>. In general, a dynamical system in <inline-formula><alternatives><mml:math id="inf801"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft801">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> that is given in an implicit form <inline-formula><alternatives><mml:math id="inf802"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft802">\begin{document}$\boldsymbol G(\boldsymbol x, \boldsymbol{\dot x}, \boldsymbol u, \boldsymbol{\dot u}) = 0$\end{document}</tex-math></alternatives></inline-formula> with external inputs <inline-formula><alternatives><mml:math id="inf803"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft803">\begin{document}$(\boldsymbol x, \boldsymbol{\dot x})$\end{document}</tex-math></alternatives></inline-formula> is said to be in a moving equilibrium if the variable <inline-formula><alternatives><mml:math id="inf804"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft804">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> is an instantaneous function of the input <inline-formula><alternatives><mml:math id="inf805"><mml:mi>𝒙</mml:mi></mml:math><tex-math id="inft805">\begin{document}$\boldsymbol x$\end{document}</tex-math></alternatives></inline-formula> at any point in time, <inline-formula><alternatives><mml:math id="inf806"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft806">\begin{document}$\boldsymbol u = \boldsymbol F(\boldsymbol x)$\end{document}</tex-math></alternatives></inline-formula>. The fact that the implicit differential equation <inline-formula><alternatives><mml:math id="inf807"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft807">\begin{document}$\boldsymbol G = 0$\end{document}</tex-math></alternatives></inline-formula> represents a dynamical system in <inline-formula><alternatives><mml:math id="inf808"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft808">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> implies that, in principle, it has a representation in the explicit form <inline-formula><alternatives><mml:math id="inf809"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft809">\begin{document}$\boldsymbol{\dot u}= \boldsymbol g(\boldsymbol u, \boldsymbol x, \boldsymbol{\dot x})$\end{document}</tex-math></alternatives></inline-formula>, guaranteed by an invertible Jacobian <inline-formula><alternatives><mml:math id="inf810"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="inft810">\begin{document}$\tfrac{\partial \boldsymbol G}{\partial \boldsymbol{\dot u}}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Our example is obtained from <inline-formula><alternatives><mml:math id="inf811"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>𝝉</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>𝒇</mml:mi></mml:mrow></mml:math><tex-math id="inft811">\begin{document}$\boldsymbol G = (1 + \boldsymbol \tau\!{\!\cdot\!}\!\tfrac{{\mathrm{d}}}{{\mathrm{d}} t}) \boldsymbol f$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf812"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft812">\begin{document}$\boldsymbol f(\boldsymbol u, \boldsymbol x) = \frac{\partial L}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf813"><mml:mrow><mml:mi>𝒙</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft813">\begin{document}$\boldsymbol x = (\boldsymbol{\bar{r}}_{{\text{in}}},{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula>, leading to <inline-formula><alternatives><mml:math id="inf814"><mml:mrow><mml:mi>𝒙</mml:mi><mml:mo>+</mml:mo><mml:mi>𝝉</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒆</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft814">\begin{document}$\boldsymbol x + \boldsymbol \tau{\!\cdot\!}\boldsymbol{\dot x}= (\boldsymbol r_{{\text{in}}}, \boldsymbol e_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula>. Given the paramterization of <inline-formula><alternatives><mml:math id="inf815"><mml:mi>𝑮</mml:mi></mml:math><tex-math id="inft815">\begin{document}$\boldsymbol G$\end{document}</tex-math></alternatives></inline-formula> by the weights, we get the parametrized function <inline-formula><alternatives><mml:math id="inf816"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft816">\begin{document}$\boldsymbol u = \boldsymbol F_{W}(\boldsymbol x)$\end{document}</tex-math></alternatives></inline-formula>, and this is restricted to the output components <inline-formula><alternatives><mml:math id="inf817"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub></mml:math><tex-math id="inft817">\begin{document}$\boldsymbol u_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> of <inline-formula><alternatives><mml:math id="inf818"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft818">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>. The condition on the Jacobian translates to <inline-formula><alternatives><mml:math id="inf819"><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msup><mml:mi>𝒖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math><tex-math id="inft819">\begin{document}$\tfrac{\partial \boldsymbol G}{\partial \boldsymbol{\dot u}}= \tfrac{\partial \boldsymbol f}{\partial \boldsymbol u}= \tfrac{\partial^2 L}{\partial \boldsymbol u^2}$\end{document}</tex-math></alternatives></inline-formula> being invertible. Crucially, the description of the dynamics in the biological or physical substrate is not given in its explicit form <inline-formula><alternatives><mml:math id="inf820"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft820">\begin{document}$\boldsymbol{\dot u}= \boldsymbol g(\boldsymbol u, \boldsymbol x, \boldsymbol{\dot x})$\end{document}</tex-math></alternatives></inline-formula>. However, it is given in an implicit form expressed as <inline-formula><alternatives><mml:math id="inf821"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒉</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒙</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft821">\begin{document}$\boldsymbol{\dot u}= \boldsymbol h (\boldsymbol x, \boldsymbol{\dot x}, \boldsymbol u, \boldsymbol{\dot u})$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf822"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft822">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula> still appears on the right-hand side. This ‘hybrid’ form is directly solved either in real time by the biophysical substrate itself, or by the forward-Euler scheme on clocked hardware, see (<inline-formula><alternatives><mml:math id="inf823"><mml:mi>i</mml:mi></mml:math><tex-math id="inft823">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula>) above. Notice that moving equilibria <inline-formula><alternatives><mml:math id="inf824"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft824">\begin{document}$\boldsymbol u = \boldsymbol F_{W}(\boldsymbol x)$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf825"><mml:mrow><mml:mi>𝒙</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft825">\begin{document}$\boldsymbol x = (\boldsymbol{\bar{r}}_{{\text{in}}},{\bar{\boldsymbol{ e }}}_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula> are able to capture complex temporal processing of the instantaneous input <inline-formula><alternatives><mml:math id="inf826"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft826">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>. In fact, the low-pass filtering <inline-formula><alternatives><mml:math id="inf827"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft827">\begin{document}$\boldsymbol{\bar{r}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> can be obtained on various time scales through different <inline-formula><alternatives><mml:math id="inf828"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft828">\begin{document}$\tau_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>’s, and <inline-formula><alternatives><mml:math id="inf829"><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:math><tex-math id="inft829">\begin{document}$\boldsymbol F_{W}$\end{document}</tex-math></alternatives></inline-formula> for a general network <inline-formula><alternatives><mml:math id="inf830"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft830">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> can be arbitrary complex. The task is to adapt <inline-formula><alternatives><mml:math id="inf831"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft831">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> such that the ‘hybrid’ dynamical system eventually implements the target mapping <inline-formula><alternatives><mml:math id="inf832"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft832">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}= \boldsymbol F^{*}(\boldsymbol x)$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The Latent Equilibrium (<xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>) can be analogously formalized as a dynamical system in <inline-formula><alternatives><mml:math id="inf833"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft833">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, implicitly given by <inline-formula><alternatives><mml:math id="inf834"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft834">\begin{document}$\boldsymbol G(\boldsymbol x, \boldsymbol u, \boldsymbol{\dot u}) = 0$\end{document}</tex-math></alternatives></inline-formula>, and having a solution of the form <inline-formula><alternatives><mml:math id="inf835"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>𝝉</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft835">\begin{document}$\boldsymbol u + \boldsymbol \tau{\!\cdot\!}\boldsymbol{\dot u}= \boldsymbol F(\boldsymbol x)$\end{document}</tex-math></alternatives></inline-formula>. Abbreviating again <inline-formula><alternatives><mml:math id="inf836"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft836">\begin{document}$\boldsymbol f(\boldsymbol u, \boldsymbol x) = \frac{\partial L}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> with the same Lagrangian <inline-formula><alternatives><mml:math id="inf837"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>‖</mml:mi><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft837">\begin{document}$L = \tfrac{1}{2}\| \boldsymbol u - \boldsymbol W \rho(\boldsymbol u) \|^{2}+ \tfrac{\beta}{2}C$\end{document}</tex-math></alternatives></inline-formula> as in the present NLA, the Latent Equilibrium is obtained for <inline-formula><alternatives><mml:math id="inf838"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>𝝉</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft838">\begin{document}$\boldsymbol G(\boldsymbol x, \boldsymbol u, \boldsymbol{\dot u}) = \boldsymbol f(\boldsymbol u + \boldsymbol \tau{\!\cdot\!}\boldsymbol{\dot u}, \boldsymbol x)$\end{document}</tex-math></alternatives></inline-formula>. The solution implies that the rate <inline-formula><alternatives><mml:math id="inf839"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>𝝉</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft839">\begin{document}$\boldsymbol r = \rho(\boldsymbol u + \boldsymbol \tau{\!\cdot\!}\boldsymbol{\dot u}) = \rho(\boldsymbol F(\boldsymbol x))$\end{document}</tex-math></alternatives></inline-formula> is an instantaneous function of <inline-formula><alternatives><mml:math id="inf840"><mml:mrow><mml:mi>𝒙</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒆</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft840">\begin{document}$\boldsymbol x = (\boldsymbol r_{{\text{in}}}, \boldsymbol e_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula>, here without low-pass filtering. As for moving equilibria, the crucial point is that the biophysical substrate implements a hybrid form of the dynamical system, now <inline-formula><alternatives><mml:math id="inf841"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒉</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒙</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft841">\begin{document}$\boldsymbol{\dot u}= \boldsymbol h (\boldsymbol x, \boldsymbol u, \boldsymbol{\dot u})$\end{document}</tex-math></alternatives></inline-formula>, that is implicitly solved by the analog substrate, and also allows for a solution in clocked hardware. For an extended stability analysis of the moving and latent equilibria see Appendix 4.</p></sec></sec><sec id="s4-8"><title>Simulation details</title><p>Solving the explicit differential equation seems to be more robust when the learning rate for <inline-formula><alternatives><mml:math id="inf842"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft842">\begin{document}$\boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula> gets larger. The explicit form is also less sensitive to large Euler steps <inline-formula><alternatives><mml:math id="inf843"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft843">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula>, see Appendix 3. By this reason, the ordinary differential equations (ODE) were solved in the explicit form when including plasticity <inline-formula><alternatives><mml:math id="inf844"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft844">\begin{document}$\boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula>. The algorithms are summarized as follows, once without interneurons (Algorithm 1), and once with interneurons (Algorithm 2):</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups" id="AL1"><thead><tr><th align="left" valign="bottom">Algorithm 1. with projection neurons only, for <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig4">4</xref> (using the explicit ODE, i.e., Step 12 instead of 11)</th></tr></thead><tbody><tr><td align="left" valign="bottom">1: current state: <inline-formula><alternatives><mml:math id="inf845"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft845">\begin{document}${u}(t)$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf846"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft846">\begin{document}${W}(t)$\end{document}</tex-math></alternatives></inline-formula><break/>2: # consider full vectors and matrices (padded with 0’s for feedforward networks)<break/>3:# drop time argument <inline-formula><alternatives><mml:math id="inf847"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft847">\begin{document}${(t)}$\end{document}</tex-math></alternatives></inline-formula> for convenience<break/>4: <inline-formula><alternatives><mml:math id="inf848"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft848">\begin{document}${\bar{r}}_{{{\!\text{net}}}}\leftarrow\rho({u})$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf849"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft849">\begin{document}${\bar{r}}\leftarrow\left({\bar{r}}_{{\text{in}}},{\bar{r}}_{{{\!\text{net}}}}\right)^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> , <inline-formula><alternatives><mml:math id="inf850"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft850">\begin{document}${W}\leftarrow\left({W}_{{\text{in}}},{W}_{{{\!\text{net}}}}\right)$\end{document}</tex-math></alternatives></inline-formula><break/>5: calculate weight derivatives<break/>6: <inline-formula><alternatives><mml:math id="inf851"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft851">\begin{document}${\dot{W}}\leftarrow\eta({u}-{W}{\bar{r}}){\bar{r}}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula><break/>7: calculate low-pass-filtered errors<break/>8: <inline-formula><alternatives><mml:math id="inf852"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">←</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft852">\begin{document}${\bar{e}}_{{o}}^{*}\leftarrow{u}_{{o}}^{*}-{u}_{{o}}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf853"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft853">\begin{document}${\bar{e}}_{i}^{*}=0$\end{document}</tex-math></alternatives></inline-formula> for non-output neurons<break/>9: <inline-formula><alternatives><mml:math id="inf854"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft854">\begin{document}${\bar{e}}\leftarrow{\bar{r}}_{{{\!\text{net}}}}^{\prime}{\!\cdot\!}{W}_{{{\!\text{net}}}}^{{\text{T}}}({u}-{W}{\bar{r}})+\beta{\bar{e}}^{*}$\end{document}</tex-math></alternatives></inline-formula><break/>10: calculate temporal voltage derivatives either implicitly (11) or explicitly (12)<break/>11: Implicit:  <inline-formula><alternatives><mml:math id="inf855"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft855">\begin{document}$\tau{\dot{u}}\leftarrow-{u}+{W}({\bar{{r}}}+\tau\dot{{\bar{{r}}}})+({\bar{{e}}}+\tau\dot{{\bar{{e}}}})$\end{document}</tex-math></alternatives></inline-formula><break/>12: Explicit: <inline-formula><alternatives><mml:math id="inf856"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft856">\begin{document}${f}\leftarrow{u}-{W}{\bar{r}}-{\bar{e}}$\end{document}</tex-math></alternatives></inline-formula> , <inline-formula><alternatives><mml:math id="inf857"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="inft857">\begin{document}${H}\leftarrow\frac{\partial{f}}{\partial{u}}$\end{document}</tex-math></alternatives></inline-formula> , <inline-formula><alternatives><mml:math id="inf858"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft858">\begin{document}${\dot{u}}\leftarrow$\end{document}</tex-math></alternatives></inline-formula> solve <inline-formula><alternatives><mml:math id="inf859"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="inft859">\begin{document}$\tau{H}({u})\,\dot{{u}}=-{f}-\tau\frac{\partial{f}}{\partial t}$\end{document}</tex-math></alternatives></inline-formula> via Cholesky decomposition<break/>13: update voltage and weights<break/>14: <inline-formula><alternatives><mml:math id="inf860"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft860">\begin{document}${u}\leftarrow{u}+{\dot{u}}{\!\cdot\!}dt$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf861"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft861">\begin{document}${W}\leftarrow{W}+{\dot{W}}{\!\cdot\!}dt$\end{document}</tex-math></alternatives></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups" id="AL2"><thead><tr><th align="left" valign="bottom">Algorithm 2. including plastic interneurons, for <xref ref-type="fig" rid="fig5">Figure 5</xref> (using the explicit ODE, i.e., Step 13 instead of 12)</th></tr></thead><tbody><tr><td align="left" valign="bottom">1: current state: <inline-formula><alternatives><mml:math id="inf862"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft862">\begin{document}${u}(t)$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf863"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft863">\begin{document}${W}(t),{u}^{\text{I}}(t),{W}^{\text{PI}}(t),{W}^{\text{IP}}(t)$\end{document}</tex-math></alternatives></inline-formula><break/>2: # consider full vectors and matrices and drop time argument as in Algorithm 1<break/>3: <inline-formula><alternatives><mml:math id="inf864"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft864">\begin{document}${\bar{r}}\leftarrow\left({\bar{r}}_{\text{in}},\rho({u})\right)^{\text{T}}$\end{document}</tex-math></alternatives></inline-formula><break/>4: calculate weight derivatives<break/>5: <inline-formula><alternatives><mml:math id="inf865"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft865">\begin{document}${\dot{W}}\leftarrow\eta({u}-{W}{\bar{r}})\bar{r}^{\text{T}}$\end{document}</tex-math></alternatives></inline-formula><break/>6: <inline-formula><alternatives><mml:math id="inf866"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">←</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft866">\begin{document}${\dot{W}}^{\text{PI}}\leftarrow\eta^{\text{PI}}({B}{u}-{W}^{\text{PI}}{u}^{\text{I}}){u^{\text{I}}}^{\text{T}}$\end{document}</tex-math></alternatives></inline-formula><break/>7: <inline-formula><alternatives><mml:math id="inf867"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">←</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft867">\begin{document}${\dot{W}}^{\text{IP}}\leftarrow\eta^{\text{IP}}({u}^{\text{I}}-{W}^{\text{IP}}{\bar{r}})\bar{{r}}^{\text{T}}$\end{document}</tex-math></alternatives></inline-formula><break/>8: calculate low-pass filtered errors<break/>9: <inline-formula><alternatives><mml:math id="inf868"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">←</mml:mo><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft868">\begin{document}${\bar{e}}_{{o}}^{*}\leftarrow{u}_{{o}}^{*}-{u}_{{o}}$\end{document}</tex-math></alternatives></inline-formula> (<inline-formula><alternatives><mml:math id="inf869"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft869">\begin{document}$\bar{e}_{i}^{*}=0$\end{document}</tex-math></alternatives></inline-formula> for non-output neurons <italic>i</italic>)<break/>10: <inline-formula><alternatives><mml:math id="inf870"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft870">\begin{document}${\bar{e}}\leftarrow{B}{u}-{W}^{\text{PI}}{u}^{\text{I}}+\beta{\bar{e}}^{*}$\end{document}</tex-math></alternatives></inline-formula> (<inline-formula><alternatives><mml:math id="inf871"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mo>:</mml:mo></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft871">\begin{document}${B}_{o,:}={W}^{\text{PI}}_{o,:}=0$\end{document}</tex-math></alternatives></inline-formula> for output neurons o)<break/>11: calculate temporal voltage derivatives either implicitly (12) or explicitly (13)<break/>12: Implicit: <inline-formula><alternatives><mml:math id="inf872"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft872">\begin{document}$\tau{\dot{u}}\leftarrow-{u}+{W}(\bar{{r}}+\tau\dot{\bar{{r}}})+(\bar{{e}}+\tau\dot{\bar{{e}}})$\end{document}</tex-math></alternatives></inline-formula><break/>13: Explicit: <inline-formula><alternatives><mml:math id="inf873"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft873">\begin{document}${f}\leftarrow{u}-{W}{\bar{r}}-{\bar{e}}$\end{document}</tex-math></alternatives></inline-formula> , <inline-formula><alternatives><mml:math id="inf874"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="inft874">\begin{document}${H}\leftarrow\frac{\partial{f}}{\partial{u}}$\end{document}</tex-math></alternatives></inline-formula> , <inline-formula><alternatives><mml:math id="inf875"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">←</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft875">\begin{document}${\dot{u}}\leftarrow$\end{document}</tex-math></alternatives></inline-formula> solve <inline-formula><alternatives><mml:math id="inf876"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="inft876">\begin{document}$\tau{H}({u})\,\dot{u}=-{f}-\tau\frac{\partial{f}}{\partial t}$\end{document}</tex-math></alternatives></inline-formula> via Cholesky decomposition<break/>14: update network state \For<inline-formula><alternatives><mml:math id="inf877"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>PI</mml:mtext></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft877">\begin{document}${X}\in\{{u},{W},{W}^{\text{PI}},{W}^{\text{IP}}\}$\end{document}</tex-math></alternatives></inline-formula><break/>15: <inline-formula><alternatives><mml:math id="inf878"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft878">\begin{document}${X}\leftarrow{X}+{\dot{X}}dt$\end{document}</tex-math></alternatives></inline-formula> End For<break/>16: <inline-formula><alternatives><mml:math id="inf879"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">←</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mtext>IP</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mover><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mtext>I</mml:mtext></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft879">\begin{document}${u}^{\text{I}}\leftarrow(1-\beta^{\text{I}}){W}^{\text{IP}}\bar{{r}}+\beta^{\text{I}}{B}^{\mathrm{I}\mathrm{P}}{u}$\end{document}</tex-math></alternatives></inline-formula></td></tr></tbody></table></table-wrap><sec id="s4-8-1"><title>Details for <xref ref-type="fig" rid="fig3">Figure 3b</xref></title><p>Color coded snapshot of cortical local field potentials (LFPs) in a human brain from 56 deep iEEG electrodes at various locations, converted with the sigmoidal voltage-to-rate function <inline-formula><alternatives><mml:math id="inf880"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">−</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft880">\begin{document}${\bar{r}}(u) = \frac{1}{1 + e^{-u}}$\end{document}</tex-math></alternatives></inline-formula> and plotted onto a standard Talairach Brain (<xref ref-type="bibr" rid="bib90">Talairach and Tournoux, 1988</xref>). The iEEG data is from a patient with pharmacoresistant epilepsy and electrodes implanted during presurgical evaluation, extracted from the data release of <xref ref-type="bibr" rid="bib15">Burrello et al., 2019</xref>. The locations of the electrodes are chosen in accordance with plausibilty, as the original positions of the electrodes were omitted due to ethical standards to prevent patient identification.</p></sec><sec id="s4-8-2"><title>Details for <xref ref-type="fig" rid="fig3">Figure 3c</xref></title><p>Simulations of the voltage dynamics (<xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>) and weight dynamics (<xref ref-type="disp-formula" rid="equ9">Equation 8</xref>), with learning rate <inline-formula><alternatives><mml:math id="inf881"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft881">\begin{document}$\eta=10^{-3}$\end{document}</tex-math></alternatives></inline-formula>, step size <inline-formula><alternatives><mml:math id="inf882"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:math><tex-math id="inft882">\begin{document}$dt =$\end{document}</tex-math></alternatives></inline-formula> 1ms for the forward Euler integration, membrane time constant  <inline-formula><alternatives><mml:math id="inf883"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft883">\begin{document}$\rm \tau =10\,{ms}$\end{document}</tex-math></alternatives></inline-formula> and logistic activation function. Weights were initialized randomly from a normal distribution <inline-formula><alternatives><mml:math id="inf884"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo separator="true">,</mml:mo><mml:mn>0</mml:mn><mml:mi>.</mml:mi><mml:msup><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft884">\begin{document}${\mathcal{N}}(0, 0.1^{2})$\end{document}</tex-math></alternatives></inline-formula> with a cut-off at ± 0.3. The number of neurons in the network <inline-formula><alternatives><mml:math id="inf885"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:math><tex-math id="inft885">\begin{document}${\mathcal{N}}$\end{document}</tex-math></alternatives></inline-formula> was <inline-formula><alternatives><mml:math id="inf886"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>96</mml:mn></mml:mrow></mml:math><tex-math id="inft886">\begin{document}$n=96$\end{document}</tex-math></alternatives></inline-formula>, among them 56 output neurons <inline-formula><alternatives><mml:math id="inf887"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi><mml:mo>⊂</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow></mml:math><tex-math id="inft887">\begin{document}${{\mathcal{O}}}\subset{{\mathcal{N}}}$\end{document}</tex-math></alternatives></inline-formula> that were simultaneously nudged, and 40 hidden neurons. During training, all output neurons were nudged simultaneously (with <inline-formula><alternatives><mml:math id="inf888"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math><tex-math id="inft888">\begin{document}$\beta = 0.1$\end{document}</tex-math></alternatives></inline-formula>), whereas during testing, only 42 out of 56 neurons were nudged, the remaining 14 left to reproduce the traces. Data points of the iEEG signal were sampled with a frequency of 512 Hz. For simplicity, we, therefore, assumed that successive data points are separated by 2ms, and up-sampled the signal via simple interpolation to 1 ms resolution as required by our integration scheme. Furthermore, the raw values were normalized by dividing them by a factor of 200 to ensure that they are approximately in a range of ±1–2. Training and testing was done on two separate 8 s traces of the iEEG recording. Same data as in <xref ref-type="fig" rid="fig3">Figure 3b1</xref>.</p></sec><sec id="s4-8-3"><title>Details for <xref ref-type="fig" rid="fig4">Figure 4</xref></title><p>Simulation of the neuronal and synaptic dynamics as given by <xref ref-type="disp-formula" rid="equ9">Equation 8</xref>, <xref ref-type="disp-formula" rid="equ7">Equation 7a</xref>, <xref ref-type="disp-formula" rid="equ8">Equation 7b</xref>. For 5 ms, 10 ms, and 50 ms presentation time, we used an integration step size of <inline-formula><alternatives><mml:math id="inf889"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.05</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft889">\begin{document}$dt =\, 0.05\rm\, ms$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf890"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.1</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft890">\begin{document}$dt=\,0.1\,\rm ms$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf891"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.5</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft891">\begin{document}$dt =\rm \,0.5\, ms$\end{document}</tex-math></alternatives></inline-formula>, respectively (and <inline-formula><alternatives><mml:math id="inf892"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft892">\begin{document}$dt=\,1\rm\, ms$\end{document}</tex-math></alternatives></inline-formula> otherwise). As an activation function, we used the step-linear function (hard sigmoidal) with <inline-formula><alternatives><mml:math id="inf893"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft893">\begin{document}$\bar r(u) = 0$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf894"><mml:mrow><mml:mi>u</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft894">\begin{document}$u \leq 0$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf895"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft895">\begin{document}$\bar r(u) = 1$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf896"><mml:mrow><mml:mi>u</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft896">\begin{document}$u \geq 1$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf897"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:math><tex-math id="inft897">\begin{document}$\bar r(u) = u$\end{document}</tex-math></alternatives></inline-formula> in between. The learning rate was initially set to <inline-formula><alternatives><mml:math id="inf898"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft898">\begin{document}$\eta=10^{-3}$\end{document}</tex-math></alternatives></inline-formula> and then reduced to <inline-formula><alternatives><mml:math id="inf899"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft899">\begin{document}$\eta = 10^{-4}$\end{document}</tex-math></alternatives></inline-formula> after 22,000 s. The nudging strength was <inline-formula><alternatives><mml:math id="inf900"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft900">\begin{document}$\beta=\, 0.1$\end{document}</tex-math></alternatives></inline-formula> and the membrane time constant <inline-formula><alternatives><mml:math id="inf901"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>10</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft901">\begin{document}$\tau =\, 10\,\rm ms$\end{document}</tex-math></alternatives></inline-formula>. In these simulations (and only for these) we assumed that at each presynaptic layer <inline-formula><alternatives><mml:math id="inf902"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>0,1</mml:mn><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft902">\begin{document}$l=0,1,..,n-1$\end{document}</tex-math></alternatives></inline-formula> there is a first neuron indexed by 0 that fires with constant rate <inline-formula><alternatives><mml:math id="inf903"><mml:mrow><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mo separator="true">,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft903">\begin{document}${\bar{r}}_{l,0}= 1$\end{document}</tex-math></alternatives></inline-formula>, effectively allowing the postsynaptic neurons <inline-formula><alternatives><mml:math id="inf904"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft904">\begin{document}$\boldsymbol{\bar{r}}_{l+1}$\end{document}</tex-math></alternatives></inline-formula> to learn a bias through the first column of the weight matrix <inline-formula><alternatives><mml:math id="inf905"><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft905">\begin{document}$\boldsymbol W_{l+1}$\end{document}</tex-math></alternatives></inline-formula>. Weights were initialized randomly from a normal distribution <inline-formula><alternatives><mml:math id="inf906"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo separator="true">,</mml:mo><mml:msup><mml:mn>0.01</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft906">\begin{document}${\mathcal{N}}(0, 0.01^{2})$\end{document}</tex-math></alternatives></inline-formula> with a cut-off at ±0.03. For an algorithmic conversion see the scheme below. In <xref ref-type="fig" rid="fig4">Figure 4c1</xref>, ‘rt-DeEP w/o lookahead’ is based on the dynamics <inline-formula><alternatives><mml:math id="inf907"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft907">\begin{document}$\tau \boldsymbol{\dot u}= - \boldsymbol u + \boldsymbol W \bar{\boldsymbol r}+ \bar{\boldsymbol e}$\end{document}</tex-math></alternatives></inline-formula>. For ‘<inline-formula><alternatives><mml:math id="inf908"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft908">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> w/o error + backprop,’ we use <inline-formula><alternatives><mml:math id="inf909"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi></mml:mrow></mml:math><tex-math id="inft909">\begin{document}$\tau \boldsymbol{\dot u}= - \boldsymbol u + \boldsymbol W \boldsymbol r$\end{document}</tex-math></alternatives></inline-formula> as the forward model (so without error terms on the membrane potential, but a prospective <inline-formula><alternatives><mml:math id="inf910"><mml:mi>𝒓</mml:mi></mml:math><tex-math id="inft910">\begin{document}$\boldsymbol r$\end{document}</tex-math></alternatives></inline-formula>), and calculate weight updates using error backpropagation. In 4c2, we provide three controls: the test error for (i) a standard shallow artificial neural network trained on MNIST (black dashed line), (ii) rt-DeEP without prospective coding (as in <xref ref-type="fig" rid="fig4">Figure 4c1</xref>), but in <xref ref-type="fig" rid="fig4">Figure 4c2</xref> with plasticity only turned on when the network is completely stationary, i.e., after waiting for several 100ms, such that synaptic weights are not changed during transients (orange dashed line, denoted by ‘w/o transients’), and (iii) an equivalent artificial neural network, <inline-formula><alternatives><mml:math id="inf911"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft911">\begin{document}$\boldsymbol u_{l}= \boldsymbol W_{l}{\bar{\boldsymbol{ r }}}_{l-1}$\end{document}</tex-math></alternatives></inline-formula>, trained using error backpropagation (black dashed line, ‘standard backprop’).</p></sec><sec id="s4-8-4"><title>Details for <xref ref-type="fig" rid="fig5">Figure 5</xref></title><p>Simulation of neuronal and synaptic dynamics with plastic microcircuit, i.e., the pyramidal-to-interneuron and lateral weights of the microcircuit learned during training.</p><p>For the results shown in <xref ref-type="fig" rid="fig5">Figure 5c2</xref>, the following parameters were used. As an activation function, we used a hard sigmoid function and the membrane time constant was set to <inline-formula><alternatives><mml:math id="inf912"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math><tex-math id="inft912">\begin{document}$\tau = 10$\end{document}</tex-math></alternatives></inline-formula> ms. Image presentation time is 100ms. Forward, pyramidal-to-interneuron and interneuron-to-pyramidal weights were initialized randomly from a normal distribution <inline-formula><alternatives><mml:math id="inf913"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo separator="true">,</mml:mo><mml:msup><mml:mn>0.01</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft913">\begin{document}$\mathcal{N}(0, 0.01^{2})$\end{document}</tex-math></alternatives></inline-formula> with a cut-off at ±0.03. All learning rates were chosen equal <inline-formula><alternatives><mml:math id="inf914"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft914">\begin{document}$\eta = 10^{-3}$\end{document}</tex-math></alternatives></inline-formula> and were subsequently reduced to <inline-formula><alternatives><mml:math id="inf915"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft915">\begin{document}$\eta = 10^{-4}$\end{document}</tex-math></alternatives></inline-formula> after 22,000 s training time. The nudging parameters were set to <inline-formula><alternatives><mml:math id="inf916"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math><tex-math id="inft916">\begin{document}$\beta = 0.1$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf917"><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>0.1</mml:mn><mml:mn>1.1</mml:mn></mml:mfrac></mml:mrow></mml:math><tex-math id="inft917">\begin{document}$\beta^{{\mathrm{I}}}= \frac{0.1}{1.1}$\end{document}</tex-math></alternatives></inline-formula>. The feedback connections <inline-formula><alternatives><mml:math id="inf918"><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft918">\begin{document}$\boldsymbol B_{l}$\end{document}</tex-math></alternatives></inline-formula> and the nudging matrices <inline-formula><alternatives><mml:math id="inf919"><mml:msubsup><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:math><tex-math id="inft919">\begin{document}$\boldsymbol B^{{\mathrm{I}}{\mathrm{P}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> were initialized randomly from a normal distribution <inline-formula><alternatives><mml:math id="inf920"><mml:mrow><mml:mn>5</mml:mn><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo separator="true">,</mml:mo><mml:msup><mml:mn>0.01</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft920">\begin{document}$5{\!\cdot\!}\mathcal{N}(0, 0.01^{2})$\end{document}</tex-math></alternatives></inline-formula> with a cut-off at ±0.15. The used integration step size was <inline-formula><alternatives><mml:math id="inf921"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math><tex-math id="inft921">\begin{document}$dt = 0.25$\end{document}</tex-math></alternatives></inline-formula> ms. All weights were trained simultaneously. For an algorithmic conversion see the scheme below. The interneuron membrane potential was calculated by <xref ref-type="disp-formula" rid="equ10">Equation 9</xref> with a linear transfer function.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con3"><p>Data curation, Software, Formal analysis, Investigation, Methodology</p></fn><fn fn-type="con" id="con4"><p>Data curation, Software, Investigation, Visualization</p></fn><fn fn-type="con" id="con5"><p>Software, Supervision, Investigation, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Formal analysis, Investigation, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-89674-mdarchecklist1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, and the modelling code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/unibe-cns/nla-code">GitHub</ext-link>, copy archived at <xref ref-type="bibr" rid="bib27">Ellenberger, 2024</xref>.</p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to thank Federico Benitez, Jonathan Binas, Paul Haider, Kevin Max, Alexander Mathis, Alexander Meulemans, and Jean-Pascal Pfister for helpful discussions, Kaspar Schindler for providing the human intracortical EEG data, and the late Karlheinz Meier for his dedication and support throughout the early stages of the project. WS thanks Nicolas Zucchet for mathematical discussions and hints to the literature on time-varying optimal control. DD acknowledges support through the European Space Agency's Postdoctoral Research Fellowship Programme. We express our particular gratitude towards the Manfred Stärk Foundation for their continued support.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Varela</surname><given-names>JA</given-names></name><name><surname>Sen</surname><given-names>K</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Synaptic depression and cortical gain control</article-title><source>Science</source><volume>275</volume><fpage>220</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1126/science.275.5297.221</pub-id><pub-id pub-id-type="pmid">8985017</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ackley</surname><given-names>DH</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>A learning algorithm for boltzmann machines</article-title><source>Cognitive Science</source><volume>9</volume><fpage>147</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1016/S0364-0213(85)80012-4</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Akrout</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>C</given-names></name><name><surname>Humphreys</surname><given-names>PC</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name><name><surname>Tweed</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Deep Learning without Weight Transport</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1904.05391">https://arxiv.org/abs/1904.05391</ext-link></element-citation></ref><ref id="bib4"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Alonso</surname><given-names>E</given-names></name><name><surname>Fairbank</surname><given-names>M</given-names></name><name><surname>Mondragón</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Conditioning for least action</article-title><conf-name>Proceedings of the 11th International Conference on Cognitive Modeling, ICCM</conf-name><fpage>234</fpage><lpage>239</lpage></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amirikian</surname><given-names>BR</given-names></name><name><surname>Lukashin</surname><given-names>AV</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>A neural network learns trajectory of motion from the least action principle</article-title><source>Biological Cybernetics</source><volume>66</volume><fpage>261</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1007/BF00198479</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JS</given-names></name><name><surname>Lampl</surname><given-names>I</given-names></name><name><surname>Gillespie</surname><given-names>DC</given-names></name><name><surname>Ferster</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The contribution of noise to contrast invariance of orientation tuning in cat visual cortex</article-title><source>Science</source><volume>290</volume><fpage>1968</fpage><lpage>1972</lpage><pub-id pub-id-type="doi">10.1126/science.290.5498.1968</pub-id><pub-id pub-id-type="pmid">11110664</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bannon</surname><given-names>NM</given-names></name><name><surname>Chistiakova</surname><given-names>M</given-names></name><name><surname>Volgushev</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Synaptic plasticity in cortical inhibitory neurons: what mechanisms may help to balance synaptic weight changes?</article-title><source>Frontiers in Cellular Neuroscience</source><volume>14</volume><elocation-id>00204</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2020.00204</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartolozzi</surname><given-names>C</given-names></name><name><surname>Indiveri</surname><given-names>G</given-names></name><name><surname>Donati</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Embodied neuromorphic intelligence</article-title><source>Nature Communications</source><volume>13</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1038/s41467-022-28487-2</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Usrey</surname><given-names>WM</given-names></name><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Mangun</surname><given-names>GR</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Canonical microcircuits for predictive coding</article-title><source>Neuron</source><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id><pub-id pub-id-type="pmid">23177956</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellec</surname><given-names>G</given-names></name><name><surname>Scherr</surname><given-names>F</given-names></name><name><surname>Subramoney</surname><given-names>A</given-names></name><name><surname>Hajek</surname><given-names>E</given-names></name><name><surname>Salaj</surname><given-names>D</given-names></name><name><surname>Legenstein</surname><given-names>R</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A solution to the learning dilemma for recurrent networks of spiking neurons</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3625</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17236-y</pub-id><pub-id pub-id-type="pmid">32681001</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betti</surname><given-names>A</given-names></name><name><surname>Gori</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The principle of least cognitive action</article-title><source>Theoretical Computer Science</source><volume>633</volume><fpage>83</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.tcs.2015.06.042</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blom</surname><given-names>T</given-names></name><name><surname>Feuerriegel</surname><given-names>D</given-names></name><name><surname>Johnson</surname><given-names>P</given-names></name><name><surname>Bode</surname><given-names>S</given-names></name><name><surname>Hogendoorn</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Predictions drive neural representations of visual events ahead of incoming sensory information</article-title><source>PNAS</source><volume>117</volume><fpage>7510</fpage><lpage>7515</lpage><pub-id pub-id-type="doi">10.1073/pnas.1917777117</pub-id><pub-id pub-id-type="pmid">32179666</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borovik</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A mathematician’s view of the unreasonable ineffectiveness of mathematics in biology</article-title><source>Bio Systems</source><volume>205</volume><elocation-id>104410</elocation-id><pub-id pub-id-type="doi">10.1016/j.biosystems.2021.104410</pub-id><pub-id pub-id-type="pmid">33766624</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Bourdoukan</surname><given-names>R</given-names></name><name><surname>Vertechi</surname><given-names>P</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning to represent signals spike by spike</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007692</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007692</pub-id><pub-id pub-id-type="pmid">32176682</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Burrello</surname><given-names>A</given-names></name><name><surname>Cavigelli</surname><given-names>L</given-names></name><name><surname>Schindler</surname><given-names>K</given-names></name><name><surname>Benini</surname><given-names>L</given-names></name><name><surname>Rahimi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Laelaps: an energy-efficient seizure detection algorithm from long-term human iEEG recordings without false alarms</article-title><conf-name>2019 Design, Automation &amp; Test in Europe Conference &amp; Exhibition</conf-name><fpage>752</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.23919/DATE.2019.8715186</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campagnola</surname><given-names>L</given-names></name><name><surname>Seeman</surname><given-names>SC</given-names></name><name><surname>Chartrand</surname><given-names>T</given-names></name><name><surname>Kim</surname><given-names>L</given-names></name><name><surname>Hoggarth</surname><given-names>A</given-names></name><name><surname>Gamlin</surname><given-names>C</given-names></name><name><surname>Ito</surname><given-names>S</given-names></name><name><surname>Trinh</surname><given-names>J</given-names></name><name><surname>Davoudian</surname><given-names>P</given-names></name><name><surname>Radaelli</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>M-H</given-names></name><name><surname>Hage</surname><given-names>T</given-names></name><name><surname>Braun</surname><given-names>T</given-names></name><name><surname>Alfiler</surname><given-names>L</given-names></name><name><surname>Andrade</surname><given-names>J</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Dalley</surname><given-names>R</given-names></name><name><surname>Henry</surname><given-names>A</given-names></name><name><surname>Kebede</surname><given-names>S</given-names></name><name><surname>Alice</surname><given-names>M</given-names></name><name><surname>Sandman</surname><given-names>D</given-names></name><name><surname>Williams</surname><given-names>G</given-names></name><name><surname>Larsen</surname><given-names>R</given-names></name><name><surname>Teeter</surname><given-names>C</given-names></name><name><surname>Daigle</surname><given-names>TL</given-names></name><name><surname>Berry</surname><given-names>K</given-names></name><name><surname>Dotson</surname><given-names>N</given-names></name><name><surname>Enstrom</surname><given-names>R</given-names></name><name><surname>Gorham</surname><given-names>M</given-names></name><name><surname>Hupp</surname><given-names>M</given-names></name><name><surname>Dingman Lee</surname><given-names>S</given-names></name><name><surname>Ngo</surname><given-names>K</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>Potekhina</surname><given-names>L</given-names></name><name><surname>Ransford</surname><given-names>S</given-names></name><name><surname>Gary</surname><given-names>A</given-names></name><name><surname>Goldy</surname><given-names>J</given-names></name><name><surname>McMillen</surname><given-names>D</given-names></name><name><surname>Pham</surname><given-names>T</given-names></name><name><surname>Tieu</surname><given-names>M</given-names></name><name><surname>Siverts</surname><given-names>L</given-names></name><name><surname>Walker</surname><given-names>M</given-names></name><name><surname>Farrell</surname><given-names>C</given-names></name><name><surname>Schroedter</surname><given-names>M</given-names></name><name><surname>Slaughterbeck</surname><given-names>C</given-names></name><name><surname>Cobb</surname><given-names>C</given-names></name><name><surname>Ellenbogen</surname><given-names>R</given-names></name><name><surname>Gwinn</surname><given-names>RP</given-names></name><name><surname>Keene</surname><given-names>CD</given-names></name><name><surname>Ko</surname><given-names>AL</given-names></name><name><surname>Ojemann</surname><given-names>JG</given-names></name><name><surname>Silbergeld</surname><given-names>DL</given-names></name><name><surname>Carey</surname><given-names>D</given-names></name><name><surname>Casper</surname><given-names>T</given-names></name><name><surname>Crichton</surname><given-names>K</given-names></name><name><surname>Clark</surname><given-names>M</given-names></name><name><surname>Dee</surname><given-names>N</given-names></name><name><surname>Ellingwood</surname><given-names>L</given-names></name><name><surname>Gloe</surname><given-names>J</given-names></name><name><surname>Kroll</surname><given-names>M</given-names></name><name><surname>Sulc</surname><given-names>J</given-names></name><name><surname>Tung</surname><given-names>H</given-names></name><name><surname>Wadhwani</surname><given-names>K</given-names></name><name><surname>Brouner</surname><given-names>K</given-names></name><name><surname>Egdorf</surname><given-names>T</given-names></name><name><surname>Maxwell</surname><given-names>M</given-names></name><name><surname>McGraw</surname><given-names>M</given-names></name><name><surname>Pom</surname><given-names>CA</given-names></name><name><surname>Ruiz</surname><given-names>A</given-names></name><name><surname>Bomben</surname><given-names>J</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Hejazinia</surname><given-names>N</given-names></name><name><surname>Shi</surname><given-names>S</given-names></name><name><surname>Szafer</surname><given-names>A</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Phillips</surname><given-names>J</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Esposito</surname><given-names>L</given-names></name><name><surname>D’Orazi</surname><given-names>FD</given-names></name><name><surname>Sunkin</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>K</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Arkhipov</surname><given-names>A</given-names></name><name><surname>Sorensen</surname><given-names>S</given-names></name><name><surname>Lein</surname><given-names>E</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Murphy</surname><given-names>G</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Jarsky</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Local connectivity and synaptic dynamics in mouse and human neocortex</article-title><source>Science</source><volume>375</volume><elocation-id>eabj5861</elocation-id><pub-id pub-id-type="doi">10.1126/science.abj5861</pub-id><pub-id pub-id-type="pmid">35271334</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Chachuat</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Nonlinear and dynamic optimization: from theory to practice</source><publisher-name>EPFL - Swiss Federal Institute of Technology Lausanne</publisher-name></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chavlis</surname><given-names>S</given-names></name><name><surname>Poirazi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Drawing inspiration from biological dendrites to empower artificial neural networks</article-title><source>Current Opinion in Neurobiology</source><volume>70</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2021.04.007</pub-id><pub-id pub-id-type="pmid">34087540</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Coopersmith</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>The Lazy Universe: An Introduction to the Principle of Least Action</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/oso/9780198743040.001.0001</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Courant</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1934">1934</year><source>Differential and Integral Calculus</source><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cramer</surname><given-names>B</given-names></name><name><surname>Billaudelle</surname><given-names>S</given-names></name><name><surname>Kanya</surname><given-names>S</given-names></name><name><surname>Leibfried</surname><given-names>A</given-names></name><name><surname>Grübl</surname><given-names>A</given-names></name><name><surname>Karasenko</surname><given-names>V</given-names></name><name><surname>Pehle</surname><given-names>C</given-names></name><name><surname>Schreiber</surname><given-names>K</given-names></name><name><surname>Stradmann</surname><given-names>Y</given-names></name><name><surname>Weis</surname><given-names>J</given-names></name><name><surname>Schemmel</surname><given-names>J</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Surrogate gradients for analog neuromorphic computing</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2109194119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2109194119</pub-id><pub-id pub-id-type="pmid">35042792</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deperrois</surname><given-names>N</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Jordan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Learning cortical representations through perturbed and adversarial dreaming</article-title><source>eLife</source><volume>11</volume><elocation-id>e76384</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.76384</pub-id><pub-id pub-id-type="pmid">35384841</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deperrois</surname><given-names>N</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Jordan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Learning beyond sensations: How dreams organize neuronal representations</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>157</volume><elocation-id>105508</elocation-id><pub-id pub-id-type="doi">10.1016/j.neubiorev.2023.105508</pub-id><pub-id pub-id-type="pmid">38097096</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimitriou</surname><given-names>M</given-names></name><name><surname>Edin</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Human muscle spindles act as forward sensory models</article-title><source>Current Biology</source><volume>20</volume><fpage>1763</fpage><lpage>1767</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.08.049</pub-id><pub-id pub-id-type="pmid">20850322</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimitriou</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Enhanced muscle afferent signals during motor learning in humans</article-title><source>Current Biology</source><volume>26</volume><fpage>1062</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.02.030</pub-id><pub-id pub-id-type="pmid">27040776</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimitriou</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Human muscle spindles are wired to function as controllable signal-processing devices</article-title><source>eLife</source><volume>11</volume><elocation-id>e78091</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.78091</pub-id><pub-id pub-id-type="pmid">35829705</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Ellenberger</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>nla-code</data-title><version designator="swh:1:rev:332f19fa0bcf0dcbe455dbeb8c09a88f4e5f1106">swh:1:rev:332f19fa0bcf0dcbe455dbeb8c09a88f4e5f1106</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:3f560cc78613625619a47793e7b93c8fc4653c7a;origin=https://github.com/unibe-cns/nla-code;visit=swh:1:snp:4a2c350e73f99fd6df01b95c3a09de36ced0baf7;anchor=swh:1:rev:332f19fa0bcf0dcbe455dbeb8c09a88f4e5f1106">https://archive.softwareheritage.org/swh:1:dir:3f560cc78613625619a47793e7b93c8fc4653c7a;origin=https://github.com/unibe-cns/nla-code;visit=swh:1:snp:4a2c350e73f99fd6df01b95c3a09de36ced0baf7;anchor=swh:1:rev:332f19fa0bcf0dcbe455dbeb8c09a88f4e5f1106</ext-link></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Feldman</surname><given-names>AG</given-names></name><name><surname>Levin</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2009">2009</year><chapter-title>The equilibrium-point hypothesis – past, present and future</chapter-title><person-group person-group-type="editor"><name><surname>Sternad</surname><given-names>D</given-names></name></person-group><source>Progress in Motor Control</source><publisher-name>Springer</publisher-name><fpage>699</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1007/978-0-387-77064-2_38</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Feynman</surname><given-names>RP</given-names></name><name><surname>Leighton</surname><given-names>RB</given-names></name><name><surname>Sands</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>The Feynman Lectures on Physics, Vol. II: Mainly Electromagnetism and Matter</source><publisher-name>Feynmanlectures</publisher-name></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flannery</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The enigma of nonholonomic constraints</article-title><source>American Journal of Physics</source><volume>73</volume><fpage>265</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1119/1.1830501</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>S</given-names></name><name><surname>Kotelba</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Principle of least psychomotor action: modelling situated entropy in optimization of psychomotor work involving human, cyborg and robot workers</article-title><source>Entropy</source><volume>20</volume><elocation-id>836</elocation-id><pub-id pub-id-type="doi">10.3390/e20110836</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname><given-names>J</given-names></name><name><surname>Urbanczik</surname><given-names>R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spatio-temporal credit assignment in neuronal population learning</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1002092</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002092</pub-id><pub-id pub-id-type="pmid">21738460</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname><given-names>J</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Spike-based decision learning of Nash equilibria in two-player games</article-title><source>PLOS Computational Biology</source><volume>8</volume><elocation-id>e1002691</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002691</pub-id><pub-id pub-id-type="pmid">23028289</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The free-energy principle: a unified brain theory?</article-title><source>Nature Reviews Neuroscience</source><volume>11</volume><fpage>127</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nrn2787</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Costa</surname><given-names>LD</given-names></name><name><surname>Sajid</surname><given-names>N</given-names></name><name><surname>Heins</surname><given-names>C</given-names></name><name><surname>Ueltzhöffer</surname><given-names>K</given-names></name><name><surname>Pavliotis</surname><given-names>GA</given-names></name><name><surname>Parr</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A free energy principle made simpler but not too simple</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2201.06387">https://arxiv.org/abs/2201.06387</ext-link></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Kistler</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>Spiking Neuron Models: Single Neurons, Populations, Plasticity</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511815706</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Göltz</surname><given-names>J</given-names></name><name><surname>Kriener</surname><given-names>L</given-names></name><name><surname>Baumbach</surname><given-names>A</given-names></name><name><surname>Billaudelle</surname><given-names>S</given-names></name><name><surname>Breitwieser</surname><given-names>O</given-names></name><name><surname>Cramer</surname><given-names>B</given-names></name><name><surname>Dold</surname><given-names>D</given-names></name><name><surname>Kungl</surname><given-names>AF</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Schemmel</surname><given-names>J</given-names></name><name><surname>Meier</surname><given-names>K</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Fast and energy-efficient neuromorphic deep learning with first-spike times</article-title><source>Nature Machine Intelligence</source><volume>3</volume><fpage>823</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1038/s42256-021-00388-x</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Granier</surname><given-names>A</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wilmes</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Precision estimation and second-order prediction errors in cortical circuits</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/pdf/2309.16046v2">https://arxiv.org/pdf/2309.16046v2</ext-link></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guerguiev</surname><given-names>J</given-names></name><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Richards</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Towards deep learning with segregated dendrites</article-title><source>eLife</source><volume>6</volume><elocation-id>e22901</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.22901</pub-id><pub-id pub-id-type="pmid">29205151</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Haider</surname><given-names>P</given-names></name><name><surname>Ellenberger</surname><given-names>B</given-names></name><name><surname>Kriener</surname><given-names>L</given-names></name><name><surname>Jordan</surname><given-names>J</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Petrovici</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Latent equilibrium: arbitrarily fast computation with arbitrarily slow neurons</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2110.14549">https://arxiv.org/abs/2110.14549</ext-link></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neuroscience-Inspired Artificial Intelligence</article-title><source>Neuron</source><volume>95</volume><fpage>245</fpage><lpage>258</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.011</pub-id><pub-id pub-id-type="pmid">28728020</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzfeld</surname><given-names>DJ</given-names></name><name><surname>Vaswani</surname><given-names>PA</given-names></name><name><surname>Marko</surname><given-names>MK</given-names></name><name><surname>Shadmehr</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A memory of errors in sensorimotor learning</article-title><source>Science</source><volume>345</volume><fpage>1349</fpage><lpage>1353</lpage><pub-id pub-id-type="doi">10.1126/science.1253138</pub-id><pub-id pub-id-type="pmid">25123484</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hodgkin</surname><given-names>AL</given-names></name><name><surname>Huxley</surname><given-names>AF</given-names></name></person-group><year iso-8601-date="1952">1952</year><article-title>A quantitative description of membrane current and its application to conduction and excitation in nerve</article-title><source>The Journal of Physiology</source><volume>117</volume><fpage>500</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1952.sp004764</pub-id><pub-id pub-id-type="pmid">12991237</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Neural networks and physical systems with emergent collective computational abilities</article-title><source>PNAS</source><volume>79</volume><fpage>2554</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id><pub-id pub-id-type="pmid">6953413</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jordan</surname><given-names>J</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Wybo</surname><given-names>WAM</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Learning bayes-optimal dendritic opinion pooling</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2104.13238">http://arxiv.org/abs/2104.13238</ext-link></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karkar</surname><given-names>S</given-names></name><name><surname>Ayed</surname><given-names>I</given-names></name><name><surname>Gallinari</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A principle of least action for the training of neural networks</article-title><source>Lecture Notes in Computer Science</source><volume>01</volume><fpage>101</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-67661-2_7</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawato</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Internal models for motor control and trajectory planning</article-title><source>Current Opinion in Neurobiology</source><volume>9</volume><fpage>718</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1016/s0959-4388(99)00028-8</pub-id><pub-id pub-id-type="pmid">10607637</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Predictive processing: a canonical cortical computation</article-title><source>Neuron</source><volume>100</volume><fpage>424</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.003</pub-id><pub-id pub-id-type="pmid">30359606</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiebel</surname><given-names>SJ</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Free energy and dendritic self-organization</article-title><source>Frontiers in Systems Neuroscience</source><volume>5</volume><elocation-id>80</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2011.00080</pub-id><pub-id pub-id-type="pmid">22013413</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Köndgen</surname><given-names>H</given-names></name><name><surname>Geisler</surname><given-names>C</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>X-J</given-names></name><name><surname>Lüscher</surname><given-names>H-R</given-names></name><name><surname>Giugliano</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The dynamical response properties of neocortical neurons to temporally modulated noisy inputs in vitro</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>2086</fpage><lpage>2097</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm235</pub-id><pub-id pub-id-type="pmid">18263893</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kunin</surname><given-names>D</given-names></name><name><surname>Nayebi</surname><given-names>A</given-names></name><name><surname>Sagastuy-Brena</surname><given-names>J</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Bloom</surname><given-names>J</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Two routes to scalable credit assignment without weight symmetry</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2003.01513">https://arxiv.org/abs/2003.01513</ext-link></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>La Camera</surname><given-names>G</given-names></name><name><surname>Rauch</surname><given-names>A</given-names></name><name><surname>Thurbon</surname><given-names>D</given-names></name><name><surname>Lüscher</surname><given-names>H-R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Multiple time scales of temporal response in pyramidal and fast spiking cortical neurons</article-title><source>Journal of Neurophysiology</source><volume>96</volume><fpage>3448</fpage><lpage>3464</lpage><pub-id pub-id-type="doi">10.1152/jn.00453.2006</pub-id><pub-id pub-id-type="pmid">16807345</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larkum</surname><given-names>ME</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Lüscher</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Top-down dendritic input increases the gain of layer 5 pyramidal neurons</article-title><source>Cerebral Cortex</source><volume>14</volume><fpage>1059</fpage><lpage>1070</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhh065</pub-id><pub-id pub-id-type="pmid">15115747</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Latash</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Motor synergies and the equilibrium-point hypothesis</article-title><source>Motor Control</source><volume>14</volume><fpage>294</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1123/mcj.14.3.294</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Latash</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Muscle coactivation: definitions, mechanisms, and functions</article-title><source>Journal of Neurophysiology</source><volume>120</volume><fpage>88</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1152/jn.00084.2018</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The MNIST database of handwritten digits</article-title><ext-link ext-link-type="uri" xlink:href="http://yann.lecun.com/exdb/mnist">http://yann.lecun.com/exdb/mnist</ext-link><date-in-citation iso-8601-date="2019-01-01">January 1, 2019</date-in-citation></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Zhuang</surname><given-names>C</given-names></name><name><surname>Hao</surname><given-names>M</given-names></name><name><surname>He</surname><given-names>X</given-names></name><name><surname>Marquez</surname><given-names>JC</given-names></name><name><surname>Niu</surname><given-names>CM</given-names></name><name><surname>Lan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Coordinated alpha and gamma control of muscles and spindles in movement and posture</article-title><source>Frontiers in Computational Neuroscience</source><volume>9</volume><elocation-id>122</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2015.00122</pub-id><pub-id pub-id-type="pmid">26500531</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Cownden</surname><given-names>D</given-names></name><name><surname>Tweed</surname><given-names>DB</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Random synaptic feedback weights support error backpropagation for deep learning</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13276</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13276</pub-id><pub-id pub-id-type="pmid">27824044</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Marris</surname><given-names>L</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Backpropagation and the brain</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>335</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0277-3</pub-id><pub-id pub-id-type="pmid">32303713</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohmiller</surname><given-names>W</given-names></name><name><surname>Slotine</surname><given-names>J-JE</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>On contraction analysis for non-linear systems</article-title><source>Automatica</source><volume>34</volume><fpage>683</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1016/S0005-1098(98)00019-3</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Max</surname><given-names>K</given-names></name><name><surname>Kriener</surname><given-names>L</given-names></name><name><surname>Nowotny</surname><given-names>T</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Petrovici</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Learning efficient backprojections across cortical hierarchies in real time</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2212.10249">http://arxiv.org/abs/2212.10249</ext-link></element-citation></ref><ref id="bib62"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mesnard</surname><given-names>T</given-names></name><name><surname>Vignoud</surname><given-names>G</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Ghost units yield biologically plausible backprop in deep neural networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1911.08585">https://arxiv.org/abs/1911.08585</ext-link></element-citation></ref><ref id="bib63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meulemans</surname><given-names>A</given-names></name><name><surname>Farinha</surname><given-names>MT</given-names></name><name><surname>Ordóñez</surname><given-names>JG</given-names></name><name><surname>Aceituno</surname><given-names>PV</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Grewe</surname><given-names>BF</given-names></name></person-group><year iso-8601-date="2021">2021</year><chapter-title>Credit assignment in neural networks through deep feedback control</chapter-title><person-group person-group-type="editor"><name><surname>Meulemans</surname><given-names>A</given-names></name><name><surname>Farinha</surname><given-names>MT</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><publisher-name>Semantic Scholar</publisher-name><fpage>1</fpage><lpage>47</lpage></element-citation></ref><ref id="bib64"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Meulemans</surname><given-names>A</given-names></name><name><surname>Zucchet</surname><given-names>N</given-names></name><name><surname>Kobayashi</surname><given-names>S</given-names></name><name><surname>von Oswald</surname><given-names>J</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The least-control principle for local learning at equilibrium</article-title><conf-name>Conference on Neural Information Processing Systems</conf-name><fpage>1</fpage><lpage>47</lpage></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikulasch</surname><given-names>FA</given-names></name><name><surname>Rudelt</surname><given-names>L</given-names></name><name><surname>Priesemann</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Local dendritic balance enables learning of efficient representations in networks of spiking neurons</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2021925118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2021925118</pub-id><pub-id pub-id-type="pmid">34876505</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikulasch</surname><given-names>FA</given-names></name><name><surname>Rudelt</surname><given-names>L</given-names></name><name><surname>Wibral</surname><given-names>M</given-names></name><name><surname>Priesemann</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Where is the error? Hierarchical predictive coding through dendritic error computation</article-title><source>Trends in Neurosciences</source><volume>46</volume><fpage>45</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2022.09.007</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nedeljkov</surname><given-names>M</given-names></name><name><surname>Oberguggenberger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Ordinary differential equations with delta function terms</article-title><source>Publications de l’Institut Mathematique</source><volume>91</volume><fpage>125</fpage><lpage>135</lpage><pub-id pub-id-type="doi">10.2298/PIM1205125N</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ostojic</surname><given-names>S</given-names></name><name><surname>Szapiro</surname><given-names>G</given-names></name><name><surname>Schwartz</surname><given-names>E</given-names></name><name><surname>Barbour</surname><given-names>B</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Hakim</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal morphology generates high-frequency firing resonance</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>7056</fpage><lpage>7068</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3924-14.2015</pub-id><pub-id pub-id-type="pmid">25948257</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>SE</given-names></name><name><surname>Marre</surname><given-names>O</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Predictive information in a sensory population</article-title><source>PNAS</source><volume>112</volume><fpage>6908</fpage><lpage>6913</lpage><pub-id pub-id-type="doi">10.1073/pnas.1506855112</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papaioannou</surname><given-names>S</given-names></name><name><surname>Dimitriou</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Goal-dependent tuning of muscle spindle receptors during movement preparation</article-title><source>Science Advances</source><volume>7</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1126/sciadv.abe0401</pub-id><pub-id pub-id-type="pmid">33627426</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezzulo</surname><given-names>G</given-names></name><name><surname>Parr</surname><given-names>T</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The evolution of brain architectures for predictive coding and active inference</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>377</volume><elocation-id>0531</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2020.0531</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfister</surname><given-names>JP</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1271</fpage><lpage>1275</lpage><pub-id pub-id-type="doi">10.1038/nn.2640</pub-id><pub-id pub-id-type="pmid">20852625</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poirazi</surname><given-names>P</given-names></name><name><surname>Papoutsi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Illuminating dendritic function with computational models</article-title><source>Nature Reviews Neuroscience</source><volume>21</volume><fpage>303</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0301-7</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>RPN</given-names></name><name><surname>Ballard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rauch</surname><given-names>A</given-names></name><name><surname>La Camera</surname><given-names>G</given-names></name><name><surname>Luscher</surname><given-names>H-R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neocortical pyramidal cells respond as integrate-and-fire neurons to in vivo-like input currents</article-title><source>Journal of Neurophysiology</source><volume>90</volume><fpage>1598</fpage><lpage>1612</lpage><pub-id pub-id-type="doi">10.1152/jn.00293.2003</pub-id><pub-id pub-id-type="pmid">12750422</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Beaudoin</surname><given-names>P</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Christensen</surname><given-names>A</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Costa</surname><given-names>RP</given-names></name><name><surname>de Berker</surname><given-names>A</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Gillon</surname><given-names>CJ</given-names></name><name><surname>Hafner</surname><given-names>D</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name><name><surname>Lindsay</surname><given-names>GW</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Pack</surname><given-names>CC</given-names></name><name><surname>Poirazi</surname><given-names>P</given-names></name><name><surname>Roelfsema</surname><given-names>P</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Scellier</surname><given-names>B</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Zylberberg</surname><given-names>J</given-names></name><name><surname>Therien</surname><given-names>D</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A deep learning framework for neuroscience</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1761</fpage><lpage>1770</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0520-2</pub-id><pub-id pub-id-type="pmid">31659335</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Williams</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Learning representations by back-propagating errors</article-title><source>Nature</source><volume>323</volume><fpage>533</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1038/323533a0</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Costa</surname><given-names>RP</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dendritic cortical microcircuits approximate the backpropagation algorithm</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>8721</fpage><lpage>8732</lpage></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scellier</surname><given-names>B</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Equilibrium propagation: bridging the gap between energy-based models and backpropagation</article-title><source>Frontiers in Computational Neuroscience</source><volume>11</volume><elocation-id>24</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2017.00024</pub-id><pub-id pub-id-type="pmid">28522969</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schiess</surname><given-names>M</given-names></name><name><surname>Urbanczik</surname><given-names>R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Somato-dendritic synaptic plasticity and error-backpropagation in active dendrites</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004638</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004638</pub-id><pub-id pub-id-type="pmid">26841235</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wyler</surname><given-names>K</given-names></name><name><surname>Clamann</surname><given-names>HP</given-names></name><name><surname>Kleinle</surname><given-names>J</given-names></name><name><surname>Larkum</surname><given-names>M</given-names></name><name><surname>Lüscher</surname><given-names>H</given-names></name><name><surname>Muller</surname><given-names>L</given-names></name><name><surname>Streit</surname><given-names>J</given-names></name><name><surname>Vogt</surname><given-names>K</given-names></name><name><surname>Wannier</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Recruitment by Size and Principle of Least Action</source><publisher-name>Universität Bern</publisher-name><pub-id pub-id-type="doi">10.48350/191998</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wyler</surname><given-names>K</given-names></name><name><surname>Clamann</surname><given-names>HP</given-names></name><name><surname>Kleinle</surname><given-names>J</given-names></name><name><surname>Lüscher</surname><given-names>HR</given-names></name><name><surname>Müller</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Size principle and information theory</article-title><source>Biological Cybernetics</source><volume>76</volume><fpage>11</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1007/s004220050317</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simonetto</surname><given-names>A</given-names></name><name><surname>Dall’Anese</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Prediction-correction algorithms for time-varying constrained optimization</article-title><source>IEEE Transactions on Signal Processing</source><volume>65</volume><fpage>5481</fpage><lpage>5494</lpage><pub-id pub-id-type="doi">10.1109/TSP.2017.2728498</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simonetto</surname><given-names>A</given-names></name><name><surname>Dall’Anese</surname><given-names>E</given-names></name><name><surname>Paternain</surname><given-names>S</given-names></name><name><surname>Leus</surname><given-names>G</given-names></name><name><surname>Giannakis</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Time-varying convex optimization: time-structured algorithms and applications</article-title><source>Proceedings of the IEEE</source><volume>108</volume><fpage>2032</fpage><lpage>2048</lpage><pub-id pub-id-type="doi">10.1109/JPROC.2020.3003156</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sjöström</surname><given-names>PJ</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Rate, timing, and cooperativity jointly determine cortical synaptic plasticity</article-title><source>Neuron</source><volume>32</volume><fpage>1149</fpage><lpage>1164</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(01)00542-6</pub-id><pub-id pub-id-type="pmid">11754844</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>Y</given-names></name><name><surname>Millidge</surname><given-names>B</given-names></name><name><surname>Salvatori</surname><given-names>T</given-names></name><name><surname>Lukasiewicz</surname><given-names>T</given-names></name><name><surname>Xu</surname><given-names>Z</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Inferring neural activity before plasticity as a foundation for learning beyond backpropagation</article-title><source>Nature Neuroscience</source><volume>27</volume><fpage>348</fpage><lpage>358</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01514-1</pub-id><pub-id pub-id-type="pmid">38172438</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Spicher</surname><given-names>D</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Predictive plasticity in dendrites: from a computational principle to experimental data in Cosyne</article-title><ext-link ext-link-type="uri" xlink:href="https://boris.unibe.ch/id/eprint/191715">https://boris.unibe.ch/id/eprint/191715</ext-link><date-in-citation iso-8601-date="2017-02-25">February 25, 2017</date-in-citation></element-citation></ref><ref id="bib88"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Stewart</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><source>Multivariable calculus</source><publisher-name>Udmey</publisher-name></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summers</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>An action principle for biological systems</article-title><source>Journal of Physics</source><volume>2090</volume><elocation-id>012109</elocation-id><pub-id pub-id-type="doi">10.1088/1742-6596/2090/1/012109</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Talairach</surname><given-names>J</given-names></name><name><surname>Tournoux</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1988">1988</year><source>Co-planar stereotaxic atlas of the human brain: 3-dimensional proportional system: an approach to cerebral imaging</source><publisher-loc>New York</publisher-loc><publisher-name>Thieme Medical Publishers, Inc</publisher-name></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theis</surname><given-names>AK</given-names></name><name><surname>Rózsa</surname><given-names>B</given-names></name><name><surname>Katona</surname><given-names>G</given-names></name><name><surname>Schmitz</surname><given-names>D</given-names></name><name><surname>Johenning</surname><given-names>FW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Voltage gated calcium channel activation by backpropagating action potentials downregulates NMDAR function</article-title><source>Frontiers in Cellular Neuroscience</source><volume>12</volume><elocation-id>109</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2018.00109</pub-id><pub-id pub-id-type="pmid">29755321</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><chapter-title>Optimal control theory</chapter-title><person-group person-group-type="editor"><name><surname>Kenji</surname><given-names>D</given-names></name><name><surname>Shin</surname><given-names>I</given-names></name><name><surname>Alexandre</surname><given-names>P</given-names></name><name><surname>Rajesh</surname><given-names>P</given-names></name></person-group><source>The Bayesian Brain</source><publisher-name>MIT Press</publisher-name><fpage>1</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.7551/mitpress/9780262042383.003.0012</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Optimal feedback control as a theory of motor coordination</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>1226</fpage><lpage>1235</lpage><pub-id pub-id-type="doi">10.1038/nn963</pub-id><pub-id pub-id-type="pmid">12404008</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorov</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Optimality principles in sensorimotor control</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>907</fpage><lpage>915</lpage><pub-id pub-id-type="doi">10.1038/nn1309</pub-id><pub-id pub-id-type="pmid">15332089</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsodyks</surname><given-names>MV</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability</article-title><source>PNAS</source><volume>94</volume><fpage>719</fpage><lpage>723</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.2.719</pub-id><pub-id pub-id-type="pmid">9012851</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulrich</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dendritic resonance in rat neocortical pyramidal cells</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>2753</fpage><lpage>2759</lpage><pub-id pub-id-type="doi">10.1152/jn.2002.87.6.2753</pub-id><pub-id pub-id-type="pmid">12037177</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urbanczik</surname><given-names>R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning by the dendritic prediction of somatic spiking</article-title><source>Neuron</source><volume>81</volume><fpage>521</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.030</pub-id><pub-id pub-id-type="pmid">24507189</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varela</surname><given-names>JA</given-names></name><name><surname>Sen</surname><given-names>K</given-names></name><name><surname>Gibson</surname><given-names>J</given-names></name><name><surname>Fost</surname><given-names>J</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Nelson</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A quantitative description of short-term plasticity at excitatory synapses in layer 2/3 of rat primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>7926</fpage><lpage>7940</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-20-07926.1997</pub-id><pub-id pub-id-type="pmid">9315911</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Vargas</surname><given-names>AM</given-names></name><name><surname>Bisi</surname><given-names>A</given-names></name><name><surname>Chiappa</surname><given-names>A</given-names></name><name><surname>Versteeg</surname><given-names>C</given-names></name><name><surname>Miller</surname><given-names>L</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Task-driven neural network models predict neural dynamics of proprioception</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.06.15.545147</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A</given-names></name><name><surname>Shazeer</surname><given-names>N</given-names></name><name><surname>Parmar</surname><given-names>N</given-names></name><name><surname>Uszkoreit</surname><given-names>J</given-names></name><name><surname>Jones</surname><given-names>L</given-names></name><name><surname>Gomez</surname><given-names>AN</given-names></name><name><surname>Kaiser</surname><given-names>L</given-names></name><name><surname>Polosukhin</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attention is all you need NIPS</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1706.03762">http://arxiv.org/abs/1706.03762</ext-link></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title><source>Science</source><volume>334</volume><fpage>1569</fpage><lpage>1573</lpage><pub-id pub-id-type="doi">10.1126/science.1211095</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JC</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity</article-title><source>Neural Computation</source><volume>29</volume><fpage>1229</fpage><lpage>1262</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00949</pub-id><pub-id pub-id-type="pmid">28333583</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Theories of error back-propagation in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>235</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.12.005</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wigner</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>The unreasonable effectiveness of mathematics in the natural sciences. Richard courant lecture in mathematical sciences delivered at New York University, May 11, 1959</article-title><source>Communications on Pure and Applied Mathematics</source><volume>13</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1002/cpa.3160130102</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Computational principles of movement neuroscience</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>1212</fpage><lpage>1217</lpage><pub-id pub-id-type="doi">10.1038/81497</pub-id><pub-id pub-id-type="pmid">11127840</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>X</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Equivalence of backpropagation and contrastive Hebbian learning in a layered network</article-title><source>Neural Computation</source><volume>15</volume><fpage>441</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1162/089976603762552988</pub-id><pub-id pub-id-type="pmid">12590814</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>SuperSpike: supervised learning in multilayer spiking neural networks</article-title><source>Neural Computation</source><volume>30</volume><fpage>1514</fpage><lpage>1541</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01086</pub-id><pub-id pub-id-type="pmid">29652587</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Swamy</surname><given-names>MNS</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A novel technique for tracking time-varying minimum and its applications</article-title><conf-name>Canadian Conference on Electrical and Computer Engineering</conf-name><fpage>910</fpage><lpage>913</lpage><pub-id pub-id-type="doi">10.1109/CCECE.1998.685646</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Threshold-linear transfer functions</title><p>There is an important special case where the presynaptic voltage error can directly be extracted from presynaptic firing rates, without need to invert the transfer function via synaptic depression as shown below. This is the case when voltage errors in the upper layers are small, and the voltage-to-rate transfer function has derivatives <inline-formula><alternatives><mml:math id="inf922"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft922">\begin{document}$\rho'=0$\end{document}</tex-math></alternatives></inline-formula> or 1, so that <inline-formula><alternatives><mml:math id="inf923"><mml:mrow><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft923">\begin{document}$\bar{\boldsymbol{r}}_{{{l\!+\!1}}}' = (\bar{\boldsymbol{r}}_{{{l\!+\!1}}}')^{2}$\end{document}</tex-math></alternatives></inline-formula>. The condition is satisfied, for instance, for a doubly threshold-linear function (a ‘doubly rectified linear unit’, ReLu) defined by <inline-formula><alternatives><mml:math id="inf924"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˘</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft924">\begin{document}$\rho(\breve u)=0$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf925"><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˘</mml:mo></mml:mover><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft925">\begin{document}$\breve u \lt 0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf926"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˘</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˘</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft926">\begin{document}$\rho(\breve u)=\breve u$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf927"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˘</mml:mo></mml:mover><mml:mo>≤</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext/><mml:mi>max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft927">\begin{document}$0 \leq \breve u \leq r_{\mathrm{max}}$\end{document}</tex-math></alternatives></inline-formula>, while <inline-formula><alternatives><mml:math id="inf928"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˘</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext/><mml:mi>max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft928">\begin{document}$\rho(\breve u)=r_{\mathrm{max}}$\end{document}</tex-math></alternatives></inline-formula> for larger voltages. In this case we calculate<disp-formula id="equ45"><label>(41a)</label><alternatives><mml:math id="m45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t45">\begin{document}$$\displaystyle \bar{\boldsymbol{e}}_{{{l\!+\!1}}}= \bar{\boldsymbol{r}}_{{{l\!+\!1}}}'{\!\cdot\!}\bar{\boldsymbol{e}}_{{{l\!+\!1}}}^{A}= (\bar{\boldsymbol{r}}_{{{l\!+\!1}}}')^{2}{\!\cdot\!}\bar{\boldsymbol{e}}_{{{l\!+\!1}}}^{A}= \bar{\boldsymbol{r}}_{{{l\!+\!1}}}'{\!\cdot\!}\bar{\boldsymbol{e}}_{{{l\!+\!1}}}= \bar{\boldsymbol{r}}_{{{l\!+\!1}}}'{\!\cdot\!}\left(\boldsymbol u_{{{l\!+\!1}}}- \boldsymbol W_{{{l\!+\!1}}}{\bar{\boldsymbol{ r }}}_{l}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ46"><label>(41b)</label><alternatives><mml:math id="m46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mspace width="30pt"/><mml:mo>≈</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>+</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t46">\begin{document}$$\displaystyle \hspace{30 pt} \approx \rho(\boldsymbol u_{{{l\!+\!1}}}) - \rho(\boldsymbol W_{{{l\!+\!1}}}{\bar{\boldsymbol{ r }}}_{l}) ={\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}- \rho(\boldsymbol W_{{{l\!+\!1}}}{\bar{\boldsymbol{ r }}}_{l}).$$\end{document}</tex-math></alternatives></disp-formula></p><p>The approximation uses the Taylor expansion in <inline-formula><alternatives><mml:math id="inf929"><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft929">\begin{document}$\boldsymbol u_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> and assumes that <inline-formula><alternatives><mml:math id="inf930"><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft930">\begin{document}$\bar{\boldsymbol{e}}_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> is small. The crucial point of <xref ref-type="disp-formula" rid="equ45">Equation 41a</xref> is that the mismatch error defined on the voltage, <inline-formula><alternatives><mml:math id="inf931"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft931">\begin{document}$\bar{\boldsymbol{e}}_{{{l\!+\!1}}}= \boldsymbol u_{{{l\!+\!1}}}- \boldsymbol W_{{{l\!+\!1}}}{\bar{\boldsymbol{ r }}}_{l}$\end{document}</tex-math></alternatives></inline-formula>, can be factorized into a product of the postsynaptic rate derivative, <inline-formula><alternatives><mml:math id="inf932"><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup></mml:math><tex-math id="inft932">\begin{document}$\bar{\boldsymbol{r}}_{{{l\!+\!1}}}'$\end{document}</tex-math></alternatives></inline-formula>, and the apical error, and hence it can be expressed as an error defined on the rate. Restricted to the segment <inline-formula><alternatives><mml:math id="inf933"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mrow><mml:mtext/><mml:mi>max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft933">\begin{document}$0 \leq{\bar{\boldsymbol{ u }}}_{{{l\!+\!1}}}\leq \boldsymbol r_{\mathrm{max}}$\end{document}</tex-math></alternatives></inline-formula> where the transfer function is linear and errors do not vanish, the same microcircuit delivers the feedback <inline-formula><alternatives><mml:math id="inf934"><mml:mrow><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft934">\begin{document}$\boldsymbol B_{l}{\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula> to the apical tree through the top-down projections, and <inline-formula><alternatives><mml:math id="inf935"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑩</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft935">\begin{document}$-\boldsymbol B_{l}\,\rho(\boldsymbol W_{{{l\!+\!1}}}{\bar{\boldsymbol{ r }}}_{l})$\end{document}</tex-math></alternatives></inline-formula> through the lateral connections from the interneurons. While the plasticity rules for <inline-formula><alternatives><mml:math id="inf936"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>PI</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft936">\begin{document}$\boldsymbol{W^{\text{PI}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf937"><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="inft937">\begin{document}$\boldsymbol{W^{\text{IP}}}_{l}$\end{document}</tex-math></alternatives></inline-formula> stay the same, the top-down nudging of the interneurons, see <xref ref-type="disp-formula" rid="equ10">Equation 9</xref>, can then be formulated based on the rate instead of the upper layer voltage, <inline-formula><alternatives><mml:math id="inf938"><mml:mrow><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msub><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:msub><mml:msup><mml:mi>𝑩</mml:mi><mml:mtext>IP</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft938">\begin{document}$\boldsymbol{u^{\text{I}}}_{l}= (1 -{\beta^\text{I}}) \boldsymbol{W^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{l}+{\beta^\text{I}}\boldsymbol{B^{\text{IP}}}_{l}{\bar{\boldsymbol{ r }}}_{{{l\!+\!1}}}$\end{document}</tex-math></alternatives></inline-formula>, with transfer function of the interneuron again the (doubly) threshold-linear <inline-formula><alternatives><mml:math id="inf939"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:msup><mml:mi>𝒖</mml:mi><mml:mtext>I</mml:mtext></mml:msup><mml:mi>l</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft939">\begin{document}$\rho(\boldsymbol{u^{\text{I}}}_{l})$\end{document}</tex-math></alternatives></inline-formula>. Since voltages and rates are identical in the segment <inline-formula><alternatives><mml:math id="inf940"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mi>l</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>+</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mrow><mml:mtext/><mml:mi>max</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft940">\begin{document}$0 \leq{\bar{\boldsymbol{ u }}}_{{{l\!+\!1}}}\leq \boldsymbol r_{\mathrm{max}}$\end{document}</tex-math></alternatives></inline-formula> for each component, <xref ref-type="disp-formula" rid="equ38 equ43">Equations 36 with 39</xref> can still be inferred.</p><sec sec-type="appendix" id="s8-1"><title>Rate-to-voltage inversion by short-term synaptic depression</title><p>We wish to readout the voltage error also for other nonlinear transfer functions than clipped ReLu’s. To do so, we take inspiration from the classical short-term synaptic depression model (<xref ref-type="bibr" rid="bib95">Tsodyks and Markram, 1997</xref>; <xref ref-type="bibr" rid="bib1">Abbott et al., 1997</xref>; <xref ref-type="bibr" rid="bib98">Varela et al., 1997</xref>), see also <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1a1</xref> (that deviates from the release-independent synaptic depression, see <xref ref-type="bibr" rid="bib16">Campagnola et al., 2022</xref>). We consider a dynamic vesicle release probability that is proportional to the pool size of available vesicles, <inline-formula><alternatives><mml:math id="inf941"><mml:mrow><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft941">\begin{document}$v(\bar r)$\end{document}</tex-math></alternatives></inline-formula>, and this pool size is postulated to depend on past presynaptic rates,<disp-formula id="equ47"><label>(42)</label><alternatives><mml:math id="m47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>release</mml:mtext><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>∝</mml:mo><mml:mspace width="thickmathspace"/><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t47">\begin{document}$$\displaystyle p(\text{release}\, |\, \bar r) \;\propto\; v(\bar r) = 1 + \frac{a}{1 + d \, \bar r}, $$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf942"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft942">\begin{document}$\bar r$\end{document}</tex-math></alternatives></inline-formula> is the low-pass filtered presynaptic rate, <inline-formula><alternatives><mml:math id="inf943"><mml:mi>a</mml:mi></mml:math><tex-math id="inft943">\begin{document}$a$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf944"><mml:mi>d</mml:mi></mml:math><tex-math id="inft944">\begin{document}$d$\end{document}</tex-math></alternatives></inline-formula> are constants. The proportionality factor is <inline-formula><alternatives><mml:math id="inf945"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft945">\begin{document}$\frac{1}{1+a}$\end{document}</tex-math></alternatives></inline-formula>, making a probability out of the vesicle pools size. The effective synaptic strength <inline-formula><alternatives><mml:math id="inf946"><mml:mi>B</mml:mi></mml:math><tex-math id="inft946">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> of a ‘backprojecting top-down’ connection is the product of the absolute synaptic strength <inline-formula><alternatives><mml:math id="inf947"><mml:msub><mml:mi>B</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub></mml:math><tex-math id="inft947">\begin{document}$B_{\circ}$\end{document}</tex-math></alternatives></inline-formula> and the vesicle pool size <inline-formula><alternatives><mml:math id="inf948"><mml:mi>v</mml:mi></mml:math><tex-math id="inft948">\begin{document}$v$\end{document}</tex-math></alternatives></inline-formula>, i.e., <inline-formula><alternatives><mml:math id="inf949"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mspace width="0.1667em"/><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft949">\begin{document}$B = B_{\circ}\, v(\bar r)$\end{document}</tex-math></alternatives></inline-formula>. The contribution to the postsynaptic current of the synapse is <inline-formula><alternatives><mml:math id="inf950"><mml:mrow><mml:mi>W</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:math><tex-math id="inft950">\begin{document}$W r$\end{document}</tex-math></alternatives></inline-formula>, and the contribution to the postsynaptic voltage is <inline-formula><alternatives><mml:math id="inf951"><mml:mrow><mml:mi>W</mml:mi><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft951">\begin{document}$W \bar r$\end{document}</tex-math></alternatives></inline-formula>.</p><p>We search for an activation function <inline-formula><alternatives><mml:math id="inf952"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft952">\begin{document}$\bar r(u)$\end{document}</tex-math></alternatives></inline-formula> such that the postsynaptic voltage contribution is the scaled presynaptic potential, <inline-formula><alternatives><mml:math id="inf953"><mml:mrow><mml:mi>B</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mi>u</mml:mi><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft953">\begin{document}$B \, \bar r (u) = B_{\circ}u\,$\end{document}</tex-math></alternatives></inline-formula>. Plugging in the above expression for <inline-formula><alternatives><mml:math id="inf954"><mml:mi>B</mml:mi></mml:math><tex-math id="inft954">\begin{document}$B$\end{document}</tex-math></alternatives></inline-formula> yields <inline-formula><alternatives><mml:math id="inf955"><mml:mrow><mml:mi>B</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mi>u</mml:mi></mml:mrow></mml:math><tex-math id="inft955">\begin{document}$B \, \bar r (u) = B_{\circ}v(\bar r) \, \bar r (u) = B_{\circ}u$\end{document}</tex-math></alternatives></inline-formula>, and dividing <inline-formula><alternatives><mml:math id="inf956"><mml:msub><mml:mi>B</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub></mml:math><tex-math id="inft956">\begin{document}$B_{\circ}$\end{document}</tex-math></alternatives></inline-formula> out, <inline-formula><alternatives><mml:math id="inf957"><mml:mrow><mml:mspace width="0.1667em"/><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:math><tex-math id="inft957">\begin{document}$\,v(\bar r) \, \bar r(u) = u$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1a2</xref>. With the expression for <inline-formula><alternatives><mml:math id="inf958"><mml:mrow><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft958">\begin{document}$v(\bar r)$\end{document}</tex-math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="equ47">Equation 42</xref> we obtain a quadratic equation in <inline-formula><alternatives><mml:math id="inf959"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft959">\begin{document}$\bar r$\end{document}</tex-math></alternatives></inline-formula> that is solved by the non-negative and monotonically increasing function<disp-formula id="equ48"><label>(43)</label><alternatives><mml:math id="m48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:msqrt><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mspace width="negativethinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="negativethinmathspace"/><mml:mi>θ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>4</mml:mn><mml:mi>u</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo><mml:mtext> for </mml:mtext><mml:mi>u</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t48">\begin{document}$$\displaystyle \bar r = \frac{1}{2}\left(u \!-\! \theta + \sqrt{(u \! -\!\theta)^{2}+ 4 u /d}\right) \geq 0 \,, \text{ for }u\geq 0, $$\end{document}</tex-math></alternatives></disp-formula></p><p>with ‘smooth’ threshold <inline-formula><alternatives><mml:math id="inf960"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>/</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:math><tex-math id="inft960">\begin{document}$\theta = (1 + a)/d$\end{document}</tex-math></alternatives></inline-formula> and asymptote <inline-formula><alternatives><mml:math id="inf961"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>≈</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:math><tex-math id="inft961">\begin{document}$\bar r \approx u-\theta$\end{document}</tex-math></alternatives></inline-formula>. This gives us a transfer function <inline-formula><alternatives><mml:math id="inf962"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft962">\begin{document}$\bar r(u)$\end{document}</tex-math></alternatives></inline-formula> that qualitatively matches those observed for pyramidal neurons recorded in the steady state (<xref ref-type="bibr" rid="bib6">Anderson et al., 2000</xref>; <xref ref-type="bibr" rid="bib75">Rauch et al., 2003</xref>), see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1a3</xref>.</p><p>The approach generalizes to other pairs of strictly monotonic neuronal activation and depression functions <inline-formula><alternatives><mml:math id="inf963"><mml:mrow><mml:mo form="prefix" stretchy="false">{</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">}</mml:mo></mml:mrow></mml:math><tex-math id="inft963">\begin{document}$\{\bar r(u), v(\bar r)\}$\end{document}</tex-math></alternatives></inline-formula>, as long as <inline-formula><alternatives><mml:math id="inf964"><mml:mi>u</mml:mi></mml:math><tex-math id="inft964">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> is not driven below some minimal value, here <inline-formula><alternatives><mml:math id="inf965"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext/><mml:mi>rest</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft965">\begin{document}$u_{\mathrm{rest}}=0$\end{document}</tex-math></alternatives></inline-formula>, corresponding to <inline-formula><alternatives><mml:math id="inf966"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft966">\begin{document}$\bar r = 0$\end{document}</tex-math></alternatives></inline-formula>. The last requirement can, for instance, be accomplished by offsetting the activation function into a regime that guarantees that <inline-formula><alternatives><mml:math id="inf967"><mml:mi>u</mml:mi></mml:math><tex-math id="inft967">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> stays positive.</p><p>In our simulations for <xref ref-type="fig" rid="fig5">Figure 5</xref>, we did not explicitly implement a dynamic vesicle pool, i.e., the right-hand side of <inline-formula><alternatives><mml:math id="inf968"><mml:mrow><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:math><tex-math id="inft968">\begin{document}$v(\bar r)\, \bar r = u$\end{document}</tex-math></alternatives></inline-formula>, but instead directly used the recovered membrane potentials <inline-formula><alternatives><mml:math id="inf969"><mml:mi>u</mml:mi></mml:math><tex-math id="inft969">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Recovering presynaptic potentials through short term depression.</title><p>(a1) Relative voltage response of a depressing cortical synapse recreated from <xref ref-type="bibr" rid="bib1">Abbott et al., 1997</xref>, identified as synaptic release probability <inline-formula><alternatives><mml:math id="inf970"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft970">\begin{document}$p$\end{document}</tex-math></alternatives></inline-formula>. (a2) The product of the low-pass filtered presynaptic firing rate <inline-formula><alternatives><mml:math id="inf971"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft971">\begin{document}$\bar{r} (u)$\end{document}</tex-math></alternatives></inline-formula> times the synaptic release probability is <inline-formula><alternatives><mml:math id="inf972"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft972">\begin{document}${p} (\bar{r} )$\end{document}</tex-math></alternatives></inline-formula> proportional to the presynaptic membrane potential, <inline-formula><alternatives><mml:math id="inf973"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>∝</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft973">\begin{document}${p} (\bar{r}) \bar{r}\propto u$\end{document}</tex-math></alternatives></inline-formula>. (a3) Average in vivo firing rate of a neuron in the visual cortex as a function of the somatic membrane potential recreated from <xref ref-type="bibr" rid="bib6">Anderson et al., 2000</xref>, which can be qualitatively identified as the stationary rate <inline-formula><alternatives><mml:math id="inf974"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft974">\begin{document}$\bar{r}(u) $\end{document}</tex-math></alternatives></inline-formula> derived in <xref ref-type="disp-formula" rid="equ48">Equation 43</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89674-app1-fig1-v2.tif"/></fig></sec></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Looking back and forward in time with derivatives</title><p>Since dealing with extrapolations into the future is a crucial notion of the paper we present here some of the calculations. The discounted future voltage was introduced in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> as<disp-formula id="equ49"><alternatives><mml:math id="m49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t49">\begin{document}$$\displaystyle {\tilde{u}}(t) = \frac{1}{\tau}\int_{t}^{\infty}u(t') e^{-\frac{t'-t}{\tau}}{\text{d}}t' \;.$$\end{document}</tex-math></alternatives></disp-formula></p><p>To show that <inline-formula><alternatives><mml:math id="inf975"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft975">\begin{document}${\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> satisfies <inline-formula><alternatives><mml:math id="inf976"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft976">\begin{document}$u ={\tilde{u}}- \tau{\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>, we need to apply the Leibniz integral rule in calculating the derivative <inline-formula><alternatives><mml:math id="inf977"><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft977">\begin{document}${\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>. This leads to<disp-formula id="equ50"><alternatives><mml:math id="m50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msubsup><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t50">\begin{document}$$\displaystyle \frac{{\mathrm{d}} {\tilde{u}}}{{\mathrm{d}} t}(t) = - \frac{1}{\tau}u(t) + \frac{1}{\tau}\int_{t}^{\infty}u(t') \frac{1}{\tau}e^{-\frac{t'-t}{\tau}}{\text{d}}t' \;.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Multiplying this equation by <inline-formula><alternatives><mml:math id="inf978"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft978">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> and using the definition of <inline-formula><alternatives><mml:math id="inf979"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft979">\begin{document}${\tilde{u}}$\end{document}</tex-math></alternatives></inline-formula> yields <inline-formula><alternatives><mml:math id="inf980"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft980">\begin{document}$\tau{\dot{{\tilde{u}}}}(t) = - u(t) +{\tilde{u}}(t)$\end{document}</tex-math></alternatives></inline-formula>, or <inline-formula><alternatives><mml:math id="inf981"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft981">\begin{document}$u ={\tilde{u}}- \tau{\dot{{\tilde{u}}}}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>By applying the Leibniz integral rule one also shows that <inline-formula><alternatives><mml:math id="inf982"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft982">\begin{document}$\bar x$\end{document}</tex-math></alternatives></inline-formula>, defined in <xref ref-type="disp-formula" rid="equ16">Equation 15</xref>,<disp-formula id="equ51"><alternatives><mml:math id="m51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="negativethinmathspace"/><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t51">\begin{document}$$\displaystyle \bar x(t) = \frac{1}{\tau}\int_{-\infty}^{t}\! x(t') e^{-\frac{t-t'}{\tau}}\mathrm{d}t' \,,$$\end{document}</tex-math></alternatives></disp-formula></p><p>solves <inline-formula><alternatives><mml:math id="inf983"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>x</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft983">\begin{document}$\tau \dot{\bar{x}}(t) = - \bar{x}(t) + x(t)$\end{document}</tex-math></alternatives></inline-formula>. This differential equation can be written as <inline-formula><alternatives><mml:math id="inf984"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math><tex-math id="inft984">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\bar{x}= x$\end{document}</tex-math></alternatives></inline-formula>, with lookahead operator <inline-formula><alternatives><mml:math id="inf985"><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow></mml:math><tex-math id="inft985">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}$\end{document}</tex-math></alternatives></inline-formula> defined in <xref ref-type="disp-formula" rid="equ15">Equation 14</xref>. To show that <inline-formula><alternatives><mml:math id="inf986"><mml:mrow><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math><tex-math id="inft986">\begin{document}$\overline{{\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)} x}= \bar x + \tau \overline{\dot x}= x$\end{document}</tex-math></alternatives></inline-formula>, one applies partial integration to <inline-formula><alternatives><mml:math id="inf987"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft987">\begin{document}$\overline{\dot x(t)}$\end{document}</tex-math></alternatives></inline-formula>. Note that the equality <inline-formula><alternatives><mml:math id="inf988"><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math><tex-math id="inft988">\begin{document}$\bar x + \tau \overline{\dot x}= \bar x + \tau \dot{\bar x}= x$\end{document}</tex-math></alternatives></inline-formula> only holds if we integrate from <inline-formula><alternatives><mml:math id="inf989"><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft989">\begin{document}$-\infty$\end{document}</tex-math></alternatives></inline-formula>, and hence if the initialization of the trajectory is far back in the past as compared to the time constant <inline-formula><alternatives><mml:math id="inf990"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft990">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula>.</p><sec sec-type="appendix" id="s9-1"><title>Uniqueness of the rate function</title><p>In the main text we concluded from the postulate <inline-formula><alternatives><mml:math id="inf991"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft991">\begin{document}$r = \rho(u) + \tau \dot \rho(u)$\end{document}</tex-math></alternatives></inline-formula> and the general relation <inline-formula><alternatives><mml:math id="inf992"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft992">\begin{document}$r = \bar r + \tau \dot{\bar r}$\end{document}</tex-math></alternatives></inline-formula> that <inline-formula><alternatives><mml:math id="inf993"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft993">\begin{document}${\bar{r}}(t) = \rho(u(t))$\end{document}</tex-math></alternatives></inline-formula>. This conclusion is a consequence of the uniqueness of a solution of an ordinary differential equation for a given initial condition that may include delta-functions on the right-hand side, see e.g., <xref ref-type="bibr" rid="bib67">Nedeljkov and Oberguggenberger, 2012</xref>. In fact, we may consider both variables <inline-formula><alternatives><mml:math id="inf994"><mml:mi>ρ</mml:mi></mml:math><tex-math id="inft994">\begin{document}$\rho$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf995"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft995">\begin{document}$\bar r$\end{document}</tex-math></alternatives></inline-formula> as solutions of the differential equation <inline-formula><alternatives><mml:math id="inf996"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>x</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math><tex-math id="inft996">\begin{document}$\tau \dot x = - x + r$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf997"><mml:mi>x</mml:mi></mml:math><tex-math id="inft997">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula> either <inline-formula><alternatives><mml:math id="inf998"><mml:mi>ρ</mml:mi></mml:math><tex-math id="inft998">\begin{document}$\rho$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf999"><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft999">\begin{document}$\bar r$\end{document}</tex-math></alternatives></inline-formula>. Because the solution is unique, we conclude that <inline-formula><alternatives><mml:math id="inf1000"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1000">\begin{document}$\rho = \bar r$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec sec-type="appendix" id="s9-2"><title>Learning the input time constants</title><p>In our applications we assumed that the input rates in the original mapping <inline-formula><alternatives><mml:math id="inf1001"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>𝑭</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1001">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t) = \boldsymbol F^{*}(\boldsymbol{\bar{r}}_{{\text{in}}}(t))$\end{document}</tex-math></alternatives></inline-formula> are low-pass filtered by a common time constant <inline-formula><alternatives><mml:math id="inf1002"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>in</mml:mtext><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:math><tex-math id="inft1002">\begin{document}$\tau_{{\text{in}}(t),i}^{*}= \tau$\end{document}</tex-math></alternatives></inline-formula> that is also shared as membrane time constant of the neurons. But in general, we may consider a subclass of network neurons (with voltage vector <inline-formula><alternatives><mml:math id="inf1003"><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="inft1003">\begin{document}$\boldsymbol u_{1}$\end{document}</tex-math></alternatives></inline-formula>) that receive exclusively input rates <inline-formula><alternatives><mml:math id="inf1004"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1004">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> and integrate these rates with corresponding time constants <inline-formula><alternatives><mml:math id="inf1005"><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1005">\begin{document}$\boldsymbol \tau_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>. The prospective rates of these neurons, <inline-formula><alternatives><mml:math id="inf1006"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1006">\begin{document}$\boldsymbol r_{1}= \rho (\boldsymbol u_{1}) + \tau \,\dot{\rho}(\boldsymbol u_{1})$\end{document}</tex-math></alternatives></inline-formula>, are then produced by the same voltage time constant <inline-formula><alternatives><mml:math id="inf1007"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft1007">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> of the down-stream neurons. The downstream voltage integration then cancels the presynaptic look-ahead in the presynaptic firing rate, leading again to an instantaneous voltage propagation across the entire network.</p><p>The general setting of learning to map time series is that input time series, <inline-formula><alternatives><mml:math id="inf1008"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1008">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> are low-pass filtered with given time constants <inline-formula><alternatives><mml:math id="inf1009"><mml:msubsup><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft1009">\begin{document}$\boldsymbol \tau_{{\text{in}}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, and the target output time series <inline-formula><alternatives><mml:math id="inf1010"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1010">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t)$\end{document}</tex-math></alternatives></inline-formula> are a function of these low-pass filtered inputs, <inline-formula><alternatives><mml:math id="inf1011"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝑭</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:msubsup><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext><mml:mo>*</mml:mo></mml:msubsup></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1011">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t) = \boldsymbol F_{\boldsymbol o}^{*}(\overline{\boldsymbol r}_{{\text{in}}}^{\boldsymbol \tau_{{\text{in}}}^*}(t))$\end{document}</tex-math></alternatives></inline-formula>. In the student network, the input time constants appear as parameters that can be learned by gradient descent to match the output of the teacher network, just as the synaptic weights are learned.</p><p>We ask for a learning rule so that the student network can extract the input time constants <inline-formula><alternatives><mml:math id="inf1012"><mml:msubsup><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft1012">\begin{document}$\boldsymbol \tau_{{\text{in}}}^{*}$\end{document}</tex-math></alternatives></inline-formula> used by the teacher network. For this, we assume that only the neurons <inline-formula><alternatives><mml:math id="inf1013"><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><tex-math id="inft1013">\begin{document}${\boldsymbol u_1}$\end{document}</tex-math></alternatives></inline-formula> obtain the external input and hence carry the time constant <inline-formula><alternatives><mml:math id="inf1014"><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1014">\begin{document}$\boldsymbol \tau_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>. Because <inline-formula><alternatives><mml:math id="inf1015"><mml:mrow><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mover><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:msubsup></mml:mrow></mml:math><tex-math id="inft1015">\begin{document}$\overline{\boldsymbol r}_{{\text{in}}}^{\boldsymbol \tau_{{\text{in}}}}= \boldsymbol r_{{\text{in}}}- \boldsymbol \tau_{{\text{in}}}{\!\cdot\!}\dot{\overline{\boldsymbol r}}_{{\text{in}}}^{\boldsymbol \tau_{{\text{in}}}}$\end{document}</tex-math></alternatives></inline-formula>, the gradient rule for the input time constant is<disp-formula id="equ52"><label>(44)</label><alternatives><mml:math id="m52"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:msub><mml:mover><mml:mi>𝝉</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:msup><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:msubsup></mml:mrow></mml:mfrac><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>T</mml:mtext></mml:mrow></mml:msup><mml:mspace width="0.1667em"/><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:msubsup></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext><mml:mtext>T</mml:mtext></mml:msubsup><mml:msup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:msubsup><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mtext>T</mml:mtext></mml:msup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mover><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:msubsup><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t52">\begin{document}$$\displaystyle \begin{align}\dot{\boldsymbol \tau}_{{\text{in}}}= -\frac{\partial L}{\partial \boldsymbol \tau_{{\text{in}}}}= -\frac{\partial L}{\partial \overline{\boldsymbol r}_{{\text{in}}}^{\boldsymbol \tau_{{\text{in}}}}}^{\!\!\!{\text{T}}}\, \frac{\partial \overline{\boldsymbol r}_{{\text{in}}}^{\boldsymbol \tau_{{\text{in}}}}}{\partial \boldsymbol \tau_{{\text{in}}}}= - \boldsymbol W_{\text{in}}^{\text{T}}\left({\boldsymbol u_1}- \boldsymbol W_{\text{in}}\overline{\boldsymbol r}_{\text{in}}^{\boldsymbol \tau_{{\text{in}}}}\right)^{\text{T}}{\!\cdot\!}\dot{\overline{\boldsymbol r}}_{\text{in}}^{\boldsymbol \tau_{{\text{in}}}}\,. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>This local learning rule also globally reduces the Lagrangian, and in the limits of <inline-formula><alternatives><mml:math id="inf1016"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1016">\begin{document}$\beta\to \infty$\end{document}</tex-math></alternatives></inline-formula> it is gradient descent on the mismatch energy, while in the limit <inline-formula><alternatives><mml:math id="inf1017"><mml:mrow><mml:mi>β</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1017">\begin{document}$\beta\to 0$\end{document}</tex-math></alternatives></inline-formula> it is gradient descent on the cost. The proof works as in Theorem 1. To learn a more complex mapping of time series that includes more complex temporal processing beyond a function of merely <inline-formula><alternatives><mml:math id="inf1018"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝑭</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝒓</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:msubsup><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext><mml:mo>*</mml:mo></mml:msubsup></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1018">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t) = \boldsymbol F_{\boldsymbol o}^{*}(\overline{\boldsymbol r}_{{\text{in}}}^{\boldsymbol \tau_{{\text{in}}}^*}(t))$\end{document}</tex-math></alternatives></inline-formula>, additional variables need to be introduced that form memories (see Appendix 6).</p></sec></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>From the implicit to the explicit differential equation</title><sec sec-type="appendix" id="s10-1"><title>Global convergence to a moving equilibrium (i.e. to <inline-formula><alternatives><mml:math id="inf1019"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1019">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>)</title><p>The original Euler-Lagrange equation is <inline-formula><alternatives><mml:math id="inf1020"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1020">\begin{document}$(1 + \tau \frac{{\text{d}}}{{\text{d}} t}) \frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>, 20, with Jacobian <inline-formula><alternatives><mml:math id="inf1021"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1021">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol f(\boldsymbol u, t) = \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>. Remember the definition of <inline-formula><alternatives><mml:math id="inf1022"><mml:mrow><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1022">\begin{document}${\bar{\boldsymbol{ \epsilon }}}={\bar{\boldsymbol{ r }}}'_{{{\!\text{net}}}}{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula> given in 21. While <inline-formula><alternatives><mml:math id="inf1023"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1023">\begin{document}${\bar{\boldsymbol{ e }}}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula> is an error that may not vanish, the ‘corrected error’ <inline-formula><alternatives><mml:math id="inf1024"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1024">\begin{document}$\boldsymbol f = \frac{\partial L}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> is shown to vanish exponentially quick, leading to the moving equilibrium with <inline-formula><alternatives><mml:math id="inf1025"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1025">\begin{document}$\boldsymbol u = \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>. In fact, <inline-formula><alternatives><mml:math id="inf1026"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒇</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1026">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol f + \tau \dot{\boldsymbol f}= 0$\end{document}</tex-math></alternatives></inline-formula>, has the general solution<disp-formula id="equ53"><label>(45)</label><alternatives><mml:math id="m53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mo stretchy="false">⟶</mml:mo><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t53">\begin{document}$$\displaystyle \boldsymbol{f}(\boldsymbol{u}(t), t) = \boldsymbol{f}(\boldsymbol{u}_{0}, t_{0}) \, e^{-\frac{t-t_{0}}{\tau}}\longrightarrow \boldsymbol 0$$\end{document}</tex-math></alternatives></disp-formula></p><p>as an exponentially decaying function in <inline-formula><alternatives><mml:math id="inf1027"><mml:mi>t</mml:mi></mml:math><tex-math id="inft1027">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf1028"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="inft1028">\begin{document}$\boldsymbol{u}(t_{0}) = \boldsymbol{u}_{0}$\end{document}</tex-math></alternatives></inline-formula>. Note that the argument <inline-formula><alternatives><mml:math id="inf1029"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1029">\begin{document}$\boldsymbol{u}$\end{document}</tex-math></alternatives></inline-formula> of the function <inline-formula><alternatives><mml:math id="inf1030"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1030">\begin{document}$\boldsymbol f(\boldsymbol u, t) = \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula> does apriori not depend on time. It only becomes a function of time, <inline-formula><alternatives><mml:math id="inf1031"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1031">\begin{document}$\boldsymbol{u}(t)$\end{document}</tex-math></alternatives></inline-formula>, by requiring that <inline-formula><alternatives><mml:math id="inf1032"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒇</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1032">\begin{document}$\boldsymbol f + \tau \dot{\boldsymbol f}= 0$\end{document}</tex-math></alternatives></inline-formula>. The voltage <inline-formula><alternatives><mml:math id="inf1033"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1033">\begin{document}$\boldsymbol{u}(t)$\end{document}</tex-math></alternatives></inline-formula> becomes a non-trivial function of time because the time-dependence of the function <inline-formula><alternatives><mml:math id="inf1034"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1034">\begin{document}$\boldsymbol f(\boldsymbol u, t)$\end{document}</tex-math></alternatives></inline-formula>, that apriori enters only through the second argument, expresses the temporally varying input <inline-formula><alternatives><mml:math id="inf1035"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1035">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>, including a possible target output <inline-formula><alternatives><mml:math id="inf1036"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1036">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t)$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec sec-type="appendix" id="s10-2"><title>Implicit differential equation</title><p>To make the dependence of <inline-formula><alternatives><mml:math id="inf1037"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1037">\begin{document}$\dot{\boldsymbol u }$\end{document}</tex-math></alternatives></inline-formula> on the right-hand-side of the implicit differential <xref ref-type="disp-formula" rid="equ24">Equation 22</xref> more transparent, we rewrite this in the form<disp-formula id="equ54"><label>(46)</label><alternatives><mml:math id="m54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t54">\begin{document}$$\displaystyle \dot{\boldsymbol u}= - \frac{ \boldsymbol f }{\tau }- \frac{\partial \boldsymbol f}{\partial t}+ \frac{\partial }{\partial \boldsymbol u}(\boldsymbol W{\bar{\boldsymbol{ r }}}+{\bar{\boldsymbol{ \epsilon }}}+ \beta{\bar{\boldsymbol{ e }}}^{*}) \, \dot{\boldsymbol u}= - \frac{ \boldsymbol f }{\tau }- \frac{\partial \boldsymbol f}{\partial t}+ \boldsymbol M \dot{\boldsymbol u}= \boldsymbol K (\boldsymbol r_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*}, \boldsymbol u, \dot{\boldsymbol u })\,. $$\end{document}</tex-math></alternatives></disp-formula></p><p>The partial derivative of <inline-formula><alternatives><mml:math id="inf1038"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1038">\begin{document}$\boldsymbol f(\boldsymbol u, t)$\end{document}</tex-math></alternatives></inline-formula> with respect to time, <inline-formula><alternatives><mml:math id="inf1039"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1039">\begin{document}$\frac{\partial \boldsymbol f}{\partial t}$\end{document}</tex-math></alternatives></inline-formula>, captures the external drive from the inputs and output targets that do not depend on <inline-formula><alternatives><mml:math id="inf1040"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1040">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, but may directly depend on time. In fact, instead of the argument <inline-formula><alternatives><mml:math id="inf1041"><mml:mi>t</mml:mi></mml:math><tex-math id="inft1041">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> of <inline-formula><alternatives><mml:math id="inf1042"><mml:mi>𝒇</mml:mi></mml:math><tex-math id="inft1042">\begin{document}$\boldsymbol f$\end{document}</tex-math></alternatives></inline-formula>, we could consider the two arguments <inline-formula><alternatives><mml:math id="inf1043"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1043">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1044"><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft1044">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>, so that the partial derivative of <inline-formula><alternatives><mml:math id="inf1045"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1045">\begin{document}$\boldsymbol f(\boldsymbol u, t) = \boldsymbol f(\boldsymbol u,{\bar{\boldsymbol{ r }}}_{{\text{in}}}, \boldsymbol u^{*}_{\boldsymbol o})$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1046"><mml:mi>t</mml:mi></mml:math><tex-math id="inft1046">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> can be written as<disp-formula id="equ55"><label>(47)</label><alternatives><mml:math id="m55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo mathvariant="bold">˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t55">\begin{document}$$\displaystyle \frac{\partial f_{i}}{\partial t}= \frac{\partial f_{i}}{\partial \bar{\boldsymbol{r}}_{\text{in}}}\, \boldsymbol{\dot{\bar{r}}}_{\text{in}}+ \frac{\partial f_{i}}{\partial \boldsymbol{u}^{*}_{\boldsymbol{o}}}\, \boldsymbol{\dot{u}}^{*}_{\boldsymbol{o}}= W_{i, \text{in}}\, \boldsymbol{\dot{\bar{r}}}_{\text{in}}+ \beta \, \delta_{io}\, \boldsymbol{\dot{u}}^{*}_{\boldsymbol{o}}, $$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf1047"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1047">\begin{document}$\delta_{io}$\end{document}</tex-math></alternatives></inline-formula> is the Kronecker delta that is equal to 1 if <inline-formula><alternatives><mml:math id="inf1048"><mml:mi>i</mml:mi></mml:math><tex-math id="inft1048">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula><italic>i</italic> is an output neuron, and 0 else. The partial derivatives of <inline-formula><alternatives><mml:math id="inf1049"><mml:mi>𝒇</mml:mi></mml:math><tex-math id="inft1049">\begin{document}$\boldsymbol f$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1050"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1050">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> represents the (symmetric) Hessian of the Lagrangian, <inline-formula><alternatives><mml:math id="inf1051"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft1051">\begin{document}$H_{ij}= \frac{\partial f_{i}}{\partial u_{j}}= \frac{\partial^{2}L}{\partial u_{i}\partial u_{j}}= \delta_{ij}- \frac{\partial }{\partial u_{j}}(\boldsymbol W{\bar{\boldsymbol{ r }}}+{\bar{\boldsymbol{ \epsilon }}}+ \beta{\bar{\boldsymbol{ e }}}^{*})_{i}$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf1052"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1052">\begin{document}$\delta_{ij}$\end{document}</tex-math></alternatives></inline-formula> being the Kronecker-delta, <inline-formula><alternatives><mml:math id="inf1053"><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft1053">\begin{document}${\bar{\boldsymbol{ \epsilon }}}$\end{document}</tex-math></alternatives></inline-formula> defined in 21 and <inline-formula><alternatives><mml:math id="inf1054"><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:math><tex-math id="inft1054">\begin{document}${\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula> defined above 16. Remember that <inline-formula><alternatives><mml:math id="inf1055"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1055">\begin{document}$\boldsymbol W = (\boldsymbol W_{{\text{in}}}, \boldsymbol W_{{{\!\text{net}}}})$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1056"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>𝝆</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1056">\begin{document}${\bar{\boldsymbol{ r }}}= ({\bar{\boldsymbol{ r }}}_{{\text{in}}},{\bar{\boldsymbol{ r }}}_{{{\!\text{net}}}}) = ({\bar{\boldsymbol{ r }}}_{{\text{in}}}, \boldsymbol \rho(\boldsymbol u))$\end{document}</tex-math></alternatives></inline-formula>. In vectorial notation the Hessian of the Lagrangian is<disp-formula id="equ56"><label>(48)</label><alternatives><mml:math id="m56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t56">\begin{document}$$\displaystyle \boldsymbol H (\boldsymbol u) = \frac{\partial \boldsymbol f}{\partial \boldsymbol u}= \frac{\partial^{2}L}{\partial \boldsymbol u \, \partial \boldsymbol u}= \boldsymbol 1 - \boldsymbol W_{{{\!\text{net}}}}\,{\mathrm{diag}}\left (\rho'(\boldsymbol u) \right) - \frac{\partial }{\partial \boldsymbol u}({\bar{\boldsymbol{ \epsilon }}}+ \beta{\bar{\boldsymbol{ e }}}^{*})(\boldsymbol u), $$\end{document}</tex-math></alternatives></disp-formula></p><p>where 1 is the identity matrix. This Hessian is ‘typically’ positive definite, as we argue next. For a functionally feedforward network, the weight matrix <inline-formula><alternatives><mml:math id="inf1057"><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:math><tex-math id="inft1057">\begin{document}$\boldsymbol W_{{{\!\text{net}}}}$\end{document}</tex-math></alternatives></inline-formula> is lower triangular, and for small enough <inline-formula><alternatives><mml:math id="inf1058"><mml:mi>β</mml:mi></mml:math><tex-math id="inft1058">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> (for which <inline-formula><alternatives><mml:math id="inf1059"><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft1059">\begin{document}${\bar{\boldsymbol{ \epsilon }}}$\end{document}</tex-math></alternatives></inline-formula> is small) the diagonal elements are all positive and hence the Hessian <inline-formula><alternatives><mml:math id="inf1060"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft1060">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> is invertible. Since <inline-formula><alternatives><mml:math id="inf1061"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft1061">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> is also symmetric, it is, therefore, positive definite. In the general case, we require that <inline-formula><alternatives><mml:math id="inf1062"><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:math><tex-math id="inft1062">\begin{document}$\boldsymbol W_{{{\!\text{net}}}}$\end{document}</tex-math></alternatives></inline-formula> has Eigenvalues smaller than 1, since otherwise the recurrent network dynamics may explode. If <inline-formula><alternatives><mml:math id="inf1063"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1063">\begin{document}$\rho'(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> is also smaller than 1, and <inline-formula><alternatives><mml:math id="inf1064"><mml:mi>β</mml:mi></mml:math><tex-math id="inft1064">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> still small enough, we conclude again that the Hessian is invertible (and hence positive definite). Notice that the property of <inline-formula><alternatives><mml:math id="inf1065"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi><mml:mspace width="0.1667em"/><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1065">\begin{document}$\boldsymbol H = \frac{\partial^{2}L}{\partial \boldsymbol u \, \partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> being symmetric is a general property of differentiable functions and ways weaker than the requirement that the recurrent weight matrix <inline-formula><alternatives><mml:math id="inf1066"><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:math><tex-math id="inft1066">\begin{document}$\boldsymbol W_{{{\!\text{net}}}}$\end{document}</tex-math></alternatives></inline-formula> is symmetric, as classically required for fixed point convergence in Hopfield-type networks.</p><p>Since in the implicit differential equation of <xref ref-type="disp-formula" rid="equ54">Equation 46</xref> the <inline-formula><alternatives><mml:math id="inf1067"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1067">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula> also arises on the right-hand-side, we need to show that this <xref ref-type="disp-formula" rid="equ54">Equation 46</xref>, for fixed <inline-formula><alternatives><mml:math id="inf1068"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1068">\begin{document}$(\boldsymbol r_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*}, \boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, can be solved for <inline-formula><alternatives><mml:math id="inf1069"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1069">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>. To find the solution <inline-formula><alternatives><mml:math id="inf1070"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1070">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula> for given arguments <inline-formula><alternatives><mml:math id="inf1071"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1071">\begin{document}$(\boldsymbol r_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*}, \boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> in <inline-formula><alternatives><mml:math id="inf1072"><mml:mi>𝑲</mml:mi></mml:math><tex-math id="inft1072">\begin{document}$\boldsymbol K$\end{document}</tex-math></alternatives></inline-formula>, we search for a fixed point of the mapping <inline-formula><alternatives><mml:math id="inf1073"><mml:mrow><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1073">\begin{document}$\boldsymbol{\dot u}^{(i+1)}= \boldsymbol K (\boldsymbol{\dot u}^{(i)})$\end{document}</tex-math></alternatives></inline-formula>. In the argument <inline-formula><alternatives><mml:math id="inf1074"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1074">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>, the mapping is affine, <inline-formula><alternatives><mml:math id="inf1075"><mml:mrow><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mi>𝒇</mml:mi><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>𝑴</mml:mi><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft1075">\begin{document}$\boldsymbol{\dot u}^{(i+1)}= - \frac{ \boldsymbol f }{\tau }- \frac{\partial \boldsymbol f}{\partial t}+ \boldsymbol M \boldsymbol{\dot u}^{(i)}$\end{document}</tex-math></alternatives></inline-formula>, with matrix <inline-formula><alternatives><mml:math id="inf1076"><mml:mrow><mml:mi>𝑴</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1076">\begin{document}$\boldsymbol{M}(\boldsymbol{u}) = \frac{\partial }{\partial \boldsymbol u}(\boldsymbol W{\bar{\boldsymbol{ r }}}+{\bar{\boldsymbol{ \epsilon }}}+ \beta{\bar{\boldsymbol{ e }}}^{*})$\end{document}</tex-math></alternatives></inline-formula> appearing in <xref ref-type="disp-formula" rid="equ54">Equation 46</xref>. The Banach fixed point theorem asserts that if <inline-formula><alternatives><mml:math id="inf1077"><mml:mrow><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1077">\begin{document}$\boldsymbol K(\dot{\boldsymbol u})$\end{document}</tex-math></alternatives></inline-formula> is strictly contracting with <inline-formula><alternatives><mml:math id="inf1078"><mml:mi>k</mml:mi></mml:math><tex-math id="inft1078">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula>, i.e., if <inline-formula><alternatives><mml:math id="inf1079"><mml:mrow><mml:mi>‖</mml:mi><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mi>‖</mml:mi><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mi>‖</mml:mi></mml:mrow></mml:math><tex-math id="inft1079">\begin{document}$\| \boldsymbol K(\dot{\boldsymbol u}^{(2)}) - \boldsymbol K(\dot{\boldsymbol u}^{(1)}) \|^{2}\leq k \| \dot{\boldsymbol u}^{(2)}-\dot{\boldsymbol u}^{(1)}\|$\end{document}</tex-math></alternatives></inline-formula> for all pairs of inputs and <inline-formula><alternatives><mml:math id="inf1080"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft1080">\begin{document}$0\leq k \lt 1$\end{document}</tex-math></alternatives></inline-formula>, then the iteration (here with iteration time step <inline-formula><alternatives><mml:math id="inf1081"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1081">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula>) locally converges to a fixed point <inline-formula><alternatives><mml:math id="inf1082"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1082">\begin{document}$\dot{\boldsymbol u}= \boldsymbol K (\dot{\boldsymbol u })$\end{document}</tex-math></alternatives></inline-formula>. Because <inline-formula><alternatives><mml:math id="inf1083"><mml:mrow><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝑴</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1083">\begin{document}$\boldsymbol K(\dot{\boldsymbol u}^{(2)}) - \boldsymbol K(\dot{\boldsymbol u}^{(1)}) = \boldsymbol M (\dot{\boldsymbol u}^{(2)}- \dot{\boldsymbol u}^{(1)})$\end{document}</tex-math></alternatives></inline-formula>, the mapping is <inline-formula><alternatives><mml:math id="inf1084"><mml:mi>k</mml:mi></mml:math><tex-math id="inft1084">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula>-contractive if the eigenvalues of <inline-formula><alternatives><mml:math id="inf1085"><mml:mi>𝑴</mml:mi></mml:math><tex-math id="inft1085">\begin{document}$\boldsymbol M$\end{document}</tex-math></alternatives></inline-formula> have absolute value smaller than <inline-formula><alternatives><mml:math id="inf1086"><mml:mi>k</mml:mi></mml:math><tex-math id="inft1086">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula>. This is the case if the Hessian <inline-formula><alternatives><mml:math id="inf1087"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:mi>𝑴</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1087">\begin{document}$\boldsymbol H(\boldsymbol u) = \boldsymbol 1 - \boldsymbol{M}(\boldsymbol{u}) = \boldsymbol 1 - \boldsymbol W_{{{\!\text{net}}}}\rho' (\boldsymbol u) -{\bar{\boldsymbol{ e }}}'(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf1088"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1088">\begin{document}${\bar{\boldsymbol{ e }}}={\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, is strictly positive definite (which is ‘typically’ the case, see above).</p></sec><sec sec-type="appendix" id="s10-3"><title>Stable solution of the implicit differential equation</title><p>According to the above reasoning, the Banach fixed point theorem asserts (for the typically positive Hessian) that during convergence of the mapping <inline-formula><alternatives><mml:math id="inf1089"><mml:mrow><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1089">\begin{document}$\boldsymbol{\dot u}^{(i+1)}= \boldsymbol K (\boldsymbol{\dot u}^{(i)})$\end{document}</tex-math></alternatives></inline-formula> the distance to the fixed point is bounded by a constant times <inline-formula><alternatives><mml:math id="inf1090"><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mi>i</mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math><tex-math id="inft1090">\begin{document}$e^{-i \frac{1-k}{dt}}$\end{document}</tex-math></alternatives></inline-formula>, with iteration index <inline-formula><alternatives><mml:math id="inf1091"><mml:mi>i</mml:mi></mml:math><tex-math id="inft1091">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> and ‘virtual’ Euler step <inline-formula><alternatives><mml:math id="inf1092"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1092">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula>. Formally,<disp-formula id="equ57"><label>(49)</label><alternatives><mml:math id="m57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo>≤</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>i</mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo stretchy="false">⟶</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t57">\begin{document}$$\displaystyle \| \boldsymbol K(\dot{\boldsymbol u}^{(i+1)}) - \boldsymbol K(\dot{\boldsymbol u}^{(i)}) \| = \| \boldsymbol M (\dot{\boldsymbol u}^{(i+1)}- \dot{\boldsymbol u}^{(1)}) \| \leq k \| \dot{\boldsymbol u}^{(i+1)}-\dot{\boldsymbol u}^{(i)}\| \leq c_{0}\, e^{-i \frac{1-k}{dt}}\longrightarrow \boldsymbol 0. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Crucially, because the mapping is affine in <inline-formula><alternatives><mml:math id="inf1093"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1093">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>, the convergence is global in <inline-formula><alternatives><mml:math id="inf1094"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1094">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula> while fixing the other arguments <inline-formula><alternatives><mml:math id="inf1095"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1095">\begin{document}$(\boldsymbol r_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*}, \boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> of <inline-formula><alternatives><mml:math id="inf1096"><mml:mi>𝑲</mml:mi></mml:math><tex-math id="inft1096">\begin{document}$\boldsymbol K$\end{document}</tex-math></alternatives></inline-formula>.</p><p>In an analog physical device that implements exactly this feedback circuit in continuous time, the <inline-formula><alternatives><mml:math id="inf1097"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1097">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula> becomes truly infinitesimal and in this sense the convergence is instantaneous. If <inline-formula><alternatives><mml:math id="inf1098"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1098">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula> remains finite, <inline-formula><alternatives><mml:math id="inf1099"><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup></mml:math><tex-math id="inft1099">\begin{document}$\dot{\boldsymbol u }^{(i)}$\end{document}</tex-math></alternatives></inline-formula> converges to a moving target because the mapping <inline-formula><alternatives><mml:math id="inf1100"><mml:mrow><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1100">\begin{document}$\dot{\boldsymbol u}^{(i+1)}= \boldsymbol K (\dot{\boldsymbol u }^{(i)})$\end{document}</tex-math></alternatives></inline-formula> changes with time. The target should not move quicker than the time scale <inline-formula><alternatives><mml:math id="inf1101"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1101">\begin{document}$\frac{dt}{1-k}$\end{document}</tex-math></alternatives></inline-formula> of the <inline-formula><alternatives><mml:math id="inf1102"><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup></mml:math><tex-math id="inft1102">\begin{document}$\dot{\boldsymbol u }^{(i)}$\end{document}</tex-math></alternatives></inline-formula> convergence (but, fortunately, this convergence time-scale can be made arbitrarily quick by reducing <inline-formula><alternatives><mml:math id="inf1103"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1103">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula>). Given a time course of the input rate <inline-formula><alternatives><mml:math id="inf1104"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1104">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> and target <inline-formula><alternatives><mml:math id="inf1105"><mml:mrow><mml:msup><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1105">\begin{document}${\boldsymbol u_o}^{*}(t)$\end{document}</tex-math></alternatives></inline-formula> that has bounded variation, the <inline-formula><alternatives><mml:math id="inf1106"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1106">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula> can be chosen so that convergence becomes arbitrary quick, and in the limit instantaneous. As a consequence, for small enough <inline-formula><alternatives><mml:math id="inf1107"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1107">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula>, the <inline-formula><alternatives><mml:math id="inf1108"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1108">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> becomes the same on the left- and right-hand side of the implicit differential <xref ref-type="disp-formula" rid="equ54">Equation 46</xref>.</p><p>If <inline-formula><alternatives><mml:math id="inf1109"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1109">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> contains well-separated delta-functions, while otherwise still having bounded variations, the reasoning still applies since at any point in time, except at the time points of the isolated delta-function, <inline-formula><alternatives><mml:math id="inf1110"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1110">\begin{document}$\boldsymbol f(\boldsymbol u, t) = 0$\end{document}</tex-math></alternatives></inline-formula>. This statement is proven in the Appendix 4.</p><p>In practical simulations, a caveat is in place when the learning rate becomes too big and <inline-formula><alternatives><mml:math id="inf1111"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1111">\begin{document}$\boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula> starts to change the neuronal dynamics. In this case, the Hessian becomes <inline-formula><alternatives><mml:math id="inf1112"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo>=</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mrow><mml:mtext/><mml:mi>diag</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mtext/><mml:mi>diag</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1112">\begin{document}$\boldsymbol H = \boldsymbol 1 - (\boldsymbol W \mathrm{diag}(\rho') + \boldsymbol{\dot W}\mathrm{diag}(\rho)) -{\bar{\boldsymbol{ e }}}'$\end{document}</tex-math></alternatives></inline-formula>, and the Eigenvalues may become negative due to the <inline-formula><alternatives><mml:math id="inf1113"><mml:mover><mml:mi>𝑾</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1113">\begin{document}$\boldsymbol{\dot W}$\end{document}</tex-math></alternatives></inline-formula> term. Simulations can in fact become unstable with a big learning rate, and this is more pronounced if also the Euler <inline-formula><alternatives><mml:math id="inf1114"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1114">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula> is large. The explicit differential equation avoids the fast iteration towards a moving target and hence allows for larger <inline-formula><alternatives><mml:math id="inf1115"><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1115">\begin{document}$dt$\end{document}</tex-math></alternatives></inline-formula>. This in particular pays out in the presence of a high learning rate (although the Cholesky decomposition also requires positive definiteness). For this reason, the large-scale simulations involving plasticity are performed with the explicit form described next.</p></sec><sec sec-type="appendix" id="s10-4"><title>Explicit differential equation</title><p>To isolate <inline-formula><alternatives><mml:math id="inf1116"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1116">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> in the implicit differential equation, we rewrite <inline-formula><alternatives><mml:math id="inf1117"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1117">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\boldsymbol f = 0$\end{document}</tex-math></alternatives></inline-formula> again as<disp-formula id="equ58"><label>(50)</label><alternatives><mml:math id="m58"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒇</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>𝒇</mml:mi><mml:mspace width="0.2778em"/><mml:mo separator="true">,</mml:mo><mml:mspace width="1em"/><mml:mtext> or </mml:mtext><mml:mspace width="1em"/><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>j</mml:mi></mml:munder></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t58">\begin{document}$$\displaystyle  \tau \dot{\boldsymbol f}= \tau \left(\frac{\partial \boldsymbol f}{\partial \boldsymbol u}\dot{\boldsymbol u}+ \frac{\partial \boldsymbol f}{\partial t}\right) = - \boldsymbol f \;, \quad \text{ or }\quad \tau \frac{d f_{i}}{dt}= \tau \, \left(\sum_{j}\frac{\partial f_{i}}{\partial u_{j}}\dot u_{j}+ \frac{\partial f_{i}}{\partial t}\right) = - f_{i}\,. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Plugging the Hessian <inline-formula><alternatives><mml:math id="inf1118"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1118">\begin{document}$\boldsymbol H(\boldsymbol u) = \frac{\partial \boldsymbol f}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> from <xref ref-type="disp-formula" rid="equ56">Equation 48</xref> into <xref ref-type="disp-formula" rid="equ58">Equation 50</xref>, we obtain the voltage dynamics from <xref ref-type="disp-formula" rid="equ24">Equation 22</xref> in the equivalent form<disp-formula id="equ59"><label>(51)</label><alternatives><mml:math id="m59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t59">\begin{document}$$\displaystyle \tau \boldsymbol H (\boldsymbol u) \, \dot{\boldsymbol{u}}= -\boldsymbol f - \tau\frac{\partial \boldsymbol f}{\partial t}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>In our applications, the Hessian <inline-formula><alternatives><mml:math id="inf1119"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft1119">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> appears to be invertible (although this may not be the case for arbitrary networks), and <xref ref-type="disp-formula" rid="equ59">Equation 51</xref> can be solved for the unique <inline-formula><alternatives><mml:math id="inf1120"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1120">\begin{document}$\dot{\boldsymbol{u}}$\end{document}</tex-math></alternatives></inline-formula> using the Cholesky decompositions. In fact, if <inline-formula><alternatives><mml:math id="inf1121"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft1121">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> is invertible, the system implicit ordinary differential equations from <xref ref-type="disp-formula" rid="equ59">Equation 51</xref> can be converted into a system of explicit ordinary differential equations (with <inline-formula><alternatives><mml:math id="inf1122"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1122">\begin{document}$\boldsymbol f(\boldsymbol u, t) = \frac{\partial L}{\partial \boldsymbol u}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1123"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft1123">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> given in <xref ref-type="disp-formula" rid="equ56">Equation 48</xref>),<disp-formula id="equ60"><label>(52)</label><alternatives><mml:math id="m60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t60">\begin{document}$$\displaystyle \dot{\boldsymbol{u}}= \boldsymbol g(\boldsymbol u, t) = - \frac{1}{\tau}\boldsymbol H^{-1}(\boldsymbol u) \left(\boldsymbol f(\boldsymbol u) + \tau\frac{\partial \boldsymbol f}{\partial t}\right), $$\end{document}</tex-math></alternatives></disp-formula></p><p>and as such it has a unique solution for any given initial condition. <xref ref-type="disp-formula" rid="equ60">Equation 52</xref> represents the explicit solution of the iteration <inline-formula><alternatives><mml:math id="inf1124"><mml:mrow><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1124">\begin{document}$\boldsymbol{\dot u}^{(i+1)}= \boldsymbol K (\boldsymbol{\dot u}^{(i)})$\end{document}</tex-math></alternatives></inline-formula> after the convergence to the fixed point <inline-formula><alternatives><mml:math id="inf1125"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝑲</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1125">\begin{document}$\dot{\boldsymbol u}= \boldsymbol K (\dot{\boldsymbol u})$\end{document}</tex-math></alternatives></inline-formula>. The condition for the convergence is the same as the condition for solving for <inline-formula><alternatives><mml:math id="inf1126"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1126">\begin{document}$\dot{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>, namely an invertible (and hence positive definite) Hessian.</p><p>Because <inline-formula><alternatives><mml:math id="inf1127"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo separator="true">,</mml:mo><mml:mtext>in</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mspace width="0.1667em"/><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft1127">\begin{document}$\frac{\partial f_{i}}{\partial t}= W_{i, {\text{in}}}\dot{{\boldsymbol{\bar{r}}}}_{{\text{in}}}+ \beta \, \delta_{io}\dot{ \boldsymbol u}^{*}_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ55">Equation 47</xref>, the regularity requirement for <inline-formula><alternatives><mml:math id="inf1128"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1128">\begin{document}$\tau \, \dot{\boldsymbol{u}}$\end{document}</tex-math></alternatives></inline-formula> to be integrable is satisfied even if <inline-formula><alternatives><mml:math id="inf1129"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1129">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1130"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1130">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}(t)$\end{document}</tex-math></alternatives></inline-formula> contain step functions (and <inline-formula><alternatives><mml:math id="inf1131"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1131">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> delta-functions), see Appendix 4 for details.</p><p>Even in the presence of such step-functions, the Euler-Lagrange equations <inline-formula><alternatives><mml:math id="inf1132"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1132">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\boldsymbol f = 0$\end{document}</tex-math></alternatives></inline-formula> lead to an <inline-formula><alternatives><mml:math id="inf1133"><mml:mi>𝒇</mml:mi></mml:math><tex-math id="inft1133">\begin{document}$\boldsymbol f$\end{document}</tex-math></alternatives></inline-formula> that is a decaying exponential, <inline-formula><alternatives><mml:math id="inf1134"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft1134">\begin{document}$f_{i}(\boldsymbol u(t), t) = c_{i}\, e^{-\frac{t-t_{0}}{\tau}}$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ53">Equation 45</xref>. For initialization at <inline-formula><alternatives><mml:math id="inf1135"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1135">\begin{document}$t_{0}= -\infty$\end{document}</tex-math></alternatives></inline-formula> we have <inline-formula><alternatives><mml:math id="inf1136"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1136">\begin{document}$\boldsymbol f = \frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> at any time. In fact, <xref ref-type="disp-formula" rid="equ60">Equation 52</xref> is equivalent to <inline-formula><alternatives><mml:math id="inf1137"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1137">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\boldsymbol f = 0$\end{document}</tex-math></alternatives></inline-formula>, and hence any solution of <xref ref-type="disp-formula" rid="equ60">Equation 52</xref>, even if <inline-formula><alternatives><mml:math id="inf1138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="inft1138">\begin{document}$\tfrac{\partial \boldsymbol f}{\partial t}$\end{document}</tex-math></alternatives></inline-formula> contains a delta-function, is also a solution of <inline-formula><alternatives><mml:math id="inf1139"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mi>𝒇</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1139">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\boldsymbol f = 0$\end{document}</tex-math></alternatives></inline-formula>. Possible jumps in <inline-formula><alternatives><mml:math id="inf1140"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1140">\begin{document}${\boldsymbol{\bar{r}}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf1141"><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup></mml:math><tex-math id="inft1141">\begin{document}$\boldsymbol u^{*}_{\boldsymbol o}$\end{document}</tex-math></alternatives></inline-formula> are compensated by the jumps they induce in <inline-formula><alternatives><mml:math id="inf1142"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1142">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> (see below for the full mathematical description with a simple example). To give an intuition, we assume that a recurrent network of our prospective neurons has separate fixed points for the two constant input currents <inline-formula><alternatives><mml:math id="inf1143"><mml:msubsup><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="inft1143">\begin{document}$\boldsymbol r_{{\text{in}}}^{(1)}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1144"><mml:msubsup><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="inft1144">\begin{document}$\boldsymbol r_{{\text{in}}}^{(2)}$\end{document}</tex-math></alternatives></inline-formula>. This network still shows an overall relaxation time of <inline-formula><alternatives><mml:math id="inf1145"><mml:msub><mml:mi>𝝉</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1145">\begin{document}$\boldsymbol \tau_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> (but not longer!) when the input rates instantaneously switch from <inline-formula><alternatives><mml:math id="inf1146"><mml:msubsup><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="inft1146">\begin{document}$\boldsymbol r_{{\text{in}}}^{(1)}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf1147"><mml:msubsup><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mn>2</mml:mn><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="inft1147">\begin{document}$\boldsymbol r_{{\text{in}}}^{(2)}$\end{document}</tex-math></alternatives></inline-formula>. Nevertheless, at any moment during this relaxation process, gradient learning of the mapping <inline-formula><alternatives><mml:math id="inf1148"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑭</mml:mi><mml:mi>𝒐</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1148">\begin{document}$\boldsymbol u_{\boldsymbol o}(t) = \boldsymbol F_{\boldsymbol o}(\boldsymbol{\bar{r}}_{{\text{in}}}(t))$\end{document}</tex-math></alternatives></inline-formula> towards <inline-formula><alternatives><mml:math id="inf1149"><mml:mrow><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>𝑭</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1149">\begin{document}$\boldsymbol u_{\boldsymbol o}^{*}(t) = \boldsymbol F_{\boldsymbol o}^{*}(\boldsymbol{\bar{r}}_{{\text{in}}}(t))$\end{document}</tex-math></alternatives></inline-formula> is still guaranteed (Theorem 1).</p></sec><sec sec-type="appendix" id="s10-5"><title>Link to time-varying optimal control</title><p>The explicit differential equation, <xref ref-type="disp-formula" rid="equ60">Equation 52</xref>, is a special case of the one in <xref ref-type="bibr" rid="bib84">Simonetto et al., 2020</xref>, <xref ref-type="disp-formula" rid="equ22">Equation 20</xref>, where the function to be minimized (their <inline-formula><alternatives><mml:math id="inf1150"><mml:mi>f</mml:mi></mml:math><tex-math id="inft1150">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>) can take a general (Lipschitz continuous) form (hence their <inline-formula><alternatives><mml:math id="inf1151"><mml:mi>f</mml:mi></mml:math><tex-math id="inft1151">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> is our Lagrangian, <inline-formula><alternatives><mml:math id="inf1152"><mml:mrow><mml:mi>f</mml:mi><mml:mo>≡</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math><tex-math id="inft1152">\begin{document}$f \equiv L$\end{document}</tex-math></alternatives></inline-formula>). To avoid inverting the Hessian, an iteration algorithm can be applied similar to our implicit form, although more involved to deal with the more general form of <inline-formula><alternatives><mml:math id="inf1153"><mml:mi>L</mml:mi></mml:math><tex-math id="inft1153">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="bibr" rid="bib83">Simonetto and Dall’Anese, 2017</xref>). The idea of tracking the solution of a time-varying optimization problem with a linear look-ahead in time has been introduced introduced in <xref ref-type="bibr" rid="bib108">Zhao and Swamy, 1998</xref>.</p></sec></sec><sec sec-type="appendix" id="s11"><title>The NLA keeps stability as compared to an infinitesimally fast (<inline-formula><alternatives><mml:math id="inf1154"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1154">\begin{document}$\tau\to 0$\end{document}</tex-math></alternatives></inline-formula>) equilibrium propagation</title><p>What have we gained as compared to making the time constant in Equilibrium propagation very small? The answer lies in the stability. To make the comparison explicit, we remind us of the Equilibrium Propagation which we formulate in terms of a Lagrangian. In both cases, the NLA and the Equilibrium Propagation, the Lagrangians are identical. We have chosen the notation <inline-formula><alternatives><mml:math id="inf1155"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1155">\begin{document}${\bar{\boldsymbol{ r }}}= ({\bar{\boldsymbol{ r }}}_{{\text{in}}}, \rho(\boldsymbol u))$\end{document}</tex-math></alternatives></inline-formula> to express that the quantities can be interpreted as a low-pass filtering of <inline-formula><alternatives><mml:math id="inf1156"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mi>𝒓</mml:mi></mml:mrow></mml:math><tex-math id="inft1156">\begin{document}$\boldsymbol r + \tau \boldsymbol{\boldsymbol r}$\end{document}</tex-math></alternatives></inline-formula>. In the Equilibrium propagation, they are called <inline-formula><alternatives><mml:math id="inf1157"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1157">\begin{document}$\boldsymbol r = (\boldsymbol r_{{\text{in}}}, \rho(\boldsymbol u))$\end{document}</tex-math></alternatives></inline-formula>, but this only represents a renaming of the input rates (and a notation change from <inline-formula><alternatives><mml:math id="inf1158"><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft1158">\begin{document}${\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf1159"><mml:mi>𝒓</mml:mi></mml:math><tex-math id="inft1159">\begin{document}$\boldsymbol r$\end{document}</tex-math></alternatives></inline-formula>). Hence, the Lagrangian <inline-formula><alternatives><mml:math id="inf1160"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>‖</mml:mi><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft1160">\begin{document}$L = \tfrac{1}{2}\| \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}\|^{2}+ \beta C$\end{document}</tex-math></alternatives></inline-formula> in the NLA with <inline-formula><alternatives><mml:math id="inf1161"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1161">\begin{document}${\bar{\boldsymbol{ r }}}= ({\bar{\boldsymbol{ r }}}_{{\text{in}}}, \rho(\boldsymbol u))$\end{document}</tex-math></alternatives></inline-formula> is rewritten by <inline-formula><alternatives><mml:math id="inf1162"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>‖</mml:mi><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft1162">\begin{document}$L = \tfrac{1}{2}\| \boldsymbol u - \boldsymbol W \boldsymbol r \|^{2}+ \beta C$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf1163"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1163">\begin{document}$\boldsymbol r = (\boldsymbol r_{{\text{in}}}, \rho(\boldsymbol u))$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The only true difference is that in the NLA we apply the combined lookahead operator <inline-formula><alternatives><mml:math id="inf1164"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1164">\begin{document}${{\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}}\tfrac{\partial }{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> to the Lagrangian <inline-formula><alternatives><mml:math id="inf1165"><mml:mi>L</mml:mi></mml:math><tex-math id="inft1165">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula>, while in the Equilibrium Propagation one applies the reduced operator <inline-formula><alternatives><mml:math id="inf1166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="inft1166">\begin{document}$\tfrac{\partial }{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf1167"><mml:mi>L</mml:mi></mml:math><tex-math id="inft1167">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula>. We claim that the lookahead makes the difference for ‘living’ systems that learnt to optimize in-time with respect to future quantities. The Euler-Lagrange equations for the Equilibrium Propagation reduce to <inline-formula><alternatives><mml:math id="inf1168"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>T</mml:mtext></mml:msup><mml:mi>𝒆</mml:mi><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi>𝒆</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1168">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol u - \boldsymbol W \boldsymbol r - \rho'(\boldsymbol u){\!\cdot\!}\boldsymbol W^{{\text{T}}}\boldsymbol e - \beta \boldsymbol e^{*}= 0$\end{document}</tex-math></alternatives></inline-formula>, where now <inline-formula><alternatives><mml:math id="inf1169"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi></mml:mrow></mml:math><tex-math id="inft1169">\begin{document}$\boldsymbol e = \boldsymbol u - \boldsymbol W \boldsymbol r$\end{document}</tex-math></alternatives></inline-formula>. Since these are not differential equations (no <inline-formula><alternatives><mml:math id="inf1170"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1170">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula> in there), one introduces the gradient descent dynamics <inline-formula><alternatives><mml:math id="inf1171"><mml:mrow><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>T</mml:mtext></mml:msup><mml:mi>𝒆</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi>𝒆</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1171">\begin{document}$\tau \boldsymbol{\dot u}= - \frac{\partial L}{\partial \boldsymbol u}= - \boldsymbol u + \boldsymbol W \boldsymbol r + \rho'(\boldsymbol u){\!\cdot\!}\boldsymbol W^{{\text{T}}}\boldsymbol e + \beta \boldsymbol e^{*}$\end{document}</tex-math></alternatives></inline-formula> and waits for convergence for fixed input and fixed target. If <inline-formula><alternatives><mml:math id="inf1172"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1172">\begin{document}$\tau=0$\end{document}</tex-math></alternatives></inline-formula> in both the NLA and the Equilibrium propagation, we obtain the same implicit and stationary equations in <inline-formula><alternatives><mml:math id="inf1173"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1173">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Because the equation is implicit in <inline-formula><alternatives><mml:math id="inf1174"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1174">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, it has to be solved first for <inline-formula><alternatives><mml:math id="inf1175"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1175">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>. While the Equilibrium propagation suggests to keep the inputs constant until a fixed point is reached, the NLA dynamically moves along the trajectory of fixed points while the inputs are changing. In the Equilibrium propagation we cannot simply take the limit <inline-formula><alternatives><mml:math id="inf1176"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1176">\begin{document}$\tau\to 0$\end{document}</tex-math></alternatives></inline-formula> since then the dynamics either disappears (when <inline-formula><alternatives><mml:math id="inf1177"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft1177">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> remains on the left, <inline-formula><alternatives><mml:math id="inf1178"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1178">\begin{document}$\tau \Delta \boldsymbol u \to 0$\end{document}</tex-math></alternatives></inline-formula>) or explodes (when <inline-formula><alternatives><mml:math id="inf1179"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft1179">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> is moved to the right, <inline-formula><alternatives><mml:math id="inf1180"><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mstyle><mml:mo>→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1180">\begin{document}$\tfrac{{\mathrm{d}} t}{\tau}\to \infty$\end{document}</tex-math></alternatives></inline-formula>), leading to either too small or too big jumps.</p></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s12"><title>Contraction analysis and delta-function inputs</title><sec sec-type="appendix" id="s12-1"><title>Contraction property</title><p>We next show when the voltage dynamics obtained from <inline-formula><alternatives><mml:math id="inf1181"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1181">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> is locally contracting, i.e., when neighboring trajectories of the explicit differential equations, for given inputs and targets, locally converge. This is a different stability property as compared to the (global) convergence properties for the implicit differential equation stated in <xref ref-type="disp-formula" rid="equ53 equ57">Equations 45 and 49</xref>.</p><p>For the contraction analysis we rewrite <xref ref-type="disp-formula" rid="equ59">Equation 51</xref> in the form <inline-formula><alternatives><mml:math id="inf1182"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒚</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒇</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1182">\begin{document}$\boldsymbol G(\boldsymbol y, \dot{\boldsymbol u}) ={\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol f + \tau \dot{\boldsymbol f}= 0$\end{document}</tex-math></alternatives></inline-formula>, where the explicit time dependence of <inline-formula><alternatives><mml:math id="inf1183"><mml:mi>E</mml:mi></mml:math><tex-math id="inft1183">\begin{document}$E$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1184"><mml:mi>𝒇</mml:mi></mml:math><tex-math id="inft1184">\begin{document}$\boldsymbol f$\end{document}</tex-math></alternatives></inline-formula> is a short-cut to express the dependence on <inline-formula><alternatives><mml:math id="inf1185"><mml:mrow><mml:mi>𝒚</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1185">\begin{document}$\boldsymbol y = (\boldsymbol r_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*}, \boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>. According to the implicit function theorem, at any point in time when <inline-formula><alternatives><mml:math id="inf1186"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1186">\begin{document}$\frac{\partial \boldsymbol G}{\partial \dot{\boldsymbol u}}$\end{document}</tex-math></alternatives></inline-formula> is invertible, we can locally write <inline-formula><alternatives><mml:math id="inf1187"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒚</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1187">\begin{document}$\dot{\boldsymbol{u}}= \boldsymbol g(\boldsymbol y)$\end{document}</tex-math></alternatives></inline-formula>. When absorbing the dependence of <inline-formula><alternatives><mml:math id="inf1188"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1188">\begin{document}$\dot{\boldsymbol{u}}$\end{document}</tex-math></alternatives></inline-formula> on <inline-formula><alternatives><mml:math id="inf1189"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1189">\begin{document}$(\boldsymbol r_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*})$\end{document}</tex-math></alternatives></inline-formula> into an explicit time dependence, we can rewrite this differential equation as <inline-formula><alternatives><mml:math id="inf1190"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1190">\begin{document}$\dot{\boldsymbol{u}}= \boldsymbol g(\boldsymbol u, t)$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ60">Equation 52</xref>, when explicitly expressing the dependency of <inline-formula><alternatives><mml:math id="inf1191"><mml:mi>𝒈</mml:mi></mml:math><tex-math id="inft1191">\begin{document}$\boldsymbol g$\end{document}</tex-math></alternatives></inline-formula> on <inline-formula><alternatives><mml:math id="inf1192"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1192">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> only (instead of all the variables <inline-formula><alternatives><mml:math id="inf1193"><mml:mi>𝒚</mml:mi></mml:math><tex-math id="inft1193">\begin{document}$\boldsymbol y$\end{document}</tex-math></alternatives></inline-formula>). This differential equation is contractive and thus stable if the Jacobian of <inline-formula><alternatives><mml:math id="inf1194"><mml:mi>𝒈</mml:mi></mml:math><tex-math id="inft1194">\begin{document}$\boldsymbol g$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1195"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1195">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> is uniformly negative definite (<xref ref-type="bibr" rid="bib60">Lohmiller and Slotine, 1998</xref>). The contraction analysis tells that locally, where <inline-formula><alternatives><mml:math id="inf1196"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1196">\begin{document}$\frac{\partial \boldsymbol G}{\partial \dot{\boldsymbol u}}$\end{document}</tex-math></alternatives></inline-formula> is invertible, we can express <inline-formula><alternatives><mml:math id="inf1197"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1197">\begin{document}$\boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula> as a function <inline-formula><alternatives><mml:math id="inf1198"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒚</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1198">\begin{document}$\boldsymbol{\dot u}= \boldsymbol g(\boldsymbol y)$\end{document}</tex-math></alternatives></inline-formula>, that has derivative <inline-formula><alternatives><mml:math id="inf1199"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒚</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:msup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒚</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1199">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol y}= - \left(\frac{\partial \boldsymbol G}{\partial \boldsymbol{\dot u}}\right)^{-1}\frac{\partial \boldsymbol G}{\partial \boldsymbol y}$\end{document}</tex-math></alternatives></inline-formula> according to the implicit function theorem. Restricted to the <inline-formula><alternatives><mml:math id="inf1200"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1200">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>-component of <inline-formula><alternatives><mml:math id="inf1201"><mml:mi>𝒚</mml:mi></mml:math><tex-math id="inft1201">\begin{document}$\boldsymbol y$\end{document}</tex-math></alternatives></inline-formula> we get the Jacobian<disp-formula id="equ61"><label>(53)</label><alternatives><mml:math id="m61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi mathvariant="bold-italic">H</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t61">\begin{document}$$\displaystyle \frac{\partial \boldsymbol g}{\partial \boldsymbol u}= - \left(\frac{\partial \boldsymbol G}{\partial \dot{\boldsymbol u}}\right)^{-1}\frac{\partial \boldsymbol G}{\partial \boldsymbol u}= - \frac{1}{\tau}\boldsymbol 1 - \boldsymbol H^{-1}\frac{\partial \boldsymbol H}{\partial \boldsymbol u}\dot{\boldsymbol u}= - \frac{1}{\tau}\boldsymbol 1 - \frac{d \log \boldsymbol H}{dt}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>To prove <xref ref-type="disp-formula" rid="equ61">Equation 53</xref> we note that according to <xref ref-type="disp-formula" rid="equ59">Equation 51</xref> we have <inline-formula><alternatives><mml:math id="inf1202"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒚</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1202">\begin{document}$\boldsymbol G(\boldsymbol y, \dot{\boldsymbol u}) = \boldsymbol f + \tau{\!\cdot\!}\boldsymbol H (\boldsymbol u) \, \dot{\boldsymbol{u}}+ \tau \frac{\partial \boldsymbol f}{\partial t}= 0$\end{document}</tex-math></alternatives></inline-formula>, and with this calculate <inline-formula><alternatives><mml:math id="inf1203"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mi>𝑯</mml:mi></mml:mrow></mml:math><tex-math id="inft1203">\begin{document}$\frac{\partial \boldsymbol G}{\partial \dot{\boldsymbol u}}= \tau \boldsymbol H$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf1204"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1204">\begin{document}$H_{ij}= \frac{\partial f_{i}}{\partial u_{j}}$\end{document}</tex-math></alternatives></inline-formula> specified above. Since according to <xref ref-type="disp-formula" rid="equ55">Equation 47</xref> the term <inline-formula><alternatives><mml:math id="inf1205"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1205">\begin{document}$\frac{\partial \boldsymbol f}{\partial t}$\end{document}</tex-math></alternatives></inline-formula> does not depend on <inline-formula><alternatives><mml:math id="inf1206"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1206">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, we also calculate <inline-formula><alternatives><mml:math id="inf1207"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝑯</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑯</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝑯</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>𝑯</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1207">\begin{document}$\frac{\partial \boldsymbol G}{\partial \boldsymbol u}= \boldsymbol H + \tau \frac{\partial \boldsymbol H}{\partial \boldsymbol u}\dot{\boldsymbol u}= \boldsymbol H + \tau \frac{d \boldsymbol H}{d t}$\end{document}</tex-math></alternatives></inline-formula>. Hence, <inline-formula><alternatives><mml:math id="inf1208"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi>𝑯</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mi>𝑯</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>𝑯</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mspace width="0.1667em"/><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/></mml:mrow><mml:mi>𝑯</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1208">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol u}= - \frac{1}{\tau}\boldsymbol H^{-1}\left(\boldsymbol H + \tau \frac{d \boldsymbol H}{d t}\right) = - \frac{1}{\tau}\boldsymbol 1 - \frac{d \log \boldsymbol H}{dt}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>If we had <inline-formula><alternatives><mml:math id="inf1209"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1209">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol u}= - \frac{1}{\tau}\boldsymbol 1$\end{document}</tex-math></alternatives></inline-formula> alone, <inline-formula><alternatives><mml:math id="inf1210"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1210">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> would be obviously negative definite, guaranteeing the local contraction property (<xref ref-type="bibr" rid="bib60">Lohmiller and Slotine, 1998</xref>). To understand this statement, we consider the local representation of neighboring trajectories. The linear approximation of the voltage dynamics <inline-formula><alternatives><mml:math id="inf1211"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1211">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula>, starting with <inline-formula><alternatives><mml:math id="inf1212"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1212">\begin{document}$\boldsymbol u(t_{\circ})$\end{document}</tex-math></alternatives></inline-formula> in a dim-<inline-formula><alternatives><mml:math id="inf1213"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1213">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>-dimensional neighbourhood around some point <inline-formula><alternatives><mml:math id="inf1214"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1214">\begin{document}$\boldsymbol u_{\circ}(t_{\circ})$\end{document}</tex-math></alternatives></inline-formula>, is <inline-formula><alternatives><mml:math id="inf1215"><mml:mrow><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1215">\begin{document}$\frac{d }{d t}(\boldsymbol u - \boldsymbol u_{\circ}) = \frac{\partial \boldsymbol g(\boldsymbol u_{\circ},t)}{\partial \boldsymbol u}(\boldsymbol u - \boldsymbol u_{\circ}) = - \frac{1}{\tau}(\boldsymbol u - \boldsymbol u_{\circ})$\end{document}</tex-math></alternatives></inline-formula>. While <inline-formula><alternatives><mml:math id="inf1216"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1216">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula> is the linear approximations of the original voltage dynamics starting at <inline-formula><alternatives><mml:math id="inf1217"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1217">\begin{document}$\boldsymbol u(t_{\circ})$\end{document}</tex-math></alternatives></inline-formula>, the trajectory <inline-formula><alternatives><mml:math id="inf1218"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1218">\begin{document}$\boldsymbol u_{\circ}(t)$\end{document}</tex-math></alternatives></inline-formula> is the true voltage dynamics starting at the ‘center’ <inline-formula><alternatives><mml:math id="inf1219"><mml:mrow><mml:msub><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1219">\begin{document}$\boldsymbol u_{\circ}(t_{\circ})$\end{document}</tex-math></alternatives></inline-formula> of the neighborhood. This shows the exponential local contraction of surrounding trajectories to <inline-formula><alternatives><mml:math id="inf1220"><mml:msub><mml:mi>𝒖</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub></mml:math><tex-math id="inft1220">\begin{document}$\boldsymbol u_{\circ}$\end{document}</tex-math></alternatives></inline-formula> at times <inline-formula><alternatives><mml:math id="inf1221"><mml:mi>t</mml:mi></mml:math><tex-math id="inft1221">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> around <inline-formula><alternatives><mml:math id="inf1222"><mml:msub><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub></mml:math><tex-math id="inft1222">\begin{document}$t_{\circ}$\end{document}</tex-math></alternatives></inline-formula>, would we have <inline-formula><alternatives><mml:math id="inf1223"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1223">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol u}= - \frac{1}{\tau}\boldsymbol 1$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The additional log-term in <xref ref-type="disp-formula" rid="equ61">Equation 53</xref> may cause a local violation of this contraction property. However, the additional term in <xref ref-type="disp-formula" rid="equ61">Equation 53</xref> becomes small for large or small voltages for which we assume that the curvature of the transfer function also becomes small, <inline-formula><alternatives><mml:math id="inf1224"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1224">\begin{document}$\rho''(\boldsymbol u) \approx \boldsymbol 0$\end{document}</tex-math></alternatives></inline-formula>. In fact, based on <xref ref-type="disp-formula" rid="equ56">Equation 48</xref> we calculate <inline-formula><alternatives><mml:math id="inf1225"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑯</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1225">\begin{document}$\frac{\partial \boldsymbol H}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> being a function of <inline-formula><alternatives><mml:math id="inf1226"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1226">\begin{document}$\rho''(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> that vanishes with vanishing <inline-formula><alternatives><mml:math id="inf1227"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1227">\begin{document}$\rho''(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ62"><label>(54)</label><alternatives><mml:math id="m62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo>″</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo>″</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t62">\begin{document}$$\displaystyle \frac{\partial \boldsymbol H(\boldsymbol u)}{\partial \boldsymbol u}= - \boldsymbol W_{{{\!\text{net}}}}\,{\mathrm{diag}}\left(\rho''(\boldsymbol u) \right) - \frac{\partial^{2}}{\partial \boldsymbol u^{2}}({\bar{\boldsymbol{ \epsilon }}}+ \beta{\bar{\boldsymbol{ e }}}^{*})(\boldsymbol u) = \boldsymbol o (\rho''(\boldsymbol u)). $$\end{document}</tex-math></alternatives></disp-formula></p><p>Plugging <xref ref-type="disp-formula" rid="equ62">Equation 54</xref> into <xref ref-type="disp-formula" rid="equ61">Equation 53</xref> we conclude that <inline-formula><alternatives><mml:math id="inf1228"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1228">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol u}\approx - \frac{1}{\tau}\boldsymbol 1$\end{document}</tex-math></alternatives></inline-formula> where the curvature of the transfer function vanishes, <inline-formula><alternatives><mml:math id="inf1229"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1229">\begin{document}$\rho''(\boldsymbol u) \approx \boldsymbol 0$\end{document}</tex-math></alternatives></inline-formula>. Yet, <inline-formula><alternatives><mml:math id="inf1230"><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup></mml:math><tex-math id="inft1230">\begin{document}$\rho''$\end{document}</tex-math></alternatives></inline-formula> may strongly deviate from 0 for intermediate values of <inline-formula><alternatives><mml:math id="inf1231"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1231">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>. For a rectified linear unit (ReLu), <inline-formula><alternatives><mml:math id="inf1232"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:math><tex-math id="inft1232">\begin{document}$\rho(u)=u$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf1233"><mml:mrow><mml:mi>u</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1233">\begin{document}$u\geq 0$\end{document}</tex-math></alternatives></inline-formula> and 0 else, for instance, <inline-formula><alternatives><mml:math id="inf1234"><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup></mml:math><tex-math id="inft1234">\begin{document}$\rho''$\end{document}</tex-math></alternatives></inline-formula> is a delta-function at 0. Even if the deviation from <inline-formula><alternatives><mml:math id="inf1235"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>0</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1235">\begin{document}$\rho''(\boldsymbol u) = \boldsymbol 0$\end{document}</tex-math></alternatives></inline-formula> in this case is on a set of measure 0, integrating across voltages <inline-formula><alternatives><mml:math id="inf1236"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1236">\begin{document}$u=0$\end{document}</tex-math></alternatives></inline-formula> can cause a jump in the voltage dynamics, preventing a strict local contraction property everywhere. The contraction property, in the example of a ReLu, only holds almost everywhere. Because the ReLu is an important transfer function in practical applications, we elaborate on this example further.</p></sec><sec sec-type="appendix" id="s12-2"><title>Comparison of the NLA with the latent equilibrium</title><p>Here, we point out that the appearance of a delta-function for ReLu’s in the NLA may represent a technical challenge, that this specific challenge is tamed in the simpler version of the NLA principle formulated as Latent Equilibrium (<xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>), and that the Latent Equilibrium may represent a viable new approach for time-varying optimization in general.</p><p>The Euler-Lagrange equation for the presented NLA, <inline-formula><alternatives><mml:math id="inf1237"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1237">\begin{document}$(1 + \tau \frac{{\text{d}}}{{\text{d}} t}) \frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>, <xref ref-type="disp-formula" rid="equ22">Equation 20</xref>, with Jacobian <inline-formula><alternatives><mml:math id="inf1238"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1238">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol f(\boldsymbol u, t) = \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula>, implies second-order derivatives with respect to the voltage <inline-formula><alternatives><mml:math id="inf1239"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1239">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>. This is the case because the total derivative with respect to time, <inline-formula><alternatives><mml:math id="inf1240"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1240">\begin{document}$\frac{{\text{d}}}{{\text{d}} t}$\end{document}</tex-math></alternatives></inline-formula>, applied to the error <inline-formula><alternatives><mml:math id="inf1241"><mml:mrow><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft1241">\begin{document}${\bar{\boldsymbol{ \epsilon }}}={\bar{\boldsymbol{ r }}}'_{{{\!\text{net}}}}{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}\,$\end{document}</tex-math></alternatives></inline-formula> contained in <inline-formula><alternatives><mml:math id="inf1242"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1242">\begin{document}$\boldsymbol f(\boldsymbol u, t)$\end{document}</tex-math></alternatives></inline-formula>, implies the expression <inline-formula><alternatives><mml:math id="inf1243"><mml:mrow><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1243">\begin{document}$\frac{{\text{d}}}{{\text{d}} t}{\bar{\boldsymbol{ r }}}'_{{{\!\text{net}}}}= \rho''(\boldsymbol u) \, \boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>, with ″ equivalent to <inline-formula><alternatives><mml:math id="inf1244"><mml:mfrac><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1244">\begin{document}$\frac{\partial^{2}}{\partial \boldsymbol u \partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>. These second-order derivatives enter both in the implicit form (<xref ref-type="disp-formula" rid="equ54 equ59">Equations 46 and 51</xref>) and the explicit differential <xref ref-type="disp-formula" rid="equ60">Equation 52</xref>. When integrating these equations across the components <inline-formula><alternatives><mml:math id="inf1245"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1245">\begin{document}$u=0$\end{document}</tex-math></alternatives></inline-formula>, a jump in <inline-formula><alternatives><mml:math id="inf1246"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1246">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> emerges that must be explicitly included in the simulations. It is the same jump that may transiently violate the contraction property as shown above (<xref ref-type="disp-formula" rid="equ61 equ62">Equations 53 and 54</xref>, but does not violate the exponential convergence from <xref ref-type="disp-formula" rid="equ53">Equation 45</xref>, see below).</p><p>In the Latent Equilibrium, our Lagrangian <inline-formula><alternatives><mml:math id="inf1247"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>‖</mml:mi><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft1247">\begin{document}$L = \tfrac{1}{2}\| \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}\|^{2}+ \beta C$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf1248"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1248">\begin{document}${\bar{\boldsymbol{ r }}}= ({\bar{\boldsymbol{ r }}}_{{\text{in}}}, \rho(\boldsymbol u))$\end{document}</tex-math></alternatives></inline-formula> is replaced by <inline-formula><alternatives><mml:math id="inf1249"><mml:mrow><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mi>‖</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft1249">\begin{document}$L(\boldsymbol u, \dot{\boldsymbol u}) = \tfrac{1}{2}\| \boldsymbol{\breve u}- \boldsymbol W \boldsymbol r \|^{2}+ \beta C$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf1250"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1250">\begin{document}$\boldsymbol r = (\boldsymbol r_{{\text{in}}}, \rho(\boldsymbol{\breve u}))$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1251"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1251">\begin{document}$\boldsymbol{\breve u}= \boldsymbol u + \tau \boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>. If we were asking for stationary trajectories <inline-formula><alternatives><mml:math id="inf1252"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1252">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula> of <inline-formula><alternatives><mml:math id="inf1253"><mml:mrow><mml:mo movablelimits="false">∫</mml:mo><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1253">\begin{document}$\int L(\boldsymbol u, \dot{\boldsymbol u}){\mathrm{d}}t$\end{document}</tex-math></alternatives></inline-formula> with respect to variations in <inline-formula><alternatives><mml:math id="inf1254"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1254">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, we would obtain the unstable Euler-Lagrange equations <inline-formula><alternatives><mml:math id="inf1255"><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>−</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1255">\begin{document}$\tfrac{\partial L}{\partial \boldsymbol u}- \tfrac{{\mathrm{d}}}{{\mathrm{d}} t}\tfrac{\partial L}{\partial \boldsymbol{\dot u}}= (1 - \tau \tfrac{{\mathrm{d}}}{{\mathrm{d}} t}) \tfrac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>, solved by an exponentially growing function of time, <inline-formula><alternatives><mml:math id="inf1256"><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mi>𝒄</mml:mi><mml:mspace width="0.1667em"/><mml:msup><mml:mi>e</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mstyle></mml:msup></mml:mrow></mml:math><tex-math id="inft1256">\begin{document}$\tfrac{\partial L}{\partial \boldsymbol u}= \boldsymbol c \,e^{\tfrac{t-t_0}{\tau}}$\end{document}</tex-math></alternatives></inline-formula>, unless <inline-formula><alternatives><mml:math id="inf1257"><mml:mrow><mml:mi>𝒄</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1257">\begin{document}$\boldsymbol c = 0$\end{document}</tex-math></alternatives></inline-formula>. To force the trajectory moving along <inline-formula><alternatives><mml:math id="inf1258"><mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1258">\begin{document}$\tfrac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>, one again requires that variations of the action <inline-formula><alternatives><mml:math id="inf1259"><mml:mrow><mml:mo movablelimits="false">∫</mml:mo><mml:mi>L</mml:mi><mml:mspace width="0.1667em"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1259">\begin{document}$\int L \,{\mathrm{d}}t$\end{document}</tex-math></alternatives></inline-formula> are stationary with respect to a prospective voltage, this time with respect to <inline-formula><alternatives><mml:math id="inf1260"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1260">\begin{document}$\boldsymbol{\breve u}= \boldsymbol u + \tau \boldsymbol{\dot u}$\end{document}</tex-math></alternatives></inline-formula>. Because the Lagrangian for the Latent Equilibrium can be expressed as a function <inline-formula><alternatives><mml:math id="inf1261"><mml:mrow><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1261">\begin{document}$L(\boldsymbol{\breve u})$\end{document}</tex-math></alternatives></inline-formula> of <inline-formula><alternatives><mml:math id="inf1262"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:math><tex-math id="inft1262">\begin{document}$\boldsymbol{\breve u}$\end{document}</tex-math></alternatives></inline-formula> only, not of <inline-formula><alternatives><mml:math id="inf1263"><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1263">\begin{document}$\dot{\boldsymbol{\breve u}}$\end{document}</tex-math></alternatives></inline-formula>, the Euler-Lagrange equations becomes <inline-formula><alternatives><mml:math id="inf1264"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msup><mml:mi>𝑾</mml:mi><mml:mtext>T</mml:mtext></mml:msup><mml:mi>𝒆</mml:mi><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi>𝒆</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1264">\begin{document}$\frac{\partial L}{\partial \boldsymbol{\breve u}}= \boldsymbol{\breve u}- \boldsymbol W \boldsymbol r - \rho'(\boldsymbol{\breve u}){\!\cdot\!}\boldsymbol W^{{\text{T}}}\boldsymbol e - \beta \boldsymbol e^{*}= 0$\end{document}</tex-math></alternatives></inline-formula>, where now <inline-formula><alternatives><mml:math id="inf1265"><mml:mrow><mml:mi>𝒆</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mi>𝒓</mml:mi></mml:mrow></mml:math><tex-math id="inft1265">\begin{document}$\boldsymbol e = \boldsymbol{\breve u}- \boldsymbol W \boldsymbol r$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The Latent Equilibrium is consistent with the central idea of the NLA to deal with future quantities. While the presented version of the NLA deals with the discounted future voltage <inline-formula><alternatives><mml:math id="inf1266"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;font-weight:bold;">~</mml:mo></mml:mover></mml:math><tex-math id="inft1266">\begin{document}$\boldsymbol{\tilde u}$\end{document}</tex-math></alternatives></inline-formula> (leading to the operator <inline-formula><alternatives><mml:math id="inf1267"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1267">\begin{document}${{\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}}\tfrac{\partial }{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> applied to the Lagrangian), the Latent Equilibrium deals with the linear approximation <inline-formula><alternatives><mml:math id="inf1268"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:math><tex-math id="inft1268">\begin{document}$\boldsymbol{\breve u}$\end{document}</tex-math></alternatives></inline-formula> of the future voltage (leading to the operator <inline-formula><alternatives><mml:math id="inf1269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="inft1269">\begin{document}$\tfrac{\partial }{\partial \boldsymbol{\breve u}}$\end{document}</tex-math></alternatives></inline-formula> applied to the Lagrangian). Both, the NLA and the Latent Equilibrium differ in this crucial aspect from the Equilibrium Propagation that deals with the current voltage <inline-formula><alternatives><mml:math id="inf1270"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1270">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> (leading to the operator <inline-formula><alternatives><mml:math id="inf1271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="inft1271">\begin{document}$\tfrac{\partial }{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> applied to the Lagrangian <inline-formula><alternatives><mml:math id="inf1272"><mml:mrow><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1272">\begin{document}$L(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, without appearance of <inline-formula><alternatives><mml:math id="inf1273"><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1273">\begin{document}$\dot{\boldsymbol{\breve u}}$\end{document}</tex-math></alternatives></inline-formula>, and hence without intrinsic dynamics, see above).</p><p>For the Latent Equilibrium, it is not obvious to find global convergence properties as expressed in <xref ref-type="disp-formula" rid="equ53 equ57">Equations 45 and 49</xref> for the presented version of the NLA. However, the Latent Equilibrium satisfies the strict local contraction property <inline-formula><alternatives><mml:math id="inf1274"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1274">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol u}= - \frac{1}{\tau}\boldsymbol 1$\end{document}</tex-math></alternatives></inline-formula>. In fact, writing the Euler-Lagrange equations as <inline-formula><alternatives><mml:math id="inf1275"><mml:mrow><mml:mi>𝑮</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒚</mml:mi><mml:mo separator="true">,</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1275">\begin{document}$\boldsymbol G(\boldsymbol y, \dot{\boldsymbol u}) = \frac{\partial L}{\partial \boldsymbol{\breve u}}= 0$\end{document}</tex-math></alternatives></inline-formula> with the abbreviation <inline-formula><alternatives><mml:math id="inf1276"><mml:mrow><mml:mi>𝒚</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo separator="true">,</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1276">\begin{document}$\boldsymbol y = (\boldsymbol r_{{\text{in}}}, \dot{\boldsymbol r}_{{\text{in}}}, \boldsymbol u_{\boldsymbol o}^{*}, \dot{\boldsymbol u}_{\boldsymbol o}^{*}, \boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, leads to <inline-formula><alternatives><mml:math id="inf1277"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac></mml:mstyle><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1277">\begin{document}$\frac{\partial \boldsymbol G}{\partial \boldsymbol{\breve u}}= \frac{\partial \boldsymbol G}{\partial \boldsymbol u}= \tfrac{1}{\tau}\frac{\partial \boldsymbol G}{\partial \boldsymbol{\dot u}}$\end{document}</tex-math></alternatives></inline-formula>, and the linear approximation obtained from plugging these partial derivatives into <xref ref-type="disp-formula" rid="equ61">Equation 53</xref> yields the claimed contraction property <inline-formula><alternatives><mml:math id="inf1278"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:mstyle style="font-style:italic;font-family:Cambria, `Times New Roman`, serif;font-weight:bold;"><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:math><tex-math id="inft1278">\begin{document}$\frac{\partial \boldsymbol g}{\partial \boldsymbol u}= - \frac{1}{\tau}\boldsymbol 1$\end{document}</tex-math></alternatives></inline-formula> for the Latent Equilibrium. The Jacobian <inline-formula><alternatives><mml:math id="inf1279"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑮</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˙</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1279">\begin{document}$\frac{\partial \boldsymbol G}{\partial \boldsymbol{\dot u}}$\end{document}</tex-math></alternatives></inline-formula> is invertible if the Hessian <inline-formula><alternatives><mml:math id="inf1280"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1280">\begin{document}$\boldsymbol H = \frac{\partial^{2}L}{\partial \boldsymbol{\breve u} \partial \boldsymbol{\breve u}}$\end{document}</tex-math></alternatives></inline-formula> is (that looks as in <xref ref-type="disp-formula" rid="equ56">Equation 48</xref>, but with <inline-formula><alternatives><mml:math id="inf1281"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1281">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> replaced by <inline-formula><alternatives><mml:math id="inf1282"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">˘</mml:mo></mml:mover></mml:math><tex-math id="inft1282">\begin{document}$\boldsymbol{\breve u}$\end{document}</tex-math></alternatives></inline-formula>).</p><p>Crucially, for the Latent Equilibrium, the analogous theorems on real-time dendritic error propagation and learning (rt-DeEP and rt-DeEL) hold. The key property is that the trajectories of the Latent Equilibrium are stationary solution of the corresponding action <inline-formula><alternatives><mml:math id="inf1283"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo movablelimits="false">∫</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mi>L</mml:mi><mml:mspace width="0.1667em"/><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:math><tex-math id="inft1283">\begin{document}$A=\int\!L \,{\mathrm{d}}t$\end{document}</tex-math></alternatives></inline-formula>, so that the variation of <inline-formula><alternatives><mml:math id="inf1284"><mml:mi>A</mml:mi></mml:math><tex-math id="inft1284">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> induced by <inline-formula><alternatives><mml:math id="inf1285"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft1285">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> reduces to the partial derivative of <inline-formula><alternatives><mml:math id="inf1286"><mml:mi>L</mml:mi></mml:math><tex-math id="inft1286">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1287"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft1287">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The above strict contraction property that for non-vanishing errors only holds for the Latent Equilibrium, but not for the NLA, may be a reason why the simulations of the error-based updates in our hands seem to be more stable for the Latent Equilibrium as compared to the NLA. This does not withstand the fact that the NLA equations are used in the context of time-varying optimal control (see above). It would be interesting to consider also the Latent Equilibrium as a tool for non-stationary, time-varying optimization (<xref ref-type="bibr" rid="bib84">Simonetto et al., 2020</xref>).</p></sec><sec sec-type="appendix" id="s12-3"><title>Delta-function inputs keep <inline-formula><alternatives><mml:math id="inf1288"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1288">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula></title><p>We next explain in more details why delta-functions in the input rates <inline-formula><alternatives><mml:math id="inf1289"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1289">\begin{document}$\boldsymbol r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> for the NLA the stationarity (‘equilibrium’) condition <inline-formula><alternatives><mml:math id="inf1290"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1290">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> is always satisfied (the delta-function in <inline-formula><alternatives><mml:math id="inf1291"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1291">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> for the NLA corresponding to step-function in <inline-formula><alternatives><mml:math id="inf1292"><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1292">\begin{document}$\boldsymbol r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> for the Latent Equilibrium). We reconsider the explicit differential equation <inline-formula><alternatives><mml:math id="inf1293"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi>𝑯</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mi>𝒇</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft1293">\begin{document}$\dot{\boldsymbol{u}}= \boldsymbol g(\boldsymbol u, t) = - \frac{1}{\tau}\boldsymbol H^{-1}\left(\boldsymbol f + \tau \frac{\partial \boldsymbol f}{\partial t}\right)$\end{document}</tex-math></alternatives></inline-formula> given in <xref ref-type="disp-formula" rid="equ60">Equation 52</xref>, with <inline-formula><alternatives><mml:math id="inf1294"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup></mml:mrow></mml:math><tex-math id="inft1294">\begin{document}$\boldsymbol f(\boldsymbol u, t) = \frac{\partial L}{\partial \boldsymbol u}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}-{\bar{\boldsymbol{ \epsilon }}}- \beta{\bar{\boldsymbol{ e }}}^{*}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1295"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft1295">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> given in <xref ref-type="disp-formula" rid="equ56">Equation 48</xref>.</p><p>To simplify matters, we consider a single delta-function at <inline-formula><alternatives><mml:math id="inf1296"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1296">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula> as input in the absence of output nudging. In this case, we get <inline-formula><alternatives><mml:math id="inf1297"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mover><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;font-weight:bold;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>𝒐</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>𝜹</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1297">\begin{document}$\frac{\partial \boldsymbol f}{\partial t}= \frac{\partial \boldsymbol f}{\partial{\bar{\boldsymbol{ r }}}_{{\text{in}}}}\dot{{\boldsymbol{\bar{r}}}}_{{\text{in}}}+ \frac{\partial \boldsymbol f}{\partial \boldsymbol{\bar{r}}_{{\text{in}}}}\dot{ \boldsymbol u}^{*}_{\boldsymbol o}= \boldsymbol W_{{\text{in}}}\boldsymbol \delta_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>, where the input matrix <inline-formula><alternatives><mml:math id="inf1298"><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1298">\begin{document}$\boldsymbol W_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> is typically sparse (not all network neurons receive external input), and <inline-formula><alternatives><mml:math id="inf1299"><mml:mrow><mml:msub><mml:mi>𝜹</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1299">\begin{document}$\boldsymbol \delta_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> is a vector of delta-functions restricted to the input neurons. Following (<xref ref-type="bibr" rid="bib67">Nedeljkov and Oberguggenberger, 2012</xref>), Proposition 2.1, we can then write the explicit differential equation, <xref ref-type="disp-formula" rid="equ59">Equation 51</xref>, in the form<disp-formula id="equ63"><label>(55)</label><alternatives><mml:math id="m63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">δ</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t63">\begin{document}$$\displaystyle \dot{\boldsymbol{u}}= \boldsymbol g(\boldsymbol u, t) = \check{\boldsymbol g}(\boldsymbol u, t) + \boldsymbol H(\boldsymbol u)^{-1}\boldsymbol W_{{\text{in}}}\boldsymbol \delta_{{\text{in}}}(t), $$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf1300"><mml:mrow><mml:mover><mml:mi>𝒈</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1300">\begin{document}$\check{\boldsymbol g}(\boldsymbol u, t)$\end{document}</tex-math></alternatives></inline-formula> is globally Lipschitz continuous. Due to the Lipschitz continuity the change in <inline-formula><alternatives><mml:math id="inf1301"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1301">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> evoked by <inline-formula><alternatives><mml:math id="inf1302"><mml:mrow><mml:mover><mml:mi>𝒈</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1302">\begin{document}$\check{\boldsymbol g}(\boldsymbol u, t)$\end{document}</tex-math></alternatives></inline-formula> during a small time interval <inline-formula><alternatives><mml:math id="inf1303"><mml:mrow><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="inft1303">\begin{document}$[-\varepsilon, \varepsilon]$\end{document}</tex-math></alternatives></inline-formula> around <inline-formula><alternatives><mml:math id="inf1304"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1304">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula> vanishes when this interval shrinks, <inline-formula><alternatives><mml:math id="inf1305"><mml:mrow><mml:mi>ε</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1305">\begin{document}$\varepsilon\to 0$\end{document}</tex-math></alternatives></inline-formula>. To quantify the change in <inline-formula><alternatives><mml:math id="inf1306"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1306">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> during these intervals it is, therefore, enough to consider <inline-formula><alternatives><mml:math id="inf1307"><mml:mrow><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>𝜹</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1307">\begin{document}$\dot{\boldsymbol{u}}= \boldsymbol H(\boldsymbol u)^{-1}\boldsymbol W_{{\text{in}}}\boldsymbol \delta_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>, or equivalently <inline-formula><alternatives><mml:math id="inf1308"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>𝜹</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1308">\begin{document}$\boldsymbol H(\boldsymbol u) \dot{\boldsymbol{u}}= \boldsymbol W_{{\text{in}}}\boldsymbol \delta_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>. To estimate the jump induced by the delta-functions, we consider some mollifier <inline-formula><alternatives><mml:math id="inf1309"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>ϕ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mi>/</mml:mi><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1309">\begin{document}$\phi_{\varepsilon}(t) = \varepsilon^{-1}\phi(t/\varepsilon)$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf1310"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1310">\begin{document}$\phi(t)$\end{document}</tex-math></alternatives></inline-formula> is a smooth function on the interval <inline-formula><alternatives><mml:math id="inf1311"><mml:mrow><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mn>1</mml:mn><mml:mo separator="true">,</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="inft1311">\begin{document}$[-1, 1]$\end{document}</tex-math></alternatives></inline-formula> with integral 1. By <inline-formula><alternatives><mml:math id="inf1312"><mml:mrow><mml:msub><mml:mi>𝝓</mml:mi><mml:mrow><mml:mtext>in</mml:mtext><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1312">\begin{document}$\boldsymbol \phi_{{\text{in}},\varepsilon}(t)$\end{document}</tex-math></alternatives></inline-formula> we denote the vector of mollifiers centered at the delta-functions of the input neurons. We now consider the two differential equations, with the second approximating the first on the interval <inline-formula><alternatives><mml:math id="inf1313"><mml:mrow><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="inft1313">\begin{document}$[-\varepsilon, \varepsilon]$\end{document}</tex-math></alternatives></inline-formula>, but without regular term <inline-formula><alternatives><mml:math id="inf1314"><mml:mrow><mml:mover><mml:mi>𝒈</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1314">\begin{document}$\check{\boldsymbol g}(\boldsymbol u, t)$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ64"><label>(56a)</label><alternatives><mml:math id="m64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>,</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t64">\begin{document}$$\displaystyle \tau \boldsymbol H(\boldsymbol u_{\varepsilon}) \, \dot{\boldsymbol{u}}_{\varepsilon}= \tau \boldsymbol H(\boldsymbol u_{\varepsilon}) \check{\boldsymbol g}(\boldsymbol u, t) + \boldsymbol W_{{\text{in}}}\boldsymbol \phi_{{\text{in}},\varepsilon}(t)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ65"><label>(56b)</label><alternatives><mml:math id="m65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mi mathvariant="bold-italic">H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>,</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>ε</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>ε</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t65">\begin{document}$$\displaystyle \tau \boldsymbol H(\check{\boldsymbol u}_{\varepsilon}) \,\dot{\check{\boldsymbol{u}}}_{\varepsilon}= \boldsymbol W_{{\text{in}}}\boldsymbol \phi_{{\text{in}},\varepsilon}(t) \;, \quad \check{\boldsymbol u}_{\varepsilon}(-\varepsilon) = \boldsymbol u_{\varepsilon}(-\varepsilon).$$\end{document}</tex-math></alternatives></disp-formula></p><p>We assume that for all <inline-formula><alternatives><mml:math id="inf1315"><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="inft1315">\begin{document}$t \in [-\varepsilon, \varepsilon]$\end{document}</tex-math></alternatives></inline-formula> the matrices <inline-formula><alternatives><mml:math id="inf1316"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1316">\begin{document}$\boldsymbol H(\boldsymbol u_{\varepsilon}(t))$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1317"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1317">\begin{document}$\boldsymbol H(\check{\boldsymbol u}_{\varepsilon}(t))$\end{document}</tex-math></alternatives></inline-formula> are invertible, so that the two <xref ref-type="disp-formula" rid="equ64">Equation 56a</xref>, <xref ref-type="disp-formula" rid="equ65">Equation 56b</xref> can be turned into an explicit differential equations. Analogously to the 1-dimensional case (<xref ref-type="bibr" rid="bib67">Nedeljkov and Oberguggenberger, 2012</xref>), we conclude that the solution of <xref ref-type="disp-formula" rid="equ64">Equation 56a</xref>, <xref ref-type="disp-formula" rid="equ65">Equation 56b</xref> on the interval <inline-formula><alternatives><mml:math id="inf1318"><mml:mrow><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="inft1318">\begin{document}$[-\varepsilon , \varepsilon]$\end{document}</tex-math></alternatives></inline-formula> converge to each other, <inline-formula><alternatives><mml:math id="inf1319"><mml:mrow><mml:munder><mml:mi>sup</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">]</mml:mo></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mi>|</mml:mi><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>|</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1319">\begin{document}$\sup_{t \in [-\varepsilon, \varepsilon] }| \boldsymbol u_{\varepsilon}(t) - \check{\boldsymbol u}_{\varepsilon}(t)| \to 0$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf1320"><mml:mrow><mml:mi>ε</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1320">\begin{document}$\varepsilon \to 0$\end{document}</tex-math></alternatives></inline-formula>. As a consequence, the jump of <inline-formula><alternatives><mml:math id="inf1321"><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub></mml:math><tex-math id="inft1321">\begin{document}$\check{\boldsymbol u}_{\varepsilon}$\end{document}</tex-math></alternatives></inline-formula> at <inline-formula><alternatives><mml:math id="inf1322"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1322">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula> converges to the corresponding jump of <inline-formula><alternatives><mml:math id="inf1323"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>ε</mml:mi></mml:msub></mml:math><tex-math id="inft1323">\begin{document}$\boldsymbol u_{\varepsilon}$\end{document}</tex-math></alternatives></inline-formula> in the various dimensions.</p><p>To calculate the jump of <inline-formula><alternatives><mml:math id="inf1324"><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub></mml:math><tex-math id="inft1324">\begin{document}$\check{\boldsymbol u}_{\varepsilon}$\end{document}</tex-math></alternatives></inline-formula> we have to integrate <inline-formula><alternatives><mml:math id="inf1325"><mml:mrow><mml:mi>τ</mml:mi><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:msub><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft1325">\begin{document}$\tau \boldsymbol H(\check{\boldsymbol u}_{\varepsilon}) \,\dot{\check{\boldsymbol{u}}}_{\varepsilon}$\end{document}</tex-math></alternatives></inline-formula> across the time interval <inline-formula><alternatives><mml:math id="inf1326"><mml:mrow><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="inft1326">\begin{document}$[-\varepsilon, \varepsilon]$\end{document}</tex-math></alternatives></inline-formula>. Instead of integrating <inline-formula><alternatives><mml:math id="inf1327"><mml:msub><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub></mml:math><tex-math id="inft1327">\begin{document}$\dot{\check{\boldsymbol{u}}}_{\varepsilon}$\end{document}</tex-math></alternatives></inline-formula>, we first integrate <inline-formula><alternatives><mml:math id="inf1328"><mml:mrow><mml:mi>τ</mml:mi><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:msub><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft1328">\begin{document}$\tau \boldsymbol H(\check{\boldsymbol u}_{\varepsilon}) \, \dot{\check{\boldsymbol{u}}}_{\varepsilon}$\end{document}</tex-math></alternatives></inline-formula> given in <xref ref-type="disp-formula" rid="equ65">Equation 56b</xref>. Moving from right to left yields<disp-formula id="equ66"><label>(57)</label><alternatives><mml:math id="m66"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>𝑰</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">−</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mi>ε</mml:mi></mml:msubsup><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>𝝓</mml:mi><mml:mrow><mml:mtext>in</mml:mtext><mml:mo separator="true">,</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mi>ε</mml:mi></mml:msubsup><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:msub><mml:mover><mml:mi>𝒗</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:mrow><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t66">\begin{document}$$\displaystyle \boldsymbol W_{{\text{in}}}\boldsymbol I_{{\text{in}}}= \int_{-\varepsilon}^{\varepsilon}\boldsymbol W_{{\text{in}}}\boldsymbol \phi_{{\text{in}},\varepsilon}(t) \,dt = \tau \int_{-\varepsilon}^{\varepsilon}\boldsymbol H(\check{\boldsymbol u}_{\varepsilon}(t)) \, \dot{\boldsymbol v}_{\varepsilon}(t) \,dt = \tau \int_{\check{\boldsymbol u}_\varepsilon(-\varepsilon)}^{\check{\boldsymbol u}_\varepsilon(\varepsilon)}\boldsymbol H(\check{\boldsymbol u}_{\varepsilon}) \, \,d\check{\boldsymbol u}_{\varepsilon}\,, $$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf1329"><mml:msub><mml:mi>𝑰</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1329">\begin{document}$\boldsymbol I_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> is the index vector of the input neurons having a delta-function, i.e., <inline-formula><alternatives><mml:math id="inf1330"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>in</mml:mtext><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft1330">\begin{document}$I_{{\text{in}},j}= 1$\end{document}</tex-math></alternatives></inline-formula> if there is a delta-input, and else 0. Note that <inline-formula><alternatives><mml:math id="inf1331"><mml:mrow><mml:msub><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft1331">\begin{document}$\dot v_{\varepsilon, j}\, dt = dv_{\varepsilon,j}$\end{document}</tex-math></alternatives></inline-formula>. Because <inline-formula><alternatives><mml:math id="inf1332"><mml:mi>𝑯</mml:mi></mml:math><tex-math id="inft1332">\begin{document}$\boldsymbol H$\end{document}</tex-math></alternatives></inline-formula> is itself a derivative, <inline-formula><alternatives><mml:math id="inf1333"><mml:mrow><mml:mi>𝑯</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1333">\begin{document}$\boldsymbol H = \frac{\partial \boldsymbol f}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>, we can explicitly calculate the latter integral (also for <inline-formula><alternatives><mml:math id="inf1334"><mml:mrow><mml:mi>β</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1334">\begin{document}$\beta \gt 0$\end{document}</tex-math></alternatives></inline-formula>, but for clarity here only done for <inline-formula><alternatives><mml:math id="inf1335"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1335">\begin{document}$\beta=0$\end{document}</tex-math></alternatives></inline-formula>). The last integral in <xref ref-type="disp-formula" rid="equ66">Equation 57</xref> is defined as a vector with <inline-formula><alternatives><mml:math id="inf1336"><mml:mi>i</mml:mi></mml:math><tex-math id="inft1336">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula>-th component being<disp-formula id="equ67"><label>(58)</label><alternatives><mml:math id="m67"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:mrow><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mrow><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:mrow><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mrow><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mrow><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mi>d</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mrow><mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">|</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mrow><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mrow><mml:mi>ε</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:msub><mml:mi>𝒗</mml:mi><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒗</mml:mi><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t67">\begin{document}$$\displaystyle  \left(\int_{\check{\boldsymbol u}_\varepsilon(-\varepsilon)}^{\check{\boldsymbol u}_\varepsilon(\varepsilon)}\boldsymbol H(\check{\boldsymbol u}_{\varepsilon}) \, \,d\check{\boldsymbol u}_{\varepsilon}\right)_{i}= \sum_{j=1}^{N}\int_{\check{u}_{\varepsilon,j}(-\varepsilon)}^{\check{u}_{\varepsilon,j}(\varepsilon)}H_{ij}(u_{j}) \, du_{j}= \sum_{j=1}^{N}\left. (\delta_{ij}u_{i}- W_{ij}\rho (u_{j})) \right|_{\check{u}_{\varepsilon,j}(-\varepsilon)}^{\check{u}_{\varepsilon,j}(\varepsilon)}= \big(\boldsymbol v_{\varepsilon}(\varepsilon) - \boldsymbol v_{\varepsilon}(-\varepsilon) \big)_{i}\,, $$\end{document}</tex-math></alternatives></disp-formula></p><p>where in the second last equality we used that <inline-formula><alternatives><mml:math id="inf1337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1337">\begin{document}$H_{ij}(\boldsymbol u) = \delta_{ij}- W_{ij}\rho'(u_{j})$\end{document}</tex-math></alternatives></inline-formula> does only depend on the component <inline-formula><alternatives><mml:math id="inf1338"><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="inft1338">\begin{document}$u_{j}$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ56">Equation 48</xref>. In the last equality we introduced the ‘network voltage error’ <inline-formula><alternatives><mml:math id="inf1339"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒗</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1339">\begin{document}$\check{\boldsymbol v}_{\varepsilon}= \check{\boldsymbol u}_{\varepsilon}- \boldsymbol W_{{{\!\text{net}}}}\rho(\check{\boldsymbol u}_{\varepsilon})$\end{document}</tex-math></alternatives></inline-formula>. Following the 1-dimensional case treated in <xref ref-type="disp-formula" rid="equ75">Equation 66</xref>, Proposition 1.2 we introduce the ‘jump function’ (called <inline-formula><alternatives><mml:math id="inf1340"><mml:mrow><mml:mi>G</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1340">\begin{document}$G(y)$\end{document}</tex-math></alternatives></inline-formula> in the cited work)<disp-formula id="equ68"><label>(59)</label><alternatives><mml:math id="m68"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>𝑱</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mover><mml:mi>𝒗</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mover><mml:mi>𝒗</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.2778em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t68">\begin{document}$$\displaystyle \begin{align}\boldsymbol J(\check{\boldsymbol u}_{\varepsilon}) = \tau (\check{\boldsymbol v}_{\varepsilon} - \check{\boldsymbol v}_{\circ}) \;, \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>with <inline-formula><alternatives><mml:math id="inf1341"><mml:msub><mml:mover><mml:mi>𝒗</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub></mml:math><tex-math id="inft1341">\begin{document}$\check{\boldsymbol v}_{\circ}$\end{document}</tex-math></alternatives></inline-formula> thought to represent <inline-formula><alternatives><mml:math id="inf1342"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒗</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1342">\begin{document}$\check{\boldsymbol v}_{\varepsilon}(t_{\circ})$\end{document}</tex-math></alternatives></inline-formula> at some time <inline-formula><alternatives><mml:math id="inf1343"><mml:msub><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub></mml:math><tex-math id="inft1343">\begin{document}$t_{\circ}$\end{document}</tex-math></alternatives></inline-formula> before the delta-kick sets in. With this setting, <xref ref-type="disp-formula" rid="equ66">Equation 57</xref> turns into<disp-formula id="equ69"><label>(60)</label><alternatives><mml:math id="m69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ε</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>ε</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t69">\begin{document}$$\displaystyle \boldsymbol W_{{\text{in}}}\boldsymbol I_{{\text{in}}}= \boldsymbol J(\check{\boldsymbol u}_{\varepsilon}(\varepsilon)) - \boldsymbol J(\check{\boldsymbol u}_{\varepsilon}(-\varepsilon)). $$\end{document}</tex-math></alternatives></disp-formula></p><p>In the limit <inline-formula><alternatives><mml:math id="inf1344"><mml:mrow><mml:mi>ε</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1344">\begin{document}$\varepsilon\to 0$\end{document}</tex-math></alternatives></inline-formula> we get a relation between <inline-formula><alternatives><mml:math id="inf1345"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1345">\begin{document}$\boldsymbol u(t)$\end{document}</tex-math></alternatives></inline-formula> immediately before and after the jump, <inline-formula><alternatives><mml:math id="inf1346"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1346">\begin{document}$\boldsymbol u(-0)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1347"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">+</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1347">\begin{document}$\boldsymbol u(+0)$\end{document}</tex-math></alternatives></inline-formula>, using that in this limit the boundary points of the trajectories also converge, <inline-formula><alternatives><mml:math id="inf1348"><mml:mrow><mml:msub><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">ˇ</mml:mo></mml:mover><mml:mi>ε</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">±</mml:mo><mml:mi>ε</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>→</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">±</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1348">\begin{document}$\check{\boldsymbol u}_{\varepsilon}(\pm \varepsilon) \to \boldsymbol u(\pm 0)$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ70"><label>(61)</label><alternatives><mml:math id="m70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t70">\begin{document}$$\displaystyle \boldsymbol J(\boldsymbol u(+0)) = \boldsymbol J(\boldsymbol u(-0)) + \boldsymbol W_{{\text{in}}}\boldsymbol I_{{\text{in}}}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>We now assume that the function <inline-formula><alternatives><mml:math id="inf1349"><mml:mrow><mml:mi>𝑱</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒗</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒗</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1349">\begin{document}$\boldsymbol J(\boldsymbol u) = \tau (\boldsymbol v - \boldsymbol v_{\circ})$\end{document}</tex-math></alternatives></inline-formula> is invertible around the jump. This is the case if the Jacobian <inline-formula><alternatives><mml:math id="inf1350"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑱</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1350">\begin{document}$\frac{\partial \boldsymbol J(\boldsymbol u)}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> is invertible, and because <inline-formula><alternatives><mml:math id="inf1351"><mml:mrow><mml:mi>𝒗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1351">\begin{document}$\boldsymbol v = \boldsymbol u - \boldsymbol W_{{{\!\text{net}}}}\rho(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, we require invertability of <inline-formula><alternatives><mml:math id="inf1352"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑱</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mi>𝑯</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1352">\begin{document}$\frac{\partial \boldsymbol J(\boldsymbol u)}{\partial \boldsymbol u}= \tau \boldsymbol H (\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, with Hessian defined in <xref ref-type="disp-formula" rid="equ56">Equation 48</xref>.</p><p>In the case of invertability we get the voltage after the jump as<disp-formula id="equ71"><label>(62)</label><alternatives><mml:math id="m71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t71">\begin{document}$$\displaystyle \boldsymbol u(+0) = \boldsymbol J^{-1}\big(\boldsymbol J(\boldsymbol u(-0)) + \boldsymbol W_{{\text{in}}}\boldsymbol I_{{\text{in}}}\big). $$\end{document}</tex-math></alternatives></disp-formula></p><p>We next calculate the jump in <inline-formula><alternatives><mml:math id="inf1353"><mml:mi>𝒗</mml:mi></mml:math><tex-math id="inft1353">\begin{document}$\boldsymbol v$\end{document}</tex-math></alternatives></inline-formula>. This is easy since <inline-formula><alternatives><mml:math id="inf1354"><mml:mrow><mml:mi>𝒗</mml:mi><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1354">\begin{document}$\boldsymbol v = \boldsymbol u - \boldsymbol W_{{{\!\text{net}}}}\rho(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> linearly enters in the function <inline-formula><alternatives><mml:math id="inf1355"><mml:mrow><mml:mi>𝑱</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒗</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒗</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1355">\begin{document}$\boldsymbol J(\boldsymbol u) = \tau (\boldsymbol v - \boldsymbol v_{\circ})$\end{document}</tex-math></alternatives></inline-formula>. Plugging the explicit expression for <inline-formula><alternatives><mml:math id="inf1356"><mml:mi>𝑱</mml:mi></mml:math><tex-math id="inft1356">\begin{document}$\boldsymbol J$\end{document}</tex-math></alternatives></inline-formula> into <xref ref-type="disp-formula" rid="equ70">Equation 61</xref> we get <inline-formula><alternatives><mml:math id="inf1357"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒗</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">+</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒗</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒗</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>𝒗</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>𝑰</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1357">\begin{document}$\tau \, (\boldsymbol v(+0) - \boldsymbol v_{\circ}) = \tau \, (\boldsymbol v(-0) - \boldsymbol v_{\circ}) + \boldsymbol W_{{\text{in}}}\boldsymbol I_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>, or<disp-formula id="equ72"><label>(63)</label><alternatives><mml:math id="m72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t72">\begin{document}$$\displaystyle \boldsymbol v(+0) = \boldsymbol v(-0) + \frac{1}{\tau}\boldsymbol W_{{\text{in}}}\boldsymbol I_{{\text{in}}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>Knowing the jump in <inline-formula><alternatives><mml:math id="inf1358"><mml:mi>𝒗</mml:mi></mml:math><tex-math id="inft1358">\begin{document}$\boldsymbol v$\end{document}</tex-math></alternatives></inline-formula> helps to show that the equilibrium condition <inline-formula><alternatives><mml:math id="inf1359"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1359">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> is always satisfied, even immediately after the delta-in put, provided the initialization is at <inline-formula><alternatives><mml:math id="inf1360"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1360">\begin{document}$t_{0}= -\infty$\end{document}</tex-math></alternatives></inline-formula>. To show this, remember that in the absence of nudging we have <inline-formula><alternatives><mml:math id="inf1361"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mi>𝒗</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1361">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol f(\boldsymbol u, t) = \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}= \boldsymbol u - \boldsymbol W_{{{\!\text{net}}}}\rho(\boldsymbol u) - \boldsymbol W_{{\text{in}}}{\bar{\boldsymbol{ r }}}_{{\text{in}}}= \boldsymbol v - \boldsymbol W_{{\text{in}}}{\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>. The jump size of <inline-formula><alternatives><mml:math id="inf1362"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1362">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> for a delta-function at <inline-formula><alternatives><mml:math id="inf1363"><mml:mrow><mml:mi>t</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>=</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1363">\begin{document}$t\!=\!0$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf1364"><mml:mrow><mml:msub><mml:mi>𝒓</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>𝜹</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1364">\begin{document}$\boldsymbol r_{{\text{in}}}(t) = \boldsymbol \delta_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> is <inline-formula><alternatives><mml:math id="inf1365"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac></mml:math><tex-math id="inft1365">\begin{document}$\frac{1}{\tau}$\end{document}</tex-math></alternatives></inline-formula>. This is because <inline-formula><alternatives><mml:math id="inf1366"><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1366">\begin{document}${\bar{\boldsymbol{ r }}}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> satisfies the differential equations <inline-formula><alternatives><mml:math id="inf1367"><mml:mrow><mml:msub><mml:mover><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msub><mml:mi>𝜹</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1367">\begin{document}$\dot{ {\bar{\boldsymbol{ r }}}}_{{\text{in}}}(t) = - \frac{1}{\tau}{\bar{\boldsymbol{ r }}}_{{\text{in}}}(t) + \frac{1}{\tau}\boldsymbol \delta_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula>, provided that <inline-formula><alternatives><mml:math id="inf1368"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1368">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula>. Hence,<disp-formula id="equ73"><label>(64)</label><alternatives><mml:math id="m73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t73">\begin{document}$$\displaystyle {\bar{\boldsymbol{ r }}}_{{\text{in}}}(+0) ={\bar{\boldsymbol{ r }}}_{{\text{in}}}(-0) + \frac{1}{\tau}\boldsymbol I_{{\text{in}}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>With <xref ref-type="disp-formula" rid="equ72 equ73">Equations 63 and 64</xref> we conclude that <inline-formula><alternatives><mml:math id="inf1369"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>𝒗</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>𝑾</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1369">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}= \boldsymbol v - \boldsymbol W_{{\text{in}}}{\bar{\boldsymbol{ r }}}_{{\text{in}}}= 0$\end{document}</tex-math></alternatives></inline-formula> throughout.</p></sec></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s13"><title>Example of a single recurrently connected neuron</title><p>To get an intuition for the instantaneity in the recurrent case we consider the example of a single, recurrently connected neuron. We also put this into the context of the Latent Equilibrium (<xref ref-type="bibr" rid="bib40">Haider et al., 2021</xref>). Consider the weight vector <inline-formula><alternatives><mml:math id="inf1370"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1370">\begin{document}$\boldsymbol W = (W_{{\text{in}}}, W_{{{\!\text{net}}}})$\end{document}</tex-math></alternatives></inline-formula> with an input rate <inline-formula><alternatives><mml:math id="inf1371"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1371">\begin{document}$r_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> driving the postsynaptic voltage <inline-formula><alternatives><mml:math id="inf1372"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1372">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>. The postsynaptic rate is <inline-formula><alternatives><mml:math id="inf1373"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1373">\begin{document}$r = \rho(u) + \tau \dot \rho(u)$\end{document}</tex-math></alternatives></inline-formula>, and its low-pass filter with respect to <inline-formula><alternatives><mml:math id="inf1374"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft1374">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> is <inline-formula><alternatives><mml:math id="inf1375"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1375">\begin{document}$\bar r = \rho(u)$\end{document}</tex-math></alternatives></inline-formula>. As always, the low-pass filtering reaches back to an initialization at <inline-formula><alternatives><mml:math id="inf1376"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1376">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ16">Equation 15</xref>. The Lagrangian has the form<disp-formula id="equ74"><label>(65)</label><alternatives><mml:math id="m74"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:msup><mml:mo>*</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msup><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t74">\begin{document}$$\displaystyle \begin{align}L = \frac{1}{2}\bar e^{2} + \frac{\beta}{2}{\bar e}^{*^2}= \frac{1}{2}\big(u - (W_{{\!\text{net}}}\rho(u) + W_{\text{in}}\overline{r}_{\text{in}}) \big)^{2} + \frac{\beta}{2}(u^{*} - u)^{2} \;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>The Euler-Lagrange equations <inline-formula><alternatives><mml:math id="inf1377"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1377">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\frac{\partial L}{\partial u}= 0$\end{document}</tex-math></alternatives></inline-formula> are derived from <inline-formula><alternatives><mml:math id="inf1378"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mspace width="0.1667em"/></mml:mrow></mml:math><tex-math id="inft1378">\begin{document}$\frac{\partial L}{\partial u}= \bar e - \rho'(u) W_{{{\!\text{net}}}}\bar e - \beta \bar e^{*}\,$\end{document}</tex-math></alternatives></inline-formula>. Applying the look-ahead operator <inline-formula><alternatives><mml:math id="inf1379"><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1379">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="equ15">Equation 14</xref>), and abbreviating <inline-formula><alternatives><mml:math id="inf1380"><mml:mrow><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1380">\begin{document}$\bar \epsilon = \rho'(u) W_{{{\!\text{net}}}}\bar e$\end{document}</tex-math></alternatives></inline-formula>, the Euler-Lagrange equations deliver the voltage dynamics,<disp-formula id="equ75"><label>(66)</label><alternatives><mml:math id="m75"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msup><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t75">\begin{document}$$\displaystyle \begin{align}\tau \, \dot u = - u + W_{{\!\text{net}}}\big(\rho(u) + \tau \dot \rho(u) \big) + W_{\text{in}}r_{\text{in}}+ \epsilon + \beta e^{*} \;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>To simplify matters, we consider the nudging-free case, <inline-formula><alternatives><mml:math id="inf1381"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1381">\begin{document}$\beta=0$\end{document}</tex-math></alternatives></inline-formula>. This implies that <inline-formula><alternatives><mml:math id="inf1382"><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover><mml:mi>ϵ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1382">\begin{document}$\bar e = \bar \epsilon = 0$\end{document}</tex-math></alternatives></inline-formula>. With <inline-formula><alternatives><mml:math id="inf1383"><mml:mrow><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1383">\begin{document}$\dot \rho(u) = \rho'(u) \dot u$\end{document}</tex-math></alternatives></inline-formula>, we obtain the differential equation<disp-formula id="equ76"><label>(67)</label><alternatives><mml:math id="m76"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mspace width="0.1667em"/><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t76">\begin{document}$$\displaystyle \begin{align}\tau \, \left(1 - W_{{\!\text{net}}}\rho'(u) \right) \, \dot u = - u + W_{{\!\text{net}}}\rho(u) + W_{\text{in}}r_{\text{in}}\;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Abbreviating <inline-formula><alternatives><mml:math id="inf1384"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1384">\begin{document}$v = u - W_{{{\!\text{net}}}}\rho(u)$\end{document}</tex-math></alternatives></inline-formula> as ‘network voltage error,’ the above differential equation reads as<disp-formula id="equ77"><label>(68)</label><alternatives><mml:math id="m77"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t77">\begin{document}$$\displaystyle \begin{align}\tau \, \dot v = - v + W_{\text{in}}r_{\text{in}}\;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Integrating the effective voltage dynamics (<xref ref-type="disp-formula" rid="equ77">Equation 68</xref>), assuming initialization infinitely far in the past, is equal to <inline-formula><alternatives><mml:math id="inf1385"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1385">\begin{document}$v = W_{{\text{in}}}\overline{r}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>. This equation is equivalent to the Euler-Lagrange equation <inline-formula><alternatives><mml:math id="inf1386"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1386">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\frac{\partial L}{\partial u}= 0$\end{document}</tex-math></alternatives></inline-formula> being integrate, and because the solution of the Euler Lagrange equation is <inline-formula><alternatives><mml:math id="inf1387"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mspace width="0.1667em"/><mml:msup><mml:mi>𝒆</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft1387">\begin{document}$\frac{\partial L}{\partial u}= c \,{\boldsymbol e}^{-\frac{t-t_{0}}{\tau}}$\end{document}</tex-math></alternatives></inline-formula>, we have (using <inline-formula><alternatives><mml:math id="inf1388"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1388">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula>)<disp-formula id="equ78"><label>(69)</label><alternatives><mml:math id="m78"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t78">\begin{document}$$\displaystyle \begin{align}\frac{\partial L}{\partial u}= v - W_{\text{in}}\overline{r}_{\text{in}}= 0 \;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><sec sec-type="appendix" id="s13-1"><title>Voltage dynamics for a delta-function input</title><p>We next apply a delta-function in the input rate, say <inline-formula><alternatives><mml:math id="inf1389"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1389">\begin{document}$r_{in}(t) = \delta (t)$\end{document}</tex-math></alternatives></inline-formula> and consider the dynamics at the level of the voltage, <xref ref-type="disp-formula" rid="equ76">Equation 67</xref>. As in <xref ref-type="disp-formula" rid="equ75">Equation 66</xref>, Proposition 1.2 we introduce the ‘jump function’ (called <inline-formula><alternatives><mml:math id="inf1390"><mml:mrow><mml:mi>G</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1390">\begin{document}$G(y)$\end{document}</tex-math></alternatives></inline-formula> in the cited work)<disp-formula id="equ79"><label>(70)</label><alternatives><mml:math id="m79"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mo>∘</mml:mo></mml:msub><mml:mi>u</mml:mi></mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo fence="false" symmetric="true" minsize="1.8em" maxsize="1.8em">(</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo fence="false" symmetric="true" minsize="1.8em" maxsize="1.8em">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t79">\begin{document}$$\displaystyle \begin{align}J(u) = \tau \int^{u}_{u_\circ}\left(1 - W_{{\!\text{net}}}\rho'(y) \right) dy = \tau \Big(\big(u - W_{{\!\text{net}}}\rho(u) \big) - v_{\circ} \Big) = \tau (v - v_{\circ}) \;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>As in <xref ref-type="bibr" rid="bib67">Nedeljkov and Oberguggenberger, 2012</xref>, Proposition 1.2, we show that the voltage <inline-formula><alternatives><mml:math id="inf1391"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1391">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> makes a unique jump at the moment of the delta function that <inline-formula><alternatives><mml:math id="inf1392"><mml:mrow><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1392">\begin{document}$J(u)$\end{document}</tex-math></alternatives></inline-formula> is invertible around the jump.</p><p>We set <inline-formula><alternatives><mml:math id="inf1393"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1393">\begin{document}$v_{\circ}= u_{\circ}- W_{{{\!\text{net}}}}\rho(u_{\circ})$\end{document}</tex-math></alternatives></inline-formula>. Here, <inline-formula><alternatives><mml:math id="inf1394"><mml:msub><mml:mi>u</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub></mml:math><tex-math id="inft1394">\begin{document}$u_{\circ}$\end{document}</tex-math></alternatives></inline-formula> is some voltage before the jump, say <inline-formula><alternatives><mml:math id="inf1395"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mn>1</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1395">\begin{document}$u_{\circ}= u(-1)$\end{document}</tex-math></alternatives></inline-formula> evaluated at time <inline-formula><alternatives><mml:math id="inf1396"><mml:mrow><mml:mi>t</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>=</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="inft1396">\begin{document}$t \!=\! -1$\end{document}</tex-math></alternatives></inline-formula>, when the jump is at <inline-formula><alternatives><mml:math id="inf1397"><mml:mrow><mml:mi>t</mml:mi><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>=</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1397">\begin{document}$t \!=\! 0$\end{document}</tex-math></alternatives></inline-formula>. When <inline-formula><alternatives><mml:math id="inf1398"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1398">\begin{document}$u_{0}^{-}= u(-0)$\end{document}</tex-math></alternatives></inline-formula> is the voltage immediately before the jump, the voltage immediately after the jump is <inline-formula><alternatives><mml:math id="inf1399"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mo form="prefix" stretchy="false">+</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1399">\begin{document}$u_{0}^{+}= u(+0)$\end{document}</tex-math></alternatives></inline-formula> specified by<disp-formula id="equ80"><label>(71)</label><alternatives><mml:math id="m80"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t80">\begin{document}$$\displaystyle \begin{align}J(u_{0}^{+}) = J(u_{0}^{-}) + W_{\text{in}}\,. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>The reason is that the <inline-formula><alternatives><mml:math id="inf1400"><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1400">\begin{document}$W_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>-scaled delta-function triggers a step of size <inline-formula><alternatives><mml:math id="inf1401"><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1401">\begin{document}$W_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> when integrating over it as done in <xref ref-type="disp-formula" rid="equ79">Equation 70</xref>. The new value <inline-formula><alternatives><mml:math id="inf1402"><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup></mml:math><tex-math id="inft1402">\begin{document}$u_{0}^{+}$\end{document}</tex-math></alternatives></inline-formula> is unique if <inline-formula><alternatives><mml:math id="inf1403"><mml:mi>J</mml:mi></mml:math><tex-math id="inft1403">\begin{document}$J$\end{document}</tex-math></alternatives></inline-formula> is invertible, and looking at the defining integral in <xref ref-type="disp-formula" rid="equ79">Equation 70</xref>, this is the case if <inline-formula><alternatives><mml:math id="inf1404"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1404">\begin{document}$1 - W_{{{\!\text{net}}}}\rho '(u_{0}^{+}) \neq 0$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The jump in <inline-formula><alternatives><mml:math id="inf1405"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1405">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> translates into a jump in <inline-formula><alternatives><mml:math id="inf1406"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1406">\begin{document}$v = u - W_{{{\!\text{net}}}}\rho(u)$\end{document}</tex-math></alternatives></inline-formula> from <inline-formula><alternatives><mml:math id="inf1407"><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup></mml:math><tex-math id="inft1407">\begin{document}$v_{0}^{-}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf1408"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1408">\begin{document}$v_{0}^{+}= u_{0}^{+}- W_{{{\!\text{net}}}}\rho(u_{0}^{+})$\end{document}</tex-math></alternatives></inline-formula>. This endpoint can also be expressed as<disp-formula id="equ81"><label>(72)</label><alternatives><mml:math id="m81"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mi>τ</mml:mi></mml:mfrac><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t81">\begin{document}$$\displaystyle \begin{align}v_{0}^{+} = v_{0}^{-} + \frac{W_{{\text{in}}}}{\tau}\,. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>To check this, we assume without loss of generality that <inline-formula><alternatives><mml:math id="inf1409"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mo lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">∘</mml:mo></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1409">\begin{document}$v_{\circ}= u_{\circ}- W_{{{\!\text{net}}}}\rho(u_{\circ}) = 0$\end{document}</tex-math></alternatives></inline-formula>. Then <inline-formula><alternatives><mml:math id="inf1410"><mml:mrow><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:math><tex-math id="inft1410">\begin{document}$J(u) = \tau (u - W_{{{\!\text{net}}}}\rho(u)) = \tau v$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1411"><mml:mrow><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1411">\begin{document}$J(u_{0}^{+}) = J(u_{0}^{-}) + W_{{\text{in}}}= \tau v_{0}^{-}+ W_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> according to <xref ref-type="disp-formula" rid="equ80">Equation 71</xref>. Since also <inline-formula><alternatives><mml:math id="inf1412"><mml:mrow><mml:mi>J</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup></mml:mrow></mml:math><tex-math id="inft1412">\begin{document}$J(u_{0}^{+}) = \tau v_{0}^{+}$\end{document}</tex-math></alternatives></inline-formula>, we conclude that <inline-formula><alternatives><mml:math id="inf1413"><mml:mrow><mml:mi>τ</mml:mi><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">+</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1413">\begin{document}$\tau v_{0}^{+}= \tau v_{0}^{-}+ W_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>, as claimed above.</p><p>We finally show that even far away from the initialization, the stationarity condition <inline-formula><alternatives><mml:math id="inf1414"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1414">\begin{document}$\frac{\partial L}{\partial u}= 0$\end{document}</tex-math></alternatives></inline-formula> holds before and immediately after the jump. In fact, for <inline-formula><alternatives><mml:math id="inf1415"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1415">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula>, the evolution of the ‘network voltage error’ becomes<disp-formula id="equ82"><label>(73)</label><alternatives><mml:math id="m82"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2778em"/><mml:mtext> for </mml:mtext><mml:mspace width="0.2778em"/><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mspace width="1em"/><mml:mtext> and </mml:mtext><mml:mspace width="1em"/><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi>𝒆</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mspace width="0.2778em"/><mml:mtext> for </mml:mtext><mml:mspace width="0.2778em"/><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t82">\begin{document}$$\displaystyle \begin{align}v(t) = 0 \; \text{ for }\; t\leq 0\,, \quad \text{ and }\quad v(t) = \frac{W_{{\text{in}}}}{\tau}{\boldsymbol e}^{-\frac{t}{\tau}}\; \text{ for }\; t \gt 0 \;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, we used that <inline-formula><alternatives><mml:math id="inf1416"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1416">\begin{document}$v_{0}^{-}= 0$\end{document}</tex-math></alternatives></inline-formula> and according to <xref ref-type="disp-formula" rid="equ81">Equation 72</xref> the <inline-formula><alternatives><mml:math id="inf1417"><mml:mi>v</mml:mi></mml:math><tex-math id="inft1417">\begin{document}$v$\end{document}</tex-math></alternatives></inline-formula> jumps to <inline-formula><alternatives><mml:math id="inf1418"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mn>0</mml:mn><mml:mo lspace="0em" rspace="0em">−</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1418">\begin{document}$v_{0}^{-}= \frac{W_{{\text{in}}}}{\tau}$\end{document}</tex-math></alternatives></inline-formula>. Remember, that for initialization far in the past, <inline-formula><alternatives><mml:math id="inf1419"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1419">\begin{document}$\frac{\partial L}{\partial u}= 0$\end{document}</tex-math></alternatives></inline-formula> is equivalent to <inline-formula><alternatives><mml:math id="inf1420"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1420">\begin{document}$v = W_{{\text{in}}}\overline{r}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>, see <xref ref-type="disp-formula" rid="equ78">Equation 69</xref>. We, therefore, have to calculate the jump in <inline-formula><alternatives><mml:math id="inf1421"><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1421">\begin{document}$\overline{r}_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> induced by the delta-input. Since <inline-formula><alternatives><mml:math id="inf1422"><mml:mrow><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1422">\begin{document}$\overline{r}_{{\text{in}}}(t)$\end{document}</tex-math></alternatives></inline-formula> is the solution of <inline-formula><alternatives><mml:math id="inf1423"><mml:mrow><mml:mi>τ</mml:mi><mml:msub><mml:mover><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1423">\begin{document}$\tau \dot{ \overline{r}}_{{\text{in}}}(t) = - \overline{r}_{{\text{in}}}(t) + \delta (t)$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf1424"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1424">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula>, we find that<disp-formula id="equ83"><label>(74)</label><alternatives><mml:math id="m83"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2778em"/><mml:mtext> for </mml:mtext><mml:mspace width="0.2778em"/><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mspace width="1em"/><mml:mtext> and </mml:mtext><mml:mspace width="1em"/><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msup><mml:mi>𝒆</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup><mml:mspace width="0.2778em"/><mml:mtext> for </mml:mtext><mml:mspace width="0.2778em"/><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t83">\begin{document}$$\displaystyle \begin{align}\overline{r}_{\text{in}}(t) = 0 \; \text{ for }\; t\leq 0\,, \quad \text{ and }\quad \overline{r}_{\text{in}}(t) = \frac{1}{\tau}{\boldsymbol e}^{-\frac{t}{\tau}}\; \text{ for }\; t \gt 0 \;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Combing the two <xref ref-type="disp-formula" rid="equ82 equ83">Equations 73 and 74</xref> proves that <inline-formula><alternatives><mml:math id="inf1425"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1425">\begin{document}$\frac{\partial L}{\partial u}= v - W_{{\text{in}}}\overline{r}_{{\text{in}}}= 0$\end{document}</tex-math></alternatives></inline-formula> holds true any moment in time, provided the initialization is far in the past.</p><p>One may ask why the delta-kink is different from resetting <inline-formula><alternatives><mml:math id="inf1426"><mml:mi>v</mml:mi></mml:math><tex-math id="inft1426">\begin{document}$v$\end{document}</tex-math></alternatives></inline-formula> at a new initialization off from 0. The reason is that at <inline-formula><alternatives><mml:math id="inf1427"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1427">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula> there is a cause for the jump in <inline-formula><alternatives><mml:math id="inf1428"><mml:mrow><mml:mi>r</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1428">\begin{document}$r(0)$\end{document}</tex-math></alternatives></inline-formula>, while at <inline-formula><alternatives><mml:math id="inf1429"><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math><tex-math id="inft1429">\begin{document}$t_{0}$\end{document}</tex-math></alternatives></inline-formula> there is no cause in <inline-formula><alternatives><mml:math id="inf1430"><mml:mrow><mml:mi>r</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1430">\begin{document}$r(t_{0})$\end{document}</tex-math></alternatives></inline-formula>. In fact, there is no jump initially, just the start of <inline-formula><alternatives><mml:math id="inf1431"><mml:mi>v</mml:mi></mml:math><tex-math id="inft1431">\begin{document}$v$\end{document}</tex-math></alternatives></inline-formula> at some initial condition. Differently from the initialization at <inline-formula><alternatives><mml:math id="inf1432"><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math><tex-math id="inft1432">\begin{document}$t_{0}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf1433"><mml:mrow><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1433">\begin{document}$v(t_{0}) \gt 0$\end{document}</tex-math></alternatives></inline-formula> implies <inline-formula><alternatives><mml:math id="inf1434"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1434">\begin{document}$\frac{\partial L}{\partial u}(t) \gt 0$\end{document}</tex-math></alternatives></inline-formula> for finite <inline-formula><alternatives><mml:math id="inf1435"><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1435">\begin{document}$t-t_{0} \gt 0$\end{document}</tex-math></alternatives></inline-formula>, the jump of <inline-formula><alternatives><mml:math id="inf1436"><mml:mrow><mml:mi>v</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1436">\begin{document}$v(0)$\end{document}</tex-math></alternatives></inline-formula> at <inline-formula><alternatives><mml:math id="inf1437"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1437">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula> to a positive value does leave <inline-formula><alternatives><mml:math id="inf1438"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1438">\begin{document}$\frac{\partial L}{\partial u}(t) = 0$\end{document}</tex-math></alternatives></inline-formula> for all <inline-formula><alternatives><mml:math id="inf1439"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1439">\begin{document}$t \gt 0$\end{document}</tex-math></alternatives></inline-formula>, provided <inline-formula><alternatives><mml:math id="inf1440"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1440">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec sec-type="appendix" id="s13-2"><title>Linear transfer function</title><p>We first consider the case of a linear transfer-function <inline-formula><alternatives><mml:math id="inf1441"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1441">\begin{document}$\rho(u) = 0$\end{document}</tex-math></alternatives></inline-formula> (or threshold linear, being in the linear regime). Then the differential equation becomes<disp-formula id="equ84"><label>(75)</label><alternatives><mml:math id="m84"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t84">\begin{document}$$\displaystyle \begin{align}\tau \,\dot u = - u + \frac{W_{{\text{in}}}}{ 1 - W_{{{\!\text{net}}}}}r_{\text{in}}\;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>With initialization at <inline-formula><alternatives><mml:math id="inf1442"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1442">\begin{document}$t = - \infty$\end{document}</tex-math></alternatives></inline-formula> and low-pass filtering <inline-formula><alternatives><mml:math id="inf1443"><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:mi>τ</mml:mi></mml:msubsup></mml:math><tex-math id="inft1443">\begin{document}$\overline{r}_{{\text{in}}}^{\tau}$\end{document}</tex-math></alternatives></inline-formula> defined in <xref ref-type="disp-formula" rid="equ16">Equation 15</xref> the solution is<disp-formula id="equ85"><label>(76)</label><alternatives><mml:math id="m85"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:mi>τ</mml:mi></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t85">\begin{document}$$\displaystyle \begin{align}u(t) = \tfrac{W_{\text{in}}}{ 1 - W_{{\!\text{net}}} }\overline{r}_{\text{in}}^{\tau} (t)\;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>The point is that the time constant is <inline-formula><alternatives><mml:math id="inf1444"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft1444">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> and is not <inline-formula><alternatives><mml:math id="inf1445"><mml:mfrac><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1445">\begin{document}$\frac{\tau}{1-W_{{{\!\text{net}}}}}$\end{document}</tex-math></alternatives></inline-formula>, as this would be the case without prospective firing rate. In fact, for the ‘classical’ differential equation,<disp-formula id="equ86"><label>(77)</label><alternatives><mml:math id="m86"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mspace width="0.2778em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t86">\begin{document}$$\displaystyle \begin{align}\tau \, \dot u = - u + W_{{\!\text{net}}}\rho(u) + W_{\text{in}}r_{\text{in}}\;, \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>and <inline-formula><alternatives><mml:math id="inf1446"><mml:mi>ρ</mml:mi></mml:math><tex-math id="inft1446">\begin{document}$\rho$\end{document}</tex-math></alternatives></inline-formula> the identity, we obtain the differential equation <inline-formula><alternatives><mml:math id="inf1447"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext/><mml:mi>eff</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.1667em"/><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1447">\begin{document}$\tau_{\mathrm{eff}}\,\dot u = - u + \frac{W_{{\text{in}}}}{ 1 - W_{{{\!\text{net}}}}}r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf1448"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext/><mml:mi>eff</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>τ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1448">\begin{document}$\tau_{\mathrm{eff}}= \frac{\tau}{1 - W_{{{\!\text{net}}}}}$\end{document}</tex-math></alternatives></inline-formula> and solution <inline-formula><alternatives><mml:math id="inf1449"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle><mml:msubsup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:mtext>in</mml:mtext><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext/><mml:mi>eff</mml:mi></mml:mrow></mml:msub></mml:msubsup></mml:mrow></mml:math><tex-math id="inft1449">\begin{document}$u = \tfrac{W_{\text{in}}}{ 1 - W_{{\!\text{net}}} }\overline{r}_{{\text{in}}}^{\tau_\mathrm{eff}}$\end{document}</tex-math></alternatives></inline-formula> that is now the low-pass filtering with respect to the effective time constant.</p></sec><sec sec-type="appendix" id="s13-3"><title>Sigmoidal transfer function</title><p>For a sigmoidal transfer function <inline-formula><alternatives><mml:math id="inf1450"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mtext/><mml:mi>max</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>𝒆</mml:mi><mml:mrow><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1450">\begin{document}$\rho(u) = \frac{\bar r_{\mathrm{max}}}{1 +{\boldsymbol e}^{\vartheta-u}}$\end{document}</tex-math></alternatives></inline-formula>, a positive feedback weight <inline-formula><alternatives><mml:math id="inf1451"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1451">\begin{document}$W_{{{\!\text{net}}}} \gt 0$\end{document}</tex-math></alternatives></inline-formula>, and a constant external input <inline-formula><alternatives><mml:math id="inf1452"><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub></mml:math><tex-math id="inft1452">\begin{document}$r_{{\text{in}}}$\end{document}</tex-math></alternatives></inline-formula>, say, the solutions <inline-formula><alternatives><mml:math id="inf1453"><mml:mrow><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1453">\begin{document}$u(t)$\end{document}</tex-math></alternatives></inline-formula> of <xref ref-type="disp-formula" rid="equ75">Equation 66</xref> either converge to a fixed point or diverge. When converging, the voltage satisfies the fixed point condition<disp-formula id="equ87"><label>(78)</label><alternatives><mml:math id="m87"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t87">\begin{document}$$\displaystyle \begin{align}u = W_{{\!\text{net}}}\rho(u) + W_{\text{in}}r_{\text{in}}\;. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>This fixed point equation can be numerically solved by time-discrete iteration process. But it can also be solved by a time-continuous process that underlies a neural or neuromorphic implementation. The prospective firing rate introduced in the NLA can be seen as a method to quickly find the fixed point in continuous time. When directly solving the implicit differential equation (as opposed to convert this into an explicit differential equation using e.g., the Cholesky decomposition), the fixed point is potentially found with a fewer number of steps.</p><p>To estimate the speed of convergence, we look at the initial speed when taking off at initial condition <inline-formula><alternatives><mml:math id="inf1454"><mml:mrow><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1454">\begin{document}$u(0)$\end{document}</tex-math></alternatives></inline-formula> between the unstable and stable fixed point. The initial speed for the classical differential equation, <xref ref-type="disp-formula" rid="equ86">Equation 77</xref>, and the NLA version, <xref ref-type="disp-formula" rid="equ75">Equation 66</xref>, are, respectively,<disp-formula id="equ88"><label>(79a)</label><alternatives><mml:math id="m88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t88">\begin{document}$$\displaystyle \dot u(0)= \frac{\Delta u(0)}{\tau}, $$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ89"><label>(79b)</label><alternatives><mml:math id="m89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t89">\begin{document}$$\displaystyle \dot u(0)= \frac{\Delta u(0)}{ \tau \, (1 - W_{{{\!\text{net}}}}\rho'(u(0))) },$$\end{document}</tex-math></alternatives></disp-formula></p><p>where we set <inline-formula><alternatives><mml:math id="inf1455"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1455">\begin{document}$\Delta u(0) = - u(0) + W_{{{\!\text{net}}}}\rho(u(0)) + W_{{\text{in}}}r_{{\text{in}}}(0)$\end{document}</tex-math></alternatives></inline-formula>. As <inline-formula><alternatives><mml:math id="inf1456"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1456">\begin{document}$W_{{{\!\text{net}}}}\rho' \gt 0$\end{document}</tex-math></alternatives></inline-formula>, the initial convergence speed of the NLA solution is larger. The scheme has some resemblance to the Newton algorithm of finding zero’s of a function by using its derivative.</p></sec></sec></app><app id="appendix-6"><title>Appendix 6</title><sec sec-type="appendix" id="s14"><title>NLA for conductance-based neurons and least-action principle in physics</title><p>The mismatch energies and costs can be generalized in different ways. Here, we focus on a biophysical version of the mismatch energy that includes conductance-based neurons. This also relates to the least-action principle in physics. But the NLA can also be generalized to include other dynamica variables such as adaptive thresholds or synaptic short-term plasticity.</p><sec sec-type="appendix" id="s14-1"><title>Equivalent somato-dentritic circuit</title><p>For conductance based synapses, the excitatory and inhibitory conductances, <inline-formula><alternatives><mml:math id="inf1457"><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1457">\begin{document}$g_{{\mathrm{E}}}$\end{document}</tex-math></alternatives></inline-formula> and gI, are driven by the presynaptic firing rates and have the form <inline-formula><alternatives><mml:math id="inf1458"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.1667em"/><mml:mi>r</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1458">\begin{document}$g_{{\mathrm{E}}}(t) = W_{{\mathrm{E}}}\, r(t)$\end{document}</tex-math></alternatives></inline-formula>, and analogously <inline-formula><alternatives><mml:math id="inf1459"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.1667em"/><mml:mi>r</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1459">\begin{document}$g_{{\mathrm{I}}}(t) = W_{{\mathrm{I}}}\, r(t)$\end{document}</tex-math></alternatives></inline-formula>. The dynamics of a somatic voltage <inline-formula><alternatives><mml:math id="inf1460"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1460">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> and a dendritic voltage <inline-formula><alternatives><mml:math id="inf1461"><mml:mi>v</mml:mi></mml:math><tex-math id="inft1461">\begin{document}$v$\end{document}</tex-math></alternatives></inline-formula> reads as<disp-formula id="equ90"><label>(80)</label><alternatives><mml:math id="m90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t90">\begin{document}$$\displaystyle c \, \dot u=g_{\mathrm{L}}(E_{\mathrm{L}}- u) + g_{{\mathrm{sd}}}(v - u),$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ91"><label>(81)</label><alternatives><mml:math id="m91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t91">\begin{document}$$\displaystyle c_{\mathrm{d}}\, \dot v=g_{\mathrm{L}}(E_{\mathrm{L}}- v) + g_{\mathrm{E}}(E_{\mathrm{E}}- v) + g_{\mathrm{I}}(E_{\mathrm{I}}- v)+ g_{{\mathrm{ds}}}(u -v)$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf1462"><mml:mi>c</mml:mi></mml:math><tex-math id="inft1462">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1463"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1463">\begin{document}$c_{\mathrm{d}}$\end{document}</tex-math></alternatives></inline-formula> are the somatic and dendritic capacitances, <inline-formula><alternatives><mml:math id="inf1464"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mi>/</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mi>/</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math><tex-math id="inft1464">\begin{document}$E_{{\mathrm{L}}/{\mathrm{E}}/{\mathrm{I}}}$\end{document}</tex-math></alternatives></inline-formula> the reversal potentials for the leak, the excitatory and inhibitory currents, <inline-formula><alternatives><mml:math id="inf1465"><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext/><mml:mi>sd</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1465">\begin{document}$g_{{{\mathrm{sd}}}}$\end{document}</tex-math></alternatives></inline-formula> the transfer conductance from the dendrite to the soma, and <inline-formula><alternatives><mml:math id="inf1466"><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext/><mml:mi>ds</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1466">\begin{document}$g_{{{\mathrm{ds}}}}$\end{document}</tex-math></alternatives></inline-formula> in the other direction.</p><p>We consider the case when the dendritic capacitance <inline-formula><alternatives><mml:math id="inf1467"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1467">\begin{document}$c_{\mathrm{d}}$\end{document}</tex-math></alternatives></inline-formula> is small as compared to the sum of conductances <inline-formula><alternatives><mml:math id="inf1468"><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1468">\begin{document}$g_{\mathrm{d}}$\end{document}</tex-math></alternatives></inline-formula> on the right-hand-side of <xref ref-type="disp-formula" rid="equ91">Equation 81</xref>, yielding a fast dendritic time constant. In this case we can solve this equation in the steady state for <inline-formula><alternatives><mml:math id="inf1469"><mml:mi>v</mml:mi></mml:math><tex-math id="inft1469">\begin{document}$v$\end{document}</tex-math></alternatives></inline-formula>, plug this into <xref ref-type="disp-formula" rid="equ90">Equation 80</xref>, and get<disp-formula id="equ92"><label>(82)</label><alternatives><mml:math id="m92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t92">\begin{document}$$\displaystyle c \, \dot u = g \, (V - u), $$\end{document}</tex-math></alternatives></disp-formula></p><p>with effective reversal potential <inline-formula><alternatives><mml:math id="inf1470"><mml:mrow><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext/><mml:mi>sd</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>g</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext/><mml:mi>ds</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>v</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>/</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:math><tex-math id="inft1470">\begin{document}$V = (g_{{\mathrm{L}}}E_{{\mathrm{L}}}+ g_{{{\mathrm{sd}}}}\frac{g_{\text{ff}}}{g_{\text{ff}}+ g_{{{\mathrm{ds}}}}}v_{\text{ff}}) / g$\end{document}</tex-math></alternatives></inline-formula>, total conductance <inline-formula><alternatives><mml:math id="inf1471"><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext/><mml:mi>sd</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi>g</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mtext/><mml:mi>ds</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1471">\begin{document}$g = g_{{\mathrm{L}}}+ g_{{{\mathrm{sd}}}}\frac{g_{\text{ff}}}{g_{\text{ff}}+ g_{{{\mathrm{ds}}}}}$\end{document}</tex-math></alternatives></inline-formula>, feedforward dendritic voltage <inline-formula><alternatives><mml:math id="inf1472"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>/</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mtext>ff</mml:mtext></mml:msub></mml:mrow></mml:math><tex-math id="inft1472">\begin{document}$v_{\text{ff}}= (g_{{\mathrm{L}}}E_{{\mathrm{L}}}+ g_{{\mathrm{E}}}E_{{\mathrm{E}}}+ g_{{\mathrm{I}}}E_{{\mathrm{I}}}) / g_{\text{ff}}$\end{document}</tex-math></alternatives></inline-formula> and feedforward dendritic conductance <inline-formula><alternatives><mml:math id="inf1473"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mtext>ff</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft1473">\begin{document}$g_{\text{ff}}= g_{{\mathrm{L}}}+ g_{{\mathrm{E}}}+ g_{{\mathrm{I}}}$\end{document}</tex-math></alternatives></inline-formula>. Because <inline-formula><alternatives><mml:math id="inf1474"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mi>/</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mi>/</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="0.1667em"/><mml:mi>r</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext/><mml:mi>pre</mml:mi></mml:mrow></mml:msub><mml:mo separator="true">,</mml:mo><mml:msub><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mrow><mml:mtext/><mml:mi>pre</mml:mi></mml:mrow></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1474">\begin{document}$g_{{\mathrm{E}}/{\mathrm{I}}}= W_{{\mathrm{E}}/{\mathrm{I}}}\, r(u_{\mathrm{pre}}, \dot u_{\mathrm{pre}})$\end{document}</tex-math></alternatives></inline-formula>, the conductance depends on the presynaptic voltage and its derivative. <xref ref-type="disp-formula" rid="equ92">Equation 82</xref> describes the effective circuit that has the identical voltage time course as <xref ref-type="disp-formula" rid="equ90 equ91">Equations 80 and 81</xref> with <inline-formula><alternatives><mml:math id="inf1475"><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1475">\begin{document}$\dot v=0$\end{document}</tex-math></alternatives></inline-formula>, but with a single time-dependent ‘battery voltage’ <inline-formula><alternatives><mml:math id="inf1476"><mml:mi>V</mml:mi></mml:math><tex-math id="inft1476">\begin{document}$V$\end{document}</tex-math></alternatives></inline-formula> and Ohmic resistance <inline-formula><alternatives><mml:math id="inf1477"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:math><tex-math id="inft1477">\begin{document}$R=1/g$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec sec-type="appendix" id="s14-2"><title>Somato-dentritic mismatch power and action</title><p>The synaptic inputs <inline-formula><alternatives><mml:math id="inf1478"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1478">\begin{document}$g_{{\mathrm{E}}}(t)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1479"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1479">\begin{document}$g_{{\mathrm{I}}}(t)$\end{document}</tex-math></alternatives></inline-formula> are continuously driving <inline-formula><alternatives><mml:math id="inf1480"><mml:mrow><mml:mi>V</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1480">\begin{document}$V(t)$\end{document}</tex-math></alternatives></inline-formula>, and the best what one can hope for the dynamics of <inline-formula><alternatives><mml:math id="inf1481"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1481">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> is that it traces <inline-formula><alternatives><mml:math id="inf1482"><mml:mi>V</mml:mi></mml:math><tex-math id="inft1482">\begin{document}$V$\end{document}</tex-math></alternatives></inline-formula> with some integration delay determined by the time constant <inline-formula><alternatives><mml:math id="inf1483"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>/</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:math><tex-math id="inft1483">\begin{document}$\tau = c/g$\end{document}</tex-math></alternatives></inline-formula>. In fact, if <inline-formula><alternatives><mml:math id="inf1484"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1484">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> follows the dynamics of <xref ref-type="disp-formula" rid="equ92">Equation 82</xref>, then <inline-formula><alternatives><mml:math id="inf1485"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1485">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> becomes the low-pass filtered target potential, <inline-formula><alternatives><mml:math id="inf1486"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft1486">\begin{document}$u=\overline V$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf1487"><mml:mrow><mml:mi>V</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1487">\begin{document}$V(t)$\end{document}</tex-math></alternatives></inline-formula> is filtered with the dynamic time constant <inline-formula><alternatives><mml:math id="inf1488"><mml:mrow><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1488">\begin{document}$\tau(t)$\end{document}</tex-math></alternatives></inline-formula>. The defining equations for the low-pass filtering is<disp-formula id="equ93"><label>(83)</label><alternatives><mml:math id="m93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t93">\begin{document}$$\displaystyle \bar u + \tau \dot{\bar u}= u, $$\end{document}</tex-math></alternatives></disp-formula></p><p>and this self-consistency equation is equivalent to the explicit form<disp-formula id="equ94"><label>(84)</label><alternatives><mml:math id="m94"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mtext/><mml:mi>dt</mml:mi></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mspace width="0.1667em"/><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:mfrac><mml:mspace width="0.1667em"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mi>t</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mtext/><mml:mi>dt</mml:mi></mml:mrow><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>τ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mspace width="0.2778em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t94">\begin{document}$$\displaystyle \bar u(t) = \int_{-\infty}^{t}{\mathrm{dt}}' \, \frac{u(t')}{\tau(t')}\, e^{- \int_{t'}^t {\mathrm{dt}}'' \frac{1}{\tau(t'')} }\;. $$\end{document}</tex-math></alternatives></disp-formula></p><p>To capture the voltage dynamics with our NLA principle we recall that the somatic voltage <inline-formula><alternatives><mml:math id="inf1489"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1489">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> can be nudged by an ‘apical voltage’ <inline-formula><alternatives><mml:math id="inf1490"><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft1490">\begin{document}$\bar e$\end{document}</tex-math></alternatives></inline-formula> that causes a somatic voltage error <inline-formula><alternatives><mml:math id="inf1491"><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft1491">\begin{document}$\bar e = u - \overline V$\end{document}</tex-math></alternatives></inline-formula>. The voltage error drives a current <inline-formula><alternatives><mml:math id="inf1492"><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1492">\begin{document}$I = g \bar e$\end{document}</tex-math></alternatives></inline-formula> through the conductance <inline-formula><alternatives><mml:math id="inf1493"><mml:mi>g</mml:mi></mml:math><tex-math id="inft1493">\begin{document}$g$\end{document}</tex-math></alternatives></inline-formula>. The electrical power of this current <inline-formula><alternatives><mml:math id="inf1494"><mml:mi>I</mml:mi></mml:math><tex-math id="inft1494">\begin{document}$I$\end{document}</tex-math></alternatives></inline-formula> driven by the voltage <inline-formula><alternatives><mml:math id="inf1495"><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft1495">\begin{document}$\bar e$\end{document}</tex-math></alternatives></inline-formula> is <inline-formula><alternatives><mml:math id="inf1496"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:msup><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft1496">\begin{document}$P=I \bar e^{2}$\end{document}</tex-math></alternatives></inline-formula>. This motivates the definition of the mismatch power in a network of <inline-formula><alternatives><mml:math id="inf1497"><mml:mi>N</mml:mi></mml:math><tex-math id="inft1497">\begin{document}$N$\end{document}</tex-math></alternatives></inline-formula> neurons by<disp-formula id="equ95"><label>(85)</label><alternatives><mml:math id="m95"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi><mml:mi>N</mml:mi></mml:munderover></mml:mrow><mml:mfrac><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mspace width="0.1667em"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mi>𝒈</mml:mi><mml:mtext>T</mml:mtext></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t95">\begin{document}$$\displaystyle  {\mathcal{P}}= \sum_{i}^{N}\frac{g_{i}}{2}\, (u_{i}- \overline V_{i})^{2}= \frac{1}{2}\boldsymbol g^{{\text{T}}}(\boldsymbol u - \overline{\boldsymbol V})^{2}\,. $$\end{document}</tex-math></alternatives></disp-formula></p><p><inline-formula><alternatives><mml:math id="inf1498"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><tex-math id="inft1498">\begin{document}${\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula> is a virtual power that, nevertheless, is related to some physical flow of ions. Assume we could measure all the ions flowing in the original circuit of <xref ref-type="disp-formula" rid="equ90 equ91">Equations 80 and 81</xref> (in the limit of small ratio <inline-formula><alternatives><mml:math id="inf1499"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mi>/</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft1499">\begin{document}$C_{\mathrm{d}}/g_{\mathrm{d}}$\end{document}</tex-math></alternatives></inline-formula>). From this flow, delete the ion flow that cancels at the level of electrical charge exchange due to the counter directed flow. The remaining effective ion flow defines an effective current flowing through the conductance <inline-formula><alternatives><mml:math id="inf1500"><mml:mi>g</mml:mi></mml:math><tex-math id="inft1500">\begin{document}$g$\end{document}</tex-math></alternatives></inline-formula> with driving force <inline-formula><alternatives><mml:math id="inf1501"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1501">\begin{document}$(V-u)$\end{document}</tex-math></alternatives></inline-formula>, <xref ref-type="disp-formula" rid="equ92">Equation 82</xref>. If it were only this effective current in the reduced circuit, the voltage <inline-formula><alternatives><mml:math id="inf1502"><mml:mrow><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1502">\begin{document}$u(t)$\end{document}</tex-math></alternatives></inline-formula>, starting at <inline-formula><alternatives><mml:math id="inf1503"><mml:mrow><mml:mi>u</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1503">\begin{document}$u(0)$\end{document}</tex-math></alternatives></inline-formula>, would converge with time-constant <inline-formula><alternatives><mml:math id="inf1504"><mml:mi>τ</mml:mi></mml:math><tex-math id="inft1504">\begin{document}$\tau$\end{document}</tex-math></alternatives></inline-formula> to the low-pass filtering <inline-formula><alternatives><mml:math id="inf1505"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:math><tex-math id="inft1505">\begin{document}$\overline V$\end{document}</tex-math></alternatives></inline-formula>. Without additional ‘hidden’ current, the voltage <inline-formula><alternatives><mml:math id="inf1506"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1506">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> would then instantaneously follow <inline-formula><alternatives><mml:math id="inf1507"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:math><tex-math id="inft1507">\begin{document}$\overline V$\end{document}</tex-math></alternatives></inline-formula> that is itself given by the forward dendritic input conductances. The deviation of <inline-formula><alternatives><mml:math id="inf1508"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1508">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> from <inline-formula><alternatives><mml:math id="inf1509"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:math><tex-math id="inft1509">\begin{document}$\overline V$\end{document}</tex-math></alternatives></inline-formula>, caused by some initial conditions in <inline-formula><alternatives><mml:math id="inf1510"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1510">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> or by a feedback current from the network affecting <inline-formula><alternatives><mml:math id="inf1511"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1511">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>, builds the mismatch power <inline-formula><alternatives><mml:math id="inf1512"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><tex-math id="inft1512">\begin{document}${\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula>. The feedback may originate from a target imposed downstream, and the neuron is ‘free’ in how to dynamically match <inline-formula><alternatives><mml:math id="inf1513"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1513">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1514"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:math><tex-math id="inft1514">\begin{document}$\overline V$\end{document}</tex-math></alternatives></inline-formula>. It is, therefore, tempting to see <inline-formula><alternatives><mml:math id="inf1515"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><tex-math id="inft1515">\begin{document}${\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula> as a ‘free power’, and the NLA principle as minimizing the corresponding ‘free energy’. In fact, the free-energy principle says that any self-organizing system that is in a dynamic equilibrium with its environment (here <inline-formula><alternatives><mml:math id="inf1516"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft1516">\begin{document}$u=\overline V$\end{document}</tex-math></alternatives></inline-formula> in the absence of output nudging) must minimize its free energy (that here builds up by imposing a target; <xref ref-type="bibr" rid="bib34">Friston, 2010</xref>).</p><p>The NLA principle states that the time-integral of <inline-formula><alternatives><mml:math id="inf1517"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><tex-math id="inft1517">\begin{document}${\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula> is minimized with respect to the look-ahead voltage <inline-formula><alternatives><mml:math id="inf1518"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft1518">\begin{document}$\tilde u$\end{document}</tex-math></alternatives></inline-formula>. We, therefore, define the physical mismatch energy as<disp-formula id="equ96"><label>(86)</label><alternatives><mml:math id="m96"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mo movablelimits="false">∫</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msubsup><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi><mml:mspace width="0.1667em"/><mml:mrow><mml:mtext/><mml:mi>dt</mml:mi></mml:mrow><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t96">\begin{document}$$\displaystyle A = \int_{t_1}^{t_2}\!{\mathcal{P}}\,{\mathrm{dt}}\,, $$\end{document}</tex-math></alternatives></disp-formula></p><p>that has the units of energy. <inline-formula><alternatives><mml:math id="inf1519"><mml:msub><mml:mi class="MJX-tex-caligraphic" mathvariant="script">E</mml:mi><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1519">\begin{document}${\cal E}_{{\mathrm{M}}}$\end{document}</tex-math></alternatives></inline-formula> takes the role of our neural action (<inline-formula><alternatives><mml:math id="inf1520"><mml:mi>A</mml:mi></mml:math><tex-math id="inft1520">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> in the main text) for conductance-based neurons.</p></sec><sec sec-type="appendix" id="s14-3"><title>Euler-Lagrange equations for conductance-based neurons</title><p>The NLA for conductance-based neurons seeks to minimize <inline-formula><alternatives><mml:math id="inf1521"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo movablelimits="false">∫</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mrow><mml:mtext/><mml:mi>dt</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft1521">\begin{document}$A = \int{\mathcal{P}}(\boldsymbol u) \,{\mathrm{dt}}$\end{document}</tex-math></alternatives></inline-formula> with respect to variations of <inline-formula><alternatives><mml:math id="inf1522"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1522">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, such that <inline-formula><alternatives><mml:math id="inf1523"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1523">\begin{document}$\frac{\delta A}{\delta \boldsymbol u}=0$\end{document}</tex-math></alternatives></inline-formula>. In the simplest example of the main text we considered prospective rates, <inline-formula><alternatives><mml:math id="inf1524"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>ρ</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1524">\begin{document}$\boldsymbol r = \rho(\boldsymbol u) + \tau \dot \rho(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>, so that the low-pass filtered rates become a function of the instantaneous voltage, <inline-formula><alternatives><mml:math id="inf1525"><mml:mrow><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1525">\begin{document}${\bar{\boldsymbol{ r }}}= \rho(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>. These low-pass filtered presynaptic rates, <inline-formula><alternatives><mml:math id="inf1526"><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft1526">\begin{document}${\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula>, determine the postsynaptic voltage <inline-formula><alternatives><mml:math id="inf1527"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1527">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>. Analogously, the low-pass filtered reversal potential, <inline-formula><alternatives><mml:math id="inf1528"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow></mml:math><tex-math id="inft1528">\begin{document}$\overline{\boldsymbol V}$\end{document}</tex-math></alternatives></inline-formula>, determines the postsynaptic voltage <inline-formula><alternatives><mml:math id="inf1529"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1529">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula>, and we again postulate that <inline-formula><alternatives><mml:math id="inf1530"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow></mml:math><tex-math id="inft1530">\begin{document}$\overline{\boldsymbol V}$\end{document}</tex-math></alternatives></inline-formula> is an instantaneous function of the presynaptic voltage, <inline-formula><alternatives><mml:math id="inf1531"><mml:mrow><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi>ϕ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1531">\begin{document}$\overline{\boldsymbol V}= \phi(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula>. Here, we argue that active dendritic mechanisms advance to postsynaptic reversal potential <inline-formula><alternatives><mml:math id="inf1532"><mml:mi>V</mml:mi></mml:math><tex-math id="inft1532">\begin{document}$V$\end{document}</tex-math></alternatives></inline-formula>, so that the delayed <inline-formula><alternatives><mml:math id="inf1533"><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow></mml:math><tex-math id="inft1533">\begin{document}$\overline V$\end{document}</tex-math></alternatives></inline-formula> again becomes instantaneous, similarly to the advancement of the apical dendritic potential observed in cortical pyramidal neurons (<xref ref-type="bibr" rid="bib96">Ulrich, 2002</xref>), see also <xref ref-type="fig" rid="fig2">Figure 2b</xref>. With this instantaneity, the stationarity of the action with respect to generalized (compact and non-compact) variations, <inline-formula><alternatives><mml:math id="inf1534"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1534">\begin{document}$\frac{\delta A}{\delta \boldsymbol u}=0$\end{document}</tex-math></alternatives></inline-formula>, translates to the condition <inline-formula><alternatives><mml:math id="inf1535"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1535">\begin{document}$\frac{ \partial {\mathcal{P}}}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Calculating <inline-formula><alternatives><mml:math id="inf1536"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1536">\begin{document}$\frac{ \partial {\mathcal{P}}}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf1537"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><tex-math id="inft1537">\begin{document}${\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula> given in <xref ref-type="disp-formula" rid="equ95">Equation 85</xref> and <inline-formula><alternatives><mml:math id="inf1538"><mml:mrow><mml:mi>𝝉</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>/</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow></mml:math><tex-math id="inft1538">\begin{document}$\boldsymbol \tau = c/\boldsymbol g$\end{document}</tex-math></alternatives></inline-formula> for the total conductance <inline-formula><alternatives><mml:math id="inf1539"><mml:mrow><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1539">\begin{document}$\boldsymbol g (\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> specified after <xref ref-type="disp-formula" rid="equ92">Equation 82</xref> is a bit more demanding. For a probabilistic version, where <inline-formula><alternatives><mml:math id="inf1540"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><tex-math id="inft1540">\begin{document}${\mathcal{P}}$\end{document}</tex-math></alternatives></inline-formula> is derived from the negative log-likelihood of a Gaussian density of the voltage, <inline-formula><alternatives><mml:math id="inf1541"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/></mml:mrow><mml:mi>p</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mi>|</mml:mi><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mi>𝒈</mml:mi><mml:mtext>T</mml:mtext></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/></mml:mrow><mml:mi>𝒈</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mtext/><mml:mi>const</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft1541">\begin{document}${\mathcal{P}}= -\log p(\boldsymbol u | \overline{\boldsymbol V}) = \frac{1}{2}\boldsymbol g^{{\text{T}}}(\boldsymbol u - \overline{\boldsymbol V})^{2}- \tfrac{1}{2}\log \boldsymbol g + \mathrm{const}$\end{document}</tex-math></alternatives></inline-formula>, the calculation is done in <xref ref-type="bibr" rid="bib45">Jordan et al., 2022</xref>. In this probabilistic version, there is an additional normalization term that enters as <inline-formula><alternatives><mml:math id="inf1542"><mml:mrow><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/></mml:mrow><mml:mi>𝒈</mml:mi></mml:mrow></mml:math><tex-math id="inft1542">\begin{document}$\log \boldsymbol g$\end{document}</tex-math></alternatives></inline-formula>. In the deterministic version considered here, this log term is not present and we calculate<disp-formula id="equ97"><label>(87)</label><alternatives><mml:math id="m97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>−</mml:mo><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mspace width="1em"/><mml:mtext>with </mml:mtext><mml:mspace width="thickmathspace"/><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mtext>net</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>−</mml:mo><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>−</mml:mo><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t97">\begin{document}$$\displaystyle \frac{ \partial {\mathcal{P}}}{\partial \boldsymbol u}= \boldsymbol g{\cdot}\left(\boldsymbol u - \overline{\boldsymbol V}\right) -{\bar{\boldsymbol{ \epsilon }}}\quad \text{with }\;{\bar{\boldsymbol{ \epsilon }}}={\bar{\boldsymbol{ r }}}' \cdot \boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}\left((\boldsymbol u - \overline{\boldsymbol V}){\!\cdot\!}(E^{\mathrm{E/I}}- \overline{\boldsymbol V}) - \tfrac{1}{2}(\boldsymbol u - \overline{\boldsymbol V})^{2}\right). $$\end{document}</tex-math></alternatives></disp-formula></p><p>Notice that the transpose <inline-formula><alternatives><mml:math id="inf1543"><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup></mml:math><tex-math id="inft1543">\begin{document}$\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> selects the downstream network neuron to backpropagate from there the first- and second-order errors. From <inline-formula><alternatives><mml:math id="inf1544"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1544">\begin{document}$\frac{ \partial {\mathcal{P}}}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1545"><mml:mrow><mml:mi>𝝉</mml:mi><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>/</mml:mi><mml:mi>𝒈</mml:mi></mml:mrow></mml:math><tex-math id="inft1545">\begin{document}$\boldsymbol \tau = c/\boldsymbol g$\end{document}</tex-math></alternatives></inline-formula> we conclude that<disp-formula id="equ98"><label>(88)</label><alternatives><mml:math id="m98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mi>c</mml:mi><mml:mi mathvariant="bold-italic">τ</mml:mi></mml:mfrac><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>−</mml:mo><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="1em"/><mml:mtext> or </mml:mtext><mml:mspace width="1em"/><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mi>c</mml:mi></mml:mfrac></mml:mstyle><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t98">\begin{document}$$\displaystyle \frac{c}{\boldsymbol \tau}{\!\cdot\!}\left(\boldsymbol u - \overline{\boldsymbol V}\right) -{\bar{\boldsymbol{ \epsilon }}}= 0 \quad \text{ or }\quad \boldsymbol u = \overline{\boldsymbol V}+ \tfrac{\boldsymbol \tau}{c}{\!\cdot\!}{\bar{\boldsymbol{ \epsilon }}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>We next apply the look ahead operator to the expression in this <xref ref-type="disp-formula" rid="equ98">Equation 88</xref>. Assuming an initialization at <inline-formula><alternatives><mml:math id="inf1546"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math><tex-math id="inft1546">\begin{document}$t_{0}=-\infty$\end{document}</tex-math></alternatives></inline-formula>, the condition <inline-formula><alternatives><mml:math id="inf1547"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1547">\begin{document}$\frac{ \partial {\mathcal{P}}}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula> becomes equivalent to <inline-formula><alternatives><mml:math id="inf1548"><mml:mrow><mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1548">\begin{document}${\big(1 + \tau \tfrac{{\text{d}}}{{\text{d}} t} \big)}\frac{ \partial {\mathcal{P}}}{\partial \boldsymbol u}= 0$\end{document}</tex-math></alternatives></inline-formula>, and hence <xref ref-type="disp-formula" rid="equ98">Equation 88</xref> becomes equivalent to<inline-formula><alternatives><mml:math id="inf1549"><mml:mrow><mml:mi>𝒈</mml:mi><mml:mspace width="0.1667em"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mspace width="0.1667em"/><mml:mi>𝒈</mml:mi><mml:mspace width="0.1667em"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒈</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mspace width="0.1667em"/><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>𝒈</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑽</mml:mi><mml:mo>−</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>𝝐</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mi>𝒈</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mspace width="0.1667em"/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>𝑽</mml:mi></mml:mrow><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1549">\begin{document}$\boldsymbol g \,(\boldsymbol u - \overline{\boldsymbol V}) -{\bar{\boldsymbol{ \epsilon }}}+ \tau \, \boldsymbol g \, (\dot{\boldsymbol u}- \dot{ \overline{\boldsymbol V}}) - \tau \dot{{\bar{\boldsymbol{ \epsilon }}}}+ \tau \dot{\boldsymbol g}\, (\boldsymbol u - \overline{\boldsymbol V}) = c \, \dot{\boldsymbol u}- \boldsymbol g{\!\cdot\!}(\boldsymbol V - \boldsymbol u) - \boldsymbol \epsilon + \tau \dot{\boldsymbol g}\, (\boldsymbol u - \overline{\boldsymbol V}) = 0$\end{document}</tex-math></alternatives></inline-formula>, and with the total conductance <inline-formula><alternatives><mml:math id="inf1550"><mml:mrow><mml:mi>𝒈</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1550">\begin{document}$\boldsymbol g(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> specified after <xref ref-type="disp-formula" rid="equ92">Equation 82</xref> this is calculated to become (see <xref ref-type="bibr" rid="bib45">Jordan et al., 2022</xref>).<disp-formula id="equ99"><label>(89)</label><alternatives><mml:math id="m99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">τ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mspace width="negativethinmathspace"/><mml:mo>⋅</mml:mo><mml:mspace width="negativethinmathspace"/></mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t99">\begin{document}$$\displaystyle c \, \dot{\boldsymbol u}= \boldsymbol g{\!\cdot\!}(\boldsymbol V - \boldsymbol u) + \boldsymbol \epsilon + \dot{\boldsymbol \tau}{\!\cdot\!}{\bar{\boldsymbol{ \epsilon }}}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>A learning rule of the form <inline-formula><alternatives><mml:math id="inf1551"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>∝</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1551">\begin{document}$\dot{\boldsymbol W}\propto \frac{\partial {\mathcal{P}}}{\partial \boldsymbol W}={\bar{\boldsymbol{e}}}_{\mathrm{post}}\,{\bar{\boldsymbol{r}}}^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> with an appropriate postsynaptic error <inline-formula><alternatives><mml:math id="inf1552"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1552">\begin{document}${\bar{\boldsymbol{e}}}_{\mathrm{post}}$\end{document}</tex-math></alternatives></inline-formula> can again be derived (see <xref ref-type="bibr" rid="bib45">Jordan et al., 2022</xref>) for a single neuron in the probabilistic framework.</p></sec><sec sec-type="appendix" id="s14-4"><title>Generalizations: Long memories, reinforcement learning</title><p>One could also extend the NLA principle by adding e.g., threshold adaptation that endows the dynamics with additional and longer time constants. For this, the rate function is parametrized by an additional threshold, <inline-formula><alternatives><mml:math id="inf1553"><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>ϑ</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1553">\begin{document}$\bar r = \rho(u - \vartheta)$\end{document}</tex-math></alternatives></inline-formula>, an the Lagrangian is added by an error term on the threshold. Such an error addition can take the form <inline-formula><alternatives><mml:math id="inf1554"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>‖</mml:mi><mml:mi>ϑ</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>ϑ</mml:mi></mml:msub></mml:msup><mml:msup><mml:mi>‖</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft1554">\begin{document}$L = ...+ \frac{1}{2}\| \vartheta - \overline r^{\tau_\vartheta}\|^{2}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf1555"><mml:msup><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>r</mml:mi></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>ϑ</mml:mi></mml:msub></mml:msup></mml:math><tex-math id="inft1555">\begin{document}$\overline r^{\tau_\vartheta}$\end{document}</tex-math></alternatives></inline-formula> now represents a low-pass filtering of the rate with a long threshold adaptation time constant <inline-formula><alternatives><mml:math id="inf1556"><mml:msub><mml:mi>τ</mml:mi><mml:mi>ϑ</mml:mi></mml:msub></mml:math><tex-math id="inft1556">\begin{document}$\tau_{\vartheta}$\end{document}</tex-math></alternatives></inline-formula>. Neurons that show an additional threshold adaptation will still be able to instantaneously transmit a voltage jump through a prospective firing rate, but this will now also depend on the neuron’s history. Short-term plasticity may be included in the same way. Due to the history dependence, the stationarity of the action <inline-formula><alternatives><mml:math id="inf1557"><mml:mrow><mml:mi>δ</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1557">\begin{document}$\delta A = 0$\end{document}</tex-math></alternatives></inline-formula> cannot anymore be reduced to the stationarity of the Lagrangian at any moment in time. As a consequence, the errors will look-ahead into to future more than only based on the local derivatives.</p><p>Generalizations are further possible for the cost function that favor voltage regions with high cost, say corresponding to punishment, or negative cost, corresponding to punishment to reward. These extensions will be considered in future work.</p></sec><sec sec-type="appendix" id="s14-5"><title>Voltage dynamics from the least-action principle in physics</title><p>We have shown that through the look-ahead in Hamilton’s least-action principle, the notion of friction enters through the backdoor. In the least-action formalism in physics, friction is directly introduced by extending the Hamiltonian principle to a generalized D’Alembert principle, where at the level of the Euler-Lagrange equations the generalized force is equated to the dissipation force (<xref ref-type="bibr" rid="bib30">Flannery, 2005</xref>). For an introduction to the least-action principle in physics see e.g., (<xref ref-type="bibr" rid="bib29">Feynman et al., 2011</xref>), and for an introduction to the calculus of variation in general with a derivation of the Euler-Lagrange equation see e.g., (<xref ref-type="bibr" rid="bib17">Chachuat, 2007</xref>).</p><p>The electro-chemical properties of a membrane can be captured by an equivalent circuit consisting of a battery voltage <inline-formula><alternatives><mml:math id="inf1558"><mml:mi>V</mml:mi></mml:math><tex-math id="inft1558">\begin{document}$V$\end{document}</tex-math></alternatives></inline-formula>, a capacitance <inline-formula><alternatives><mml:math id="inf1559"><mml:mi>C</mml:mi></mml:math><tex-math id="inft1559">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> and a resistance <inline-formula><alternatives><mml:math id="inf1560"><mml:mi>R</mml:mi></mml:math><tex-math id="inft1560">\begin{document}$R$\end{document}</tex-math></alternatives></inline-formula>, arranged in parallel. The voltage dynamics is derived from the Euler-Lagrange equations that are added by a dissipative force.</p><p>Formally, in the absence of an inductance defining the kinetic energy, the Lagrangian <inline-formula><alternatives><mml:math id="inf1561"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:math><tex-math id="inft1561">\begin{document}${\mathcal{L}}$\end{document}</tex-math></alternatives></inline-formula> becomes identical to the potential energy <inline-formula><alternatives><mml:math id="inf1562"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">U</mml:mi></mml:math><tex-math id="inft1562">\begin{document}${\mathcal{U}}$\end{document}</tex-math></alternatives></inline-formula> that itself is<disp-formula id="equ100"><label>(90)</label><alternatives><mml:math id="m100"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">U</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-left" style="padding:0.7ex 0em 0.7ex 0em;"><mml:mrow><mml:mi>Q</mml:mi><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>Q</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>/</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>C</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t100">\begin{document}$$\displaystyle \begin{align}{\mathcal{L}}={\mathcal{U}}=&amp;Q V - Q^{2}/ (2C) \,, \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf1563"><mml:mi>Q</mml:mi></mml:math><tex-math id="inft1563">\begin{document}$Q$\end{document}</tex-math></alternatives></inline-formula> represents the charge across the membrane. Looking for stationary trajectory of the action (time integral of the Lagrangian) with only the potential energy in the Lagrangian would not give any dynamics. In fact, the Euler-Lagrange equation <inline-formula><alternatives><mml:math id="inf1564"><mml:mrow><mml:msub><mml:mi>∂</mml:mi><mml:mi>Q</mml:mi></mml:msub><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>∂</mml:mi><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:msub><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1564">\begin{document}$\partial_{Q}{\mathcal{L}}- d_{t}\partial_{\dot Q}{\mathcal{L}}= 0$\end{document}</tex-math></alternatives></inline-formula> yields <inline-formula><alternatives><mml:math id="inf1565"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mspace width="0.1667em"/><mml:mi>V</mml:mi></mml:mrow></mml:math><tex-math id="inft1565">\begin{document}$Q = C\, V$\end{document}</tex-math></alternatives></inline-formula>. The potential energy is, therefore, extended by the dissipative Rayleigh energy <inline-formula><alternatives><mml:math id="inf1566"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">F</mml:mi></mml:math><tex-math id="inft1566">\begin{document}${\mathcal{F}}$\end{document}</tex-math></alternatives></inline-formula> that introduces friction,<disp-formula id="equ101"><label>(91)</label><alternatives><mml:math id="m101"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 0em;width:50%;"/><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">F</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd class="tml-left" style="padding:0.7ex 0em 0.7ex 0em;"><mml:mrow><mml:mtext/><mml:mi>R</mml:mi><mml:msup><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mi>/</mml:mi><mml:mn>2</mml:mn><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.7ex 0em 0.7ex 1em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t101">\begin{document}$$\displaystyle \begin{align}{\mathcal{F}}=&amp;\ R \dot Q^{2}/ 2 \,. \end{align}$$\end{document}</tex-math></alternatives></disp-formula></p><p>According to D’Alembert’s principle, the Rayleigh energy enters as a gradient at the level of the Euler-Lagrange equation. At this point, the theory steps out from the original principle by adding the Rayleigh gradient ‘by hand’ to the Euler-Lagrange equation (different from the NLA, see below). Otherwise, no first order differential equation with friction in the desired form would be obtained from the least-action principle in physics (if we were adding <inline-formula><alternatives><mml:math id="inf1567"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">F</mml:mi></mml:math><tex-math id="inft1567">\begin{document}${\mathcal{F}}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf1568"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:math><tex-math id="inft1568">\begin{document}${\mathcal{L}}$\end{document}</tex-math></alternatives></inline-formula>, for instance, the <inline-formula><alternatives><mml:math id="inf1569"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>∂</mml:mi><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:msub><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow></mml:math><tex-math id="inft1569">\begin{document}$d_{t}\partial_{\dot Q}{\mathcal{L}}$\end{document}</tex-math></alternatives></inline-formula>-term in the Euler-Lagrange equations would yield the term <inline-formula><alternatives><mml:math id="inf1570"><mml:mrow><mml:mi>R</mml:mi><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">¨</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1570">\begin{document}$R\ddot Q$\end{document}</tex-math></alternatives></inline-formula> instead of <inline-formula><alternatives><mml:math id="inf1571"><mml:mrow><mml:mi>R</mml:mi><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1571">\begin{document}$R\dot Q$\end{document}</tex-math></alternatives></inline-formula>). Hence, with D’Alembert’s patch the dynamics is characterized by the Euler-Lagrange equation added by a dissipative force,<disp-formula id="equ102"><alternatives><mml:math id="m102"><mml:mrow><mml:msub><mml:mi>∂</mml:mi><mml:mi>Q</mml:mi></mml:msub><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>∂</mml:mi><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:msub><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>∂</mml:mi><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:msub><mml:mi class="MJX-tex-caligraphic" mathvariant="script">F</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.2778em"/><mml:mo separator="true">,</mml:mo></mml:mrow></mml:math><tex-math id="t102">\begin{document}$$\displaystyle \partial_{Q}{\mathcal{L}}- d_{t}\partial_{\dot Q}{\mathcal{L}}+ \partial_{\dot Q}{\mathcal{F}}= 0 \;,$$\end{document}</tex-math></alternatives></disp-formula></p><p>and this equation reduces to <inline-formula><alternatives><mml:math id="inf1572"><mml:mrow><mml:mo>−</mml:mo><mml:mi>V</mml:mi><mml:mo>+</mml:mo><mml:mi>Q</mml:mi><mml:mi>/</mml:mi><mml:mi>C</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false" class="tml-capshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1572">\begin{document}$-V + Q/C + R \dot Q = 0$\end{document}</tex-math></alternatives></inline-formula>. Identifying the charge by means of voltage across the capacitance, <inline-formula><alternatives><mml:math id="inf1573"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:math><tex-math id="inft1573">\begin{document}$Q = Cu$\end{document}</tex-math></alternatives></inline-formula>, this equation can also be written as <inline-formula><alternatives><mml:math id="inf1574"><mml:mrow><mml:mo>−</mml:mo><mml:mi>V</mml:mi><mml:mo>+</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>C</mml:mi><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1574">\begin{document}$-V + u + R C \dot u = 0$\end{document}</tex-math></alternatives></inline-formula>, or<disp-formula id="equ103"><label>(92)</label><alternatives><mml:math id="m103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t103">\begin{document}$$\displaystyle \tau \dot u = - u + V, $$\end{document}</tex-math></alternatives></disp-formula></p><p>with <inline-formula><alternatives><mml:math id="inf1575"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft1575">\begin{document}$\tau = R C$\end{document}</tex-math></alternatives></inline-formula>, similarly as derived in <xref ref-type="disp-formula" rid="equ99">Equation 89</xref>.</p><p>The link to our NLA principle is most easily made by assuming that the ‘membrane’ conductance <inline-formula><alternatives><mml:math id="inf1576"><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi>/</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:math><tex-math id="inft1576">\begin{document}$g=1/R$\end{document}</tex-math></alternatives></inline-formula> does not depend on the voltage <inline-formula><alternatives><mml:math id="inf1577"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1577">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> (of the post- or presynaptic neuron, as this is the case in general, see explanation after <xref ref-type="disp-formula" rid="equ92">Equation 82</xref>). In this simplified case, the Lagrangian from <xref ref-type="disp-formula" rid="equ96">Equation 86</xref> becomes the power<disp-formula id="equ104"><label>(93)</label><alternatives><mml:math id="m104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mover><mml:mi>V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t104">\begin{document}$$\displaystyle {\mathcal{P}}= (u - \overline V)^{2}/ (2R). $$\end{document}</tex-math></alternatives></disp-formula></p><p>The Euler-Lagrange equation with respect to <inline-formula><alternatives><mml:math id="inf1578"><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft1578">\begin{document}$\tilde u$\end{document}</tex-math></alternatives></inline-formula>, applied to the action <inline-formula><alternatives><mml:math id="inf1579"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo movablelimits="false">∫</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi><mml:mspace width="0.1667em"/><mml:mrow><mml:mtext/><mml:mi>dt</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft1579">\begin{document}$A = \int \!{\mathcal{P}}\,{\mathrm{dt}}$\end{document}</tex-math></alternatives></inline-formula> is then calculated by<disp-formula id="equ105"><label>(94)</label><alternatives><mml:math id="m105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">P</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>R</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mover><mml:mi>V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mover><mml:mover><mml:mi>V</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>or</mml:mtext></mml:mrow></mml:mstyle></mml:math><tex-math id="t105">\begin{document}$$\displaystyle \frac{\partial {\mathcal{P}}}{\partial \tilde u}- \frac{{\mathrm{d}}}{{\mathrm{d}} t}\frac{\partial {\mathcal{P}}}{\partial \dot{\tilde u}}= \left(1 + \tau \frac{{\mathrm{d}}}{{\mathrm{d}} t}\right) \frac{\partial {\mathcal{P}}}{\partial u}= \frac{1}{R}\big(u + \tau \, \dot u - (\overline V + \tau \, \dot{\overline V}) \big) = 0,\text{or}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ106"><label>(95)</label><alternatives><mml:math id="m106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>τ</mml:mi><mml:mrow><mml:mover><mml:mi>u</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t106">\begin{document}$$\displaystyle \tau \dot u= - u + V.$$\end{document}</tex-math></alternatives></disp-formula></p><p>We used that <inline-formula><alternatives><mml:math id="inf1580"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:math><tex-math id="inft1580">\begin{document}$\tau = RC$\end{document}</tex-math></alternatives></inline-formula> while <inline-formula><alternatives><mml:math id="inf1581"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>u</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1581">\begin{document}$u = \tilde u - \tau \dot{\tilde u}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1582"><mml:mrow><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mrow style="padding:0.1em 0 0 0;border-top:0.065em solid;"><mml:mi>V</mml:mi></mml:mrow><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1582">\begin{document}$V = \overline V + \tau \dot{\overline V}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The dynamics derived from the NLA <xref ref-type="disp-formula" rid="equ106">Equation 95</xref> is identical to the dynamics derived from the least-action principle with friction in physics (<xref ref-type="disp-formula" rid="equ103">Equation 92</xref>). Hence, the minimization of the energy (i.e. the time-integral of the power, <inline-formula><alternatives><mml:math id="inf1583"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo movablelimits="false">∫</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi><mml:mspace width="0.1667em"/><mml:mrow><mml:mtext/><mml:mi>dt</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="inft1583">\begin{document}$A = \int \!{\mathcal{P}}\,{\mathrm{dt}}$\end{document}</tex-math></alternatives></inline-formula>) by looking ahead in time is equivalent to the stationarity of the physical action without looking ahead, but by taking account of the Rayleigh dissipation. The trick of looking ahead in time generates a dynamics out of an action <inline-formula><alternatives><mml:math id="inf1584"><mml:mi>A</mml:mi></mml:math><tex-math id="inft1584">\begin{document}$A$\end{document}</tex-math></alternatives></inline-formula> that encompasses only a potential energy, no kinetic energy. Without looking ahead, no dynamics would emerge from such an action. Notice, though, that the NLA action has units of energy (the time-integral of a power), while the physical action has units of energy times time (the time-integral of energies).</p></sec></sec></app><app id="appendix-7"><title>Appendix 7</title><sec sec-type="appendix" id="s15"><title>A tutorial on total and partial derivatives as used in the paper</title><p>The proof of Theorem 1 given in the Methods (Sect. Proving theorem 1 (rt-DeEP)) makes use of partial and total derivatives and follows the notation of <xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref> and <xref ref-type="bibr" rid="bib64">Meulemans et al., 2022</xref>. As there is some variability (and community-dependent sloppiness) in the notation of partial and total derivatives here and in general, we provide some explanations on how this notation is interpreted, and why, for instance, total derivatives commute with each other, and also partial with each other (although not total with partial). For a standard basic textbook introducing the concepts of partial derivatives, total differentials, the implicit function theorem etc., see <xref ref-type="bibr" rid="bib88">Stewart, 2010</xref>, being historically based on the classics of <xref ref-type="bibr" rid="bib20">Courant, 1934</xref>.</p><list list-type="roman-lower" id="list4"><list-item><p>In a differential geometric setting, the derivative of real-valued function <inline-formula><alternatives><mml:math id="inf1585"><mml:mrow><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1585">\begin{document}$E(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> on a point <inline-formula><alternatives><mml:math id="inf1586"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1586">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> of a manifold (like the flat Euclidean space) is considered as a mapping of tangent vectors at <inline-formula><alternatives><mml:math id="inf1587"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1587">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> to the real numbers. When interpreting the derivative as mapping, the <inline-formula><alternatives><mml:math id="inf1588"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1588">\begin{document}$\frac{\partial E}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> is living in the dual space of <inline-formula><alternatives><mml:math id="inf1589"><mml:mi>u</mml:mi></mml:math><tex-math id="inft1589">\begin{document}$u$\end{document}</tex-math></alternatives></inline-formula> and is, therefore, a row vector if is a column vector. If a function <inline-formula><alternatives><mml:math id="inf1590"><mml:mrow><mml:mi>𝒇</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1590">\begin{document}$\boldsymbol f (\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> of <inline-formula><alternatives><mml:math id="inf1591"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1591">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> is a vector valued, then its derivative is a matrix with entries <inline-formula><alternatives><mml:math id="inf1592"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒇</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1592">\begin{document}$\left(\frac{\partial \boldsymbol f}{\partial \boldsymbol u}\right)_{ij}= \frac{\partial f_{i}}{\partial u_{j}}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf1593"><mml:mi>i</mml:mi></mml:math><tex-math id="inft1593">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> is indexing the rows (i.e. running down) and <inline-formula><alternatives><mml:math id="inf1594"><mml:mi>j</mml:mi></mml:math><tex-math id="inft1594">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> is indexing the columns (i.e. running right). When <inline-formula><alternatives><mml:math id="inf1595"><mml:mrow><mml:mi>𝒓</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1595">\begin{document}$\boldsymbol r = \rho(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> is a column vector with <inline-formula><alternatives><mml:math id="inf1596"><mml:mi>ρ</mml:mi></mml:math><tex-math id="inft1596">\begin{document}$\rho$\end{document}</tex-math></alternatives></inline-formula> applied to each component of <inline-formula><alternatives><mml:math id="inf1597"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1597">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>, we consider the (partial) derivative <inline-formula><alternatives><mml:math id="inf1598"><mml:mrow><mml:msup><mml:mi>𝒓</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1598">\begin{document}$\boldsymbol r' = \rho'(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> for convenience as column vector with components <inline-formula><alternatives><mml:math id="inf1599"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1599">\begin{document}$\rho'(u_{i})$\end{document}</tex-math></alternatives></inline-formula>. To strictly follow the formalism, it should be a diagonal matrix.</p></list-item><list-item><p>Because we introduced the error vector <inline-formula><alternatives><mml:math id="inf1600"><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:math><tex-math id="inft1600">\begin{document}${\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula> as column vector, it is easier to write <inline-formula><alternatives><mml:math id="inf1601"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi></mml:mrow></mml:math><tex-math id="inft1601">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}={\bar{\boldsymbol{ e }}}+ ...$\end{document}</tex-math></alternatives></inline-formula>, where now <inline-formula><alternatives><mml:math id="inf1602"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1602">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> is also considered as column vector. To be consistent with the above, we should have written <inline-formula><alternatives><mml:math id="inf1603"><mml:mrow><mml:msup><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mtext>T</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi></mml:mrow></mml:math><tex-math id="inft1603">\begin{document}$\frac{\partial L}{\partial \boldsymbol u}^{{\text{T}}}={\bar{\boldsymbol{ e }}}+ ...$\end{document}</tex-math></alternatives></inline-formula>. The <inline-formula><alternatives><mml:math id="inf1604"><mml:msup><mml:mi>.</mml:mi><mml:mtext>T</mml:mtext></mml:msup></mml:math><tex-math id="inft1604">\begin{document}$.^{{\text{T}}}$\end{document}</tex-math></alternatives></inline-formula> appeared us as too heavy so that we neglected it, where it did not have further mathematical consequences (hoping it does not cause confusions). Sticking here to a column vector also renders the backpropagation error to be a column vector in <xref ref-type="disp-formula" rid="equ23">Equation 21</xref>. This error then gets the classical form with the weight transpose, <inline-formula><alternatives><mml:math id="inf1605"><mml:mrow><mml:mover><mml:mi>𝝐</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mo lspace="0em" rspace="0em" class="tml-prime">′</mml:mo></mml:msubsup><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mo>⋅</mml:mo><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/></mml:mrow><mml:msubsup><mml:mi>𝑾</mml:mi><mml:mrow><mml:mspace width="-0.1667em" style="margin-left:-0.1667em;"/><mml:mtext>net</mml:mtext></mml:mrow><mml:mtext>T</mml:mtext></mml:msubsup><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1605">\begin{document}${\bar{\boldsymbol{ \epsilon }}}={\bar{\boldsymbol{ r }}}'_{{{\!\text{net}}}}{\!\cdot\!}\boldsymbol W_{{{\!\text{net}}}}^{{\text{T}}}{\bar{\boldsymbol{ e }}}$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p>We typically have real-valued functions of the form <inline-formula><alternatives><mml:math id="inf1606"><mml:mrow><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝜽</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1606">\begin{document}$E(\boldsymbol{u_\theta}, \boldsymbol \theta)$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf1607"><mml:mrow><mml:mi>𝜽</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1607">\begin{document}$\boldsymbol \theta = (\boldsymbol W, \beta)$\end{document}</tex-math></alternatives></inline-formula> being a vector of parameters, and <inline-formula><alternatives><mml:math id="inf1608"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1608">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> being a function of <inline-formula><alternatives><mml:math id="inf1609"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1609">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula>. To get the total derivative of <inline-formula><alternatives><mml:math id="inf1610"><mml:mi>E</mml:mi></mml:math><tex-math id="inft1610">\begin{document}$E$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1611"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1611">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula> we consider the values <inline-formula><alternatives><mml:math id="inf1612"><mml:mi>E</mml:mi></mml:math><tex-math id="inft1612">\begin{document}$E$\end{document}</tex-math></alternatives></inline-formula> as a function of <inline-formula><alternatives><mml:math id="inf1613"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1613">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula>. This can be done by introducing a new function <inline-formula><alternatives><mml:math id="inf1614"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1614">\begin{document}${\cal E}(\boldsymbol \theta)$\end{document}</tex-math></alternatives></inline-formula> defined as <inline-formula><alternatives><mml:math id="inf1615"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝜽</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1615">\begin{document}${\cal E}(\boldsymbol \theta) = E(\boldsymbol{ u_\theta}, \boldsymbol \theta)$\end{document}</tex-math></alternatives></inline-formula>, where the components <inline-formula><alternatives><mml:math id="inf1616"><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="inft1616">\begin{document}$\theta_{i}$\end{document}</tex-math></alternatives></inline-formula> are considered as independent variables. The total derivative of <inline-formula><alternatives><mml:math id="inf1617"><mml:mi>E</mml:mi></mml:math><tex-math id="inft1617">\begin{document}$E$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1618"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1618">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula> is then defined as vector-valued function <inline-formula><alternatives><mml:math id="inf1619"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo separator="true">,</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo separator="true">,</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1619">\begin{document}$\frac{{\mathrm{d}} E}{{\mathrm{d}} \boldsymbol \theta}= \left(\frac{{\mathrm{d}} E}{{\mathrm{d}}\theta_{1}},...,\frac{{\mathrm{d}} E}{{\mathrm{d}}\theta_{n}}\right) = \left(\frac{{\mathrm{d}} {\cal E}}{{\mathrm{d}}\theta_{1}},...,\frac{{\mathrm{d}} {\cal E}}{{\mathrm{d}}\theta_{n}}\right) = \frac{\partial {\cal E}}{\partial \boldsymbol \theta}$\end{document}</tex-math></alternatives></inline-formula> for a <inline-formula><alternatives><mml:math id="inf1620"><mml:mi>n</mml:mi></mml:math><tex-math id="inft1620">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula>-dimensional <inline-formula><alternatives><mml:math id="inf1621"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1621">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula>. It can be helpful to think of the components of this total derivative as a (total) directional derivatives in the unit directions. For the last (<inline-formula><alternatives><mml:math id="inf1622"><mml:mi>n</mml:mi></mml:math><tex-math id="inft1622">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula>-th) unit direction <inline-formula><alternatives><mml:math id="inf1623"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msup><mml:mi>𝜽</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>n</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mo separator="true">,</mml:mo><mml:mn>0,1</mml:mn><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1623">\begin{document}$\Delta \boldsymbol \theta^{(n)}= (0,..,0,1)$\end{document}</tex-math></alternatives></inline-formula>, for instance, we have <inline-formula><alternatives><mml:math id="inf1624"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munder><mml:mi>lim</mml:mi><mml:mrow><mml:mi>ε</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>ε</mml:mi></mml:mfrac><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>𝜽</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msup><mml:mi>𝜽</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>n</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msup><mml:mi>𝜽</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>n</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mrow style="font-weight:bold;"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝜽</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi></mml:mrow><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft1624">\begin{document}$\frac{{\mathrm{d}} E}{{\mathrm{d}}\theta_{n}}= \lim_{\varepsilon\to 0}\frac{1}{\varepsilon}\left (E(\boldsymbol u_{\boldsymbol \theta+\varepsilon \Delta \boldsymbol \theta^{(n)}}, \boldsymbol \theta+\varepsilon \Delta \boldsymbol \theta^{(n)}) - E(\boldsymbol{u_\theta,\theta}) \right)$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p>The cost gradient, <inline-formula><alternatives><mml:math id="inf1625"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>∝</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:msup><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math><tex-math id="inft1625">\begin{document}$\frac{{\mathrm{d}} C}{{\mathrm{d}} \boldsymbol W}\propto (\boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}) \,{\bar{\boldsymbol{ r }}}^{T}$\end{document}</tex-math></alternatives></inline-formula> has the same dimension as <inline-formula><alternatives><mml:math id="inf1626"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft1626">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula>. Recall that by the cost gradient we mean <inline-formula><alternatives><mml:math id="inf1627"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1627">\begin{document}$\frac{{\mathrm{d}} C}{{\mathrm{d}} \boldsymbol W}= \frac{\partial {\cal C} }{\partial \boldsymbol W}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf1628"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:math><tex-math id="inft1628">\begin{document}$\cal C$\end{document}</tex-math></alternatives></inline-formula> is defined as <inline-formula><alternatives><mml:math id="inf1629"><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝐨</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:msubsup><mml:mi>𝒖</mml:mi><mml:mi>𝐨</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1629">\begin{document}${\cal C}(\boldsymbol W) = C(\boldsymbol u_{\bf o}(\boldsymbol W), \boldsymbol u_{\bf o}^{*})$\end{document}</tex-math></alternatives></inline-formula>, with the voltage <inline-formula><alternatives><mml:math id="inf1630"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝐨</mml:mi></mml:msub></mml:math><tex-math id="inft1630">\begin{document}$\boldsymbol u_{\bf o}$\end{document}</tex-math></alternatives></inline-formula> of the output neurons being itself a function of <inline-formula><alternatives><mml:math id="inf1631"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft1631">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p>To calculate the partial derivative <inline-formula><alternatives><mml:math id="inf1632"><mml:mrow><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1632">\begin{document}$\frac{\partial }{\partial \boldsymbol \theta}E(\boldsymbol u, \boldsymbol \theta)$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1633"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1633">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula>, we fix the first argument <inline-formula><alternatives><mml:math id="inf1634"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝜽</mml:mi></mml:msub></mml:math><tex-math id="inft1634">\begin{document}$\boldsymbol{u_\theta}$\end{document}</tex-math></alternatives></inline-formula>, even if for <inline-formula><alternatives><mml:math id="inf1635"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1635">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> we often plugged in the components of the trajectory <inline-formula><alternatives><mml:math id="inf1636"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝜽</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1636">\begin{document}$\boldsymbol u = \boldsymbol u_{\boldsymbol \theta}(t)$\end{document}</tex-math></alternatives></inline-formula> that now does depend on <inline-formula><alternatives><mml:math id="inf1637"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1637">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula>. In contrast, the total derivative is <inline-formula><alternatives><mml:math id="inf1638"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝒖</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1638">\begin{document}$\frac{{\mathrm{d}} }{{\mathrm{d}} \boldsymbol \theta}E(\boldsymbol u, \boldsymbol \theta) = \frac{\partial E(\boldsymbol u, \boldsymbol \theta)}{\partial \boldsymbol u}\frac{{\mathrm{d}} \boldsymbol u}{{\mathrm{d}} \boldsymbol \theta}+ \frac{\partial E(\boldsymbol u, \boldsymbol \theta)}{\partial \boldsymbol \theta}$\end{document}</tex-math></alternatives></inline-formula>. Here, <inline-formula><alternatives><mml:math id="inf1639"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1639">\begin{document}$\frac{\partial E(\boldsymbol u, \boldsymbol \theta)}{\partial \boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula> is a row vector, as also <inline-formula><alternatives><mml:math id="inf1640"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1640">\begin{document}$\frac{\partial E(\boldsymbol u, \boldsymbol \theta)}{\partial \boldsymbol \theta}$\end{document}</tex-math></alternatives></inline-formula>, consistent with the convention (that we have broken in <xref ref-type="disp-formula" rid="equ30">Equation 28</xref> to keep vectors as columns). When <inline-formula><alternatives><mml:math id="inf1641"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1641">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> is considered as trajectory, <inline-formula><alternatives><mml:math id="inf1642"><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝒖</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝜽</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft1642">\begin{document}$\frac{{\mathrm{d}} \boldsymbol u}{{\mathrm{d}} \boldsymbol \theta}$\end{document}</tex-math></alternatives></inline-formula> does not vanish in general, but it does when <inline-formula><alternatives><mml:math id="inf1643"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1643">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> is simply considered as independent variable.</p></list-item><list-item><p>When replacing the argument <inline-formula><alternatives><mml:math id="inf1644"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1644">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula> in <inline-formula><alternatives><mml:math id="inf1645"><mml:mrow><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1645">\begin{document}$E(\boldsymbol u, \boldsymbol \theta)$\end{document}</tex-math></alternatives></inline-formula> by <inline-formula><alternatives><mml:math id="inf1646"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1646">\begin{document}$\boldsymbol u = \tilde{\boldsymbol u}- \tau \dot{\tilde {\boldsymbol u}}$\end{document}</tex-math></alternatives></inline-formula> we get the ‘Lagrangian’ <inline-formula><alternatives><mml:math id="inf1647"><mml:mrow><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mi>θ</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1647">\begin{document}$L(\tilde{\boldsymbol u}, \dot{\tilde {\boldsymbol u}}, \boldsymbol \theta) = E(\tilde{\boldsymbol u}- \tau \dot{\tilde {\boldsymbol u}}, \theta)$\end{document}</tex-math></alternatives></inline-formula>. The partial derivative of <inline-formula><alternatives><mml:math id="inf1648"><mml:mi>L</mml:mi></mml:math><tex-math id="inft1648">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> with respect to <inline-formula><alternatives><mml:math id="inf1649"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft1649">\begin{document}$\tilde{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>, for instance, is then <inline-formula><alternatives><mml:math id="inf1650"><mml:mrow><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>𝒖</mml:mi></mml:mrow></mml:mfrac><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1650">\begin{document}$\frac{ \partial }{\partial \tilde {\boldsymbol u}}L(\tilde{\boldsymbol u}, \dot{\tilde {\boldsymbol u}}, \boldsymbol \theta) = \frac{\partial }{\partial \boldsymbol u}E(\boldsymbol u, \boldsymbol \theta) \frac{\partial \boldsymbol u}{\partial \tilde{\boldsymbol u}}= \frac{\partial }{\partial \boldsymbol u}E(\boldsymbol u, \boldsymbol \theta)$\end{document}</tex-math></alternatives></inline-formula>. The partial derivative <inline-formula><alternatives><mml:math id="inf1651"><mml:mrow><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mi>L</mml:mi></mml:mrow></mml:math><tex-math id="inft1651">\begin{document}$\frac{ \partial }{\partial \tilde{\boldsymbol u}}L$\end{document}</tex-math></alternatives></inline-formula> considers <inline-formula><alternatives><mml:math id="inf1652"><mml:mi>L</mml:mi></mml:math><tex-math id="inft1652">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> as a function of independent arguments <inline-formula><alternatives><mml:math id="inf1653"><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover></mml:math><tex-math id="inft1653">\begin{document}$\tilde{\boldsymbol u}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf1654"><mml:mover><mml:mover><mml:mi>𝒖</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">~</mml:mo></mml:mover><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">˙</mml:mo></mml:mover></mml:math><tex-math id="inft1654">\begin{document}$\dot{\tilde{\boldsymbol u}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1655"><mml:mi>𝜽</mml:mi></mml:math><tex-math id="inft1655">\begin{document}$\boldsymbol \theta$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p>We also used that the total derivatives commute, in the current example <inline-formula><alternatives><mml:math id="inf1656"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mi>E</mml:mi></mml:mrow></mml:math><tex-math id="inft1656">\begin{document}$\frac{{\mathrm{d}} }{{\mathrm{d}} \boldsymbol W}\frac{{\mathrm{d}} }{{\mathrm{d}} \beta}E = \frac{{\mathrm{d}} }{{\mathrm{d}} \beta}\frac{{\mathrm{d}} }{{\mathrm{d}} \boldsymbol W}E$\end{document}</tex-math></alternatives></inline-formula>. This is generally true for derivatives of Lipschitz continuous functions, for which derivatives exist almost everywhere. The total derivatives (where they exist) then commute because the difference quotients in <inline-formula><alternatives><mml:math id="inf1657"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft1657">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1658"><mml:mi>β</mml:mi></mml:math><tex-math id="inft1658">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> are uniformly bounded. The Moore-Osgood theorem tells that two limits, of which at least one is uniform in the other, can be commuted. This also applies to the double difference quotients involved in the definition of <inline-formula><alternatives><mml:math id="inf1659"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>𝑾</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1659">\begin{document}$\frac{{\mathrm{d}} }{{\mathrm{d}} \boldsymbol W}\frac{{\mathrm{d}} }{{\mathrm{d}} \beta}$\end{document}</tex-math></alternatives></inline-formula>. Remember that the total derivative, for instance with respect to the <inline-formula><alternatives><mml:math id="inf1660"><mml:mi>n</mml:mi></mml:math><tex-math id="inft1660">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula>-th parameter, can be written as <inline-formula><alternatives><mml:math id="inf1661"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munder><mml:mi>lim</mml:mi><mml:mrow><mml:mi>ε</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mspace width="0.1667em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>ε</mml:mi></mml:mfrac><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mi>𝒖</mml:mi><mml:mrow><mml:mi>𝜽</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msup><mml:mi>𝜽</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>n</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msup><mml:mi>𝜽</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="false" lspace="0em" rspace="0em">(</mml:mo><mml:mi>n</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mrow style="font-weight:bold;"><mml:msub><mml:mi>𝒖</mml:mi><mml:mi>𝜽</mml:mi></mml:msub><mml:mo separator="true">,</mml:mo><mml:mi>𝜽</mml:mi></mml:mrow><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft1661">\begin{document}$\frac{{\mathrm{d}} E}{{\mathrm{d}}\theta_{n}}= \lim_{\varepsilon\to 0}\frac{1}{\varepsilon}\left(E(\boldsymbol u_{\boldsymbol \theta+\varepsilon \Delta \boldsymbol \theta^{(n)}}, \boldsymbol \theta+ \varepsilon \Delta \boldsymbol \theta^{(n)}) - E(\boldsymbol{u_\theta,\theta}) \right)$\end{document}</tex-math></alternatives></inline-formula>. But note again that, while for Lipschitz functions partial derivatives commute among themselves, and total derivatives commute among themselves, partial and total derivatives in general do not commute (not even with additional smoothness conditions)!</p></list-item></list></sec></app><app id="appendix-8"><title>Appendix 8</title><sec sec-type="appendix" id="s16"><title>Proof of theorem 1, part (<italic>ii</italic>), using only partial derivatives</title><p>This section proves <xref ref-type="disp-formula" rid="equ31 equ32 equ33">Equations 29–31</xref> in terms of only partial derivatives, banning nested functions and banning the main theorem to calculate total derivatives in higher dimensions as presented in item <inline-formula><alternatives><mml:math id="inf1662"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1662">\begin{document}$(v)$\end{document}</tex-math></alternatives></inline-formula> of the above Tutorial. While a reduction to partial derivatives only may represent a conceptual simplification, it requires many more additional (unnested) functions to be defined (and in fact being the reason why in mathematics the concept of a total differential / total derivative is introduced, see e.g. <xref ref-type="bibr" rid="bib20">Courant, 1934</xref>). – The cited three equations are also the core for the proof for Equilibrium Propagation (<xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>), although there only applied in the steady state after the network converged to a constant activity.</p><p>We assume a network of <inline-formula><alternatives><mml:math id="inf1663"><mml:mi>d</mml:mi></mml:math><tex-math id="inft1663">\begin{document}$d$\end{document}</tex-math></alternatives></inline-formula> neurons whose membrane potential is given by <inline-formula><alternatives><mml:math id="inf1664"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><tex-math id="inft1664">\begin{document}$\boldsymbol u \in \mathbb{R}^{d}$\end{document}</tex-math></alternatives></inline-formula> and which are connected via weights <inline-formula><alternatives><mml:math id="inf1665"><mml:mrow><mml:mi>𝑾</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="inft1665">\begin{document}$\boldsymbol W \in \mathbb{R}^{d \times d}$\end{document}</tex-math></alternatives></inline-formula>. By <inline-formula><alternatives><mml:math id="inf1666"><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:mi>𝒖</mml:mi></mml:msub></mml:math><tex-math id="inft1666">\begin{document}${\boldsymbol \nabla_{\boldsymbol u }}$\end{document}</tex-math></alternatives></inline-formula>, we denote the gradient with respect to the membrane potentials, i.e., <inline-formula><alternatives><mml:math id="inf1667"><mml:mrow><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:mi>𝒖</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mtext/><mml:mo separator="true">,</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1667">\begin{document}${\boldsymbol \nabla_{\boldsymbol u }}= (\frac{\partial}{\partial u_{1}}, ...\ , \frac{\partial}{\partial u_{d}})$\end{document}</tex-math></alternatives></inline-formula>. Similarly, <inline-formula><alternatives><mml:math id="inf1668"><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:mi>𝑾</mml:mi></mml:msub></mml:math><tex-math id="inft1668">\begin{document}${\boldsymbol \nabla_{\boldsymbol W }}$\end{document}</tex-math></alternatives></inline-formula> is a matrix containing the derivatives with respect to the weights, <inline-formula><alternatives><mml:math id="inf1669"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msub><mml:mo form="prefix" stretchy="false" style="font-weight:bold;">∇</mml:mo><mml:mi>𝑾</mml:mi></mml:msub><mml:msub><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="inft1669">\begin{document}$({\boldsymbol \nabla_{\boldsymbol W }})_{ij}= \frac{\partial}{\partial W_{ij}}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>To prove the rt-DeEP theorem 1, we first have to make a few definitions and observations:</p><list list-type="order" id="list5"><list-item><p>For a given <inline-formula><alternatives><mml:math id="inf1670"><mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1670">\begin{document}$(\boldsymbol W, \beta)$\end{document}</tex-math></alternatives></inline-formula>, the dynamics yield certain membrane potentials <inline-formula><alternatives><mml:math id="inf1671"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><tex-math id="inft1671">\begin{document}${f_{\boldsymbol u}}\in \mathbb{R}^{d}$\end{document}</tex-math></alternatives></inline-formula>. Formally, we define this as<disp-formula id="equ107"><label>(96)</label><alternatives><mml:math id="m107"><mml:mtable displaystyle="true" style="width:100%;"><mml:mtr><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"/><mml:mtd class="tml-left" style="padding:0.5ex 0em 0.5ex 1em;"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub><mml:mo lspace="0.2222em" rspace="0.2222em">:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi>ℝ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>d</mml:mi></mml:msup><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mtext/><mml:mtext/><mml:mtext/><mml:mtext/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>↦</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mspace width="0.1667em"/><mml:mi>.</mml:mi></mml:mrow></mml:mtd><mml:mtd class="tml-right" style="padding:0.5ex 0em 0.5ex 0em;width:50%;"><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="t107">\begin{document}$$\displaystyle {f_{\boldsymbol u}}: \mathbb{R}^{d \times d}\times \mathbb{R}\rightarrow \mathbb{R}^{d}\,, \ \ \ \ (\boldsymbol W, \beta) \mapsto{f_{\boldsymbol u}}(\boldsymbol W, \beta) \,.$$\end{document}</tex-math></alternatives></disp-formula></p><p>The <italic>i</italic>th element of <inline-formula><alternatives><mml:math id="inf1672"><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub></mml:math><tex-math id="inft1672">\begin{document}${f_{\boldsymbol u}}$\end{document}</tex-math></alternatives></inline-formula> is denoted by <inline-formula><alternatives><mml:math id="inf1673"><mml:msub><mml:mi>f</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:math><tex-math id="inft1673">\begin{document}$f_{u_i}$\end{document}</tex-math></alternatives></inline-formula> and hence <inline-formula><alternatives><mml:math id="inf1674"><mml:mrow><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:mfrac><mml:mo separator="true">,</mml:mo><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mi>.</mml:mi><mml:mtext/><mml:mo separator="true">,</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:msub></mml:mrow></mml:mfrac><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1674">\begin{document}${\boldsymbol \nabla_{ {f_{\boldsymbol u}} }}= (\frac{\partial}{\partial f_{u_1}}, ...\ , \frac{\partial}{\partial f_{u_d}})$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item><list-item><p>We define the following functions:</p><list list-type="bullet" id="list5subList1"><list-item><p>the mismatch energy <inline-formula><alternatives><mml:math id="inf1675"><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo lspace="0.2222em" rspace="0.2222em">:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>d</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:mi>ℝ</mml:mi><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mtext/><mml:mtext/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝑾</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>↦</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝑾</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:munderover></mml:mrow><mml:msup><mml:mrow><mml:mo fence="true" form="prefix">[</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>j</mml:mi></mml:munder></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false" class="tml-xshift" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo fence="true" form="postfix">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft1675">\begin{document}${E^\text{M}}: \mathbb{R}^{d}\times \mathbb{R}^{d\times d}\rightarrow \mathbb{R}\,, \ \ (\boldsymbol u, \boldsymbol W) \mapsto{E^\text{M}}(\boldsymbol u, \boldsymbol W) = \frac{1}{2}\sum_{i=1}^{d}\left[u_{i}- \sum_{j}W_{ij}\bar r_{j}\right]^{2}$\end{document}</tex-math></alternatives></inline-formula> ,</p></list-item><list-item><p>the cost function <inline-formula><alternatives><mml:math id="inf1676"><mml:mrow><mml:mi>C</mml:mi><mml:mo lspace="0.2222em" rspace="0.2222em">:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>d</mml:mi></mml:msup><mml:mo stretchy="false">→</mml:mo><mml:mi>ℝ</mml:mi><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mtext/><mml:mtext/><mml:mi>𝒖</mml:mi><mml:mo>↦</mml:mo><mml:mi>C</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:msup><mml:mrow><mml:mo fence="true" form="prefix">‖</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>k</mml:mi><mml:mo lspace="0em" rspace="0em">*</mml:mo></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo fence="true" form="postfix">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="inft1676">\begin{document}$C: \mathbb{R}^{d}\rightarrow \mathbb{R}\,, \ \ \boldsymbol u \mapsto C(\boldsymbol u) = \frac{1}{2}\sum_{k\in{\mathcal{O}}}\left\| u_{k}^{*}- u_{k}\right\|^{2}$\end{document}</tex-math></alternatives></inline-formula> ,</p></list-item><list-item><p>the Lagrangian <inline-formula><alternatives><mml:math id="inf1677"><mml:mrow><mml:mi>L</mml:mi><mml:mo lspace="0.2222em" rspace="0.2222em">:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>d</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi>ℝ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>ℝ</mml:mi><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mtext/><mml:mtext/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>↦</mml:mo><mml:mi>L</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>𝑾</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝒖</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1677">\begin{document}$L: \mathbb{R}^{d}\times \mathbb{R}^{d \times d}\times \mathbb{R}\rightarrow \mathbb{R}\,, \ \ (\boldsymbol u, \boldsymbol W, \beta) \mapsto L (\boldsymbol u, \boldsymbol W, \beta) ={E^\text{M}}(\boldsymbol u, \boldsymbol W) + \beta C(\boldsymbol u)$\end{document}</tex-math></alternatives></inline-formula> . To make the dependency of the cost and energies on <inline-formula><alternatives><mml:math id="inf1678"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1678">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1679"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1679">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula> explicit, we further introduce three auxiliary functions <inline-formula><alternatives><mml:math id="inf1680"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mtext>M</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1680">\begin{document}${F_\text{M}}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf1681"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mtext>C</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1681">\begin{document}${F_\text{C}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf1682"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mtext>L</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1682">\begin{document}${F_\text{L}}$\end{document}</tex-math></alternatives></inline-formula> :</p></list-item><list-item><p>for the mismatch energy <inline-formula><alternatives><mml:math id="inf1683"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mtext>M</mml:mtext></mml:msub><mml:mo lspace="0.2222em" rspace="0.2222em">:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi>ℝ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>ℝ</mml:mi><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mtext/><mml:mtext/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>↦</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mtext>M</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo separator="true">,</mml:mo><mml:mi>𝑾</mml:mi><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft1683">\begin{document}${F_\text{M}}: \mathbb{R}^{d \times d}\times \mathbb{R}\rightarrow \mathbb{R}\,, \ \ (\boldsymbol W, \beta) \mapsto{F_\text{M}}(\boldsymbol W, \beta) ={E^\text{M}}\left({f_{\boldsymbol u}}(\boldsymbol W, \beta), \boldsymbol W\right)$\end{document}</tex-math></alternatives></inline-formula> ,</p></list-item><list-item><p>for the cost function <inline-formula><alternatives><mml:math id="inf1684"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo lspace="0.2222em" rspace="0.2222em">:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi>ℝ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>ℝ</mml:mi><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mtext/><mml:mtext/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>↦</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="inft1684">\begin{document}${F_C}: \mathbb{R}^{d \times d}\times \mathbb{R}\rightarrow \mathbb{R}\,, \ \ (\boldsymbol W, \beta) \mapsto{F_C}(\boldsymbol W, \beta) = C\left({f_{\boldsymbol u}}(\boldsymbol W, \beta)\right)$\end{document}</tex-math></alternatives></inline-formula> ,</p></list-item><list-item><p>for the Lagrangian <inline-formula><alternatives><mml:math id="inf1685"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo lspace="0.2222em" rspace="0.2222em">:</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi>ℝ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>ℝ</mml:mi><mml:mspace width="0.1667em"/><mml:mo separator="true">,</mml:mo><mml:mtext/><mml:mtext/><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>↦</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mtext>M</mml:mtext></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝑾</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>β</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="inft1685">\begin{document}${F_L}: \mathbb{R}^{d \times d}\times \mathbb{R}\rightarrow \mathbb{R}\,, \ \ (\boldsymbol W, \beta) \mapsto{F_L}(\boldsymbol W, \beta) ={F_\text{M}}(\boldsymbol W, \beta) + \beta{F_C}(\boldsymbol W, \beta)$\end{document}</tex-math></alternatives></inline-formula></p></list-item></list></list-item><list-item><p>The Euler-Lagrange equations can be written as <inline-formula><alternatives><mml:math id="inf1686"><mml:mrow><mml:mi>τ</mml:mi><mml:mfrac><mml:mtext>d</mml:mtext><mml:mrow><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:mi>𝒖</mml:mi></mml:msub><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo form="prefix" stretchy="false">−</mml:mo><mml:msub><mml:mo form="prefix" stretchy="false" style="font-weight:bold;">∇</mml:mo><mml:mi>𝒖</mml:mi></mml:msub><mml:mi>L</mml:mi></mml:mrow></mml:math><tex-math id="inft1686">\begin{document}$\tau \frac{{\text{d}}}{{\text{d}} t}{\boldsymbol \nabla_{\boldsymbol u }}L = -{\boldsymbol \nabla_{\boldsymbol u }}L$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Hence, far enough away from initialization and for smooth enough input (and targets) we have <inline-formula><alternatives><mml:math id="inf1687"><mml:mrow><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub></mml:msub><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1687">\begin{document}${\boldsymbol \nabla_{ {f_{\boldsymbol u}} }}L = 0$\end{document}</tex-math></alternatives></inline-formula> at all times, even when changing the network input continuously. Note that both the cost and the mismatch energies are defined on low-pass-filtered signals, and it is with respect to the low-pass filtered external input that the low-pass-filtered output error is minimized.</p></list-item><list-item><p>Without output nudging (i.e. <inline-formula><alternatives><mml:math id="inf1688"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1688">\begin{document}$\beta = 0$\end{document}</tex-math></alternatives></inline-formula>), the output error vanishes and consequently all other prediction errors vanish as well, <inline-formula><alternatives><mml:math id="inf1689"><mml:mrow><mml:mover><mml:mi>𝒆</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>𝒖</mml:mi><mml:mo>−</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="inft1689">\begin{document}${\bar{\boldsymbol{ e }}}= \boldsymbol u - \boldsymbol W{\bar{\boldsymbol{ r }}}= 0$\end{document}</tex-math></alternatives></inline-formula>. This can be easily shown for layered network architectures and holds true for arbitrary connections (e.g. recurrent networks) as long as <inline-formula><alternatives><mml:math id="inf1690"><mml:msub><mml:mi>f</mml:mi><mml:mi>𝒖</mml:mi></mml:msub></mml:math><tex-math id="inft1690">\begin{document}${f_{\boldsymbol u}}$\end{document}</tex-math></alternatives></inline-formula> uniquely exists, i.e., <inline-formula><alternatives><mml:math id="inf1691"><mml:mrow><mml:mi>𝒖</mml:mi><mml:mo>=</mml:mo><mml:mi>𝑾</mml:mi><mml:mover><mml:mi>𝒓</mml:mi><mml:mo stretchy="false" style="math-style:normal;math-depth:0;">‾</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="inft1691">\begin{document}$\boldsymbol u = \boldsymbol W{\bar{\boldsymbol{ r }}}$\end{document}</tex-math></alternatives></inline-formula> has a unique solution for <inline-formula><alternatives><mml:math id="inf1692"><mml:mi>𝒖</mml:mi></mml:math><tex-math id="inft1692">\begin{document}$\boldsymbol u$\end{document}</tex-math></alternatives></inline-formula>. From the form of the mismatch energy, we then get<disp-formula id="equ108"><label>(97)</label><alternatives><mml:math id="m108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t108">\begin{document}$$\displaystyle {\boldsymbol \nabla_{\boldsymbol W }}{E^\text{M}}\big|_{\beta = 0}= \big(\boldsymbol W \,{\bar{\boldsymbol{ r }}}- \boldsymbol u \big) \,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}\big|_{\beta = 0}= 0.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Since we are assuming smooth functions, this also implies that<disp-formula id="equ109"><label>(98)</label><alternatives><mml:math id="m109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t109">\begin{document}$$\displaystyle \lim_{\epsilon_\beta \to 0}{\boldsymbol \nabla_{\boldsymbol W }}{E^\text{M}}\big|_{\beta = \epsilon_\beta}= 0. $$\end{document}</tex-math></alternatives></disp-formula></p></list-item><list-item><p>From the assumption of well-behaved (smooth) functions, it also follows that partial derivatives commute <inline-formula><alternatives><mml:math id="inf1693"><mml:mrow><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:mi>𝑾</mml:mi></mml:msub><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mi>∂</mml:mi><mml:mrow><mml:mi>∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:mi>𝑾</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="inft1693">\begin{document}${\boldsymbol \nabla_{\boldsymbol W }}{\frac{\partial }{\partial \beta }}={\frac{\partial }{\partial \beta }}{\boldsymbol \nabla_{\boldsymbol W }}$\end{document}</tex-math></alternatives></inline-formula>.</p></list-item></list><p>Our goal is to find a plasticity rule that minimizes the cost <inline-formula><alternatives><mml:math id="inf1694"><mml:mi>C</mml:mi></mml:math><tex-math id="inft1694">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula>, which we do by calculating <inline-formula><alternatives><mml:math id="inf1695"><mml:mrow><mml:msub><mml:mo style="font-weight:bold;">∇</mml:mo><mml:mi>𝑾</mml:mi></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mo fence="false" stretchy="true" symmetric="true" minsize="1.2em" maxsize="1.2em">|</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="inft1695">\begin{document}${\boldsymbol \nabla_{\boldsymbol W }}{F_C}\big|_{\beta = 0}$\end{document}</tex-math></alternatives></inline-formula>. Similar to <xref ref-type="bibr" rid="bib79">Scellier and Bengio, 2017</xref>, to achieve this, we first calculate the partial derivatives of <inline-formula><alternatives><mml:math id="inf1696"><mml:msub><mml:mi>F</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:math><tex-math id="inft1696">\begin{document}${F_L}$\end{document}</tex-math></alternatives></inline-formula> with respect to the nudging strength <inline-formula><alternatives><mml:math id="inf1697"><mml:mi>β</mml:mi></mml:math><tex-math id="inft1697">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula><disp-formula id="equ110"><label>(99a)</label><alternatives><mml:math id="m110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mtext>M</mml:mtext></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t110">\begin{document}$$\displaystyle {\frac{\partial {F_L} }{\partial \beta }}={\frac{\partial {F_\text{M}} }{\partial \beta }}+ \beta{\frac{\partial {F_C} }{\partial \beta }}+{F_C}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ111"><label>(99b)</label><alternatives><mml:math id="m111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t111">\begin{document}$$\displaystyle  = \sum_{i=1}^{d}\left({\frac{\partial {E^\text{M}} }{\partial f_{u_i}}}{\frac{\partial f_{u_i}}{\partial \beta }}+ \beta{\frac{\partial C }{\partial f_{u_i}}}{\frac{\partial f_{u_i}}{\partial \beta }}\right) + C$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ112"><label>(99c)</label><alternatives><mml:math id="m112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t112">\begin{document}$$\displaystyle  = \sum_{i=1}^{d}\underbrace{{\frac{\partial \left({E^\text{M}} + \beta C\right) }{\partial f_{u_i}}}}_{= 0}{\frac{\partial f_{u_i}}{\partial \beta }}+ C$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ113"><label>(99d)</label><alternatives><mml:math id="m113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t113">\begin{document}$$\displaystyle = C,$$\end{document}</tex-math></alternatives></disp-formula></p><p>and the weights <inline-formula><alternatives><mml:math id="inf1698"><mml:mi>𝑾</mml:mi></mml:math><tex-math id="inft1698">\begin{document}$\boldsymbol W$\end{document}</tex-math></alternatives></inline-formula><disp-formula id="equ114"><label>(100a)</label><alternatives><mml:math id="m114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mtext>M</mml:mtext></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t114">\begin{document}$$\displaystyle {\frac{\partial {F_L} }{\partial W_{ij}}}={\frac{\partial {F_\text{M}} }{\partial W_{ij}}}+ \beta{\frac{\partial {F_C} }{\partial W_{ij}}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ115"><label>(100b)</label><alternatives><mml:math id="m115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t115">\begin{document}$$\displaystyle  \sum_{k=1}^{d}\left({\frac{\partial {E^\text{M}} }{\partial f_{u_k}}}{\frac{\partial f_{u_k}}{\partial W_{ij}}}+ \beta{\frac{\partial C }{\partial f_{u_k}}}{\frac{\partial f_{u_k}}{\partial W_{ij}}}\right) +{\frac{\partial {E^\text{M}} }{\partial W_{ij}}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ116"><label>(100c)</label><alternatives><mml:math id="m116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:munderover><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t116">\begin{document}$$\displaystyle  = \sum_{k=1}^{d}\underbrace{{\frac{\partial \left({E^\text{M}} + \beta C\right) }{\partial f_{u_k}}}}_{=0}{\frac{\partial f_{u_k}}{\partial W_{ij}}}+{\frac{\partial {E^\text{M}} }{\partial W_{ij}}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ117"><label>(100d)</label><alternatives><mml:math id="m117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t117">\begin{document}$$\displaystyle ={\frac{\partial {E^\text{M}} }{\partial W_{ij}}}\,,$$\end{document}</tex-math></alternatives></disp-formula></p><p>or in vectorized form<disp-formula id="equ118"><label>(101)</label><alternatives><mml:math id="m118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t118">\begin{document}$$\displaystyle {\boldsymbol \nabla_{\boldsymbol W }}{F_L}={\boldsymbol \nabla_{\boldsymbol W }}{E^\text{M}}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>With these identities in place, we can calculate the plasticity rule:<disp-formula id="equ119"><label>(102a)</label><alternatives><mml:math id="m119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math><tex-math id="t119">\begin{document}$$\displaystyle -\lim_{\epsilon_\beta \to 0}\boldsymbol{\nabla}_{\boldsymbol{W}}F_{C}= \lim_{\epsilon_\beta \to 0}\boldsymbol{\nabla}_{\boldsymbol{W}}\frac{\partial F_{L}}{\partial \beta}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ120"><label>(102b)</label><alternatives><mml:math id="m120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="t120">\begin{document}$$\displaystyle \lim_{\epsilon_\beta \to 0}\frac{\partial}{\partial \beta}\boldsymbol{\nabla}_{\boldsymbol{W}}F_{L}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ121"><label>(102c)</label><alternatives><mml:math id="m121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>δ</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t121">\begin{document}$$\displaystyle = \lim_{\epsilon_\beta \to 0}\lim_{\delta \to 0}\frac{1}{\delta}\left( \boldsymbol{\nabla}_{\boldsymbol{W}}F_{L}\big|_{\beta = \epsilon_\beta + \delta}- \boldsymbol{\nabla}_{\boldsymbol{W}}F_{L}\big|_{\beta = \epsilon_\beta}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ122"><label>(102d)</label><alternatives><mml:math id="m122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>δ</mml:mi></mml:mfrac><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t122">\begin{document}$$\displaystyle = \lim_{\delta \to 0}\frac{1}{\delta}\lim_{\epsilon_\beta \to 0}\left( \boldsymbol{\nabla}_{\boldsymbol{W}}E^{\text{M}}\big|_{\beta = \epsilon_\beta + \delta}- \boldsymbol{\nabla}_{\boldsymbol{W}}E^{\text{M}}\big|_{\beta = \epsilon_\beta}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ123"><label>(102e)</label><alternatives><mml:math id="m123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>δ</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:munder><mml:mrow><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext> from (equation 98)</mml:mtext></mml:mrow></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t123">\begin{document}$$\displaystyle = \lim_{\delta \to 0}\frac{1}{\delta}\left( \lim_{\epsilon_\beta \to 0}\boldsymbol{\nabla}_{\boldsymbol{W}}E^{\text{M}}\big|_{\beta = \epsilon_\beta + \delta}- \underbrace{\lim_{\epsilon_\beta \to 0} \boldsymbol{\nabla}_{\boldsymbol{W}} E^{\text{M}} \big|_{\beta = \epsilon_\beta}}_{=0 \text{ from (equation 98)}}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ124"><label>(102f)</label><alternatives><mml:math id="m124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>δ</mml:mi></mml:mfrac><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="t124">\begin{document}$$\displaystyle =\lim_{\delta \to 0}\frac{1}{\delta}\boldsymbol{\nabla}_{\boldsymbol{W}}E^{\text{M}}\big|_{\beta = \delta}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ125"><label>(103g)</label><alternatives><mml:math id="m125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>≈</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>δ</mml:mi></mml:mfrac><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mi>δ</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mtext>for </mml:mtext><mml:mi>δ</mml:mi><mml:mo>≪</mml:mo><mml:mn>1.</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="t125">\begin{document}$$\displaystyle \approx \frac{1}{\delta}\boldsymbol{\nabla}_{\boldsymbol{W}}E^{\text{M}}\big|_{\beta = \delta}\quad \text{for }\delta \ll 1.$$\end{document}</tex-math></alternatives></disp-formula></p><p>where we used that limits can be exchanged for smooth functions. Using the definition of <inline-formula><alternatives><mml:math id="inf1699"><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:math><tex-math id="inft1699">\begin{document}${E^\text{M}}$\end{document}</tex-math></alternatives></inline-formula>, we obtain a plasticity rule that minimizes the cost function<disp-formula id="equ126"><label>(103)</label><alternatives><mml:math id="m126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo movablelimits="true" form="prefix">lim</mml:mo><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:msub><mml:mi mathvariant="bold">∇</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mtext>M</mml:mtext></mml:msup></mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mrow><mml:mtext>for </mml:mtext><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msub><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="t126">\begin{document}$$\displaystyle -\lim_{\epsilon_\beta \to 0}{\boldsymbol \nabla_{\boldsymbol W }}C\big|_{\beta = \epsilon_\beta}\approx - \frac{1}{\epsilon_{\beta}}{\boldsymbol \nabla_{\boldsymbol W }}{E^\text{M}}\big|_{\beta = \epsilon_\beta}= \frac{1}{\epsilon_{\beta}}\big(\boldsymbol u - \boldsymbol W \,{\bar{\boldsymbol{ r }}}\big) \,{\bar{\boldsymbol{ r }}}^{\mathrm{T}}\big|_{\beta = \epsilon_\beta}\ \ \text{for $\epsilon_{\beta}\ll 1$}. $$\end{document}</tex-math></alternatives></disp-formula></p><p>In practice, the prefactor <inline-formula><alternatives><mml:math id="inf1700"><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>β</mml:mi></mml:msub></mml:mfrac></mml:math><tex-math id="inft1700">\begin{document}$\frac{1}{\epsilon_{\beta}}$\end{document}</tex-math></alternatives></inline-formula> is absorbed into the learning rate.</p></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89674.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>École Normale Supérieure - PSL</institution><country>France</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>This manuscript describes a potentially <bold>important</bold> theoretical framework to link predictive coding, error-based learning, and neuronal dynamics. The provided evidence is <bold>solid</bold>, but some details would benefit from additional clarification. The exposition of the manuscript is targeted for a specialist audience.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89674.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The manuscript considers a hierarchical network of neurons, of the type that can be found in sensory cortex, and assumes that they aim to constantly predict sensory inputs that may change in time. The paper describes the dynamics of neurons and rules of synaptic plasticity that minimize the integral of prediction errors over time.</p><p>The manuscript describes and analyses the model in great detail, and presents multiple and diverse simulations illustrating the model's functioning. However, the manuscript could be made more accessible and easier to read. The paper may help to understand the organization of cortical neurons, their properties, as well as the function of its particular components (such as apical dendrites).</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89674.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Neuroscientists often state that we have no theory of the brain. The example of theoretical physics is often cited, where numerous and quite complex phenomena are explained by a compact mathematical description. Lagrangian and Hamiltonian pictures provide such powerful 'single equation'. These frameworks are referred to as 'energy', an elegant way to turn numerous differential equations into a single compact relationship between observable quantities (state variables like position and speed) and scaling constants (like the gravity constant or the Planck constant). Such energy pictures have been used in theoretical neuroscience since the 1980s.</p><p>The manuscript &quot;neuronal least-action principle for real-time learning in cortical circuits&quot; by Walter Senn and collaborators describes a theoretical framework to link predictive coding, error-based learning, and neuronal dynamics. The central concept is that an energy function combining self-supervised and supervised objectives is optimized by realistic neuronal dynamics and learning rules when considering the state of a neuron as a mixture of the current membrane potential and its rate of change. As compared with previous energy functions in theoretical neuroscience, this theory captures a more extensive range of observations while satisfying normative constraints. Particularly, no theory had to my knowledge related adaptive dynamics widely observed in the brain (referred to as prospective coding in the text, but is sometimes referred to as adaptive coding or redundancy reduction) with the dynamics of learning rules.</p><p>The manuscript first exposes the theory of two previously published papers by the same group on somato-dendritic error with apical and basal dendrites. These dynamics are then related to an energy function, whose optimum recovers the dynamics. The rest of the manuscript illustrates how features of this model fits either normative or observational constraints. Learning follows a combination of self-supervised learning (learning to predict the next step) and supervised learning (learning to predict an external signal). The credit assignment problem is solved by an apical-compartment projecting set of interneurons with learning rules whose role is to align many weight matrices to avoid having to do multiplexing. An extensive method section and supplementary material expand on mathematical proofs and make more explicit the mathematical relationship between different frameworks.</p><p>Experts would say that much of the article agglomerates previous theoretical papers by the same authors that have been published recently either in archival servers or in conference proceedings. A number of adaptations to previous theoretical results were necessary, so the present article is not easily reduced to a compendium of previous pre-prints. However, the manuscript is by no means easy to read. Also, there remain a few thorny assumptions (unobserved details of the learning rules or soma-dendrites interactions), but the theory is likely going to be regarded as an important step towards a comprehensive theory of the brain.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89674.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Senn</surname><given-names>Walter</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib><contrib contrib-type="author"><name><surname>Dold</surname><given-names>Dominik</given-names></name><role specific-use="author">Author</role><aff><institution>European Space Agency</institution><addr-line><named-content content-type="city">Darmstadt</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Kungl</surname><given-names>Akos F</given-names></name><role specific-use="author">Author</role><aff><institution>Left academia</institution><addr-line><named-content content-type="city">Heidelberg</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Ellenberger</surname><given-names>Benjamin</given-names></name><role specific-use="author">Author</role><aff><institution>Insel Data Science Center, University Hospital Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib><contrib contrib-type="author"><name><surname>Jordan</surname><given-names>Jakob</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib><contrib contrib-type="author"><name><surname>Bengio</surname><given-names>Yoshua</given-names></name><role specific-use="author">Author</role><aff><institution>Mila - Quebec Artificial Intelligence Institute</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Sacramento</surname><given-names>João</given-names></name><role specific-use="author">Author</role><aff><institution>Department of Computer Science, ETH Zurich</institution><addr-line><named-content content-type="city">Zurich</named-content></addr-line><country>Switzerland</country></aff></contrib><contrib contrib-type="author"><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name><role specific-use="author">Author</role><aff><institution>University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>Major comments:</p><p>(1) It is nice that the authors compared their model to the one &quot;without lookahead&quot; in Figure 4, but this comparison requires more evidence in my opinion, as I explain in this comment. The model without lookahead is closely related or possibly equivalent to the standard predictive coding. In predictive coding, one can make the network follow the stimulus rapidly by reducing the time constant tau. However, as the time constant decreases, the network would become unstable both in simulations (due to limited integration time step) and physical implementation (due to noise). Therefore I wonder if the proposed model has an advantage over standard predictive coding with an optimized time constant. Hence I suggest to also add a comparison between the proposed model, and the predictive coding with parameters (such as tau) optimized independently for each model. Of course, we know that the time-constant of biological neurons is fixed, but biological neurons might have had different time constants (by changing leak conductance) and such analysis could shed light on the question of why the neurons are organized the way they are.</p></disp-quote><p>The comparison with a predictive network for which the neuronal time constants shrink towards 0 is in fact helpful. We added two news subsections in the SI that formally compares the NLA with other approaches, Equilibrium propagation and the Latent Equilibrium, with a version of Equilibrium Propagation also covering the standard predictive coding you describe (SI, Sect.C and D). The Subsection C concludes: “In the Equilibrium propagation we cannot simply take the limit t--&gt;0 since then the dynamics either disappears (when tau remains on the left, t Du--&gt;0) or explodes (when t is moved to the right, dt/ t --&gt; ∞), leading to either too small or too big jumps.”</p><p>We have also expanded the passage on the predictive coding in the main text, comparing our instantaneous network processing (up to a remaining time constant tin) with experimental data from humans (see page 10 of the revised ms). The new paragraph ends with:</p><p>“Notice that, from a technical perspective, making the time constants of individual cortical neurons arbitrarily short leads to network instabilities and is unlikely the option chosen by the brain (see SI Sect. C, Comparison to the Equilibrium Propagation).”</p><p>A new formal definition of the moving equilibrium in the Methods (Sect. F) helps to understand this notion of being in a balanced equilibrium state during the dynamics. This formal definition directly leads to the contraction analysis in the SI, Sect. D, showing why the Latent Equilibrium is always contractive, while the current form of the NLA may show jumps at the corner of a ReLu (since a second order derivative of the transfer function enters in the error propagation).</p><p>The reviewer perhaps has additional simulations in mind that compare the robustness of the different models. However, as this paper is more about presenting a novel concept with a comprehensive theory (summing up to 45 pages), we prefer to not add more than the simulations necessary to check the statements of the theorems.</p><disp-quote content-type="editor-comment"><p>(2) I found this paper difficult to follow, because the Results sections went straight into details, and various elements of the model were introduced without explaining why they are necessary. Furthermore, the neural implementation was introduced after the model simulations. I suggest reorganizing the manuscript, to describe the model following Marr's levels of description and then presenting the results of simulations. In particular, I suggest starting the Results section by explaining what computation the network is trying to achieve (describe the setup, function L, define its integral over time, and explain that the goal is to find a model minimizing this integral). Then, I suggest presenting the algorithm the neurons need to employ to minimize this integral, i.e. their dynamics and plasticity (I wonder if r=rho(u) + tau rho(u)' is a consequence of action minimization or a necessary assumption - please clarify it). Next please explain how the algorithms could be implemented in biological neurons. Afterward please present the results of the simulation.</p></disp-quote><p>We are sorry to realize that we could not convey the main message clearly enough. After rewriting the paper and straightening the narrative, we hope it is simpler to understand now.</p><p>The paper does not suggest a new model to solve a task, and writing down the function to be minimized is not enough. The point of the NLA is that the time integral of our Lagrangian is minimized with respect to the prospective coordinates, i.e. the discounted future voltage. It is about the question how dynamic equations in biology are derived. Of course, we also solve these equations, prove theorems and perform simulations. But the main point that biology seems to deal with time differently than physics deals with time. Biology “thinks” in terms of future quantities, physics “thinks” in terms of current quantities. We tried to explain this better now in the Introduction, the Results (e.g. after Eq. 5) and the Methods.</p><disp-quote content-type="editor-comment"><p>(3) Understanding the paper requires background knowledge that most readers of eLife are unlikely to have, even if they are mathematically minded. For example, I am from the field of computational neuroscience, and I have never heard about Least Action principle from physics or the EulerLagrange equation. I felt lost after reading this paper, and to be able to write this review I needed to watch videos on the Euler-Lagrange equation. To help other readers, I have two suggestions: First, I feel that Eq 4-6 could be moved to the methods, because I found the concept of u~ difficult to understand, and it does not appear in the algorithm. Second, I advise to write in the Introduction, what knowledge is required to follow this paper, and point the readers to resources where they can find the required information. The authors may specify what background is required to follow the main text, and what is required to understand the methods.</p></disp-quote><p>We hope that after explaining the rationale better, it becomes clear that we cannot skip the equations for the prospective coordinates. Likewise, the Euler-Lagrange equations need to be presented in the abstract form, since these are the equations that are eventually transformed into the “model”. We tried to give the basic intuition for this in the main text. As we explained above, the equations asked to be skipped represent the essence of the proposal. It is about how to derive a model equations.</p><p>Moreover, we give more explanations in the Methods to understand the derivations, and we refer to the specifically sections in the SI for further details. We are aware that a full understanding of the theory requires some basic knowledge of the calculus of variation.</p><p>We are hesitating to write in the Introduction what type of knowledge is required to understand the paper. An understanding can be on various levels. Moreover, the materials that are considered to be helpful depend on the background. While for some it is a Youtube, for some Wikipedia, and for others it is a textbook where specific ingredients can be extracted. But we do cite two textbooks in the Results and more in the SI, Sect. F, when referring to the principle of least action in physics and the mathematics, including weblinks.</p><disp-quote content-type="editor-comment"><p>Minor comments</p><p>Eq.3: The Authors refer to this equation as a Lagrangian. Could you please clarify why? Is the logic to minimize the energy subject to a constraint that Cost = 0?</p></disp-quote><p>Thanks for asking. The cost is not really a constraint, it is globally minimized, in parallel steps. We are explaining this right after Eq. 3. “We `prospectively' minimize L locally across a voltage trajectory, so that, as a consequence, the local synaptic plasticity for W will globally reduce the cost along the trajectory (Theorem 1 below).”</p><p>We were adding two sentence that explain why this function in Eq. 3 is called a Lagrangian: “While in classical energy-based approaches L is called the total energy, we call it the `Lagrangian' because it will be integrated along real and virtual voltage trajectories as done in variational calculus (leading to the Euler-Lagrange equations, see below and SI, Sect. F)”</p><disp-quote content-type="editor-comment"><p>p.4, below Eq. 5 - Please explain the rationale behind NLA, i.e. why is it beneficial that &quot;the trajectory u˜(t) keeps the action A stationary with respect to small variations δu˜&quot;? I guess you wish to minimize L integrated over time, but this is not evident from the text.</p></disp-quote><p>Hmm, yes and no. We wish to minimize the cost, and on the way there minimize the action. Since the global minimization of C is technically difficult, one looks for stationary trajectory as defined in the cited sentence, while minimizing L with respect to W, to eventually minimize the cost.</p><p>In the text we now explain after Eq. 5:</p><p>“The motivation to search for a trajectory that keeps the action stationary is borrowed from physics. The motivation to search for a stationary trajectory by varying the near-future voltages ũ instead of u is assigned to the evolutionary pressure in biology to 'think ahead of time'. To not react too late, internal delays involved in the integration of external feedback need to be considered and eventually need to be overcome. In fact, only for the 'prospective coordinates' defined by looking ahead into the future, even when only virtually, will a real-time learning from feedback errors become possible (as expressed by our Theorems below).”</p><disp-quote content-type="editor-comment"><p>Bottom of page 8. The authors say that in the case of single equilibrium and strong nudging the model reduced to the Least Control Principle. Does it also reduce to Predictive coding for supervised learning? If so, it would be helpful to state so.</p></disp-quote><p>Yes, in this case the prediction error in the apical dendrite becomes the one of predictive coding. We are stating this now right at the end of the cited sentence:</p><p>“In the case of strong nudging and a single steady-state equilibrium, the NLA principle reduces to the Least-Control Principle (Meulemans et al., 2022) that minimizes the mismatch energy E^M for a constant input and a constant target, with the apical prediction error becoming the prediction error from standard predictive coding (Rao &amp; Ballard, 1999).”</p><p>In the Discussion we also added a further point (iv) to compare the NLA principle with predictive coding. Both “improve” the sensory representation, but the NLA does in favor of an output, and the predictive coding in favor of the sensory prediction itself (see Discussion).</p><disp-quote content-type="editor-comment"><p>Whenever you refer to supplementary materials, please specify the section, so it is easier for the reader to find it.</p></disp-quote><p>Done. Sorry to not have done it earlier. We are now also indicate specific sections when referring to the Methods.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>There are no major issues with this article, but I have several considerations that I think would greatly improve the impact, clarity, and validity of the claims.</p><p>(1) Unifying the narrative. There are many many ideas put forward in what feels like a deluge. While I appreciate the enthusiasm, as a reader I found it hard to understand what it was that the authors thought was the main breakthrough. For instance, the abstract, results, introduction, and discussion all seem to provide different answers to that question. The abstract seems to focus on the motor error idea. The introduction seems to focus on the novel prospective+predictive setup of the energy function. The discussion lists the different perks of the theory (delay compensation, moving equilibrium, microcircuit) without referring to the prospective+predictive setup of the energy function.</p></disp-quote><p>Thanks much for these helpful hints. Yes, the paper became an agglomerate of many ideas, also own to the fact that we wish to show how the NLA principle can be applied to explain various phenomenology in neurosicence. We now simplified the narrative to this one point of providing a novel theoretical framework for neuroscience, and explaining why this is novel and why it “suddenly works” (the prospective minimization of the energy).</p><p>As you can see from the dominating red in the revised pdf, we did fully rewrite Abstract, Introduction and Discussion under the narrative of the NLA and prospective coding.</p><disp-quote content-type="editor-comment"><p>(2) Laying out the organization of the notation clearly. There are quite a few subtle distinctions of what is meant by the different weight matrices (omnibus matrix then input vs recurrent then layered architecture), different temporal horizon formalisms (bar, not bar, tilde), different operators (L, curly L, derivative version, integral version). These different levels are introduced on the fly, which makes it harder to grasp. The fact that there are many duplicate notations for the same quantities does not help the reader. For instance u_0 becomes equal to u_N at one point (above Eq 25). Another example is the constant flipping between integrated and 'current input' pictures. So laying out the multiple layers early, making a table or a figure for the notation, or sticking with one level would help convey the idea to a wide readership.</p></disp-quote><p>Thanks for the hints. We included the table you suggested, but put it to the SI as it became a full page itself. We banned the curly L abbreviating the look-ahead operator.</p><p>The “change of notation” you are alluding to is tricky, though. In a recurrent layer, the index of the output neuron is called o. In a forward network with N layer, the index of the output neurons becomes the last layer N. One has to introduce the layer index l anway for the deeper layers l &lt; N, and we found it more consistent to explain that, while switching from the recurrent to the forward network, the voltage of the output layer becomes now u_o = u_N. There are more of these examples, like the weight matrix W splitting into a intrinsic network part W_net across which errors backpropagate, and a part conveying the input, W_in, that has to be excluded when writing the backpropagation formula for general networks. Again, in the case of the feedforward networks, the notation reduces to W_l, with index l coding for the layer. Presenting the general approach and a specific example may appear as we would duplicate notations – we haven’t found a solution here.</p><disp-quote content-type="editor-comment"><p>(3) Separate the algorithm from the implementation level. I particularly struggled with separating the ideas that belonged to the algorithm level (cost function, optimization objectives) and the biophysics. The two are interwoven in a way that does not have to be. Particularly, some of the normative elements may be implemented by other types of biophysics than the authors have in mind. It is for this reason that I think that separating more clearly what belongs to the implementation and algorithm levels would help make the ideas more widely understood. On this point, a trigger point for me was the definition of the 'prospective input rates' e_i, which comes in the second paragraph.</p></disp-quote><p>We are very sorry to have made you thinking that the 'prospective input rates' would be e_i. The prospective input rates are r_i. The misunderstanding likely appeared by an unclear formulation from our side that is now corrected (see first and second paragraph of the Results where we introduce r_i and e_i).</p><disp-quote content-type="editor-comment"><p>From a biophysical perspective, it is quite arbitrary to define the input to be the difference between the basal input and the somatic (prospective) potential. It sounds like it comes from some unclear normative picture at this point. But the authors seem to have in mind to use the fact that the somatic potential is the sum of apical and basal input, that's the biophysical picture.</p></disp-quote><p>We hope to have disentangled the normative and biophysical view in the 2nd and 3rd paragraph of the Results, respectively. We introduce the prospective error ei as abstract notion in the first paragraph, while explaining that it will be interpreted as somato-dendritic mismatch error in neuron I in the next paragraph. The second paragraph contains the biophysical details with the apical and basal morphology.</p><disp-quote content-type="editor-comment"><p>(4) Experts and non-expert would appreciate an explanation of why/how the choice of state variables matters in the NLA. The prospective coding state variables cannot be said to be the naïve guess. Why does the simple u, dot{u} not work as state variables applied on the same energy function, as would be a naïve application of the Lagrangian ideas?</p></disp-quote><p>We are very glad for this hint to present an intuition behind the variation of the action with respect to a prospective state, instead of the state itself. The simple L(u, dot{u}) does not work because one does not obtain the first-order voltage dynamics compatible with the biophysics. We made an effort to explain the intuition to non-experts and experts in an additional paragraph right after presenting the voltage and error dynamics (Eq. 7 on page 4).</p><p>Here is how the paragraph starts (not displaying the formulas here):</p><p>“From the point of view of theoretical physics, where the laws of motion derived from the least-action principle contain an acceleration term (as in Newton's law of motion, like … for a harmonic oscillator), one may wonder why no second-order time derivative appears in the NLA dynamics. As an intuitive example, consider driving into a bend. Looking ahead in time helps us to reduce the lateral acceleration by braking early enough, as opposed to braking only when the lateral acceleration is already present. This intuition is captured by minimizing the neuronal action A with respect to the discounted future voltages ũi instead of the instantaneous voltages ui.</p><p>Keeping up an internal equilibrium in the presence of a changing environment requires to look ahead and compensate early for the predicted perturbations.</p><p>Technically, …”</p><p>More details are given in the Methods after Eq. 20. Moreover, in the last part of the SI, Sect. F, we have made the link to the least-action principle in physics more explicitly. There we show how the voltage dynamics can be derived from the physical least-action principle by including the Rayleigh dissipation (Eq. 92 and 95).</p><disp-quote content-type="editor-comment"><p>(5) Specify that the learning rules have not been observed. Though the learning rules are Hebbian, the details of the rules have not to my knowledge been observed. Would be worth mentioning as this is a sticking point of most related theories.</p></disp-quote><p>We agree, and we do now explicitly write in the Discussion that the learning rule still awaits to be experimentally tested.</p><disp-quote content-type="editor-comment"><p>1. Some relevant literature. Chalk et al. PNAS (2018) have explored the relationship between temporal predictive coding and Rao &amp; Ballard predictive coding based on the parameters of the cost function. Harkin et al. eLife (2023) have shown that 'prospective coding' also takes place in the serotonergic system, while Kim ... Ma (2021) have put forward similar ideas for dopamine, both may participate in setting the cost function. Instantaneous voltage propagation is also a focus of Greedy et al. (2023). The authors cite Zenke et al. for spiking error propagation, but there are biological references to that end.</p></disp-quote><p>Thanks much for these hints. We do now cite the book of Gerstner &amp; Kistler on spiking neurons, and more specifically the spike-based approach for learning to represent signals (Brendel, .., Machens, Denève, PLoS CB, 2020). Otherwise, we had difficulties to incorporate the other literature that seems to us not directly related to our approach, even when related notions come up like predictive coding and temporal processing in Chalk et al. (2018), where various temporal coding schemes coding efficiency is studied as a function of the signal-to-noise ratio, or the apical activities in Greedy et al. (2022), where bursting, multiplexing and synaptic facilitation arises. We found it would confuse more than it would help if we would cite these papers too (we do already cite 95 papers).</p><disp-quote content-type="editor-comment"><p>(7) In the main text, theorem two is presented as proof without assumptions on the level of nudging, but the actual proof uses strong assumptions in that respect, relying on numerical ad hoc observations for the general case.</p></disp-quote><p>Thanks for pointing this out. We agree it is a better style to state all the critical assumptions in Theorem itself, rather than deferring them to the Methods. We now state: “Then, for suitable top-down nudging, learning rates, and initial conditions, the ….weights …evolve such that…”.</p><disp-quote content-type="editor-comment"><p>(8) In the discussion regarding error-backpropagation, it seems to me that it could be clarified that the current algorithm asks for a weight alignment between FF and FB matrices as well as between FB and interneuron circuit matrices. Whether all of these matrices can be learned together remains to be shown; neither Akrout, Kunin nor Max et al. have shown this explicitly. Particularly when there are other inputs to the apical dendrites from other areas.</p></disp-quote><p>Yes, it is difficult to learn to align all in parallel. Nevertheless, our simulations in fact do align the lateral and vertical circuits, at is also claimed in Theorem 2. Yet, as specified in the theorem, “for suitable learning rates” (that were all the same, but were commonly reduced after some training time, as previously explained in the Methods, Details for Fig. 5).</p><p>In the Discussion we now emphasis that, in general, simulating all the circuitries jointly from scratch in a single phase is tricky. We write:</p><p>“A fundamental difficulty arises when the neuronal implementation of the Euler-Lagrange equations requires an additional microcircuit with its own dynamics. This is the case for the suggested microcircuit extracting the local errors. Formally, the representation of the apical feedback errors first needs to be learned before the errors can teach the feedforward synapses on the basal dendrites. We showed that this error learning can itself be formulated as minimizing an apical mismatch energy. What the lateral feedback through interneurons cannot explain away from the top-down feedback remains as apical prediction error.</p><p>Ideally, while the network synapses targetting the basal tree are performing gradient descent on the global cost, the microcircuit synapses involved in the lateral feedback are performing gradient descent on local error functions, both at any moment in time.</p><p>The simulations show that this intertwined system can in fact learn simultaneously with a common learning rate that is properly tuned. The cortical model network of inter- and pyramidal neurons learned to classify handwritten digits on the fly, with 10 digit samples presented per second. Yet, the overall learning is more robust if the error learning in the apical dendrites operates in phases without output teaching but with corresponding sensory activity, as may arise during sleep (see e.g. Deperrois et al., 2022 and 2023).”</p><disp-quote content-type="editor-comment"><p>(9) The short-term depression model is assuming a slow type of short-term depression, not the fast types that are the focus of much recent experimental literature (like Campagnola et al. Science 2022).</p><p>This assumption should be specified.</p></disp-quote><p>Thanks for hinting to this literature that we were not aware of. We are now citing the releaseindependent plasticity (Campagnola et al. 2022) in the context of our synaptic depression model.</p><disp-quote content-type="editor-comment"><p>(10) There seems to be a small notation issue: Eq 21 combines vectors of the size of the full network (bar{e}) and the size of the readout network (bar{e}star).</p></disp-quote><p>Well, for notational convenience we set the target error to e*=0 for non-output neurons. This way we can write the total error for an arbitrary network neuron as the sum of the backpropagated error plus the putative target error (if the neuron is an output neuron). Otherwise we would always have to distinguish between network neuron that may be output neurons, and those that are not. We did say this in the main text, but are repeating it now again right after Eq. 21. -- Notations are often the result of a tradoff.</p></body></sub-article></article>