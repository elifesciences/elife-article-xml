<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">65540</article-id><article-id pub-id-type="doi">10.7554/eLife.65540</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Dynamic decision policy reconfiguration under outcome uncertainty</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-206964"><name><surname>Bond</surname><given-names>Krista</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1492-6798</contrib-id><email>kbond@andrew.cmu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-220775"><name><surname>Dunovan</surname><given-names>Kyle</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7857-5133</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-220776"><name><surname>Porter</surname><given-names>Alexis</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-47130"><name><surname>Rubin</surname><given-names>Jonathan E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1513-1551</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-34236"><name><surname>Verstynen</surname><given-names>Timothy</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4720-0336</contrib-id><email>timothyv@andrew.cmu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Psychology, Carnegie Mellon University</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Center for the Neural Basis of Cognition</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Carnegie Mellon Neuroscience Institute</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution>Department of Psychology, Northwestern University</institution><addr-line><named-content content-type="city">Evanston</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>Department of Mathematics, University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution>Department of Biomedical Engineering, Carnegie Mellon University</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>O'Connell</surname><given-names>Redmond G</given-names></name><role>Reviewing Editor</role><aff><institution>Trinity College Dublin</institution><country>Ireland</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Radboud University</institution><country>Netherlands</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>24</day><month>12</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e65540</elocation-id><history><date date-type="received" iso-8601-date="2020-12-07"><day>07</day><month>12</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-12-23"><day>23</day><month>12</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Bond et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Bond et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-65540-v2.pdf"/><abstract><p>In uncertain or unstable environments, sometimes the best decision is to change your mind. To shed light on this flexibility, we evaluated how the underlying decision policy adapts when the most rewarding action changes. Human participants performed a dynamic two-armed bandit task that manipulated the certainty in relative reward (conflict) and the reliability of action-outcomes (volatility). Continuous estimates of conflict and volatility contributed to shifts in exploratory states by changing both the rate of evidence accumulation (drift rate) and the amount of evidence needed to make a decision (boundary height), respectively. At the trialwise level, following a switch in the optimal choice, the drift rate plummets and the boundary height weakly spikes, leading to a slow exploratory state. We find that the drift rate drives most of this response, with an unreliable contribution of boundary height across experiments. Surprisingly, we find no evidence that pupillary responses associated with decision policy changes. We conclude that humans show a stereotypical shift in their decision policies in response to environmental changes.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>conflict</kwd><kwd>volatility</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006602</institution-id><institution>Air Force Research Laboratory</institution></institution-wrap></funding-source><award-id>FA9550-18-1-0251</award-id><principal-award-recipient><name><surname>Bond</surname><given-names>Krista</given-names></name><name><surname>Verstynen</surname><given-names>Timothy</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A suspected change in action-outcome contingencies evokes a stereotyped response in the processes underlying a decision, resulting in a slow exploratory decision policy that gradually shifts to an exploitative policy as the environment remains stable.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>‘Should I stay or should I go?‘ refers not only to an iconic 1980s punk anthem but also the fundamental dilemma all animals face in uncertain or unstable environments. Should someone buy coffee from the cafe that serves their favorite roast or try the new cafe that opened down the street? If their favorite drink is bitter one day, is that a sign to switch to a new blend or is one subpar experience inadequate to prompt a switch? Ultimately, these decisions converge to a single predicament: whether we choose an action that we believe is likely to produce desirable results (i.e. exploit) or risk choosing another action that is less certain, on the chance that it will produce a more positive outcome (i.e. explore) (<xref ref-type="bibr" rid="bib56">O’Reilly, 2013</xref>). Ultimately, this is the problem of knowing when to change your mind.</p><p>The shift of a decision policy from exploratory to exploitative states is driven by environmental context. To illustrate this, <xref ref-type="fig" rid="fig1">Figure 1A</xref> shows what happens when a simple reinforcement learning (RL) agent tries to maximize reward in a dynamic variant of the two-armed bandit task (<xref ref-type="bibr" rid="bib72">Sutton and Barto, 1998</xref>; see Materials and methods). Here, the relative difference in reward probability for the two actions (conflict) and the frequency of a change in the optimal action (volatility) were independently manipulated. For each level of conflict and volatility, a set of tabular Q-learning (<xref ref-type="bibr" rid="bib72">Sutton and Barto, 1998</xref>) agents played the task with learning rate held constant while the degree of randomness of the selection policy (<inline-formula><mml:math id="inf1"><mml:mi>β</mml:mi></mml:math></inline-formula> in a Softmax function) varied. The agent that returned the most rewards was identified as the agent with the best exploration-exploitation balance. Increasing either form of uncertainty led to selecting agents with more random or exploratory selection policies (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). As the value of the optimal choice decreases relative to the value of a suboptimal choice (conflict increases), the learner exploits what she already knows. Action values grow unstable (volatility increases) when the clarity of the optimal choice is constant (constant conflict), and the learner is biased toward exploration (<xref ref-type="bibr" rid="bib9">Bland and Schaefer, 2012</xref>). As these two forms of uncertainty change together, the gradient of action selection strategy also changes.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Dynamic decision policy reconfiguration.</title><p>(<bold>A</bold>) The degree of conflict and volatility shifts the optimal balance between exploration and exploitation. (<bold>B</bold>) The drift diffusion model. (<bold>C</bold>) Accuracy (probability that left choice selected is selected; P(L)) as a function of coordinated changes in the rate of evidence accumulation (v) and the amount of information needed to make a decision, or the boundary height (a). (<bold>D</bold>) Reaction time as a function of changes in the rate of evidence accumulation and the boundary height. (<bold>E</bold>) Decision policy reconfiguration.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig1-v2.tif"/></fig><p>Knowing <italic>how</italic> decision policies shift in the face of dynamic environments requires looking at the algorithmic properties of the policy itself. One popular set of algorithms for describing the dynamics of decision making are accumulation-to-bound processes like the drift-diffusion model (DDM; <xref ref-type="bibr" rid="bib62">Ratcliff, 1978</xref>). The normative form of the DDM proposes that a decision between two choices is described by a noisy accumulation process that drifts toward one of two decision boundaries at a specific rate (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Two parameters of this model are critical in determining the degree of randomness of a selection policy: the rate of evidence accumulation (drift rate; <inline-formula><mml:math id="inf2"><mml:mi>v</mml:mi></mml:math></inline-formula>) and the amount of information required to make a decision (boundary height; <inline-formula><mml:math id="inf3"><mml:mi>a</mml:mi></mml:math></inline-formula>). For example, decreasing the drift rate and increasing the boundary height leads to more random decisions (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), with the speed of these decisions depending on the ratio of the two parameters (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Thus, exploratory policies can result in either fast or slow decisions, depending on the relative configuration of drift rate and boundary height.</p><p>Are the parameters that govern accumulation of evidence for decision making modifiable? Previous modeling work has shown that the parameters of a DDM process can be modulated by feedback signals and choice history (<xref ref-type="bibr" rid="bib59">Pedersen et al., 2017</xref>; <xref ref-type="bibr" rid="bib63">Ratcliff and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib24">Dunovan and Verstynen, 2019</xref>; <xref ref-type="bibr" rid="bib25">Dunovan et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Mendonça et al., 2020</xref>; <xref ref-type="bibr" rid="bib76">Urai et al., 2018</xref>) with different mechanisms for adapting the drift rate and the boundary height. In value-based decision-making tasks where the statistics of sensory signals are equivalent for all actions, drift rate fluctuations appear to track the relative value of an action or the value difference between actions (<xref ref-type="bibr" rid="bib25">Dunovan et al., 2019</xref>; <xref ref-type="bibr" rid="bib49">Mikhael and Bogacz, 2016</xref>; <xref ref-type="bibr" rid="bib6">Bariselli et al., 2019</xref>; <xref ref-type="bibr" rid="bib65">Rubin et al., 2021</xref>). In contrast to value estimation, selection errors in this context have been linked to changes in the boundary height (<xref ref-type="bibr" rid="bib27">Forstmann et al., 2008</xref>; <xref ref-type="bibr" rid="bib28">Forstmann et al., 2010</xref>; <xref ref-type="bibr" rid="bib12">Bogacz et al., 2010</xref>; <xref ref-type="bibr" rid="bib34">Herz et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Herz et al., 2017</xref>; <xref ref-type="bibr" rid="bib25">Dunovan et al., 2019</xref>; <xref ref-type="bibr" rid="bib24">Dunovan and Verstynen, 2019</xref>) and internal estimates of environmental change (<xref ref-type="bibr" rid="bib54">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib84">Wilson and Niv, 2011</xref>; <xref ref-type="bibr" rid="bib55">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib8">Behrens et al., 2007</xref>).</p><p>Given the adaptive sensitivity of the drift rate and the boundary height to value estimation and selection, respectively, these decision parameters define unique states on a surface of fast or slow and exploratory or exploitative decision policies. These policies, in turn, adaptively reconfigure based on current environmental feedback signals by modulating value estimation and the rate of selection errors (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). Agents can move along the surface of decision policies, from exploitative states (bright colors, <xref ref-type="fig" rid="fig1">Figure 1E</xref>) to different types of exploratory states (darker colors, <xref ref-type="fig" rid="fig1">Figure 1E</xref>), as they commit a greater number of selection errors prompted by change in action-outcome contingencies. As the system relearns properties of the environment, the decision policy migrates along the surface to return to an exploitative state until a change occurs again.</p><p>One plausible neural mechanism for this migration along the surface of selection policies is the locus coereleus norepinephrine (LC-NE) system, which has been linked to adaptive behavioral variability in response to uncertainty (<xref ref-type="bibr" rid="bib75">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Dayan and Yu, 2006</xref>; <xref ref-type="bibr" rid="bib16">Bouret and Sara, 2005</xref>). The LC-NE system has two distinct modes (<xref ref-type="bibr" rid="bib3">Aston-Jones and Bloom, 1981</xref>) that map onto distinct decision states (<xref ref-type="bibr" rid="bib5">Aston-Jones and Cohen, 2005</xref>). In the phasic mode, a burst of LC activity results in a global, temporally precise release of NE. This increases the gain on cortical processing and encourages exploitation. In the tonic mode, NE is released without the temporal precision of the phasic mode, increasing baseline NE (<xref ref-type="bibr" rid="bib3">Aston-Jones and Bloom, 1981</xref>). This encourages disengagement from the current task and facilitates exploration. The dynamic fluctuation of these two modes is thought to optimize the trade-off between the exploitation of stable sources of reward and the exploration of potentially better options (<xref ref-type="bibr" rid="bib5">Aston-Jones and Cohen, 2005</xref>). Thus the LC-NE system, which can be indirectly measured by fluctuations in pupil diameter (<xref ref-type="bibr" rid="bib5">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib40">Jepma and Nieuwenhuis, 2011</xref>), may be a central mechanism for modulating selection policies.</p><p>We investigated the malleability of decision policies as the environment necessitates a change of mind as to what constitutes the ‘best’ decision. To control environmental uncertainty, we manipulated the volatility of changes in action-outcome contingencies (i.e. which of two targets returns the most rewards), as well as ambiguity in optimal choice (<italic>conflict</italic>), while human participants performed a dynamic variant of the two-armed bandit task (<xref ref-type="bibr" rid="bib73">Sutton and Barto, 2018</xref>). We predicted that, in response to suspected changes in action-outcome contingencies, humans would exhibit a stereotyped adjustment in the drift rate and boundary height that pushes decisions from certain, exploitative states to uncertain, exploratory states and back again (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). In addition, using pupillary data, we explored whether the LC-NE system covaries with shifts of the boundary height in response to a change in action outcomes to facilitate exploration, consistent with prior studies (<xref ref-type="bibr" rid="bib43">Keung et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Murphy et al., 2014</xref>; <xref ref-type="bibr" rid="bib20">Cavanagh et al., 2014</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Across two experiments, we used a dynamic two-armed bandit task with equivalent sensory reliability across arms to independently manipulate the reward conflict and the volatility of action outcomes in order to measure how underlying decision processes respond to changes in action-outcome contingencies (see Stimuli and Procedure). Both of these experiments shared a common feedback structure. Participants were asked to select either the left or right target presented on the screen using the corresponding key on a response box. Rewards were probabilistically determined for each target and, if a reward was delivered, it was sampled from a Gaussian distribution. The optimally rewarding target delivered reward with a predetermined probability (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) and the suboptimal target gave reward with the inverse probability (<inline-formula><mml:math id="inf5"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>). After a delay determined by the rate parameter of a Poisson distribution (<inline-formula><mml:math id="inf6"><mml:mi>λ</mml:mi></mml:math></inline-formula>), the reward probabilities for the optimal and suboptimal targets would switch.</p><p>In Experiment 1, 24 participants completed four sessions (high and low conflict; high and low volatility) each composed of 600 trials. During each session, they were asked to select one of two coin boxes (Exp. 1: <xref ref-type="fig" rid="fig2">Figure 2A</xref>). The levels of conflict and volatility for all four conditions in Experiment 1 are shown as gray dots in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. Experiment 2 was a replication of Experiment 1 with more extensive within-subject sampling of conflict and volatility, as well as the inclusion of pupilometry as a proxy for measuring LC-NE dynamics. In Experiment 2, participants were asked to choose between one of two Greebles (one male, one female). Each Greeble probabilistically delivered a monetary reward (Exp. 2: <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Participants were trained to discriminate between male and female Greebles prior to testing to prevent errors in perceptual discrimination from interfering with selection on the basis of value estimation. Four participants completed nine sessions composed of 400 trials each, generating 3600 trials in total per subject. The levels of conflict and volatility for all nine conditions in Experiment 2 are shown as black dots in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. Importantly, Experiment 2 manipulated the same forms of uncertainty as Experiment 1, but had different perceptual features and more expansively sampled the space of conflict and volatility. Given the similarity in design, the behavioral results for both of these experiments are presented together below.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Task and uncertainty manipulation.</title><p>(<bold>A</bold>) In Experiment 1, participants were asked to choose between one of two ‘mystery boxes’. The point value associated with a selection was displayed above the chosen mystery box. The sum of points earned across trials was shown to the left of a treasure box on the upper right portion of the screen. (<bold>B</bold>) In Experiment 2, participants were asked to choose between one of two Greebles (one male, one female). The total number of points earned was displayed at the center of the screen. The stimulus display was rendered isoluminant throughout the task. (<bold>C</bold>) The manipulation of conflict and volatility for Experiments 1 (gray) and 2 (black). Each point represents the combination of degrees of conflict and volatility. Under high conflict, the probability of reward for the optimal and suboptimal target is relatively close. Under high volatility, a switch in the identity of the optimal target selection is relatively frequent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig2-v2.tif"/></fig><sec id="s2-1"><title>The influence of ambiguity and instability on speed and accuracy</title><p>We first looked at overall speed and accuracy effects in both Experiments 1 and 2. In Experiment 1, accuracy (i.e. optimal choice selection) suffered as the optimal choice grew more ambiguous, with accuracy in the low conflict condition being 1.2 times higher than what is observed in the high conflict condition (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>1.213</mml:mn></mml:mrow></mml:math></inline-formula>, 95% CI: 1.192, 1.235, z = 21.36, p &lt; 2e-16). In contrast, increasing conflict had no observable impact on overall reaction times (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>6.902</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mo>-</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, 95% CI: –0.002, 0.002, t = −0.06, p = 0.951). As expected, participants also became less accurate as the instability of action outcomes (i.e. volatility) grew (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; <inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.092</mml:mn></mml:mrow></mml:math></inline-formula>, 95% CI: 0.077, 0.111, z = 10.36, p &lt; 2e-16). Under volatile conditions, participants also took slightly longer to make a decision (<inline-formula><mml:math id="inf10"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.012</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, 95% CI: –0.015,–.010, t = −10.80, p &lt; 2e-16); however, while this effect on reaction times was statistically reliable, the impact of volatility on reaction times was weak (increasing volatility increased reaction time by ∼13 ms on average; <xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Behavior.</title><p>(<bold>A</bold>) Mean accuracy and reaction time for the manipulation of conflict in Experiment 1. (<bold>B</bold>) Mean accuracy and reaction time for the manipulation of volatility in Experiment 1. Each point represents the average for a single subject. The distribution to the right represents the bootstrapped uncertainty in the mean difference between conditions (high conflict or high volatility subtracted from low conflict or low volatility). Distributions with 95% CIs that do not encompass 0 are marked with an asterisk. (<bold>C</bold>) Mean accuracy for Experiment 2. Each purple line represents a subject. The black line represents the mean accuracy calculated across subjects. (<bold>D</bold>) Reaction time distributions for each subject for Experiment 2. The black line represents the mean reaction time calculated over subjects. Error bars indicate a bootstrapped 95% confidence interval. For panels C and D, <inline-formula><mml:math id="inf11"><mml:mi>λ</mml:mi></mml:math></inline-formula> values shown above each plot specify the average period of optimal choice stability and the probability of reward shown on the x-axis specifies the degree of conflict. Means are calculated over all trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig3-v2.tif"/></fig><p>Experiment 2 served as a high powered test of whether the effects we observed in Experiment 1 were replicable at the within-subject level. Because Experiment 2 independently manipulated conflict and volatility, we were able to test whether conflict and volatility interacted to affect behavior. We found similar effects of conflict and volatility on accuracy as we observed in Experiment 1 (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Accuracy increased as conflict decreased (i.e. as the probability of reward increased; <inline-formula><mml:math id="inf12"><mml:mi>β</mml:mi></mml:math></inline-formula>=0.223, 95% CI = 0.189,0.256, z = 12.757, p&lt;2e-16). As the environment grew less volatile, accuracy increased (<inline-formula><mml:math id="inf13"><mml:mi>β</mml:mi></mml:math></inline-formula> = 0.101, 95% CI = 0.066,0.14, z = 5.828, p = 5.6e-09). We did not observe an interaction of conflict and volatility on accuracy (<inline-formula><mml:math id="inf14"><mml:mi>β</mml:mi></mml:math></inline-formula> = 0.024, 95% CI = −0.013, 0.058, z = 1.364, p = 0.173).</p><p>However, we did find that conflict and volatility interacted to affect reaction time (RT; <inline-formula><mml:math id="inf15"><mml:mi>β</mml:mi></mml:math></inline-formula>=−0.002, 95% CI = −0.004, –0.001, t = −3.084, p = 0.002), with a linear increase in reaction time as the environment grew less volatile and conflict was highest (when <inline-formula><mml:math id="inf16"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.65</mml:mn></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mn>0.472</mml:mn><mml:mo>,</mml:mo><mml:mn>0.480</mml:mn><mml:mo>,</mml:mo><mml:mn>0.493</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> as a function of <inline-formula><mml:math id="inf17"><mml:mi>λ</mml:mi></mml:math></inline-formula>; see <xref ref-type="fig" rid="fig3">Figure 3D</xref> for RT distributions). When conflict was moderate (<inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) or low (<inline-formula><mml:math id="inf19"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.85</mml:mn></mml:mrow></mml:math></inline-formula>), volatility had a nonlinear effect on RTs. Here, reaction times decreased when volatility was moderate (<inline-formula><mml:math id="inf20"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.483</mml:mn></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf21"><mml:mi>λ</mml:mi></mml:math></inline-formula>=20 and <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf23"><mml:mi>λ</mml:mi></mml:math></inline-formula>=20 and <inline-formula><mml:math id="inf24"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.85</mml:mn></mml:mrow></mml:math></inline-formula>). Reaction times increased to approximately the same extent within moderate or low conflict conditions when volatility was high (<inline-formula><mml:math id="inf25"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.499</mml:mn></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf26"><mml:mi>λ</mml:mi></mml:math></inline-formula>=10 and <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf28"><mml:mi>λ</mml:mi></mml:math></inline-formula>=10 and <inline-formula><mml:math id="inf29"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.85</mml:mn></mml:mrow></mml:math></inline-formula>) and when volatility was low (<inline-formula><mml:math id="inf30"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.506</mml:mn></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.85</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), with an increase in baseline reaction times when conflict was low relative to moderate (<inline-formula><mml:math id="inf35"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.527</mml:mn></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.85</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> when <inline-formula><mml:math id="inf37"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula>; see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> for interaction visualization).</p><p>At the gross level, over all trials within an experimental condition, increasing the ambiguity of the optimal choice (conflict) and increasing the instability of action outcomes (volatility) decreases the probability of selecting the optimal choice. Reaction time effects were inconsistent, with a negligible effect of volatility in Experiment 1. Experiment two revealed that volatility and conflict interact to influence reaction times in complex ways. However, because trials where action-outcome contingencies change are so infrequent, even under high volatility conditions, these overall effects on speed and accuracy may be masking more subtle behavioral dynamics in response to feedback changes. We adopt a more focal, model-based analysis in the next section to clarify these peri-change point dynamics.</p></sec><sec id="s2-2"><title>Tracking estimates of action value and environmental volatility</title><p>We calculated trial-by-trial estimates of two ideal observer parameters of environmental states (see Cognitive model for calculation details; <xref ref-type="bibr" rid="bib54">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib77">Vaghi et al., 2017</xref>). Belief in the value difference (<inline-formula><mml:math id="inf38"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula>) reflects the difference between the learned values of the optimal and suboptimal targets. For ease of interpretation, we refer to the converse of belief as doubt, such that when belief decreases doubt increases. <inline-formula><mml:math id="inf39"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> thus reflects a local estimate of uncertainty regarding the choices themselves. To capture the estimated probability of fundamental shifts in action values, we calculated how often the same action gave a different reward (change point probability; <inline-formula><mml:math id="inf40"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>). Here, <inline-formula><mml:math id="inf41"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> reflects a global estimate of uncertainty in the environment, specifically the uncertainty in response contingencies. We used the data from Experiment 1 to assess how well these learning estimates captured our imposed manipulations, and observed similar results in Experiment 2 (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>).</p><p>In Experiment 1, we observed a sharp decrease in <inline-formula><mml:math id="inf42"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> after a switch in action outcomes and a gradual return to asymptotic values (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) with a decreased difference in reward probability resulting in increased doubt (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; <inline-formula><mml:math id="inf43"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.216</mml:mn></mml:mrow></mml:math></inline-formula>, 95% CI:0.206, 0.224, t = 46.24, p &lt; 2e-16). As expected, less volatile conditions allowed the learner to more fully update her belief in the value of the optimal choice over all trials (<inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.058</mml:mn></mml:mrow></mml:math></inline-formula>, 95% CI:0.050, 0.068, t = 12.32, p &lt; 2e-16), though to a smaller degree than low conflict conditions allowed (see <xref ref-type="fig" rid="fig4">Figure 4B</xref>). Increasing volatility resulted in a sharp increase in the estimate of <inline-formula><mml:math id="inf45"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> at the onset of a change point with a quick return to a baseline estimate of change (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Notably, this estimate of <inline-formula><mml:math id="inf46"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> was more sensitive to change points when conditions were relatively volatile, with a more pronounced peak in response to a change under high volatility conditions than under low volatility conditions (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Correspondingly, over all trials, <inline-formula><mml:math id="inf47"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> was higher under more volatile conditions (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.022</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, 95% CI:−0.023,–0.020, t = −30.74, p &lt; 2e-16) indicating sensitivity to the increased frequency of action outcome switches in the reward schedule.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Changes in ideal observer estimates as a function of condition for Experiment 1.</title><p>(<bold>A</bold>) Changes in the belief in the value of the optimal target (<inline-formula><mml:math id="inf49"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula>) as a function of conflict and volatility over time. (<bold>B</bold>) Belief in the value of the optimal choice by condition and averaged over all trials. (<bold>C</bold>) Changes in change point probability (<inline-formula><mml:math id="inf50"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>) as a function of conflict and volatility over time. (<bold>D</bold>) Change point probability by condition and averaged over all trials. Error bars represent 95% CIs.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig4-v2.tif"/></fig><p>When the identity of the optimal choice was clear (i.e. when conflict was low), the estimate of <inline-formula><mml:math id="inf51"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> was more sensitive to the presence of a true change point than when the optimal choice was ambiguous (i.e. when conflict was high) (<xref ref-type="fig" rid="fig4">Figure 4C and D</xref>). This observation is consistent with the idea that increasing the difficulty of value estimation and, thereby, the assignment of value to a given choice also impairs change point sensitivity. Interestingly, increasing conflict nevertheless resulted in a net increase in <inline-formula><mml:math id="inf52"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> calculated over all trials (<xref ref-type="fig" rid="fig4">Figure 4D</xref>; <inline-formula><mml:math id="inf53"><mml:mi>β</mml:mi></mml:math></inline-formula>=−0.006, 95 %CI:−0.007,–0.004, t = −8.64, p &lt; 2e-16), likely because higher conflict conditions increased the baseline estimate of change instead of enhancing sensitivity to true change points (see change point response and relative baseline values for the high conflict condition in <xref ref-type="fig" rid="fig4">Figure 4C</xref>). Here, the system conservatively over-estimates the volatility of action outcomes, assuming a slightly greater frequency of changes in the probability of reward for the optimal choice than we imposed (actual proportion of change points for high conflict condition: <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.041</mml:mn><mml:mo>±</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; estimated <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><p>Reassuringly, net change point probability was much greater when change points were more frequent (see increased <inline-formula><mml:math id="inf56"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> estimates for high volatility conditions over high conflict conditions in <xref ref-type="fig" rid="fig4">Figure 4D</xref>). These results suggest that our formulation of these ideal observer estimates adequately captures our manipulation of volatility and conflict at a continuous level.</p><p>Thus, these ideal observer parameters show a reliable response to a change in action-outcome contingencies. The difference in value belief decreases, or doubt increases, when a change point occurs and slowly recovers over the course of six to eight trials as participants learn new action-outcome contingencies. The initial drop in belief difference is deeper and the recovery time after a change point is slower in conditions with greater overall uncertainty (i.e. under high conflict and high volatility). In contrast, internal estimates that a change has occurred briefly spike at a change point, indicating that participants can reliably detect that something has changed, and quickly settle after a few trials. Interestingly, net change point probability estimates are higher in the conditions with higher uncertainty (high conflict, high volatility), likely reflecting increased vigilance for changes in those conditions. In the next section, we explore how the underlying parameters of the decision process itself respond to local changes in action-outcome contingencies.</p></sec><sec id="s2-3"><title>Different forms of uncertainty impact distinct decision processes</title><p>Our next goal was to test which decision parameters were sensitive to a change point. To this end, we estimated the change point evoked response of the boundary height <inline-formula><mml:math id="inf57"><mml:mi>a</mml:mi></mml:math></inline-formula>, drift rate <inline-formula><mml:math id="inf58"><mml:mi>v</mml:mi></mml:math></inline-formula>, non-decision time <inline-formula><mml:math id="inf59"><mml:mi>t</mml:mi></mml:math></inline-formula>, starting bias <inline-formula><mml:math id="inf60"><mml:mi>z</mml:mi></mml:math></inline-formula>, and drift criterion <inline-formula><mml:math id="inf61"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula> for each trial surrounding the change point. To detect changes in the change-point-evoked distributions for each decision parameter, we evaluated whether the sequential distributions evoked by each trial were significantly different, beginning with the trial preceding the change point and ending three trials after the change point. For example, if the 95% CI of the <inline-formula><mml:math id="inf62"><mml:mi>z</mml:mi></mml:math></inline-formula> distribution evoked on the trial prior to the change point overlapped with the 95% CI of the distribution evoked on the change point and so on for all successive trials considered, then we would conclude that <inline-formula><mml:math id="inf63"><mml:mi>z</mml:mi></mml:math></inline-formula> failed to show change point sensitivity (see Hierarchical drift diffusion modeling for details). To select the model that best accounted for the data, we compared the deviance information criterion (DIC) scores (<xref ref-type="bibr" rid="bib70">Spiegelhalter et al., 2002</xref>) for these models. DIC scores provide a measure of model fit adjusted for model complexity and quantify information loss. A lower DIC score indicates a model that loses less information. Here, a difference of ≤ two points from the lowest-scoring model cannot rule out the higher scoring model; a difference of 3–7 points suggests that the higher scoring model has considerably less support; and a difference of 10 points suggests essentially no support for the higher scoring model (<xref ref-type="bibr" rid="bib70">Spiegelhalter et al., 2002</xref>; <xref ref-type="bibr" rid="bib17">Burnham and Anderson, 1998</xref>).</p><p>Under this analysis, we found that only the boundary height and drift rate showed change point sensitivity as defined above. The drift rate showed a clear, persistent separation between trial-specific distributions, with a rapid decrease at the onset of the change point (<inline-formula><mml:math id="inf64"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> 95% CI = 1.021, 1.218; <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>=−0.972, –0.779) and a return to baseline values thereafter (<inline-formula><mml:math id="inf66"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> = −0.656,,–0.46; <inline-formula><mml:math id="inf67"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>=0.039, 0.241; <inline-formula><mml:math id="inf68"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>=0.411, 0.616; <xref ref-type="fig" rid="fig5">Figure 5A</xref>). The boundary height showed a transient response to the change point, spiking (<inline-formula><mml:math id="inf69"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> 95% CI = 0.792, 0.819; <inline-formula><mml:math id="inf70"><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>=0.820, 0.847) and then dropping to baseline levels (<inline-formula><mml:math id="inf71"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> = 0.789, 0.815; <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>=0.783, 0.811; <inline-formula><mml:math id="inf73"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>=0.780, 0.808; <xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Change point sensitivity of underlying decision processes.</title><p>Posterior distributions for each decision parameter are shown for the trial prior to a change point to three trials after the change point. (<bold>A</bold>) The drift rate. (<bold>B</bold>) The boundary height. (<bold>C</bold>) Non-decision (onset) time. (<bold>D</bold>) Starting bias. (<bold>E</bold>) Drift criterion. (<bold>F</bold>) Degree of fit to observational data as information loss. The models that lost the least information are marked with an asterisk.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig5-v2.tif"/></fig><p>The remainder of the decision parameters showed no change point sensitivity. Non-decision time showed no clear response (<inline-formula><mml:math id="inf74"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> 95% CI = 0.183, 0.188; <inline-formula><mml:math id="inf75"><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>=0.183, 0.186; <inline-formula><mml:math id="inf76"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>=0.184, 0.191; <inline-formula><mml:math id="inf77"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>=0.181, 0.186; <inline-formula><mml:math id="inf78"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>=0.183, 0.186; <xref ref-type="fig" rid="fig5">Figure 5C</xref>) along with the starting bias (<inline-formula><mml:math id="inf79"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> 95% CI = −0.112,,–0.01; <inline-formula><mml:math id="inf80"><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>=−0.098, 0.002; <inline-formula><mml:math id="inf81"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>=−0.090, 0.008; <inline-formula><mml:math id="inf82"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>=−0.069, 0.032; <inline-formula><mml:math id="inf83"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>=−0.055, 0.045; <xref ref-type="fig" rid="fig5">Figure 5D</xref>) and the drift criterion (<inline-formula><mml:math id="inf84"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> 95% CI = 0.229, 0.439; <inline-formula><mml:math id="inf85"><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>=0.175, 0.374; <inline-formula><mml:math id="inf86"><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>=0.223, 0.435; <inline-formula><mml:math id="inf87"><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>=0.245, 0.458; <inline-formula><mml:math id="inf88"><mml:msub><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula>=0.244, 0.464; <xref ref-type="fig" rid="fig5">Figure 5E</xref>).</p><p>Further, models fitting drift rate and boundary height lost the least null-model-adjusted information relative to models of the change-point-evoked response for the other parameters, showing that a change-point-evoked decrease in drift rate and spike in the boundary height best accounted for our observational data in comparison to all alternatives (<inline-formula><mml:math id="inf89"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf90"><mml:mi>v</mml:mi></mml:math></inline-formula> = –978 and <inline-formula><mml:math id="inf91"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf92"><mml:mi>a</mml:mi></mml:math></inline-formula> = –13.7; see <xref ref-type="fig" rid="fig5">Figure 5F</xref>).</p><p>Given that only the drift rate and boundary height showed change point sensitivity, we next focused on how those two parameters related to internal estimates of change and conflict in both experiments. Recall that we used the ideal observer parameters <inline-formula><mml:math id="inf93"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf94"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> as proxies for internal estimates of belief in the difference in learned target values and change point probability, respectively. This provided a continuous quantification of our manipulation of conflict and volatility (see Tracking estimates of action value and environmental volatility). Experiment 2 provided an intensively sampled within-subject test of the change-point-evoked mapping between decision processes and these ideal observer estimates.</p><p>In order to determine the nature of the mapping between the ideal observer parameters and the change-point sensitive decision parameters, we estimated single and dual-parameter models mapping <inline-formula><mml:math id="inf95"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf96"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> and the change-point-sensitive decision parameters, drift rate and boundary height, and examined the fit of these models to our data. We found that the model mapping <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> to drift rate and <inline-formula><mml:math id="inf98"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> to boundary height provided the best fit in Experiment 1 (<inline-formula><mml:math id="inf99"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>2698.0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; left panel of <xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Model comparison for Experiments 1 and 2.</title><p>Roman numerals refer to a given model, as defined by the mapping between the ideal observer estimates and decision parameters in the first two columns. The left panel shows the deviance information criterion (DIC) scores for the set of models considered during the model selection procedure for Experiment 1. The right panel shows the DIC scores for the equivalent model selection analysis for Experiment 2, with a model estimated for each of four subjects. Values shown represent the mean and standard deviation computed over subjects. Note that the raw DIC values for each of the subjects in Experiment 2 are included in <xref ref-type="table" rid="app3table1">Appendix 3—table 1</xref>. The column labeled DIC gives the raw DIC score, <inline-formula><mml:math id="inf100"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> lists the change in model fit from an intercept-only model (the null-adjusted fit), and <inline-formula><mml:math id="inf101"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> provides the change in null-adjusted model fit from the best-fitting model. The best performing model is denoted by an asterisk, with equivocal best cases marked by a tilde.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="6" valign="bottom">Experiment 1</th></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">DIC</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mtext>DIC</mml:mtext><mml:mrow><mml:mtext>null</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>D</mml:mi><mml:mi>I</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">*I</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf106"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf107"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="bottom">–18643.9</td><td align="char" char="." valign="bottom">–2698.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="left" valign="bottom">II</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf108"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf109"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="bottom">–16265.6</td><td align="char" char="." valign="bottom">–319.7</td><td align="char" char="." valign="bottom">2378.3</td></tr><tr><td align="left" valign="bottom">III</td><td align="left" valign="bottom">–</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf110"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="bottom">–16180.5</td><td align="char" char="." valign="bottom">–234.7</td><td align="char" char="." valign="bottom">2463.3</td></tr><tr><td align="left" valign="bottom">IV</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf111"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">–</td><td align="char" char="." valign="bottom">–18630.8</td><td align="char" char="." valign="bottom">–2684.9</td><td align="char" char="." valign="bottom">13.1</td></tr><tr><td align="left" valign="bottom">V</td><td align="left" valign="bottom">–</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf112"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="bottom">–15949.20</td><td align="char" char="." valign="bottom">–3.4</td><td align="char" char="." valign="bottom">2694.7</td></tr><tr><td align="left" valign="bottom">VI</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf113"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">–</td><td align="char" char="." valign="bottom">–16032.8</td><td align="char" char="." valign="bottom">–87.0</td><td align="char" char="." valign="bottom">2611.1</td></tr><tr><td align="left" valign="bottom">VII</td><td align="left" valign="bottom">–</td><td align="left" valign="bottom">–</td><td align="char" char="." valign="bottom">–15945.8</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">2698.0</td></tr><tr><th align="left" colspan="5" valign="bottom">Experiment 2</th></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><inline-formula><mml:math id="inf114"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf115"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf116"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mtext>null</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf117"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mtext>best</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">*∼I</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf118"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf119"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="char" char="plusmn" valign="bottom">–90.3 ± 71.7</td><td align="char" char="plusmn" valign="bottom">1.0 ± 0.8</td></tr><tr><td align="left" valign="bottom">II</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf120"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf121"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="char" char="plusmn" valign="bottom">–7.6 ± 13.1</td><td align="char" char="plusmn" valign="bottom">83.8 ± 60.5</td></tr><tr><td align="left" valign="bottom">III</td><td align="left" valign="bottom">–</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf122"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="char" char="plusmn" valign="bottom">–8.5 ± 13.1</td><td align="char" char="plusmn" valign="bottom">82.9 ± 61.4</td></tr><tr><td align="left" valign="bottom">*∼IV</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf123"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">–</td><td align="char" char="plusmn" valign="bottom">–90.8 ± 71.0</td><td align="char" char="plusmn" valign="bottom">0.5 ± 1.1</td></tr><tr><td align="left" valign="bottom">V</td><td align="left" valign="bottom">–</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf124"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="char" char="plusmn" valign="bottom">0.3 ± 2.5</td><td align="char" char="plusmn" valign="bottom">91.6 ± 70.6</td></tr><tr><td align="left" valign="bottom">VI</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf125"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">–</td><td align="char" char="plusmn" valign="bottom">0.95 ± 1.4</td><td align="char" char="plusmn" valign="bottom">92.3 ± 70.9</td></tr><tr><td align="left" valign="bottom">VII</td><td align="left" valign="bottom">–</td><td align="left" valign="bottom">–</td><td align="char" char="plusmn" valign="bottom">0 ± 0</td><td align="char" char="plusmn" valign="bottom">91.3 ± 71.5</td></tr></tbody></table></table-wrap><p>To test whether this mapping was preserved in an independent data set, we performed the same model comparison procedure for Experiment 2. Because Experiment 2 followed a replication-based design, we fit a separate model to each subject to assess the replicability of the best fitting model from Experiment 1. While we found support for the model mapping <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> to drift rate and <inline-formula><mml:math id="inf127"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> to boundary height, we also found that the DIC scores for the single-parameter model mapping <inline-formula><mml:math id="inf128"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf129"><mml:mi>v</mml:mi></mml:math></inline-formula> alone fit the data equally well (see bottom panel of <xref ref-type="table" rid="table1">Table 1</xref> for summary statistics and <xref ref-type="table" rid="app3table1">Appendix 3—table 1</xref>). Altogether, this suggests that we have strong evidentiary support for a mapping between value-driven belief and drift rate (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, blue). However, the support for a mapping between change point probability and boundary height (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, red), while robustly present in Experiment 1, fails to appear when tested in an independent data set.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Change-point-evoked uncertainty.</title><p>(<bold>A</bold>) Changes in ideal observer estimates of uncertainty over time and their effect on the boundary height and the drift rate. Directly after a change point, the boundary height <italic>increases</italic> and the drift rate slows. Over time, the boundary height returns to its baseline value and the drift rate increases. (<bold>B</bold>) Fitted estimates of change-point-evoked drift rate and boundary height for both experiments with 95% CIs of the posterior distributions. Inset plots represent data from Experiment 2.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig6-v2.tif"/></fig><p>For a more granular assessment of how drift rate and boundary height respond to a change point, we quantified the change-point-evoked effect of <inline-formula><mml:math id="inf130"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf131"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> on drift rate and boundary height, respectively, for both experiments (see Hierarchical drift diffusion modeling for details). In Experiment 1, we found that the rate of evidence accumulation, <inline-formula><mml:math id="inf132"><mml:mi>v</mml:mi></mml:math></inline-formula>, increased with the belief in the value of the optimal choice relative to a change point (<inline-formula><mml:math id="inf133"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.576</mml:mn></mml:mrow></mml:math></inline-formula>, 95% CI: 0.544, 0.609, empirical <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.000</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig6">Figure 6B</xref>, left panel). The boundary height <italic>increased</italic> with change point probability (<inline-formula><mml:math id="inf135"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.046</mml:mn></mml:mrow></mml:math></inline-formula>, 95% CI: 0.005, 0.088, empirical <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig6">Figure 6B</xref>, right panel).</p><p>Experiment two showed similar, but attenuated, results, with drift rate increasing with <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="inf138"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.112</mml:mn></mml:mrow></mml:math></inline-formula>, 95% CI: 0.016, 0.227, empirical <inline-formula><mml:math id="inf139"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig6">Figure 6B</xref>, inset panel on left) and an unreliable effect of <inline-formula><mml:math id="inf140"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> on boundary height (<inline-formula><mml:math id="inf141"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.036</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, 95% CI: –0.155, 0.097, empirical <inline-formula><mml:math id="inf142"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.282</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="fig6">Figure 6B</xref>, inset panel on right). Therefore, as the belief in the value of the optimal choice approaches the reward value for the optimal choice, the rate of information accumulation increases. An internal estimate of change point probability weakly increases the amount of information required to make a decision, although this latter effect is less reliable.</p><p>Altogether, these results suggest a drift rate mechanism for adaptation to change that may also combine with boundary height dynamics (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). However, the strength of the drift rate response weakened and the boundary height response was statistically unreliable in Experiment 2 (<xref ref-type="fig" rid="fig6">Figure 6B</xref> inset panels). When a change point is detected and the threshold for committing to a choice (<italic>a</italic>) responds, it shows a weak, transient increase. At the same time, the drift rate approaches zero, allowing time for the decision process to diffuse and encouraging a random selection. As the learner accrues information about the new optimal choice, the rate of information accumulation slowly recovers to asymptotic levels, with the decision process assuming a more directed path toward the choice that has accrued evidence for reward. Together, the changes in these underlying decision processes, largely driven by drift rate dynamics, point to a mechanism for gathering information in a relatively slow, unbiased manner shortly after the learner suspects she should update her valuation. We now explore these dynamics in more detail in the next section.</p></sec><sec id="s2-4"><title>Environmental instability prompts a stereotyped decision trajectory</title><p>So far, we have established that both the drift rate and the boundary height can be independently manipulated by two different estimates of environmental uncertainty with different temporal dynamics, although this effect reduces to drift rate dynamics in Experiment 2. This suggests that a change in action-outcome contingencies prompts a unique trajectory through the space of possible decision policies (<xref ref-type="fig" rid="fig1">Figure 1E</xref>).</p><p>To visualize this trajectory, we plot the temporal relationship between drift rate and boundary height beginning with the trial prior to the change point and ending three trials after the change point (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). To clearly visualize the distribution of the change-point driven response in the relationship between drift rate and boundary height over time, we also represent the trialwise shift in these two decision variables as vectors. The trial-by-trial estimates of drift rate and boundary height were taken from the best model of the fitted change-point-evoked response and z-scored (see Different forms of uncertainty impact distinct decision processes for model selection). Then the difference between each sequential set of boundary height and drift rate coordinates, <inline-formula><mml:math id="inf143"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, was calculated to produce a vector length. The arc tangent between these differenced values was computed to yield an angle in radians between sequential decision vectors, concisely representing the overall decision dynamics (<inline-formula><mml:math id="inf144"><mml:mi>θ</mml:mi></mml:math></inline-formula>, <xref ref-type="fig" rid="fig7">Figure 7B</xref>; see Decision vector representation for methodological details).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>The decision surface.</title><p>(<bold>A</bold>) Representing decision space in vector form. An angle (<inline-formula><mml:math id="inf145"><mml:mi>θ</mml:mi></mml:math></inline-formula>) was calculated between sequential values of (<inline-formula><mml:math id="inf146"><mml:mi>a</mml:mi></mml:math></inline-formula>,<inline-formula><mml:math id="inf147"><mml:mi>v</mml:mi></mml:math></inline-formula>) coordinates, beginning with the trial prior to the change point. This represents subject-averaged data from Experiment 1. Note that these trajectories are z-scored. (<bold>B</bold>) Distributions depicting the angle between drift rate and boundary height for both Experiments 1 and 2. Each subpanel shows the distribution of angles between (<inline-formula><mml:math id="inf148"><mml:mi>a</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf149"><mml:mi>v</mml:mi></mml:math></inline-formula>) over sequential trials, beginning with the trial prior to the change point. The area of the shaded region is proportional to the density and the arrow represents the circular mean.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig7-v2.tif"/></fig><p>For Experiment 1, following a shift in response contingencies, the navigation of this decision surface follows a stereotyped pattern. The boundary height spikes and drift rate decreases rapidly, gradually recovering and stabilizing over time (see the trial prior to the change point in <xref ref-type="fig" rid="fig7">Figure 7A</xref>). This decision trajectory is robust in Experiment 1 (<xref ref-type="fig" rid="fig7">Figure 7B</xref>, top panel).</p><p>Here, we find that the distribution of <inline-formula><mml:math id="inf150"><mml:mi>θ</mml:mi></mml:math></inline-formula> prior to a change point averages to ∼300°, sharply changes in response to the observation of a change point (∼165°) and steadily returns to values prior to the onset of a change (main panels in <xref ref-type="fig" rid="fig7">Figure 7B</xref>). One trial after the change point, drift rate sharply decreases and boundary height spikes, after which boundary height quickly recovers and drift rate steadily progresses toward its baseline value.</p><p>However, this trajectory is substantially more variable in Experiment 2, with most of the response restricted to the drift rate dimension and inconsistent trajectories along the boundary height dimension (<xref ref-type="fig" rid="fig7">Figure 7B</xref>, lower panel). Here, the distribution of <inline-formula><mml:math id="inf151"><mml:mi>θ</mml:mi></mml:math></inline-formula> prior to a change point averages to ∼270° and shifts to ∼90° with the observation of a change. In both experiments, we find that the decision trajectory quickly responds to a shift in action outcomes and also quickly recovers and stabilizes.</p><p>Having characterized the change-point-evoked trajectory through the range of decision policies, we next asked whether conditions of increased volatility and increased conflict might modify its path. To this end, we conducted a comparison of a null model with models specifying the change-point evoked response alone and this evoked response as a function of conflict and volatility. To estimate this relationship between drift rate and boundary height, we used Bayesian circular regression (<xref ref-type="bibr" rid="bib50">Mulder and Klugkist, 2017</xref>). First, we tested the null hypothesis that the decision dynamics (the relationship between drift rate and boundary height; <inline-formula><mml:math id="inf152"><mml:mi>θ</mml:mi></mml:math></inline-formula>) were solely a function of the intercept, or the average of the decision dynamics <inline-formula><mml:math id="inf153"><mml:mi>θ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula></p><p>We call this the null model.</p><p>To test the hypothesis that decision dynamics varied solely as a function of time after a switch in action-outcome contingencies, we estimated the change in <inline-formula><mml:math id="inf154"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> coordinates (<inline-formula><mml:math id="inf155"><mml:mi>θ</mml:mi></mml:math></inline-formula>) relative to a change point, with the time scale of consideration determined by the results of a stability analysis from Experiment 1 (see Model proposals and evaluation; <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>):<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We call this the evoked response model.</p><p>Our model comparison logic was as follows. We first evaluated whether the posterior probability of the evoked response model was greater than that for the null model. This would suggest that time relative to a change point alone is a better predictor of decision dynamics than the average response. If the posterior probability of the evoked response model reliably exceeded the posterior probability of the null model, we then quantified the evidence for alternative models relative to the evoked response model. The sole effect of time relative to a change point was then framed as the new null hypothesis.</p><p>We used Bayes Factors to quantify the ratio of evidence for two competing hypotheses. If the ratio is close to 1, then the evidence is equivocal. As the ratio grows more positive, there is greater evidence for the model specified in the numerator, and if the ratio is less than 1, then there is evidence for the model specified in the denominator (<xref ref-type="bibr" rid="bib39">Jeffreys, 1998</xref>). Evidence for the null hypothesis is denoted <inline-formula><mml:math id="inf156"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and evidence for the alternative hypothesis is denoted <inline-formula><mml:math id="inf157"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>10</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Because Experiment 2 took a within-subject approach, a separate model was fit for each participant for all proposed models.</p><p>To determine whether volatility and conflict affected these peri-change decision dynamics, we modeled changes in decision policy on the drift rate and boundary height surface as a function of <inline-formula><mml:math id="inf158"><mml:mi>λ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf159"><mml:mi>p</mml:mi></mml:math></inline-formula>, where <inline-formula><mml:math id="inf160"><mml:mi>λ</mml:mi></mml:math></inline-formula> corresponds to the average period of stability and <inline-formula><mml:math id="inf161"><mml:mi>p</mml:mi></mml:math></inline-formula> corresponds to the mean probability of reward for the optimal choice (see <xref ref-type="fig" rid="fig8">Figure 8</xref> for the full set of models considered). We explored the potential influence of volatility and conflict on the relationship between drift rate and boundary height by examining the posterior probability for each hypothesized model given the set of alternative hypotheses (Model proposals and evaluation; <xref ref-type="fig" rid="fig8">Figure 8A</xref>). We found that the evoked response model describing the relationship between shifts in decision parameters and time relative to a change point was more probable than the null model (see <xref ref-type="fig" rid="fig8">Figure 8A</xref>).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Model comparisons for the effect of volatility and conflict on the relationship between drift rate and boundary height.</title><p>(<bold>A</bold>) The posterior probability for models testing for an effect of volatility and conflict on the angle of shift in <inline-formula><mml:math id="inf162"><mml:mi>a</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:mi>v</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf164"><mml:mi>θ</mml:mi></mml:math></inline-formula>. (<bold>B</bold>) The Bayes Factor for the null model relative to the alternative models specifying either an effect of time relative to a change point alone or a conditional effect on this evoked response <inline-formula><mml:math id="inf165"><mml:mi>θ</mml:mi></mml:math></inline-formula>. (<bold>C</bold>) The Bayes Factor for the evoked response model relative to the surviving alternative models specifying a conditional effect on the evoked response, <inline-formula><mml:math id="inf166"><mml:mi>θ</mml:mi></mml:math></inline-formula>. Note that time refers to time relative to the onset of a change point. All models specifying an interaction also include main effects. Dotted horizontal lines refer to grades of evidence (<xref ref-type="bibr" rid="bib80">Wagenmakers, 2007</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig8-v2.tif"/></fig><p>We also present the evidence for the null model against each alternative model as a Bayes Factor (<inline-formula><mml:math id="inf167"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) (<xref ref-type="fig" rid="fig8">Figure 8B</xref>). The 95% confidence interval for the <inline-formula><mml:math id="inf168"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:mn>01</mml:mn></mml:mrow></mml:math></inline-formula> comparing the ratio of evidence for the null model and the evoked response model specifying time-dependent effects of volatility included 1, suggesting inconclusive evidence for either of these models. Likewise, the 95% confidence interval for the <inline-formula><mml:math id="inf169"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> comparing the evidence for the null model against the model specifying change-point-evoked effects of conflict included 1, suggesting no substantive difference between them. Given the equivocal evidence for these two models we excluded them from further comparison with the evoked response model.</p><p>The remainder of the models had substantially negative <inline-formula><mml:math id="inf170"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> values (<xref ref-type="fig" rid="fig8">Figure 8B</xref>), suggesting that they better fit the data than the null model and allowing them to survive to the next stage of analysis. To evaluate the hypothesis that time alone best accounted for the data, we computed the <inline-formula><mml:math id="inf171"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> for the evoked response model against the surviving models from the null model analysis. We find that, for all the remaining models, the <inline-formula><mml:math id="inf172"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is substantially positive (<xref ref-type="fig" rid="fig8">Figure 8C</xref>), indicating that the evoked response model best accounted for the data (posterior probability of evoked response model given the set of models considered: <inline-formula><mml:math id="inf173"><mml:mrow><mml:mn>0.76</mml:mn><mml:mo>±</mml:mo><mml:mn>0.473</mml:mn></mml:mrow></mml:math></inline-formula>; posterior prob. for 3/4 participants &gt; 0.99).</p><p>These analyses suggest that the relationship between the rate of evidence accumulation and the boundary height is only related to the change point itself. We find no evidence to suggest that changing the degree of volatility or changing the degree of conflict changes the path of the decision policy following a change point. Thus, the stereotyped response of the decision policy is solely dependent on the presence of a change point rather than either the history of change point frequency or the history of optimal choice ambiguity. Note that while the ideal observer estimates respond to our conditional manipulations of volatility and conflict, the decision dynamics <inline-formula><mml:math id="inf174"><mml:mi>θ</mml:mi></mml:math></inline-formula> we observe do not reflect these effects. This is due to the noisy, imperfect correspondence between the ideal observer signals and <inline-formula><mml:math id="inf175"><mml:mi>a</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf176"><mml:mi>v</mml:mi></mml:math></inline-formula>. This suggests that adaptation to environmental changes in action-outcome contingencies involves a rapid, coordinated increase in the relationship between the amount of information needed to make a decision and a decrease in the rate of information accumulation, with a stereotyped return to a stable baseline soon thereafter until another change occurs.</p></sec><sec id="s2-5"><title>No evidence for locus-coeruleus norepinephrine (LC-NE) system contribution to the decision trajectory</title><p>The LC-NE system is known to modulate exploration states under uncertainty and pupil diameter shows a tight correspondence with LC neuron firing rate (<xref ref-type="bibr" rid="bib5">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib61">Rajkowski et al., 1994</xref>), with changes in pupil diameter indexing the explore-exploit decision state (<xref ref-type="bibr" rid="bib40">Jepma and Nieuwenhuis, 2011</xref>). Similar to the classic Yerkes-Dodson curve relating arousal to performance (<xref ref-type="bibr" rid="bib88">Yerkes and Dodson, 1908</xref>), performance is optimal when tonic LC activity is moderate and phasic LC activity increases following a goal-related stimulus (<xref ref-type="bibr" rid="bib4">Aston-Jones et al., 1999</xref>, but see <xref ref-type="bibr" rid="bib41">Joshi et al., 2016</xref> for an exception). Because of this link between LC-NE and the regulation of behavioral variability in response to uncertainty, we expected that LC-NE system responses, as recorded by pupil diameter, would associate with environmental uncertainty and the trajectory through decision policy space following a change in action-contingencies. Specifically, if the LC-NE system were sensitive to a change in the optimal choice then we should observe a moderate spike in phasic activity following a change in action-outcome contingencies. Note that we do not observe previously established links between exploratory choice behavior and the pupillary response (<xref ref-type="bibr" rid="bib40">Jepma and Nieuwenhuis, 2011</xref>; <xref ref-type="bibr" rid="bib51">Murphy et al., 2011</xref>; <xref ref-type="bibr" rid="bib78">van Kempen et al., 2019</xref>). We ask the reader to titrate their interpretation of these pupillary data accordingly.</p><p>We characterized the evoked pupillary response on each trial in Experiment 2 using seven metrics: the mean of the pupil data over each trial interval, the latency to the peak onset and offset, the latency to peak amplitude, the peak amplitude, and the area under the curve of the pupillary response (see Pupil data preprocessing; <xref ref-type="fig" rid="fig9">Figure 9A</xref>). From a computational perspective, reducing the dimensionality of this set of pupillary response metrics expands the set of models we can consider without taxing computational resources in a reasonable amount of time. Further, dimensionality reduction of the pupillary response allows us to capture separable sources of variance relating to timing and amplitude effects without restricting the data to a smaller set of metrics and possibly discarding information (e.g. timing effects may not be constrained to peak latency or onset latency; amplitude effects may not be constrained to peak dilation amplitude). Therefore, we submitted these metrics to principal component analysis to reduce their dimensionality while capturing maximum variance.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Method for analyzing pupil data.</title><p>(<bold>A</bold>) The evoked pupillary response was characterized according to seven metrics. (<bold>B</bold>) These pupillary features were submitted to a principal component analysis. The contribution of each feature to the variance explained for the first two components is plotted for each subject. Note that we also conducted a supplementary analysis of the task-evoked pupillary response using a more conventional method with similar results.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig9-v2.tif"/></fig><p>Evoked response characterization and principal component analyses were conducted for each session and for each subject in Experiment 2. The 95% CI for the number of principal components needed to explain 95% of the variance in the data was calculated over subjects and sessions to determine the number of principal components to keep for further analysis. To aid in interpreting subsequent analysis using the selected principal components, the feature importance of each pupil metric was calculated for each principal component and aggregated across subjects as a mean and bootstrapped 95% CI (<xref ref-type="fig" rid="fig9">Figure 9</xref>). We found that the first two principal components explained 95% of the variance in the pupillary data. Peak onset, peak offset, and latency to peak amplitude had the greatest feature importance for the first principal component (<xref ref-type="fig" rid="fig9">Figure 9B</xref>, upper panel). Mean pupil diameter and peak amplitude had the greatest feature importance for the second principal component (<xref ref-type="fig" rid="fig9">Figure 9B</xref>, lower panel). Thus, for interpretability, we refer to the first and second principal components as timing and magnitude components, respectively (<xref ref-type="fig" rid="fig9">Figure 9B</xref>). Note that we also conduct this analysis using more conventional methods of pupillary analysis and continue to observe a null effect (see Pupil data preprocessing for details).</p><p>To test for the possibility that fluctuations in norepinephrine covaried with changes in the drift-rate and the boundary height, we evaluated a set of models exploring the relationship between the timing and magnitude components of the change-point-evoked pupillary response and shifts in <inline-formula><mml:math id="inf177"><mml:mi>θ</mml:mi></mml:math></inline-formula>. As in our previous model comparison (<xref ref-type="fig" rid="fig8">Figure 8</xref>; see Environmental instability prompts a stereotyped decision trajectory), we found that the model describing the relationship between decision policy shift and time relative to a change point had the highest posterior probability given the set of models considered (<xref ref-type="fig" rid="fig10">Figure 10A</xref>). To further evaluate the extent of the evidence for the evoked response hypothesis, we present the evidence for the evoked response model against the original model set as <inline-formula><mml:math id="inf178"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig10">Figure 10B</xref>). We find unambiguous evidence in favor of the evoked response model relative to the models specifying the modulation of <inline-formula><mml:math id="inf179"><mml:mi>θ</mml:mi></mml:math></inline-formula> via the timing and magnitude features of the change-point-evoked pupillary response (posterior probability of time-null model given the set of models considered: <inline-formula><mml:math id="inf180"><mml:mrow><mml:mn>0.997</mml:mn><mml:mo>±</mml:mo><mml:mn>0.002</mml:mn></mml:mrow></mml:math></inline-formula>), with substantially positive <inline-formula><mml:math id="inf181"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> values. We find no evidence that the pupillary response associates with the dynamics of the decision policy changes in response to a change in action-outcome contingencies.</p><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Model comparisons for the effect of change-point-evoked pupillary dynamics on the relationship between drift rate and boundary height (<inline-formula><mml:math id="inf182"><mml:mi>θ</mml:mi></mml:math></inline-formula>).</title><p>(<bold>A</bold>) The posterior probability for models testing for an effect of pupillary dynamics on <inline-formula><mml:math id="inf183"><mml:mi>θ</mml:mi></mml:math></inline-formula>. (<bold>B</bold>) The Bayes Factor for the evoked response model relative to the alternative models specifying an effect of pupillary dynamics on the evoked response, <inline-formula><mml:math id="inf184"><mml:mi>θ</mml:mi></mml:math></inline-formula>. Note that time refers to time relative to the onset of a change point. All models specifying an interaction also include main effects.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-fig10-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We investigated how decision policies change when the rules of the environment change. In two separate experiments, we characterized how decision processes adapted in response to a change in action-outcome contingencies as a trajectory through the space of possible types of exploratory and exploitative decision policies. Our findings highlight how, in the context of two choice paradigms, when faced with a possible change in outcomes, humans rapidly shift to a slow exploratory strategy by reducing the drift rate and, sometimes, increasing the boundary height in a stereotyped manner. Using pupillary data, we were unable to detect a relationship between the LC-NE system and the dynamics of adaptive decision policies in unstable environments. Our findings show how the underlying decision algorithm adapts to different forms of uncertainty.</p><p>Exploration and exploitation states are not discrete, but exist along a continuum (<xref ref-type="bibr" rid="bib1">Addicott et al., 2017</xref>). Instead of switching between binary states, humans manage environmental instability by adjusting the greediness of their decision policies (<xref ref-type="bibr" rid="bib66">Sadeghiyeh et al., 2020</xref>; <xref ref-type="bibr" rid="bib60">Prat-Carrabin et al., 2020</xref>; <xref ref-type="bibr" rid="bib26">Feng et al., 2020</xref>; <xref ref-type="bibr" rid="bib85">Wilson et al., 2014</xref>; <xref ref-type="bibr" rid="bib57">Payzan-LeNestour and Bossaerts, 2011</xref>; <xref ref-type="bibr" rid="bib58">Payzan-Lenestour and Bossaerts, 2012</xref>; <xref ref-type="bibr" rid="bib86">Wilson et al., 2021</xref>). Depending on the relative configuration of parameters in the accumulation to bound process, this adjustment can manifest as either speeded or slowed decisions (<xref ref-type="fig" rid="fig1">Figure 1E</xref>; <xref ref-type="bibr" rid="bib2">Alexandrowicz, 2020</xref>; <xref ref-type="bibr" rid="bib62">Ratcliff, 1978</xref>). Our results suggest that, in the context of volatile two-choice decisions, humans adopt a mechanism that simultaneously changes the rate of evidence accumulation and, sometimes, the threshold of evidence needed to trigger a decision, so as to adapt to an environmental change (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). As soon as a shift in action outcomes is suspected, an internal estimate of change point probability increases and an estimate of the belief in the value of the optimal target plummets (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). The rapid increase in change point probability causes a rapid <italic>rise</italic> in the boundary height on the subsequent trial, thereby increasing the criterion for selecting a new action and allowing variability in the accumulation process to have a greater influence on choice (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), although this latter effect is inconsistent across experiments. These changes lead to slow exploratory decisions that facilitate discovery of the new optimal action and result in a quick recovery of the original threshold value over the course of a few trials. In parallel, the rate of evidence accumulation for the optimal choice decreases, with an immediate drop that gradually returns to its asymptotic value as the belief in the value of the optimal choice stabilizes. These results show that when a learner confronts a change point, the decision policy becomes more exploratory by simultaneously increasing the amount of evidence needed to make a decision <italic>and</italic> slowing the integration of evidence over time. Together, these decision dynamics form a mechanism for gathering information in an unbiased manner that slows the decision at the decision process level but responds quickly relative to a suspected change in trial time.</p><p>Critically, our finding that underlying decision policies can reconfigure multiple underlying decision parameters closely parallels recent work in the domain of information-seeking. Information seeking has been decomposed into random and directed components (<xref ref-type="bibr" rid="bib85">Wilson et al., 2014</xref>). Random exploration refers to inherent behavioral variability that leads us to explore other options, while directed exploration refers to the volitional pursuit of new information. Feng and colleagues recently found that random exploration is driven by changes in the drift rate and the boundary height, with drift rate changes dominating the policy shift (<xref ref-type="bibr" rid="bib26">Feng et al., 2020</xref>). When environmental conditions encouraged exploration, the drift rate slowed, reducing the signal-to-noise ratio of the reward representation. This finding clearly aligns with our current observations showing that the drift rate sharply decreases in response to a change point and that this change in drift rate dominates the reconfiguration of decision processes, although our experiments were not designed to isolate the directed and random elements of exploration.</p><p>Our results are also broadly consistent with a growing body of research converging on the idea that decision policies are not static, but sensitive to changes in environmental dynamics (<xref ref-type="bibr" rid="bib24">Dunovan and Verstynen, 2019</xref>; <xref ref-type="bibr" rid="bib76">Urai et al., 2018</xref>). Previous work by our lab (<xref ref-type="bibr" rid="bib24">Dunovan and Verstynen, 2019</xref>) has shown how, during a modified reactive inhibitory control task, different feedback signals target different parts of the accumulation-to-bound process. Specifically, errors in response timing drove rapid changes in the drift rate on subsequent trials, while selection errors (i.e. making a response on trials where the response should be inhibited) changed the boundary height. Further, there is new evidence that the drift rate adapts on the basis of previous choices, independent of the feedback given for those choices. Urai and colleagues have convincingly demonstrated that choice history signals sculpt the dynamics of the accumulation process by biasing the rate of evidence accumulation (<xref ref-type="bibr" rid="bib76">Urai et al., 2018</xref>). Our current findings and these previous observations (<xref ref-type="bibr" rid="bib59">Pedersen et al., 2017</xref>; <xref ref-type="bibr" rid="bib63">Ratcliff and Frank, 2012</xref>) all highlight how sensitive the parameters of accumulation-to-bound processes are to immediate experience.</p><p>Previous literature has shown a conflict-induced spike in reaction time (e.g. <xref ref-type="bibr" rid="bib38">Jahfari et al., 2019</xref>). However, our complex reaction time results depart from this. One reason for this departure may relate to the demands of the task we are asking participants to perform. While increased cognitive demand should increase reaction times across conditions, we observe a linear decrease in reaction time as a function of volatility when conflict is highest, and we also see that a net increase in conflict decreases reaction times (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). We suspect that the presence of both conflict and volatility blurs the distinction between these two sources of uncertainty, especially under high volatility and high conflict conditions. We also see this effect in our formulation of change point probability (CPP), with a bias to overestimate CPP when conflict is high (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). It is possible that participants also exhibit this bias to overestimate volatility when conflict is high, which could muddle the effect of conflict on reaction times. Future research should explore the interaction of change point and conflict estimation on the speed-accuracy trade-off.</p><p>We hypothesized that any shift in decision policy in response to a change in action-outcome contingencies would be linked to changes in phasic responses of the LC-NE pathways (<xref ref-type="bibr" rid="bib5">Aston-Jones and Cohen, 2005</xref>). However, we failed to find any evidence of this link using pupillary responses as a proxy of LC-NE dynamics. It should be noted, however, that our experimental design cannot distinguish between pupillary dynamics driven by other catecholamines, such as dopamine, and those dynamics driven by the LC-NE system (<xref ref-type="bibr" rid="bib71">Spiers and Calne, 1969</xref>; <xref ref-type="bibr" rid="bib47">McClure et al., 2005</xref>; <xref ref-type="bibr" rid="bib31">Gershman and Tzovaras, 2018</xref>; <xref ref-type="bibr" rid="bib32">Gershman and Uchida, 2019</xref>), Thus it is possible that the LC-NE system may still be playing a role in shift of decision policies, and the pupil responses we collected were insensitive to the underlying dynamics. Nonetheless, this null association suggests that an alternative neural mechanism drives the adaptive changes that we observed behaviorally.</p><p>One possible alternative mechanism for resetting decision policies is is dopaminergic changes to the cortico-basal ganglia-thalamic (CBGT) pathways, or ‘loops’. Both recent experimental (<xref ref-type="bibr" rid="bib87">Yartsev et al., 2018</xref>; <xref ref-type="bibr" rid="bib23">Dunovan et al., 2015</xref>) and theoretical (<xref ref-type="bibr" rid="bib13">Bogacz and Larsen, 2011</xref>; <xref ref-type="bibr" rid="bib19">Caballero et al., 2018</xref>; <xref ref-type="bibr" rid="bib81">Wei et al., 2015</xref>) studies have pointed to the CBGT loops as being a crucial pathway for accumulating evidence during decision making, with the wiring architecture of these pathways ideal for implementing the sequential probability ratio test (<xref ref-type="bibr" rid="bib11">Bogacz and Gurney, 2007</xref>; <xref ref-type="bibr" rid="bib10">Bogacz, 2007</xref>), the statistically optimal algorithm for evidence accumulation decisions and the basis for the DDM itself (<xref ref-type="bibr" rid="bib62">Ratcliff, 1978</xref>). Further, multiple lines of theoretical work have suggested that, within the CBGT pathways, the difference in direct pathway activity between action channels covaries with the rate of evidence accumulation for individual decisions (<xref ref-type="bibr" rid="bib49">Mikhael and Bogacz, 2016</xref>; <xref ref-type="bibr" rid="bib6">Bariselli et al., 2019</xref>; <xref ref-type="bibr" rid="bib25">Dunovan et al., 2019</xref>; <xref ref-type="bibr" rid="bib65">Rubin et al., 2021</xref>), while the indirect pathways are linked to control of the boundary height (<xref ref-type="bibr" rid="bib81">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">Herz et al., 2016</xref>; <xref ref-type="bibr" rid="bib10">Bogacz, 2007</xref>; <xref ref-type="bibr" rid="bib63">Ratcliff and Frank, 2012</xref>). This suggests that changes in the direct and indirect pathways, both within and between representations of different actions, may regulate shifts in decision policies.</p><p>Critically, the CBGT pathways are a target of the dopaminergic signaling that drives reinforcement learning (<xref ref-type="bibr" rid="bib68">Schultz et al., 1992</xref>), suggesting that changes in relative action-value should drive trial-by-trial changes in the drift rate. Indeed, previous work relating dopaminergic circuitry to decision policy adaptation suggests that dopamine may play a critical role in modulating decision policies. Dopamine has substantial links to exploration (<xref ref-type="bibr" rid="bib42">Kakade and Dayan, 2002</xref>) and recent pharmacological evidence suggests a role for dopaminergic regulation of exploration in humans (<xref ref-type="bibr" rid="bib21">Chakroun et al., 2020</xref>). More explicitly, both directed and random exploration have been linked to variations in genes that affect dopamine levels in prefrontal cortex and striatum, respectively (<xref ref-type="bibr" rid="bib31">Gershman and Tzovaras, 2018</xref>). Physiologically, previous work has found that a dopamine-controlled spike-timing-dependent plasticity rule alters the ratio of direct to indirect pathway efficacy in a simulated corticostriatal network (<xref ref-type="bibr" rid="bib79">Vich et al., 2020</xref>), with overall indirect pathway activity (i.e. pre-decision firing rates) linked to the modulation of the boundary height in a DDM and the difference in direct pathway activation across action channels associating with changes in the drift rate (<xref ref-type="bibr" rid="bib25">Dunovan et al., 2019</xref>; <xref ref-type="bibr" rid="bib65">Rubin et al., 2021</xref>). Moreover, recent optogenetic work in mice suggests that activating the subthalamic nucleus, a key node in the indirect pathway, not only halts the motoric response but also interrupts cognitive processes related to action selection (<xref ref-type="bibr" rid="bib36">Heston et al., 2020</xref>). Our current observations, combined with this previous work, suggests that the decision policy reconfiguration that we observe may associate with similar underlying corticostriatal dynamics, with belief-driven changes to drift rate varying with the difference in direct pathway firing rates across action channels (<xref ref-type="bibr" rid="bib25">Dunovan et al., 2019</xref>), and change-point-probability-driven changes to the boundary height varying with overall indirect pathway activity (<xref ref-type="bibr" rid="bib25">Dunovan et al., 2019</xref>; <xref ref-type="bibr" rid="bib79">Vich et al., 2020</xref>). Future physiological studies should focus on validating this predicted relationship between decision policy reconfiguration and CBGT pathways.</p><p>The current study raises many more questions about the dynamics of adaptive decision policies than it answers. For example, we only sparsely sampled the space of possible states of value conflict and volatility. Future work would benefit from a more complete sampling of the conflict and volatility space. A psychophysical characterization of how decision states shift in response to varying forms of uncertainty will expose potential non-linear relationships between the decision policy and feedback uncertainty. Moreover, the decisions that we have modeled here are simple two choice decisions, constrained mostly by the normative form of the traditional DDM framework (<xref ref-type="bibr" rid="bib62">Ratcliff, 1978</xref>). Scaling the complexity of the task will allow for a more complete assessment of how these relationships change with more complex decisions that better approximate the choices that we make outside the lab. This could be done by moving the cognitive model to frameworks that can fit processes for decisions involving more than two alternatives (e.g. <xref ref-type="bibr" rid="bib74">Tajima et al., 2019</xref>). Finally, because our estimate of the relationship between our ideal observer estimates of uncertainty and human estimates of uncertainty were indirect, this work would benefit from online approximations of ideal observer estimates, as has been done previously (<xref ref-type="bibr" rid="bib83">Wilson et al., 2010</xref>). Indeed, there can be substantive individual differences in the detection of of change points (<xref ref-type="bibr" rid="bib83">Wilson et al., 2010</xref>). Thus, an approximation of how well the estimates of change point probability from our ideal observer correspond to estimates that human observers hold is needed. This approximation would validate the fidelity of the relationship between the ideal observer estimates of uncertainty and the decision parameters that we observed.</p><p>Together, our results suggest that when humans are forced to change their mind about the best action to take, the underlying decision policy adapts in a specific way. When a change in action-outcome contingency is suspected, the rate of evidence accumulation decreases and more evidence may briefly be required to commit to a response, allowing variability inherent to the decision process to play a greater role in response selection and resulting in a <italic>slow</italic> exploratory state. As the environment becomes stable, the system gradually adapts to an exploitative state. Importantly, we find no evidence that norepinephrine pathways associate with this response. This suggests that other pathways may be engaged in this adaptive reconfiguration of decision policies. These results reveal the multifaceted underlying decision processes that can adapt action selection policy under multiple forms of environmental uncertainty.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Neurologically healthy adults were recruited from the local university population. All procedures were approved by the Carnegie Mellon University Institutional Review Board (Approval Code: 2018_00000195; Funding: Air Force Research Laboratory, Grant Office ID: 180119). All research participants provided informed consent to participate in the study and consent to publish any research findings based on their provided data.</p><p>Twenty-four participants (19 female, 22 right-handed, 19–31 years old) were recruited for Experiment 1 and paid $20 at the end of four sessions. Four participants (two female, 4 right-handed, 21–28 years old) were recruited for Experiment 2 and paid $10 for each of nine sessions, in addition to a performance bonus.</p><p>Processed data and code are available within a Github <ext-link ext-link-type="uri" xlink:href="https://github.com/kmbond/dynamic_decision_policy_reconfiguration">repository</ext-link> for this publication (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:de31a380724a5954d16e67a0a6eda17431e11607;origin=https://github.com/kmbond/dynamic_decision_policy_reconfiguration;visit=swh:1:snp:561cc2fa2a2a7aa9aba3d43fe505a2d36b992b7d;anchor=swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8">swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8</ext-link>, <xref ref-type="bibr" rid="bib15">Bond, 2021</xref>). Hypotheses were <ext-link ext-link-type="uri" xlink:href="https://osf.io/5esn4">registered</ext-link> prior to the completion of data collection using the Open Science Framework (<xref ref-type="bibr" rid="bib29">Foster, MSLS and Deardorff, MLIS, 2017</xref>).</p></sec><sec id="s4-2"><title>Stimuli and procedure</title><sec id="s4-2-1"><title>Experiment 1</title><p>To begin the task, each participant read the following instructions:</p><p>“You’re going on a treasure hunt! You will start with 600 coins in your treasure chest, and you’ll be able to pay a coin to open either a purple or an orange box. When you open one of those boxes, you will get a certain number of coins, depending on the color of the box. However, opening the same box will not always give you the same number of coins, and each choice costs one coin. After making your choice, you will receive feedback about how much money you have. Your goal is to make as much money as possible. Press the green button when you’re ready to continue. Choose the left box by pressing the left button with your left index finger and choose the right box by pressing the right button with your right index finger. Note that if you choose too slowly or too quickly, you won’t earn any coins. Finally, remember to make your choice based on the color of the box. Press the green button when you’re ready to begin the hunt!”.</p><p>On each trial, participants chose between one of two ‘mystery boxes’ presented side-by-side on the computer screen (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Participants selected one of the two boxes by pressing either a left button (left box selection) or right button (right box selection) on a button box (Black Box ToolKit USB Response Pad, URP48). Reaction time (RT) was defined as the time elapsed from stimulus presentation to stimulus selection. Reaction time was constrained so that participants had to respond within 100 ms to 1000 ms from stimulus presentation. If participants responded too quickly, the trial was followed by a 5 s pause and they were informed that they were too fast and asked to slow down. If participants responded too slowly, they received a message saying that they were too slow, and were asked to choose quickly on the next trial. In both of these cases, participants did not receive any reward feedback or earn any points, and the trial was repeated so that 600 trials met these reaction time constraints. In order to avoid fatigue, a small break was given midway through each session (break time: 0.72 ± 1.42 m). Participants began each condition with 600 points and lost one point for each incorrect decision.</p><p>Feedback was given after each rewarded choice in the form of points drawn from the normal distribution <inline-formula><mml:math id="inf185"><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and converted to an integer. If the choice was unrewarded, then participants received 0 points. These points were displayed above the selected mystery box for 0.9 s. To prevent stereotyped responses, the inter-trial interval was sampled from a uniform distribution with a lower limit of 250ms and an upper limit of 750ms (<inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>U</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>750</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). The relative left-right position of each target was pseudorandomized on each trial to prevent incidental learning based on the spatial position of either the mystery box or the responding hand.</p><p>To induce decision-conflict, the probability of reward for the optimal target (<inline-formula><mml:math id="inf187"><mml:mi>P</mml:mi></mml:math></inline-formula>) was manipulated across two conditions. We imposed a relatively low probability of reward for the high conflict condition (<inline-formula><mml:math id="inf188"><mml:mi>P</mml:mi></mml:math></inline-formula> = 0.65). Conversely, we imposed a relatively high probability of reward for the low conflict condition (<inline-formula><mml:math id="inf189"><mml:mi>P</mml:mi></mml:math></inline-formula> = 0.85). For all conditions, the probability of the low-value target was <inline-formula><mml:math id="inf190"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula>.</p><p>Along with these reward manipulations, we also introduced volatility in the action-outcome contingencies. After a prespecified number of trials, the identity of the optimal target switched periodically. The point at which the optimal target switched identities was termed a <italic>change point</italic>. Each period of mean contingency stability was defined as an epoch. Consequently, each session was composed of multiple change points and multiple epochs. Epoch lengths, in trials, were drawn from a Poisson distribution. The lambda parameter was held constant for both high conflict and low conflict conditions (<inline-formula><mml:math id="inf191"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>25</mml:mn></mml:mrow></mml:math></inline-formula>).</p><p>To manipulate volatility, epoch lengths were manipulated across two conditions. The high volatility condition drew epoch lengths from a Poisson distribution where <inline-formula><mml:math id="inf192"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula> and the low volatility condition drew epoch lengths from a distribution where <inline-formula><mml:math id="inf193"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>35</mml:mn></mml:mrow></mml:math></inline-formula>. In these conditions manipulating volatility, the probability of reward was held constant (<inline-formula><mml:math id="inf194"><mml:mi>P</mml:mi></mml:math></inline-formula> = 0.75).</p><p>Each participant was tested under four experimental conditions: high conflict, low conflict, high volatility, and low volatility. Each condition was completed in a unique experimental session and each session consisted of 600 trials. Each participant completed the entire experiment over two testing days. To eliminate the effect of timing and its correlates on reward learning (<xref ref-type="bibr" rid="bib18">Byrne et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Murray et al., 2009</xref>), the order of conditions was counterbalanced across participants.</p></sec><sec id="s4-2-2"><title>Experiment 2</title><p>Experiment 2 used male and female Greebles (<xref ref-type="bibr" rid="bib30">Gauthier and Tarr, 1997</xref>) as selection targets (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Participants were first trained to discriminate between male and female Greebles to prevent errors in perceptual discrimination from interfering with selection on the basis of value. Using a two-alternative forced choice task, participants were presented with a male and female Greeble and asked to select the female, with the male and female Greeble identities resampled on each trial. Participants received binary feedback regarding their selection (correct or incorrect). This criterion task ended after participants reached 95% accuracy (mean number of trials to reach criterion: 31.29, standard deviation over means for subjects: 9.99).</p><p>After reaching perceptual discrimination criterion for each session, each participant was tested under nine reinforcement learning conditions composed of 400 trials each, generating 3600 trials per subject in total. Data were collected from four participants in accordance with a replication-based design, with each participant serving as a replication experiment. Participants completed these sessions across three weeks in randomized order. Each trial presented a male and female Greeble (<xref ref-type="bibr" rid="bib30">Gauthier and Tarr, 1997</xref>), with the goal of selecting the sex identity of the Greeble that was most profitable (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Individual Greeble identities were resampled on each trial; thus, the task of the participant was to choose the sex identity rather than the individual identity of the Greeble which was most rewarding. Probabilistic reward feedback was given in the form of points drawn from the normal distribution <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and converted to an integer, as in Experiment 1. These points were displayed at the center of the screen. Participants began with 200 points and lost one point for each incorrect decision. To promote incentive compatibility (<xref ref-type="bibr" rid="bib37">Hurwicz, 1972</xref>; <xref ref-type="bibr" rid="bib45">Ledyard, 1989</xref>), participants earned a cent for every point earned. Reaction time was constrained such that participants were required to respond within 0.1 and 0.75 s from stimulus presentation. If participants responded in <inline-formula><mml:math id="inf196"><mml:mrow><mml:mi/><mml:mo>≤</mml:mo><mml:mn>.1</mml:mn></mml:mrow></mml:math></inline-formula> s, <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi/><mml:mo>≥</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula> s, or failed to respond altogether, the point total turned red and decreased by five points. Each trial lasted 1.5 s and reward feedback for a given trial was displayed from the time of the participant’s response to the end of the trial.</p><p>To manipulate change point probability, the sex identity of the most rewarding Greeble was switched probabilistically, with a change occurring every 10, 20, or 30 trials, on average. To manipulate the belief in the value of the optimal target, the probability of reward for the optimal target was manipulated, with <inline-formula><mml:math id="inf198"><mml:mi>P</mml:mi></mml:math></inline-formula> set to 0.65, 0.75, or 0.85. Each session combined one value of <inline-formula><mml:math id="inf199"><mml:mi>P</mml:mi></mml:math></inline-formula> with one level of change point probability, such that all combinations of change point frequency and reward probability were imposed across the nine sessions (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). As in Experiment 1, the position of the high-value target was pseudo-randomized on each trial to prevent prepotent response selections on the basis of location.</p><p>Throughout the task, the head-stabilized diameter and gaze position of the left pupil were measured with an Eyelink 1,000 desktop mount at 1000 Hz. Participants viewed stimuli from within a custom-built booth designed to eliminate the influence of ambient sources of luminance. Because the extent of the pupillary response is known to be highly sensitive to a variety of influences (<xref ref-type="bibr" rid="bib69">Sirois and Brisson, 2014</xref>), we established the dynamic range of the pupillary response for each session by exposing participants to a sinusoidal variation in luminance prior to the reward-learning task. During the reward-learning task, all stimuli were rendered isoluminant with the background of the display to further prevent luminance-related confounds of the task-evoked pupillary response. To obtain as clean a trial-evoked pupillary response as possible and minimize the overlap of the pupillary response between trials, the inter-trial interval was sampled from a truncated exponential distribution with a minimum of 4 s, a maximum of 16 s, and a rate parameter of 2. The eyetracker was calibrated and the calibration was validated at the beginning of each session. See Pupil data preprocessing for pupil data preprocessing steps.</p></sec></sec><sec id="s4-3"><title>Models and simulations</title><sec id="s4-3-1"><title>Q-learning simulations</title><p>A simple, tabular q-learning agent (<xref ref-type="bibr" rid="bib72">Sutton and Barto, 1998</xref>) was used to simulate action selection in contexts of varying degrees of conflict and volatility. On each trial, <inline-formula><mml:math id="inf200"><mml:mi>t</mml:mi></mml:math></inline-formula>, the agent chooses which of two actions to take according to the policy<disp-formula id="equ3"><label>(1)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>exp</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf201"><mml:mi>β</mml:mi></mml:math></inline-formula> is the inverse temperature parameter, <inline-formula><mml:math id="inf202"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:math></inline-formula>, reflecting the greediness of the selection policy and <inline-formula><mml:math id="inf203"><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> is the estimated state-action value vector on that trial. Higher values of <inline-formula><mml:math id="inf204"><mml:mi>β</mml:mi></mml:math></inline-formula> reflect more exploitative decision policies.</p><p>After selection, a binary reward was returned. This was used to update the <inline-formula><mml:math id="inf205"><mml:mi>Q</mml:mi></mml:math></inline-formula> table according using a simple update rule<disp-formula id="equ4"><label>(2)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf206"><mml:mi>α</mml:mi></mml:math></inline-formula> is the learning rate for the model.</p><p>On each simulation an agent was initialized with a specific <inline-formula><mml:math id="inf207"><mml:mi>β</mml:mi></mml:math></inline-formula> value, ranging from 0.1 to 3. On each run the agent completed 500 trials at a specific conflict and volatility level, according to the experimental procedures described in Stimuli and Procedure. The total returned reward was tallied after each run, which was repeated for 200 iterations to provide a stable estimate of return for each agent and condition. The agent was tested on a range of pairwise conflict (<inline-formula><mml:math id="inf208"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>0.55</mml:mn><mml:mo>-</mml:mo><mml:mn>0.90</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) and volatility (<inline-formula><mml:math id="inf209"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mo>-</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) conditions.</p><p>After all agents were tested on all conditions, the <inline-formula><mml:math id="inf210"><mml:mi>β</mml:mi></mml:math></inline-formula> value for the agent that returned the greatest average reward across runs was identified as the optimal agent for that experimental condition.</p></sec><sec id="s4-3-2"><title>Drift diffusion model simulations</title><p>A normative drift-diffusion model (DDM) process (<xref ref-type="bibr" rid="bib62">Ratcliff, 1978</xref>) was used to simulate the outcomes of agents with different drift rates and boundary heights. The DDM assumes that evidence is stochastically accumulated as the log-likelihood ratio of evidence for two competing decision outcomes. Evidence is tracked by a single decision variable <inline-formula><mml:math id="inf211"><mml:mi>θ</mml:mi></mml:math></inline-formula> until reaching one of two boundary heights, representing the evidence criterion for committing to a choice. The dynamics of <inline-formula><mml:math id="inf212"><mml:mi>θ</mml:mi></mml:math></inline-formula> is given by.<disp-formula id="equ5"><label>(3)</label><mml:math id="m5"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mi>θ</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>v</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mi>W</mml:mi><mml:mspace width="thickmathspace"/><mml:mspace width="thickmathspace"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>for</mml:mtext></mml:mstyle><mml:mspace width="thickmathspace"/><mml:mspace width="thickmathspace"/><mml:mi>t</mml:mi><mml:mo>§gt;</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mo>;</mml:mo></mml:mstyle></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>a</mml:mi></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf213"><mml:mi>v</mml:mi></mml:math></inline-formula> is the mean strength of the evidence and <inline-formula><mml:math id="inf214"><mml:mi>σ</mml:mi></mml:math></inline-formula> is the standard deviation of a white noise process <inline-formula><mml:math id="inf215"><mml:mi>W</mml:mi></mml:math></inline-formula>, representing the degree of noise in the accumulation process. The choice and reaction time (RT) on each trial are determined by the first passage of <inline-formula><mml:math id="inf216"><mml:mi>θ</mml:mi></mml:math></inline-formula> through one of the two decision boundaries <inline-formula><mml:math id="inf217"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mn> 0</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>. In this formulation, <inline-formula><mml:math id="inf218"><mml:mi>θ</mml:mi></mml:math></inline-formula> remains fixed at a predefined starting point <inline-formula><mml:math id="inf219"><mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>/</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> until time <inline-formula><mml:math id="inf220"><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:math></inline-formula>, resulting in an unbiased evidence accumulation process when <inline-formula><mml:math id="inf221"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. In perceptual decision tasks, <inline-formula><mml:math id="inf222"><mml:mi>v</mml:mi></mml:math></inline-formula> reflects the signal-to-noise ratio of the stimulus. However, in a value-based decision task, <inline-formula><mml:math id="inf223"><mml:mi>v</mml:mi></mml:math></inline-formula> can be taken to reflect the difference between Q-values for the left and right actions. Thus, an increase (decrease) in <inline-formula><mml:math id="inf224"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> from 0 would correspond to a proportional increase (decrease) in <inline-formula><mml:math id="inf225"><mml:mi>v</mml:mi></mml:math></inline-formula>, leading to more rapid and frequent terminations of <inline-formula><mml:math id="inf226"><mml:mi>θ</mml:mi></mml:math></inline-formula> at the upper (lower) boundary <inline-formula><mml:math id="inf227"><mml:mi>a</mml:mi></mml:math></inline-formula> (0).</p><p>Using this DDM framework, we simulated a set of agents with different configurations of <inline-formula><mml:math id="inf228"><mml:mi>a</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf229"><mml:mi>v</mml:mi></mml:math></inline-formula>. Each agent completed 1,500 trials of a ‘left’ (upper bound) or ‘right’ (lower bound) choice task, with <inline-formula><mml:math id="inf230"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.26</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf231"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></inline-formula>. The values for <inline-formula><mml:math id="inf232"><mml:mi>a</mml:mi></mml:math></inline-formula> were sampled between 0.05 and 0.2 in intervals of 0.005. The values for <inline-formula><mml:math id="inf233"><mml:mi>v</mml:mi></mml:math></inline-formula> were sampled from 0 to 0.3 in 0.005 intervals. At the end of each agent run, the probability of selecting the left target, <inline-formula><mml:math id="inf234"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and the mean RT were recorded.</p></sec><sec id="s4-3-3"><title>Cognitive model</title><p>Our a priori <ext-link ext-link-type="uri" xlink:href="https://osf.io/5esn4">hypothesis</ext-link> was that the drift rate (<inline-formula><mml:math id="inf235"><mml:mi>v</mml:mi></mml:math></inline-formula>) and the boundary height (<inline-formula><mml:math id="inf236"><mml:mi>a</mml:mi></mml:math></inline-formula>) should change on a trial-by-trial basis according to two estimates of uncertainty from an ideal observer (<xref ref-type="bibr" rid="bib14">Bond et al., 2018</xref>). We adapted the below ideal observer calculations from a previous study (<xref ref-type="bibr" rid="bib77">Vaghi et al., 2017</xref>; for the original formulation of this reduced ideal observer model and its derivation, see <xref ref-type="bibr" rid="bib54">Nassar et al., 2010</xref>).</p><p>First, we assumed that reward feedback drove the belief in the reward associated with an action. We called the belief in the reward attributable to a given action <inline-formula><mml:math id="inf237"><mml:mi>B</mml:mi></mml:math></inline-formula>. This reward belief is learned separately for each action target. Given the chosen target (<inline-formula><mml:math id="inf238"><mml:mi>c</mml:mi></mml:math></inline-formula>) and the unchosen target (<inline-formula><mml:math id="inf239"><mml:mi>u</mml:mi></mml:math></inline-formula>), the belief in the mean reward for the chosen and unchosen targets on the next trial (trial <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) was calculated as:<disp-formula id="equ6"><label>(4)</label><mml:math id="m6"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf241"><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> denotes the learning rate, <inline-formula><mml:math id="inf242"><mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> the prediction error, and <inline-formula><mml:math id="inf243"><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> the change point probability on the current trial <inline-formula><mml:math id="inf244"><mml:mi>t</mml:mi></mml:math></inline-formula>, as discussed below. <inline-formula><mml:math id="inf245"><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> refers to the pooled expected value of both targets:<disp-formula id="equ7"><label>(5)</label><mml:math id="m7"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with <inline-formula><mml:math id="inf246"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> fixed based on the imposed target reward probabilities.</p><p>The prediction error, <inline-formula><mml:math id="inf247"><mml:msub><mml:mi>δ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula>, was the difference between the reward obtained for the target chosen and the model belief:<disp-formula id="equ8"><label>(6)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The signed belief in the reward difference between optimal and suboptimal targets (<inline-formula><mml:math id="inf248"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula>) was calculated as the difference in reward value belief between target identities:<disp-formula id="equ9"><label>(7)</label><mml:math id="m9"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Model confidence (<inline-formula><mml:math id="inf249"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>) was defined as a function of change point probability (<inline-formula><mml:math id="inf250"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>) and the variance of the generative distribution of points (<inline-formula><mml:math id="inf251"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>), both of which formed an estimate of relative uncertainty (<inline-formula><mml:math id="inf252"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:math></inline-formula>):<disp-formula id="equ10"><label>(8)</label><mml:math id="m10"><mml:mrow><mml:mi>R</mml:mi><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Thus <inline-formula><mml:math id="inf253"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> is calculated as:<disp-formula id="equ11"><label>(9)</label><mml:math id="m11"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>An estimate of the variance of the reward distribution, <inline-formula><mml:math id="inf254"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, was calculated as:<disp-formula id="equ12"><label>(10)</label><mml:math id="m12"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf255"><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula> is the fixed variance of the generative reward distribution.</p><p>The learning rate of the model (<inline-formula><mml:math id="inf256"><mml:mi>α</mml:mi></mml:math></inline-formula>) was determined by the change point probability (<inline-formula><mml:math id="inf257"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>) and the model confidence (<inline-formula><mml:math id="inf258"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>). Here, the learning rate was high if either (1) a change in the mean of the distribution of the difference in expected values was likely (<inline-formula><mml:math id="inf259"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula> is high) or (2) the estimate of the mean was highly imprecise (<inline-formula><mml:math id="inf260"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> was high):<disp-formula id="equ13"><label>(11)</label><mml:math id="m13"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To model how learners update action-values, we calculated an estimate of how often the same action gave a different reward (<xref ref-type="bibr" rid="bib77">Vaghi et al., 2017</xref>). This estimate gave our representation of change point probability, <inline-formula><mml:math id="inf261"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>. The change point probability approached one from below as the probability of a sample coming from a uniform distribution, relative to a Gaussian distribution, increased:<disp-formula id="equ14"><label>(12)</label><mml:math id="m14"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>U</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>U</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In <xref ref-type="disp-formula" rid="equ19">equation (12)</xref>, <inline-formula><mml:math id="inf262"><mml:mi>H</mml:mi></mml:math></inline-formula> refers to the hazard rate, or the global probability of a change point over trials:<disp-formula id="equ15"><label>(13)</label><mml:math id="m15"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Our <ext-link ext-link-type="uri" xlink:href="https://osf.io/5esn4">preregistered expectation</ext-link> was that the belief in the value of a given action and an estimate of environmental stability would target different parameters of the DDM model. Specifically, we hypothesized that the belief in the relative reward for the two choices, <inline-formula><mml:math id="inf263"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula>, would update the drift rate, <inline-formula><mml:math id="inf264"><mml:mi>v</mml:mi></mml:math></inline-formula>, or the rate of evidence accumulation:<disp-formula id="equ16"><label>(14)</label><mml:math id="m16"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>⋅</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>while the change point probability, <inline-formula><mml:math id="inf265"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>, would increase the boundary height, <inline-formula><mml:math id="inf266"><mml:mi>a</mml:mi></mml:math></inline-formula>, or the amount of evidence needed to make a decision:<disp-formula id="equ17"><label>(15)</label><mml:math id="m17"><mml:mrow><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-3-4"><title>Hierarchical drift diffusion modeling</title><p>First, to identify which decision parameters were sensitive to the onset of a change point, we estimated the posterior distribution of drift rate (<inline-formula><mml:math id="inf267"><mml:mi>v</mml:mi></mml:math></inline-formula>), boundary height (<inline-formula><mml:math id="inf268"><mml:mi>a</mml:mi></mml:math></inline-formula>), drift criterion (<inline-formula><mml:math id="inf269"><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:math></inline-formula>), starting point (<inline-formula><mml:math id="inf270"><mml:mi>z</mml:mi></mml:math></inline-formula>), and non-decision time (<inline-formula><mml:math id="inf271"><mml:mi>t</mml:mi></mml:math></inline-formula>) for the trial preceding the change point and the following three trials using stimulus-coded fitting methods for Experiment 1. We then looked for change-point-evoked effects in these parameters by comparing the overlap of the distributions for each decision parameter for each of these trials. If less than 5% of the mass of the trial-wise posterior distributions for a given decision parameter overlapped, we considered those distributions to exhibit change point sensitivity.</p><p>To identify the fits that best accounted for the data, we conducted a model selection process using Deviance Information Criterion (DIC) scores. We compared the set of fitted models (<xref ref-type="table" rid="table1">Table 1</xref>) to an intercept-only regression model (<inline-formula><mml:math id="inf272"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>). A lower DIC score indicates a model that loses less information. Here, a difference of ≤ two points from the lowest-scoring model cannot rule out the higher scoring model; a difference of 3–7 points suggests that the higher scoring model has considerably less support; and a difference of 10 points suggests essentially no support for the higher scoring model (<xref ref-type="bibr" rid="bib70">Spiegelhalter et al., 2002</xref>; <xref ref-type="bibr" rid="bib17">Burnham and Anderson, 1998</xref>).</p><p>We used these complementary model ‘pruning’ methods (i.e. distributional overlap and information loss) as an out-of-set filtering method to determine which decision parameters to include for the subsequent HDDM regression analyses in Experiment 2.</p><p>The best parameter fits, evaluated as above, were used to plot the decision trajectory (Decision vector representation) and to estimate the change-point-evoked relationship between those winning parameters (Model proposals and evaluation).</p><p>For Experiment 2, to assess whether and how much the ideal observer estimates of change point probability (<inline-formula><mml:math id="inf273"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>) and the belief in the value of the optimal target (<inline-formula><mml:math id="inf274"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mtext>B</mml:mtext></mml:mrow></mml:math></inline-formula>) updated the rate of evidence accumulation (<inline-formula><mml:math id="inf275"><mml:mi>v</mml:mi></mml:math></inline-formula>) and the amount of evidence needed to make a decision (<inline-formula><mml:math id="inf276"><mml:mi>a</mml:mi></mml:math></inline-formula>), we regressed the change-point-evoked ideal observer estimates onto the decision parameters using hierarchical drift diffusion model (HDDM) regression (<xref ref-type="bibr" rid="bib82">Wiecki et al., 2013</xref>). These ideal observer estimates of environmental uncertainty served as a more direct and continuous measure of the uncertainty we sought to induce with our experimental conditions (see <xref ref-type="fig" rid="fig4">Figure 4</xref> for how the experimental conditions impacted these estimates). Considering this more direct approach, we pooled change point probability and belief across all conditions and used these values as our predictors of drift rate and boundary height. Responses were accuracy-coded, and the belief in the difference between targets values was transformed to the belief in the value of the optimal target (<inline-formula><mml:math id="inf277"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mtext>optimal(t)</mml:mtext></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mtext>optimal(t)</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mtext>suboptimal(t)</mml:mtext></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>). This <ext-link ext-link-type="uri" xlink:href="https://github.com/kmbond/dynamic_decision_policy_reconfiguration/blob/master/revised_analysis/E2_evoked_regression.ipynb">approach</ext-link> allowed us to estimate trial-by-trial covariation between the ideal observer estimates and the decision parameters relative to the onset of a change point.</p><p>For both the HDDM fits for Experiment 1 and the regression analyses for Experiment 2, Markov-chain Monte-Carlo methods were used to sample the posterior distributions of the regression coefficients. Twenty thousand samples were drawn from the posterior distributions of the coefficients for each model, with 5000 burned samples and a thinning factor of five. We chose this number of samples to optimize the trade-off between computation time and the precision of parameter estimates, and all model parameters converged to stability. This method generates a distributional estimate of the regression coefficients instead of a single best fit.</p><p>To test our hypotheses regarding these HDDM regression estimates, we again used the posterior distributions of the regression parameters. To quantify the reliability of each regression coefficient, we computed the probability of the regression coefficient being greater than or less than 0 over the posterior distribution. We considered a regression coefficient to be reliable if the estimated coefficient maintained the same sign over at least 95% of the mass of the posterior distribution.</p></sec></sec><sec id="s4-4"><title>Analyses</title><sec id="s4-4-1"><title>General statistical analysis</title><p>Statistical analyses and data visualization were conducted using custom scripts written in R (R Foundation for Statistical Computing, version 3.4.3) and Python (Python Software Foundation, version 3.5.5).</p><p>To determine how many trials would be needed to detect proposed condition effects, we conducted a power analysis by way of parameter recovery. For this, we simulated accuracy and reaction time data using our hypothesized model (Cognitive model) and calculated the generative or “true” mean drift rate and boundary height parameters across trials. Then we conducted hierarchical parameter estimation given 200, 400, 600, 800, or 1000 simulated trials. The mean squared error of parameter estimates was stable at 600 trials for all decision parameters. Additionally, as a validation measure, we estimated parameters using component models (drift rate alone, boundary height alone) and a combined model (drift rate and boundary height). We found that the Deviance Information Criterion (DIC) scores among competing models were clearly separable at 600 trials, and in favor of the hypothesized model from which we generated the data, as expected (Acknowledgments). Based on these results, we used 600 trials per condition for each participant for our first experiment. We chose to recruit 24 participants for this experiment to fully counterbalance the four conditions (4! = 24).</p><p>Binary accuracy data were submitted to a mixed effects logistic regression analysis with either the degree of conflict (the probability of reward for the optimal target) or the degree of volatility (mean change point frequency) as predictors. The resulting log-likelihood estimates were transformed to likelihood for interpretability. RT data were log-transformed and submitted to a mixed effects linear regression analysis with the same predictors as in the previous analysis. To determine if participants used ideal observer estimates to update their behavior, two more mixed effects regression analyses were performed. Estimates of change point probability and the belief in the value of the optimal target served as predictors of reaction time and accuracy across groups. As before, we used a mixed logistic regression for accuracy data and a mixed linear regression for reaction time data.</p><p>Because we adopted a within-subjects design, all regression analyses of behavior modeled the non-independence of the data as constantly correlated data within participants (random intercepts). Unless otherwise specified, we report bootstrapped 95% confidence intervals for behavioral regression estimates. To prevent any bias in the regression estimates emerging from collinearity between predictors and to aid easy interpretation, all predictors for these regressions were mean-centered and standardized prior to analysis. The Satterthwaite approximation was used to estimate p-values for mixed effects models (<xref ref-type="bibr" rid="bib67">Satterthwaite, 1946</xref>; <xref ref-type="bibr" rid="bib46">Luke, 2017</xref>).</p></sec><sec id="s4-4-2"><title>Decision vector representation</title><p>To concisely capture the change-point-driven response in the relationship between the boundary height and the drift rate over time, we represented the relationship between these two decision variables in vector space. Trial-by-trial estimates of drift rate and boundary height were calculated from the winning HDDM regression equation and z-scored. Then the difference between each sequential set of <inline-formula><mml:math id="inf278"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> coordinates was calculated to produce a vector length. The arctangent between these subtracted values was computed to yield an angle in radians between sequential decision vectors (<xref ref-type="fig" rid="fig7">Figure 7B</xref>).</p><p>For Experiment 1, these computations were performed from the trial prior to the onset of the change point to eight trials after the change point. The initial window of nine trials was selected to maximize the overlap of stable data between high and low volatility conditions (see Supp. Fig. References). This resulted in a sequence of angles formed between trials –1 and 0 (<inline-formula><mml:math id="inf279"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> yielding <inline-formula><mml:math id="inf280"><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>), 0 and 1 (<inline-formula><mml:math id="inf281"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> yielding <inline-formula><mml:math id="inf282"><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>), and so on. To observe the timescale of these dynamics, a circular regression (<xref ref-type="bibr" rid="bib50">Mulder and Klugkist, 2017</xref>) was performed to determine how <inline-formula><mml:math id="inf283"><mml:mi>θ</mml:mi></mml:math></inline-formula> changed as a function of the number of trials after the change point:<disp-formula id="equ18"><mml:math id="m18"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mtext>…</mml:mtext></mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>8</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To quantitatively assess the number of trials needed for <inline-formula><mml:math id="inf284"><mml:mi>θ</mml:mi></mml:math></inline-formula> to stabilize, we calculated the probability that the posterior distributions of the regression estimates (<xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>) for sequential pairs of trials had equal means (<inline-formula><mml:math id="inf285"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula>). This result (<xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref>) provided an out-of-set constraint on the timescale of the decision response to consider for analogous analyses in Experiment 2.</p><p>Experiment 2 used the stability convergence analysis from Experiment 1 to guide the timescale of further circular analyses and, thus, placed a constraint on the complexity of the models proposed (Model proposals and evaluation). Because Experiment 2 took a replication-based approach, a separate model was fit for each participant for all proposed models. We report the mean and 95% CI of the posterior distributions of regression parameter estimates and the mean and standard deviation of estimates across subjects.</p><p>The circular regression analyses used Markov-chain Monte-Carlo (MCMC) methods to sample the posterior distributions of the regression coefficients. For both experiments, 10,000 effective samples were drawn from the posterior distributions of the coefficients for each model (<xref ref-type="bibr" rid="bib44">Kruschke and Vanpaemel, 2015</xref>). Traces were plotted against MCMC iteration for a visual assessment of equilibrium, the autocorrelation function was calculated to verify independence of MCMC steps, trace distributions were visually evaluated for normality, and point estimates of the mean value were verified to be contained within the 95% credible interval of the posterior distribution for the estimated coefficients.</p></sec><sec id="s4-4-3"><title>Pupil data preprocessing</title><p>Pupil diameter data were segmented to capture the interval from 500ms prior to trial onset to the end of the 1500ms trial, for a total of 2000ms of data per trial. While the latency in the phasic component of the task-evoked pupillary response ranges from 100 to 200ms on average (<xref ref-type="bibr" rid="bib7">Beatty, 1982</xref>), suggesting that our segmentation should end 200ms after the trial ending, participants tended to blink after the offset of the stimulus and during the intertrial interval (see <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref> for a representative sample of blink timing). Because of this, we ended the analysis window with the offset of the stimulus. Following segmentation, pupil diameter samples marked as blinks by the Eyelink 1000 default blink detection algorithm and zero- or negative-valued samples were replaced by linearly interpolating between adjacent valid samples. Pupil diameter samples with values exceeding three standard deviations of the mean value for that session were likewise removed and interpolated. Interpolated data were bandpass filtered using a 0.01–5 Hz second-order Butterworth filter. Median pupil diameter calculated over the 500ms prior to the onset of the stimulus was subtracted from the trial data. Finally, processed data were z-scored by session.</p><p>For each trial interval, we characterized the evoked response as the mean of the pupil data over that interval, the latency to peak onset and offset, the latency to peak amplitude, the peak amplitude, and the area under the curve of the phasic pupillary response (<xref ref-type="fig" rid="fig9">Figure 9A</xref>). We then submitted these metrics to principal component analysis to reduce their dimensionality while capturing maximum variance. Evoked response characterization and principal component analysis were conducted for each session and for each subject.</p><p>The 95% CI for the number of principal components needed to explain 95% of the variance in the data was calculated over subjects and sessions to determine the number of principal components to keep for further analysis.</p><p>To aid in interpreting further analysis using the selected principal components, the feature importance of each pupil metric was calculated for each principal component and aggregated across subjects as a mean and bootstrapped 95% CI (<xref ref-type="fig" rid="fig9">Figure 9B</xref>).</p><p>Note that we also conducted a similar analysis using more conventional methods to assess the task-evoked pupillary response and observed another null effect. Specifically, if we take the derivative of the evoked pupillary response with respect to time (<xref ref-type="bibr" rid="bib64">Reimer et al., 2016</xref>) and then characterize the pupillary response with the above metrics and conduct principal component analysis, we again see no evidence for a relationship between the pupillary response and the decision trajectory. Additionally, we observe no relationship between our experimental manipulations of conflict and volatility and these metrics, or a change-point evoked shift in pre-stimulus pupillary response (<xref ref-type="bibr" rid="bib33">Gilzenrat et al., 2010</xref>, <xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13</xref>). As such, we caution the reader to view our pupillary results in light of this lack of replication of pre-established exploration-driven pupillary responses.</p></sec><sec id="s4-4-4"><title>Model proposals and evaluation</title><p>To assess the hypothesized influences on <inline-formula><mml:math id="inf286"><mml:mi>θ</mml:mi></mml:math></inline-formula> in Experiment 2, we began our model set proposal with a null hypothesis. Our null model estimates decision dynamics as a function of the intercept, or the average of <inline-formula><mml:math id="inf287"><mml:mi>θ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ19"><mml:math id="m19"><mml:mrow><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Next, we estimated decision dynamics solely as a function of time relative to a change point, with the timescale of consideration determined by the results of the stability convergence analysis from Experiment 1. We call this the evoked response model:<disp-formula id="equ20"><mml:math id="m20"><mml:mrow><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We first evaluated whether the posterior probability of the evoked response model given the data was greater than the posterior probability for the absolute null model. If the lower bound of the 95% CI of the posterior probability for the time-null model exceeded the upper bound of the 95% CI for the absolute null model (i.e the posterior probability was greater for the evoked response model and the CIs were non-overlapping), we proceeded to evaluate the evidence for alternative models relative to this evoked response model. We evaluated the statistical reliability of the posterior probabilities using a bootstrapped 95% CI computed over subjects.</p><p>We considered an explicit set of hypotheses regarding the effect of the change-point-evoked pupillary response on boundary height and drift rate dynamics (see <xref ref-type="fig" rid="fig10">Figure 10</xref> for the full set of models considered). The first two principal components of the set of pupil metrics, which we term the timing and magnitude components, respectively, were included in this model set to evaluate the effect of the timing and magnitude of noradrenergic dynamics on the change-point-evoked decision manifold. Under the assumption of a neuromodulatory effect on decision dynamics, these principal components were shifted forward by one trial to match the expected timing of the response to neuromodulation.</p><p>To determine whether perturbations of volatility and conflict affected change-point-evoked decision dynamics, we estimated the evoked decision dynamics as a function of <inline-formula><mml:math id="inf288"><mml:mi>λ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf289"><mml:mi>p</mml:mi></mml:math></inline-formula>, where <inline-formula><mml:math id="inf290"><mml:mi>λ</mml:mi></mml:math></inline-formula> corresponds to the average length of an epoch and <inline-formula><mml:math id="inf291"><mml:mi>p</mml:mi></mml:math></inline-formula> corresponds to the mean probability of reward for optimal target selection (see <xref ref-type="table" rid="table1">Table 1</xref> for the full set of models considered).</p><p>We used Bayes Factors to quantify the ratio of evidence for competing hypotheses (<xref ref-type="bibr" rid="bib80">Wagenmakers, 2007</xref>). To estimate whether these models accounted for decision dynamics beyond the effect of time relative to a change point alone, we calculate the Bayes Factor for the evoked response model relative to each candidate model (<inline-formula><mml:math id="inf292"><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mn>01</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>). Finally, we calculate the posterior probability of the null model given the full set of alternative models (<xref ref-type="bibr" rid="bib80">Wagenmakers, 2007</xref>). Note that this approach assumes that each model has equal a priori plausibility.</p><p>Bayes Factor visualizations represent the mean and bootstrapped 95% CI with 1000 bootstrap iterations.</p></sec></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Resources, Software, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Methodology, Software, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation, Project administration</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Funding acquisition, Investigation, Project administration, Resources, Supervision, Validation, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Neurologically healthy adults were recruited from the local university population. All procedures were approved by the Carnegie Mellon University Institutional Review Board (Approval Code: 2018_00000195; Funding: Air Force Research Laboratory, Grant Office ID: 180119). All research participants provided informed consent to participate in the study and consent to publish any research findings based on their provided data.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-65540-transrepform1-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Behavioral data and their computational derivatives are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/kmbond/dynamic_decision_policy_reconfiguration">https://github.com/kmbond/dynamic_decision_policy_reconfiguration</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:de31a380724a5954d16e67a0a6eda17431e11607;origin=https://github.com/kmbond/dynamic_decision_policy_reconfiguration;visit=swh:1:snp:561cc2fa2a2a7aa9aba3d43fe505a2d36b992b7d;anchor=swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8">swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8</ext-link>). Code used to generate figures can be found here. Raw pupillometry data (DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1184/R1/13543133">10.1184/R1/13543133</ext-link>), the features of the task-evoked pupillometry response (DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1184/R1/13543067.v1">10.1184/R1/13543067.v1</ext-link>), and the principal components calculated from those features (DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1184/R1/13543160.v1">10.1184/R1/13543160.v1</ext-link>) are available <ext-link ext-link-type="uri" xlink:href="https://kilthub.cmu.edu/projects/Dynamic_decision_policy_reconfiguration_under_outcome_uncertainty/96116">here</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Bond</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Raw pupillometry data</data-title><source>KiltHub</source><pub-id pub-id-type="doi">10.1184/R1/13543133</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Bond</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Features of task-evoked pupillary response</data-title><source>KiltHub</source><pub-id pub-id-type="doi">10.1184/R1/13543067.v1</pub-id></element-citation></p><p><element-citation id="dataset3" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Bond</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Principal components of task-evoked pupillary response</data-title><source>KiltHub</source><pub-id pub-id-type="doi">10.1184/R1/13543160.v1</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank all members of the Cognitive Axon Lab for their feedback during the development of this work. We also thank Marlene Behrmann and Michael Granovetter for their help with eye-tracking and pupillometry data collection and Chris Wordingham for his programming and engineering consultation in the early phases of this project.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Addicott</surname><given-names>MA</given-names></name><name><surname>Pearson</surname><given-names>JM</given-names></name><name><surname>Sweitzer</surname><given-names>MM</given-names></name><name><surname>Barack</surname><given-names>DL</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A primer on foraging and the explore/exploit trade-off for psychiatry research</article-title><source>Neuropsychopharmacology: Official Publication of the American College of Neuropsychopharmacology</source><volume>42</volume><fpage>1931</fpage><lpage>1939</lpage><pub-id pub-id-type="doi">10.1038/npp.2017.108</pub-id><pub-id pub-id-type="pmid">28553839</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexandrowicz</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The diffusion model visualizer: an interactive tool to understand the diffusion model parameters</article-title><source>Psychological Research</source><volume>84</volume><fpage>1157</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1007/s00426-018-1112-6</pub-id><pub-id pub-id-type="pmid">30361811</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Bloom</surname><given-names>FE</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Activity of norepinephrine-containing locus coeruleus neurons in behaving rats anticipates fluctuations in the sleep-waking cycle</article-title><source>The Journal of Neuroscience</source><volume>1</volume><fpage>876</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.01-08-00876.1981</pub-id><pub-id pub-id-type="pmid">7346592</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Rajkowski</surname><given-names>J</given-names></name><name><surname>Cohen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Role of locus coeruleus in attention and behavioral flexibility</article-title><source>Biological Psychiatry</source><volume>46</volume><fpage>1309</fpage><lpage>1320</lpage><pub-id pub-id-type="doi">10.1016/s0006-3223(99)00140-7</pub-id><pub-id pub-id-type="pmid">10560036</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bariselli</surname><given-names>S</given-names></name><name><surname>Fobbs</surname><given-names>WC</given-names></name><name><surname>Creed</surname><given-names>MC</given-names></name><name><surname>Kravitz</surname><given-names>AV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A competitive model for striatal action selection</article-title><source>Brain Research</source><volume>1713</volume><fpage>70</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2018.10.009</pub-id><pub-id pub-id-type="pmid">30300636</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Task-evoked pupillary responses, processing load, and the structure of processing resources</article-title><source>Psychological Bulletin</source><volume>91</volume><fpage>276</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.91.2.276</pub-id><pub-id pub-id-type="pmid">7071262</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bland</surname><given-names>AR</given-names></name><name><surname>Schaefer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Different varieties of uncertainty in human decision-making</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>85</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00085</pub-id><pub-id pub-id-type="pmid">22701401</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Optimal decision-making theories: linking neurobiology with behaviour</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>118</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.12.006</pub-id><pub-id pub-id-type="pmid">17276130</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Gurney</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The basal ganglia and cortex implement optimal decision making between alternative actions</article-title><source>Neural Computation</source><volume>19</volume><fpage>442</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.2.442</pub-id><pub-id pub-id-type="pmid">17206871</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name><name><surname>Forstmann</surname><given-names>BU</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The neural basis of the speed-accuracy tradeoff</article-title><source>Trends in Neurosciences</source><volume>33</volume><fpage>10</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2009.09.002</pub-id><pub-id pub-id-type="pmid">19819033</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Larsen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Integration of reinforcement learning and optimal decision-making theories of the basal ganglia</article-title><source>Neural Computation</source><volume>23</volume><fpage>817</fpage><lpage>851</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00103</pub-id><pub-id pub-id-type="pmid">21222528</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bond</surname><given-names>K</given-names></name><name><surname>Dunovan</surname><given-names>K</given-names></name><name><surname>Verstynen</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>The Influence of Volatility and Conflict on Adaptive Decision Making</source><publisher-name>OSF</publisher-name></element-citation></ref><ref id="bib15"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bond</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Dynamic decision policy reconfiguration under outcome uncertainty</data-title><version designator="swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8">swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:de31a380724a5954d16e67a0a6eda17431e11607;origin=https://github.com/kmbond/dynamic_decision_policy_reconfiguration;visit=swh:1:snp:561cc2fa2a2a7aa9aba3d43fe505a2d36b992b7d;anchor=swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8">https://archive.softwareheritage.org/swh:1:dir:de31a380724a5954d16e67a0a6eda17431e11607;origin=https://github.com/kmbond/dynamic_decision_policy_reconfiguration;visit=swh:1:snp:561cc2fa2a2a7aa9aba3d43fe505a2d36b992b7d;anchor=swh:1:rev:0486705db0f004a5e1365759f5f5a391790771f8</ext-link></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouret</surname><given-names>S</given-names></name><name><surname>Sara</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Network reset: a simplified overarching theory of locus coeruleus noradrenaline function</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>574</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2005.09.002</pub-id><pub-id pub-id-type="pmid">16165227</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Burnham</surname><given-names>KP</given-names></name><name><surname>Anderson</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="1998">1998</year><chapter-title>Practical use of the information-theoretic approach</chapter-title><person-group person-group-type="editor"><name><surname>Burnham</surname><given-names>KP</given-names></name></person-group><source>Model Selection and Inference</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer</publisher-name><fpage>75</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1007/978-1-4757-2917-7</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Byrne</surname><given-names>JEM</given-names></name><name><surname>Hughes</surname><given-names>ME</given-names></name><name><surname>Rossell</surname><given-names>SL</given-names></name><name><surname>Johnson</surname><given-names>SL</given-names></name><name><surname>Murray</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Time of day differences in neural reward functioning in healthy young men</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>8895</fpage><lpage>8900</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0918-17.2017</pub-id><pub-id pub-id-type="pmid">28842409</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caballero</surname><given-names>JA</given-names></name><name><surname>Humphries</surname><given-names>MD</given-names></name><name><surname>Gurney</surname><given-names>KN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A probabilistic, distributed, recursive mechanism for decision-making in the brain</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006033</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006033</pub-id><pub-id pub-id-type="pmid">29614077</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanagh</surname><given-names>JF</given-names></name><name><surname>Wiecki</surname><given-names>TV</given-names></name><name><surname>Kochar</surname><given-names>A</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Eye tracking and pupillometry are indicators of dissociable latent decision processes</article-title><source>Journal of Experimental Psychology. General</source><volume>143</volume><fpage>1476</fpage><lpage>1488</lpage><pub-id pub-id-type="doi">10.1037/a0035813</pub-id><pub-id pub-id-type="pmid">24548281</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chakroun</surname><given-names>K</given-names></name><name><surname>Mathar</surname><given-names>D</given-names></name><name><surname>Wiehler</surname><given-names>A</given-names></name><name><surname>Ganzer</surname><given-names>F</given-names></name><name><surname>Peters</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dopaminergic modulation of the exploration/exploitation trade-off in human decision-making</article-title><source>eLife</source><volume>9</volume><elocation-id>e51260</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51260</pub-id><pub-id pub-id-type="pmid">32484779</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Yu</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Phasic norepinephrine: a neural interrupt signal for unexpected events</article-title><source>Network</source><volume>17</volume><fpage>335</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1080/09548980601004024</pub-id><pub-id pub-id-type="pmid">17162459</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunovan</surname><given-names>K</given-names></name><name><surname>Lynch</surname><given-names>B</given-names></name><name><surname>Molesworth</surname><given-names>T</given-names></name><name><surname>Verstynen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Competing basal ganglia pathways determine the difference between stopping and deciding not to go</article-title><source>eLife</source><volume>4</volume><elocation-id>e08723</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08723</pub-id><pub-id pub-id-type="pmid">26402462</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunovan</surname><given-names>K</given-names></name><name><surname>Verstynen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Errors in action timing and inhibition facilitate learning by tuning distinct mechanisms in the underlying decision process</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>2251</fpage><lpage>2264</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1924-18.2019</pub-id><pub-id pub-id-type="pmid">30655353</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunovan</surname><given-names>K</given-names></name><name><surname>Vich</surname><given-names>C</given-names></name><name><surname>Clapp</surname><given-names>M</given-names></name><name><surname>Verstynen</surname><given-names>T</given-names></name><name><surname>Rubin</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reward-driven changes in striatal pathway competition shape evidence evaluation in decision-making</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006998</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006998</pub-id><pub-id pub-id-type="pmid">31060045</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>SF</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Zarnescu</surname><given-names>S</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The Dynamics of Explore-Exploit Decisions Reveal a Signal-to-Noise Mechanism for Random Exploration</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/uepr7</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forstmann</surname><given-names>BU</given-names></name><name><surname>Dutilh</surname><given-names>G</given-names></name><name><surname>Brown</surname><given-names>S</given-names></name><name><surname>Neumann</surname><given-names>J</given-names></name><name><surname>von Cramon</surname><given-names>DY</given-names></name><name><surname>Ridderinkhof</surname><given-names>KR</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Striatum and pre-SMA facilitate decision-making under time pressure</article-title><source>PNAS</source><volume>105</volume><fpage>17538</fpage><lpage>17542</lpage><pub-id pub-id-type="doi">10.1073/pnas.0805903105</pub-id><pub-id pub-id-type="pmid">18981414</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forstmann</surname><given-names>BU</given-names></name><name><surname>Anwander</surname><given-names>A</given-names></name><name><surname>Schäfer</surname><given-names>A</given-names></name><name><surname>Neumann</surname><given-names>J</given-names></name><name><surname>Brown</surname><given-names>S</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Cortico-striatal connections predict control over speed and accuracy in perceptual decision making</article-title><source>PNAS</source><volume>107</volume><fpage>15916</fpage><lpage>15920</lpage><pub-id pub-id-type="doi">10.1073/pnas.1004932107</pub-id><pub-id pub-id-type="pmid">20733082</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster, MSLS</surname><given-names>ED</given-names></name><name><surname>Deardorff, MLIS</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Open Science Framework (OSF)</article-title><source>Journal of the Medical Library Association</source><volume>105</volume><elocation-id>88</elocation-id><pub-id pub-id-type="doi">10.5195/JMLA.2017.88</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname><given-names>I</given-names></name><name><surname>Tarr</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Becoming a “Greeble” expert: exploring mechanisms for face recognition</article-title><source>Vision Research</source><volume>37</volume><fpage>1673</fpage><lpage>1682</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(96)00286-6</pub-id><pub-id pub-id-type="pmid">9231232</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Tzovaras</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dopaminergic genes are associated with both directed and random exploration</article-title><source>Neuropsychologia</source><volume>120</volume><fpage>97</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2018.10.009</pub-id><pub-id pub-id-type="pmid">30347192</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Believing in dopamine</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>703</fpage><lpage>714</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0220-7</pub-id><pub-id pub-id-type="pmid">31570826</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilzenrat</surname><given-names>MS</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>10</volume><fpage>252</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.3758/CABN.10.2.252</pub-id><pub-id pub-id-type="pmid">20498349</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herz</surname><given-names>DM</given-names></name><name><surname>Zavala</surname><given-names>BA</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural correlates of decision thresholds in the human subthalamic nucleus</article-title><source>Current Biology</source><volume>26</volume><fpage>916</fpage><lpage>920</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.01.051</pub-id><pub-id pub-id-type="pmid">26996501</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herz</surname><given-names>DM</given-names></name><name><surname>Tan</surname><given-names>H</given-names></name><name><surname>Brittain</surname><given-names>JS</given-names></name><name><surname>Fischer</surname><given-names>P</given-names></name><name><surname>Cheeran</surname><given-names>B</given-names></name><name><surname>Green</surname><given-names>AL</given-names></name><name><surname>FitzGerald</surname><given-names>J</given-names></name><name><surname>Aziz</surname><given-names>TZ</given-names></name><name><surname>Ashkan</surname><given-names>K</given-names></name><name><surname>Little</surname><given-names>S</given-names></name><name><surname>Foltynie</surname><given-names>T</given-names></name><name><surname>Limousin</surname><given-names>P</given-names></name><name><surname>Zrinzo</surname><given-names>L</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct mechanisms mediate speed-accuracy adjustments in cortico-subthalamic networks</article-title><source>eLife</source><volume>6</volume><elocation-id>e21481</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21481</pub-id><pub-id pub-id-type="pmid">28137358</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heston</surname><given-names>J</given-names></name><name><surname>Friedman</surname><given-names>A</given-names></name><name><surname>Baqai</surname><given-names>M</given-names></name><name><surname>Bavafa</surname><given-names>N</given-names></name><name><surname>Aron</surname><given-names>AR</given-names></name><name><surname>Hnasko</surname><given-names>TS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Activation of subthalamic nucleus stop circuit disrupts cognitive performance</article-title><source>ENeuro</source><volume>7</volume><elocation-id>ENEURO.0159-20.2020</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0159-20.2020</pub-id><pub-id pub-id-type="pmid">32887694</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hurwicz</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>On informationally decentralized systems</article-title><source>Decision and Organization</source><volume>1</volume><elocation-id>320</elocation-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jahfari</surname><given-names>S</given-names></name><name><surname>Ridderinkhof</surname><given-names>KR</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Waldorp</surname><given-names>LJ</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cross-task contributions of frontobasal ganglia circuitry in response inhibition and conflict-induced slowing</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>1969</fpage><lpage>1983</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy076</pub-id><pub-id pub-id-type="pmid">29912363</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jeffreys</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>The Theory of Probability</source><publisher-name>OUP Oxford Press</publisher-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil diameter predicts changes in the exploration-exploitation trade-off: evidence for the adaptive gain theory</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>1587</fpage><lpage>1596</lpage><pub-id pub-id-type="doi">10.1162/jocn.2010.21548</pub-id><pub-id pub-id-type="pmid">20666595</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between Pupil Diameter and Neuronal Activity in the Locus Coeruleus, Colliculi, and Cingulate Cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakade</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dopamine: generalization and bonuses</article-title><source>Neural Networks</source><volume>15</volume><fpage>549</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1016/s0893-6080(02)00048-5</pub-id><pub-id pub-id-type="pmid">12371511</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keung</surname><given-names>W</given-names></name><name><surname>Hagen</surname><given-names>TA</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Regulation of evidence accumulation by pupil-linked arousal processes</article-title><source>Nature Human Behaviour</source><volume>3</volume><fpage>636</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0551-4</pub-id><pub-id pub-id-type="pmid">31190022</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kruschke</surname><given-names>JK</given-names></name><name><surname>Vanpaemel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Bayesian estimation in hierarchical models</chapter-title><person-group person-group-type="editor"><name><surname>Busemeyer</surname><given-names>JR</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Townsend</surname><given-names>JT</given-names></name><name><surname>Eidels</surname><given-names>A</given-names></name></person-group><source>The Oxford Handbook of Computational and Mathematical Psychology</source><publisher-name>Oxford University Press</publisher-name><fpage>279</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1093/oxfordhb/9780199957996.013.13</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ledyard</surname><given-names>JO</given-names></name></person-group><year iso-8601-date="1989">1989</year><chapter-title>Incentive compatibility</chapter-title><person-group person-group-type="editor"><name><surname>Eatwell</surname><given-names>J</given-names></name><name><surname>Milgate</surname><given-names>M</given-names></name><name><surname>Newman</surname><given-names>P</given-names></name></person-group><source>Allocation, Information and Markets</source><publisher-name>Springer</publisher-name><fpage>1</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1007/978-1-349-20215-7</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luke</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Evaluating significance in linear mixed-effects models in R</article-title><source>Behavior Research Methods</source><volume>49</volume><fpage>1494</fpage><lpage>1502</lpage><pub-id pub-id-type="doi">10.3758/s13428-016-0809-y</pub-id><pub-id pub-id-type="pmid">27620283</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>McClure</surname><given-names>SM</given-names></name><name><surname>Gilzenrat</surname><given-names>MS</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><conf-name>An exploration-exploitation model based on norepinepherine and dopamine activity</conf-name><article-title>Advances in Neural Information Processing Systems</article-title><fpage>867</fpage><lpage>874</lpage></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mendonça</surname><given-names>AG</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Vicente</surname><given-names>MI</given-names></name><name><surname>DeWitt</surname><given-names>EEJ</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The impact of learning on perceptual decisions and its implication for speed-accuracy tradeoffs</article-title><source>Nature Communications</source><volume>11</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1038/s41467-020-16196-7</pub-id><pub-id pub-id-type="pmid">32488065</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikhael</surname><given-names>JG</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning Reward Uncertainty in the Basal Ganglia</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005062</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005062</pub-id><pub-id pub-id-type="pmid">27589489</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulder</surname><given-names>K</given-names></name><name><surname>Klugkist</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Bayesian estimation and hypothesis tests for a circular Generalized Linear Model</article-title><source>Journal of Mathematical Psychology</source><volume>80</volume><fpage>4</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2017.07.001</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name><name><surname>O’connell</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupillometry and P3 index the locus coeruleus-noradrenergic arousal function in humans</article-title><source>Psychophysiology</source><volume>48</volume><fpage>1532</fpage><lpage>1543</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2011.01226.x</pub-id><pub-id pub-id-type="pmid">21762458</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Vandekerckhove</surname><given-names>J</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil-linked arousal determines variability in perceptual decision making</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003854</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003854</pub-id><pub-id pub-id-type="pmid">25232732</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>G</given-names></name><name><surname>Nicholas</surname><given-names>CL</given-names></name><name><surname>Kleiman</surname><given-names>J</given-names></name><name><surname>Dwyer</surname><given-names>R</given-names></name><name><surname>Carrington</surname><given-names>MJ</given-names></name><name><surname>Allen</surname><given-names>NB</given-names></name><name><surname>Trinder</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Nature’s clocks and human mood: the circadian system modulates reward motivation</article-title><source>Emotion</source><volume>9</volume><fpage>705</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1037/a0017080</pub-id><pub-id pub-id-type="pmid">19803592</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id><pub-id pub-id-type="pmid">20844132</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>JX</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Making predictions in a changing world-inference, uncertainty, and learning</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>105</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00105</pub-id><pub-id pub-id-type="pmid">23785310</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payzan-LeNestour</surname><given-names>E</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1001048</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1001048</pub-id><pub-id pub-id-type="pmid">21283774</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payzan-Lenestour</surname><given-names>E</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Do not bet on the unknown versus try to find out more: Estimation uncertainty and “unexpected uncertainty” both modulate exploration</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>150</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00150</pub-id><pub-id pub-id-type="pmid">23087606</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedersen</surname><given-names>ML</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Biele</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The drift diffusion model as the choice rule in reinforcement learning</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>24</volume><fpage>1234</fpage><lpage>1251</lpage><pub-id pub-id-type="doi">10.3758/s13423-016-1199-y</pub-id><pub-id pub-id-type="pmid">27966103</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Prat-Carrabin</surname><given-names>A</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Da Silveira</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Human Inference in Changing Environments with Temporal Structure</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/720516</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajkowski</surname><given-names>J</given-names></name><name><surname>Kubiak</surname><given-names>P</given-names></name><name><surname>Aston-Jones</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Locus coeruleus activity in monkey: phasic and tonic changes are associated with altered vigilance</article-title><source>Brain Research Bulletin</source><volume>35</volume><fpage>607</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1016/0361-9230(94)90175-9</pub-id><pub-id pub-id-type="pmid">7859118</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>A theory of memory retrieval</article-title><source>Psychological Review</source><volume>85</volume><fpage>59</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.85.2.59</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Reinforcement-based decision making in corticostriatal circuits: mutual constraints by neurocomputational and diffusion models</article-title><source>Neural Computation</source><volume>24</volume><fpage>1186</fpage><lpage>1229</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00270</pub-id><pub-id pub-id-type="pmid">22295983</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Rodenkirch</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id><pub-id pub-id-type="pmid">27824036</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>JE</given-names></name><name><surname>Vich</surname><given-names>C</given-names></name><name><surname>Clapp</surname><given-names>M</given-names></name><name><surname>Noneman</surname><given-names>K</given-names></name><name><surname>Verstynen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The credit assignment problem in cortico-basal ganglia-thalamic networks: A review, a problem and a possible solution</article-title><source>The European Journal of Neuroscience</source><volume>53</volume><fpage>2234</fpage><lpage>2253</lpage><pub-id pub-id-type="doi">10.1111/ejn.14745</pub-id><pub-id pub-id-type="pmid">32302439</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadeghiyeh</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Alberhasky</surname><given-names>MR</given-names></name><name><surname>Kyllo</surname><given-names>HM</given-names></name><name><surname>Shenhav</surname><given-names>A</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Temporal discounting correlates with directed exploration but not with random exploration</article-title><source>Scientific Reports</source><volume>10</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1038/s41598-020-60576-4</pub-id><pub-id pub-id-type="pmid">32132573</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satterthwaite</surname><given-names>FE</given-names></name></person-group><year iso-8601-date="1946">1946</year><article-title>An approximate distribution of estimates of variance components</article-title><source>Biometrics</source><volume>2</volume><fpage>110</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.2307/3002019</pub-id><pub-id pub-id-type="pmid">20287815</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Apicella</surname><given-names>P</given-names></name><name><surname>Scarnati</surname><given-names>E</given-names></name><name><surname>Ljungberg</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Neuronal activity in monkey ventral striatum related to the expectation of reward</article-title><source>The Journal of Neuroscience</source><volume>12</volume><fpage>4595</fpage><lpage>4610</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.12-12-04595.1992</pub-id><pub-id pub-id-type="pmid">1464759</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sirois</surname><given-names>S</given-names></name><name><surname>Brisson</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupillometry</article-title><source>Wiley Interdisciplinary Reviews. Cognitive Science</source><volume>5</volume><fpage>679</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1002/wcs.1323</pub-id><pub-id pub-id-type="pmid">26308873</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiegelhalter</surname><given-names>DJ</given-names></name><name><surname>Best</surname><given-names>NG</given-names></name><name><surname>Carlin</surname><given-names>BP</given-names></name><name><surname>van der Linde</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Bayesian measures of model complexity and fit</article-title><source>Journal of the Royal Statistical Society</source><volume>64</volume><fpage>583</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1111/1467-9868.00353</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiers</surname><given-names>AS</given-names></name><name><surname>Calne</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="1969">1969</year><article-title>Action of dopamine on the human iris</article-title><source>British Medical Journal</source><volume>4</volume><fpage>333</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.1136/bmj.4.5679.333</pub-id><pub-id pub-id-type="pmid">5386267</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Reinforcement Learning: An Introduction</article-title><source>IEEE Transactions on Neural Networks</source><volume>9</volume><elocation-id>1054</elocation-id><pub-id pub-id-type="doi">10.1109/TNN.1998.712192</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introduction</source><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tajima</surname><given-names>S</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Patel</surname><given-names>N</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optimal policy for multi-alternative decisions</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1503</fpage><lpage>1511</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0453-9</pub-id><pub-id pub-id-type="pmid">31384015</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Braun</surname><given-names>A</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</article-title><source>Nature Communications</source><volume>8</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1038/ncomms14637</pub-id><pub-id pub-id-type="pmid">28256514</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Urai</surname><given-names>A</given-names></name><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Donner</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><conf-name>Choice History Biases Subsequent Evidence Accumulation</conf-name><article-title>2018 Conference on Cognitive Computational Neuroscience</article-title><conf-loc>Philadelphia, Pennsylvania, USA</conf-loc><pub-id pub-id-type="doi">10.32470/CCN.2018.1192-0</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaghi</surname><given-names>MM</given-names></name><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Sule</surname><given-names>A</given-names></name><name><surname>Fineberg</surname><given-names>NA</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name><name><surname>De Martino</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Compulsivity Reveals a Novel Dissociation between Action and Confidence</article-title><source>Neuron</source><volume>96</volume><fpage>348</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.006</pub-id><pub-id pub-id-type="pmid">28965997</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kempen</surname><given-names>J</given-names></name><name><surname>Loughnane</surname><given-names>GM</given-names></name><name><surname>Newman</surname><given-names>DP</given-names></name><name><surname>Kelly</surname><given-names>SP</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name><name><surname>O’Connell</surname><given-names>RG</given-names></name><name><surname>Bellgrove</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Behavioural and neural signatures of perceptual decision-making are modulated by pupil-linked arousal</article-title><source>eLife</source><volume>8</volume><elocation-id>e42541</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.42541</pub-id><pub-id pub-id-type="pmid">30882347</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vich</surname><given-names>C</given-names></name><name><surname>Dunovan</surname><given-names>K</given-names></name><name><surname>Verstynen</surname><given-names>T</given-names></name><name><surname>Rubin</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Corticostriatal synaptic weight evolution in a two-alternative forced choice task: a computational study</article-title><source>Communications in Nonlinear Science and Numerical Simulation</source><volume>82</volume><elocation-id>105048</elocation-id><pub-id pub-id-type="doi">10.1016/j.cnsns.2019.105048</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A practical solution to the pervasive problems of p values</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>14</volume><fpage>779</fpage><lpage>804</lpage><pub-id pub-id-type="doi">10.3758/bf03194105</pub-id><pub-id pub-id-type="pmid">18087943</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>W</given-names></name><name><surname>Rubin</surname><given-names>JE</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Role of the indirect pathway of the basal ganglia in perceptual decision making</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>4052</fpage><lpage>4064</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3611-14.2015</pub-id><pub-id pub-id-type="pmid">25740532</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiecki</surname><given-names>TV</given-names></name><name><surname>Sofer</surname><given-names>I</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>HDDM: Hierarchical Bayesian estimation of the Drift-Diffusion Model in Python</article-title><source>Frontiers in Neuroinformatics</source><volume>7</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2013.00014</pub-id><pub-id pub-id-type="pmid">23935581</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Bayesian online learning of the hazard rate in change-point problems</article-title><source>Neural Computation</source><volume>22</volume><fpage>2452</fpage><lpage>2476</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00007</pub-id><pub-id pub-id-type="pmid">20569174</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inferring relevance in a changing world</article-title><source>Frontiers in Human Neuroscience</source><volume>5</volume><elocation-id>189</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00189</pub-id><pub-id pub-id-type="pmid">22291631</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Geana</surname><given-names>A</given-names></name><name><surname>White</surname><given-names>JM</given-names></name><name><surname>Ludvig</surname><given-names>EA</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Humans use directed and random exploration to solve the explore-exploit dilemma</article-title><source>Journal of Experimental Psychology. General</source><volume>143</volume><fpage>2074</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1037/a0038199</pub-id><pub-id pub-id-type="pmid">25347535</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Bonawitz</surname><given-names>E</given-names></name><name><surname>Costa</surname><given-names>VD</given-names></name><name><surname>Ebitz</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Balancing exploration and exploitation with information and randomization</article-title><source>Current Opinion in Behavioral Sciences</source><volume>38</volume><fpage>49</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.10.001</pub-id><pub-id pub-id-type="pmid">33184605</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname><given-names>MM</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Yoon</surname><given-names>AM</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Causal contribution and dynamical encoding in the striatum during evidence accumulation</article-title><source>eLife</source><volume>7</volume><elocation-id>e34929</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34929</pub-id><pub-id pub-id-type="pmid">30141773</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yerkes</surname><given-names>RM</given-names></name><name><surname>Dodson</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1908">1908</year><article-title>The relation of strength of stimulus to rapidity of habit-formation</article-title><source>Journal of Comparative Neurology and Psychology</source><volume>18</volume><fpage>459</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1002/cne.920180503</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Reaction times.</title><p>Median reaction times as a function of volatility (epoch length; <inline-formula><mml:math id="inf293"><mml:mi>λ</mml:mi></mml:math></inline-formula>) and conflict (probability of reward; <inline-formula><mml:math id="inf294"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig1-v2.tif"/></fig><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Change-point-evoked accuracy.</title><p>Change-point-evoked accuracy by subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig2-v2.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Change-point evoked reaction times.</title><p>Change-point-evoked reaction times by subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig3-v2.tif"/></fig><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Ideal observer estimates for Experiment 2.</title><p>(<bold>A</bold>) The average belief in the value of the optimal target (<inline-formula><mml:math id="inf295"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula>) as a function of the probability of reward (conflict) and the average period of stability for the optimal choice (<inline-formula><mml:math id="inf296"><mml:mi>λ</mml:mi></mml:math></inline-formula>; volatility). (<bold>B</bold>) Average change point probability (<inline-formula><mml:math id="inf297"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula>) as a function of conflict and volatility.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig4-v2.tif"/></fig><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Initial window selection.</title><p>Analysis conducted on data from Experiment 1 to determine the timescale of the response that maximized the intersection between high volatility (<inline-formula><mml:math id="inf298"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:math></inline-formula>) and low volatility (<inline-formula><mml:math id="inf299"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>35</mml:mn></mml:mrow></mml:math></inline-formula>) data. The bolded line represents the mean and the gray lines represent individual subjects. The dotted line indicates the initial window of nine trials used.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig5-v2.tif"/></fig><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Stability analysis.</title><p>Analysis conducted on Experiment 1 to determine the timescale of the response to consider for Experiment 2. The estimated angle is plotted as a function of time within an epoch (estimate from circular regression).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig6-v2.tif"/></fig><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Quantification of stability.</title><p>Probability that sequential posterior distributions for <inline-formula><mml:math id="inf300"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> have equal means.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig7-v2.tif"/></fig><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Blink timing.</title><p>Blink timing for a sample participant. For visibility, thirty trials were selected at random. The onset of the trial is marked as time 0 and the trial ends at 1500ms. Blinks are marked in black. Blink timing plots are available for all subjects and all conditions in the GitHub repository for this publication.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig8-v2.tif"/></fig><fig id="app1fig9" position="float"><label>Appendix 1—figure 9.</label><caption><title>Raw pupil diameter.</title><p>Mean time course of pupil diameter by subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig9-v2.tif"/></fig><fig id="app1fig10" position="float"><label>Appendix 1—figure 10.</label><caption><title>Evoked pupil diameter by condition.</title><p>Mean time course of pupil diameter by condition.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig10-v2.tif"/></fig><fig id="app1fig11" position="float"><label>Appendix 1—figure 11.</label><caption><title>First temporal derivative of pupil diameter.</title><p>Mean time course of derivative of pupil diameter by subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig11-v2.tif"/></fig><fig id="app1fig12" position="float"><label>Appendix 1—figure 12.</label><caption><title>Derivative of evoked pupil diameter by condition.</title><p>Mean time course of derivative of pupil diameter by condition.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig12-v2.tif"/></fig><fig id="app1fig13" position="float"><label>Appendix 1—figure 13.</label><caption><title>Prestimulus pupillary response.</title><p>Mean prestimulus pupillary response by subject.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65540-app1-fig13-v2.tif"/></fig></app><app id="appendix-2"><title>Appendix 2</title><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Power analysis for Experiment 1.</title><p>The results of the model comparison analysis using simulated data. Roman numerals refer to a given model, as defined by the mapping between the ideal observer estimates and decision parameters in the first two columns. The column labeled DIC gives the raw DIC score, <inline-formula><mml:math id="inf301"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> lists the change in model fit from an intercept-only model (the null-adjusted fit), and <inline-formula><mml:math id="inf302"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> provides the change in null-adjusted model fit from the best-fitting model. The last row represents the null, intercept-only regression model. The best performing model is denoted by an asterisk.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="left" valign="top"><inline-formula><mml:math id="inf303"><mml:mi>B</mml:mi></mml:math></inline-formula></th><th align="left" valign="top"><inline-formula><mml:math id="inf304"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula></th><th align="left" valign="top">DIC</th><th align="left" valign="top"><inline-formula><mml:math id="inf305"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mtext>null</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula></th><th align="left" valign="top"><inline-formula><mml:math id="inf306"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mtext>best</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="left" valign="top">I*</td><td align="left" valign="top"><inline-formula><mml:math id="inf307"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="left" valign="top"><inline-formula><mml:math id="inf308"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="top">–101886.4</td><td align="char" char="." valign="top">–15477.5</td><td align="char" char="." valign="top">0.0</td></tr><tr><td align="left" valign="top">II</td><td align="left" valign="top"><inline-formula><mml:math id="inf309"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="left" valign="top"><inline-formula><mml:math id="inf310"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="top">–87486.7</td><td align="char" char="." valign="top">–1077.8</td><td align="char" char="." valign="top">14399.7</td></tr><tr><td align="left" valign="top">III</td><td align="left" valign="top">–</td><td align="left" valign="top"><inline-formula><mml:math id="inf311"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="top">–87373.9</td><td align="char" char="." valign="top">–965.0</td><td align="char" char="." valign="top">14512.5</td></tr><tr><td align="left" valign="top">IV</td><td align="left" valign="top"><inline-formula><mml:math id="inf312"><mml:mi>v</mml:mi></mml:math></inline-formula></td><td align="left" valign="top">–</td><td align="char" char="." valign="top">–97634.70</td><td align="char" char="." valign="top">–11225.8</td><td align="char" char="." valign="top">4251.70</td></tr><tr><td align="left" valign="top">V</td><td align="left" valign="top">–</td><td align="left" valign="top"><inline-formula><mml:math id="inf313"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="char" char="." valign="top">–90577.3</td><td align="char" char="." valign="top">–4168.40</td><td align="char" char="." valign="top">11309.00</td></tr><tr><td align="left" valign="top">VI</td><td align="left" valign="top"><inline-formula><mml:math id="inf314"><mml:mi>a</mml:mi></mml:math></inline-formula></td><td align="left" valign="top">–</td><td align="char" char="." valign="top">–86525.7</td><td align="char" char="." valign="top">–116.70</td><td align="char" char="." valign="top">15360.7</td></tr><tr><td align="left" valign="top">VII</td><td align="left" valign="top">–</td><td align="left" valign="top">–</td><td align="char" char="." valign="top">–86408.9</td><td align="char" char="." valign="top">0.0</td><td align="char" char="." valign="top">15477.5</td></tr></tbody></table></table-wrap></app><app id="appendix-3"><title>Appendix 3</title><table-wrap id="app3table1" position="float"><label>Appendix 3—table 1.</label><caption><title>Raw model selection results for Experiment 2.</title><p>The raw results of the model comparison analysis conducted depicted in <xref ref-type="table" rid="table1">Table 1</xref> for Experiment 2. Roman numerals refer to a given model, as defined by the mapping between the ideal observer estimates and decision parameters in the first two columns. The column labeled DIC gives the raw DIC score, <inline-formula><mml:math id="inf315"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> lists the change in model fit from an intercept-only model (the null-adjusted fit), and <inline-formula><mml:math id="inf316"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mtext>DIC</mml:mtext><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> provides the change in null-adjusted model fit from the best-fitting model. The last row for each subject represents the null, intercept-only regression model. Equivocal winning models marked with an asterisk and a tilde.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Subject</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf317"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf318"><mml:mi mathvariant="normal">Ω</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf319"><mml:mrow><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf320"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf321"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>D</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></th></tr></thead><tbody><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">5286.0</td><td align="char" char="." valign="bottom">–156.1</td><td align="char" char="." valign="bottom">1.8 *<inline-formula><mml:math id="inf322"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">5430.2</td><td align="char" char="." valign="bottom">–11.9</td><td align="char" char="." valign="bottom">146.0</td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">5431.3</td><td align="char" char="." valign="bottom">–10.8</td><td align="char" char="." valign="bottom">147.1</td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5284.1</td><td align="char" char="." valign="bottom">–157.9</td><td align="char" char="." valign="bottom">0.0 *<inline-formula><mml:math id="inf323"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">5444.0</td><td align="char" char="." valign="bottom">2.0</td><td align="char" char="." valign="bottom">159.9</td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5441.1</td><td align="char" char="." valign="bottom">–0.9</td><td align="char" char="." valign="bottom">157.0</td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5442.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">157.9</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">5162.9</td><td align="char" char="." valign="bottom">–144.1</td><td align="char" char="." valign="bottom">0.0 *<inline-formula><mml:math id="inf324"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">5283.0</td><td align="char" char="." valign="bottom">–24.1</td><td align="char" char="." valign="bottom">120.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">5281.0</td><td align="char" char="." valign="bottom">–26.1</td><td align="char" char="." valign="bottom">118.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5165.1</td><td align="char" char="." valign="bottom">–142.0</td><td align="char" char="." valign="bottom">2.1 *<inline-formula><mml:math id="inf325"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">5303.7</td><td align="char" char="." valign="bottom">–3.4</td><td align="char" char="." valign="bottom">140.8</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5309.2</td><td align="char" char="." valign="bottom">2.1</td><td align="char" char="." valign="bottom">146.2</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5307.1</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">144.1</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">3034.8</td><td align="char" char="." valign="bottom">–53.4</td><td align="char" char="." valign="bottom">0.7 *<inline-formula><mml:math id="inf326"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">3090.1</td><td align="char" char="." valign="bottom">1.9</td><td align="char" char="." valign="bottom">56.0</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">3089.5</td><td align="char" char="." valign="bottom">1.2</td><td align="char" char="." valign="bottom">55.4</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">3034.1</td><td align="char" char="." valign="bottom">–54.1</td><td align="char" char="." valign="bottom">0.0 *<inline-formula><mml:math id="inf327"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">3089.2</td><td align="char" char="." valign="bottom">0.9</td><td align="char" char="." valign="bottom">55.1</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">3088.8</td><td align="char" char="." valign="bottom">0.6</td><td align="char" char="." valign="bottom">54.7</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">3088.2</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">54.1</td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">5438.9</td><td align="char" char="." valign="bottom">–7.7</td><td align="char" char="." valign="bottom">1.4 *<inline-formula><mml:math id="inf328"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">5450.5</td><td align="char" char="." valign="bottom">3.8</td><td align="char" char="." valign="bottom">13.0</td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">v</td><td align="char" char="." valign="bottom">5448.5</td><td align="char" char="." valign="bottom">1.8</td><td align="char" char="." valign="bottom">11.0</td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">v</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5437.5</td><td align="char" char="." valign="bottom">–9.1</td><td align="char" char="." valign="bottom">0.0 *<inline-formula><mml:math id="inf329"><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">a</td><td align="char" char="." valign="bottom">5448.2</td><td align="char" char="." valign="bottom">1.6</td><td align="char" char="." valign="bottom">10.7</td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">a</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5448.7</td><td align="char" char="." valign="bottom">2.0</td><td align="char" char="." valign="bottom">11.2</td></tr><tr><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">-</td><td align="left" valign="bottom">-</td><td align="char" char="." valign="bottom">5446.7</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">9.1</td></tr></tbody></table></table-wrap></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.65540.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>O'Connell</surname><given-names>Redmond G</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Trinity College Dublin</institution><country>Ireland</country></aff></contrib></contrib-group></front-stub><body><p>The authors conducted an impressive study investigating dynamic adjustments in decision policies as a function of two types of uncertainty: decision conflict and volatility (change point probability). They combine learning model parameters with drift diffusion modeling to assess how the policy (as a combination of drift rate and threshold) varies with uncertainty and also test how these adjustments relate to the LC-NE system via pupil diameter. This work is impressive and will certainly be of interest to many.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.65540.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>O'Connell</surname><given-names>Redmond G</given-names></name><role>Reviewing Editor</role><aff><institution>Trinity College Dublin</institution><country>Ireland</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Kloosterman</surname><given-names>Niels A</given-names></name><role>Reviewer</role><aff><institution>Max Planck Institute for Human Development</institution><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Dynamic decision policy reconfiguration under outcome uncertainty&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Floris de Lange as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Redmond O'Connell (Reviewer #1), Niels A Kloosterman (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) The authors should rewrite sections of the manuscript to more clearly articulate for the reader the core theoretical questions that this study sets out to address. Beyond linking elements of choice uncertainty to parameters of an influential decision model, what were the study goals and why are they important/interesting? Similarly, the authors should clarify the broader implications of their findings for current theory and future research. In addition, the Results section is very long and at times it is hard to follow the rationale for each analysis step or how it relates to the study goals. The authors might consider moving certain details that are not essential to the Methods or Supplemental Materials.</p><p>2) The reviewers agreed that the DDM analyses seem overly restricted, being limited to only two parameters when there are other parameters of this model that can plausibly mediate the observed uncertainty effects. The authors make strong claims about the specific nature of the decision policy adjustments observed here but this interpretation would be greatly strengthened if the authors examined model variants that leave other parameters (e.g. non-decision time, drift bias). Please also provide some illustration of the fits to individual data.</p><p>3) Several concerns were raised regarding the pupillometry analyses.</p><p>a) First, there is a concern that any underlying relationships with choice strategy may have been obscured if the task stimuli evoked strong pupil light reflexes (constrictions) within the measurement window. This cannot be properly assessed without the authors providing plots of the average pupil diameter timecourses along with details regarding the stimuli (e.g. brightness).</p><p>b) Second, the authors appear to overlook several relevant metrics. This includes unbaselined prestimulus pupil diameter which has been linked to variations in choice performance in a number of investigations and also to exploration/exploitation switches in at least one report (Jepma and Nieuwenhuis 2011). Previous work has also shown that the LC-NE system is in fact better tracked by using the first time derivative of the pupil signal (Reimer et al., Nat Comm, 2016). The authors should consider looking at the pupil derivative to see if this reveals a link to their experimental manipulations. Importantly, using the derivative instead of the actual pupil time series attenuates the pupil light reflect since only the slope is taken.</p><p>c) Third, the authors should check whether they can replicate the relationships between uncertainty and pupil diameter that have been reported in the previous literature. This would go a long way toward confirming the validity both of their pupil data and the null result in the relationship with exploration/exploitation</p><p>The authors should also take note of the individual comments of the reviewers provided below as many additional suggestions are provided that should help further improve the manuscript.</p><p><italic>Reviewer #1:</italic></p><p>In this paper the authors seek to uncover the decision policy adjustments that underpin participants choices on a two-armed bandit task in which the relative reward and probability of reward associated with each alternative varied unpredictably over time. In an extensive modelling analysis the authors examined whether decision dynamics on this task could be understood in terms of adjustments to the bound and/or drift rate parameters of the drift diffusion model. The results indicate that when participants detect a change in which of two choice alternatives is most rewarding they switch from an exploitative to an exploratory decision strategy by lowering both the bound and drift rate of the decision process. My sense is that these findings are supported by extensive analyses reported in the paper.</p><p>1. I note that the authors allowed only one decision model parameter to map on to volatility and conflict. It would be interesting to know whether or not allowing either bound or drift rate to account for both volatility and conflict would improve the model fits.</p><p>2. The paper also reports a failure to detect any relationship between pupillary responses (here used as a proxy for noradrenergic arousal) during decision making and the aforementioned decision policy adjustments. Here the authors should cite the work of Joshi et al. (2016, Neuron) which, to my knowledge, was the first peer-reviewed paper to report a relationship between locus coeruleus activity and pupil diameter. This paper is also important to consider because they report a failure to observe the tonic/phasic firing modes originally reported by Aston-Jones and colleagues that form the basis for the present hypotheses.</p><p>3. The prior literature suggests that there are important functional distinctions between average absolute (i.e. unbaselined) pupil diameter measured in a given time window and the pupil dilation responses that are elicited during decision making. The authors do not consider the former which has been linked to exploration/exploitation strategies at least once in the prior literature (Jepma and Nieuwenhuis, 2011, J Cog Neuro) and which has been linked to variations in choice performance on several occasions (e.g. Murphy et al. 2011, Psychophysiology; Van Kempen et al. 2019, <italic>eLife</italic>). The authors then conducted a principal component analysis on 7 different metrics extracted from the stimulus-evoked pupil dilation response.</p><p>4. Aside from the desire to reduce dimensionality a clear rationale for this approach is not provided. This limits the ability to compare the present results to those in the related literature since most previous studies have investigated relationships between choice behaviour and metrics like pupil dilation amplitude, peak latency and onset latency individually.</p><p>5. The manuscript would benefit from more clearly articulating the theoretical advances/insights that it provides. It could be argued that the modelling work results in a situation where one set of cognitive constructs (change point detection and value estimation) are swapped for another set (bound and drift rate) but it is not clear what new understanding is gained from this.</p><p><italic>Reviewer #2:</italic></p><p>In the present study the authors investigated decision-policy adjustments as a function of two distinct forms of uncertainty, conflict and volatility. They extend previous studies on explore-exploit dynamics by investigating specifically how choice parameters in an evidence accumulation framework vary with uncertainty.</p><p>To that aim they experimentally manipulated conflict and volatility in a two armed bandit task and combined bayesian models of learning with evidence accumulation models of decision-making. Then they quantify the degree to which the relationship between estimated choice parameters – indexing the choice policy – varies as a function of the context in which the choice is made. They further recorded pupil diameters to index LC-NE activity and test whether policy adjustments are related to this activity</p><p>Choice conflict modulated the rate of evidence accumulation and change points – while also increasing conflict – decreased the boundary height, leading to fast exploratory choices. The authors show that choice dynamics are linked to uncertainty dynamics by driving systematic changes in the decision-policy characterized by the combination of drift rate and threshold. Fast increases in uncertainty following change points drove fast exploratory choices (low drift rate, low threshold) that gradually recovered to exploitatory choices as the new reward contingencies were learned (high drift rate, high threshold).</p><p>They further find no evidence that these changes relate to fluctuations in the LC-NE system as indexed with pupil diameter.</p><p>This work is methodologically very impressive and theoretically very interesting. It expands the space of decision-policies beyond the explore-exploit dichotomy and characterizes elegantly how decision-policies should dynamically vary along a two-dimensional policy space as the environment is found to change.</p><p>Overall, I really liked the study. I do however have some questions and suggestions for additional analyses and edits.</p><p>Questions:</p><p>1. Typically more similar options/conflict leads to longer RTs. In Exp 1 the authors find no effect and in Exp 2 the opposite. That's usually a pretty robust effect. Any idea why that's not the case here?</p><p>2. Also how does this square with the positive effect of ΔB on drift rate? I think that might be worth picking up and unpacking a bit, if only to show the superiority of model-based analyses to raw behavior given that the behavioral findings are super confusing and the parameter results make perfect sense.</p><p>3. Could that be some power issue (re number of subjects, not observations)? Is maybe one subject weird in exp. 2 and can't detect change points so well or track the values?</p><p>4. What is meant by the similar time course of belief updating for high and low volatility? (p 5 line 178) Shouldn't people update more under higher volatility? Is that what's captured in the change point probability parameter? Maybe that sentence could be clarified so it doesn't confuse readers familiar with work linking volatility and the α parameter in RL (as in more learning/updating under high volatility).</p><p>5. If I understand correctly, when change point probability goes up, ΔB always goes down. What's the correlation between the two and if there is a correlation, what does that mean for the impact of those learning parameters on decision parameters? Can you assess conflict effects independent of change point effects (are there period where values are stable and super similar)?</p><p>Suggestions:</p><p>6. Provide a clearer rationale for the model comparisons to test hypotheses about policy adjustments.</p><p>I honestly found it a bit difficult to follow the model comparison for theta. I also think that when the pupil is added, the rationale could be explained a bit more clearly to allow the reader to follow. Specifically I got confused about the intercept and time null models (is that just time or time relative to change point if the latter, why is that a null model?).</p><p>7. Replicate relationship between uncertainty parameters and pupil measures before linking it to policy adjustments.</p><p>As I understand, you find that the adjustments in the decision-policy are unrelated to pupil diameter. As a sanity check, have the authors looked at pupil diameter as a function of the uncertainty parameters? It would be good to show that earlier effects of uncertainty and their temporal dynamics are replicated (have a plot with the betas over time pre-choice and post feedback). I think the conclusion can be stronger if the authors show that pupil dilation tracks both forms of uncertainty and the anticipation and response dynamics associate with that, but that the subsequent adjustments are not mediated by this system.</p><p>Right now something could be wrong with the pupil data and the reader has no way to know. It would also be important just to see that these earlier findings replicate.</p><p>8. Reconsider causal language/interpretation of drift rate effects in the discussion.</p><p>You say in the discussion that people reduce the drift rate. Isn't the drift rate here determined by the consistency of the evidence? Sure, people can focus more (i.e. in cognitive control tasks, where the response rules are well known and errors are primarily driven by early incorrect activations of prepotent responses or attentional lapses), but I can focus all I want when there's no evidence (when I just don't know what the relative values are because I currently have zero [or little] valid experience to draw from after I detected a change point ) and my drift rate will still be low. No? Couldn't it be that participants have a sense that their drift rate is low (because they have no idea what's going on) and because taking time to sample would be useless (because uncertainty is not reducible other than through action), dropping the threshold is the right thing to do? In that sense the (expected) drift rate would dictate the optimal boundary height. I'm thinking of work by Tajima et al.</p><p>9. Reconsider reinterpretation of previous findings in the discussion – add nuance where nuance is due.</p><p>I have a bit of a problem with the authors’ assertion that previous findings relating boundary height and conflict could be a misattribution of volatility effects (Frank and colleagues). These previous studies did not have change points. So that is an unlikely explanation of that finding. What is more likely is that the choice dynamics were different because the choices were not temporally dependent, i.e. participants made choices between different options on each trial, meaning that the conflict and thus the optimal decision-strategy differed on every trial (in addition to any learning related uncertainty, but importantly, the true values associated with stimuli never changed). That is not the same as a change point/volatility. Further in the present study, conflict is anticipated, except in the case of change points. So that could equally be the difference between expected and unexpected uncertainty that leads to dissociable effects on decision strategies. In both cases, what drives the threshold adjustment is probably some form of surprise (unexpected conflict). As it stands, the statement in the discussion is inaccurate/misleading. That’s an easy fix though.</p><p><italic>Reviewer #3:</italic></p><p>Shifting between more explorative and more exploitative modes of decision making is crucial for adaptive human behavior. Therefore, the authors' attempt to investigate the internal processes that allow these modes is important to begin to understand this remarkable ability. In addition, investigating the proposed link to the LC-NE system is sensible and establishing its role in these processes would help the field forward. The authors present a thorough, modelling-heavy set of analysis on two interesting datasets aimed at revealing the underlying mechanisms.</p><p>1. Despite these strong points, the manuscript in its current version falls somewhat short of answering the questions that it poses. For one, the DDM analyses are restricted to only two parameters, which begs the question whether other established parameters might be better able to explain the results and thereby shed more light on the underlying mechanisms. Also, regarding the role of the pupil-linked LC-NE system, no strong conclusions can be drawn from the data, since the visual stimulus design likely resulted in strong pupil light reflexes, which might well have overshadowed subtler, more interesting modulations of the pupil. Despite the manuscripts innovative and clever use of Bayesian modelling and PCA, these two shortcomings might limit the impact of the manuscript in its current form on the field.</p><p>Shifting between more explorative and more exploitative modes of decision making is crucial for adaptive human behavior. Therefore, the authors' attempt to investigate the internal processes that allow these modes is important to begin to understand this remarkable faculty. In addition, investigating the proposed link to the LC-NE system is sensible and establishing its role in these processes would help the field forward. However, although in general the presented analyses seem thorough, I have two main concerns that in my opinion should be addressed before conclusions can be drawn from the data.</p><p>First, the DDM modelling is too restrictive, only focusing on the bound and drift parameters. Besides these two main parameters, another main parameter of the standard DDM is non-decision time, which to my surprise is not mentioned at all in the manuscript. Moreover, recent work has shown that two further parameters can capture internal processes possibly related to explore/exploit policies: starting point (z) and drift bias (called drift criterion or dc by Ratcliff and McKoon (2008)). Including these latter two parameters possibly can explain the RTs better than drift only and shed more light on the components underlying conflict and volatility. In addition, non-decision time might also be affected by the experimental manipulations, and should at least be reported in the manuscript (I assume that the authors did include it in their currently reported DDMs). In my mind, investigating all these further parameters is crucial before the conclusion that bound and drift rate best capture conflict and volatility is warranted.</p><p>My second point concerns the pupil analysis.</p><p>a) Although I could not find information about visual stimulus size and brightness in the methods, Figure 2AB suggests that there were strong visual transients at trial onset (black screen → stimulus), which presumably resulted in strong pupil constrictions due to the pupil light reflex (PLR).</p><p>b) I would have liked to see pupil time courses in this manuscript. The first components of the PCA, as employed by the authors (which in principle I think is a great idea) is likely to capture exactly these PLR dynamics given the large variance due to PLR.</p><p>c) Now, previous work has shown that the LC-NE system is in fact better tracked by using the first time derivative of the pupil signal (Reimer et al., Nat Comm, 2016). The authors should consider looking at the pupil derivative to see if this reveals a link to their experimental manipulations. Importantly, using the derivative instead of the actual pupil time series attenuates the PLR since only the slope is taken. Hence, when using the derivative, the PCA might pick up more interesting, cognitive drivers of pupil dynamics, since the PLR dynamics are suppressed. It would be interesting to see if this would reveal a link to the experimental manipulations.</p><p>d) Further, please note that the pupil likely not only is linked to the LC-NE system, but generally to catecholamines, which includes dopamine (Joshi et al. Neuron 2015). Therefore, I would recommend to not exclusively link pupil to LC-NE in the manuscript while interpreting the pupil results.</p><p>e) In any case, the author should show raw pupil as well as pupil derivative time courses for the different conditions to give insight in their data.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.65540.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The authors should rewrite sections of the manuscript to more clearly articulate for the reader the core theoretical questions that this study sets out to address. Beyond linking elements of choice uncertainty to parameters of an influential decision model, what were the study goals and why are they important/interesting? Similarly, the authors should clarify the broader implications of their findings for current theory and future research. In addition, the Results section is very long and at times it is hard to follow the rationale for each analysis step or how it relates to the study goals. The authors might consider moving certain details that are not essential to the Methods or Supplemental Materials.</p></disp-quote><p>We have made substantial changes to the frontend of manuscript (Abstract and Introduction) to more explicitly clarify the core theoretical questions that our study set out to address. We have also edited the Results and Discussion in targeted ways to better align the framing of our findings to the context of our theoretical questions. We hope that this better articulates the goals of our work.</p><disp-quote content-type="editor-comment"><p>2) The reviewers agreed that the DDM analyses seem overly restricted, being limited to only two parameters when there are other parameters of this model that can plausibly mediate the observed uncertainty effects. The authors make strong claims about the specific nature of the decision policy adjustments observed here but this interpretation would be greatly strengthened if the authors examined model variants that leave other parameters (e.g. non-decision time, drift bias). Please also provide some illustration of the fits to individual data.</p></disp-quote><p>The reviewers raise crucial points regarding the restricted set of model comparisons. Our original focus on these parameters was driven by prior work showing adaptation of the drift rate and boundary height terms under uncertainty, including findings linking cortico-basal ganglia dynamics with these drift-diffusion parameters under uncertain conditions (Dunovan et al. 2019; Dunovan and Verstynen 2019; Rubin et al. 2021). As we detail below, we have now expanded the set of models considered to include other plausible decision parameters (non-decision time (tr), drift criterion / drift bias (dc), and the starting point (z), in addition to the drift rate (v) and boundary height (a)).</p><p>These more rigorous analyses have resulted in an update to the change-point-evoked effect on boundary height (<italic>a)</italic>. Instead of <italic>a decreasing</italic> in response to a suspected change in reward contingencies, <italic>a increases</italic> in response to a suspected change. Ironically, this is consistent with our <ext-link ext-link-type="uri" xlink:href="https://osf.io/5esn4">preregistered</ext-link> <ext-link ext-link-type="uri" xlink:href="https://osf.io/5esn4">hypothesis</ext-link> as well as with prior experimental results in our lab (and others). We have updated both our key figures and the text of the Results and Discussion to reflect this change. (See response below).</p><disp-quote content-type="editor-comment"><p>3) Several concerns were raised regarding the pupillometry analyses.</p><p>a) First, there is a concern that any underlying relationships with choice strategy may have been obscured if the task stimuli evoked strong pupil light reflexes (constrictions) within the measurement window. This cannot be properly assessed without the authors providing plots of the average pupil diameter timecourses along with details regarding the stimuli (e.g. brightness).</p></disp-quote><p>We were careful to control the effect of light on the pupillary response during data collection. This included the construction of a specific rig around the testing computer so as to reduce ambient reflection of light from walls and ceiling.</p><p>To control luminance we also used a Derrington-Krauskopf-Lennie (DKL) color space that allows for direct luminance control. As a result, the stimulus presentation display was rendered isoluminant throughout the task. In addition, the lead author built a booth to isolate the participant from ambient sources of light during data collection.</p><p>We now mention these details in the Methods:</p><p>“Throughout the task, the head-stabilized diameter and gaze position of the left pupil were measured with an Eyelink 1000 desktop mount at 1000 Hz. […] During the reward-learning task, we used this method to isolate the task-evoked pupillary response.”</p><p>Additionally, we include a reminder as part of the caption for Figure 2B to aid the reader in interpreting the results as they progress through the paper:</p><p>“(B) In Experiment 2, participants were asked to choose between one of two Greebles (one male, one female). The total number of points earned was displayed at the center of the screen. The stimulus display was rendered isoluminant throughout the task.”</p><disp-quote content-type="editor-comment"><p>(b) Second, the authors appear to overlook several relevant metrics. This includes unbaselined prestimulus pupil diameter which has been linked to variations in choice performance in a number of investigations and also to exploration/exploitation switches in at least one report (Jepma and Nieuwenhuis 2011). Previous work has also shown that the LC-NE system is in fact better tracked by using the first time derivative of the pupil signal (Reimer et al., Nat Comm, 2016). The authors should consider looking at the pupil derivative to see if this reveals a link to their experimental manipulations. Importantly, using the derivative instead of the actual pupil time series attenuates the pupil light reflect since only the slope is taken.</p></disp-quote><p>We have reanalyzed the data using un-baselined prestimulus pupil diameter and the first time derivative of the pupillary response. We again observe a null result. These analyses are detailed as part of our point-by-point reply to reviewers below. Figures visualizing these time courses have been added to the supplementary section of the manuscript (Supplementary Figures 10 and 11).</p><disp-quote content-type="editor-comment"><p>c) Third, the authors should check whether they can replicate the relationships between uncertainty and pupil diameter that have been reported in the previous literature. This would go a long way toward confirming the validity both of their pupil data and the null result in the relationship with exploration/exploitation</p></disp-quote><p>We have now conducted analyses to check for the previously reported links between exploratory choice behavior and the pupillary response. However, we observe no clear evidence for these pre-established links. Therefore, we qualify the use of the pupillary data. The Results section now states this lack of replication to titrate the reader’s confidence in the pupillary results and the corresponding inferences relating to LC-NE system influence on the progression through the decision manifold:</p><p>“Specifically, if the LC-NE system were sensitive to a change in the optimal choice, then we should observe a moderate spike in phasic activity following a change in action-outcome contingencies. […] We ask the reader to titrate their interpretation of these pupillary data accordingly.”</p><p>We include a similar addition to the pupillometry subsection of the Methods:</p><p>“Note that we also conducted a similar analysis using more conventional methods to assess the task-evoked pupillary response and observed another null effect. […] As such, we caution the reader to view our pupillary results in light of this lack of replication of pre-established exploration-driven pupillary responses.”</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>In this paper the authors seek to uncover the decision policy adjustments that underpin participants choices on a two-armed bandit task in which the relative reward and probability of reward associated with each alternative varied unpredictably over time. In an extensive modelling analysis the authors examined whether decision dynamics on this task could be understood in terms of adjustments to the bound and/or drift rate parameters of the drift diffusion model. The results indicate that when participants detect a change in which of two choice alternatives is most rewarding they switch from an exploitative to an exploratory decision strategy by lowering both the bound and drift rate of the decision process. My sense is that these findings are supported by extensive analyses reported in the paper.</p><p>1. I note that the authors allowed only one decision model parameter to map on to volatility and conflict. It would be interesting to know whether or not allowing either bound or drift rate to account for both volatility and conflict would improve the model fits.</p></disp-quote><p>The choice to map distinct ideal observer estimates to distinct decision parameters reflects the theoretical motivation underlying the development of our hypotheses tested here. We now expand on this in the introduction to make clear the reasoning for our narrow focus, as below:</p><p>“Are the parameters that govern accumulation of evidence for decision making modifiable? […] These policies, in turn, adaptively reconfigure based on current environmental feedback signals by modulating value estimation and the rate of selection errors (Figure 1E).”</p><p>A complete, exhaustive sweep of decision parameters as proposed would be computationally inefficient. This would require evaluation of all possible single parameter, dual-parameter (<italic>n</italic>-parameter) pairings, with both many-to-one ideal observer to DDM mappings and many-to-one DDM parameter mappings to ideal observer mappings. As model complexity increases in these hierarchical DDM fits, the convergence or stability of the fits is more difficult to achieve. So we opted for parsimony in the set of model fits to avoid a data mining expedition that would very likely lead to a set of inconclusive model fits on overly complex models. This sort of restricted set test is quite common when using hierarchical DDM (and, indeed, many hierarchical models in general). Further, estimating pairwise ideal observer to DDM parameter mappings alone keeps model complexity constant, allowing us to make clear comparisons in information loss scores between candidate models.</p><disp-quote content-type="editor-comment"><p>2. The paper also reports a failure to detect any relationship between pupillary responses (here used as a proxy for noradrenergic arousal) during decision making and the aforementioned decision policy adjustments. Here the authors should cite the work of Joshi et al. (2016, Neuron) which, to my knowledge, was the first peer-reviewed paper to report a relationship between locus coeruleus activity and pupil diameter. This paper is also important to consider because they report a failure to observe the tonic/phasic firing modes originally reported by Aston-Jones and colleagues that form the basis for the present hypotheses.</p></disp-quote><p>We thank the reviewer for this omitted reference. Indeed, Joshi et al. 2016 provides clear evidence of a link between locus coeruleus activity and pupil diameter. To our knowledge, this observation extends back to the work of Rajkowski, Kubiak, and Aston-Jones 1994, showing the phasic and tonic modes of the locus-coeruleus system in relation to exploratory behavior. All of this prior work is clearly important to consider, and we thank the reviewer for bringing this to our attention.</p><p>We now cite both studies in our revised manuscript:</p><p>“The LC-NE system is known to modulate exploration states under uncertainty and pupil diam- eter shows a tight correspondence with LC neuron firing rate (Aston-Jones and Cohen, 2005; Rajkowski et al., 1994), with changes in pupil diameter indexing the explore-exploit decision state (Jepma and Nieuwenhuis, 2011). Similar to the classic Yerkes-Dodson curve relating arousal to performance (Yerkes et al., 1908), performance is optimal when tonic LC activity is moderate and phasic LC activity increases following a goal-related stimulus (Aston-Jones et al. (1999), but see Joshi et al. (2016) for an exception).”</p><disp-quote content-type="editor-comment"><p>3. The prior literature suggests that there are important functional distinctions between average absolute (i.e. unbaselined) pupil diameter measured in a given time window and the pupil dilation responses that are elicited during decision making. The authors do not consider the former which has been linked to exploration/exploitation strategies at least once in the prior literature (Jepma and Nieuwenhuis, 2011, J Cog Neuro) and which has been linked to variations in choice performance on several occasions (e.g. Murphy et al. 2011, Psychophysiology; Van Kempen et al. 2019, eLife).</p></disp-quote><p>Thank you for bringing this important functional distinction between un-baselined pupil diameter and the dilation response to our attention. In our data, if baseline pupil diameter were sensitive to shifts from exploitation to exploration, then we should observe a change in baseline pupil diameter proximal to a change point. However, we do not observe a change-point-evoked shift in baseline pupil diameter in our data, as we might expect given the previous links to exploratory behavior. We now mention our lack of support for these validation analyses in the Results section and visualize the pupillary time courses and results in the Supplementary section (Supp. Figures 10-13).</p><p>“Specifically, if the LC-NE system were sensitive to a change in the optimal choice, then we should observe a moderate spike in phasic activity following a change in action-outcome contingencies. Note that we do not observe previously established links between exploratory choice behavior and the pupillary response (Jepma and Nieuwenhuis, 2011; Murphy et al., 2011; van Kempen et al., 2019). We ask the reader to titrate their interpretation of these pupillary data accordingly.”</p><disp-quote content-type="editor-comment"><p>4. The authors then conducted a principal component analysis on 7 different metrics extracted from the stimulus-evoked pupil dilation response. Aside from the desire to reduce dimensionality a clear rationale for this approach is not provided. This limits the ability to compare the present results to those in the related literature since most previous studies have investigated relationships between choice behaviour and metrics like pupil dilation amplitude, peak latency and onset latency individually.</p></disp-quote><p>From a computational perspective, reducing the dimensionality of this set of pupillary response metrics expands the set of models we can consider without taxing computational resources in a reasonable amount of time.</p><p>Further, our original PCA method was intended to maximize the variability of the pupillary response linked to the decision manifold. This allowed us to capture separable sources of variance relating to timing and amplitude effects without restricting the data to a smaller set of metrics and possibly discarding information (e.g. timing effects may not be constrained to peak latency or onset latency; amplitude effects may not be constrained to peak dilation amplitude).</p><p>We have edited the Results section with the motivation for our PCA approach:</p><p>“We characterized the evoked pupillary response on each trial using seven metrics: the mean of the pupil data over each trial interval, the latency to the peak onset and offset, the latency to peak amplitude, the peak amplitude, and the area under the curve of the pupillary response. […] Therefore, we submitted these metrics to principal component analysis to reduce their dimensionality while capturing maximum variance.”</p><p>We have also reanalyzed these pupillary data using conventional analysis methods and continue to observe a null effect (see points 3C and 7 for Reviewer 3). We have edited the Results section to reflect this:</p><p>“Thus, for interpretability, we refer to the first and second principal components as timing and magnitude components, respectively (Figure 9B). Note that we also conduct this analysis using more conventional methods of pupillary analysis and continue to observe a null effect (see the Pupil data preprocessing for details).”</p><disp-quote content-type="editor-comment"><p>5. The manuscript would benefit from more clearly articulating the theoretical advances/insights that it provides. It could be argued that the modelling work results in a situation where one set of cognitive constructs (change point detection and value estimation) are swapped for another set (bound and drift rate) but it is not clear what new understanding is gained from this.</p></disp-quote><p>This is an excellent point and it reflects our somewhat opaque framing in the</p><p>Introduction, which we have now fixed (see our response to the first point raised by the Review Editor). Our primary goal was to understand how the evidence accumulation dynamics changed when the environment requires reassessing learned state action values. Rather than think of these accumulation dynamics, driven by drift rate, boundary height, etc., as a static process, we make the case of thinking of these as points on a continuum of possible states (see manifold in Figure 1e). So our primary focus is on the algorithms of information processing. However, if these are dynamic processes, e.g., drift rate fluctuates over time, then there has to be some learning signal that drives these fluctuations. We chose the ideal observer parameters as likely learning signals that drive plasticity in the decision policy state. We acknowledge that these may not be the <italic>only</italic> signals that drive adjustments in decision policy dynamics, but they are ideal in that they reflect two correlated, but separate estimates of environmental state.</p><p>In line with our response to point 1 from Reviewer 1, we now make this clearer in the Introduction:</p><p>“Knowing how decision policies shift in the face of dynamic environments requires looking at the algorithmic properties of the policy itself. […] We predicted that, in response to suspected changes in action-outcome contingencies, humans would exhibit a stereotyped adjustment in the drift rate and boundary height that pushes decisions from certain, exploitative states to uncertain, exploratory states and back again (Figure 1E).”</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] Overall, I really liked the study. I do however have some questions and suggestions for additional analyses and edits.</p><p>Questions:</p><p>1. Typically more similar options/conflict leads to longer RTs. In Exp 1 the authors find no effect and in Exp 2 the opposite. That's usually a pretty robust effect. Any idea why that's not the case here?</p></disp-quote><p>The reviewer is correct, we do observe different effects of conflict on reaction time in Experiments 1 and 2. The effect is absent in Experiment 1 and small enough in Experiment 2 that it can effectively be considered a null finding. One possible reason for attenuated effects of conflict on reaction time is that participants were overtrained</p><p>(Experiment 1 was 2hrs per participant, Experiment 2 was nine hours per participant). This may result in participants having developed an expectation of change point frequency and/or conflict manipulation. If this were the case, then we might expect to see an effect on reaction times in Experiment 1, where participants undergo four sessions of training, but not in Experiment 2, where participants undergo nine sessions of training each. However, we instead see negligible effects on reaction times in Experiment 2 and no effect of conflict on reaction times in Experiment 1.</p><p>A second possibility relates to the complexity of our manipulations. Here we impose a range of conflict levels that also vary with degrees of volatility, meaning that our observed reaction time effects are a mix of responses to different extents of conflict and volatility together. This contrasts with previous reports measuring a more restricted range of conflict and without the influence of volatility. Thus, participants are tracking two sources of uncertainty, which may attenuate the overall observed RT response to conflict alone.</p><p>We now acknowledge this discrepancy in the Discussion.</p><p>“Previous literature has shown a conflict-induced spike in reaction time (e.g. Jahfari et al. 2019). […] Future research should explore the interaction of change point and conflict estimation on the speed-accuracy tradeoff.”</p><p>Either way, this discrepancy between our results and other studies, as well as the lack of internal replication of the change point probability and boundary height association in Experiment 2 of our results, is an interesting avenue of exploratory research that we are currently following up on.</p><disp-quote content-type="editor-comment"><p>2. Also how does this square with the positive effect of ΔB on drift rate? I think that might be worth picking up and unpacking a bit, if only to show the superiority of model-based analyses to raw behavior given that the behavioral findings are super confusing and the parameter results make perfect sense.</p></disp-quote><p>The reviewer is absolutely correct. The lack of simple main effects on RT across experiments obscures meaningful behavioral patterns that can be detected with a model-based approach. We now reference the value of a model-based analysis after reviewing the ambiguous behavioral results:</p><p>“At the gross level, across all trials within an experimental condition, increasing the ambiguity of the optimal choice (conflict) and increasing the instability of action outcomes (volatility) decreases the probability of selecting the optimal choice. […] We adopt a more focal, model-based analysis in the next section to clarify these peri-change point dynamics.”</p><disp-quote content-type="editor-comment"><p>3. Could that be some power issue (re number of subjects, not observations)? Is maybe one subject weird in exp. 2 and can't detect change points so well or track the values?</p></disp-quote><p>We see fairly consistent sensitivity to change points across subjects in Experiment 2, with accuracy plummeting and recovering with similar time courses, suggesting that all participants track the value of the optimal choice in a consistent manner (see Supplementary Figures 8 and 9 for evoked response profiles by subject). In addition, we conducted <ext-link ext-link-type="uri" xlink:href="https://github.com/kmbond/loki_0/blob/master/hypotheses.ipynb">a power analysis</ext-link> prior to data collection <ext-link ext-link-type="uri" xlink:href="https://osf.io/5esn4">(preregistration</ext-link>) and the within-session, within-subject power for Experiment 2 is still high enough to detect our hypothesized effects.</p><p>As in our response to the previous comment, we think that the RT effects are masking compensatory changes in two different parameters in the accumulation process, rather than outlier participants or sessions.</p><p>That said, it may be the case that the reaction time effects simply require more power to detect than accuracy effects, and both of our experiments fail to detect them for that reason. We plan to conduct a replication experiment to recover the effects we observed using a high-powered experimental design both within and across subjects. We hope that the results of this replication address this question. However, given that this is a tangential focus to our original research question, it is more suitable to address this as a follow up paper.</p><disp-quote content-type="editor-comment"><p>4. What is meant by the similar time course of belief updating for high and low volatility? (p 5 line 178) Shouldn't people update more under higher volatility? Is that what's captured in the change point probability parameter? Maybe that sentence could be clarified so it doesn't confuse readers familiar with work linking volatility and the α parameter in RL (as in more learning/updating under high volatility).</p></disp-quote><p>This was an awkwardly worded sentence. We apologize. What we meant here is that the rate of change in relative reward value (ΔB) after a change point is qualitatively similar under both low and high volatility conditions. In other words, the slope of the lines for the two volatility manipulations in Figure 4A is approximately the same. However, the change-point-evoked response belies the main effect of volatility on overall estimates of relative reward value, as shown in Figure 4B. Therefore, we removed this sentence to maintain clarity.</p><disp-quote content-type="editor-comment"><p>5. If I understand correctly, when change point probability goes up, ΔB always goes down. What's the correlation between the two and if there is a correlation, what does that mean for the impact of those learning parameters on decision parameters? Can you assess conflict effects independent of change point effects (are there period where values are stable and super similar)?</p></disp-quote><p>These two parameters are indeed correlated. In fact, ΔB is included in the calculation of change point probability and vice versa. But this interdependence is expected: your certainty in value is going to decrease if you live in a chaotic and changing world. However, the real question is whether they are too correlated to impact our model interpretability. The correlation between change point probability and ΔB is small but reliable, with an increase in belief as change point probability decreases (Spearman’s rho = -0.234 +/- 0.029). However, the Variance Inflation Factor, a collinearity metric, is within an acceptable range for both experiments (Experiment 1: 1.100 +/- 0.013; Experiment 2: 1.058 +/- 0.017). This is generally considered to be an acceptable degree of collinearity (values greater than 10 cause concern; Chatterjee and Simonoff 2013, p. 28-29, <ext-link ext-link-type="uri" xlink:href="https://github.com/kmbond/dynamic_decision_policy_reconfiguration/blob/master/analysis/E1_ideal_observer_correlation_check.ipynb">notebook</ext-link> showing these results). Thus, the degree of correlation between change point probability and ΔB should have a minimal effect on the estimation of the decision parameters. This suggests that we can safely estimate independent effects of volatility and conflict using change point probability and belief.</p><disp-quote content-type="editor-comment"><p>Suggestions:</p><p>6. Provide a clearer rationale for the model comparisons to test hypotheses about policy adjustments.</p><p>I honestly found it a bit difficult to follow the model comparison for theta. I also think that when the pupil is added, the rationale could be explained a bit more clearly to allow the reader to follow. Specifically I got confused about the intercept and time null models (is that just time or time relative to change point if the latter, why is that a null model?).</p></disp-quote><p>We thank the reviewer for bringing this lack of clarity to our attention. The time-null model tested for an impact of time relative to a change point, separate from conditional influences of volatility and conflict and the influence of the pupillary response.</p><p>We have renamed these models for clarity and expanded on our selection logic for models specifying an impact on decision policy adjustment and updated our naming convention in the Methods section and in the Results section:</p><p>“First, we tested the null hypothesis that the decision dynamics was solely a function of the intercept, or the average of the decision dynamics. […] We call this the evoked response model.”</p><disp-quote content-type="editor-comment"><p>7. Replicate relationship between uncertainty parameters and pupil measures before linking it to policy adjustments.</p><p>As I understand, you find that the adjustments in the decision-policy are unrelated to pupil diameter. As a sanity check, have the authors looked at pupil diameter as a function of the uncertainty parameters? It would be good to show that earlier effects of uncertainty and their temporal dynamics are replicated (have a plot with the betas over time pre-choice and post feedback). I think the conclusion can be stronger if the authors show that pupil dilation tracks both forms of uncertainty and the anticipation and response dynamics associate with that, but that the subsequent adjustments are not mediated by this system.</p><p>Right now something could be wrong with the pupil data and the reader has no way to know. It would also be important just to see that these earlier findings replicate.</p></disp-quote><p>The reviewer raises an excellent point. We did look into this relationship and yet failed to observe evidence for a relationship between our uncertainty parameters – belief and change point probability – and the pupillary response, as measured by both the metrics we calculated and the principal components derived from those metrics.</p><p>We have now stated this lack of replication in the Results section to caution the reader:</p><p>“Specifically, if the LC-NE system were sensitive to a change in the optimal choice, then we should observe a moderate spike in phasic activity following a change in action-outcome contingencies. […] We ask the reader to titrate their interpretation of these pupillary data accordingly and to view the corresponding inferences relating noradrenergic and catecholaminergic systems to decision policy adjustment in this light.”</p><disp-quote content-type="editor-comment"><p>8. Reconsider causal language/interpretation of drift rate effects in the discussion.</p><p>You say in the discussion that people reduce the drift rate. Isn't the drift rate here determined by the consistency of the evidence? Sure, people can focus more (i.e. in cognitive control tasks, where the response rules are well known and errors are primarily driven by early incorrect activations of prepotent responses or attentional lapses), but I can focus all I want when there's no evidence (when I just don't know what the relative values are because I currently have zero [or little] valid experience to draw from after I detected a change point ) and my drift rate will still be low. No? Couldn't it be that participants have a sense that their drift rate is low (because they have no idea what's going on) and because taking time to sample would be useless (because uncertainty is not reducible other than through action), dropping the threshold is the right thing to do? In that sense the (expected) drift rate would dictate the optimal boundary height. I'm thinking of work by Tajima et al.</p></disp-quote><p>The reviewer brings up two points in this comment. We will address each separately.</p><p>First there appears to be a conflation of intention with causation. While we fully agree that we can reduce the causal certainty of the language used in the Discussion (something we now do in the revised text), the fact remains that in our data, drift rate reliably changes in response to a changepoint in a stereotypic fashion. Given the nature of the experimental design, we are careful to not make any assumptions as to whether this change is driven by explicit or intentional mechanisms (e.g., increased focus) versus implicit or automatic mechanisms.</p><p>The second point raised regards alignment with the work by Tajima and colleagues. It is very likely that the drift rate and boundary height are changing in a cooperative, adaptive manner, at least insofar as the trials immediately surrounding a change point are concerned. The temporal profile of the two parameter changes (at least in Exp. 1 given our new analysis) is quite different, with boundary height changes being brief and drift rate adaptation requiring more time. So, if a change in the boundary height is dictating drift rate changes it is only happening briefly. Therefore we think that a majority of the changes seen in response to a change point are occurring through independent means (consistent with our prior computational models of these pathways (Dunovan et al. 2019; Dunovan and Verstynen 2019; Rubin et al. 2021)).</p><disp-quote content-type="editor-comment"><p>9. Reconsider reinterpretation of previous findings in the discussion – add nuance where nuance is due.</p><p>I have a bit of a problem with the authors' assertion that previous findings relating boundary height and conflict could be a misattribution of volatility effects (Frank and colleagues). These previous studies did not have change points. So that is an unlikely explanation of that finding. What is more likely is that the choice dynamics were different because the choices were not temporally dependent, i.e. participants made choices between different options on each trial, meaning that the conflict and thus the optimal decision-strategy differed on every trial (in addition to any learning related uncertainty, but importantly, the true values associated with stimuli never changed). That is not the same as a change point/volatility. Further in the present study, conflict is anticipated, except in the case of change points. So that could equally be the difference between expected and unexpected uncertainty that leads to dissociable effects on decision strategies. In both cases, what drives the threshold adjustment is probably some form of surprise (unexpected conflict). As it stands, the statement in the discussion is inaccurate/misleading. That's an easy fix though.</p></disp-quote><p>Thank you for this careful reading of our critique. Given the update to our results after the more thorough set of model comparisons requested, we no longer include this point in the Discussion. Further, we have made sure to qualify our interpretation of how our findings integrate with the broader literature where necessary. We hope this reflects a more nuanced view of the prior literature.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>Shifting between more explorative and more exploitative modes of decision making is crucial for adaptive human behavior. Therefore, the authors' attempt to investigate the internal processes that allow these modes is important to begin to understand this remarkable ability. In addition, investigating the proposed link to the LC-NE system is sensible and establishing its role in these processes would help the field forward. The authors present a thorough, modelling-heavy set of analysis on two interesting datasets aimed at revealing the underlying mechanisms.</p><p>1. Despite these strong points, the manuscript in its current version falls somewhat short of answering the questions that it poses. For one, the DDM analyses are restricted to only two parameters, which begs the question whether other established parameters might be better able to explain the results and thereby shed more light on the underlying mechanisms. Also, regarding the role of the pupil-linked LC-NE system, no strong conclusions can be drawn from the data, since the visual stimulus design likely resulted in strong pupil light reflexes, which might well have overshadowed subtler, more interesting modulations of the pupil. Despite the manuscripts innovative and clever use of Bayesian modelling and PCA, these two shortcomings might limit the impact of the manuscript in its current form on the field.</p><p>Shifting between more explorative and more exploitative modes of decision making is crucial for adaptive human behavior. Therefore, the authors' attempt to investigate the internal processes that allow these modes is important to begin to understand this remarkable faculty. In addition, investigating the proposed link to the LC-NE system is sensible and establishing its role in these processes would help the field forward. However, although in general the presented analyses seem thorough, I have two main concerns that in my opinion should be addressed before conclusions can be drawn from the data.</p><p>First, the DDM modelling is too restrictive, only focusing on the bound and drift parameters. Besides these two main parameters, another main parameter of the standard DDM is non-decision time, which to my surprise is not mentioned at all in the manuscript. Moreover, recent work has shown that two further parameters can capture internal processes possibly related to explore/exploit policies: starting point (z) and drift bias (called drift criterion or dc by Ratcliff and McKoon (2008)). Including these latter two parameters possibly can explain the RTs better than drift only and shed more light on the components underlying conflict and volatility. In addition, non-decision time might also be affected by the experimental manipulations, and should at least be reported in the manuscript (I assume that the authors did include it in their currently reported DDMs). In my mind, investigating all these further parameters is crucial before the conclusion that bound and drift rate best capture conflict and volatility is warranted.</p></disp-quote><p>The reviewer is correct. Investigating the remaining DDM parameters is crucial to substantiate our claim that the drift rate and boundary height respond in a coordinated fashion to promote exploration in response to a suspected change. This was something that we did in our initial model evaluations but was left out for the sake of concision. We now include a more thorough test of the set of DDM parameters (<italic>a,v,t,z,dc</italic>) that could respond to a change point. This broader first-level test confirms our initial results showing that the <italic>t</italic>, <italic>z</italic>, and <italic>dc</italic> parameters do not reliably change in response to a change point (Figure 5).</p><disp-quote content-type="editor-comment"><p>My second point concerns the pupil analysis. Regarding the role of the pupil-linked LC-NE system, no strong conclusions can be drawn from the data, since the visual stimulus design likely resulted in strong pupil light reflexes, which might well have overshadowed subtler, more interesting modulations of the pupil.</p><p>a) Although I could not find information about visual stimulus size and brightness in the methods, Figure 2AB suggests that there were strong visual transients at trial onset (black screen → stimulus), which presumably resulted in strong pupil constrictions due to the pupil light reflex (PLR).</p></disp-quote><p>The representation of the display depicted in Figures 2A and B does not show the actual luminance of the stimulus display for Experiment 2. As we state in our general response to the Editor above and in point B of this response, we carefully controlled task-related luminance and ambient sources of light in order to maximize our capacity to detect subtle pupillary effects. See point 3A in our response to the Editor and the revised language included in that response.</p><disp-quote content-type="editor-comment"><p>b) I would have liked to see pupil time courses in this manuscript. The first components of the PCA, as employed by the authors (which in principle I think is a great idea) is likely to capture exactly these PLR dynamics given the large variance due to PLR.</p></disp-quote><p>It is unlikely that we are capturing pupillary light reflexes given our control of luminance in the experimental testing rig. However, we have now included average time courses of the pupillary response to the Supplementary section (Supp. Figure 9-13). We hope these are useful for readers who share this concern. See point 3C of our response to the editor for cautionary language added to the Results and Methods section.</p><disp-quote content-type="editor-comment"><p>c) Now, previous work has shown that the LC-NE system is in fact better tracked by using the first time derivative of the pupil signal (Reimer et al., Nat Comm, 2016). The authors should consider looking at the pupil derivative to see if this reveals a link to their experimental manipulations. Importantly, using the derivative instead of the actual pupil time series attenuates the PLR since only the slope is taken. Hence, when using the derivative, the PCA might pick up more interesting, cognitive drivers of pupil dynamics, since the PLR dynamics are suppressed. It would be interesting to see if this would reveal a link to the experimental manipulations.</p></disp-quote><p>We have now calculated the first time derivative of the pupil signal and reanalyzed our data on this measure. Using the first time derivative of the pupil signal, we recalculated the principal components of the pupillary response as with the first order signal. Using these recalculated principal components, we reassessed the relationship between the pupillary data and our conditional manipulations and retested the link between these principal components and theta, the relationship between <italic>a</italic> and <italic>v</italic>. We continue to observe null effects. See point 4 of our response to Reviewer 1.</p><disp-quote content-type="editor-comment"><p>d) Further, please note that the pupil likely not only is linked to the LC-NE system, but generally to catecholamines, which includes dopamine (Joshi et al. Neuron 2015). Therefore, I would recommend to not exclusively link pupil to LC-NE in the manuscript while interpreting the pupil results.</p></disp-quote><p>We appreciate the point that other catecholamines, such as dopamine, also contribute to the task-evoked pupillary response. We now acknowledge this lack of specificity in the Discussion:</p><p>“We hypothesized that these shifts in decision policies would be linked to changes in phasic responses of the LC-NE pathways, although we should note our experimental design does not distinguish between pupillary dynamics driven by other catecholamines, such as dopamine, and those dynamics driven by the LC-NE system.”</p><disp-quote content-type="editor-comment"><p>e) In any case, the author should show raw pupil as well as pupil derivative time courses for the different conditions to give insight in their data.</p></disp-quote><p>We now include subject-wise visualizations of the evoked pupillary response and the time derivative of that response for all combinations of conflict and volatility in the Supplementary section (Supp. Figures 11 and 13).</p></body></sub-article></article>