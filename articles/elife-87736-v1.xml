<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">87736</article-id><article-id pub-id-type="doi">10.7554/eLife.87736</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87736.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Running modulates primate and rodent visual cortex differently</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Liska</surname><given-names>John P</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Rowley</surname><given-names>Declan P</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Nguyen</surname><given-names>Trevor Thai Kim</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0005-3277-9535</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Muthmann</surname><given-names>Jens-Oliver</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0439-9704</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Butts</surname><given-names>Daniel A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0158-5317</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Yates</surname><given-names>Jacob</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8322-5982</contrib-id><email>yates@berkeley.edu</email><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="fn" rid="pa1">§</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Huk</surname><given-names>Alexander C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1430-6935</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib2">‡</xref><xref ref-type="fn" rid="pa2">#</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>Departments of Neuroscience and Psychology, Center for Perceptual Systems, Institute for Neuroscience, The University of Texas at Austin</institution></institution-wrap><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>Departments of Ophthalmology and Psychiatry &amp; Biobehavioral Sciences, Fuster Laboratory for Cognitive Neuroscience, UCLA</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/047s2c258</institution-id><institution>Department of Biology and Program in Neuroscience and Cognitive Science, University of Maryland</institution></institution-wrap><addr-line><named-content content-type="city">College Park</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>Herbert Wertheim School of Optometry and Vision Science, University of California, Berkeley</institution></institution-wrap><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00ggpsq73</institution-id><institution>Otto-von-Guericke University Magdeburg</institution></institution-wrap><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>Beijing Normal University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="con" id="equal-contrib2"><label>‡</label><p>These authors also contributed equally to this work</p></fn><fn fn-type="present-address" id="pa1"><label>§</label><p>Herbert Wertheim School of Optometry and Vision Science, Berkeley, United States</p></fn><fn fn-type="present-address" id="pa2"><label>#</label><p>Fuster Laboratory for Cognitive Neuroscience, UCLA, Los Angeles, United States</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>19</day><month>11</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP87736</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-04-06"><day>06</day><month>04</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-03-14"><day>14</day><month>03</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.06.13.495712"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-07-14"><day>14</day><month>07</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87736.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-08"><day>08</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87736.2"/></event></pub-history><permissions><copyright-statement>© 2023, Liska, Rowley et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Liska, Rowley et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-87736-v1.pdf"/><related-article related-article-type="commentary" ext-link-type="doi" xlink:href="10.7554/eLife.101013" id="ra1"/><abstract><p>When mice run, activity in their primary visual cortex (V1) is strongly modulated. This observation has altered conceptions of a brain region assumed to be a passive image processor. Extensive work has followed to dissect the circuits and functions of running-correlated modulation. However, it remains unclear whether visual processing in primates might similarly change during locomotion. We therefore measured V1 activity in marmosets while they viewed stimuli on a treadmill. In contrast to mouse, running-correlated modulations of marmoset V1 were small and tended to be slightly suppressive. Population-level analyses revealed trial-to-trial fluctuations of shared gain across V1 in both species, but while strongly correlated with running in mice, gain modulations were smaller and more often negatively correlated with running in marmosets. Thus, population-wide fluctuations of V1 may reflect a common feature of mammalian visual cortical function, but important quantitative differences point to distinct consequences for the relation between vision and action in primates versus rodents.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd><italic>Callithrix jacchus</italic></kwd><kwd>V1</kwd><kwd>running</kwd><kwd>comparative</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>BRAIN Initiative U01-UF1NS116377</award-id><principal-award-recipient><name><surname>Huk</surname><given-names>Alexander C</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000181</institution-id><institution>Air Force Office of Scientific Research</institution></institution-wrap></funding-source><award-id>FA9550-19-1-0357</award-id><principal-award-recipient><name><surname>Huk</surname><given-names>Alexander C</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>NSC-FO 2123605</award-id><principal-award-recipient><name><surname>Butts</surname><given-names>Daniel A</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>K99EY032179-02</award-id><principal-award-recipient><name><surname>Yates</surname><given-names>Jacob</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Although activity in mouse V1 increases substantially during volitional running, such modulations in the foveal/central representation of primate V1 appear much smaller and suppressive.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Sensation and action are traditionally thought to involve separate brain circuits serving distinct functions: activity in early sensory areas is driven nearly exclusively by the corresponding sensory input, whereas activity in motor areas is exclusively related to movement. Recent work in mice, a major mammalian model system in neuroscience, has called for a re-evaluation of this distinction, given recent demonstrations that activity in mouse primary visual cortex (V1) depends as much on whether the mouse is running or stationary as on what visual stimulus is shown (<xref ref-type="bibr" rid="bib36">Niell and Stryker, 2010</xref>). Neurons in V1 of virtually all mammals are selective for simple image features, a presumably critical early step of image processing that continues throughout a hierarchy of visual brain areas (<xref ref-type="bibr" rid="bib45">Rosa and Krubitzer, 1999</xref>; <xref ref-type="bibr" rid="bib17">Felleman and Van Essen, 1991</xref>), and this is true of mice as well (<xref ref-type="bibr" rid="bib35">Niell and Stryker, 2008</xref>). The observation that running modulates (mouse) V1 of a comparable magnitude to the visually driven activity has motivated substantial effort in the field to understand the biological mechanisms and functional consequences of this powerful interaction between sensation and action (<xref ref-type="bibr" rid="bib26">Keller et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Vinck et al., 2015</xref>; <xref ref-type="bibr" rid="bib5">Bennett et al., 2013</xref>; <xref ref-type="bibr" rid="bib46">Saleem et al., 2013</xref>; <xref ref-type="bibr" rid="bib16">Erisken et al., 2014</xref>; <xref ref-type="bibr" rid="bib44">Reimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib38">Pakan et al., 2016</xref>; <xref ref-type="bibr" rid="bib40">Polack et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">Fu et al., 2014</xref>; <xref ref-type="bibr" rid="bib31">Mineault et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Ayaz et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Christensen and Pillow, 2022</xref>; <xref ref-type="bibr" rid="bib12">Dipoppa et al., 2018</xref>).</p><p>However, these observations have all been made in rodents; similar measurements have not been made in primates. Although rodents certainly rely on vision for important behaviors (<xref ref-type="bibr" rid="bib24">Hoy et al., 2016</xref>; <xref ref-type="bibr" rid="bib59">Yilmaz and Meister, 2013</xref>), primates are more fundamentally visual organisms, with exquisite acuity and specialized functional characteristics such as foveas and corresponding high-resolution representations of the central visual field in V1 (<xref ref-type="bibr" rid="bib27">Land and Fernald, 1992</xref>), in addition to a larger network of areas involved in vision (<xref ref-type="bibr" rid="bib17">Felleman and Van Essen, 1991</xref>). While experiments that allow subjects to run while viewing visual stimuli may now be commonplace in mice, analogous experiments in nonhuman primates have remained technically daunting. It has thus remained unclear whether the large effect of running on early visual processing is a general property of mammalian brains revealed by work in mice or whether the early stages of primate visual processing are less affected by nonvisual factors. Here, we fill this major gap in cross-species understanding by taking advantage of the relatively small size and peaceable nature of the common marmoset (<italic>Callithrix jacchus</italic>), which allowed us to have animals on a custom-designed treadmill and to use high-channel-count electrode arrays, including Neuropixels. Our comparative study fits into a larger emerging enterprise to assess whether substantial signals due to animal movements affect sensory processing similarly in rodents and primates (<xref ref-type="bibr" rid="bib50">Talluri et al., 2023</xref>; <xref ref-type="bibr" rid="bib49">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="bib33">Musall et al., 2019</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We tested for running-based modulations in V1 of the common marmoset, a highly visual new world primate. Marmosets were head-fixed, placed on a wheel-based treadmill suited to their arboreal nature (<xref ref-type="fig" rid="fig1">Figure 1a</xref>), and alternated between running and not running while we presented various visual stimuli designed to assess the properties and responsiveness of V1 neurons (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). We recorded from foveal and parafoveal neurons in two marmosets (using chronically implanted N-Form 3D electrode arrays), and in one marmoset were also able to simultaneously record from both foveal and peripheral V1 (using Neuropixels 1.0 probes). To support precise comparison to rodent V1, we used the same analysis pipeline on a publicly available mouse dataset that used matching stimuli in a treadmill paradigm (<ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>). This let us perform direct quantitative and statistical comparisons of the effects of running on V1 activity in a rodent and a primate.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Recording from marmoset V1 during active locomotion.</title><p>(<bold>a</bold>) Apparatus for recording from marmoset V1 while presenting visual stimuli on a high-resolution display, monitoring gaze using an eye tracker, on a toroidal treadmill that allowed the marmoset to run or not run. (<bold>b</bold>) Schematic example of variables of interest. Visual stimuli were presented (top row). Rasters show activity from a V1 array (second row). Gaze was monitored (third row, x and y time series plotted in black and gray), saccades were detected (red), and pupil size was also measured (fourth row). Running speed was measured using a rotary encoder attached to the treadmill (fifth row). (<bold>c</bold>) Before the main experiments, receptive fields (RFs) were mapped using sparse noise (<xref ref-type="bibr" rid="bib57">Yates et al., 2021</xref>). The array of pseudocolor images shows three examples of V1 RFs (two foveal and one peripheral neuron). (<bold>d</bold>) Main experiment involved presenting full-field sinusoidal gratings that drifted in one of 12 directions (top row), at a variety of spatial frequencies (vertical axis at left). Rasters show example V1 activity during stimulus presentations when running (red) or stationary (black). (<bold>e</bold>) Summary of RF locations in the mouse dataset (orange, top), and (<bold>f</bold>) our data from marmosets (blue and green, bottom). In both marmosets, we recorded from a portion of V1 accessible at the dorsal surface of the brain using chronically implanted arrays, which yielded neurons with foveal RFs (green RFs). We also recorded from one marmoset using Neuropixels arrays, allowing us to simultaneously access both peripheral and foveal V1 (blue RFs; peripheral units are analyzed later/separately, see text). (<bold>g</bold>) Examples of mouse V1 orientation tuning curves, for cells with weak, moderate, and strong orientation tuning. (<bold>h</bold>) Same, for marmoset V1. (<bold>i, j</bold>) Histograms of orientation-selectivity indices (OSIs) for mice (<bold>i</bold>) and marmosets (<bold>j</bold>). Marmoset OSIs, likely lower than previously reported because we used full-field stimuli not optimized to the spatial frequency tuning of each neuron, and which likely recruited surround suppression. Regardless, the marmoset V1 neurons had strong visual responses and qualitatively conventional tuning. (<bold>k, l</bold>) Running speeds in mice (<bold>k</bold>) and marmosets (<bold>l</bold>). Marmosets were acclimated to the treadmill and motivated to run with fluid rewards yoked to traveling a criterion distance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87736-fig1-v1.tif"/></fig><p>First, we mapped the receptive fields of marmoset V1 neurons using reverse-correlation techniques adapted to free-viewing (<xref ref-type="bibr" rid="bib57">Yates et al., 2021</xref>) while we measured gaze using a video-based eyetracker (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). In V1 of both marmosets, we found receptive fields within the central few degrees of vision, with sizes expected at those eccentricities (1–5°, <xref ref-type="fig" rid="fig1">Figure 1f</xref>, blue and green; these can be compared to those in mouse, <xref ref-type="fig" rid="fig1">Figure 1e</xref>). As expected for primary visual cortex, marmoset V1 (both well-isolated single units and well-tuned multi-unit clusters) responded robustly to oriented gratings and exhibited orientation- (and sometimes direction-) selectivity (<xref ref-type="bibr" rid="bib60">Yu and Rosa, 2014</xref>; <xref ref-type="bibr" rid="bib48">Sengpiel et al., 1996</xref>), similar to that in the mouse V1 dataset (<xref ref-type="fig" rid="fig1">Figure 1g and h</xref>). Orientation tuning spanned a range from weak to strong tuning, with many units exhibiting strong and conventional tuning curves (<xref ref-type="fig" rid="fig1">Figure 1i and j</xref>).</p><p>As a first test for effects of running on V1 activity, we assessed whether running speed was correlated with aggregate V1 activity by comparing the time series of these variables throughout each session. In the mouse, such modulations are easily visually evident when inspecting the time series of neural activity and running: when the mouse runs, V1 spiking often increases substantially. <xref ref-type="fig" rid="fig2">Figure 2a and b</xref> shows example sessions with the maximal and median amounts of correlation between the time series of running speed and a generic low-dimensional representation of the population activity (the first principal component [PC] of the simultaneously recorded V1 trial spike counts, see ‘Materials and methods’). This correlation could be seen when running/not running alternated on slow (<xref ref-type="fig" rid="fig2">Figure 2a</xref>) or fast (<xref ref-type="fig" rid="fig2">Figure 2b</xref>) time scales.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Mice and marmosets exhibit different correlations between V1 activity and running speed.</title><p>(<bold>a</bold>) Mice show visually compelling correlations between V1 trial spike counts and running speed. Example session with the highest correlation between running and V1 activity. Raster at top shows spiking activity of all mouse V1 neurons recorded. Population activity is summarized below the raster as the first principal component of the V1 array activity (‘First Neural PC’, orange trace); running speed is plotted underneath it on the same time axis (gray trace). Clearly, the two curves are highly similar. (<bold>b</bold>) Same, for an example mouse session chosen to have the median correlation between running and V1 activity. In this example, the modulations of running speed and neural activity rise and fall together on a faster time scale than in the example in (<bold>a</bold>). (<bold>c, d</bold>) Marmosets show smaller, and typically negative, correlations between V1 spiking activity and running speed. Format same as the mouse data in (<bold>a, b</bold>), with example sessions chosen to show the maximal and the median correlations between V1 activity and running speed. The (anti-correlated) similarity between V1 activity (First Neural PC) and Running Speed curves is harder to discern in the marmoset. (<bold>e, f</bold>) Correlations between V1 activity and running in the mouse (<bold>e</bold>) had a median &gt;0 (median = 0.407, p=<inline-formula><mml:math id="inf1"><mml:mrow><mml:mn>9.04</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 308, n = 25, Mann–Whitney <italic>U</italic> test), and many individual sessions had significant correlations with running (filled bars), and all such significant sessions had positive correlations (with significance determined via permutation to remove effects of autocorrelation; <xref ref-type="bibr" rid="bib22">Harris, 2021</xref>). In the marmosets (<bold>f</bold>), the distributions of correlations were slightly but reliably negative (median = −0.033, p=0.034, stat = 101, n = 27, Mann–Whitney <italic>U</italic> test), and all significantly modulated individual sessions exhibited negative correlations (5/27).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87736-fig2-v1.tif"/></fig><p>A starkly different impression comes from visual inspection of the relationship between running and the activity of marmoset V1 neurons representing the central visual field. Any relation between V1 activity and running appears considerably smaller. In examples showing the maximal and median relationships between running and V1 activity (<xref ref-type="fig" rid="fig2">Figure 2c and d</xref>), V1 activity did not track running speed as clearly, although the activity did tend to increase when the monkey stopped running, explaining the modest negative correlations.</p><p>We then quantified the relationship between the timecourses of aggregate V1 activity and running across all experiments on a session-by-session basis, in both species. For mice, this confirmed a strong positive correlation (<xref ref-type="fig" rid="fig2">Figure 2e</xref>; median = 0.407, n = 25, p=<inline-formula><mml:math id="inf2"><mml:mrow><mml:mn>9.04</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 308, Mann–Whitney <italic>U</italic> test). For marmosets, the distribution of correlations between V1 activity and running was subtly but reliably negative (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, median = −0.033, p=0.034, stat = 101, n = 27, Mann–Whitney <italic>U</italic> test). Most importantly, the correlation between V1 activity and running was significantly different between the two species (p=<inline-formula><mml:math id="inf3"><mml:mrow><mml:mn>6.93</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 934, Mann–Whitney <italic>U</italic> test). This session-level analysis confirmed that running modulations in mice are large and mostly reflect increases in response. In contrast, running modulations in marmoset foveal V1 are small, and if anything, reflect slight reductions in activity.</p><p>To perform additional quantitative tests at the level of individual V1 units, we divvied up each unit’s spiking responses to drifting gratings based on whether or not the animal was running (<xref ref-type="fig" rid="fig3">Figure 3</xref>). This analysis confirmed, in mouse, a tendency for large response increases during running to both the preferred orientation stimulus (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, geometric mean ratio [running/stationary] = 1.523, 95% CI [1.469, 1.579], n = 743 tuned units) and to all visual stimuli (<xref ref-type="fig" rid="fig3">Figure 3b</xref>, 1.402 [1.365, 1.440], n = 1168). Many individual units had significant running modulations and were more often increases rather than decreases (803/1168 [69%] increased firing rate and 115/1168 [10%] decreased, bootstrapped <italic>t</italic>-test). In marmoset V1, there was again a modest decrease evident in the response to the preferred stimulus (<xref ref-type="fig" rid="fig3">Figure 3c</xref>; geometric mean ratio [running/stationary] = 0.899, 95% CI [0.851, 0.949], n = 228 tuned units). Not even modest suppression was evident in responses aggregated across all stimuli (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, 1.011 [0.995, 1.027], n = 786). The number of significantly modulated units was relatively small and was more balanced between decreases and increases in firing rate (172/786 [22%] increased and 161/786 [20%] decreased, bootstrapped <italic>t</italic>-test). Because we performed quantitative comparisons on subsets of the data for which the stimuli were nearly identical across species, and used the same data analysis code to calculate response metrics, these analyses solidly confirm a substantial difference between the form of running modulations of V1 activity in mouse versus marmoset (log ratio of running:stationary was significantly different between mouse and marmoset for all units: p=<inline-formula><mml:math id="inf4"><mml:mrow><mml:mn>6.62</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>99</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 1399874, Mann–Whitney <italic>U</italic> test, and tuned units: p=<inline-formula><mml:math id="inf5"><mml:mrow><mml:mn>4.69</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>57</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 4030135). Thus, the overall impacts of running on V1 units again appear large and positive in mice, and much smaller (and perhaps slightly negative) in marmoset.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Running strongly increases mouse V1 activity and subtly decreases marmoset V1 activity, evidenced at the level of individual units.</title><p>Mouse data points are plotted in orange and marmoset data in blue. (<bold>a</bold>) Scatterplot (log-log) shows firing rate to preferred stimulus for tuned units (orientation-selectivity indices [OSI] &gt; 0.2), during running (y-axis) and stationary (x-axis). Histogram summarizes the projections onto the line of unity and shows a clear shift indicating increases in response during running (geometric mean ratio [running/stationary] = 1.523 [1.469, 1.579], n = 743). Dark-shaded symbols indicate individually significant units. Dashed lines indicate doubling (2×) and halving (0.5×) of response. (<bold>b</bold>) Same format, but now showing the response aggregated over all stimuli, for all units (geometric mean ratio [running/stationary] = 1.402 [1.365, 1.440], n = 1168). A similar pattern reflecting primarily large increases is evident. (<bold>c, d</bold>) V1 units in marmoset show a very different pattern. Responses of tuned units to preferred stimuli (<bold>c</bold>) cluster more closely to the line of unity, with a small but significant shift indicating a subtle decrease in response (geometric mean ratio [running/stationary] = 0.899 [0.851, 0.949], n = 228). Responses to all stimuli for all units (<bold>d</bold>) show even less running-related modulation (geometric mean ratio [running/stationary] = 1.011 [0.995, 1.027], n = 786).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87736-fig3-v1.tif"/></fig><p>Given these apparently categorical differences between the two species at the levels of both experimental sessions (<xref ref-type="fig" rid="fig2">Figure 2</xref>) and individual units (<xref ref-type="fig" rid="fig3">Figure 3</xref>), a key question is whether mouse and marmoset visual cortices are modulated by non-visual input in fundamentally different ways. To answer this, we employed more powerful model-based neuronal population analyses that inferred trial-to-trial variations in shared gain modulations across V1 (<xref ref-type="fig" rid="fig4">Figure 4a and d</xref>; <xref ref-type="bibr" rid="bib55">Whiteway et al., 2019</xref>), in a manner totally agnostic to running (or any other aspect of behavior). This shared-gain model improved descriptions of the population data over simpler models that only took the stimulus (and slow drifts in baseline firing rate) into account for all sessions (<xref ref-type="fig" rid="fig4">Figure 4b and c</xref>; marmoset p=<inline-formula><mml:math id="inf6"><mml:mrow><mml:mn>1.52</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>82</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 27174, n = 754, Wilcoxon signed-rank test; mouse p=<inline-formula><mml:math id="inf7"><mml:mrow><mml:mn>4.64</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>181</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 25966, n = 1257). This was true in both species, bolstering the emerging notion that population-level gain modulations are a general principle of mammalian V1 function (<xref ref-type="bibr" rid="bib55">Whiteway et al., 2019</xref>; <xref ref-type="bibr" rid="bib30">Lin et al., 2015</xref>; <xref ref-type="bibr" rid="bib1">Arandia-Romero et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="bib18">Ferguson and Cardin, 2020</xref>). This shared gain term modulated more strongly in mice compared to marmosets (<xref ref-type="fig" rid="fig4">Figure 4e</xref>, std. dev. in mouse = 2.170 [2.106, 2.245], marmoset = 1.188 [1.072, 1.274], p&lt;<inline-formula><mml:math id="inf8"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, stat = 1013202, Mann×Whitney <italic>U</italic> test). Furthermore, in the mouse, shared gain was higher for running than stationary as estimated during stimulus presentations (mean difference 0.970 [0.761, 1.225], p~0, stat 8.017, <italic>t</italic>-test), demonstrating that a substantial portion of modulations of mouse V1 can be explained by a shared gain term that increases with running (<xref ref-type="fig" rid="fig4">Figure 4f</xref>, orange point). In marmoset, shared gain was slightly but reliably lower when running (mean difference = −0.125 [-0.203, -0.059], p=0.002, stat = −3.360, <italic>t</italic>-test, <xref ref-type="fig" rid="fig4">Figure 4f</xref>, blue point), a quantitatively very different relation to running than in mouse (p=<inline-formula><mml:math id="inf9"><mml:mrow><mml:mn>8.77</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 6.615, two-sample <italic>t</italic>-test). Thus, a common mechanism (shared gain) can describe running modulations in both species, but with quantitatively different correlations with behavior that make for potentially distinct downstream impacts on perception and action.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Shared gain model accounts for fluctuations in both mouse and marmoset V1, and explains species differences.</title><p>(<bold>a</bold>) Structure of shared modulator model. In addition to the effects of the stimulus (and slow drift in responsiveness, not rendered), the model allows for a shared gain/multiplicative term (green). Each simultaneously recorded neuron is fitted with a weight to the latent gain term. (<bold>b</bold>) The resulting model provides a better account of both mouse and marmoset V1 responses compared to a simple model that only fits stimulus and slow drift terms. Points show variance explained (<inline-formula><mml:math id="inf10"><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) on test data for each session under each of the two models, plotted against one another. (<bold>c</bold>) Variance explained for individual units was significantly improved in both species (marmoset: gain model [median  <inline-formula><mml:math id="inf11"><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> = 0.2504] significantly higher than stim + drift [median  <inline-formula><mml:math id="inf12"><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> = 0.1220], p=<inline-formula><mml:math id="inf13"><mml:mrow><mml:mn>1.52</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>82</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 27174, Wilcoxon signed-rank test; mouse: gain model [median  <inline-formula><mml:math id="inf14"><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> = 0.4420] significantly better than stim + drift [median  <inline-formula><mml:math id="inf15"><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> = 0.1697], p=<inline-formula><mml:math id="inf16"><mml:mrow><mml:mn>4.64</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>181</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 25966, Wilcoxon signed-rank test). (<bold>d</bold>) Example of relationship between neural responses (top raster, blue), the shared gain (green), and running speed (black trace). Visual inspection similar to that in <xref ref-type="fig" rid="fig2">Figure 2</xref> can be performed. (<bold>e</bold>) Gain modulations span a larger range in mice than in marmosets. Orange, gain term from each mouse session; blue, gain term from each marmoset session. Triangles indicate medians (mouse = 2.17 [2.11, 2.25], marmoset = 1.19 [1.07, 1.27]). (<bold>f</bold>) Shared gain term is larger during running for mouse data, but is slightly smaller during running for marmoset data (difference is plotted on y-axis; mouse = 0.970 [0.761, 1.225], p=<inline-formula><mml:math id="inf17"><mml:mrow><mml:mn>4.73</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat 8.017, one-sample <italic>t</italic>-test; marmoset = −0.125 [−0.203, −0.059], p=0.002, stat = −3.360, one-sample <italic>t</italic>-test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87736-fig4-v1.tif"/></fig><p>Although our marmoset dataset focused on V1 neurons representing the central portion of the visual field, we were also able to record simultaneously from neurons with peripheral and central (foveal) receptive fields by advancing a Neuropixels probe into both the superficial portion of V1 (foveal/central) and the calcarine sulcus (peripheral), resulting in simultaneous recordings of 110 and 147 (stimulus-driven) units representing the central and peripheral portions of the visual field, respectively. Analyzing neurons with peripheral receptive fields separately revealed a difference in running modulations between these retinotopically distinct portions of V1: peripheral neurons had slightly higher stimulus-driven responses during running (aggregating over all stimuli, geometric mean ratio [running/stationary] = 1.129 [1.068, 1.194], n = 147; difference with the central units was significant, p=2.100e-03, stat = 12376, Mann–Whitney <italic>U</italic> test), and the two sessions in which we were able to perform these measurements had higher positive correlations than any sessions in our entire foveal V1 dataset (assessed by correlating running speed either with the First Neural PC or with a shared gain term). Although the foveal representation in V1 (accessible in marmosets on the dorsal surface of the brain) is slightly suppressed by running, it appears that quantitative differences exist in the peripheral representation (which we recorded from in the calcarine sulcus). This initial set of recordings suggests that subtle increases in response might occur in the peripheral representation in marmoset V1. This finding calls for a larger-scale study of how such modulations might differ across portions of the retinotopic map, and for further consideration of the implications for cross-species comparisons. An intriguing conjecture is that the primate foveal representation might be functionally unique, but that the primate peripheral representation might be more functionally similar to that of mouse V1 (<xref ref-type="bibr" rid="bib23">Horrocks et al., 2022</xref>).</p><p>Although this is an interesting potential distinction that further work will investigate more systematically, we emphasize that the main result described earlier still holds: the effects of running are small in marmoset V1. Even though there are slightly positive modulations in the peripheral representation (and hence, are of the same sign as those in mouse), the magnitude of whatever running-correlated modulations we could measure in marmoset V1 are still small relative to those in mouse V1 (median spike rate modulation by running significantly different between mouse and marmoset calcarine/peripheral recordings: p=<inline-formula><mml:math id="inf18"><mml:mrow><mml:mn>7.639</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo lspace="0em" rspace="0em">−</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, stat = 7967825, Mann–Whitney <italic>U</italic> test).</p><p>Finally, we assessed whether the modest running-correlated modulations we observed in marmoset V1 might be explained by eye movements. If eye movements differed when the animal ran versus when it did not run, that would mean that the retinal input differed between the two conditions (<xref ref-type="bibr" rid="bib23">Horrocks et al., 2022</xref>). In that case, running modulations would not reflect a direct effect of running (a fundamentally non-visual effect), but rather a consequence of changes in the patterns of retinal stimulation (which we already know affects V1 responses). To test this possibility, we quantified the number of saccades per stimulus presentation, as well as saccade size (vector magnitude), and then assessed whether these eye movement metrics differed as a function of running.</p><p>We found that eye movements were quite similar between running and stationary periods, although subtle quantitative differences were revealed (<xref ref-type="fig" rid="fig5">Figure 5</xref>). In short, saccades were slightly more frequent and larger during running (saccade frequency during running: 2.653 Hz, 95% CI [2.600, 2.697]; stationary/not running: 2.525 Hz [2.475, 2.573]; saccade magnitude during running: 9.261° [9.140, 9.374]; stationary/not running: 8.337° [8.190, 8.470]). This result motivated us to then assess whether these running-correlated eye movement differences might quantitatively explain the running-correlated modulations of V1 response. Our initial analyses found that differences in retinal stimulation due to differences in eye movements are unlikely to explain running-correlated suppression of V1 activity. We used linear regression to estimate the relationship between number of saccades and the firing rate of each unit in each trial. This enabled us to predict how much change in firing rate we should expect given the differences in saccade rate between the running and stationary conditions. The response change predicted from saccades was much less than the already-small running-correlated changes in response we observed in our experiment. On the aggregate, saccades slightly increased activity (predicted spike rate increase during running based on saccades = 0.05 Hz; expressed as gain, &lt;1%), and thus cannot explain the sign or magnitude of the subtle decreases we observed. In short, the decreases in V1 activity we saw in our main dataset are not likely to be explained by differential patterns of eye movements. (Likewise, the distinction we saw between running-correlated modulations in foveal versus peripheral V1 is unlikely attributable to eye movements, as we recorded simultaneously from both parts of the retinotopic map, meaning that the eye movements were the same despite the difference in modulations.)</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Eye movements and pupil size are modestly different during running.</title><p>(<bold>a</bold>) Each panel shows overlapping histograms of a measurement made on trials when the animal was running (blue) or stationary (red). (<bold>a</bold>) Saccade rate (in Hz) is slightly higher during running. (<bold>b</bold>) Saccade magnitude (in degrees of visual angle) is also slightly higher during running. The slight differences in saccade frequency and size did not quantitatively explain the differences in neural activity during running versus stationary periods; see main text for analysis. (<bold>c</bold>) Pupil size (expressed as % of mean size during stationary) is 8% larger during running (see main text for additional quantification).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87736-fig5-v1.tif"/></fig><p>Regrettably, the mouse dataset with which we compared our marmoset recordings did not reliably have eye video with quality required to do precise gaze estimation (at least for many of the sessions), so we could not perform a definitive analysis in mouse. However, the degree to which movement-correlated modulations of sensory processing contain a retinal contribution is an important issue (<xref ref-type="bibr" rid="bib23">Horrocks et al., 2022</xref>), and one that we hope to tackle more directly in future cross-species studies wherein eyetracking and knowledge of individual receptive fields is highly, and equally, prioritized in mice and marmosets.</p><p>We also analyzed the pupil size from our eyetracking videos. Pupil size was ∼8% larger during running. This finding is consistent with the idea that the marmosets were in a higher arousal state during running. Such a result is at least loosely consistent with effects seen in mice (although in that literature, there is some degree of dissociation between modulations due to arousal and those due to running per se; <xref ref-type="bibr" rid="bib51">Vinck et al., 2015</xref>). Thus, the changes in pupil size we detected do suggest that when a marmoset runs, it is likely in a higher arousal state, similar to that in mice. However, more work would be required to perform cross-species calibrations to understand how the magnitude of changes in pupil size corresponds to changes in levels of arousal. At this point, we can conclude that the differences we see in the size (and sometimes, sign) of V1 modulations across species are unlikely due to a categorical difference in a link between running and arousal in mice versus marmosets, but possible quantitative distinctions deserve further consideration.</p></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In short, running does not affect V1 activity in marmosets like it does in mouse. The large, typically positive correlations between running and V1 activity often found in mice are simply not evident in marmosets. Although we matched our experimental protocol to mouse experiments and used the same metrics and analysis pipeline, the difference in results across species was stark. We hypothesize that this distinction holds at the level of taxonomic order, distinguishing how much behavioral state interacts with early stages of visual processing in primates versus rodents.</p><p>Diving deeper into the pattern of results, we did detect small (but statistically nonzero) modulations of marmoset V1 response correlated with running. In the foveal representation in V1 – where we made the majority of our recordings – responses on average were slightly smaller during running; in the peripheral representation, responses were slightly larger.</p><p>Despite the main result of this study being that running-correlated modulations in marmoset V1 are small, and hence quantitatively different than that in mouse V1, our population-level analyses did point towards a possible cross-species generalization. The same shared-gain model improved accounts of both mouse and marmoset V1 activity. These population-level gain modulations likely reflect modulatory inputs associated with behavioral state and arousal. This commonality connects with mechanistic knowledge of how V1 activity is modulated. The primate-rodent difference in the magnitude and sign of V1 gain modulations we observed is in fact consistent with known differences in neuromodulatory inputs related to arousal in rodent and primate V1 (<xref ref-type="bibr" rid="bib14">Disney and Robert, 2019</xref>; <xref ref-type="bibr" rid="bib11">Coppola and Disney, 2018</xref>). In primates, the locations of ACh receptors allow cholinergic inputs to increase the activity of the majority of GABAergic neurons and hence suppress net activity via inhibition (<xref ref-type="bibr" rid="bib13">Disney et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Lien and Scanziani, 2013</xref>), but pharmacologically and anatomically distinct cholinergic influences in rodent likely exert more complex effects on net activity, including disinhibition which can increase net activity (<xref ref-type="bibr" rid="bib38">Pakan et al., 2016</xref>; <xref ref-type="bibr" rid="bib19">Fu et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Pfeffer et al., 2013</xref>). Our population-level analyses also lay groundwork for connections to indirect and aggregate measures of neural activity made in humans under related conditions (<xref ref-type="bibr" rid="bib8">Chen et al., 2022</xref>; <xref ref-type="bibr" rid="bib7">Cao et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Benjamin et al., 2018</xref>), as well as the typically small modulations seen in primate visual cortices elicited by carefully controlled attentional tasks, which are more clear when population-level modulations are considered (<xref ref-type="bibr" rid="bib32">Mitchell et al., 2009</xref>; <xref ref-type="bibr" rid="bib10">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib43">Rabinowitz et al., 2015</xref>).</p><p>We also performed an analysis of whether eye movements might contribute to differential visual (retinal) stimulation, which in turn could differentially modulate visually driven activity in V1 during running versus stationary periods. We found that there were subtle increases in eye movement frequency and saccade amplitude during running. However, saccades on average slightly increased V1 activity, so it seems unlikely that eye-movement-mediated changes in retinal stimulation explain the modest decreases we observed during running. We found that analysis of eye movements was difficult in some of the mouse datasets. Because receptive fields in mouse V1 can be very large, uncontrolled (and/or uncharacterized) eye movements can not only create visual modulations of the stimulus on the screen, but can also hit the edges of the monitor under some viewing conditions. A related study <xref ref-type="bibr" rid="bib50">Talluri et al., 2023</xref> found that eye movements (or, their effects on retinal stimulation) explained all of the modulations of V1 activity that were correlated with facial/body movements in seated macaques. Further work will be needed to understand how much eye movements play a role in both running-correlated and movement-correlated modulations in the mouse. This will require monitoring eye movements and dissecting the ensuing retinal effects from those of other (body and face) movements (<xref ref-type="bibr" rid="bib33">Musall et al., 2019</xref>); all of these types of motor activity (and subsequent ‘sensory reafference’) may be partially correlated.</p><p>Our results (as well as those of <xref ref-type="bibr" rid="bib50">Talluri et al., 2023</xref>) reveal a number of additional issues that should be addressed in follow-up work to even more tightly relate work across the two species. In our study, we attempted to match the overall treadmill apparatus and the visual stimuli used in the mouse studies. Even that required species-specific customization of the treadmill, as well as taking into account the higher spatial acuity of primate vision (which is why our study used much higher spatial frequencies in our set of drifting gratings). We describe how additional unresolved issues could be addressed for improved cross-species integration.</p><p>First, we analyzed pupil size and found that it was larger when the marmosets ran. At first glance, this suggests that running does indicate a more aroused internal state in the marmosets, as it likely does in mice (<xref ref-type="bibr" rid="bib51">Vinck et al., 2015</xref>). However, it is less clear whether the magnitude of pupil size changes in marmosets corresponds to the same amount of arousal change that occurs in mice. Relative calibration of the dynamic range of pupil size (and measuring other biomarkers of arousal) may make for more satisfying inferences about internal states across species, as it has been shown that some (but not all) of running-correlated modulations are likely due to arousal (<xref ref-type="bibr" rid="bib51">Vinck et al., 2015</xref>; <xref ref-type="bibr" rid="bib28">Lee et al., 2014</xref>).</p><p>Second, although we found only small effects (relative to mouse) at the aggregate level, our results call for more specific investigations of modulations at the level of cell types and subcircuits (<xref ref-type="bibr" rid="bib36">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib38">Pakan et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Bennett et al., 2013</xref>; <xref ref-type="bibr" rid="bib40">Polack et al., 2013</xref>). Such investigations may reveal more nuanced effects in primate V1, using tools that can better unpack the circuitry associated with factors such as cholinergic modulation, which are known to differ in important ways across rodent and monkey (<xref ref-type="bibr" rid="bib11">Coppola and Disney, 2018</xref>; <xref ref-type="bibr" rid="bib14">Disney and Robert, 2019</xref>). Additionally, differences in feedback circuits also exist across the visual field representation within primate V1 (<xref ref-type="bibr" rid="bib52">Wang et al., 2022</xref>). This – and the proposition that mouse V1 may be a better model of primate peripheral vision (<xref ref-type="bibr" rid="bib23">Horrocks et al., 2022</xref>) – has motivated us to perform more systematic and larger-scale recordings to compare the foveal and peripheral representations.</p><p>Third, our results call for additional study across other visual areas. In mice, the large effects on V1 activity are likely to affect all subsequent stages of processing (<xref ref-type="bibr" rid="bib9">Christensen and Pillow, 2022</xref>), but in marmosets, the small effects are less likely to have pronounced downstream effects. That said, running may directly and more strongly interact with later stages of visual processing in primates. This would be consistent with differences in where canonical computations occur across species with different numbers of visual areas (<xref ref-type="bibr" rid="bib17">Felleman and Van Essen, 1991</xref>; <xref ref-type="bibr" rid="bib20">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib47">Scholl et al., 2013</xref>). Such measurements in primate extrastriate visual areas are already in progress in our laboratory.</p><p>Finally, larger effects of behavioral state may still be found in primate V1: other behaviors that more directly recruit active vision may reveal stronger modulations. In mice, running may have a more direct functional relation to visual processing. Marmosets may instead wish to recruit head or body movements that are not realizable in the head-fixed preparation that we used for eye-movement and neural recording. These questions will be addressed in freely moving and head-free subjects.</p><p>Although our main result is simply that running-correlated modulations in marmoset V1 are small relative to those in mouse, we did find evidence for behaviorally correlated population-level gain modulations in both species. This sort of commonality may support further cross-species generalizations that transcend simpler observations of empirical similarity or dissimilarity (<xref ref-type="bibr" rid="bib37">Niell and Scanziani, 2021</xref>; <xref ref-type="bibr" rid="bib41">Priebe and McGee, 2014</xref>). Further work explicating how shared basic mechanisms may ultimately result in rather different patterns of interaction between vision and action will be critical for linking our understanding of cortical function between currently preferred model organisms and across taxonomic orders. The results in this report reflect just the starting point for a larger comparative inquiry.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>We performed electrophysiological recordings in V1 of two common marmosets (one male, ‘marmoset G’, and one female, ‘marmoset B’, both aged 2 years). Both subjects had chronically implanted N-form arrays (Modular Bionics, Modular Bionics, Berkeley, CA) inserted into left V1. Implantations were performed with standard surgical procedures for chronically implanted arrays in primates. Additional recordings were also performed using Neuropixels 1.0 probes (<xref ref-type="bibr" rid="bib25">Jun et al., 2017</xref>) acutely inserted into small craniotomies (procedure described below). All experimental protocols were approved by The University of Texas Institutional Animal Care and Use Committee and in accordance with National Institute of Health standards for care and use of laboratory animals.</p><p>Subjects perched quadrupedally on a 12″ diameter wheel while head-fixed facing a 24″ LCD (BenQ) monitor (resolution = 1920 × 1080 pixels, refresh rate = 120 Hz) corrected to have a linear gamma function, at a distance of 36 cm (pixels per degree = 26.03) in a dark room. Eye position was recorded via an Eyelink 1000 eye tracker (SR Research) sampling at 1 kHz. A syringe pump-operated reward line was used to deliver liquid reward to the subject. Timing events were generated using a Datapixx I/O box (VPixx) for precise temporal registration. All of these systems were integrated in and controlled by MarmoView. Stimuli were generated using MarmoView, custom code based on the PLDAPS (<xref ref-type="bibr" rid="bib15">Eastman and Huk, 2012</xref>) system using Psychophysics Toolbox (<xref ref-type="bibr" rid="bib6">Brainard, 1997</xref>) in MATLAB (MathWorks). For the electrophysiology data gathered from the N-Form arrays, neural responses were recorded using two Intan C3324 headstages attached to the array connectors which sent output to an Open Ephys acquisition board and GUI on a dedicated computer. In electrophysiology data gathered using Neuropixels probes, data was sent through Neuropixels headstages to a Neuropixels PXIe acquisition card within a PXIe chassis (National Instruments). The PXIe chassis sent outputs to a dedicated computer running Open Ephys with an Open Ephys acquisition board additionally attached to record timing events sent from the Datapixx I/O box. Spike sorting on data acquired using N-Form arrays was performed using in-house code to track and merge data from identified single units across multiple recording sessions (<xref ref-type="bibr" rid="bib34">Muthmann et al., 2021</xref>). Spike sorting for data acquired using Neuropixels probes was performed using Kilosort 2.5.</p><sec id="s4-1"><title>Chronic N-Form array recordings</title><p>Chronic array recordings were performed using 64-channel chronically implanted 3D N-Form arrays consisting of 16 shanks arrayed in a 4 × 4 grid with shanks evenly spaced 0.4 mm apart (Modular Bionics, Berkeley). Iridium oxide electrodes are located at 1, 1.125, 1.25, and 1.5 mm (tip) along each shank, forming a 4 × 4 × 4 grid of electrodes. Arrays were chronically inserted into the left dorsal V1 of marmosets G and B at 1.5 and 4° eccentric in the visual field, respectively (confirmed via post hoc spatial RF mapping). Well-isolated single units were detectable on the arrays in excess of 6 months after the initial implantation procedure.</p></sec><sec id="s4-2"><title>Acute Neuropixels recordings</title><p>Acute Neuropixels recordings were performed using standard Neuropixels 1.0 electrodes (IMEC, Leuven, Belgium). Each probe consists of 384 recording channels that can individually be configured to record signals from 960 selectable sites along a 10 mm long, 70 × 24 µm cross-sectional straight shank. Probes were lowered into right dorsal V1 of marmoset G via one of three burr holes spaced irregularly along the AP axis 4–5 mm from the midline for a single session of experiments. Natural images were played to provide visual stimulus as well as occupy the subject and keep them awake during insertion and probe settling. The temporary seal on the burr hole was removed, the intact dura nicked with a thin needle and the burr hole filled with saline. The probe was then lowered through the dural slit at 500 µm/min, allowing 5 min for settling every 1000 µm of total insertion. The whole-probe LFP visualization was monitored during insertion for the characteristic banding of increased LFP amplitude that characterizes cortical tissue. The probe was inserted until this banding was visible on the electrodes nearest the tip of the probe, indicating that the probe tip itself had passed through the dorsal cortex and was within the white matter. The probe was then advanced until a second band became visible on the electrodes nearest the tip, indicating the tip of the probe had exited through the cortex of the calcarine sulcus. The probe was then advanced slightly until the entirety of the second LFP band was visible to ensure that electrodes covered the full depth of the calcarine cortex and the tip of the probe was located confidently within the CSF of the sulcus. The probe was then allowed to settle for 10 min. Active electrode sites on the probe were configured to subtend both dorsal and calcarine cortex simultaneously. Post hoc receptive field recreation confirmed that visually driven, tuned, V1 neurons were recorded at both foveal and peripheral eccentricities.</p></sec><sec id="s4-3"><title>Mouse dataset from Allen Institute</title><p>Mouse data were downloaded from the publicly available Visual Coding database at <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>. We used the same analysis code to analyze these data and the marmoset data we collected.</p></sec><sec id="s4-4"><title>General experimental procedure</title><p>Marmoset recording sessions began with eyetracking calibration. Once calibration was completed, the wheel was unlocked and the subject was allowed to locomote freely, head-fixed, while free-viewing stimuli. Trials for all stimuli were 20 s long with a 500 ms ITI and a 20-s-long natural image interleaved every fifth trial to keep the subject engaged. Stimuli were shown in blocks of 10 min and a typical recording session consisted of 50 trials of calibration followed by one or two blocks of a drifting grating stimulus and one block each of the two mapping stimuli. To elicit sufficiently reliable and frequent running behavior, subjects were rewarded at set locomotion distance intervals unrelated to the stimulus or gaze behavior (typical rewards were 50–70 µL and distance required to achieve a reward usually varied between 20 and 75 cm; reward amounts and intervals were adjusted daily to maximally motivate the subject).</p></sec><sec id="s4-5"><title>Eyetracking calibration</title><p>While the wheel was locked, subjects were allowed to free-view a sequence of patterns of marmoset faces. Marmosets naturally direct their gaze towards the faces of other marmosets when allowed to free-view with little-to-no training, allowing for the experimenter to adjust the calibration offset and gain manually between pattern presentations. Faces were 1.5° in diameter and were presented for 3 s with a 2 s ISI between patterns. A portion of presented patterns were asymmetrical across both the X and Y axes of the screen to allow for disambiguation in the case of axis sign flips in the calibration. Fifty trials were presented before each recording session to verify and refine the calibration. Calibration drift between sessions was minimal, requiring minor (&lt;1°) adjustments over the course of 1–2 months of recordings.</p></sec><sec id="s4-6"><title>Drifting grating stimuli</title><p>The primary stimulus consisted of full-field drifting gratings. Gratings were optimized to drive marmoset V1 with 3 separate spatial frequencies (one, two, and four cycles per degree), 2 drift speeds (1 or 2° per second), and 12 orientations (evenly spaced 30° intervals). Each trial consisted of multiple grating presentations, each with a randomized spatial frequency, drift speed, and orientation. Gratings were displayed for 833 ms followed by a 249–415 ms randomly jittered inter-stimulus interval. After each 20 s trial, there was a longer 500 ms inter-trial interval. Every fifth trial was replaced with a natural image to keep subjects engaged and allow for visual assessment of calibration stability on the experimenter’s display.</p></sec><sec id="s4-7"><title>Mapping of receptive fields</title><p>A spatiotemporal receptive field mapping stimulus, consisting of sparse dot noise, was shown during each recording session. One hundred 1° white and black dots were presented at 50% contrast at random points on the screen. Dots had a lifetime of two frames (16.666 ms). Marmosets freely viewed the stimulus, and we corrected for eye position offline to estimate the spatial receptive fields using forward correlation (<xref ref-type="bibr" rid="bib57">Yates et al., 2021</xref>).</p></sec><sec id="s4-8"><title>Necessary differences between mouse and marmoset experiments</title><p>Although we sought to perform experiments in marmosets that were as similar as possible to mouse experiments, some differences in their visual systems and behavior made for differences. Because the spatial frequency tunings of marmoset and mouse V1 neurons are starkly different, we used stimuli with considerably higher spatial frequencies than in the mouse experiments. Relatedly, marmoset V1 receptive fields are much smaller than in mouse. Because we used full-field stimuli (to match mouse experiments), responses in marmoset V1 were likely affected by substantial amounts of surround suppression, which would reduce overall responses. We also learned that, although the marmosets were comfortable perched on the wheel treadmill, they did not naturally run enough for our experimental purposes. We therefore incorporated a reward scheme to motivate the subjects to run more frequently. Finally, the mouse dataset we analyzed comprised a large number of mice with a small number of sessions per mouse; as is required of work with nonhuman primates, we were limited to a smaller number of subjects (N = 2) and ran many experimental sessions with each animal.</p></sec><sec id="s4-9"><title>Session and cell inclusion criteria</title><p>For the analyses shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>, sessions were included if they contained more than 250 trials and a proportion of trials running was not less than 10% or greater than 90%. For the mouse dataset, this yielded 25/32 sessions. For the marmoset dataset, this yielded 27/34 sessions. For the unit-wise analyses in <xref ref-type="fig" rid="fig3">Figure 3</xref>, super-sessioned units were included for analysis if they had more than 300 trials of data and a mean firing rate of &gt;1 spike/s. This yielded 1168/2015 units in mouse and 786/1837 units in marmoset.</p><p>For the analyses shown in <xref ref-type="fig" rid="fig4">Figure 4</xref>, sessions were included using the same trial and running criterion as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Only units that were well fit by the stimulus + slow drift model (i.e., cross-validated better than the null, see ‘Shared modulator model’) were included and sessions were excluded if fewer than 10 units met this criterion. This resulted in 31/32 sessions for mouse and 28/34 sessions for marmoset.</p></sec><sec id="s4-10"><title>Analysis of tuning</title><p>We counted spikes between the 50 ms after grating onset and 50 ms after grating offset and divided by the interval to generate a trial spike rate. To calculate orientation tuning curves, we computed the mean firing rate of each orientation and spatial frequency. Because we were limited by the animal’s behavior to determine the number of trials in each condition (i.e., running or not), we computed orientation tuning as a weighted average across spatial frequencies with weights set by the spatial frequency tuning. We used these resulting curves for all analyses of tuning. We confirmed that the results did not change qualitatively if we either used only the best spatial frequency or marginalized across spatial frequency.</p><p>Orientation selectivity index was calculated using the following equation:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">O</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msqrt><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mrow><mml:mo>∑</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf19"><mml:mi>θ</mml:mi></mml:math></inline-formula> is the orientation and <inline-formula><mml:math id="inf20"><mml:mi>r</mml:mi></mml:math></inline-formula> is the baseline-subtracted vector of rates across orientations.</p></sec><sec id="s4-11"><title>Analysis of eye movement effects on neural response</title><p>To assess whether and how eye movements might differ between running and stationary periods (and perhaps account for some or all of the running-correlated modulations of V1 response), we started by counting the number of saccades within a bin corresponding to each stimulus presentation (from 0.2 s before stimulus onset to 0.1 after offset), as well as calculating the average saccade size (vector magnitude) of those saccades. We then regressed these terms against the spike count in each bin, allowing us to estimate the effect of eye movements in units of spike rate (Hz). (We also analyzed the variance of the eye position signal and got similar results.) For the analysis of pupil size, we used the values returned by our Eyelink eyetracker, averaged in the same bins as for the saccade analyses.</p></sec><sec id="s4-12"><title>Shared modulator model</title><p>To capture shared modulator signals in an unsupervised manner, we fit our neural populations with a latent variable model (<xref ref-type="bibr" rid="bib54">Whiteway and Butts, 2019</xref>). The goal of our latent variable model was to summarize population activity with low-dimensional shared signal that operates as a gain on the stimulus processing (e.g., <xref ref-type="bibr" rid="bib21">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Lin et al., 2015</xref>). In this model, the response of an individual neuron, <inline-formula><mml:math id="inf21"><mml:msub><mml:mi>𝐫</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> on trial <italic>t</italic> is given by<disp-formula id="equ2"><label>(1)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where the stimulus response <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is given by the tuning curve, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a neuron-specific gain on the stimulus response, and <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the baseline firing rate. Similar models have been employed to describe the population response in V1 in several species (<xref ref-type="bibr" rid="bib21">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Lin et al., 2015</xref>; <xref ref-type="bibr" rid="bib1">Arandia-Romero et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">Whiteway et al., 2019</xref>).</p><p>Because the gain signal is shared across neurons, we fit this model to all <inline-formula><mml:math id="inf25"><mml:mi>n</mml:mi></mml:math></inline-formula> neurons in a given recording at the same time. To capture the stimulus tuning curves, we represented the stimulus on each trial <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> as an <italic>m</italic>-dimensional ‘one-hot’ vector, where <inline-formula><mml:math id="inf27"><mml:mi>m</mml:mi></mml:math></inline-formula> is the number of possible conditions (Orientation × Spatial Frequency) and on each trial all elements are zero, except for the condition shown. Thus, <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>f</mml:mi><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mi>s</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> becomes a linear projection of the stimulus on the tuning curves, <inline-formula><mml:math id="inf29"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf30"><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:math></inline-formula> is an <inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> matrix of tuning weights. We decomposed the gain for each neuron on each trial into a rank 1 matrix that was rectified and offset by one, <inline-formula><mml:math id="inf32"><mml:mrow><mml:mi>g</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">z</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow></mml:mrow><mml:mo form="postfix" stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf33"><mml:mi>w</mml:mi></mml:math></inline-formula> is an <italic>n</italic>-dimensional vector of loadings that map the one-dimensional trial latent <inline-formula><mml:math id="inf34"><mml:mrow><mml:mi>z</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to a population-level signal, <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>z</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mi>𝐰</mml:mi></mml:mrow></mml:math></inline-formula>. This signal is offset by 1 and rectified such that it is always positive and a loading weight of zero equals a gain of 1.0.</p><p>To capture any unit-specific slow drifts in firing rate, we further parameterized <inline-formula><mml:math id="inf36"><mml:mi>𝐛</mml:mi></mml:math></inline-formula> as a linear combination of five b0-splines evenly spaced across the experiment (<xref ref-type="bibr" rid="bib42">Quinn et al., 2021</xref>). Thus, the baseline firing rate for each neuron, <inline-formula><mml:math id="inf37"><mml:mi>i</mml:mi></mml:math></inline-formula>, was a linear combination of five ‘tent’ basis functions spaced evenly across the experiment, <inline-formula><mml:math id="inf38"><mml:mrow><mml:msub><mml:mi>𝐛</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mi>j</mml:mi></mml:munder></mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p><p>Thus, the full model describes the population response as<disp-formula id="equ3"><label>(2)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">L</mml:mi><mml:mi mathvariant="normal">U</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The parameters of the model are the stimulus tuning parameters <inline-formula><mml:math id="inf39"><mml:mi>𝐀</mml:mi></mml:math></inline-formula>, the shared gain, <inline-formula><mml:math id="inf40"><mml:mi>z</mml:mi></mml:math></inline-formula>, the gain loadings, <inline-formula><mml:math id="inf41"><mml:mi>𝐰</mml:mi></mml:math></inline-formula>, and the ‘tent’ basis weights, <inline-formula><mml:math id="inf42"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>’s.</p><p>We first fit a baseline model with only stimulus and baseline parameters<disp-formula id="equ4"><label>(3)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Following <xref ref-type="bibr" rid="bib53">Whiteway and Butts, 2017</xref>, we initialized <inline-formula><mml:math id="inf43"><mml:mi>𝐀</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf44"><mml:mi>𝐛</mml:mi></mml:math></inline-formula> using fits from a model without latent variables and initialized the latent variable, <inline-formula><mml:math id="inf45"><mml:mi>z</mml:mi></mml:math></inline-formula>, and loadings, <inline-formula><mml:math id="inf46"><mml:mi>𝐰</mml:mi></mml:math></inline-formula>, using an Autoencoder (<xref ref-type="bibr" rid="bib3">Bengio et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Whiteway and Butts, 2017</xref>). We then fit the gain, loadings, and stimulus parameters using iterative optimization with L-BFGS, by minimizing the mean squared error (MSE) between the observed spikes and the model rates. The model parameters were regularized with a modest amount of L2-penalty and the amount was set using cross-validation on the training set. The latent variables were penalized with a small squared derivative penalty to impose some smoothness across trials. This was set to be small and the same value across all sessions. We reverted the model to the autoencoder initialization if the MSE on a validation set did not improve during fitting.</p><p>We cross-validated the model using a speckled holdout pattern (<xref ref-type="bibr" rid="bib56">Williams et al., 2018</xref>) whereby some fraction of neurons were withheld on each trial with probability p=0.25. We further divided the withheld data into a validation set and a test set by randomly assigning units to either group on each trial with probability 0.5. The validation loss was used to stop the optimization during the iterative fitting and the test set was used to evaluate the models.</p></sec><sec id="s4-13"><title>Sign of latent variables</title><p>We anchored the sign of all latent variables to the average firing rate of the population, such that positive means increases in the average firing rate. In general, for both the principal components analysis (<xref ref-type="fig" rid="fig2">Figure 2</xref>) and the shared population modulation model (<xref ref-type="fig" rid="fig4">Figure 4</xref>), the sign of the latent variable is arbitrary and only becomes a signed effect once multiplied by the loading weight for each unit. Thus, to interpret these values, we used the loadings to flip the sign of the latent to be positive for increases in the average firing rate. Specifically, we took the largest eigenvector, <inline-formula><mml:math id="inf47"><mml:mi>u</mml:mi></mml:math></inline-formula>, of the covariance matrix across neurons and modified the sign such that the average sign was positive: <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>𝐮</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐮</mml:mi><mml:mo>×</mml:mo><mml:mrow><mml:mtext/><mml:mi>sign</mml:mi></mml:mrow><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">(</mml:mo><mml:mrow><mml:munder><mml:mo stretchy="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder></mml:mrow><mml:mrow><mml:mtext/><mml:mi>sign</mml:mi></mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>𝐮</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo fence="false" symmetric="true" minsize="1.2em" maxsize="1.2em">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is 1 for <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and –1 for <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. We then projected the mean-subtracted firing rates on (the sign-corrected) <inline-formula><mml:math id="inf52"><mml:mi>u</mml:mi></mml:math></inline-formula>. This gives a ‘1st PC’ with an interpretable sign. For analyses of shared gain (<xref ref-type="fig" rid="fig4">Figure 4</xref>), we projected back to the population space and then averaged the per-unit gain.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocols at The University of Texas at Austin and the University of California, Los Angeles (IACUC approval: UCLA, ARC-2022-085). All surgery was performed under anesthesia, and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-87736-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Analysis code and associated (processed) data are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/jcbyts/V1Locomotion">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib58">Yates, 2024</xref>). That public repository contains links to the individual data files (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.26508136.v1">https://doi.org/10.6084/m9.figshare.26508136.v1</ext-link>). Raw data files are very large and are available upon request to either of the co-senior authors (JLY, ACH). Finally, we made use of Allen Institute data that was publicly available (<ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/circuits-behavior/visual-coding-neuropixels">https://portal.brain-map.org/circuits-behavior/visual-coding-neuropixels</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Rowley</surname><given-names>DP</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Marmoset Visual Cortex Preprocessed Treadmill Data Combined Supersessions</data-title><source>figshare</source><pub-id pub-id-type="doi">10.6084/m9.figshare.26508136.v1</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Allison Laudano for animal and colony management and care, Christopher Badillo for apparatus design and fabrication, and Nika Hazen for assistance with animal work. Cris Niell, Cory Miller, Jude Mitchell, and Anne Churchland all provided valuable feedback on drafts of this paper. We thank the Visual Coding team at the Allen Institute for sharing the mouse data used in this paper (<ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arandia-Romero</surname><given-names>I</given-names></name><name><surname>Tanabe</surname><given-names>S</given-names></name><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multiplicative and additive modulation of neuronal tuning with population activity affects encoded information</article-title><source>Neuron</source><volume>89</volume><fpage>1305</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.01.044</pub-id><pub-id pub-id-type="pmid">26924437</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayaz</surname><given-names>A</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Schölvinck</surname><given-names>ML</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Locomotion controls spatial integration in mouse visual cortex</article-title><source>Current Biology</source><volume>23</volume><fpage>890</fpage><lpage>894</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.04.012</pub-id><pub-id pub-id-type="pmid">23664971</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Vincent</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representation learning: a review and new perspectives</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>35</volume><fpage>1798</fpage><lpage>1828</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2013.50</pub-id><pub-id pub-id-type="pmid">23787338</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamin</surname><given-names>AV</given-names></name><name><surname>Wailes-Newson</surname><given-names>K</given-names></name><name><surname>Ma-Wyatt</surname><given-names>A</given-names></name><name><surname>Baker</surname><given-names>DH</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The effect of locomotion on early visual contrast processing in humans</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>3050</fpage><lpage>3059</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1428-17.2017</pub-id><pub-id pub-id-type="pmid">29463642</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennett</surname><given-names>C</given-names></name><name><surname>Arroyo</surname><given-names>S</given-names></name><name><surname>Hestrin</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Subthreshold mechanisms underlying state-dependent modulation of visual responses</article-title><source>Neuron</source><volume>80</volume><fpage>350</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.007</pub-id><pub-id pub-id-type="pmid">24139040</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Haendel</surname><given-names>BF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Overground walking decreases alpha activity and entrains eye movements in humans</article-title><source>Frontiers in Human Neuroscience</source><volume>14</volume><elocation-id>561755</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2020.561755</pub-id><pub-id pub-id-type="pmid">33414709</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Cao</surname><given-names>L</given-names></name><name><surname>Haendel</surname><given-names>BF</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Differential effects of walking across visual cortical processing stages</article-title><source>Cortex</source><volume>149</volume><fpage>16</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2022.01.007</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>AJ</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Reduced neural activity but improved coding in rodent higher-order visual cortex during locomotion</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>1676</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-29200-z</pub-id><pub-id pub-id-type="pmid">35354804</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1594</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1038/nn.2439</pub-id><pub-id pub-id-type="pmid">19915566</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coppola</surname><given-names>JJ</given-names></name><name><surname>Disney</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Is there a canonical cortical circuit for the cholinergic system? anatomical differences across common model systems</article-title><source>Frontiers in Neural Circuits</source><volume>12</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2018.00008</pub-id><pub-id pub-id-type="pmid">29440996</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dipoppa</surname><given-names>M</given-names></name><name><surname>Ranson</surname><given-names>A</given-names></name><name><surname>Krumin</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vision and locomotion shape the interactions between neuron types in mouse visual cortex</article-title><source>Neuron</source><volume>98</volume><fpage>602</fpage><lpage>615</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.037</pub-id><pub-id pub-id-type="pmid">29656873</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Disney</surname><given-names>AA</given-names></name><name><surname>Aoki</surname><given-names>C</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Gain modulation by nicotine in macaque V1</article-title><source>Neuron</source><volume>56</volume><fpage>701</fpage><lpage>713</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.09.034</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Disney</surname><given-names>AA</given-names></name><name><surname>Robert</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Translational implications of the anatomical nonequivalence of functionally equivalent cholinergic circuit motifs</article-title><source>PNAS</source><volume>116</volume><fpage>26181</fpage><lpage>26186</lpage><pub-id pub-id-type="doi">10.1073/pnas.1902280116</pub-id><pub-id pub-id-type="pmid">31871174</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eastman</surname><given-names>KM</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>PLDAPS: a hardware architecture and software toolbox for neurophysiology requiring complex visual stimuli and online behavioral control</article-title><source>Frontiers in Neuroinformatics</source><volume>6</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2012.00001</pub-id><pub-id pub-id-type="pmid">22319490</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erisken</surname><given-names>S</given-names></name><name><surname>Vaiceliunaite</surname><given-names>A</given-names></name><name><surname>Jurjut</surname><given-names>O</given-names></name><name><surname>Fiorini</surname><given-names>M</given-names></name><name><surname>Katzner</surname><given-names>S</given-names></name><name><surname>Busse</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Effects of locomotion extend throughout the mouse early visual system</article-title><source>Current Biology</source><volume>24</volume><fpage>2899</fpage><lpage>2907</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.10.045</pub-id><pub-id pub-id-type="pmid">25484299</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname><given-names>DJ</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title><source>Cerebral Cortex</source><volume>1</volume><fpage>1</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1093/cercor/1.1.1-a</pub-id><pub-id pub-id-type="pmid">1822724</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferguson</surname><given-names>KA</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Mechanisms underlying gain modulation in the cortex</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>80</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0253-y</pub-id><pub-id pub-id-type="pmid">31911627</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Y</given-names></name><name><surname>Tucciarone</surname><given-names>JM</given-names></name><name><surname>Espinosa</surname><given-names>JS</given-names></name><name><surname>Sheng</surname><given-names>N</given-names></name><name><surname>Darcy</surname><given-names>DP</given-names></name><name><surname>Nicoll</surname><given-names>RA</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A cortical circuit for gain control by behavioral state</article-title><source>Cell</source><volume>156</volume><fpage>1139</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.01.050</pub-id><pub-id pub-id-type="pmid">24630718</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname><given-names>ME</given-names></name><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Marshel</surname><given-names>JH</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topography and areal organization of mouse visual cortex</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>12587</fpage><lpage>12600</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1124-14.2014</pub-id><pub-id pub-id-type="pmid">25209296</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goris</surname><given-names>RLT</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Partitioning neuronal variability</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>858</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1038/nn.3711</pub-id><pub-id pub-id-type="pmid">24777419</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Nonsense correlations in neuroscience</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.11.29.402719</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horrocks</surname><given-names>EAB</given-names></name><name><surname>Mareschal</surname><given-names>I</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Walking humans and running mice: perception and neural encoding of optic flow during self-motion</article-title><source>Philos Trans R Soc Lond B Biol Sci</source><volume>378</volume><elocation-id>20210450</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2021.0450</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoy</surname><given-names>JL</given-names></name><name><surname>Yavorska</surname><given-names>I</given-names></name><name><surname>Wehr</surname><given-names>M</given-names></name><name><surname>Niell</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Vision drives accurate approach behavior during prey capture in laboratory mice</article-title><source>Current Biology</source><volume>26</volume><fpage>3046</fpage><lpage>3052</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.09.009</pub-id><pub-id pub-id-type="pmid">27773567</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Barbarits</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Andrei</surname><given-names>A</given-names></name><name><surname>Aydın</surname><given-names>Ç</given-names></name><name><surname>Barbic</surname><given-names>M</given-names></name><name><surname>Blanche</surname><given-names>TJ</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Couto</surname><given-names>J</given-names></name><name><surname>Dutta</surname><given-names>B</given-names></name><name><surname>Gratiy</surname><given-names>SL</given-names></name><name><surname>Gutnisky</surname><given-names>DA</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Lopez</surname><given-names>CM</given-names></name><name><surname>Mitelut</surname><given-names>C</given-names></name><name><surname>Musa</surname><given-names>S</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Putzeys</surname><given-names>J</given-names></name><name><surname>Rich</surname><given-names>PD</given-names></name><name><surname>Rossant</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>W-L</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><volume>551</volume><fpage>232</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/nature24636</pub-id><pub-id pub-id-type="pmid">29120427</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname><given-names>GB</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sensorimotor mismatch signals in primary visual cortex of the behaving mouse</article-title><source>Neuron</source><volume>74</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.040</pub-id><pub-id pub-id-type="pmid">22681686</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Land</surname><given-names>MF</given-names></name><name><surname>Fernald</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The evolution of eyes</article-title><source>Annual Review of Neuroscience</source><volume>15</volume><fpage>1</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.15.030192.000245</pub-id><pub-id pub-id-type="pmid">1575438</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AM</given-names></name><name><surname>Hoy</surname><given-names>JL</given-names></name><name><surname>Bonci</surname><given-names>A</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name><name><surname>Niell</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Identification of a brainstem circuit regulating visual cortical state in parallel with locomotion</article-title><source>Neuron</source><volume>83</volume><fpage>455</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.06.031</pub-id><pub-id pub-id-type="pmid">25033185</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lien</surname><given-names>AD</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Tuned thalamic excitation is amplified by visual cortical circuits</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1315</fpage><lpage>1323</lpage><pub-id pub-id-type="doi">10.1038/nn.3488</pub-id><pub-id pub-id-type="pmid">23933748</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>IC</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The nature of shared cortical variability</article-title><source>Neuron</source><volume>87</volume><fpage>644</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.035</pub-id><pub-id pub-id-type="pmid">26212710</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mineault</surname><given-names>PJ</given-names></name><name><surname>Tring</surname><given-names>E</given-names></name><name><surname>Trachtenberg</surname><given-names>JT</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Enhanced spatial resolution during locomotion and heightened attention in mouse primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>6382</fpage><lpage>6392</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0430-16.2016</pub-id><pub-id pub-id-type="pmid">27307228</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>JF</given-names></name><name><surname>Sundberg</surname><given-names>KA</given-names></name><name><surname>Reynolds</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial attention decorrelates intrinsic activity fluctuations in macaque area V4</article-title><source>Neuron</source><volume>63</volume><fpage>879</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.013</pub-id><pub-id pub-id-type="pmid">19778515</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Muthmann</surname><given-names>JO</given-names></name><name><surname>Levi</surname><given-names>AJ</given-names></name><name><surname>Carney</surname><given-names>HC</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A Hardware/Software System for Electrophysiology “Supersessions” in Marmosets</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.08.09.243279</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>How cortical circuits implement cortical computations: mouse visual cortex as a model</article-title><source>Annual Review of Neuroscience</source><volume>44</volume><fpage>517</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-102320-085825</pub-id><pub-id pub-id-type="pmid">33914591</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pakan</surname><given-names>JM</given-names></name><name><surname>Lowe</surname><given-names>SC</given-names></name><name><surname>Dylda</surname><given-names>E</given-names></name><name><surname>Keemink</surname><given-names>SW</given-names></name><name><surname>Currie</surname><given-names>SP</given-names></name><name><surname>Coutts</surname><given-names>CA</given-names></name><name><surname>Rochefort</surname><given-names>NL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Behavioral-state modulation of inhibition is context-dependent and cell type specific in mouse visual cortex</article-title><source>eLife</source><volume>5</volume><elocation-id>e14985</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.14985</pub-id><pub-id pub-id-type="pmid">27552056</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeffer</surname><given-names>CK</given-names></name><name><surname>Xue</surname><given-names>M</given-names></name><name><surname>He</surname><given-names>M</given-names></name><name><surname>Huang</surname><given-names>ZJ</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inhibition of inhibition in visual cortex: the logic of connections between molecularly distinct interneurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1068</fpage><lpage>1076</lpage><pub-id pub-id-type="doi">10.1038/nn.3446</pub-id><pub-id pub-id-type="pmid">23817549</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polack</surname><given-names>PO</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular mechanisms of brain state-dependent gain modulation in visual cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1331</fpage><lpage>1339</lpage><pub-id pub-id-type="doi">10.1038/nn.3464</pub-id><pub-id pub-id-type="pmid">23872595</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>McGee</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mouse vision as a gateway for understanding how experience shapes neural circuits</article-title><source>Frontiers in Neural Circuits</source><volume>8</volume><elocation-id>123</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2014.00123</pub-id><pub-id pub-id-type="pmid">25324730</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quinn</surname><given-names>KR</given-names></name><name><surname>Seillier</surname><given-names>L</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Nienborg</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Decision-related feedback in visual cortex lacks spatial selectivity</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4473</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24629-0</pub-id><pub-id pub-id-type="pmid">34294703</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rabinowitz</surname><given-names>NC</given-names></name><name><surname>Goris</surname><given-names>RL</given-names></name><name><surname>Cohen</surname><given-names>M</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Attention stabilizes the shared gain of V4 populations</article-title><source>eLife</source><volume>4</volume><elocation-id>e08998</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08998</pub-id><pub-id pub-id-type="pmid">26523390</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Yatsenko</surname><given-names>D</given-names></name><name><surname>Denfield</surname><given-names>GH</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil fluctuations track fast switching of cortical states during quiet wakefulness</article-title><source>Neuron</source><volume>84</volume><fpage>355</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.033</pub-id><pub-id pub-id-type="pmid">25374359</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Krubitzer</surname><given-names>LA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The evolution of visual cortex: where is V2?</article-title><source>Trends in Neurosciences</source><volume>22</volume><fpage>242</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/s0166-2236(99)01398-3</pub-id><pub-id pub-id-type="pmid">10354599</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Ayaz</surname><given-names>A</given-names></name><name><surname>Jeffery</surname><given-names>KJ</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Integration of visual motion and locomotion in mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1864</fpage><lpage>1869</lpage><pub-id pub-id-type="doi">10.1038/nn.3567</pub-id><pub-id pub-id-type="pmid">24185423</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scholl</surname><given-names>B</given-names></name><name><surname>Tan</surname><given-names>AYY</given-names></name><name><surname>Corey</surname><given-names>J</given-names></name><name><surname>Priebe</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Emergence of orientation selectivity in the Mammalian visual pathway</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>10616</fpage><lpage>10624</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0404-13.2013</pub-id><pub-id pub-id-type="pmid">23804085</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengpiel</surname><given-names>F</given-names></name><name><surname>Troilo</surname><given-names>D</given-names></name><name><surname>Kind</surname><given-names>PC</given-names></name><name><surname>Graham</surname><given-names>B</given-names></name><name><surname>Blakemore</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Functional architecture of area 17 in normal and monocularly deprived marmosets (Callithrix jacchus)</article-title><source>Visual Neuroscience</source><volume>13</volume><fpage>145</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1017/s0952523800007197</pub-id><pub-id pub-id-type="pmid">8730996</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>255</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talluri</surname><given-names>BC</given-names></name><name><surname>Kang</surname><given-names>I</given-names></name><name><surname>Lazere</surname><given-names>A</given-names></name><name><surname>Quinn</surname><given-names>KR</given-names></name><name><surname>Kaliss</surname><given-names>N</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Nienborg</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Activity in primate visual cortex is minimally driven by spontaneous movements</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>1953</fpage><lpage>1959</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01459-5</pub-id><pub-id pub-id-type="pmid">37828227</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id><pub-id pub-id-type="pmid">25892300</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Hou</surname><given-names>Y</given-names></name><name><surname>Magrou</surname><given-names>L</given-names></name><name><surname>Autio</surname><given-names>JA</given-names></name><name><surname>Misery</surname><given-names>P</given-names></name><name><surname>Coalson</surname><given-names>T</given-names></name><name><surname>Reid</surname><given-names>E</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Lamy</surname><given-names>C</given-names></name><name><surname>Falchier</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Poo</surname><given-names>MM</given-names></name><name><surname>Dehay</surname><given-names>C</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Hayashi</surname><given-names>T</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Van Essen</surname><given-names>D</given-names></name><name><surname>Shen</surname><given-names>Z</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Retinotopic organization of feedback projections in primate early visual cortex: implications for active vision</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.04.27.489651</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whiteway</surname><given-names>MR</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Revealing unobserved factors underlying cortical activity with a rectified latent variable model applied to neural population recordings</article-title><source>Journal of Neurophysiology</source><volume>117</volume><fpage>919</fpage><lpage>936</lpage><pub-id pub-id-type="doi">10.1152/jn.00698.2016</pub-id><pub-id pub-id-type="pmid">27927786</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whiteway</surname><given-names>MR</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The quest for interpretable models of neural population activity</article-title><source>Current Opinion in Neurobiology</source><volume>58</volume><fpage>86</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.07.004</pub-id><pub-id pub-id-type="pmid">31426024</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Whiteway</surname><given-names>MR</given-names></name><name><surname>Socha</surname><given-names>K</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Characterizing the Nonlinear Structure of Shared Variability in Cortical Neuron Populations Using Latent Variable Models</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/pdf/1801.08881v5.pdf">https://arxiv.org/pdf/1801.08881v5.pdf</ext-link></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>AH</given-names></name><name><surname>Kim</surname><given-names>TH</given-names></name><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Schnitzer</surname><given-names>M</given-names></name><name><surname>Kolda</surname><given-names>TG</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Unsupervised discovery of demixed, low-dimensional neural dynamics across multiple timescales through tensor component analysis</article-title><source>Neuron</source><volume>98</volume><fpage>1099</fpage><lpage>1115</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.05.015</pub-id><pub-id pub-id-type="pmid">29887338</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Coop</surname><given-names>SH</given-names></name><name><surname>Sarch</surname><given-names>GH</given-names></name><name><surname>Wu</surname><given-names>RJ</given-names></name><name><surname>Butts</surname><given-names>DA</given-names></name><name><surname>Rucci</surname><given-names>M</given-names></name><name><surname>Mitchell</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Beyond fixation: detailed characterization of neural selectivity in free-viewing primates</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.11.06.467566</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Yates</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>V1Locomotion</data-title><version designator="swh:1:rev:79fd7b55f431c2a249b529c3ab12c3da9eb38003">swh:1:rev:79fd7b55f431c2a249b529c3ab12c3da9eb38003</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d4c3ba4f9936c6f5ad30f28ce5b01a9a2aa2bd1b;origin=https://github.com/jcbyts/V1Locomotion;visit=swh:1:snp:1516a48b799c36b85e54bee45244a55125d1a2d6;anchor=swh:1:rev:79fd7b55f431c2a249b529c3ab12c3da9eb38003">https://archive.softwareheritage.org/swh:1:dir:d4c3ba4f9936c6f5ad30f28ce5b01a9a2aa2bd1b;origin=https://github.com/jcbyts/V1Locomotion;visit=swh:1:snp:1516a48b799c36b85e54bee45244a55125d1a2d6;anchor=swh:1:rev:79fd7b55f431c2a249b529c3ab12c3da9eb38003</ext-link></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yilmaz</surname><given-names>M</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rapid innate defensive responses of mice to looming visual stimuli</article-title><source>Current Biology</source><volume>23</volume><fpage>2011</fpage><lpage>2015</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.08.015</pub-id><pub-id pub-id-type="pmid">24120636</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>HH</given-names></name><name><surname>Rosa</surname><given-names>MGP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Uniformity and diversity of response properties of neurons in the primary visual cortex: selectivity for orientation, direction of motion, and stimulus size from center to far periphery</article-title><source>Visual Neuroscience</source><volume>31</volume><fpage>85</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1017/S0952523813000448</pub-id><pub-id pub-id-type="pmid">24160942</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87736.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Otto-von-Guericke University Magdeburg</institution><country>Germany</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This <bold>important</bold> work advances our understanding of the differences in locomotion-induced modulation in primate and rodent visual cortexes and underlines the significant contribution cross-species comparisons make to investigating brain function. The evidence in support of these differences across species is <bold>convincing</bold>. This work will be of broad interest to neuroscientists.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87736.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>More than ten years ago, it was shown that activity in the primary visual cortex of mice substantially increases when mice are running compared to when they are sitting still. This finding 'revolutionised' our thinking about visual cortex, turning away from it being a passive image processor and highlighting the influence of non-visual factors. The current study now for the first time repeats this experiment in marmosets. The authors find that in contrast to mice, marmoset V1 activity is slightly suppressed during running, and they relate this to differences in gain modulations of V1 activity between the two species.</p><p>Strengths</p><p>- Replication in primates of the original finding in mice partly took so long, because of the inherent difficulties with recording from the brain of a running primate. In fact one recent, highly related study on macaques looked at spontaneous limb movements as the macaque was sitting. The treadmill for the marmosets in the current study is a very elegant solution to the problem of running in primates. It allows for true replication of the 'running vs stationary' experiment and undoubtedly opens up many possibilities for other experiments recording from a head-fixed but active marmoset.</p><p>- In addition to their own data in marmoset, the authors run their analyses on a publicly available data set in mouse. This allows them to directly compare mouse and marmoset findings, which significantly strengthens their conclusions.</p><p>- Marmoset vision is fundamentally different from mouse vision as they have a fovea and make goal-directed eye movements. In this revised version of their paper, the authors acknowledge this and investigate the possible effect of eye movements and pupil size on the differences they find between running and stationary. They conclude that eye input does not explain all these differences.</p><p>Significance</p><p>The paper provides interesting new evidence to the ongoing discussion about the influence of non-visual factors in general, and running in particular, on visual cortex activity. As such, it helps to pull this discussion out of the rodent field mainly and into the field of primate research. The bigger question of *why* there are differences between rodents and primates remains still unanswered, but the authors do their best to provide possible explanations. The elegant experimental set-up of the marmoset on a treadmill will certainly add new findings to this issue also in the years to come.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87736.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This work aims at answering whether activity in primate visual cortex is modulated by locomotion, as was reported for mouse visual cortex. The finding that the activity in mouse visual cortex is modulated by running has changed the concept of primary sensory cortical areas. However, it was an open question whether this modulation generalizes to primates.</p><p>To answer this fundamental question the authors established a novel paradigm in which a head-fixed marmoset was able to run on a treadmill while watching a visual stimulus on a display. In addition, eye movements and running speed were monitored continuously and extracellular neuronal activity in primary visual cortex recorded using high-channel-count electrode arrays. This paradigm uniquely permitted to investigate whether locomotion modulates sensory evoked activity in visual cortex of marmoset. Moreover, to directly compare the responses in marmoset visual cortex to responses in mouse visual cortex the authors made use of a publicly-available mouse dataset from the Allen Institute. In this dataset the mouse was also running on a treadmill and observing a set of visual stimuli on a display. The authors took extra care to have the marmoset and mouse paradigms as comparable as possible.</p><p>To characterize the visually driven activity the authors present a series of moving gratings and estimate receptive fields with sparse noise. To estimate the gain modulation by running the authors split the dataset into epochs of running and non-running which allowed them to estimate the visually evoked firing rates in both behavioral states.</p><p>Strengths:</p><p>The novel paradigm of head-fixed marmosets running on a treadmill while being presented with a visual stimulus is unique and ideally tailored to answering the question that the authors aimed to answer. Moreover, the authors took extra care to ensure that the paradigm in marmoset matched as closely as possible to the conditions in the mouse experiments such that the results can be directly compared. To directly compare their data the authors re-analyzed publicly available data from visual cortex of mice recorded at the Allen Institute. Such a direct comparison, and reuse of existing datasets, is another strong aspect of the work. Finally, the presented new marmoset dataset appears to be of high quality, the comparison between mouse and marmoset visual cortex is well done and the results and interpretation straightforward.</p><p>Weaknesses:</p><p>It is known that the locomotion gain modulation varies with layer in mouse visual cortex, with neurons in the infragranular layers expressing a diversity of modulations (Erisken et al. 2014 Current Biology). However, for the marmoset dataset the layer information was unfortunately not recorded, leaving this point open for future studies.</p><p>Nonetheless, the aim of comparing the locomotion induced modulation of activity in primate and mouse primary visual cortex was convincingly achieved by the authors. The results shown in the figures support the conclusion that locomotion modulates the activity in primate and mouse visual cortex differently. While mice show a profound gain increase, neurons in primate visual cortex show little modulation or even a reduction in response strength.</p><p>This work will have a strong impact on the field of visual neuroscience but also on neuroscience in general. It revives the debate of whether results obtained in the mouse model system can be simply generalized to other mammalian model systems, such as non-human primates. Based on the presented results, the comparison between the mouse and primate visual cortex is not as straightforward as previously assumed. This will likely trigger more comparative studies between mice and primates in the future, which is important and absolutely needed to advance our understanding of the mammalian brain.</p><p>Moreover, the reported finding that neurons in primary visual cortex of marmosets do not increase their activity during running is intriguing, as it makes you wonder why neurons in the mouse visual cortex do so. The authors discuss a few ideas in the paper which can be addressed in future experiments. In this regard it is worth noting that the authors report an interesting difference between the foveal and peripheral part of the visual cortex in marmoset. It will be interesting to investigate these differences in more detail in future studies. Likewise, while running might be an important behavioral state for mice, other behavioral states might be more relevant for marmosets and do modulate the activity of primate visual cortex more profoundly. Future work could leverage the opportunities that the marmoset model system offers to reveal new insights about behavioral related modulation in the primate brain.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87736.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Prior studies have shown that locomotion (e.g., running) modulates mouse V1 activity to a similar extent as visual stimuli. However, it's unclear if these findings hold in species with more specialized and advanced visual systems such as nonhuman primates. In this work, Liska et al. leverage population and single neuron analyses to investigate potential differences and similarities in how running modulates V1 activity in marmosets and mice. Specifically, they discovered that although a shared gain model could describe well the trial-to-trial variations of population-level neural activity for both species, locomotion more strongly modulated V1 population activity in mice. Furthermore, they found that at the level of individual units, marmoset V1 neurons, unlike mice V1 neurons, experience suppression of their activity during running.</p><p>A major strength of this work is the introduction and completion of primate electrophysiology recordings during locomotion. Data of this kind were previously limited, and this work moves the field forward in terms of data collection in a domain previously inaccessible in primates. Another core strength of this work is that it adds to a limited collection of cross-species data collection and analysis of neural activity at the single-unit and population level, attempting to standardize analysis and data collection to be able to make inferences across species. In particular, the findings on how the primate peripheral and foveal V1 representations functionally relate to and differ from the mice V1 representations speak to the power of these cross-species comparisons.</p><p>However, there are still some lingering potential extensions to this work, largely acknowledged by the authors. One of these extensions involves more detailed eye movement analysis within species, such as microsaccades in marmosets and the potential impact on marmoset V1 activity. In the mouse data, similar eye-related analyses were not possible, in part due to instability in the eye recordings of many mouse sessions that made it challenging to replicate partnered analyses for the marmosets. We agree with the authors' assessment that these analyses can be targeted in future work and still believe that the marmoset eye-movement findings provide novel insights that will inform future cross-species comparisons of the visual system. Furthermore, another important issue not fully explored is the possible effects of the reward scheme during marmoset locomotion on V1 activity. The authors note that, unlike their mice counterparts, the marmosets were encouraged to run via liquid rewards, given after subjects traversed a specific distance. While the authors discuss the changes in arousal present when marmosets were running, there are still some unanswered questions on how their reward scheme may affect biomarkers (e.g., pupil sizes) and marmoset V1 activity.</p><p>Overall, the methods and data support the work's main claims. Single neuron and population level approaches demonstrate that the activity of V1 in mice and marmoset are categorically different. Since primate V1 is so diverse and differs from mouse V1, this presents important limitations on direct inferences from mouse V1 to primate V1. This work is a great step forward in the field, especially with the novel methodology of collecting neural activity from running primates.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87736.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Liska</surname><given-names>John P</given-names></name><role specific-use="author">Author</role><aff><institution>University of Maryland, College Park</institution><addr-line><named-content content-type="city">College Park</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Rowley</surname><given-names>Declan P</given-names></name><role specific-use="author">Author</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>University of California, Los Angeles</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Nguyen</surname><given-names>Trevor Thai Kim</given-names></name><role specific-use="author">Author</role><aff><institution>University of Maryland, College Park</institution><addr-line><named-content content-type="city">College Park</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Muthmann</surname><given-names>Jens-Oliver</given-names></name><role specific-use="author">Author</role><aff><institution>University of Maryland, College Park</institution><addr-line><named-content content-type="city">College Park</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Butts</surname><given-names>Daniel A</given-names></name><role specific-use="author">Author</role><aff><institution>3University of California, Berkeley</institution><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Yates</surname><given-names>Jacob</given-names></name><role specific-use="author">Author</role><aff><institution>University of California, Los Angeles</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Huk</surname><given-names>Alexander C</given-names></name><role specific-use="author">Author</role><aff><institution>University of California, Los Angeles</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer 1(Public Review):</bold></p><p>“but an obvious influencing factor that the authors could investigate in their own data set is the retinal input. In Fig1b, the authors even show these data in the form of gaze and pupil size. In these example data, by eye, it looks like the pupil size is positively correlated with the run speed. This would of course have large consequences on the activity in V1, but the authors do not do anything with these data. The study would improve substantially if the authors would correlate their run speed traces with other factors that they have recorded too, such as pupil size and gaze.”</p></disp-quote><p>Absolutely. We have added a first level of eye movement (and pupil size) analyses to the revised manuscript, resulting in an additional figure. In short, we found that eye movements are unlikely to play a significant role in our primary results, as the patterns of eye movements differed only slightly between running and stationary periods, and the measured impacts of such eye movements were also quantitatively much smaller than the primary effect sizes.</p><p>We also note that in analyzing the eye movements, we also found that pupil size was larger during running than stationary. This is suggestive evidence that running is correlated with increases in arousal. Although more work will be needed to calibrate and quantify how much this factor affects neural responses (and perhaps to dissociate it from running per se), the simple analysis we present suggest that the large differences we observe could be explained by a difference between how arousal and running are correlated in the monkey versus the mouse. Instead, it appears that both species have at least qualitatively similar relations between pupil size (a standard proxy for arousal) and running.</p><p>On this issue, we have added extensive discussion of the relevant recent work by Talluri et al. (2023) who attempted a similar cross-species analysis that considered spontaneous body movements and their effect on cortical activity (as well as the possibility that eye movements are a critical mediator in these modulations). Due to delays in revising our manuscript, we regret that our earlier submission had not cited this work, but we now do our best to highlight its importance and the synergy between these two papers. The full citation is listed below:</p><p>Talluri BC, Kang I, Lazere A, Quinn KR, Kaliss N, Yates JL, Butts DA, Nienborg H. Activity in primate visual cortex is minimally driven by spontaneous movements. Nat Neurosci. 2023 Nov;26(11):1953-1959. doi: 10.1038/s41593-023-01459-5.</p><p>There is a finer level of analysis that we hope to do in the future along these lines. It would rely on detailed characterization of each receptive field, building an image-computable model linking those receptive fields to the neural activity, and doing so at a finer time grain that links individual eye movements and changes in the spike train within a stimulus presentation (as opposed to working at the level of spike counts per stimulus presentation). Because these steps need to be accomplished together— and each requires substantial additional work and would go beyond the first-order findings we report in this work— we hope to report on such finer analyses in a standalone paper later. We are working on being able to do this in both marmoset and mouse.</p><p>More generally, we want to emphatically agree that what is missing from this paper is the “why?”! We have done our best to show that a fair comparison reveals quantitatively different phenomena in marmoset and mouse. In the revised discussion, we lay out many lines of work that we hope will gain traction on this deeper mechanistic point. There’s a lot to do, and several of the possibilities are already current topics of exploration in our ongoing work.</p><disp-quote content-type="editor-comment"><p>“Looking at the raster plot, however, shows that this strong positive correlation must be due entirely to the lower half of the neurons significantly increasing their firing rate as the mouse starts to run; in fact, the upper 25% or so of the neurons show exactly the opposite (strong suppression of the neurons as the mouse starts running). It would be more balanced if this heterogeneity in the response is at least mentioned somewhere in the text.”</p></disp-quote><p>We are also intrigued by the heterogeneity of effects at the single neuron level. That is why the next section of the paper is dedicated to analyzing effects on a cell-by-cell basis. The fractions of neurons showing either increases or decreases are described separately, to get at this very issue.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer 2 (Public Review)::</bold></p><p>“For example, it is known that the locomotion gain modulation varies with layer in the mouse visual cortex, with neurons in the infragranular layers expressing a diversity of modulations (Erisken et al. 2014 Current Biology). However, for the marmoset dataset, it was not reported from which cortical layer the neurons are from, leaving this point unanswered.”</p><p>Reviewer 2 called for more consideration of details that have been addressed in the mouse literature, such as the cortical layer of the cells, and related aspects of circuitry. We have greatly re-worked the Discussion to address several of these issues. In short, the manuscript’s set of data were collected without strong traction on layers or cell types, and it will be quite interesting to get a better handle on this using both refinements to our recording procedures as well as new techniques that are now possible in the marmoset for future studies.</p><p>“In this regard, it is worth noting that the authors report an interesting difference between the foveal and peripheral parts of the visual cortex in marmoset. It will be interesting to investigate these differences in more detail in future studies. Likewise, while running might be an important behavioral state for mice, other behavioral states might be more relevant for marmosets and do modulate the activity of the primate visual cortex more profoundly. Future work could leverage the opportunities that the marmoset model system offers to reveal new insights about behavioral-related modulation in the primate brain.”</p></disp-quote><p>Same page! We have expanded the discussion to better emphasize these points and are already deep in follow up experiments to explore the foveal and peripheral representations.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer 3(Public Review):****:</bold></p><p>“However, the authors did not take full advantage of the quantity and diversity of the marmoset visual cortex recordings in their analyses. They mention recording and analyzing the activity of peripheral V1 neurons but mainly present results involving foveal V1 neurons. Foveal neurons, with their small receptive fields strongly affected by precise eye position, would seem to be less likely to be comparable to rodent data. If the authors have a reason for not doing so, they should provide an explanation.”</p></disp-quote><p>We agree, and hope the reviewer finds our overall reply, detailed response to Reviewer 1 (who raised a similar issue), and corresponding updates to the manuscript appropriate for this stage of understanding.</p><disp-quote content-type="editor-comment"><p>“Given that the marmosets are motivated to run with liquid rewards, the authors should provide more context as to how this may or may not affect marmoset V1 activity. Additionally, the lack of consideration of eye movements or position presents a major absence for the marmoset results, and fails to take advantage of one of the key differences between primate and rodent visual systems - the marmosets have a fovea, and make eye movements that fixate in various locations on the screen during the task.”</p></disp-quote><p>In addition to the response above, we have made edits to the manuscript to speak to issues of arousal and eye movements (also detailed in previous responses). Given the modest decrease in activity we see, the usual concerns about potential increases in neural activity related to eye movements (which we quantify in the revision) and other issues related to motivation are hard to specifically relate to existing literature. But in the revised Discussion we talk more about how future work can/should dissociate these factors, as has been done in the mouse literature.</p><disp-quote content-type="editor-comment"><p>“Finally, the model provides a strong basis for comparison at the level of neuronal populations, but some methodological choices are insufficiently described and may have an impact on interpreting the claims.”</p></disp-quote><p>We have also clarified the shared-gain model’s description, which we agree needed additional detail and clarification.</p></body></sub-article></article>