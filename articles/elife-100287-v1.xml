<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">100287</article-id><article-id pub-id-type="doi">10.7554/eLife.100287</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100287.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Stimulus representation in human frontal cortex supports flexible control in working memory</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Shao</surname><given-names>Zhujun</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0006-0886-4606</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Zhang</surname><given-names>Mengya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0006-9197-1698</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Yu</surname><given-names>Qing</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8480-7634</contrib-id><email>qingyu@ion.ac.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00vpwhm04</institution-id><institution>Institute of Neuroscience, State Key Laboratory of Brain Cognition and Brain-inspired Intelligence Technology, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qbk4x57</institution-id><institution>University of Chinese Academy of Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Xue</surname><given-names>Gui</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>Beijing Normal University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>24</day><month>04</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP100287</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-06-06"><day>06</day><month>06</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-06-07"><day>07</day><month>06</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.28.551058"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-03"><day>03</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100287.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-01-07"><day>07</day><month>01</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100287.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-03-14"><day>14</day><month>03</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100287.3"/></event></pub-history><permissions><copyright-statement>© 2024, Shao, Zhang et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Shao, Zhang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-100287-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-100287-figures-v1.pdf"/><related-article related-article-type="commentary" ext-link-type="doi" xlink:href="10.7554/eLife.106869" id="ra1"/><abstract><p>When holding visual information temporarily in working memory (WM), the neural representation of the memorandum is distributed across various cortical regions, including visual and frontal cortices. However, the role of stimulus representation in visual and frontal cortices during WM has been controversial. Here, we tested the hypothesis that stimulus representation persists in the frontal cortex to facilitate flexible control demands in WM. During functional MRI, participants flexibly switched between simple WM maintenance of visual stimulus or more complex rule-based categorization of maintained stimulus on a trial-by-trial basis. Our results demonstrated enhanced stimulus representation in the frontal cortex that tracked demands for active WM control and enhanced stimulus representation in the visual cortex that tracked demands for precise WM maintenance. This differential frontal stimulus representation traded off with the newly-generated category representation with varying control demands. Simulation using multi-module recurrent neural networks replicated human neural patterns when stimulus information was preserved for network readout. Altogether, these findings help reconcile the long-standing debate in WM research, and provide empirical and computational evidence that flexible stimulus representation in the frontal cortex during WM serves as a potential neural coding scheme to accommodate the ever-changing environment.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>working memory</kwd><kwd>cognitive flexibility</kwd><kwd>frontal cortex</kwd><kwd>visual cortex</kwd><kwd>fMRI</kwd><kwd>recurrent neural network</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002367</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap></funding-source><award-id>Strategic Priority Research Program of the Chinese Academy of Sciences, XDB1010202</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Qing</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>STI2030-Major Projects 2021ZD0203701</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Qing</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>STI2030-Major Projects 2021ZD0204202</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Qing</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32271089</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Qing</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002367</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap></funding-source><award-id>CAS Project for Young Scientists in Basic Research, YSBR-071</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Qing</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003399</institution-id><institution>Science and Technology Commission of Shanghai Municipality</institution></institution-wrap></funding-source><award-id>Shanghai Pujiang Program, 22PJ1414400</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Qing</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The distributed network of working memory, encompassing frontal, parietal, and sensory cortices, flexibly reconfigures under different tasks to adapt to varying control demands.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Real-world flexible behavior relies largely on WM, which allows the maintenance and manipulation of information in the brain in order to serve diverse behavioral goals (<xref ref-type="bibr" rid="bib2">Baddeley, 2003</xref>). One central problem in the field of WM is to understand how stimulus information is represented and maintained in WM. Over the past decade, mounting evidence has demonstrated stimulus-specific representation during WM maintenance in a distributed cortical network, including sensory, parietal, and frontal cortices (<xref ref-type="bibr" rid="bib11">Christophel et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib31">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Harrison and Tong, 2009</xref>; <xref ref-type="bibr" rid="bib52">Riggall and Postle, 2012</xref>; <xref ref-type="bibr" rid="bib53">Serences et al., 2009</xref>; <xref ref-type="bibr" rid="bib55">Sprague and Serences, 2013</xref>; <xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>; <xref ref-type="bibr" rid="bib60">Yu and Shim, 2019</xref>). However, the exact nature and functions of stimulus representation in different cortical regions remain controversial. Specifically, while neurophysiological studies in non-human primates have mostly emphasized stimulus representation in the frontal cortex (<xref ref-type="bibr" rid="bib27">Funahashi et al., 1989</xref>; <xref ref-type="bibr" rid="bib29">Fuster and Alexander, 1971</xref>; <xref ref-type="bibr" rid="bib37">Leavitt et al., 2017</xref>), neuroimaging work in humans has reported disparate findings. During the maintenance of simple visual features, stimulus representation is robustly encoded in the early visual cortex (EVC), which has been taken as the evidence in support of the sensorimotor recruitment hypothesis of WM (<xref ref-type="bibr" rid="bib33">Harrison and Tong, 2009</xref>; <xref ref-type="bibr" rid="bib52">Riggall and Postle, 2012</xref>; <xref ref-type="bibr" rid="bib53">Serences et al., 2009</xref>). Meanwhile, stimulus representation in the higher-order frontoparietal cortex is typically weaker and less stable (<xref ref-type="bibr" rid="bib19">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Riggall and Postle, 2012</xref>; <xref ref-type="bibr" rid="bib60">Yu and Shim, 2019</xref>). However, in dynamic environments such as those involving distraction, stimulus representation in EVC could be greatly interrupted or biased (<xref ref-type="bibr" rid="bib6">Bettencourt and Xu, 2016</xref>; <xref ref-type="bibr" rid="bib32">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Lorenc et al., 2018</xref>). In contrast, stimulus representation in the frontal cortex could be robust under certain circumstances including attentional prioritization (<xref ref-type="bibr" rid="bib12">Christophel et al., 2018</xref>), categorization (<xref ref-type="bibr" rid="bib38">Lee et al., 2013</xref>), and after extensive training (<xref ref-type="bibr" rid="bib47">Miller et al., 2022</xref>). To summarize, stimulus representation could vary markedly depending on specific brain regions and memory tasks, complicating the interpretation of potential functions of stimulus representation in WM.</p><p>In this study, we consider these apparent discrepancies from the perspective of cognitive flexibility (<xref ref-type="bibr" rid="bib5">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="bib28">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="bib49">Musslick and Cohen, 2021</xref>). We propose that changes in stimulus representation in different cortical regions might reflect a global reconfiguration in coding strategy and resource allocation in response to varied WM functions (<xref ref-type="bibr" rid="bib34">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="bib38">Lee et al., 2013</xref>). To elaborate, beyond the passive maintenance of incoming sensory information, WM provides an online mental workspace for active manipulation and control of stimulus contents (<xref ref-type="bibr" rid="bib2">Baddeley, 2003</xref>; <xref ref-type="bibr" rid="bib46">Miller and Cohen, 2001</xref>). As control functions often result in the generation and maintenance of new information, the brain needs to manage not only the original stimulus information but also the newly generated information in WM. Due to the limited cognitive resources available, it is likely that original stimulus representation in WM could adapt flexibly to various task goals beyond simple maintenance of WM contents, which might also co-vary with changes in the representation of the newly-generated information, leading to a systematic reconfiguration in representations of all levels across various cortices. We make two specific predictions from this account. First, in accordance with the findings of elevated neural activity in the frontal cortex with increasing demand for memory manipulation (<xref ref-type="bibr" rid="bib16">D’Esposito et al., 1999</xref>, <xref ref-type="bibr" rid="bib17">D’Esposito et al., 2000</xref>) and cognitive control (<xref ref-type="bibr" rid="bib3">Badre, 2008</xref>; <xref ref-type="bibr" rid="bib4">Badre et al., 2010</xref>; <xref ref-type="bibr" rid="bib46">Miller and Cohen, 2001</xref>), stimulus representation in frontal cortex should be enhanced for active-control-related functions in WM. By contrast, due to the precise nature of stimulus representation in visual cortex, stimulus representation in this region should be enhanced for precise-maintenance-related functions in WM (<xref ref-type="bibr" rid="bib34">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="bib38">Lee et al., 2013</xref>). Second, within the brain regions that encode the newly generated information, a dynamic tradeoff between representations of original and new information should be observed to achieve a flexible allocation of limited cognitive resources (<xref ref-type="bibr" rid="bib5">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Flesch et al., 2022</xref>).</p><p>Using functional magnetic resonance imaging (fMRI), we directly tested this account by systematically investigating stimulus representation in visual, parietal, and frontal cortices during WM tasks with varying demands for active control. In particular, we surmised that stimulus representation in the frontal cortex would increase to accommodate complex control demands such as rule-based categorization. To this end, we employed a visual WM paradigm that required flexible switching between maintenance and categorization tasks. Specifically, in the maintenance task, participants maintained one visual orientation throughout a delay period, whereas in the categorization task participants were required to categorize the remembered orientation into one of two categories in accordance with previously learned rules, which could be either switched randomly between two rules on a block-by-block basis (Experiment 1) or fixed with one rule (Experiment 2). Thus, compared with the maintenance task, the categorization task imposed additional control demands of WM information at two different levels: the first level of control being stimulus categorization, because participants needed to adapt the stimulus based on the categorization rule in WM for subsequent category judgments; the second level of control being flexibility of rules, because with two categorization rules, the flexibility in control increased.</p><p>In line with our predictions, our results showed that stimulus information was more prominently represented in the frontal cortex during the categorization than the maintenance task, and this differential representation was enhanced with increasing demands for control. Importantly, the strength of stimulus representation in the frontal cortex was predictive of WM behavioral performance in the categorization but not in the maintenance task, implicating a selective involvement of the frontal cortex in control functions. By contrast, stimulus representation in the visual cortex was found to exhibit the opposite pattern, with higher strength for the maintenance than for the categorization task. Moreover, varying control demands across experiments revealed a dynamic tradeoff between stimulus and the newly-generated category representations. To further examine whether the enhanced stimulus representation in the frontal cortex during the categorization task could be explained by global coding strategy, we simulated our flexible WM tasks with multi-module recurrent neural networks (RNNs). The results of this computational modeling well replicated our human data when precise stimulus information was preserved at the output during network training. Taken together, our results indicate the importance of the frontal cortex for flexible control in WM and highlight the relative changes of stimulus representation in different cortical regions for varying task demands of WM.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral learning and performance of WM tasks</title><p>In the fMRI session of Experiment 1, human participants (n=24) completed two tasks, maintenance and categorization, inside an MRI scanner. The maintenance task was a delayed match-to-sample WM task of orientations. Participants only needed to maintain the cued orientation throughout a memory delay. In the categorization task, participants also started with maintaining an orientation. After the task cue, they needed to categorize the remembered orientation into one of two categories using the cued categorization rule. Within an experimental block of nine trials, participants randomly switched between the two tasks. Across blocks, participants randomly switched between two categorization rules acquired during a preceding learning session. We randomized response mapping across trials to avoid potential influence by motor-planning signals (see <xref ref-type="fig" rid="fig1">Figure 1A</xref> for probe design). Prior to the main session, participants first completed a behavioral learning session to learn two categorization rules (Rule A and Rule B, see <xref ref-type="fig" rid="fig1">Figure 1B</xref>) that were orthogonal to each other. Participants acquired the two rules with equal familiarity (<italic>t</italic>(23) = 0.24, p=0.813; for Rule A, <italic>M</italic>=0.85, <italic>SD</italic> = 0.050; for Rule B, <italic>M</italic>=0.85, <italic>SD</italic> = 0.05; <xref ref-type="fig" rid="fig1">Figure 1C</xref>) and comparable precision (averaged error in reported boundaries for Rule A were 8.80°±6.29° and that for Rule B was 9.02°±5.69°; <xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design and behavioral performance in Experiment 1.</title><p>(<bold>A</bold>) Main task procedure. Each block started with a rule cue indicating the categorization rule for this block. On each trial, participants saw two orientations consecutively and were then cued to remember one of the orientations. In the maintenance task (cued by letter ‘P’), participants needed to maintain the remembered orientation as precisely as possible. In the categorization task (cued by letter ‘C’), participants needed to categorize the remembered orientation following the categorization rule of the current block. Maintenance and categorization trials were interleaved within an experimental block of nine trials. Categorization rule (Rule A or Rule B) switched randomly on a block-by-block basis. Response keys (‘F’ and ‘J’) for the categorization task were randomly assigned to the two categories. Each pair of keys displayed at random locations within the category to eliminate information on rule boundaries. (<bold>B</bold>) Illustration of the two orthogonal categorization rules (Rule A and Rule B). (<bold>C</bold>) Rule learning performance during learning session (n = 24) for Rule A (purple) and Rule B (pink). (<bold>D</bold>) Errors in participants’ self-reported rule boundaries. Errors were calculated as the average distance from reported boundaries to ground truth boundaries. (<bold>E</bold>) Accuracy compared between tasks. Boxplots show the median and the 25<sup>th</sup> and 75<sup>th</sup> percentiles. Whiskers extend to 1.5 Inter quartile range (IQR) from the quartiles. Asterisks denote significant results, n.s.: not significant; **p&lt;0.01. (<bold>F</bold>) Reaction time compared between tasks. Same conventions as (<bold>E</bold>). (<bold>G</bold>) Upper panel: accuracy in relation to distance from categorization boundaries. Lower panel: reaction time in relation to distance from categorization boundaries. Shaded areas represent ± SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Behavioral performance of Experiment 2.</title><p>(<bold>A</bold>) Accuracy (upper) and reaction time (lower) of maintenance (blue) and categorization (orange) tasks in Experiment 2 (n = 24). Boxplots show the median and the 25<sup>th</sup> and 75<sup>th</sup> percentiles. Whiskers extend to 1.5 Inter quartile range (IQR) from the quartiles. Asterisks denote significant results, n.s.: not significant; **p&lt;0.01. (<bold>B</bold>) Accuracy (upper) and reaction time (lower) for orientations based on their distances from category center for Categorization task. Shaded areas represent ± SEM. Vertical dashed line represents category center.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig1-figsupp1-v1.tif"/></fig></fig-group><p>Overall, participants performed equally well on both tasks in the fMRI session. Accuracy for the maintenance task (<italic>M</italic> ± <italic>SD</italic>: 0.81±0.07) and that for the categorization task (0.82±0.05) did not significantly differ (<italic>t</italic>(23) = 1.51, p=0.144; <xref ref-type="fig" rid="fig1">Figure 1E</xref>), suggesting that the two tasks were matched in terms of task difficulty. In line with previous categorization studies demonstrating a boundary effect (<xref ref-type="bibr" rid="bib23">Ester et al., 2020</xref>; <xref ref-type="bibr" rid="bib26">Freedman and Assad, 2006</xref>), only in the categorization task but not in the maintenance task did participants perform better for trials distant from category boundaries in terms of both accuracy and reaction time (see <xref ref-type="fig" rid="fig1">Figure 1G</xref>). These results demonstrated the effect of categorization and confirmed that participants faithfully followed task instructions.</p></sec><sec id="s2-2"><title>Enhanced stimulus representation in frontal cortex during categorization task</title><p>The primary goal of this study was to determine the role of stimulus representation in various cortices in WM. Using conventional multivariate encoding and decoding methods, we tracked stimulus (i.e. orientation) representation in three brain regions of interest (ROIs) that have been implicated in representing WM information, including EVC, intraparietal sulcus (IPS), and superior precentral sulcus (sPCS) (<xref ref-type="bibr" rid="bib12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="bib22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>), see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for a visualization of the anatomical locations of the ROIs.</p><p>First, we used multivariate inverted encoding models (IEMs) (<xref ref-type="bibr" rid="bib9">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib10">Brouwer and Heeger, 2011</xref>; <xref ref-type="bibr" rid="bib22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib51">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>) to reconstruct orientation representation at the population level in each ROI. <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows example orientation reconstructions from representative time points. To quantify the strength of orientation reconstructions, we calculated the reconstruction fidelity by first projecting the channel response at each orientation onto a vector at the cued orientation and then averaging the projected vectors to obtain the representational fidelity (<xref ref-type="bibr" rid="bib51">Rademaker et al., 2019</xref>). A larger fidelity value indicates a stronger positive representation of orientation (See <xref ref-type="fig" rid="fig2">Figure 2B</xref> for illustration). <xref ref-type="fig" rid="fig2">Figure 2C</xref> demonstrates the time course of orientation reconstruction as quantified by representational fidelity. Critically, by comparing the representational fidelity values within the same ROI across conditions (maintenance vs. categorization), we minimized the impact of effect size on our comparisons between ROIs, as all the comparisons were primarily performed within the same ROI with a comparable effect size. In EVC, we found significant orientation representation in both maintenance and categorization tasks starting from the sample period (<xref ref-type="fig" rid="fig2">Figure 2C</xref> left panel; see <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref> for full statistics), even when the categorization task did not require explicit memory of stimulus information. Additionally, the strength of orientation representation in the maintenance task became significantly higher than that in the categorization task after the task cue during the delay, suggesting the strength of orientation representations in EVC reflected the degrees of task demands for maintaining visual details. In IPS, orientation representation was significant in both tasks, but did not differ from each other at most time points (<xref ref-type="fig" rid="fig2">Figure 2C</xref> middle panel). In sPCS, a reversed pattern was observed. In the maintenance task, orientation information was maintained during early delay period and then dropped to baseline level during late delay period. By contrast, in the categorization task, orientation representation was persistent throughout the delay and response periods. The strength of orientation representation in the categorization task became statistically higher than that in the maintenance task in late delay period (<xref ref-type="fig" rid="fig2">Figure 2C</xref> right panel), suggesting that this differential representations of visual stimulus in the frontal cortex reflected the demand for active control of memory contents. To facilitate comparison of the differential stimulus representation across ROIs, we averaged the difference in representational strength across a late task epoch (11–16 s), and the difference in stimulus representation between ROIs remained (<xref ref-type="fig" rid="fig2">Figure 2D</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Orientation reconstructions at the population level using inverted encoding models (IEMs) in Experiment 1.</title><p>(<bold>A</bold>) Reconstructed population-level orientation representations from selected time points in early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS) for maintenance (blue) and categorization (orange) tasks, respectively (n = 24). X-axis represents distance from the cued orientation (at 0°), and y-axis represents reconstructed channel responses in arbitrary units. Significant orientation representation was observed at 6 s and 12 s but not at 0 s. Shaded areas represent ± SEM. (<bold>B</bold>) To quantify the strength of orientation reconstructions, we calculated the reconstruction fidelity by first projecting the channel response at each orientation onto a vector at the cued orientation and then averaging the projected vectors. (<bold>C</bold>) Time course of representational fidelity of orientations in EVC, IPS, and sPCS. In this and all subsequent figures with time course data, the time axis reflects raw time points without accounting for the hemodynamic response delay. Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at p&lt;0.05 (small), p&lt;0.01 (medium), and p&lt;0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent ± SEM. (<bold>D</bold>) Average difference of representational fidelity across 11–16 s in each region of interest (ROI) (from EVC to sPCS: p&lt;0.00001, p=0.063, p=0.007, respectively). Positive difference indicates higher representational fidelity for the categorization task, and vice versa for negative difference. Black asterisks denote FDR-corrected significance, *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001. Error bars represent ± SEM.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>p-values for the time course of inverted encoding model (IEM) results in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</title><p>Underline denotes significant results (p&lt;0.05).</p></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-100287-fig2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Visualization of the anatomical locations of the regions of interest (ROIs) on the MNI brain.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Control analyses for stimulus representation results in Experiment 1.</title><p>(<bold>A</bold>) Time course of representational fidelity of orientations in early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS) using inverted encoding models (IEMs) trained separately for each condition (n = 24). Gray shaded areas indicate the entire memory delay following task cue. Horizontal dashed lines represent a baseline of 0 or 0.5. Blue and orange dots at the bottom indicate the significance of representational fidelity at each time point of the corresponding task at p&lt;0.05 (small), p&lt;0.01 (medium), and p&lt;0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks. Shaded areas represent ± SEM. Bar plot on the right shows corresponding averaged difference between tasks across the late task epoch (11–16 s) in each region of interest (ROI). Positive difference indicates higher representational fidelity for the categorization task, and vice versa for negative difference. Black asterisks denote significance, *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001. Gray asterisk denotes marginal significance p&lt;0.1. Error bars represent ± SEM. (<bold>B</bold>) Time course of stimulus decoding accuracy. Same conventions as (<bold>A</bold>). (<bold>C</bold>) Time course of representational fidelity of orientations after removing voxel-wise mean activation for each condition at each time point. Same conventions as (<bold>A</bold>). (<bold>D</bold>) Time course of representational fidelity of orientations in functional ROIs defined by top 500 most selective voxels during sample or delay period. Same conventions as (<bold>A</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Orientation reconstructions in primary motor cortex (M1) at the population level using IEMs.</title><p>Time course of representational fidelity of orientations in M1 in Experiment 1 (n = 24). Gray shaded areas indicate the entire memory delay following task cue. The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected) at p&lt;0.05. Horizontal dashed lines represent a baseline of 0. Shaded areas represent ± SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig2-figsupp3-v1.tif"/></fig></fig-group><p>We validated the difference in stimulus representations through a series of control analyses. First, we demonstrated that these results cannot be explained by the specific model used to train the data (<xref ref-type="bibr" rid="bib40">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Sprague et al., 2018</xref>) nor the specific analytical approach used, because similar patterns were observed when we trained the IEM separately for each condition (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A</xref>) or adopted a Support Vector Machine (SVM) decoding approach (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2B</xref>; <xref ref-type="bibr" rid="bib34">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="bib51">Rademaker et al., 2019</xref>). Mean activation differences between tasks cannot account for the results either, because when we removed the mean differences in BOLD activity between tasks, the difference in representational strength remained (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2C</xref>). Furthermore, to remove the potential impact of voxel number on IEM, we selected the top 500 of most sample- or delay-selective voxels from each ROI and trained IEM using the selected voxels. Again, this analysis yielded similar findings (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2D</xref>). Lastly, when repeating the IEM analyses in primary motor cortex (M1), no similar patterns were observed, suggesting that our results cannot be explained by motor- or response-related activity (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>).</p><p>Together, these results demonstrated enhanced stimulus representation in the frontal cortex with increased demand for active control, as well as those in the visual cortex with increased demand for precise WM maintenance.</p></sec><sec id="s2-3"><title>Prediction of categorization behavior by frontal stimulus representation</title><p>Previous WM studies have shown that the strength of stimulus representation in EVC positively correlated with memory performance (<xref ref-type="bibr" rid="bib19">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="bib21">Ester et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Gosseries et al., 2018</xref>), suggesting that EVC plays an important role in precise WM maintenance. However, stimulus representation in the frontal cortex rarely predicted behavioral performance in maintenance task (<xref ref-type="bibr" rid="bib32">Hallenbeck et al., 2021</xref>), although univariate activation in the same brain region can predict memory-guided saccade performance (<xref ref-type="bibr" rid="bib15">Curtis et al., 2004</xref>). Nevertheless, if frontal stimulus representation is involved in WM control, its behavioral relevance should be subject to observation with increased control demands. Therefore, we assessed the behavioral predictability of stimulus representation during the delay period in EVC, IPS, and sPCS. <xref ref-type="fig" rid="fig3">Figure 3A, B and C</xref> illustrate the time course of correlation results, results from representative time points, and results collapsed across the late epoch, respectively. Consistent with previous findings, we found the strength of stimulus representation in EVC during the early delay period predicted behavioral accuracies in both maintenance and categorization tasks (see <xref ref-type="supplementary-material" rid="fig3sdata1">Figure 3—source data 1</xref> for full statistics). Similar predictability was found in IPS, with stimulus representation predicted behavior in the maintenance task during early delay and in the categorization task throughout the entire memory delay. Interestingly, we found that, throughout the entire memory delay, the strength of stimulus representation in sPCS predicted behavioral accuracies only in the categorization task but not in the maintenance task. These results highlighted the functional significance of stimulus representation in sPCS exclusively for the categorization task.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Behavioral correlation of stimulus representation for maintenance (blue) and categorization (orange) tasks in Experiment 1.</title><p>(<bold>A</bold>) Time course of correlation coefficients between behavioral performance and orientation representational fidelity (n = 24) in early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS). Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate significance of correlation (uncorrected) at each time point at p&lt;0.05 (small), p&lt;0.01 (medium), and p&lt;0.001 (large). (<bold>B</bold>) Correlation scatter plots at representative time points (7 s and at 12 s) in EVC, IPS, and sPCS. R denotes Pearson correlation coefficients. (<bold>C</bold>) Correlation between behavioral performance and orientation representational fidelity collapsed across the late epoch (11–16 s). Asterisks denote significant results, *p&lt;0.05; **p&lt;0.01.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>p-values for the time course of correlation results in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title><p>Underline denotes significant results (p&lt;0.05).</p></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-100287-fig3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Behavioral correlation of stimulus representation in Experiment 2.</title><p>Time course of correlation coefficients (n = 24) in early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS). Correlation was performed between strength of stimulus representations and behavioral performance (accuracy) for maintenance (blue) and categorization (orange) tasks. Gray shaded areas indicate the entire memory delay following task cue. Horizontal dashed lines represent a baseline of 0. Bottom dots indicate the significance of corresponding analyses at each time point of the corresponding task at p&lt;0.05 (small), p&lt;0.01 (medium), and p&lt;0.001 (large).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig3-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Reduced frontal stimulus representation with lower control demand</title><p>In Experiment 1, participants flexibly switched between two categorization rules to prompt the manipulation of WM content on a trial-by-trial basis. The rule switching increased control demand but also complicated the interpretation of our results. To exclude potential impact of rule switching, we conducted Experiment 2 (n = 24), in which participants performed the maintenance and categorization tasks with only one fixed rule. Behavioral results of Experiment 2 again demonstrated a classic boundary effect and were comparable to Experiment 1, with no significant difference between experiments in terms of either accuracy or reaction time (<italic>F</italic>s &lt;1.28, <italic>p</italic>s &gt;0.26; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). When using IEMs to reconstruct stimulus representation, we found EVC and IPS both showed patterns similar to those in Experiment 1 (<xref ref-type="fig" rid="fig4">Figure 4A</xref> left and middle panels), with stimulus representation decreased in EVC in the categorization task and remained at the same level in IPS between the two tasks (see <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref> for full statistics). The frontal region, sPCS, also showed a differential enhancement of stimulus representation in the categorization task as in Experiment 1, but in an earlier period (<xref ref-type="fig" rid="fig4">Figure 4A</xref> right panel). To validate such a temporal difference, we defined an additional early task epoch (5–10 s), and confirmed a significant difference in stimulus representation in sPCS during the early (p=0.015; <xref ref-type="fig" rid="fig4">Figure 4B</xref>) but not during the late epoch (p=0.372; <xref ref-type="fig" rid="fig4">Figure 4C</xref>). In addition, we performed a mixed ANOVA on experiments (Experiment 1 vs 2) and epochs (early vs. late epoch) and observed a significant interaction effect between the two, <italic>F</italic>(1, 46)=7.43, p=0.009, suggesting that the two experiments differed in terms of the temporal emergence of the differential stimulus representation in the frontal cortex. Taken together, these results are consistent with our expectation that, with reduced control demand, the differential enhancement of stimulus representation in frontal cortex was still present but decreased during late memory delay. Nevertheless, stimulus representation in Experiment 2 still predicted behavioral performance as in Experiment 1, although the difference between tasks was reduced (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Orientation reconstructions at the population level using inverted encoding models (IEMs) in Experiment 2.</title><p>(<bold>A</bold>) Time course of representational fidelity of orientations (n = 24) in early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS). Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at p&lt;0.05 (small), p&lt;0.01 (medium), and p&lt;0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent ± SEM. (<bold>B</bold>) Average difference of representational fidelity across an early (top, 5–10 s) and a late (bottom, 11–16 s) task epoch in each region of interest (ROI). Positive difference indicates higher representational fidelity for the categorization task, and vice versa for negative difference (FDR-corrected). Error bars represent ± SEM. *p&lt;0.05; ***p&lt;0.001.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>p-values for the time course of inverted encoding model (IEM) results in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title><p>Underline denotes significant results (p&lt;0.05).</p></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-100287-fig4-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig4-v1.tif"/></fig></sec><sec id="s2-5"><title>Category representation in WM in various cortices</title><p>Having observed a differential representation of stimulus in the frontal cortex, we next asked how newly generated information in WM during the categorization task emerged and sustained in the distributed WM network and how representations of the original stimulus and the new information interacted. The categorization task could demand additional generation of category information in WM. We, therefore, trained SVMs to decode category information during the categorization task. For each rule, the SVM decoder was trained to discriminate between the two categories. In both experiments, we found that during the late epoch, category information could be well decoded across ROIs (ps &lt;0.044, <xref ref-type="fig" rid="fig5">Figure 5A</xref>; also see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for full decoding time course), with a marginal difference between experiments in sPCS (p=0.055).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Decoding performance for category and abstract category information.</title><p>(<bold>A</bold>) Average category decoding accuracy using category labels under true rule across the late task epoch (11–16 s) in each region of interest (ROI) of both experiments (n = 24 for each experiment). (<bold>B</bold>) Average category decoding accuracy using category labels under orthogonal rule across the late task epoch (11–16 s) in each ROI of both experiments. (<bold>C</bold>) Schematic illustration of abstract category decoding. In the categorization task, category information can be decoded using category labels according to the true categorization rule. On the other hand, category can also be decoded due to stimulus similarity. Thus, to remove stimulus-dependent categorical information, we calculated an abstract category index by removing decoding accuracy using orthogonal category boundaries (assuming comparable stimulus-dependent effect) from that using true rule boundaries. (<bold>D</bold>) Average abstract category decoding index across the late task epoch (11–16 s) in each ROI of both experiments. Black asterisks denote FDR-corrected significance, *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001. Error bars represent ± SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Time course of category and abstract category decoding performance in Experiment 1 and 2.</title><p>(<bold>A</bold>) Time course of category decoding strength in Experiment 1 with flexible rule (orange; n = 24) and in Experiment 2 with fixed rule (light orange; n = 24). Horizontal dashed lines represent the chance level of 0.5. Gray shaded areas indicate the entire memory delay following task cue. Bottom dots indicate uncorrected significance of decoding accuracy at each time point at p&lt;0.05 (small), p&lt;0.01 (medium), and p&lt;0.001 (large). Shaded areas represent ± SEM. (<bold>B</bold>) Time course of abstract category decoding strength in Experiment 1 (dark blue) and in Experiment 2 (light blue). Horizontal dashed lines represent a baseline of 0.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Delineating stimulus and category effects using linear mixed-effects modeling.</title><p>(<bold>A</bold>) To dissociate the contribution of stimulus and abstract category representations to neural activities, we fitted neural representational dissimilarity matrices (RDMs) with three model RDMs. To construct individual neural RDMs between orientations, we first averaged all trials for each orientation within the same condition and then calculated the distance between each pair of orientations. Separately calculated for maintenance and categorization tasks, we then fitted neural RDMs with linear mixed-effects models to estimate the contribution of each model (discrete stimulus model, graded stimulus model, and category model) to the neural RDM over delay periods. (<bold>B</bold>) Fit of discrete stimulus model (pink), graded stimulus model (yellow), and category model (green) in early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS) for the maintenance and categorization tasks in the late epoch of Experiment 1 (n = 24). Darker bars indicate significant main effect of specific models (p&lt;0.05), lighter bars indicate marginally significance (p&lt;0.1), and hollow bars indicate no significance. (<bold>C</bold>) Results for early epoch in Experiment 2. Same conventions as (<bold>B</bold>). (<bold>D</bold>) Results for late epoch in Experiment 2. Same conventions as (<bold>B</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Stimulus, category, and abstract category results in additional frontal regions in Experiment 1 and 2.</title><p>(<bold>A</bold>) Time course of representational fidelity of orientations in inferior precentral sulcus (iPCS), inferior frontal sulcus (IFS), and middle frontal gyrus (MFG) in Experiment 1 (top panel; n = 24) and Experiment 2 (bottom panel; n = 24). Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at p&lt;0.05 (small), p&lt;0.01 (medium), and p&lt;0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent ± SEM. (<bold>B</bold>) Average category decoding accuracy across the late task epoch (11–16 s) in iPCS, IFS, and MFG of both experiments. (<bold>C</bold>) Average abstract category decoding index across the late task epoch (11–16 s) in the same regions of both experiments, black asterisks denote FDR-corrected significance, n.s.: not significant; *p&lt;0.05. Error bars represent ± SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig5-figsupp3-v1.tif"/></fig></fig-group><p>One might argue that the category decoding results could at least be partially attributed to stimulus similarity. To minimize the impact of stimulus similarity on category decoding, we additionally trained another decoder using the opposite rule (i.e. using category labels from the orthogonal rule; see <xref ref-type="fig" rid="fig5">Figure 5B</xref> for results). We then calculated an abstract category index by subtracting decoding accuracy under the opposite rule from that under the true rule (<xref ref-type="bibr" rid="bib48">Mok and Love, 2020</xref>; <xref ref-type="fig" rid="fig5">Figure 5C</xref>). The rationale was that the amount of stimulus similarity would be comparable for the opposite rule, but additional category information, if existed, should result in higher decoding accuracy for the true rule. In other words, positive abstract category index indicates evidence for stimulus-independent category representation. After removing stimulus-related signals, average decoding performance of abstract category was only evident in Experiment 2 (<italic>p</italic>s &lt;0.017) but not in Experiment 1 (<italic>p</italic>s &gt;0.14) for all ROIs. Moreover, decoding performance of abstract category was significantly higher in Experiment 2 than Experiment 1 in sPCS (<italic>P</italic>=0.034; <xref ref-type="fig" rid="fig5">Figure 5D</xref>). These results together suggest a potential tradeoff between stimulus difference and category representation in the frontal cortex. This tradeoff was further depicted using linear mixed-effects modeling (LMEM) on representational dissimilarity matrices (RDMs) of neural activities to decouple the contributions of stimulus and category to neural representation (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A</xref>). Overall, the LMEM results (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2B–D</xref>) replicated the above findings, with significant stimulus but not category representation in sPCS in Experiment 1, and a decreased contribution of stimulus but emerging category representation in the same brain region in Experiment 2.</p><p>Lastly, for completeness, we repeated the IEM and category decoding analyses on additional ROIs in the frontal cortex, to investigate whether the observed results were specific to sPCS. Specifically, we defined three additional ROIs based on the HCP atlas (<xref ref-type="bibr" rid="bib30">Glasser et al., 2016</xref>), including the inferior precentral sulcus (iPCS), inferior frontal sulcus (IFS), and middle frontal gyrus (MFG) (<xref ref-type="bibr" rid="bib22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Mackey et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>). Overall, results in the three ROIs were comparably weaker than sPCS (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). There was some indication that the MFG might share some results for orientation representation and category decoding, although this pattern was weaker and was only observed in some analyses in Experiment 2.</p></sec><sec id="s2-6"><title>Differential stimulus representation in frontal cortex replicated by RNN modeling</title><p>Finally, we tested how stimulus representation could emerge in frontal cortex at the mechanistic level using RNN models. Our hypothesis is that precise stimulus representation during WM might emerge in frontal cortex in response to complex task demands such as rule-based categorization. In other words, instead of relying (solely) on category representations, the cortical network might have adopted a different strategy to accommodate flexible task requirements in the current study, for instance, by preserving stimulus information until a later stage of information processing. This different strategy can be implemented by altering the RNN’s output structure. Therefore, the logic of this modeling analysis was to examine whether explicitly placing a demand for the model to preserve stimulus representation would recapitulate our fMRI findings in frontal cortex, in comparison to a model that did not specify such a demand.</p><p>Two types of modular RNNs were trained on the maintenance and categorization tasks simultaneously (<xref ref-type="bibr" rid="bib44">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="bib62">Zhou et al., 2021</xref>). The networks shared common input and hidden layer structures (i.e. orientation-tuned and retro/task cue-related units as the input layer, recurrent units with short-term synaptic plasticity in the hidden layer [80% excitatory +20% inhibitory units, equally distributed in three separate modules]). The only difference was in the structure of the output layer. The first type of RNN (RNN1; n=20) had only two units in the output layer to indicate networks’ choice (<xref ref-type="fig" rid="fig6">Figure 6A</xref>), whereas the second type of RNN (RNN2; n=20) had additional units in the output layer corresponding to the original stimulus information. In other words, the second RNN was designed to maintain stimulus information throughout the network modules. For the common hidden layer, we included three hierarchically organized (posterior, middle, and anterior) modules of recurrent units generated according to neurobiological principles of neuronal connections (e.g. denser connectivity within than between modules) to simulate the interconnected brain areas in our ROI-based fMRI analyses above: the posterior module (Module 1, simulating EVC) was directly connected with the input layer, the middle module (Module 2, simulating IPS) received projections from the posterior module and relaying information to the anterior module, and the anterior module (Module 3, simulating sPCS) projected to the output layer. Task events were simulated as numerical inputs to the model, matching the procedures of Experiment 1 (see Methods for details).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Architecture of recurrent neural networks (RNNs) and simulation results.</title><p>(<bold>A</bold>) All networks consist of three layers of artificial units: the input, hidden, and output layers. For both RNN1 and RNN2, the input layer contains 20 units including 15 orientation-tuned, red units and 5 cue units (retro-cue and task cue, orange and yellow). The hidden layer consists of three modules of 200 recurrent units with short-term synaptic plasticity (STSP), further divided into 80% excitatory (black) and 20% inhibitory (white). Connectivity within each module (black arrow) is denser compared to between modules (red and green arrows), which only occur between excitatory units. Only excitatory units in module 1 receive projections from the input layer and only excitatory units in module 3 project to the output units. For RNN1, networks output (0,1) or (1,0) through the 2 units in the output layer to indicate responses. For RNN2, the network output (0,1) or (1,0) to report the category to which the cued orientation belonged in the categorization task, or (0,0) in the maintenance task (blue units). Importantly, the models also output the orientation itself through 15 additional orientation-tuned units (red). (<bold>B</bold>) Difference in stimulus decoding between tasks in RNN1 (upper panel; n = 20) and RNN2 (lower panel; n = 20). Results were averaged across the delay period. Positive difference indicates higher decoding accuracy for the categorization task, and negative difference indicates higher decoding accuracy for maintenance. The inset above illustrates stimulus difference in human fMRI results during late epoch in Experiment 1 to provide a reference for expected patterns in RNNs. (<bold>C</bold>) Average abstract category information across the delay period for RNN1 (upper panel) and RNN2 (lower panel). The inset above illustrates abstract category representation in human fMRI. Error bars represent ± SEM. Black asterisks denote FDR-corrected significance, *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Recurrent neural network (RNN) results using inverted encoding models (IEMs).</title><p>Difference in the IEM fidelity of orientation representations between tasks in RNN2 (n = 20). Results were averaged across the delay period. Uncorrected p-values from Module 1–3: 0.10, 0.48, 0.01. Positive difference indicates higher fidelity for the categorization task, and negative difference indicates higher fidelity for the maintenance task. Error bars represent ± SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig6-figsupp1-v1.tif"/></fig></fig-group><p>After successful training, defined as reaching at least 90% accuracy in all tasks in the same training batch, we applied an SVM decoding approach to investigate population-level stimulus representations in neuronal spiking activities of the RNNs. We found that in RNN1, both the middle and anterior modules showed stronger stimulus representation in the maintenance task than the categorization task during the delay period (<italic>p<sub>posterior</sub></italic> = 0.09,<italic>p</italic><sub>middle</sub> = 0.011, <italic>p</italic><sub>anterior</sub> = 0.007; <xref ref-type="fig" rid="fig6">Figure 6B</xref> upper panel), opposite to our fMRI observation in IPS and sPCS (<xref ref-type="fig" rid="fig6">Figure 6B</xref> inset). In comparison, decoding performance in RNN2, which was explicitly required to maintain stimulus information for the output, yielded results consistent with our human findings, with increased stimulus decoding performance during categorization only in the anterior module (<italic>p</italic><sub>posterior</sub> = 0.436<italic>, p</italic><sub>middle</sub> = 0.212, <italic>p</italic><sub>anterior</sub> = 0.026; <xref ref-type="fig" rid="fig6">Figure 6B</xref> lower panel).</p><p>Besides the difference in stimulus representation, we further tested whether RNN2 could also replicate the human results on category representation. For this analysis, we focused on abstract category representation to fully remove the impact of stimulus on category decoding. To examine the influence of control demand on category decoding, following our fMRI experiment, we trained 20 additional RNNs with the same output structure as RNN2 (preserving stimulus information) to perform the tasks with a fixed categorization rule, mimicking the task structure of Experiment 2. Consistent with our human findings, we observed increased abstract category decoding performance in the fixed-rule models compared to the flexible-rule RNNs, throughout the modules (<italic>p<sub>posterior</sub> =</italic> 0.045<italic>, p</italic><sub>middle</sub> = 0.003, <italic>p</italic><sub>anterior</sub> &lt;0.001; <xref ref-type="fig" rid="fig6">Figure 6C</xref> lower panel). Similar differences between fixed-rule and flexible-rule models were also observed in RNN1 (all <italic>p</italic>s &lt;0.001; <xref ref-type="fig" rid="fig6">Figure 6C</xref> upper panel).</p><p>To quantify the similarity between human and RNN in terms of stimulus and category representations, we performed representational similarity analysis (RSA) comparing human and RNN data across tasks. Specifically, we aligned the RDMs by either stimulus (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) or category (<xref ref-type="fig" rid="fig7">Figure 7C</xref>) to prioritize the comparison of stimulus or category representations, respectively. Overall, across experiments, RNN2 consistently demonstrated higher similarity to human data than RNN1, particularly in Module 3 that corresponds to the frontal cortex (<xref ref-type="fig" rid="fig7">Figure 7B and D</xref>). In terms of the RDM patterns, consistent with previous results, RNN2 exhibited stronger stimulus representation than RNN1. Moreover, fixed-rule RNNs were found to be more categorical than flexible-rule RNNs regardless of the output structure. Altogether, these findings demonstrated that our fMRI results could be simulated by RNN models when stimulus information for readout was preserved, suggesting that the requirement for flexible control of WM content could demand high-fidelity stimulus representation at the output stage of the model. Notably, we found that RNN2 generally took fewer iterations for training and had fewer failures in learning the task (with a defined maximal number of iterations).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Representational similarity between recurrent neural network (RNN) and human data.</title><p>(<bold>A</bold>) Averaged representational dissimilarity matrices (RDMs) for RNN1 and RNN2 under flexible rule (upper panel; n = 20) and fixed rule (lower panel; n = 20), with data aligned to stimulus. Individual RDM was constructed by calculating the Pearson correlation distance between activation across trials and averaging across the delay period for each orientation and task. Before averaging, each RDM was aligned to stimulus, with orientations sorted from 1° to 180° and ordered by tasks (maintenance [M], categorization-Rule A [CA], and categorization-Rule B [CB] for flexible rule; maintenance and categorization [C] for fixed rule). (<bold>B</bold>) To quantify the similarity between RNN and human data, Kendall’s Tau correlation coefficients were computed between the RDMs of RNN and human data. Comparisons were performed between flexible-rule RNN and human data from Experiment 1 (top row), and between fixed-rule RNN and human data from early and late epochs of Experiment 2 (middle and bottom rows), for each module and corresponding ROI. Significance of correlation was evaluated using one-sided signed-rank tests. Difference between RNN1 and RNN2 was calculated using Z-transformed correlation coefficient and permutation tests. Black asterisks denote uncorrected significance, *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001. Error bars represent ± SEM. (<bold>C</bold>) Same as (<bold>A</bold>) but with data aligned to category. RDMs for each task were aligned to category and rules, with the first half of rows and columns corresponding to one category and the other half to the other category. RDMs for the two categorization rules were further averaged, resulting in two tasks (M and C). (<bold>D</bold>) Same conventions as (<bold>B</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig7-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we investigated the emergence and maintenance of stimulus representation with varied control demands of WM. In a distributed human cortical network encompassing visual, parietal, and frontal cortex, we found enhanced stimulus representation in the frontal cortex that tracked increasing demands on active WM control, as well as enhanced stimulus representation in the visual cortex that tracked the demand for the precise maintenance of WM content. The enhanced stimulus representation in frontal cortex was well predicted by RNNs that preserved stimulus information for readout at the output stage. Together, these results highlight the unique and critical contributions of stimulus representations in different cortical regions for distinct aspects of WM, and help to resolve the current controversy in the roles of various cortices in WM (see <xref ref-type="fig" rid="fig8">Figure 8</xref> for a schematic summary of the fMRI findings).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Schematic summary of the involvement of different cortical regions in the current study.</title><p>Schematic summary of stimulus representation and corresponding behavioral correlation, as well as category representation in early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS) for both Experiment 1 and Experiment 2. √ denotes the presence of the corresponding finding, and × denotes the absence of the corresponding finding in maintenance (blue) and categorization (orange) tasks.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100287-fig8-v1.tif"/></fig><sec id="s3-1"><title>Role of visual cortex in WM maintenance</title><p>The visual cortex has been considered a critical site for maintaining visual WM in the context of sensorimotor recruitment hypothesis (<xref ref-type="bibr" rid="bib18">D’Esposito and Postle, 2015</xref>; <xref ref-type="bibr" rid="bib33">Harrison and Tong, 2009</xref>). This idea, however, has been challenged in recent years due to some seemingly contradictory findings from the human neuroimaging studies. For example, compared to the frontoparietal cortex, mnemonic representations in EVC were found to be more vulnerable to distractors (<xref ref-type="bibr" rid="bib6">Bettencourt and Xu, 2016</xref>; <xref ref-type="bibr" rid="bib32">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Lorenc et al., 2018</xref>). The decodability of memory contents in visual cortex also depends on the specific task type. A previous study showed that in nonvisual tasks that required judgments on object category instead of visual details, memory contents were no longer decodable in the visual cortex (<xref ref-type="bibr" rid="bib38">Lee et al., 2013</xref>). In this study, we found that, although the strength of stimulus representation in EVC differed between WM maintenance and categorization tasks, a copy of stimulus representation remained in EVC during the categorization task. Moreover, stimulus representations in both tasks were equally predictive of subsequent memory performance, suggesting the functional significance of EVC representations in WM.</p><p>The discrepancy between our results and that of the previous work (<xref ref-type="bibr" rid="bib38">Lee et al., 2013</xref>) could be attributed to the fact that our categorization task required participants to manipulate remembered information according to arbitrary yet flexible categorization rules, rather than simply paying selective attention to different aspects (visual details vs. category membership) of everyday objects. In our case, maintaining visual details of the memoranda was critical for accurate behavioral responses. Our finding is consistent with the prediction of sensorimotor recruitment hypothesis that representation of memory contents in the visual cortex is necessary for the precise maintenance of visual information. The observation of robust category representation in EVC during the response period further indicated the recruitment of EVC in categorization, possibly for boundary comparison and rule implementation. In fact, our results are consistent with a recent study demonstrating significant stimulus representation in EVC even when memoranda had been transformed into a motor format (<xref ref-type="bibr" rid="bib34">Henderson et al., 2022</xref>). In addition, electrophysiological research in non-human primates has also shown robust feature selectivity in the visual cortex during a categorization task (<xref ref-type="bibr" rid="bib8">Brincat et al., 2018</xref>), and recent computational modeling work has suggested intact maintenance of sensory information during categorical judgments (<xref ref-type="bibr" rid="bib42">Luu and Stocker, 2021</xref>).</p></sec><sec id="s3-2"><title>Role of frontal cortex in active WM control</title><p>Compared to the prominent role of EVC in memory maintenance, sPCS in the frontal cortex played a dominant role in WM tasks that require active control of memory contents such as categorization. Although stimulus representations in sPCS have been observed during WM in previous studies, the nature of these representations remained debatable. In WM tasks that required mere maintenance of memoranda, stimulus was not always decodable in the frontal cortex (<xref ref-type="bibr" rid="bib19">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Riggall and Postle, 2012</xref>), raising the issue of functional significance of stimulus representation in the frontal cortex. On the other hand, stimulus representation in the frontal cortex could become robust in the face of tasks that require attentional prioritization and extensive training (<xref ref-type="bibr" rid="bib6">Bettencourt and Xu, 2016</xref>; <xref ref-type="bibr" rid="bib12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Lorenc et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Miller et al., 2022</xref>). Our current study contributes to the resolution of this issue by demonstrating that stimulus representation in sPCS increased with increasing demands for WM control. This finding is in line with recent computational studies proposing that active WM functions may involve neuronal mechanisms different from that for passive maintenance. For example, passive maintenance could rely mainly on synaptic plasticity mechanisms, whereas active control functions such as distractor resistance and information manipulation involve more neuronal spiking activity (<xref ref-type="bibr" rid="bib44">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="bib58">Wang, 2021</xref>). In this study, we provided the first empirical evidence that the frontal cortex exhibits enhanced stimulus representation in categorization task requiring active WM control and this representation is predictive of WM performance. In contrast, stimulus representation of WM maintenance failed to predict WM performance at high control demand. Moreover, by examining additional ROIs in the frontal cortex (i.e. iPCS, IFS, and MFG), we found that results in these brain regions were overall weaker, with the MFG demonstrating the most comparable, albeit much weaker, results to sPCS. The specific involvement of sPCS in our experiment could be due to the type of stimulus (i.e. orientation) we used, as previous work has highlighted a prominent role of sPCS in encoding stimulus-specific information in spatial (<xref ref-type="bibr" rid="bib32">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="bib55">Sprague and Serences, 2013</xref>) and orientation WM (<xref ref-type="bibr" rid="bib22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>; <xref ref-type="bibr" rid="bib60">Yu and Shim, 2019</xref>), but to a lesser extent in other WM tasks such as color (<xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>; <xref ref-type="bibr" rid="bib60">Yu and Shim, 2019</xref>). It would be of interest to further investigate whether this active control in the sPCS could be generalized to other frontal regions and tasks that require other types of WM control such as mental rotation (<xref ref-type="bibr" rid="bib54">Shi and Yu, 2024</xref>), and how other types of control task may adapt to changing flexible control demands.</p></sec><sec id="s3-3"><title>WM representations in frontal cortex support cognitive flexibility</title><p>Our results in the frontal cortex are also in line with recent theoretical proposals in the field of cognitive flexibility. To behave flexibly in complex environments with limited cognitive resources, two mechanisms have been proposed: low-dimensional abstraction of stimulus representation for generalization and efficient learning, and high-dimensional stimulus representation for separability and flexible readout (<xref ref-type="bibr" rid="bib5">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Flesch et al., 2022</xref>; <xref ref-type="bibr" rid="bib28">Fusi et al., 2016</xref>). Within this framework, high-dimensional stimulus representation during WM might emerge in the frontal cortex in response to complex control demands such as rule-based categorization. The results of the two fMRI experiments in the current study jointly demonstrate a dynamic tradeoff between high-dimensional stimulus and low-dimensional category representations depending on the control demand. Specifically, when control demand was reduced with a single categorization rule in Experiment 2 compared to Experiment 1, the differential stimulus representation in the frontal cortex was also reduced during the late delay period, accompanied by an increase in category decoding performance especially in the frontal cortex. This result is consistent with neurophysiological findings in non-human primates: while robust category selectivity was observed in frontoparietal cortex during the delay period of categorization tasks when the animal was trained on the categorization task only (<xref ref-type="bibr" rid="bib8">Brincat et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Freedman and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib25">Freedman et al., 2001</xref>; <xref ref-type="bibr" rid="bib45">McKee et al., 2014</xref>), category selectivity in the parietal cortex was significantly reduced when the animal had been exposed to a maintenance task prior to categorization training (<xref ref-type="bibr" rid="bib36">Latimer and Freedman, 2023</xref>). Our RNN simulation further confirmed that this dynamic reconfiguration in information coding at the network level can be well explained by a change in the coding strategy for the network readout. In other words, in flexible environments, and with rich prior experience, the brain might adopt an entirely different strategy for processing information in WM. High-dimensional stimulus information might be preserved in its original identity in the higher-order cortex, potentially reducing processing demands in dealing with each task and thereby facilitating efficiency and flexibility (<xref ref-type="bibr" rid="bib5">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Flesch et al., 2022</xref>; <xref ref-type="bibr" rid="bib28">Fusi et al., 2016</xref>). One important future direction would be to further address the meta-control mechanisms that determine the flexible selection of coding strategies for WM (<xref ref-type="bibr" rid="bib20">Eppinger et al., 2021</xref>).</p></sec><sec id="s3-4"><title>Differentiating between frontal and parietal cortex in WM functions</title><p>While many previous WM studies have focused on the functional distinction between sensory and frontoparietal cortex, it has remained less clear how frontal and parietal cortices might differ in terms of WM functions. Some studies have reported stimulus representations with similar functionality in frontal and parietal cortex (<xref ref-type="bibr" rid="bib12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="bib60">Yu and Shim, 2019</xref>), while others have observed differential patterns (<xref ref-type="bibr" rid="bib35">Hu and Yu, 2023</xref>; <xref ref-type="bibr" rid="bib38">Lee et al., 2013</xref>; <xref ref-type="bibr" rid="bib39">Li et al., 2023</xref>). We interpret the differential patterns as reflecting a difference in the potential origin of the corresponding cognitive functions. For example, in our study, sPCS demonstrated the most prominent effect for enhanced stimulus representation during categorization as well as the tradeoff between stimulus difference and category representation, suggesting that sPCS might serve as the source region for such effects. On the other hand, IPS did show visually similar patterns to sPCS in some analyses. For instance, stimulus representation in IPS was visually but not statistically higher in the categorization task. Additionally, stimulus representation in IPS also predicted behavioral performance in the categorization task. These results together support the view that our findings in sPCS do not occur in isolation, but rather reflect a dynamic reconfiguration of functional gradients along the cortical hierarchy from early visual to parietal and then to frontal cortex.</p></sec><sec id="s3-5"><title>The alignment between RNN and fMRI results</title><p>Although the current RNNs effectively captured our key fMRI findings, including increased stimulus representation in the frontal cortex as well as the tradeoff in category representation with varying control demands, we acknowledge that differences remain between the two modalities. For instance, all three RNN modules demonstrated significant abstract category decoding as well as differences in category decoding between experiments, which differed from our fMRI results. This discrepancy could partially be due to the higher signal sensitivity in RNNs. In addition, RNN2 did not show decreased stimulus decoding for categorization in the EVC module. However, we found that applying IEMs to the RNN data revealed a similar negative trend in the EVC module (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>), though it was not statistically significant. This result suggests that any negative difference between categorization and maintenance in EVC module was weaker compared to fMRI, if existed. We speculate that enhancing the negative difference in the EVC module might require additional modules or inputs to strengthen fine-grained stimulus representation in EVC, a mechanism that could be of interest for future research.</p></sec><sec id="s3-6"><title>Conclusion</title><p>In conclusion, we observed a distributed cortical network, including early visual, parietal, and frontal cortex, in representing stimulus-specific information in WM. These stimulus representations in visual and frontal cortex played distinct functional roles, with those in EVC contributing primarily to precise maintenance and those in frontal cortex contributing primarily to active control in WM. RNN simulations indicated that the stimulus representation in the frontal cortex might have emerged as a result of output selection to facilitate cognitive flexibility. Collectively, these results help to reconcile current debates on the functional roles of different cortical regions in WM, and provide new insights into how a unified WM framework could support varied control demands.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>A total of 54 participants were recruited at the Chinese Academy of Sciences, Shanghai Branch. Twenty-six healthy participants (21 female, all right-handed, mean age = 24.0 ± 1.4 y) were recruited for Experiment 1. Two were excluded due to failure in completing the experiment or low conformity to task instructions, remaining 24 participants who completed the main experiment (19 female, mean age = 23.92 ± 1.41 y). Twenty-eight (22 female, mean age = 24.14 ± 1.51 y) participants were recruited for Experiment 2. Two quitted after behavioral training and two did not finish scanning due to technical problems with the scanner, resulting in 24 participants (20 female, mean age = 24.13 ± 1.60 y) in the final analyses. All participants were neurologically healthy and eligible for MRI, had normal or corrected-to-normal vision, provided written informed consent approved by the Ethics Committee of the Institute of Neuroscience, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences (CEBSIT-2020028), and were monetarily compensated for their participation. Sample sizes were not estimated a priori but were comparable and even superior to those in previous studies.</p></sec><sec id="s4-2"><title>Stimuli and procedure</title><p>All stimuli were generated and presented using MATLAB (The MathWorks) and Psychtoolbox 3 extensions (<xref ref-type="bibr" rid="bib7">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib50">Pelli, 1997</xref>). During behavioral training, stimuli were presented on a ThinkVision monitor at a viewing distance of 45 cm. Behavioral responses were acquired with a keyboard. During scanning, stimuli were projected onto a SinoRad monitor (1280×1024 pixels, refreshing at 60 Hz) viewed through a coil-mounted mirror in the scanner at a viewing distance of 90.5 cm. Participants’ behavioral responses were acquired with a Sinorad MRI-compatible button box.</p><sec id="s4-2-1"><title>Behavioral training</title><p>In Experiment 1, prior to scanning, participants were trained to learn two novel rules, Rule A and Rule B, for categorizing orientations. Thirty oriented bars were used as sample stimuli, ranging from 5° to 179° (in increments of 6°; two participants used another set of thirty orientations ranging from 4° to 178°). Each abstract rule was constructed by two orthogonal boundaries that divided the thirty orientations into two categories with fifteen orientations each. Rule A and Rule B were orthogonal to each other. Corresponding boundaries were 20°/110° and 65°/155° (15°/105° and 60°/150° for the two participants using different stimuli sets).</p><p>Participants learned new rules through a rule-learning task. Each run of learning started with a rule disk informing the target rule. To avoid any potential verbal coding, rule specifics were visually illustrated as rule disks containing two distinct colors (colors randomly assigned to categories every time; see <xref ref-type="fig" rid="fig1">Figure 1A</xref> for an example). Rule disk was presented on the screen for 2 s followed by 1 s of fixation. On each trial, an oriented bar (radius = 7°) was presented for 1 s followed by a delay of 1 s. Participants were instructed to report the category of the orientation by pressing a response key (‘F’ or ‘J’). To avoid category-response mapping, we randomized the relationship between categories and key buttons across trials. Moreover, to avoid presenting rule boundaries explicitly, we presented key names at random positions within the range defining each category. In other words, participants had to memorize the exact rule boundaries as accurately as possible in order to find the correct key buttons for each trial. Feedback was given at the end of each trial to assist learning.</p><p>Participants completed 30 learning trials in each run. They reviewed rule disks after every 10 trials for memory reconsolidation. Each participant completed at least two runs for each rule. After achieving an average accuracy above 86% (26 out of 30 trials) for the first rule, they proceeded to learn the other rule and then to practice the main task for scanning (see next section). Learning order of rules was counterbalanced across subjects. Upon completion of practicing, participants needed to report the boundaries of learned rules as a qualification of behavioral training. If the total error in reported boundaries had exceeded 20°, participants had one more chance to learn by repeating the learning task. Two participants completed one additional behavioral training to recap rule knowledge prior to scanning.</p><p>Behavioral training for Experiment 2 followed the same procedure and used the identical sample set (30 orientations ranging from 4° to 178°, in increments of 6°) as Experiment 1, except that only one rule was trained. Half of the participants in Experiment 2 learned rule boundaries of 19°/109°; the other half learned rule boundaries of 67°/157°.</p></sec><sec id="s4-2-2"><title>Flexible WM task (fMRI task)</title><p>In Experiment 1, during scanning, participants completed a flexible WM task which implemented levels of control demand with different rules. To be specific, participants randomly switched between a maintenance task and a categorization task. In the maintenance task, participants needed to memorize stimulus information (i.e. orientations). In the categorization task, participants needed to categorize orientations following the rule that was randomly assigned and cued on a block basis. Procedure of the main task was visualized in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. At the beginning of each block, participants were presented with a rule disk for 3 s, followed by a 2 s interval, instructing the categorization rule of the current block. For each trial, participants saw two oriented bars presented successively. Each bar was presented for 0.75 s, with an inter-stimulus-interval of 0.5 s. Sample sets were the same as those used in behavioral training. After a 0.5 s interval, a retro-cue occurred for 0.5 s, indicating the orientation of which participants should remember. After a 1.5 s delay, a task cue was displayed at fixation for 0.5 s, followed by an 8 s memory delay. The task cue was either a letter ‘P’ on maintenance trials, instructing participants to maintain the cued orientation during memory delay as precisely as possible; or the task cue was a letter ‘C’ on categorization trials, asking participants to categorize the cued orientation using the block rule during the delay. Then, participants were probed to respond within 2 s. On maintenance trials, participants needed to select the memorized orientation from two probe orientations; while on categorization trials, participants needed to report the category of the cued orientation. Response mapping followed the same operation as in the learning tasks. Inter-trial-intervals were randomly selected from 3, 5, and 7 s with an equal trial number, resulting in an average trial length of 20 s. Participants switched to the next block after every six categorization trials and three maintenance trials. Each run contained two blocks (i.e. 18 trials).</p><p>In Experiment 2, to isolate potential effect of rule switching, the categorization rule stayed the same throughout the experiment. In Experiment 2, participants randomly switched between the maintenance task and the categorization task. Each trial followed the same procedure as Experiment 1.</p><p>In Experiment 1, orientations, tasks, and cued target order (first or second) were counterbalanced across trials, resulting in an equal trial number of 90 across all three conditions (categorization-Rule A, categorization-Rule B, and maintenance). Nineteen out of the twenty-four participants completed 15 runs of the main task. One participant completed 13 runs due to technical difficulties with the scanner. Another four participants completed 30 runs across two scan sessions. The same counterbalancing procedure was conducted for Experiment 2 (90 trials for maintenance task and 180 trials for categorization task). In Experiment 2, six participants completed 15 runs of 18 trials; the other seven completed 18 runs of 15 trials each due to scanner limitations. At the end of scanning, participants reported the rule boundaries three times as a final check of their rule memory.</p></sec></sec><sec id="s4-3"><title>Data acquisition</title><p>MRI data of Experiment 1 were collected using a 3 Tesla Siemens MRI scanner (Tim Trio; Siemens Healthineers) with a 32-channel head coil at the Functional Brain Imaging Platform at the Institute of Neuroscience, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences. Functional scanning was performed using a gradient-echo echo-planar sequence with the following parameters: repetition time (TR)=1000 ms; echo time (TE)=30 ms; flip angle (FA)=40°; voxel size = 3 × 3 × 3 mm; multi-band accelerate factor = 4; matrix size = 74 × 74; slice number = 60. A high-resolution anatomical T1 image was collected before functional scanning (TR = 2300 ms; TE = 2.98 ms; FOV = 256 × 240 × 192 mm; voxel size = 1 × 1 × 1 mm). During scanning, participants’ head positions were restricted with surrounding paddings to prevent head movements. MRI data of Experiment 2 were collected using identical procedures and settings except that the last eleven participants were scanned using a newly installed 3 Tesla Siemens MRI scanner (Prisma; Siemens Healthineers) at the Functional Brain Imaging Platform.</p></sec><sec id="s4-4"><title>Preprocessing</title><p>All preprocessing of individual MRI data was performed using AFNI (<ext-link ext-link-type="uri" xlink:href="https://afni.nimh.nih.gov/">https://afni.nimh.nih.gov/</ext-link>) (<xref ref-type="bibr" rid="bib13">Cox, 1996</xref>; <xref ref-type="bibr" rid="bib14">Cox and Hyde, 1997</xref>). Functional data of all runs were registered to the last volume of the final run with the first eight volumes of each run removed. Then, individuals’ aligned functional data were registered to their corresponding T1 volume. Alignment of registration was manually checked for each subject to ensure quality. The registered data were further motion corrected and detrended.</p></sec><sec id="s4-5"><title>ROI definition</title><p>Our primary ROI-based analyses focused on three most commonly-studied, WM-related brain areas: early visual cortex (EVC), intraparietal sulcus (IPS) in parietal cortex, and superior precentral sulcus (sPCS) in frontal cortex (<xref ref-type="bibr" rid="bib22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>). We created anatomical ROI masks based on the probabilistic atlas by Wang and colleagues (<xref ref-type="bibr" rid="bib57">Wang et al., 2015</xref>). EVC (merging bilateral V1, V2, and V3), IPS (merging bilateral IPS0-5), and sPCS (merging bilateral FEF) masks were generated by warping masks from the probabilistic atlas to individuals’ anatomical image in their native space. In order to generate functional ROI masks, we then performed general linear models (GLMs) to quantify task-related univariate activity changes in each voxel. Task events were modeled using boxcar functions convolved with a canonical hemodynamic response function (durations of event epochs for sample, post retro-cue delay, memory delay, and response were 2.5 s, 2 s, 8.5 s, and 2 s, respectively). Six nuisance regressors were also included to account for head motion artifacts in the six dimensions of rigid body motion. Functional EVC mask was defined by the 500 most active voxels during sample display. Functional IPS and sPCS masks were defined by the 500 most active voxels during memory delay. Additional ROIs in the frontal cortex were defined using the HCP atlas (<xref ref-type="bibr" rid="bib30">Glasser et al., 2016</xref>), including the inferior precentral sulcus (iPCS, generated by merging 6v, 6r, and PEF), inferior frontal sulcus (IFS, generated by merging IFJp, IFJa, IFSp, IFSa, and p47r), middle frontal gyrus (MFG, generated by merging 9-46d, 46, a9-46v, and p9-46v), and primary motor cortex (M1).</p></sec><sec id="s4-6"><title>MRI data analyses</title><sec id="s4-6-1"><title>Multivariate inverted encoding modeling (IEM)</title><p>Neural representations of orientations were reconstructed using IEM (<xref ref-type="bibr" rid="bib9">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib10">Brouwer and Heeger, 2011</xref>; <xref ref-type="bibr" rid="bib22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib51">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="bib59">Yu and Shim, 2017</xref>) with custom MATLAB scripts on individuals’ BOLD activation patterns in the ROIs. IEM provides an estimate of population-level reconstructions of stimulus-specific information. The general procedure for IEM includes using training data to train model weights and then applying weights to testing data to obtain reconstructed channel responses. For the main analyses, we used trials from all conditions to train and to test IEM in order to avoid potential biases from a specific task condition. Results for categorization task were averaged across rules for Experiment 1. Training and testing were performed for each TR separately. As a control, IEMs were also estimated for each condition separately (within-condition IEM). Training and testing underwent a leave-one-run-out cross-validation procedure, in which each run was taken out as the testing run, and the rest of the data served as the training run. This procedure was iterated until all runs had served as training and testing runs. Results from all cross-validated folds were averaged. Detailed computations for each fold were elucidated below:</p><p>We first modeled responses of voxels into nine equidistant orientation channels (initial channels were 1°, 21°, 41°, 61°, 81°, 101°, 121°, 141°, 161°), characterizing voxel selectivity for orientations. At each channel, the modeled orientation tuning curve was a half-wave-rectified sinusoid raised to eighth power, defined as the function below (<inline-formula><mml:math id="inf1"><mml:mi>c</mml:mi></mml:math></inline-formula> was the center of the channel):<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∫</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Population-level tuning responses of voxels were described using the function:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was the training dataset from our fMRI data (<inline-formula><mml:math id="inf3"><mml:mi>v</mml:mi></mml:math></inline-formula> voxels <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>×</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> trials). <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> represented the hypothesized channel responses (<inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> channels <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>×</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> trials) which were modulated by <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, a weight matrix (<inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> voxels <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>×</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> channels).</p><p>The least-squared estimates of the weight matrix (<inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) was computed using linear regression:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The weight matrix was then applied to the test dataset to reconstruct estimated channel responses (<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>):<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The analysis above was repeated for 20 times in step of 1° using leave-one-run-out cross-validation so that the nine channel centers covered all 180 orientations (<xref ref-type="bibr" rid="bib51">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Yu and Postle, 2021</xref>). All channel responses were combined to create responses for all 180 orientation channels. For statistical comparisons and for visualization, all channel responses were shifted to a common center of 0° (true orientation of trials). The responses from all trials were averaged to obtain reconstructed orientation representations for the test datasets.</p><p>To quantify the strength of each IEM reconstruction, we calculated reconstruction fidelity of channel responses (<xref ref-type="bibr" rid="bib51">Rademaker et al., 2019</xref>). First, channel responses of each trial were shifted so that the orientation of each trial was centered in stimulus space. Thus, for each shifted channel response with a vector length of <italic>r</italic> at orientation <italic>θ</italic>, the orientation was wrapped onto a 2π circular space, and <italic>r</italic> was projected to the vector at the true orientation (center of stimulus space, 0°) using the absolute angle between the channel and the center following the equation:<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The reconstruction fidelity was then calculated as the mean of all projected vectors <italic>d</italic>. A larger fidelity value indicates a stronger positive representation of orientation.</p></sec><sec id="s4-6-2"><title>Multivariate pattern analysis (MVPA)</title><p>Besides IEM, we tracked neural representations of stimulus and of category using linear Support Vector Machine (SVM) decoders. All decoding analyses were performed using the templateSVM and fitcecoc functions in MATLAB.</p><p>Decoding of stimulus was performed for every time point. We divided the thirty orientations into four bins of 45° each, two cardinal bins centered at 90° or 180° and two oblique bins centered at 45° or 135°. We then performed two two-way classifications, one trained and tested on cardinal bins, and the other trained and tested on oblique bins. We trained and tested decoders separately for each condition using the same leave-one-run-out cross-validation procedure as in IEM analyses. To avoid biases in model training, we randomly balanced the trial numbers for each bin in the training set. Decoding accuracies were then computed by averaging performance of cardinal and oblique classifiers. For the categorization task, we averaged accuracies across rules.</p><p>Decoding of category information for Experiment 1 was performed under each rule (90 trials for each rule) using a leave-one-trial-out cross-validation procedure (see next paragraph for details), and the decoding accuracies were then averaged across rules. Since Experiment 2 adopted a fixed rule with 180 trials in the categorization task, we randomly divided categorization trials into two halves with 90 trials each, and decoded category information for Experiment 2 using identical procedures as for Experiment 1.</p><p>Because closer orientations are more similar to each other inherently, orientations per se could contain categorical information by visual similarity. Thus, to isolate the influence of stimulus on category, in addition to the decoder using true category labels, we trained an opposite category decoder using category labels based on the opposite rule. If the two-way classification on categories only captured stimulus information, then true category and opposite category decoding should have had comparable performance. If abstract category information existed beyond stimulus information, then true category decoder should have outperformed the opposite category decoder. Thus, an abstract category index was calculated by subtracting opposite category decoding accuracy from true category decoding accuracy (i.e. chance level = 0). Since the opposite category decoding used re-assigned labels, to eliminate imbalance in trial number between true and opposite categories, we used a leave-one-trial-out cross-validation procedure for true category and opposite category decoders. Decoding for Experiment 1 was performed separately for each rule and were then averaged. Decoding for Experiment 2 was performed separately for randomly divided halves and averaged.</p></sec><sec id="s4-6-3"><title>Representational similarity analysis and linear mixed-effects modeling</title><p>We combined representational similarity analysis (RSA) with linear mixed-effects modeling (LMEM) to resolve contributions of stimulus and of category to the mixed neural representation. First, we constructed three hypothesized representational dissimilarity matrix (RDM) models (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A</xref>): a graded stimulus model (increasing distance between orientations as they move farther apart, corresponding to graded feature tuning responses), a discrete stimulus model (indicating equidistant orientation representations), and an abstract category model (0 for all orientations within the same category and 1 for different categories). Second, population-level neural RDMs were computed by calculating Pearson correlation distance (1 - correlation) on BOLD data between trials; distances were then averaged across time points within each of the 30 orientations and task, resulting in a 30 × 30 matrix for every task. Since there were two rules within individuals in Experiment 1 and across individuals in Experiment 2, to use orientation RDMs with the category RDMs simultaneously, we aligned the category RDMs between different categorization rules. In other words, we shifted the RDMs so that the first 15 rows and columns belonged to one category and the last 15 rows columns belonged to the other category. For instance, in Experiment 1, boundaries of Rule A were 20°/110°. The first 15 orientations in Rule A RDMs would be 22° - 106° and the other 15 orientations being 112° - 16°. With RDMs aligned, we then fitted neural RDMs in each ROI with the three model RDMs using LMEM to test the contribution of each model (graded stimulus, discrete stimulus or category). We used subject as the random effect. Significance of fixed effects was evaluated using p-values of the fixed effect coefficients.</p></sec></sec><sec id="s4-7"><title>Recurrent neural network simulations</title><sec id="s4-7-1"><title>RNN architecture</title><p>The network model was built following the details in previous work (<xref ref-type="bibr" rid="bib44">Masse et al., 2019</xref>), and implemented in TensorFlow (version: Nvidia-tensorflow 1.15.0) (<xref ref-type="bibr" rid="bib1">Abadi et al., 2016</xref>). The general network architecture consists of three layers of artificial units: the input, hidden, and output layers. The input layer contains units served to present various task-related signals corresponding to those in the fMRI paradigm, including orientations, retro-cues, task cues. In order to simulate neural activity patterns in hierarchically connected brain regions (EVC, IPS, and sPCS), we separated the hidden layer into three modules, each containing 200 recurrent units with short-term synaptic plasticity (STSP). Within each module, units were further divided into 80% excitatory and 20% inhibitory following Dale’s principle. Similar to previous work (<xref ref-type="bibr" rid="bib62">Zhou et al., 2021</xref>), modularity was achieved by constraining the recurrent connectivity in the hidden layer. Specifically, only posterior module’s (module 1) excitatory units received inputs from the input layer and only anterior module’s (module 3) excitatory units projected to the output units. Between-module connections were culled so that only 50% of a module’s excitatory units were randomly connected to their counterparts in the neighboring module(s), and vice versa (feedforward and feedback connections). Connections among inhibitory units remained strictly within-module in accordance with the observation that inhibitory connections in cortex are largely local. Thus, posterior, middle, and anterior modules were intended to simulate the three interconnected ROIs we used in the fMRI analyses that posited differently at the processing hierarchy. We specifically manipulated the output demand to investigate whether it would alter similarity of the results to the fMRI observations. To this end, one type of network architecture (RNN1) implemented a two-unit output layer with each unit corresponding to one of two possible response options, presented through the input units before the test period; In contrast, the other type of RNN architecture (RNN2) had additional units in the output layer, creating a demand for preserving the original stimulus information alongside categorical representations.</p></sec><sec id="s4-7-2"><title>Task simulation</title><p>Orientations were simulated as Gaussian signals from 15 orientation-tuned units in the input layer distributed equally across 0–180 degrees, forming a ring of receptive field. The magnitude of an orientation-tuned input unit represented the closeness of its preferred orientation to the input angle. Stimulus values were selected from an array of 20 orientations evenly spanned from (0 to 180) degrees. The sequentially-presented stimuli were presented through the same receptive field, followed by retro-cue and task cue indicated through the separate input units. For RNN1, before the test period when the network was required to make a choice, two response options were presented sequentially through the same input receptive field. The selection of the options varied slightly between the maintenance and categorization tasks: in maintenance, one orientation was always the cued sample while the other was randomly chosen from all other possible angles. In categorization, one option was taken from the same category as the cued sample but not necessarily the exact angle, while the other option was randomly chosen from orientations belonging to the other category. The network output (0,1) or (1,0) in the output units to report its choice. In comparison, RNN2 output (0,1) or (1,0) to report the category to which the cued orientation belonged in the categorization task, or (0,0) in the maintenance task. Importantly, the model also needed to report the cued orientation itself through a receptive field consisting of 15 orientation-tuned units in the output layer.</p></sec><sec id="s4-7-3"><title>Training parameters and procedure</title><p>The hyperparameters and procedure for training the models were consistent with those detailed in previous work (<xref ref-type="bibr" rid="bib44">Masse et al., 2019</xref>), with the following exceptions: standard deviations of input and recurrent noise were set to 0.01 as our tasks were much harder to train compared to those used in the reference study (especially networks were trained on both tasks simultaneously). Lowering the noise level may provide an edge for the models to successfully learn to perform the tasks. In a similar vein, we also expanded the number of hidden units to 600 and number of training iteration to a maximum of 10000. Additionally, spike penalty was set to 0 for both RNN models to remove constraints on neuronal activity.</p><p>We trained 20 models for each type of RNN and results were obtained by averaging over all of them (for single-rule RNN, 10 models for each categorization rule). The goal of the training process was to minimize the mean square error between the model outputs and correct outputs during the test period via back propagation (with a 50 ms grace period at onset when model output was not taken into account in calculating error). Training was conducted in a block-interleaved fashion in which each gradient batch consisted of 300 maintenance, 300 categorization Rule A, and 300 categorization Rule B trials, with the task block order randomized (for single rule RNN, each batch consisted of 300 maintenance and 300 categorization trials). Training would automatically stop if the model achieved 90% accuracy in the last training batch on all tasks. For RNN2, the accuracies for category and stimulus outputs were calculated separately to ensure precision of the stimulus outputs.</p></sec><sec id="s4-7-4"><title>Population decoding</title><p>We measured the strength of stimulus and category representations through training SVMs on time-resolved neuronal activity. Activities were obtained by feeding new batches of tasks into the already successfully trained networks after freezing all connection weights to prevent further changes to the models’ behaviors. The intrinsic noise for the recurrent layer was also set to 0 for decoding analyses. To ensure accurate decoding results, we sampled large number of trials (900 trials for each condition) and implemented a five-fold cross-validation procedure in which 80% of trials were used as training set and the remaining 20% as testing set in each fold. Decoders were trained separately for each module and time point.</p></sec><sec id="s4-7-5"><title>Representational similarity analysis between RNN and human data</title><p>To quantify the similarity between RNN and human data, we conducted RSA between human and RNNs. First, for each RNN, we constructed RDMs for each module by calculating the Pearson correlation distance between the activation of each time point across trials and then averaging the distance across the delay period within each orientation and task. Human RDMs for early and late epochs were constructed using methods described in the previous section. Only orientations used in both human tasks and simulations were included for RSA. To prioritize the comparison of stimulus or category representation, we aligned the RDMs either by stimulus or category. For align-by-stimulus RDMs, RDMs were aligned to orientations, sorted from 1° to 180°, and in the order of maintenance and categorization tasks. For align-by-category RDMs, RDMs were aligned to categories, with the first half rows and columns under each task corresponding to one category and the other half corresponding to the other category. RDMs for different categorization rules were further averaged.</p><p>Next, for each module in each type of RNN (RNN1 vs. RNN2, flexible vs. fixed rule), we obtained a single model RDM by averaging the RDMs of all the 20 networks. Likewise, we obtained a single RDM for each ROI in each experiment for human data of individual participant. We then calculated Kendall’s Tau correlation coefficients between human and model RDMs for each ROI and the corresponding module, and averaged the coefficient across participants. Significance of the correlation was determined using one-sided signed-rank test. Finally, to compared whether RNN1 or RNN2 was more similar to human patterns, we calculated the difference in Z-transformed coefficients between RNNs. Significance of difference was determined using sign-flip permutation with 1000 iterations (described below).</p></sec></sec><sec id="s4-8"><title>Statistical testing</title><p>Participants’ behavioral performance for the main task was assessed using accuracy and reaction time. Paired t-test was conducted for the two task types (maintenance &amp; categorization) to evaluate differences between conditions.</p><p>Statistical significance was evaluated via a sign-flip permutation procedure for all other fMRI analyses. For example, to characterize the significance of IEM fidelity, we computed the p-value by comparing the true mean fidelity of our sample with a null distribution reflecting no IEM fidelity. The null distribution was created by randomly assigning 1 or –1 to fidelity scores of our sample and then averaging the sign-flipped samples for 10,000 times, resulting in a null distribution of 10,000 fidelity scores. To characterize the difference of IEM fidelity between tasks, we sign-flipped the fidelity sample for each condition and then averaged the difference for 10,000 times. The p-value was calculated by comparing the true mean difference with the generated null distribution of difference. p-values were corrected using FDR across ROIs, time , and tasks for all analyses unless specified. An early (5–10 s; 6<sup>th</sup>-11<sup>th</sup> TR) and late (11–16 s; 12<sup>th</sup>-17<sup>th</sup> TR) task epoch was also defined to facilitate comparisons between ROIs and experiments when needed.</p><p>For RNN decoding results, we pooled decoding accuracies across a critical task period (50–75 time points during delay) to produce summary statistics aligning with what was reported in the fMRI results. Average decoding results were corrected using the FDR method.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All participants provided written informed consent approved by the Ethics Committee of Institute of Neuroscience, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences (CEBSIT-2020028).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-100287-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The codes and data used to reproduce all figures can be found at Science Data Bank: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57760/sciencedb.21184">https://doi.org/10.57760/sciencedb.21184</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Yu</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Dataset and scripts for Stimulus representation in human frontal cortex supports flexible control in working memory</data-title><source>Science Data Bank</source><pub-id pub-id-type="doi">10.57760/sciencedb.21184</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to thank Dr. Mu-ming Poo for valuable comments on an earlier version of the manuscript, and Dr. Tianming Yang for helpful discussions. This work was supported by the Strategic Priority Research Program of the Chinese Academy of Sciences (Grant No. XDB1010202), the Ministry of Science and Technology of China (STI2030-Major Projects 2021ZD0203701, 2021ZD0204202), the National Natural Science Foundation of China (32271089), CAS Project for Young Scientists in Basic Research (YSBR-071), and Shanghai Pujiang Program (22PJ1414400) to QY.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Abadi</surname><given-names>M</given-names></name><name><surname>Barham</surname><given-names>P</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Davis</surname><given-names>A</given-names></name><name><surname>Dean</surname><given-names>J</given-names></name><name><surname>Zheng</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>TensorFlow: A System for Large-Scale Machine Learning</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1605.08695</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Working memory: looking back and looking forward</article-title><source>Nature Reviews. Neuroscience</source><volume>4</volume><fpage>829</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1038/nrn1201</pub-id><pub-id pub-id-type="pmid">14523382</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>193</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.02.004</pub-id><pub-id pub-id-type="pmid">18403252</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname><given-names>D</given-names></name><name><surname>Kayser</surname><given-names>AS</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Frontal cortex and the discovery of abstract action rules</article-title><source>Neuron</source><volume>66</volume><fpage>315</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.025</pub-id><pub-id pub-id-type="pmid">20435006</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badre</surname><given-names>D</given-names></name><name><surname>Bhandari</surname><given-names>A</given-names></name><name><surname>Keglovits</surname><given-names>H</given-names></name><name><surname>Kikumoto</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The dimensionality of neural representations for control</article-title><source>Current Opinion in Behavioral Sciences</source><volume>38</volume><fpage>20</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.07.002</pub-id><pub-id pub-id-type="pmid">32864401</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bettencourt</surname><given-names>KC</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decoding the content of visual short-term memory under distraction in occipital and parietal areas</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>150</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1038/nn.4174</pub-id><pub-id pub-id-type="pmid">26595654</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brincat</surname><given-names>SL</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>von Nicolai</surname><given-names>C</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Gradual progression from sensory to task-related processing in cerebral cortex</article-title><source>PNAS</source><volume>115</volume><fpage>E7202</fpage><lpage>E7211</lpage><pub-id pub-id-type="doi">10.1073/pnas.1717075115</pub-id><pub-id pub-id-type="pmid">29991597</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding and reconstructing color from responses in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>13992</fpage><lpage>14003</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3577-09.2009</pub-id><pub-id pub-id-type="pmid">19890009</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cross-orientation suppression in human visual cortex</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>2108</fpage><lpage>2119</lpage><pub-id pub-id-type="doi">10.1152/jn.00540.2011</pub-id><pub-id pub-id-type="pmid">21775720</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophel</surname><given-names>TB</given-names></name><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decoding the contents of visual short-term memory from human visual and parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>12983</fpage><lpage>12989</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0184-12.2012</pub-id><pub-id pub-id-type="pmid">22993415</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophel</surname><given-names>TB</given-names></name><name><surname>Iamshchinina</surname><given-names>P</given-names></name><name><surname>Yan</surname><given-names>C</given-names></name><name><surname>Allefeld</surname><given-names>C</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cortical specialization for attended versus unattended working memory</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>494</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0094-4</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title><source>Computers and Biomedical Research, an International Journal</source><volume>29</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><pub-id pub-id-type="pmid">8812068</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name><name><surname>Hyde</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Software tools for analysis and visualization of FMRI data</article-title><source>NMR in Biomedicine</source><volume>10</volume><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1002/(sici)1099-1492(199706/08)10:4/5&lt;171::aid-nbm453&gt;3.0.co;2-l</pub-id><pub-id pub-id-type="pmid">9430344</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curtis</surname><given-names>CE</given-names></name><name><surname>Rao</surname><given-names>VY</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Maintenance of spatial and motor codes during oculomotor delayed response tasks</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>3944</fpage><lpage>3952</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5640-03.2004</pub-id><pub-id pub-id-type="pmid">15102910</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’Esposito</surname><given-names>M</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name><name><surname>Ballard</surname><given-names>D</given-names></name><name><surname>Lease</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Maintenance versus manipulation of information held in working memory: an event-related fMRI study</article-title><source>Brain and Cognition</source><volume>41</volume><fpage>66</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1006/brcg.1999.1096</pub-id><pub-id pub-id-type="pmid">10536086</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’Esposito</surname><given-names>M</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name><name><surname>Rypma</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Prefrontal cortical contributions to working memory: evidence from event-related fMRI studies</article-title><source>Exp Brain Res</source><volume>133</volume><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1007/s002210000395</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’Esposito</surname><given-names>M</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cognitive neuroscience of working memory</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>115</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015031</pub-id><pub-id pub-id-type="pmid">25251486</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Emrich</surname><given-names>SM</given-names></name><name><surname>Riggall</surname><given-names>AC</given-names></name><name><surname>Larocque</surname><given-names>JJ</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>6516</fpage><lpage>6523</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5732-12.2013</pub-id><pub-id pub-id-type="pmid">23575849</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eppinger</surname><given-names>B</given-names></name><name><surname>Goschke</surname><given-names>T</given-names></name><name><surname>Musslick</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Meta-control: from psychology to computational neuroscience</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>21</volume><fpage>447</fpage><lpage>452</lpage><pub-id pub-id-type="doi">10.3758/s13415-021-00919-4</pub-id><pub-id pub-id-type="pmid">34081267</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Anderson</surname><given-names>DE</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name><name><surname>Awh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A neural measure of precision in visual working memory</article-title><source>Journal of Cognitive Neuroscience</source><volume>25</volume><fpage>754</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00357</pub-id><pub-id pub-id-type="pmid">23469889</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory</article-title><source>Neuron</source><volume>87</volume><fpage>893</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.013</pub-id><pub-id pub-id-type="pmid">26257053</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Categorical biases in human occipitoparietal cortex</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>917</fpage><lpage>931</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2700-19.2019</pub-id><pub-id pub-id-type="pmid">31862856</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flesch</surname><given-names>T</given-names></name><name><surname>Juechems</surname><given-names>K</given-names></name><name><surname>Dumbalska</surname><given-names>T</given-names></name><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Orthogonal representations for robust context-dependent task performance in brains and neural networks</article-title><source>Neuron</source><volume>110</volume><fpage>1258</fpage><lpage>1270</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.005</pub-id><pub-id pub-id-type="pmid">35085492</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Categorical representation of visual stimuli in the primate prefrontal cortex</article-title><source>Science</source><volume>291</volume><fpage>312</fpage><lpage>316</lpage><pub-id pub-id-type="doi">10.1126/science.291.5502.312</pub-id><pub-id pub-id-type="pmid">11209083</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Experience-dependent representation of visual categories in parietal cortex</article-title><source>Nature</source><volume>443</volume><fpage>85</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1038/nature05078</pub-id><pub-id pub-id-type="pmid">16936716</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Bruce</surname><given-names>CJ</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Mnemonic coding of visual space in the monkey’s dorsolateral prefrontal cortex</article-title><source>Journal of Neurophysiology</source><volume>61</volume><fpage>331</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1152/jn.1989.61.2.331</pub-id><pub-id pub-id-type="pmid">2918358</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons mix: high dimensionality for higher cognition</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id><pub-id pub-id-type="pmid">26851755</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name><name><surname>Alexander</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Neuron activity related to short-term memory</article-title><source>Science</source><volume>173</volume><fpage>652</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1126/science.173.3997.652</pub-id><pub-id pub-id-type="pmid">4998337</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Hacker</surname><given-names>CD</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A multi-modal parcellation of human cerebral cortex</article-title><source>Nature</source><volume>536</volume><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1038/nature18933</pub-id><pub-id pub-id-type="pmid">27437579</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gosseries</surname><given-names>O</given-names></name><name><surname>Yu</surname><given-names>Q</given-names></name><name><surname>LaRocque</surname><given-names>JJ</given-names></name><name><surname>Starrett</surname><given-names>MJ</given-names></name><name><surname>Rose</surname><given-names>NS</given-names></name><name><surname>Cowan</surname><given-names>N</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Parietal-occipital interactions underlying control- and representation-related processes in working memory for nonspatial visual features</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>4357</fpage><lpage>4366</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2747-17.2018</pub-id><pub-id pub-id-type="pmid">29636395</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallenbeck</surname><given-names>GE</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Rahmati</surname><given-names>M</given-names></name><name><surname>Sreenivasan</surname><given-names>KK</given-names></name><name><surname>Curtis</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Working memory representations in visual cortex mediate distraction effects</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4714</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24973-1</pub-id><pub-id pub-id-type="pmid">34354071</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>SA</given-names></name><name><surname>Tong</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding reveals the contents of visual working memory in early visual areas</article-title><source>Nature</source><volume>458</volume><fpage>632</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1038/nature07832</pub-id><pub-id pub-id-type="pmid">19225460</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>MM</given-names></name><name><surname>Rademaker</surname><given-names>RL</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Flexible utilization of spatial- and motor-based codes for the storage of visuo-spatial information</article-title><source>eLife</source><volume>11</volume><elocation-id>e75688</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.75688</pub-id><pub-id pub-id-type="pmid">35522567</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Spatiotemporal dynamics of self-generated imagery reveal a reverse cortical hierarchy from cue-induced imagery</article-title><source>Cell Reports</source><volume>42</volume><elocation-id>113242</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2023.113242</pub-id><pub-id pub-id-type="pmid">37831604</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Latimer</surname><given-names>KW</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Low-dimensional encoding of decisions in parietal cortex reflects long-term training history</article-title><source>Nature Communications</source><volume>14</volume><elocation-id>1010</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-36554-5</pub-id><pub-id pub-id-type="pmid">36823109</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leavitt</surname><given-names>ML</given-names></name><name><surname>Mendoza-Halliday</surname><given-names>D</given-names></name><name><surname>Martinez-Trujillo</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sustained activity encoding working memories: not fully distributed</article-title><source>Trends in Neurosciences</source><volume>40</volume><fpage>328</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2017.04.004</pub-id><pub-id pub-id-type="pmid">28515011</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Goal-dependent dissociation of visual and prefrontal cortices during working memory</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>997</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1038/nn.3452</pub-id><pub-id pub-id-type="pmid">23817547</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Zeng</surname><given-names>X</given-names></name><name><surname>Shao</surname><given-names>Z</given-names></name><name><surname>Yu</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Neural representations in visual and parietal cortex differentiate between imagined, perceived, and illusory experiences</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>6508</fpage><lpage>6524</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0592-23.2023</pub-id><pub-id pub-id-type="pmid">37582626</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>T</given-names></name><name><surname>Cable</surname><given-names>D</given-names></name><name><surname>Gardner</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inverted encoding models of human population response conflate noise and neural tuning width</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>398</fpage><lpage>408</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2453-17.2017</pub-id><pub-id pub-id-type="pmid">29167406</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorenc</surname><given-names>ES</given-names></name><name><surname>Sreenivasan</surname><given-names>KK</given-names></name><name><surname>Nee</surname><given-names>DE</given-names></name><name><surname>Vandenbroucke</surname><given-names>ARE</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Flexible coding of visual working memory representations during distraction</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>5267</fpage><lpage>5276</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3061-17.2018</pub-id><pub-id pub-id-type="pmid">29739867</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luu</surname><given-names>L</given-names></name><name><surname>Stocker</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Categorical judgments do not modify sensory representations in working memory</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008968</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008968</pub-id><pub-id pub-id-type="pmid">34061849</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackey</surname><given-names>WE</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Curtis</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Visual field map clusters in human frontoparietal cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e22974</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.22974</pub-id><pub-id pub-id-type="pmid">28628004</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masse</surname><given-names>NY</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Song</surname><given-names>HF</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1159</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id><pub-id pub-id-type="pmid">31182866</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKee</surname><given-names>JL</given-names></name><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Task dependence of visual and category representations in prefrontal and inferior temporal cortices</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>16065</fpage><lpage>16075</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1660-14.2014</pub-id><pub-id pub-id-type="pmid">25429147</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>An integrative theory of prefrontal cortex function</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>167</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id><pub-id pub-id-type="pmid">11283309</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>JA</given-names></name><name><surname>Tambini</surname><given-names>A</given-names></name><name><surname>Kiyonaga</surname><given-names>A</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Long-term learning transforms prefrontal cortex representations during working memory</article-title><source>Neuron</source><volume>110</volume><fpage>3805</fpage><lpage>3819</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.09.019</pub-id><pub-id pub-id-type="pmid">36240768</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mok</surname><given-names>RM</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Abstract Neural Representations of Category Membership beyond Information Coding Stimulus or Response</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.02.13.947341</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musslick</surname><given-names>S</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Rationalizing constraints on the capacity for cognitive control</article-title><source>Trends in Cognitive Sciences</source><volume>25</volume><fpage>757</fpage><lpage>775</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2021.06.001</pub-id><pub-id pub-id-type="pmid">34332856</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title><source>Spatial Vision</source><volume>10</volume><fpage>437</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1163/156856897X00366</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rademaker</surname><given-names>RL</given-names></name><name><surname>Chunharas</surname><given-names>C</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Coexisting representations of sensory and mnemonic information in human visual cortex</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1336</fpage><lpage>1344</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0428-x</pub-id><pub-id pub-id-type="pmid">31263205</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riggall</surname><given-names>AC</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The relationship between working memory storage and elevated activity as measured with functional magnetic resonance imaging</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>12990</fpage><lpage>12998</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1892-12.2012</pub-id><pub-id pub-id-type="pmid">22993416</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serences</surname><given-names>JT</given-names></name><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Vogel</surname><given-names>EK</given-names></name><name><surname>Awh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Stimulus-specific delay activity in human primary visual cortex</article-title><source>Psychological Science</source><volume>20</volume><fpage>207</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02276.x</pub-id><pub-id pub-id-type="pmid">19170936</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>D</given-names></name><name><surname>Yu</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Distinct neural signatures underlying information maintenance and manipulation in working memory</article-title><source>Cerebral Cortex</source><volume>34</volume><elocation-id>bhae063</elocation-id><pub-id pub-id-type="doi">10.1093/cercor/bhae063</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1879</fpage><lpage>1887</lpage><pub-id pub-id-type="doi">10.1038/nn.3574</pub-id><pub-id pub-id-type="pmid">24212672</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Adam</surname><given-names>KCS</given-names></name><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Rahmati</surname><given-names>M</given-names></name><name><surname>Sutterer</surname><given-names>DW</given-names></name><name><surname>Vo</surname><given-names>VA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inverted encoding models assay population-level stimulus representations, not single-unit neural tuning</article-title><source>Eneuro</source><volume>5</volume><elocation-id>ENEURO</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0098-18.2018</pub-id><pub-id pub-id-type="pmid">29876523</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Mruczek</surname><given-names>REB</given-names></name><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Probabilistic maps of visual topography in human cortex</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3911</fpage><lpage>3931</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu277</pub-id><pub-id pub-id-type="pmid">25452571</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>50 years of mnemonic persistent activity: quo vadis?</article-title><source>Trends in Neurosciences</source><volume>44</volume><fpage>888</fpage><lpage>902</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2021.09.001</pub-id><pub-id pub-id-type="pmid">34654556</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Q</given-names></name><name><surname>Shim</surname><given-names>WM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Occipital, parietal, and frontal cortices selectively maintain task-relevant features of multi-feature objects in visual working memory</article-title><source>NeuroImage</source><volume>157</volume><fpage>97</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.05.055</pub-id><pub-id pub-id-type="pmid">28559190</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Q</given-names></name><name><surname>Shim</surname><given-names>WM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Temporal-order-based attentional priority modulates mnemonic representations in parietal and frontal cortices</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>3182</fpage><lpage>3192</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy184</pub-id><pub-id pub-id-type="pmid">30124789</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Q</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Working memory</article-title><source>Journal of Cognitive Neuroscience</source><volume>66</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01702</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Rosen</surname><given-names>MC</given-names></name><name><surname>Swaminathan</surname><given-names>SK</given-names></name><name><surname>Masse</surname><given-names>NY</given-names></name><name><surname>Zhu</surname><given-names>O</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Distributed functions of prefrontal and parietal cortices during sequential categorical decisions</article-title><source>eLife</source><volume>10</volume><elocation-id>e58782</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.58782</pub-id><pub-id pub-id-type="pmid">34491201</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100287.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Xue</surname><given-names>Gui</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Beijing Normal University</institution><country>China</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This work presents <bold>important</bold> findings that the human frontal cortex is involved in a flexible, dual role in both maintaining information in short-term memory, and controlling this memory content to guide adaptive behavior and decisions. The evidence supporting the conclusions is <bold>compelling</bold>, with a well-designed task, best-practice decoding methods, and careful control analyses. The work will be of broad interest to cognitive neuroscience researchers working on working memory and cognitive control.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100287.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this manuscript, Shao et al. investigate the contribution of different cortical areas to working memory maintenance and control processes, an important topic involving different ideas about how the human brain represents and uses information when no longer available to sensory systems. In two fMRI experiments, they demonstrate that human frontal cortex (area sPCS) represents stimulus (orientation) information both during typical maintenance, but even more so when a categorical response demand is present. That is, when participants have to apply an added level of decision control to the WM stimulus, sPCS areas encode stimulus information more than conditions without this added demand. These effects are then expanded upon using multi-area neural network models, recapitulating the empirical gradient of memory vs control effects from visual to parietal and frontal cortices. Multiple experiments and analysis frameworks provide support for the authors' conclusions, and control experiments and analysis are provided to help interpret and isolate the frontal cortex effect of interest. While some alternative explanations/theories may explain the roles of frontal cortex in this study and experiments, important additional analyses have been added that help ensure a strong level of support for these results and interpretations.</p><p>Strengths:</p><p>- The authors use an interesting and clever task design across two fMRI experiments that is able to parse out contributions of WM maintenance alone along with categorical, rule-based decisions. Importantly, the second experiments only uses one fixed rule, providing both an internal replication of Experiment 1's effects and extending them to a different situation when rule switching effects are not involved across mini-blocks.</p><p>- The reported analyses using both inverted encoding models (IEM) and decoders (SVM) demonstrate the stimulus reconstruction effects across different methods, which may be sensitive to different aspects of the relationship between patterns of brain activity and the experimental stimuli.</p><p>- Linking the multivariate activity patterns to memory behavior is critical in thinking about the potential differential roles of cortical areas in sub-serving successful working memory. Figure 3's nicely shows a similar interaction to that of Figure 2 in the role of sPCS in the categorization vs. maintenance tasks. This is an important contribution to the field when we consider how a distributed set of interacting cortical areas support successful working memory behavior.</p><p>- The cross-decoding analysis in Figure 4 is a clever and interesting way to parse out how stimulus and rule/category information may be intertwined, which would have been one of the foremost potential questions or analyses requested by careful readers.</p><p>- Additional ROI analyses in more anterior regions of the PFC help to contextualize the main effects of interest in the sPCS (and no effect in the inferior frontal areas, which are also retinotopic, adds specificity). And, more explanation for how motor areas or preparation are likely not involved strengthens the takeaways of the study (M1 control analysis).</p><p>- Quantitative link via RDM-style analyses between the RNNs constructed and fMRI data.</p><p>Weaknesses:</p><p>- In the given tasks, multiple types of information codes may be present, and more detail on this possibility could always be added analytically or in discussion. However, the authors have added beneficial support to this comparison in this version of the manuscript.</p><p>- The space of possible RNN architectures and their biological feasibility could always be explored more, but links between the fMRI and RNN data provide a good foundation for this work moving forward.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100287.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The author provide evidence that helps resolve long-standing questions about the differential involvement of frontal and posterior cortex in working memory. They show that whereas early visual cortex shows stronger decoding of memory content in a memorization task vs a more complex categorization task, frontal cortex shows stronger decoding during categorization tasks than memorization tasks. They find that task-optimized RNNs trained to reproduce the memorized orientations show some similarities in neural decoding to people. Together, this paper presents interesting evidence for differential responsibilities of brain areas in working memory.</p><p>Strengths:</p><p>This paper was overall strong. It had a well-designed task, best-practice decoding methods, and careful control analyses. The neural network modeling adds additional insight into the potential computational roles of different regions.</p><p>Weaknesses:</p><p>Few. The RNN-fMRI correspondence could be a little more comprehensive, but the paper contributes a compelling set of empirical findings and interpretations that can inform future research.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100287.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Shao</surname><given-names>Zhujun</given-names></name><role specific-use="author">Author</role><aff><institution>Center for Excellence in Brain Science and Intelligence Technology</institution><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Mengya</given-names></name><role specific-use="author">Author</role><aff><institution>Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Yu</surname><given-names>Qing</given-names></name><role specific-use="author">Author</role><aff><institution>Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Shanghai</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><p>We would like to sincerely thank the reviewers again for their insightful comments on the previous version of our manuscript. In the last round of review, the reviewers were mostly satisfied with our revision but raised a few suggestions and/or remaining concerns. We have further edited the manuscript to address these concerns.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1:</bold></p><p>- An explicit, quantitative link between the RNN and fMRI data is perhaps a last point that would integrate the RNN conclusion and analyses in line with the human imaging data.</p><p><bold>Reviewer #2:</bold></p><p>- Few. While more could be perhaps done to understand the RNN-fMRI correspondence, the paper contributes a compelling set of empirical findings and interpretations that can inform future research.</p></disp-quote><p>To better align the RNN and fMRI results qualitatively, we performed an additional representational similarity analysis (RSA) on the data. Specifically, we computed the representational dissimilarity matrices (RDMs) for fMRI and RNN data separately, and calculated the correlation between the RDMs to quantify the similarity between fMRI data and different RNN models. We found that, consistent with our main claims, RNN2 generally demonstrated higher similarity with the fMRI data compared to RNN1. These results provide further support that RNN2 aligns better with human neuroimaging data. We have included this result (lines 496-505) and the corresponding figure (Figure 7) in the manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1:</bold></p><p>- As Rev 2 mentions, multiple types of information codes may be present, and the response letter Figure 5 using representational similarity (RSA) gets at this question. It would strengthen the work to, at minimum, include this analysis as an extended or supplemental figure.</p></disp-quote><p>Following this suggestion, we have now included Response Letter Figure 5 from the previous round of review in the manuscript (lines 381-387 and Appendix 1 – figure 7).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1:</bold></p><p>- To sum up the results, a possible, brief schematic of each cortical area analyzed and its contribution to information coding in WM and successful subsequent behavior may help readers take away important conclusions of the cortical circuitry involved.</p></disp-quote><p>Following this suggestion, we have added a schematic figure illustrating the contribution of each cortical region in our experiment to better summarize our findings (Figure 8).</p><p>We hope that these changes further clarify the issues and strengthen the key claims in our manuscript.</p></body></sub-article></article>