<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">91034</article-id><article-id pub-id-type="doi">10.7554/eLife.91034</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.91034.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A dynamic neural resource model bridges sensory and working memory</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-326166"><name><surname>Tomić</surname><given-names>Ivan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6046-9642</contrib-id><email>ivn.tomic@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-52567"><name><surname>Bays</surname><given-names>Paul M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4684-4893</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>Department of Psychology, University of Cambridge</institution></institution-wrap><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00mv6sv71</institution-id><institution>Department of Psychology, Faculty of Humanities and Social Sciences, University of Zagreb</institution></institution-wrap><addr-line><named-content content-type="city">Zagreb</named-content></addr-line><country>Croatia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewing Editor</role><aff><institution>Wake Forest School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>03</day><month>05</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP91034</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-08-18"><day>18</day><month>08</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-07-14"><day>14</day><month>07</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.27.534406"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-11-01"><day>01</day><month>11</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.91034.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-03-21"><day>21</day><month>03</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.91034.2"/></event></pub-history><permissions><copyright-statement>© 2023, Tomić and Bays</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Tomić and Bays</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-91034-v1.pdf"/><related-article related-article-type="commentary" ext-link-type="doi" xlink:href="10.7554/elife.98274" id="ra1"/><abstract><p>Probing memory of a complex visual image within a few hundred milliseconds after its disappearance reveals significantly greater fidelity of recall than if the probe is delayed by as little as a second. Classically interpreted, the former taps into a detailed but rapidly decaying visual sensory or ‘iconic’ memory (IM), while the latter relies on capacity-limited but comparatively stable visual working memory (VWM). While iconic decay and VWM capacity have been extensively studied independently, currently no single framework quantitatively accounts for the dynamics of memory fidelity over these time scales. Here, we extend a stationary neural population model of VWM with a temporal dimension, incorporating rapid sensory-driven accumulation of activity encoding each visual feature in memory, and a slower accumulation of internal error that causes memorized features to randomly drift over time. Instead of facilitating read-out from an independent sensory store, an early cue benefits recall by lifting the effective limit on VWM signal strength imposed when multiple items compete for representation, allowing memory for the cued item to be supplemented with information from the decaying sensory trace. Empirical measurements of human recall dynamics validate these predictions while excluding alternative model architectures. A key conclusion is that differences in capacity classically thought to distinguish IM and VWM are in fact contingent upon a single resource-limited WM store.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>short-term memory</kwd><kwd>population coding</kwd><kwd>temporal dynamics</kwd><kwd>delay</kwd><kwd>encoding</kwd><kwd>decoding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.35802/106926</award-id><principal-award-recipient><name><surname>Bays</surname><given-names>Paul M</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Psychophysical measurement and computational modeling show that sensory information cannot contribute directly to a cognitive judgment, but must first be integrated into resource-limited working memory.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Keeping relevant information in an easily accessible state is vital for adaptive behavior in dynamic environments. In the primate visual system, this requirement is met by visual working memory (VWM), the capacity to actively maintain visual information from milliseconds to seconds after a stimulus disappears from view (<xref ref-type="bibr" rid="bib32">D’Esposito and Postle, 2015</xref>; <xref ref-type="bibr" rid="bib69">Pasternak and Greenlee, 2005</xref>; <xref ref-type="bibr" rid="bib58">Ma et al., 2014</xref>; <xref ref-type="bibr" rid="bib11">Bays et al., 2024</xref>). While the contents of VWM are frequently updated to reflect changes in the environment and in behavioral priorities, the visual processing hierarchy itself introduces additional layers of dynamism (<xref ref-type="bibr" rid="bib3">Barlow, 1981</xref>; <xref ref-type="bibr" rid="bib108">Van Essen et al., 1992</xref>). The fidelity of representations therefore evolves from the moment VWM starts accumulating evidence (<xref ref-type="bibr" rid="bib21">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib36">Gold and Shadlen, 2007</xref>) throughout the maintenance period until the information is used for action (<xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>; <xref ref-type="bibr" rid="bib68">Panichello et al., 2019</xref>; <xref ref-type="bibr" rid="bib107">van Ede et al., 2019</xref>).</p><p>Nonetheless, within most theoretical frameworks, VWM is treated as a stationary process whereby representations are measured and modeled as fixed states of the system. One such model of WM is based on principles of neural population coding (<xref ref-type="bibr" rid="bib6">Bays, 2014</xref>; <xref ref-type="bibr" rid="bib84">Schneegans et al., 2020</xref>). In the Neural Resource model, visual information is encoded in the activity of a population of noisy feature-selective neurons (<xref ref-type="bibr" rid="bib57">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib71">Pouget et al., 2000</xref>). The spiking activity of the neural population is constrained by normalization (<xref ref-type="bibr" rid="bib26">Carandini and Heeger, 2011</xref>; <xref ref-type="bibr" rid="bib7">Bays, 2015</xref>), such that the total activity is fixed but flexibly distributed between memoranda, implementing a form of limited memory resource. At retrieval, encoded stimulus values are reconstructed from the noisy spiking activity. This model has provided a quantitative account of patterns of recall error across a range of tasks and stimulus dimensions (<xref ref-type="bibr" rid="bib102">Tomić and Bays, 2024</xref>; <xref ref-type="bibr" rid="bib10">Bays and Taylor, 2018</xref>; <xref ref-type="bibr" rid="bib82">Schneegans and Bays, 2017</xref>; <xref ref-type="bibr" rid="bib8">Bays, 2016a</xref>; <xref ref-type="bibr" rid="bib101">Tomić and Bays, 2018</xref>). However, despite its grounding in principles of neural coding, the basic architecture of the model lacks a temporal dimension to describe the dynamics of memory representations during encoding and maintenance.</p><p>Research on prolonged memory maintenance has demonstrated that the precision of stored representations gradually deteriorates over time (e.g. <xref ref-type="bibr" rid="bib70">Pertzov et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Rademaker et al., 2018</xref>). Computational models attempting to account for these dynamics have often relied on principles of diffusion within an attractor network. In such a network, information is maintained in a sustained pattern of activity, which can be visualized as a ‘bump’ of activity centered on the stored value. Over time, the bump diffuses along the feature dimension due to random fluctuations in neural activity, leading to stochastic changes in the encoded feature value and a gradual loss of information (<xref ref-type="bibr" rid="bib23">Burak and Fiete, 2012</xref>; <xref ref-type="bibr" rid="bib112">Wimmer et al., 2014</xref>). Critically, the neural code diffuses without decay in signal strength. A growing body of empirical support, both at the behavioral (<xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>) and neural level (<xref ref-type="bibr" rid="bib54">Lim et al., 2019</xref>; <xref ref-type="bibr" rid="bib113">Wolff et al., 2020</xref>), identifies diffusion as a key mechanism of memory deterioration.</p><p>In contrast to such gradual deterioration over longer retention intervals, studies that probed memory within a few hundred milliseconds of stimulus offset revealed a precipitous decrease in memory fidelity immediately after a stimulus disappears (<xref ref-type="bibr" rid="bib33">Di Lollo and Dixon, 1988</xref>; <xref ref-type="bibr" rid="bib94">Sperling, 1960</xref>; <xref ref-type="bibr" rid="bib19">Bradley and Pearson, 2012</xref>; <xref ref-type="bibr" rid="bib72">Pratte, 2018</xref>). This early superior recall was attributed to a high-capacity but short-lived form of storage termed iconic memory (IM) (<xref ref-type="bibr" rid="bib62">Neisser, 1967</xref>). An implicit assumption has often been that the behavioral advantage of early cues derives from reading out information directly from IM and circumventing capacity limitations imposed by VWM, however, this idea has not been formally modeled or tested. At the neural level, IM is thought to be supported by a brief period of decaying neural activity in early visual areas following the response elicited by the visible stimulus (<xref ref-type="bibr" rid="bib73">Priebe et al., 2002</xref>; <xref ref-type="bibr" rid="bib81">Rolls and Tovee, 1994</xref>; <xref ref-type="bibr" rid="bib100">Teeuwen et al., 2021</xref>; <xref ref-type="bibr" rid="bib109">van Kerkoerle et al., 2017</xref>). In contrast to later memory dynamics arising due to noise accumulation, early changes in memory fidelity were supported by modulation of the neural signal strength. However, little is known about the read-out of this sensory memory buffer.</p><p>Finally, memory fidelity changes during encoding while the evidence is extracted from the visible stimulus. Previous studies revealed that longer stimulus exposures have a favorable effect on the subsequent recall, but that this effect is modulated by the number of simultaneously encoded objects (<xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>; <xref ref-type="bibr" rid="bib88">Shibuya and Bundesen, 1988</xref>; <xref ref-type="bibr" rid="bib110">Vogel et al., 2006</xref>), providing evidence for a processing or encoding limitation of VWM. As stimulus presentation duration increases, more information may be extracted from the sensory signal into VWM, increasing the fidelity of the representation. Critically, with prolonged exposure, VWM fidelity approaches a stable level that depends on the number of encoded items, suggesting that a ceiling is imposed on evidence accumulation by a shared limit on VWM resources. However, a computational framework describing information accumulation from sensory areas into VWM is lacking, and the observed encoding limit may reflect dynamics in sensory areas registering visible objects as well as VWM accumulating this sensory evidence.</p><p>Here, we investigated the temporal dynamics in the fidelity of VWM from information encoding until its recall. To map human recall fidelity to the time domain, we conducted psychophysical experiments in which we probed memory representations at different time points relative to stimulus onset and offset while simultaneously manipulating set size. To isolate memory dynamics due to changes in the representational signal, we advanced an analogue reproduction task with a novel response method specifically adapted to minimize the time cost of motor (i.e. response) processes and capture the momentary state of memory representations. This allowed us to precisely measure the time course of fidelity dynamics during representation formation (i.e. encoding) and retention (i.e. maintenance). A major conclusion is that the enhanced precision seen at very brief retention intervals depends on integration of information from the sensory store into VWM following the cue, with the result that retrieval from IM of even the simplest stimulus is subject to the temporal and capacity limitations of WM.</p><p>To explain the neural computations underlying the observed time courses, we devised a comprehensive neural model of memory dynamics whose core architecture is rooted in the Neural Resource model of VWM (<xref ref-type="bibr" rid="bib6">Bays, 2014</xref>; <xref ref-type="bibr" rid="bib84">Schneegans et al., 2020</xref>). The Dynamic Neural Resource (DyNR) model assumes that changes in memory fidelity reflect temporal dynamics in the sensory population registering the stimuli and from signal and noise accumulation processes of resource-limited VWM (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In particular, the model prescribes how time-dependent gain control mechanisms in sensory areas produce a smooth neural response following abrupt changes in stimulus presence. As this sensory signal provides feedforward input to VWM, the dynamics in VWM activity in the temporal vicinity of stimulus presentation (i.e. onset and offset) strongly reflect not only limits in VWM, but also the dynamics of the sensory signal. Finally, once accumulated into VWM, the neural signal is subject to perturbations due to noise accumulation, resulting in degradation of internal representations with time. The DyNR model accurately reproduced the detailed empirical patterns of human recall errors in the psychophysical experiments. Based on these results, we argue that changes in memory fidelity on short time scales reflect dynamics in the gain or signal strength in neural populations representing the stimulus, while changes on longer time scales are dominated by corruption of the representation by accumulated noise.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Proposed neural population dynamics for encoding a single orientation into visual working memory (VWM) and maintaining it over a delay.</title><p>Top: Stimulus onset is followed by a ramping increase in activity (indicated by color) of sensory neurons whose tuning (indicated on <italic>y</italic> axis) matches the stimulus orientation. Following stimulus offset, this sensory signal rapidly decays. The sensory signal, including its decaying post-stimulus component, provides input into VWM. Bottom: At stimulus onset, the VWM population begins to accumulate activity from the sensory population. This accumulation saturates at a maximum amplitude determined by global normalization. As the sensory activity decays, the activity in the VWM population is maintained at a constant amplitude, but accumulation of random errors causes the activity bump to diffuse along the feature dimension (<italic>y</italic> axis) over time, changing the orientation represented by the population. At recall, when the VWM population activity is decoded, accuracy of the recall estimate depends on both the orientation represented (center of the activity bump) and the fidelity with which it can be retrieved (determined by activity amplitude).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-fig1-v1.tif"/></fig><sec id="s1-1"><title>Dynamic Neural Resource (DyNR) model</title><p>The DyNR model generalizes an established neural population account of VWM, originally proposed by <xref ref-type="bibr" rid="bib6">Bays, 2014</xref>, and inspired by similar models of attention and perceptual decision-making (<xref ref-type="bibr" rid="bib43">Jazayeri and Movshon, 2006</xref>; <xref ref-type="bibr" rid="bib66">Ohshiro et al., 2011</xref>; <xref ref-type="bibr" rid="bib77">Reynolds and Heeger, 2009</xref>). In the original model, memorization and recall of visual stimuli is achieved by encoding and decoding of spiking activity in idealized feature-tuned neurons. The limited capacity of VWM to hold multiple object features simultaneously is reproduced by a global divisive normalization that constrains total spiking activity, implementing a continuous memory resource (<xref ref-type="bibr" rid="bib26">Carandini and Heeger, 2011</xref>; <xref ref-type="bibr" rid="bib6">Bays, 2014</xref>). The DyNR model (illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>) extends this stationary encoding-decoding model with a temporal dimension. First, to capture encoding dynamics, stimulus information enters the VWM population (<xref ref-type="fig" rid="fig1">Figure 1</xref>, bottom) indirectly, by accumulation of neural signal from a separate sensory population (top), which receives the visual input. The signal strength in the VWM population at any point in time jointly depends on the history of the signal in the sensory population and the number of features competing for representation in VWM. Once the sensory signal is gone, the VWM signal is maintained at its maximum attained amplitude, but the stimulus value encoded by the signal gradually diffuses due to accumulation of random noise. Recall error depends on both the stimulus value represented at the time of retrieval (<italic>what</italic> is encoded) and the signal amplitude at that time, read out in the form of spikes (<italic>how precisely</italic> it can be decoded).</p></sec><sec id="s1-2"><title>Dynamics of sensory signal strength</title><p>To model the temporal dynamics of human memory fidelity, we begin by defining computations of the sensory system registering the incoming signal. A particularly important computation is temporal filtering – a property of neurons to respond more sensitively to specific temporal patterns in stimuli. To model the signal represented in the cortical sensory level, we assume that the sensory response to a stimulus presentation of fixed duration (described as a step function in visual input amplitude, <xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, left) is controlled by a monophasic temporal filter having a low-pass frequency response (<xref ref-type="bibr" rid="bib40">Hess and Snowden, 1992</xref>). This choice is a natural one since it is consistent with electrophysiological studies demonstrating that a large range of temporal frequencies registered by the retina and LGN (<xref ref-type="bibr" rid="bib31">Derrington and Lennie, 1984</xref>; <xref ref-type="bibr" rid="bib53">Lee et al., 1989</xref>) is attenuated at higher frequencies before the signal enters the primary visual cortex (<xref ref-type="bibr" rid="bib39">Hawken et al., 1996</xref>). Passing the stimulus through such a temporal filter attenuates the neural response to fast transients in the signal, and thereby produces a smooth rise and decay of neural activity in response to a uniform input signal (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). In particular, we assume that the activity of the sensory population after stimuli onset and offset changes exponentially toward the maximum sensory activity and baseline activity, respectively. The choice of the filter’s temporal response characteristics (i.e. its time constant) fully defines dynamics in the sensory population activity and controls the signal projected toward higher areas. The available physiological evidence suggests the temporal properties of the rising and decaying neural response are not symmetric (<xref ref-type="bibr" rid="bib61">Müller et al., 2001</xref>; <xref ref-type="bibr" rid="bib67">Oram and Perrett, 1992</xref>; <xref ref-type="bibr" rid="bib79">Ringach et al., 2003</xref>). In particular, the neural response typically reaches the maximum activity after the onset faster than it reaches the baseline activity after the offset. Consistent with this, we allowed the sensory signal to decay at a different rate than the rising rate. The temporal dynamics in sensory population firing activity in response to a fixed input signal of duration <italic>t</italic><sub>offset</sub> is then given by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the maximum sensory signal, <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> are rising and decaying time constants of the temporal filter, respectively.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Schematic of signal amplitudes in the dynamic neural resource (DyNR) model during a cued recall trial.</title><p>(<bold>A</bold>) Observers are presented with a memory array (left), followed after a blank delay (not shown) by an arrow cue (center) indicating the location of one item (the target) whose remembered orientation should immediately be reported (right). (<bold>B</bold>) The amplitude of the visual input associated with each item is modeled as a step function (left). The sensory response (<bold>D</bold>) is modeled as a low-pass filtering of the stimulus input, with different time constants for rise and decay (<bold>C</bold>). (<bold>F</bold>) Amplitude of the working memory signal reflects a saturating accumulation of activity from the sensory population (illustrated in <bold>E</bold>). Beginning with stimulus onset, activity associated with each item is accumulated from the sensory population into the visual working memory (VWM) population, approaching an upper bound (green dashed line) that reflects a total activity limit shared between the <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> items in memory. Once the cue has been presented (solid orange line) and processed (dashed orange line), uncued items can be dropped from VWM, raising the ceiling on activity available to represent the cued item (green arrow). This allows more information about the cued item to be accumulated from the decaying sensory trace (equivalent to the red shaded area in D). Response variability depends on the asymptotic VWM signal amplitude available for decoding (red circle) combined with the accumulated effects of diffusion (see text).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-fig2-v1.tif"/></fig><p>The temporal properties of the sensory response have been shown to depend on the physical characteristics of stimuli, such as contrast and location (<xref ref-type="bibr" rid="bib61">Müller et al., 2001</xref>; <xref ref-type="bibr" rid="bib91">Sit et al., 2009</xref>). Similarly, previous work has demonstrated that the decaying component of the sensory response is strongly influenced by the engagement of the sensory population after stimuli offset (e.g. <xref ref-type="bibr" rid="bib81">Rolls and Tovee, 1994</xref>). In particular, a new input signal, e.g., a backward noise mask, curtails ongoing activity related to the previous stimulus, resulting in a faster decay of activity compared to the unmasked post-stimulus period (<xref ref-type="bibr" rid="bib47">Kovács et al., 1995</xref>). Consistent with this, here we assume that the backward mask operates by interrupting ongoing sensory processing of stimuli, limiting the access to the sensory signal (Figure 5) (cf. integration mask) (<xref ref-type="bibr" rid="bib105">Turvey, 1973</xref>).</p></sec><sec id="s1-3"><title>Dynamics of VWM signal strength</title><p>The information registered by the sensory system is subsequently accumulated into a VWM population capable of maintaining activity in the absence of further input (e.g. by self-excitation, see <xref ref-type="bibr" rid="bib2">Aksay et al., 2001</xref>; <xref ref-type="bibr" rid="bib112">Wimmer et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Compte et al., 2000</xref>; although only the resulting dynamics are modeled here). The total activity of the VWM neural population is normalized, implementing a limited resource shared out between memory items (<xref ref-type="bibr" rid="bib6">Bays, 2014</xref>; <xref ref-type="bibr" rid="bib84">Schneegans et al., 2020</xref>). Consequently, if the stimuli are presented for long enough, the evidence accumulated from the sensory signal into VWM will saturate at a level that reflects the total number of stimuli represented (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). The dynamics in VWM population activity are given by:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the maximum VWM signal amplitude, <italic>M</italic>(<italic>t</italic>) is the number of items represented in VWM at time <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the time constant of accumulation into VWM.</p><p>A common assumption of VWM models is that the strength of the representational signal remains stable after encoding from a visible stimulus. This stationary view has been reinforced by typically measuring VWM sufficiently long after the stimulus disappears (~1 s) and at a single time point. In contrast, work on IM demonstrated that recall fidelity in a brief period after stimulus offset typically surpasses and then precipitously decays toward VWM fidelity level (<xref ref-type="bibr" rid="bib29">Coltheart, 1980</xref>). Consistent with that, we consider how the normalized representational signal in VWM formed during encoding can be boosted in the absence of the physical stimulus. In particular, we assume a representation stored in VWM can be strengthened as long as the sensory population provides feedforward input and VWM activity is not saturated at the normalized level. Such a scenario can be achieved by cueing an item for recall in the temporal vicinity of stimulus offset, i.e., before sensory activity decays to zero. By cueing an item for recall, the remaining contents of VWM becomes obsolete and can be removed from memory (<xref ref-type="bibr" rid="bib65">Oberauer, 2018</xref>). In the model,<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>N</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the time when the item is identified for a recall and the read-out of stimulus value begins. This ‘demounting’ of resource from uncued items makes it available for storing additional information about the cued item, which is extracted from the residual sensory representation, increasing the representation fidelity beyond that granted by equal distribution of neural signal between items. Critically, as sensory information quickly decays, there will be less signal remaining to supplement the VWM representation of a cued item if the cue is delivered later, and at the longest cue intervals the cue will confer no advantage over the fidelity attained when all items compete equally for VWM representation (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). We note that removal of uncued items cannot occur until the cue has been processed to the point of identifying 1 of the <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> items in the memory array. We follow <xref ref-type="bibr" rid="bib41">Hick, 1952</xref>, in modeling this cue processing time as logarithmic in the number of alternatives:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:msub><mml:mi>log</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p><p>where <italic>b</italic> is a scaling parameter. Previous work demonstrated that estimation of temporal dynamics in attention and memory could be confounded with the time needed to interpret the cue and start acting on it (<xref ref-type="bibr" rid="bib89">Shih and Sperling, 2002</xref>). This is especially significant when trying to accurately capture quickly changing processes, such as decay of the sensory residual. Although the cue processing time likely fluctuates on a trial-by-trial basis due to changes in, e.g., attention, arousal, or motivation, here we focus on the influence of set size arising from a limited information processing capacity.</p></sec><sec id="s1-4"><title>Diffusion of VWM encoded values</title><p>So far we have described only changes in the strength of the neural signal encoding features in memory. However, feature representations maintained over time in neural activity will accumulate noise in the absence of external input. We model this process of noise-driven diffusion as Brownian motion in feature space throughout the retention interval (<xref ref-type="fig" rid="fig1">Figure 1</xref>), contributing to variability in the decoded feature value (<xref ref-type="bibr" rid="bib23">Burak and Fiete, 2012</xref>; <xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>). The resulting variability is described by a wrapped normal distribution with variance <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> that increases linearly with time from stimulus offset, so that at time <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula> the encoded feature corresponding to a true stimulus feature <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> is:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">W</mml:mi><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></disp-formula><disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>σ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>σ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> specifies the base diffusion rate. While the fast decay of sensory activity after stimuli offset accounts for early dynamics in VWM fidelity, diffusion becomes prominent over longer delays, accounting for more gradual deterioration of precision with time.</p><p>Such a diffusion account has support in the available neural evidence as well as in theoretical work. At the neural level, an electrophysiological study in monkeys performing a spatial WM task demonstrated that shifts of neural tuning curves during a memory delay predicted behavioral response errors (<xref ref-type="bibr" rid="bib112">Wimmer et al., 2014</xref>). A similar finding was observed in humans where drift in the fMRI activity patterns relative to the target predicted errors in an orientation discrimination task (<xref ref-type="bibr" rid="bib54">Lim et al., 2019</xref>). At a theoretical level, continuous attractor models explain diffusion as a consequence of neural variability in networks where excitatory and inhibitory connections constrain population activity to a sub-space or manifold corresponding to the encoded feature space (<xref ref-type="bibr" rid="bib23">Burak and Fiete, 2012</xref>; <xref ref-type="bibr" rid="bib17">Bouchacourt and Buschman, 2019</xref>; <xref ref-type="bibr" rid="bib30">Compte et al., 2000</xref>).</p></sec><sec id="s1-5"><title>Retrieval</title><p>To model the process that leads to a response we first consider that in some trials observers may erroneously identify a non-target item as being cued. Previous work indicates these ‘swap’ errors occur due to uncertainty in memory for the cue features of the stimuli, in this case their locations (<xref ref-type="bibr" rid="bib82">Schneegans and Bays, 2017</xref>; <xref ref-type="bibr" rid="bib60">McMaster et al., 2022</xref>). We assume that changes in variability in the cue features mirror those of the memory features, leading swap frequency to decrease exponentially as a function of presentation duration and increase linearly with retention interval (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>):<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the time constant related to presentation duration, and <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the rate constant related to the retention interval.</p><p>If <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> is the true feature value of the item identified as the target (i.e. the cued item with probability <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, a randomly selected non-cued item with probability <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>), then due to diffusion (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) the value encoded in the VWM population at the time of retrieval is given by:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>θ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">W</mml:mi><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We model retrieval as estimation of <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> based on spiking activity in the VWM population that encodes the selected item. For this purpose we assume an idealized set of tuning functions, where the mean response of neuron <italic>i</italic> encoding orientation <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> with population gain <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> is described by:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>γ</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula> is the number of neurons, and <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> determines the tuning width. The preferred orientations of the neurons, <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>φ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, are evenly distributed throughout the circular space to provide uniform coverage. The spike count produced by each neuron is drawn from a Poisson distribution,<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and the decoded orientation estimate is obtained by ML estimation based on the spike counts:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow><mml:mi>θ</mml:mi></mml:munder><mml:mspace width="thickmathspace"/><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s1-6"><title>Additional assumptions</title><p>To fit the model to behavioral data, we make several further simplifying assumptions. We assume that the exponential decay of the sensory signal is rapid enough that there is effectively no information remaining by the time the VWM population is decoded to generate a response. This allows us to approximate the VWM activity at the time of decoding by the asymptotic VWM activity were the sensory decay to continue indefinitely:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:msup><mml:mi mathvariant="normal">m</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Next, we identify diffusion in the encoded value at the time of retrieval with diffusion at the time of target item identification, justifying the use of <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>. We reason that the rate of diffusion is slow enough relative to the rate of sensory decay, that any additional diffusion in the brief period of post-cue sensory accumulation is negligible.</p><p>In Experiment 1 (see below), a task with a fixed 200 ms exposure period, we assume that the initial encoding of all items into VWM is complete by the time of stimulus offset, i.e., that VWM activity at this time can be approximated by its asymptotic level reflecting normalization:<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:math></disp-formula></p><p>Finally, in the condition of Experiment 1 where memory array and cue are presented simultaneously, we assume that only the cued feature is encoded in VWM, reaching the maximum amplitude, <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, irrespective of set size. Maximum likelihood (ML) fits were obtained via the Nelder-Mead simplex method (function <italic>fminsearch</italic> in Matlab). All parameters and variables used to describe the DyNR model are listed in <xref ref-type="table" rid="table1">Table 1</xref>.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Dynamic neural resource (DyNR) model parameters (1–9) and other variables (10–24) used in model description.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">No.</th><th align="left" valign="bottom">Parameter/variable</th><th align="left" valign="bottom">Description</th></tr></thead><tbody><tr><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Maximum VWM signal amplitude</td></tr><tr><td align="left" valign="bottom">2</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Tuning curve width</td></tr><tr><td align="left" valign="bottom">3</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Rise constant of the sensory temporal filter</td></tr><tr><td align="left" valign="bottom">4</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Decay constant of the sensory temporal filter</td></tr><tr><td align="left" valign="bottom">5</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Time constant of accumulation into VWM</td></tr><tr><td align="left" valign="bottom">6</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>σ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Base diffusion rate</td></tr><tr><td align="left" valign="bottom">7</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Time constant for spatial encoding</td></tr><tr><td align="left" valign="bottom">8</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>r</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Rate constant for spatial diffusion</td></tr><tr><td align="left" valign="bottom">9</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Scaling parameter for Hick’s law</td></tr><tr><td align="left" valign="bottom">10</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Time, relative to stimulus onset (<inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">11</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Time of stimulus offset</td></tr><tr><td align="left" valign="bottom">12</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Time of cue onset</td></tr><tr><td align="left" valign="bottom">13</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Time an item is identified for report</td></tr><tr><td align="left" valign="bottom">14</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Number of items in stimulus array</td></tr><tr><td align="left" valign="bottom">15</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Number of items in memory at time <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">16</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Maximum sensory signal amplitude</td></tr><tr><td align="left" valign="bottom">17</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Sensory signal amplitude at time <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">18</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">VWM signal amplitude at time <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">19</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">VWM signal amplitude at the time of decoding</td></tr><tr><td align="left" valign="bottom">20</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Accumulated diffusion at time <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">21</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Number of neurons</td></tr><tr><td align="left" valign="bottom">22</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">True stimulus feature value</td></tr><tr><td align="left" valign="bottom">23</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Encoded stimulus feature value at the time of decoding</td></tr><tr><td align="left" valign="bottom">24</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Decoded stimulus feature value</td></tr></tbody></table></table-wrap></sec><sec id="s1-7"><title>Overview of experiments</title><p>We tested predictions of the DyNR model against empirical data collected in continuous report tasks. In Experiment 1 (<xref ref-type="fig" rid="fig3">Figure 3A and B</xref>), observers were presented with an array of oriented stimuli for a fixed duration followed after a variable delay by a visual cue identifying one of the preceding stimuli whose orientation should be reported. This experiment was designed to investigate the contribution of decaying sensory representations following stimulus offset to the dynamics of recall fidelity. Experiment 2 (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) was aimed at expanding the results of the first experiment to now also assess the accumulation of information during the time the stimuli were visible. In this case, the exposure duration was varied while the delay before the visual cue was held constant. In both experiments we varied the number of stimuli in the array (set size) to assess capacity limitations affecting encoding and maintenance.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Experimental procedure.</title><p>(<bold>A</bold>) Experiment 1. On each trial, a memory array was presented consisting of 1, 4, or 10 randomly oriented Gabor stimuli. In 50% of all trials, the stimuli underwent a change of phase and contrast toward the end of the exposure period intended to minimize retinal after-effects. After a variable delay, an arrow cue was shown pointing toward the location of one stimulus from the preceding array. Observers reported the remembered orientation of the cued stimulus by swiping their index finger on the touchpad. The response was followed by feedback showing the true orientation. (<bold>B</bold>) In a proportion of trials, the cue was presented simultaneously with the stimuli. (<bold>C</bold>) Experiment 2. On each trial a memory array consisting of 1, 4, or 10 randomly oriented Gabor was presented for a variable duration, and followed by a white noise flickering mask. The mask was replaced by an arrow cue pointing toward the location of one stimulus from the preceding array. Observers reported remembered its orientation and received feedback as in Experiment 1. Stimuli are not drawn to scale.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-fig3-v1.tif"/></fig><p>To provide additional validation of the DyNR model, we also tested its predictions against data from a previously published continuous report experiment (Experiment 1 in <xref ref-type="bibr" rid="bib6">Bays, 2014</xref>) and one additional dataset collected as part of a separate study (<xref ref-type="bibr" rid="bib103">Tomić et al., 2024</xref>). A detailed description of all experiments is provided in the Methods section.</p></sec></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experiment 1: Delay duration</title><p>In Experiment 1, we evaluated the time course of VWM fidelity over brief memory intervals. Previous work has demonstrated that immediately after a stimulus physically disappears, its representation briefly persists in the sensory system in the form of residual neural activity (<xref ref-type="bibr" rid="bib100">Teeuwen et al., 2021</xref>). Accumulation of this lingering sensory activity into VWM could enable superior recall of information (<xref ref-type="bibr" rid="bib29">Coltheart, 1980</xref>) within the constraints of a finite VWM resource that strongly limits representational fidelity (<xref ref-type="bibr" rid="bib58">Ma et al., 2014</xref>). To describe these dynamics, we examined human recall of orientation stimuli presented in arrays of varying sizes and probed after a variable delay ranging from 0 ms to 1000 ms. Here, we focus on an experimental condition in which retinal afterimages were suppressed by a phase shift toward the end of stimuli presentation. Validation of this method and results from the condition without a phase shift are provided in Appendix 1.</p><sec id="s2-1-1"><title>Experimental data</title><p>Recall error distributions and mean performance in Experiment 1 are plotted in <xref ref-type="fig" rid="fig4">Figure 4A and B</xref>. Response error (measured as RMSE) increased with both set size and delay duration. A repeated measures ANOVA revealed a significant effect of set size (<inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>18</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>117.8</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.44</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>), delay time (<inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>45</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>52</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.23</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>), and their interaction (<inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>90</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>26.7</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.13</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) on response error. We further explored this interaction, first finding response error in the 1 item condition (red in <xref ref-type="fig" rid="fig4">Figure 4</xref>) did not change with delay (<inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>45</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.32</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.27</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.07</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). This was supported by Bayesian analysis (<inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.34</mml:mn></mml:mstyle></mml:math></inline-formula>) which found weak to moderate evidence against modulation of 1 item recall by memory delay. In contrast, response error increased with delay for the remaining two set sizes (4 items, green; 10 items, blue; main effect: <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>45</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>55</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.48</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). This increase in response error consisted of an initial rapid rise (over the first 200 ms), followed by a more gradual increase as the delay between stimulus and cue increased. Next, we found a modulating effect of delay on recall for the remaining two set sizes (interaction: <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>45</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10.1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). The direct comparison revealed that the increase in response error with delay (<inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>RMSE</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>RMSE</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>1000ms</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>RMSE</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>% Simult</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>) was greater when observers memorized more items (<inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>9.1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>2.88</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Experiment 1 data and model fits show the consequences of varying set size and delay duration on working memory (WM) reproduction error.</title><p>(<bold>A</bold>) Empirical recall error distributions (black circles) and the dynamic neural resource (DyNR) model fits (colored curves). Different panels correspond to different set sizes (rows) and delays (columns). (<bold>B</bold>) Corresponding RMS errors from experimental data (circles and error bars) and the DyNR model fits (curves and error patches). Error bars and patches indicate ±1 SEM. N = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-fig4-v1.tif"/></fig><p>One surprising result was the observed set size effect in the 0 ms delay condition (<inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>18</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>23.7</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>.53</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) consistent with a stepwise increase in recall error with set size (pairwise comparison, <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>2.88</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:mn>.036</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>≥</mml:mo><mml:mn>0.91</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, Bonferroni correction applied). Importantly, this effect was a consequence of responding based on a memory of the stimulus, since orientation reproduction was comparable across set sizes in the perceptual condition (simultaneous presentation; <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>18</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.26</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>.3</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>.04</mml:mn><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.47</mml:mn></mml:mstyle></mml:math></inline-formula>). Previous studies have characterized IM as an effectively unlimited store, capable of holding any number of items without a consequent loss of fidelity (<xref ref-type="bibr" rid="bib34">Doost and Turvey, 1971</xref>; <xref ref-type="bibr" rid="bib94">Sperling, 1960</xref>). While our modeling ultimately affirmed this conception of IM, we nonetheless show that recall of information is contingent on the number of objects concurrently in memory from the moment stimuli physically disappear (see below).</p><p>Taken together, these results provide evidence that the fidelity of stored representations changes dramatically over the first few moments after stimuli offset. We next aimed to explain the neural computations supporting these dynamics. In summary, behavioral data displayed three key characteristics we aimed to explain, all visible in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. First, recall fidelity for a single item remained relatively stable across changes in delay, and was the same as perceptual fidelity. Second, recall fidelity for higher set sizes showed substantial, nonlinear temporal dynamics. Lastly, recall fidelity was contingent on the number of stored items from the moment stimuli disappeared.</p></sec><sec id="s2-1-2"><title>DyNR model</title><p>Curves in <xref ref-type="fig" rid="fig4">Figure 4A and B</xref> show fits of the model with ML parameters (mean ± SE: population gain  <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> = 59.8 ± 3.3, tuning width  <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> = 3.21 ± 0.2, sensory decay time constant  <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.21 ± 0.052, VWM accumulation time constant  <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">W</mml:mi><mml:mi mathvariant="normal">M</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.096 ± 0.045, cue processing constant  <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>b</mml:mi></mml:mstyle></mml:math></inline-formula> = 0.171 s ± 0.055 s, base diffusion  <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> = 0.03 ± 0.017, swap probability  <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math></inline-formula> = 0.027 ± 0.009). The model provided a close fit to response error distributions (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) and summary statistics (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; see also <xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref> for reproduction of swap error frequencies), successfully reproducing the pattern of changes with set size and delay. In particular, the model accounted for the three key observations identified above.</p><p>First, the model predicted the near-constant recall fidelity observed for a single item across these short retention intervals. The neural signal associated with the target object at recall depends on the normalized signal in VWM at offset supplemented by the available sensory signal post-cue. The sensory signal is integrated into VWM after the cue to fill any unallocated neural resource that arose by discarding uncued items. In the case of a single item, the entirety of VWM resources are allocated to one object during encoding, so no resource is freed by the cue that would allow the signal to be further strengthened based on the decaying sensory representation.</p><p>Importantly, this prediction contradicts the classical view of direct read-out from IM, according to which representational fidelity should be enhanced with very short delays irrespective of VWM limitations (see <italic>Alternative accounts</italic> below for a formal test of such a model). Note that the DyNR model nonetheless predicts some deterioration in fidelity over time even for a single item, due to noise-driven diffusion of the stored value. However, based on previous reports, we expected this process to be substantially slower and the impact on single-item precision relatively small on this (≤1 s) time scale. The fitted diffusion parameters and resulting shallow slope of fitted RMS error (red curve in <xref ref-type="fig" rid="fig4">Figure 4B</xref>) confirmed this.</p><p>Second, the neural model predicts the specific pattern of dynamics observed in trials with multiple items (set sizes 4, green, and 10, blue curves). Once the cue is presented, resources encoding uncued items are freed and the decaying sensory signal representing the target item is further integrated into VWM, still subject to limited total VWM resources but now without competition from other items. Due to exponential decay of the sensory signal, the increase in fidelity thus accrued changes rapidly with retention interval over the first few hundred milliseconds. At longer delays, the cue identifies the target only after the sensory signal has effectively disappeared, so the VWM signal representing the target item remains at the normalized level reflecting equal distribution between all items in the memory array, and memory dynamics consist only of the more gradual deterioration of fidelity due to accumulated noise in the encoded value.</p><p>Finally, the DyNR model predicts the presence of a set size effect on fidelity throughout the entire memory period, including the no delay (0 ms) condition in which the cue onset was coincident with stimulus offset, but not in the simultaneous cue condition. In the model, this behavior emerges as a consequence of two independent processes. First, at the end of stimulus presentation, items within smaller (lower set size) arrays are encoded in VWM with higher signal amplitude, reflecting normalization. This signal strength represents a baseline that can be supplemented by further integration of the sensory signal after an early cue. However, if the sensory decay is sufficiently rapid, then even if the cue is presented immediately the target representation will not attain the maximum amplitude (equivalent to set size of 1) starting from a lower baseline. Second, as described by Hick’s law (<xref ref-type="bibr" rid="bib41">Hick, 1952</xref>), it takes longer to identify the target item based on the cue as the number of alternatives increases (see <italic>Alternative models</italic> below for a formal test of this assumption). As a result, for higher set sizes, less sensory signal encoding the target item remains to be integrated into VWM once it has been identified.</p></sec><sec id="s2-1-3"><title>Model variants</title><p>We next focused on alternative explanations for the temporal dynamics observed in Experiment 1. Specifically, we examined whether the observed dynamics could be accounted for either solely by post-stimulus changes in neural signal amplitude or solely by noise-driven diffusion of stored values. To pre-empt our conclusions, we demonstrate that both components are needed to explain the observed dynamics in memory fidelity. Moreover, to more closely examine the role of diffusion in WM dynamics, we fit our neural model to an additional dataset collected in our lab (<xref ref-type="bibr" rid="bib103">Tomić et al., 2024</xref>; see Appendix 4 for full details). This experiment used longer delays compared to those used in Experiment 1, and therefore precluded any beneficial effect of post-stimulus sensory information, while at the same time allowing the diffusion to operate over a longer period. This experiment allowed us to test whether diffusion is sufficient to account for human recall errors with longer memory delays.</p><sec id="s2-1-3-1"><title>Fixed neural signal</title><p>A recent computational study on forgetting in VWM proposed that diffusion is sufficient to explain memory dynamics over delay (<xref ref-type="bibr" rid="bib68">Panichello et al., 2019</xref>). To test for this, we developed two reduced versions of the DyNR model in which the diffusion process was solely responsible for memory fidelity dynamics. In both variants, the sensory signal terminated abruptly with stimuli offset, so the VWM signal encoding the stimuli was independent of the delay duration and equal to the limit imposed by normalization (<inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula>). In the first variant, the diffusion rate was constant across set sizes, as in the full model. The formal model comparison demonstrated that the full DyNR model performed better than this simplified alternative (ΔAIC = 609.5).</p><p>In the second variant, we allowed the diffusion rate to increase proportionally with set size (for a similar proposal, see <xref ref-type="bibr" rid="bib48">Koyluoglu et al., 2017</xref>). This model was again outperformed by the full DyNR model (ΔAIC = 666.4). Critically, both models tested here failed to qualitatively reproduce the observed nonlinear pattern of changes in recall error with time, notably overestimating recall error at the shortest delays by assuming no modulation in the representational signal (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1</xref>).</p></sec><sec id="s2-1-3-2"><title>Diffusion</title><p>We developed two variants of the proposed neural model to test the role of diffusion. In the first variant, we completely omitted the diffusion process from the model to test whether the sensory signal modulation during the retention period is sufficient to explain temporal dynamics in recall fidelity. It could be argued that diffusion accounts for only minor changes in precision over brief delays as used here and, therefore, adds unnecessary complexity to the proposed model without improving the fit substantially. However, the formal model comparison revealed that the full DyNR model provides a better fit to human recall error compared to the matching model without diffusion (ΔAIC = 17.9).</p><p>The second variant was identical to the proposed model, except that we replaced the constant diffusion rate with a set-size-scaled diffusion rate by multiplying the right side of <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> by <inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula>. The model comparison showed that the full DyNR model also outperformed this variant (ΔAIC = 29.8). While both model variants qualitatively reproduced the increase in memory error with delay and set size, the pattern of variability was better explained by the model with a constant diffusion rate across set sizes. Although a more substantial diffusion effect could become apparent with longer delays than those used here, previous work demonstrated that noise-driven diffusion causes representations to deteriorate throughout the entire retention period (<xref ref-type="bibr" rid="bib17">Bouchacourt and Buschman, 2019</xref>).</p><p>Finally, we examined the role of diffusion with longer memory intervals in a separate experiment using variable set sizes and memory intervals (1 s and 7 s) (for full details, see Additional dataset 1 in Appendix 4). We demonstrated that, once sensory information decayed completely, an accumulation of error during retention interval accounted for continuing memory deterioration. Together, the results presented here corroborate findings on the role of diffusion in temporal dynamics of recall fidelity (<xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>).</p></sec></sec></sec><sec id="s2-2"><title>Experiment 2: Exposure duration</title><p>In Experiment 2, we evaluated the encoding phase of VWM, by testing recall of orientation stimuli displayed in arrays of variable size presented for variable durations. In the DyNR model, increasing the sensory evidence by prolonging stimulus presentation has a favorable effect on later recall of stimulus, as more of that evidence can be accumulated into VWM. Importantly, this accumulation is also capped by the VWM resources available to store it (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Time course of sensory and working memory (WM) gain with variable exposure duration.</title><p>(<bold>A, B</bold>) The signal amplitude in the sensory population increases from stimulus onset, exponentially approaching the maximum sensory activity (<inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>). For shorter presentation durations (<bold>A</bold>) the attained amplitude at stimulus offset is only a fraction of the maximum (compare B, late offset). Following offset, sensory areas produce a decaying neural response, that is curtailed (faster decay) but not abolished by a backward mask. (<bold>C, D</bold>) Information about the stimulus is accumulated in WM from sensory activity. A shorter presentation (<bold>C</bold>) provides less sensory evidence for the initial accumulation of all items into visual working memory (VWM) (compare D, late offset), and subsequently less decaying sensory activity that can supplement VWM activity for the target item following the cue.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-fig5-v1.tif"/></fig><sec id="s2-2-1"><title>Experimental data</title><p><xref ref-type="fig" rid="fig6">Figure 6</xref> shows the response error for different presentation durations and set sizes. Consistent with previous findings, response error can be seen to decrease with prolonged presentation duration, but increase as the number of items in memory increases. This was confirmed with a significant effect of display duration (<inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>72</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>29.01</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.21</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>), set size (<inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>24</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>112.51</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.54</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>), and their interaction (<inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mn>144</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2.58</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.004</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.019</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). We further explored this interaction by first confirming that response error decreased with display duration within each set size (<inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>72</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>10.24</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≥</mml:mo><mml:mn>0.26</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). A consistent pattern was observed across set sizes, comprising an initial rapid decrease in response error over the briefest presentation times (first 200 ms), followed by saturation at prolonged exposure durations. Next, we calculated the change in recall error between the longest and the shortest display exposure within each set size, revealing that response error decreased more rapidly with display time as the number of items in memory decreased (ANOVA: <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>24</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>7.79</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.002</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.21</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; corrected pairwise comparisons: <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3.65</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.016</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>0.87</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mo>−</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.96</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.72</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>0.27</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Experiment 2 results and modeling data show the consequences of varying set size and stimulus exposure time on visual working memory (VWM) reproduction error.</title><p>(<bold>A</bold>) Empirical recall error distributions (black circles) and the dynamic neural resource (DyNR) model fits (colored curves). Different panels correspond to different set sizes (rows) and exposure durations (columns). (<bold>B</bold>) Corresponding RMS errors from experimental data (circles and error bars) and the DyNR model fits (curves and error patches). Error bars and patches indicate ±1 SEM. N = 13.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-fig6-v1.tif"/></fig><p>These results reveal the time course of information accumulation into VWM and forming of stable representations. We again identified several key characteristics of the dynamics of recall fidelity in the data (<xref ref-type="fig" rid="fig6">Figure 6B</xref>) to test against the DyNR model. Consistent with previous studies, we found recall fidelity changed with both presentation duration and the number of presented stimuli (<xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>; <xref ref-type="bibr" rid="bib88">Shibuya and Bundesen, 1988</xref>; <xref ref-type="bibr" rid="bib110">Vogel et al., 2006</xref>). Specifically, as display duration increased from the shortest exposure, recall error showed an initial rapid decrease followed by a gradual leveling-off. As set size increased, the initial slope became shallower and the plateau occurred at a higher level of error.</p></sec><sec id="s2-2-2"><title>DyNR model</title><p>Curves in <xref ref-type="fig" rid="fig6">Figure 6A and B</xref> shows fits of the model with ML parameters (mean ± SE: population gain  <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> = 188.5 ± 109.6, tuning width  <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> = 10.2 ± 6.08, sensory rise time constant  <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.33 ± 0.18, sensory decay time constant  <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.61 ± 0.19, VWM accumulation time constant  <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">W</mml:mi><mml:mi mathvariant="normal">M</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.8 ± 0.34, cue processing constant  <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>b</mml:mi></mml:mstyle></mml:math></inline-formula> = 0.2 s ± 0.09 s, base diffusion  <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> = 0.28 ± 0.08, spatial uncertainty time constant  <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.013 ± 0.004, swap probability p = 0.053 ± 0.01). The model provided an excellent quantitative fit to response distributions (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) and RMSE (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), successfully reproducing the pattern of changes with set size and presentation duration.</p><p>The model predicted that information from a visible stimulus accrues at a high rate immediately after the stimulus onset, consistent with observed changes in human recall error over stimulus durations up to 200 ms (<xref ref-type="fig" rid="fig6">Figure 6</xref>). This initial high encoding rate emerges naturally in the model due to the joint dynamics of sensory and VWM populations. In the sensory population, a low-pass temporal filter serves as a neural gain control mechanism, attenuating neural response to transient changes in stimuli (<xref ref-type="bibr" rid="bib40">Hess and Snowden, 1992</xref>; <xref ref-type="bibr" rid="bib39">Hawken et al., 1996</xref>). As a consequence, the neural response to stimulus onset increases exponentially (<xref ref-type="fig" rid="fig5">Figure 5</xref>). The information from sensory areas is accumulated into VWM, such that the accumulation rate is directly proportional to the difference between the current and saturating state (i.e. the rate is faster when accumulated information is far from the saturating state). Therefore, dynamics in the sensory and VWM population jointly account for the initial high rate of information extraction from stimuli, and its dependence on set size.</p><p>After the initial steep change, the model predicts that recall fidelity will asymptote. This was again observed in human behavior (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Extending stimulus presentation beyond 200 ms had negligible impact on recall precision, consistent with previous studies (<xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>). The model explains this behavior by describing how sensory signal and VWM accumulation independently saturate with time (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Since the temporal filtering in the sensory population attenuates only high-frequency stimuli (i.e. very short presentations), with sufficient exposure, the sensory signal plateaus, resulting in a stable feedforward input to VWM. Similarly, VWM signal strength is subject to limits determined by normalization. Once the accumulated information reaches the normalized maximum set by the number of objects in memory, further accumulation of sensory evidence is not possible. Following the cue, a portion of the resource is freed, allowing the target representation to be further strengthened. However, because the sensory signal plateaus at longer exposures, the information available for integration after the cue remains constant across the longer exposures, supplementing normalized VWM signal by the same amount. The result is a plateau in fidelity that varies with set size.</p></sec><sec id="s2-2-3"><title>Model variants</title><p>We investigated whether post-stimulus sensory persistence contributed to the model fits in Experiment 2. We assumed that the signal persisting after stimulus offset would be impaired but not eliminated by the subsequent presentation of a noise mask in this experiment (<xref ref-type="bibr" rid="bib47">Kovács et al., 1995</xref>). An alternative account suggests that the mask immediately terminates any stimulus-related signal. To test for this, we fit a variant of the DyNR model in which the sensory signal was terminated by the onset of the mask, providing a feedforward signal to VWM only for the period of the stimulus presentation. We found that the proposed DyNR model, in which some sensory signal persists after the mask onset, gave a better account of the data than this model variant (ΔAIC = 446.67). Although the alternative model captured the general pattern of changes in memory fidelity with exposure duration, it mispredicted fidelity at shorter exposures, in particular the effect of set size (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2A</xref>).</p><p>A testable prediction of this alternative model is that the memory fidelity at recall should obey the neural normalization principle because there was no additional signal to supplement the presentation after initial encoding. To test for this, we additionally fitted each exposure condition separately using the original neural resource model with only three parameters (i.e. neural gain, tuning width, and swap probability). This model failed to predict actual fidelity levels at recall (<xref ref-type="fig" rid="app3fig2">Appendix 3—figure 2B</xref>), corroborating the findings of the model comparison.</p><p>Finally, to investigate the role of the post-stimulus sensory persistence on encoding dynamics, we fit the DyNR model to an additional dataset from <xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref> (for full details, see Appendix 5). This experiment aimed to investigate VWM dynamics during encoding, like our Experiment 2. In contrast to our Experiment 2, <xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>, used a much longer delay interval (1100 ms vs 100 ms), precluding the possibility of further accumulation of sensory evidence following the cue. We expected that the DyNR model could account for memory dynamics in this study without any post-stimulus sensory activity. This was confirmed by accurately reproducing memory dynamics with a model in which encoding into VWM relied only on sensory evidence during stimulus presentation (detailed results in Appendix 5).</p></sec></sec><sec id="s2-3"><title>Alternative accounts</title><p>Having demonstrated the need for both post-stimulus sensory persistence and diffusion to account for empirical data, we next considered alternatives to our account of VWM accumulation and information read-out.</p></sec><sec id="s2-4"><title>Direct read-out of sensory information</title><p>In the DyNR model, recall fidelity is enhanced following the cue by integrating remaining sensory activity into capacity-limited VWM. As a consequence, response precision is bounded from above by the memory limit irrespective of the available sensory signal. An alternative possibility is that the decaying sensory representation can be directly read out following the cue to inform a response, bypassing WM limitations. To formalize this alternative model, we assumed that independent sensory and VWM representations would be optimally combined via summation of neural activity to yield population gain<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:msubsup><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula></p><p>The model is otherwise identical to the proposed DyNR model. A distinctive prediction of this model is that the precision of recall changes exponentially with delay for every set size, including 1 item (<xref ref-type="fig" rid="app3fig3">Appendix 3—figure 3</xref>). This prediction is qualitatively inconsistent with the pattern of results observed in Experiment 1, in contrast with the DyNR model which does not predict any beneficial effect of earlier cues with set size 1. This alternative model provided a worse fit to data from Experiment 1 (ΔAIC = 164) and Experiment 2 (ΔAIC = 84.6), for combined evidence favoring the DyNR model of ΔAIC = 248.6.</p><sec id="s2-4-1"><title>Cue processing</title><p>In the DyNR model, we assumed that identifying the target stimulus based on the cue is time-consuming, and becomes more so as the number of alternatives increases. Cue processing time encompasses perceptual, attentional, and decision components needed to interpret and act on the cue. We tested the necessity of this component by fitting a model variant in which VWM started accumulating evidence about the cued item at the moment of cue presentation. This model provided a worse fit to empirical data from both Experiment 1 (ΔAIC = 84.5) and Experiment 2 (ΔAIC = 107.5), for total evidence in favor of the DyNR model of ΔAIC = 192 (<xref ref-type="fig" rid="app3fig4">Appendix 3—figure 4</xref>). We fit another variant in which cue processing time was constant across set sizes. This alternative provided a worse fit to the data in Experiment 1 (ΔAIC = 191.6) and Experiment 2 (ΔAIC = 105), for combined evidence ΔAIC = 296.6 in favor of the full DyNR model that assumes cue processing time increases with set size. These results corroborate previous findings on the important role of cue processing time in models of attention (<xref ref-type="bibr" rid="bib89">Shih and Sperling, 2002</xref>) and IM (<xref ref-type="bibr" rid="bib96">Sperling, 2018</xref>).</p></sec><sec id="s2-4-2"><title>Constant accumulation rate</title><p>In the DyNR model, the rate of accumulation into VWM is proportional to the difference between the present VWM amplitude and the maximum normalized amplitude (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>). An arguably simpler assumption is that the neural signal approaches saturation at a constant rate (<xref ref-type="bibr" rid="bib15">Boerlin and Denève, 2011</xref>; <xref ref-type="bibr" rid="bib12">Beck et al., 2008</xref>). In particular, the rate at which the signal representing an item is transferred to VWM is constant and depends only on the number of encoded items, i.e.,<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>γ</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>γ</mml:mi><mml:mo stretchy="false">ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The dependence on <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> satisfies the constraint that the neural resources in VWM are allocated at a constant rate, irrespective of the number of items. We applied this model to psychophysical data from both experiments (<xref ref-type="fig" rid="app3fig5">Appendix 3—figure 5</xref>) and found it provides a worse fit to the data from Experiment 1 (ΔAIC = 11.5) and Experiment 2 (ΔAIC = 36.2), for combined evidence favoring the DyNR model with exponential saturation (ΔAIC = 47.7).</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In the present study, we investigated the temporal dynamics of short-term recall fidelity. We conducted two new human psychophysical experiments and analyzed two existing datasets in order to characterize how recall errors are influenced by set size, stimulus duration, and retention interval. We developed a DyNR model to provide a mechanistic explanation of the observed behavior, capturing not only changes in overall fidelity but also the distribution of errors in the stimulus space and frequencies of swaps (intrusion errors). A key finding is that the benefit to recall precision observed at very short delays is due to additional post-cue integration of sensory information into WM, and that direct retrieval from sensory memory is unable to account for the empirical patterns of error.</p><sec id="s3-1"><title>Sensory and WM dynamics during delay</title><p>In the first experiment we investigated the effects of brief unfilled delays on recall fidelity. With multi-item arrays, we observed that memory performance deteriorates precipitously over the first few hundred milliseconds after stimuli disappear, followed by a gradual leveling-off of error with longer delays (<xref ref-type="fig" rid="fig4">Figure 4</xref>). These results are consistent with previously reported patterns of memory dynamics (<xref ref-type="bibr" rid="bib33">Di Lollo and Dixon, 1988</xref>; <xref ref-type="bibr" rid="bib94">Sperling, 1960</xref>; <xref ref-type="bibr" rid="bib19">Bradley and Pearson, 2012</xref>; <xref ref-type="bibr" rid="bib62">Neisser, 1967</xref>), and estimates of sensory decay ranging between 100 ms and 400 ms (<xref ref-type="bibr" rid="bib55">Loftus et al., 1992</xref>; <xref ref-type="bibr" rid="bib56">Lu et al., 2005</xref>). Here, we shed new light on these results by taking a computational approach in explaining observed temporal dynamics, and asking what this superior recall’s neural origin is and its relation with VWM. To answer these questions, we adapted the Neural Resource model of <xref ref-type="bibr" rid="bib6">Bays, 2014</xref>, with a temporal component. The new DyNR model considers dynamics in a sensory neural population registering the stimuli and in a VWM population that stores the stimuli for later recall. Critically, our model assumes that objects encoded with limited precision into VWM can be flexibly supplemented with sensory activity following a recall cue, within a brief temporal window while the sensory population provides a feedforward input post-stimulus. The boost in the representational VWM signal predicts a behavioral benefit of early cues that is consistent with our data and a large corpus of previous experiments (<xref ref-type="bibr" rid="bib29">Coltheart, 1980</xref>).</p><p>A common assumption in studies of visual short-term memory is that recall over brief delays is exclusively supported by one of two memory stores, IM or VWM (<xref ref-type="bibr" rid="bib19">Bradley and Pearson, 2012</xref>; <xref ref-type="bibr" rid="bib72">Pratte, 2018</xref>). In this account, a cue presented within the first few hundred milliseconds after stimulus offset allows observers to access high resolution but rapidly deteriorating representations in IM; once the information in IM has decayed, objects must be retrieved from the capacity-limited VWM store. Two pieces of evidence from the current study contradict this view and strongly suggest that recall depends on VWM from the moment objects disappear. First, the recall benefit of short delays was not observed for one item arrays. We propose that this behavior reflects the fact that, during encoding, the entirety of the VWM resource is allocated to a single object, leaving no free capacity for further enhancement based on the available sensory signal post-cue. Second, we found clear evidence that recall fidelity varied with set size even with no delay between stimulus offset and cue (0 ms condition). We argue that this arises from the set size dependence of representational fidelity in VWM, which is only incompletely compensated by integration of the decaying sensory signal post-cue, resulting in lower fidelity for higher set sizes. The DyNR model provides a successful quantitative account for these findings, which are in clear contrast with the traditional view of IM.</p><p>The rapid changes in fidelity over short delays can be distinguished from dynamics over longer retention intervals. A number of recent studies have observed a slow deterioration of VWM precision over the course of prolonged retention (<xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>; <xref ref-type="bibr" rid="bib70">Pertzov et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Rademaker et al., 2018</xref>; <xref ref-type="bibr" rid="bib78">Ricker et al., 2014</xref>; <xref ref-type="bibr" rid="bib90">Shin et al., 2017</xref>; <xref ref-type="bibr" rid="bib116">Zhang and Luck, 2009</xref>). The causes of this deterioration are still contested, but growing evidence links this behavior to noise-driven diffusion. At a mechanistic level, diffusion is considered a fundamental property of continuous attractor networks of the kind commonly associated with models of WM (<xref ref-type="bibr" rid="bib20">Brody et al., 2003</xref>; <xref ref-type="bibr" rid="bib46">Khona and Fiete, 2022</xref>). In such networks, memorized features are represented as persistent activity ‘bumps’ in the network’s representational feature space. Over a memory delay, the activity bump is sustained by balanced excitatory and inhibitory connections, while stochasticity in neural activity causes shifts of the bump along the feature dimension, taking the form of a random walk. Although we did not model the network processes governing stability and diffusion within neural populations, our implementation is consistent with random (Brownian) perturbation, as assumed by attractor models (see also <xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>).</p><p>Our theoretical account of memory dynamics during delay differs from several existing models of forgetting, which emphasize diffusion as the dominant source of error in short-term memory (e.g. <xref ref-type="bibr" rid="bib68">Panichello et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Koyluoglu et al., 2017</xref>). To solely account for the observed data in Experiment 1, diffusion would need to be strongest early in the retention period, followed by a much weaker diffusion with longer delays. However, it is unclear why the diffusion rate would change, and particularly slow down, with time. Assuming a constant neural signal encoding the stimulus, this would predict greater variability in neural activity initially compared to the later period after stimuli offset. This is inconsistent with electrophysiological data showing relatively stable levels of spiking variability throughout the memory delay period (<xref ref-type="bibr" rid="bib45">Khanna et al., 2019</xref>; <xref ref-type="bibr" rid="bib27">Chang et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Hussar and Pasternak, 2010</xref>). The results observed here are consistent with the proposal that modulation of neural signal over short memory intervals accounts for an abrupt change in response fidelity, while diffusion accounts for a slower change that grows with time.</p><p>In the present study, a model assuming a constant diffusion rate, independent of the stored number of items, was preferred to one in which diffusion rate increases linearly with set size. This is consistent with results of <xref ref-type="bibr" rid="bib90">Shin et al., 2017</xref>, who did not find a significant effect of set size on the rate of memory deterioration. In contrast to that, <xref ref-type="bibr" rid="bib48">Koyluoglu et al., 2017</xref>, recently proposed that the rate of diffusion scales with set size. However, this study did not account for the presence of swap errors, which we found to increase with retention interval as well as set size. To draw strong conclusions about the dependence of diffusion on set size would require a future study to disentangle the different sources of error that could, in principle, increase with delay.</p></sec><sec id="s3-2"><title>Sensory and WM dynamics during encoding</title><p>Having investigated memory degradation during the retention interval, in Experiment 2 we focused on the dynamics arising from accumulation of information during stimulus presentation. Using new psychophysical data, we showed that encoding of information into VWM is contingent on both presentation duration and the number of memorized stimuli. The observed patterns of data indicate that VWM encoding of elementary stimuli is mostly completed within the first 200 ms of presentation even at the largest set sizes, with minimal benefit of longer exposures, extending previous work (<xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>; <xref ref-type="bibr" rid="bib88">Shibuya and Bundesen, 1988</xref>; <xref ref-type="bibr" rid="bib110">Vogel et al., 2006</xref>). This fast encoding process may have an adaptive role: with a key function of VWM to store and accumulate information across saccadic eye movements, an efficient system should deploy its resources within the duration of a typical gaze fixation (<xref ref-type="bibr" rid="bib1">Aagten-Murphy and Bays, 2018</xref>; <xref ref-type="bibr" rid="bib80">Rolfs and Schweitzer, 2022</xref>).</p><p>Our aim was again to move beyond the description of the encoding dynamics and to provide a biologically plausible neurocomputational account of these dynamics. To achieve that, we applied the same VWM accumulation process that operates post-cue to the sensory information during stimulus presentation. Using previously published and newly collected data, we show that a model in which VWM accumulates dynamical sensory input up to a fidelity limit can successfully account for patterns of human recall errors with variable set size and stimulus presentation. An important result of our modeling is that the accumulated information in VWM increases with a rate proportional to unfilled capacity. In particular, the model with such exponential accumulation provided a better fit than a model assuming a constant encoding rate. This parallels previous observations that models based on exponential-like extraction of information successfully characterize attention (<xref ref-type="bibr" rid="bib22">Bundesen, 1990</xref>; <xref ref-type="bibr" rid="bib95">Sperling and Weichselgartner, 1995</xref>), WM encoding (<xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>; <xref ref-type="bibr" rid="bib92">Smith and Ratcliff, 2009</xref>), memory updating (<xref ref-type="bibr" rid="bib64">Oberauer and Kliegl, 2006</xref>), and broader cognitive processes (<xref ref-type="bibr" rid="bib106">Usher and McClelland, 2001</xref>; <xref ref-type="bibr" rid="bib59">McClelland, 1979</xref>). We hypothesize that this pattern represents an approach to an equilibrium state of balanced excitation from the sensory input and lateral inhibition within the VWM population, which is the basis for capacity of the memory system.</p><p>In Experiment 2, the longest presentation duration shows an upward trend in error at set sizes 4 and 10. While this falls within the range of measurement error, it is also possible that this is a meaningful pattern arising from visual adaptation of the sensory signal, whereby neural populations reduce their activity after prolonged stimulation. This would mean less residual sensory signal would be available after the cue to supplement VWM activity, predicting a decline in fidelity at higher set sizes. Visual adaptation has previously been successfully accounted for by a type of delayed normalization model in which the sensory signal undergoes a series of linear and nonlinear transformations (<xref ref-type="bibr" rid="bib117">Zhou et al., 2019</xref>). Such a model could in future be incorporated into DyNR and validated against psychophysical and neural data.</p><p>Our computational account of VWM encoding dynamics differs from several existing modeling frameworks aiming to explain similar data. For example, the theory of visual attention (TVA; <xref ref-type="bibr" rid="bib22">Bundesen, 1990</xref>) assumes that visual stimuli participate in a parallel exponential race toward limited VWM. Like the DyNR model, TVA assumes a form of normalization in the sense that the speed with which items race toward VWM depends on the number of items in the visual field. Unlike our dynamic model, TVA is not a theory of VWM, and it considers VWM only as a storage for categorizations of visual objects. In particular, TVA takes into account the limits of VWM but does not specify why or how these limitations arise. Finally, TVA considers whether an object was selected for entry into VWM in an all-or-none fashion; our dynamic model is mostly concerned with the fidelity of representations. A somewhat alternative account of VWM encoding is provided by the competitive interaction theory (CIT; <xref ref-type="bibr" rid="bib87">Sewell et al., 2014</xref>), which is similarly based on the signal detection theory and principles of normalization (<xref ref-type="bibr" rid="bib77">Reynolds and Heeger, 2009</xref>). Like TVA, CIT is mostly focused on item selection and merely incorporates a concept of VWM capacity derived from object-based models of VWM. Although CIT had success in accounting for behavioral data from a two-alternative orthogonal discrimination task using up to four items and a limited range of encoding times, it remains an open question whether this model can account for error distributions as measured in a continuous report task, and a larger range of set sizes and stimulus exposures. Importantly, compared to both TVA and CIT, the DyNR model is strongly rooted in and inspired by findings from neuroscience. This not only adds to the biological plausibility of our model but also allows future studies to test the model’s predictions using physiological methods.</p></sec><sec id="s3-3"><title>Neural mechanisms</title><p>The theory presented here generalizes the Neural Resource model of <xref ref-type="bibr" rid="bib6">Bays, 2014</xref>, a simple encoding-decoding model in which visual features are represented in the noisy spiking activity of neural populations (<xref ref-type="bibr" rid="bib71">Pouget et al., 2000</xref>), and where the activity representing each feature scales inversely with the total number of representations, consistent with the prevalence of normalization mechanisms in the brain and observations from single-neuron recording (<xref ref-type="bibr" rid="bib24">Buschman et al., 2011</xref>) and fMRI decoding (<xref ref-type="bibr" rid="bib97">Sprague et al., 2014</xref>) studies. The population coding in the model is based on an abstract idealization of neural response functions. Nevertheless, it has recently been shown that more realistic population coding schemes that allow for heterogeneity in neural tuning curves and correlated spiking activity as observed in visual cortex maintain the key predictions of the idealized model (<xref ref-type="bibr" rid="bib98">Taylor and Bays, 2020</xref>; <xref ref-type="bibr" rid="bib84">Schneegans et al., 2020</xref>). This may be seen as a consequence of the different population codes inducing a common representational geometry (<xref ref-type="bibr" rid="bib49">Kriegeskorte and Wei, 2021</xref>).</p><p>We adapted the stationary VWM model by first incorporating a sensory population that provides an input drive to the VWM population. In parallel with neurophysiological observations, a common approach is to model these dynamics with a low-pass filter which acts like a neural gain modulation mechanism (<xref ref-type="bibr" rid="bib39">Hawken et al., 1996</xref>). As a consequence, the sensory response to stimulus onset and offset is an exponential rise and decay in activity, respectively. The decaying component of the response has been recognized as a neural substrate of visual persistence and IM (<xref ref-type="bibr" rid="bib109">van Kerkoerle et al., 2017</xref>; <xref ref-type="bibr" rid="bib100">Teeuwen et al., 2021</xref>). Here, we modeled sensory decay with an exponential function (<xref ref-type="bibr" rid="bib119">Zylberberg et al., 2009</xref>), although other forms of decay have been proposed. For example, <xref ref-type="bibr" rid="bib55">Loftus et al., 1992</xref>, showed that iconic decay could be better captured using a gamma survival function, a generalization of exponential decay that could simply be implemented in our neural model by replacing a single filter with a cascade of exponential low-pass filters.</p><p>In addition to the dynamics in the sensory population, two features of VWM introduce additional dynamics in representation fidelity: the accumulation of information (discussed above) and the diffusion of representations owing to accumulated noise. Although we did not aim to model the neural processes behind diffusion, our implementation is consistent with the consequences of neural variability in attractor networks (<xref ref-type="bibr" rid="bib23">Burak and Fiete, 2012</xref>; <xref ref-type="bibr" rid="bib46">Khona and Fiete, 2022</xref>). Converging neural evidence demonstrating such diffusion has been observed using single-unit neural recording in monkeys (<xref ref-type="bibr" rid="bib112">Wimmer et al., 2014</xref>), as well as EEG (<xref ref-type="bibr" rid="bib113">Wolff et al., 2020</xref>) and fMRI (<xref ref-type="bibr" rid="bib54">Lim et al., 2019</xref>; <xref ref-type="bibr" rid="bib115">Yu et al., 2020</xref>) studies in humans.</p><p>As well as being implicated in higher cognitive processes including VWM (<xref ref-type="bibr" rid="bib24">Buschman et al., 2011</xref>; <xref ref-type="bibr" rid="bib97">Sprague et al., 2014</xref>), divisive normalization has been shown to be widespread in basic sensory processing (<xref ref-type="bibr" rid="bib16">Bonin et al., 2005</xref>; <xref ref-type="bibr" rid="bib25">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="bib63">Ni and Maunsell, 2017</xref>). The DyNR model presently incorporates the former but not the latter type of normalization. While the data observed in our experiments do not provide evidence for normalization of sensory signals (note comparable recall errors across set size in the simultaneous cue condition of Experiment 1), this may be because sensory suppressive effects are localized and our stimuli were relatively widely separated in the visual field: future research could explore the consequences of sensory normalization for recall from VWM using, e.g., center-surround stimuli (<xref ref-type="bibr" rid="bib14">Bloem et al., 2018</xref>).</p><p>Following onset of a stimulus, the visual signal ascends through visual areas via a cascade of feedforward connections. This feedforward sweep conveys sensory information that persists during stimulus presentation and briefly after it disappears (<xref ref-type="bibr" rid="bib50">Lamme et al., 1998</xref>). Simultaneously, reciprocal feedback connections carry higher-order information back toward antecedent cortical areas (<xref ref-type="bibr" rid="bib51">Lamme and Roelfsema, 2000</xref>). In our psychophysical task, feedback connections likely play a critical role in orienting attention toward the cued item, facilitating the extraction of persisting sensory signals, and potentially signaling continuous information on the available resources for VWM encoding. While our computational study does not address the nature of these feedforward and feedback signals, a challenge for future research is to describe the relative contributions of these signals in mediating transmission of information between sensory memory and WM (<xref ref-type="bibr" rid="bib85">Semedo et al., 2022</xref>).</p><p>Our model makes a clear distinction between dynamics in sensory and VWM populations, however, it remains agnostic as to whether the populations have the same or different anatomical locus (<xref ref-type="bibr" rid="bib75">Rademaker et al., 2019</xref>). Albeit inspired by the properties of orientation-selective neurons in area V1, population tuning of this kind is a common coding motif across the brain (<xref ref-type="bibr" rid="bib71">Pouget et al., 2000</xref>). While it could be considered efficient to use already specialized circuits to maintain as well as process visual information, it is still debated whether sensory areas are a feasible candidate for memory storage (<xref ref-type="bibr" rid="bib86">Serences, 2016</xref>; <xref ref-type="bibr" rid="bib114">Xu, 2017</xref>). While some studies have focused on prefrontal (<xref ref-type="bibr" rid="bib37">Goldman-Rakic, 1995</xref>), parietal (<xref ref-type="bibr" rid="bib13">Bettencourt and Xu, 2016</xref>), or occipital (<xref ref-type="bibr" rid="bib38">Harrison and Tong, 2009</xref>) cortices as the primary locus of VWM, others argue for distributed storage by demonstrating that VWM contents can be decoded from imaging signals originating in multiple brain areas (<xref ref-type="bibr" rid="bib28">Christophel et al., 2018</xref>).</p></sec><sec id="s3-4"><title>Representational dynamics of cue-dimension features</title><p>Memory retrieval failures in which a non-cued item is reported in place of the intended target represent an important source of error in VWM recall. These swap errors occur more often at higher set sizes and when spatial confusability is high (<xref ref-type="bibr" rid="bib4">Bays et al., 2009</xref>; <xref ref-type="bibr" rid="bib35">Emrich and Ferber, 2012</xref>; <xref ref-type="bibr" rid="bib76">Rerko et al., 2014</xref>; <xref ref-type="bibr" rid="bib9">Bays, 2016b</xref>), as predicted by models in which they arise from uncertainty in the recall of cue-dimension features leading to incorrect selection of an item in memory (<xref ref-type="bibr" rid="bib82">Schneegans and Bays, 2017</xref>; <xref ref-type="bibr" rid="bib60">McMaster et al., 2022</xref>). In the current study, we assumed memory for spatial location (the cue feature) undergoes similar dynamics to memory for orientation (the report feature), and in particular that spatial information degrades with retention time (<xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>), leading to changes in swap error frequency with delay interval. Similarly, during encoding the fidelity of spatial representation increases with the accumulation of sensory evidence (<xref ref-type="bibr" rid="bib118">Zimmermann et al., 2013</xref>), reducing the uncertainty at retrieval and consequently swap errors at longer stimulus exposure. Although we did not explicitly model the neural signals representing location, the modeled dynamics in the probability of swap errors were consistent with those of the primary memory feature. We provided a more detailed neural account of swap errors in our earlier works that is theoretically compatible with the DyNR model (<xref ref-type="bibr" rid="bib82">Schneegans and Bays, 2017</xref>; <xref ref-type="bibr" rid="bib60">McMaster et al., 2022</xref>).</p><p>The DyNR model successfully captured the observed pattern of swap frequencies (intrusion errors). The only notable discrepancy between DyNR and the three-component mixture model (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>) arises with the largest set size and longest delay, although with considerable interindividual variability. As the variability in report dimension increases, the estimates of swap frequency become more variable due to the growing overlap between the probability distributions of swap and non-swap responses. This may explain apparent deviations from the modeled swap frequencies with the highest set size and longest delay where orientation response variability was greatest.</p></sec><sec id="s3-5"><title>Removal of information from WM</title><p>In the DyNR model, taking advantage of early cues requires rapid removal of the VWM signal associated with uncued items, to admit further accumulation of activity encoding the cued item. To achieve this, an active process of selective content elimination may be required (<xref ref-type="bibr" rid="bib65">Oberauer, 2018</xref>), as opposed to a passive decay of uncued representations during the post-cue interval. Mounting evidence for such active removal has been provided at the behavioral (<xref ref-type="bibr" rid="bib111">Williams et al., 2013</xref>) and neural (<xref ref-type="bibr" rid="bib52">LaRocque et al., 2013</xref>) level. Importantly, studies show that a functional role of such active removal is to release resources allocated to the uncued representations, facilitating the encoding of new information (<xref ref-type="bibr" rid="bib99">Taylor et al., 2023</xref>; <xref ref-type="bibr" rid="bib93">Souza et al., 2014</xref>). The fast reallocation of neural resources assumed by the DyNR model is consistent with such a description of active removal.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Participants</title><p>A total of 23 naive observers (12 females, 11 males; aged 18–34) took part in the study after giving informed consent in accordance with the Declaration of Helsinki. Ten observers participated in Experiment 1 and 13 observers participated in Experiment 2. Volunteers were recruited through the Cambridge Psychology research sign-up system. All observers reported normal color vision and normal or corrected-to-normal visual acuity, and were remunerated £10/hr for their participation. Procedures were approved by the University of Cambridge Psychology Research Ethics Committee (approval number PRE.2015.099).</p></sec><sec id="s4-2"><title>General methods</title><sec id="s4-2-1"><title>Experimental setup</title><p>Stimuli were presented on a 69 cm gamma-corrected LCD monitor with a refresh rate of 144 Hz. Participants were seated in a dark room and viewed the monitor at a distance of 60 cm, with their head supported by a forehead and chin rest. Responses were collected using Magic Trackpad 2, a pointing device (16×11.5 cm<sup>2</sup>) with a tactile sensor operating at ~90 Hz (Apple Inc). Eye position was monitored online at 1000 Hz using an infrared eye tracker (SR Research). Stimulus presentation and response registration were controlled by a script written in Psychtoolbox and run using Matlab (The Mathworks Inc).</p></sec><sec id="s4-2-2"><title>Stimuli</title><p>Memory stimuli consisted of randomly oriented Gabor patches (wavelength of the sinusoid, 0.65° of visual angle; s.d. of Gaussian envelope, 0.5°) presented on a uniform mid-gray background. The contrast of Gabor patches varied between experiments (see below). Memory stimulus positions were randomly chosen from a set of 10 equidistant locations on the perimeter of an invisible circle with radius 6° centered at fixation. At the start of each trial, a black fixation annulus was shown (<italic>r</italic> = 0.15° and <italic>R</italic> = 0.25°) in the display center. Once steady fixation was registered, the size of the inner radius increased (<italic>r</italic> = 0.2°). Observers perceived this change as the annulus becoming thinner. The fixation annulus then stayed visible throughout the trial. Items were cued for recall by displaying a black arrow (2° length) extending from the center of the display and pointing to one of the previously occupied locations without overlapping with it.</p></sec><sec id="s4-2-3"><title>Procedure</title><p>Each trial started with presentation of the central fixation annulus. Observers were required to maintain gaze fixation for 500 ms within a radius of 2° around the central annulus in order for a trial to proceed. Following stable fixation, the appearance of the fixation annulus changed, indicating that the memory array would appear in 500 ms. The memory sample array consisting of 1, 4, or 10 randomly oriented Gabor patches was then presented. This was followed by a delay period and finally a cue display, indicating to observers to report the memorized orientation of an item previously displayed at the indicated location.</p><p>Observers were instructed to reproduce the remembered orientation as accurately and as quickly as possible by executing a single movement of their index fingertip over the surface of the touchpad located centrally in front of them. Simultaneously with the observer’s movement, a blue line appeared on the screen, extending from the center of the screen and mimicking the observer’s response in real time. The response was terminated if one of the following conditions was satisfied: the observer stopped movement for 500 ms; the observer lifted their finger from the touchpad; or the response line reached the edge of the display. This was followed by a feedback display, consisting of the actual orientation (shown with a white line) and reported orientation (shown with a blue line) overlaid at the location of the cued item. The recalled orientation was calculated as the angle of the line connecting a starting point and an endpoint of hand movement on the touchpad.</p><p>Observers were required to maintain central fixation during the stimulus presentation and delay phase. If gaze position deviated by more than <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mn>2</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> a message appeared on the screen, and the trial was aborted and restarted with newly randomized orientations. Participants completed the task in blocks of 50 trials, and each block corresponded to one experimental condition. The order of blocks was randomized for every observer. At the beginning of the testing session observers familiarized themselves with the task and experimental setup by doing at most 50 practice trials.</p></sec></sec><sec id="s4-3"><title>Experiment 1</title><p>In Experiment 1 we investigated the temporal dynamics of VWM fidelity over short delays by presenting observers with sets of stimuli of variable size and then cueing one of them for recall after a variable delay relative to the stimuli offset. A typical trial sequence is shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. The memory sample array (Michelson contrast = 0.5) was presented for 200 ms. In 50% of trials, the stimuli changed phase (by 180°) and contrast (Michelson contrast = 1) for the last 50 ms of presentation, while remaining at the same orientation. This manipulation was intended to minimize retinal after-effects (see, e.g., <xref ref-type="bibr" rid="bib44">Kelly and Martinez-Uriegas, 1993</xref>, for similar techniques and Appendix 1 for validation). The stimuli offset was followed by a variable blank delay of 0, 100, 200, 400, or 1000 ms, after which one item was cued for recall. In one additional condition, the cue was instead presented simultaneously with the memory sample array, indicating an item while it was still visible on the screen (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>Each observer completed a total of 1800 trials, split into 36 blocks. The experiment was organized such that half of the observers first completed 18 blocks with phase shift (see above), and the other half first completed blocks without phase shift. Except for this constraint, block order was randomized for every observer. The testing was divided into four equal testing sessions, each lasting approximately 1.5 hr, with a separation of at least 1 day between sessions.</p></sec><sec id="s4-4"><title>Experiment 2</title><p>In Experiment 2 we investigated the temporal dynamics of VWM fidelity during encoding. To this end, we displayed oriented stimuli for a variable duration and in sets of variable size. The experiment was similar to the previous experiment with a few exceptions (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Each trial started with a presentation of a fixation annulus, followed by a memory array (Michelson contrast = 0.3). The stimuli stayed on the screen for a variable duration of 30, 48, 77, 122, 196, 313, or 500 ms, and were then replaced by noise masks (100 ms). Mask stimuli consisted of white noise at full contrast, windowed with a Gaussian envelope (0.5° s.d.) and flickering at 35 Hz. At the offset of the masking stimuli, one memory item was cued for recall. Each observer completed 21 blocks, for a total of 1050 trials. Blocks were spread over two testing sessions, each lasting approximately 1.5 hr, and taking place on different days. Observers completed 10 blocks in the first, and the remaining 11 blocks in the second session.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Funding acquisition, Methodology, Project administration, Resources, Software, Supervision, Visualization, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Procedures were approved by the University of Cambridge Psychology Research Ethics Committee (approval number PRE.2015.099). All subjects gave informed consent in accordance with the Declaration of Helsinki.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-91034-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data and code related to this study will be made available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17863/CAM.95223">https://doi.org/10.17863/CAM.95223</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Tomić</surname><given-names>I</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Research data supporting 'A dynamic neural resource model bridges sensory and working memory'</data-title><source>Apollo - University of Cambridge Repository</source><pub-id pub-id-type="doi">10.17863/CAM.95223</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank George Sperling and Sebastian Schneegans for helpful discussion, Robert Taylor for help with Bayesian hierarchical modeling, and Jessica McMaster for help with data collection. We used resources provided by the Cambridge Service for Data Driven Discovery (CSD3) operated by the University of Cambridge Research Computing Service. This research was supported by the Wellcome Trust (grant 106926 to PMB).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Aagten-Murphy</surname><given-names>D</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title>Functions of memory across saccadic eye movements</chapter-title><person-group person-group-type="editor"><name><surname>Hodgson</surname><given-names>T</given-names></name></person-group><source>Processes of Visuospatial Attention and Working Memory</source><publisher-name>Springer</publisher-name><fpage>155</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1007/7854_2018_66</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aksay</surname><given-names>E</given-names></name><name><surname>Gamkrelidze</surname><given-names>G</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Baker</surname><given-names>R</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>In vivo intracellular recording and perturbation of persistent activity in a neural integrator</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>184</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1038/84023</pub-id><pub-id pub-id-type="pmid">11175880</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>The Ferrier Lecture, 1980. Critical limiting factors in the design of the eye and visual cortex</article-title><source>Proceedings of the Royal Society of London. Series B, Biological Sciences</source><volume>212</volume><fpage>1</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1098/rspb.1981.0022</pub-id><pub-id pub-id-type="pmid">6115386</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Catalao</surname><given-names>RFG</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The precision of visual working memory is set by allocation of a shared resource</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/9.10.7</pub-id><pub-id pub-id-type="pmid">19810788</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Gorgoraptis</surname><given-names>N</given-names></name><name><surname>Wee</surname><given-names>N</given-names></name><name><surname>Marshall</surname><given-names>L</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Temporal dynamics of encoding, storage, and reallocation of visual working memory</article-title><source>Journal of Vision</source><volume>11</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.1167/11.10.6</pub-id><pub-id pub-id-type="pmid">21911739</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Noise in neural populations accounts for errors in working memory</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>3632</fpage><lpage>3645</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3204-13.2014</pub-id><pub-id pub-id-type="pmid">24599462</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spikes not slots: noise in neural populations limits working memory</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>431</fpage><lpage>438</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.06.004</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>A signature of neural coding at human perceptual limits</article-title><source>Journal of Vision</source><volume>16</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/16.11.4</pub-id><pub-id pub-id-type="pmid">27604067</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Evaluating and excluding swap errors in analogue tests of working memory</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>19203</elocation-id><pub-id pub-id-type="doi">10.1038/srep19203</pub-id><pub-id pub-id-type="pmid">26758902</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Taylor</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A neural model of retrospective attention in visual working memory</article-title><source>Cognitive Psychology</source><volume>100</volume><fpage>43</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2017.12.001</pub-id><pub-id pub-id-type="pmid">29272732</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>P</given-names></name><name><surname>Schneegans</surname><given-names>S</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Brady</surname><given-names>TF</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Representation and computation in working memory</article-title><source>Nature Human Behaviour</source><comment>In press</comment></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Hanks</surname><given-names>T</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Roitman</surname><given-names>J</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Probabilistic population codes for Bayesian decision making</article-title><source>Neuron</source><volume>60</volume><fpage>1142</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.021</pub-id><pub-id pub-id-type="pmid">19109917</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bettencourt</surname><given-names>KC</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Decoding the content of visual short-term memory under distraction in occipital and parietal areas</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>150</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1038/nn.4174</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bloem</surname><given-names>IM</given-names></name><name><surname>Watanabe</surname><given-names>YL</given-names></name><name><surname>Kibbe</surname><given-names>MM</given-names></name><name><surname>Ling</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Visual memories bypass normalization</article-title><source>Psychological Science</source><volume>29</volume><fpage>845</fpage><lpage>856</lpage><pub-id pub-id-type="doi">10.1177/0956797617747091</pub-id><pub-id pub-id-type="pmid">29596038</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boerlin</surname><given-names>M</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spike-based population coding and working memory</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1001080</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1001080</pub-id><pub-id pub-id-type="pmid">21379319</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The suppressive field of neurons in lateral geniculate nucleus</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>10844</fpage><lpage>10856</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3562-05.2005</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouchacourt</surname><given-names>F</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A flexible model of working memory</article-title><source>Neuron</source><volume>103</volume><fpage>147</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.04.020</pub-id><pub-id pub-id-type="pmid">31103359</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braak</surname><given-names>CJFT</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A markov chain monte carlo version of the genetic algorithm differential evolution: easy bayesian computing for real parameter spaces</article-title><source>Statistics and Computing</source><volume>16</volume><fpage>239</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1007/s11222-006-8769-1</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>C</given-names></name><name><surname>Pearson</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The sensory components of high-capacity iconic memory and visual working memory</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>355</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00355</pub-id><pub-id pub-id-type="pmid">23055993</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Basic mechanisms for graded persistent activity: discrete attractors, continuous attractors, and dynamic representations</article-title><source>Current Opinion in Neurobiology</source><volume>13</volume><fpage>204</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/s0959-4388(03)00050-3</pub-id><pub-id pub-id-type="pmid">12744975</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rats and humans can optimally accumulate evidence for decision-making</article-title><source>Science</source><volume>340</volume><fpage>95</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1126/science.1233912</pub-id><pub-id pub-id-type="pmid">23559254</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bundesen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A theory of visual attention</article-title><source>Psychological Review</source><volume>97</volume><fpage>523</fpage><lpage>547</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.97.4.523</pub-id><pub-id pub-id-type="pmid">2247540</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Fundamental limits on persistent activity in networks of noisy neurons</article-title><source>PNAS</source><volume>109</volume><fpage>17645</fpage><lpage>17650</lpage><pub-id pub-id-type="doi">10.1073/pnas.1117386109</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Roy</surname><given-names>JE</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neural substrates of cognitive capacity limitations</article-title><source>PNAS</source><volume>108</volume><fpage>11252</fpage><lpage>11255</lpage><pub-id pub-id-type="doi">10.1073/pnas.1104666108</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname><given-names>L</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title><source>Neuron</source><volume>64</volume><fpage>931</fpage><lpage>942</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.004</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Normalization as a canonical neural computation</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>51</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/nrn3136</pub-id><pub-id pub-id-type="pmid">22108672</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>MH</given-names></name><name><surname>Armstrong</surname><given-names>KM</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dissociation of response variability from firing rate effects in frontal eye field neurons during visual stimulation, working memory, and attention</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>2204</fpage><lpage>2216</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2967-11.2012</pub-id><pub-id pub-id-type="pmid">22323732</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophel</surname><given-names>TB</given-names></name><name><surname>Iamshchinina</surname><given-names>P</given-names></name><name><surname>Yan</surname><given-names>C</given-names></name><name><surname>Allefeld</surname><given-names>C</given-names></name><name><surname>Haynes</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cortical specialization for attended versus unattended working memory</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>494</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0094-4</pub-id><pub-id pub-id-type="pmid">29507410</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coltheart</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Iconic memory and visible persistence</article-title><source>Perception &amp; Psychophysics</source><volume>27</volume><fpage>183</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.3758/BF03204258</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Compte</surname><given-names>A</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Synaptic mechanisms and network dynamics underlying spatial working memory in a cortical network model</article-title><source>Cerebral Cortex</source><volume>10</volume><fpage>910</fpage><lpage>923</lpage><pub-id pub-id-type="doi">10.1093/cercor/10.9.910</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derrington</surname><given-names>AM</given-names></name><name><surname>Lennie</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Spatial and temporal contrast sensitivities of neurones in lateral geniculate nucleus of macaque</article-title><source>The Journal of Physiology</source><volume>357</volume><fpage>219</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1984.sp015498</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’Esposito</surname><given-names>M</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cognitive neuroscience of working memory</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>115</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015031</pub-id><pub-id pub-id-type="pmid">25251486</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Lollo</surname><given-names>V</given-names></name><name><surname>Dixon</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Two forms of persistence in visual information processing</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>14</volume><fpage>671</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.14.4.671</pub-id><pub-id pub-id-type="pmid">2974875</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doost</surname><given-names>R</given-names></name><name><surname>Turvey</surname><given-names>MT</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Iconic memory and central processing capacity</article-title><source>Perception &amp; Psychophysics</source><volume>9</volume><fpage>269</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.3758/BF03212646</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Emrich</surname><given-names>SM</given-names></name><name><surname>Ferber</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Competition increases binding errors in visual working memory</article-title><source>Journal of Vision</source><volume>12</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.1167/12.4.12</pub-id><pub-id pub-id-type="pmid">22523399</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Cellular basis of working memory</article-title><source>Neuron</source><volume>14</volume><fpage>477</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/0896-6273(95)90304-6</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>SA</given-names></name><name><surname>Tong</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding reveals the contents of visual working memory in early visual areas</article-title><source>Nature</source><volume>458</volume><fpage>632</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1038/nature07832</pub-id><pub-id pub-id-type="pmid">19225460</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawken</surname><given-names>MJ</given-names></name><name><surname>Shapley</surname><given-names>RM</given-names></name><name><surname>Grosof</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Temporal-frequency selectivity in monkey visual cortex</article-title><source>Visual Neuroscience</source><volume>13</volume><fpage>477</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1017/s0952523800008154</pub-id><pub-id pub-id-type="pmid">8782375</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hess</surname><given-names>RF</given-names></name><name><surname>Snowden</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Temporal properties of human visual filters: number, shapes and spatial covariation</article-title><source>Vision Research</source><volume>32</volume><fpage>47</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(92)90112-V</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hick</surname><given-names>WE</given-names></name></person-group><year iso-8601-date="1952">1952</year><article-title>On the rate of gain of information</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>4</volume><fpage>11</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1080/17470215208416600</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hussar</surname><given-names>C</given-names></name><name><surname>Pasternak</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Trial-to-trial variability of the prefrontal neurons reveals the nature of their engagement in a motion discrimination task</article-title><source>PNAS</source><volume>107</volume><fpage>21842</fpage><lpage>21847</lpage><pub-id pub-id-type="doi">10.1073/pnas.1009956107</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>M</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal representation of sensory information by neural populations</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>690</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1038/nn1691</pub-id><pub-id pub-id-type="pmid">16617339</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>DH</given-names></name><name><surname>Martinez-Uriegas</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Measurements of chromatic and achromatic afterimages</article-title><source>Journal of the Optical Society of America. A, Optics and Image Science</source><volume>10</volume><fpage>29</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1364/josaa.10.000029</pub-id><pub-id pub-id-type="pmid">8478743</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khanna</surname><given-names>SB</given-names></name><name><surname>Snyder</surname><given-names>AC</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distinct sources of variability affect eye movement preparation</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>4511</fpage><lpage>4526</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2329-18.2019</pub-id><pub-id pub-id-type="pmid">30914447</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Attractor and integrator networks in the brain</article-title><source>Nature Reviews. Neuroscience</source><volume>23</volume><fpage>744</fpage><lpage>766</lpage><pub-id pub-id-type="doi">10.1038/s41583-022-00642-0</pub-id><pub-id pub-id-type="pmid">36329249</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kovács</surname><given-names>G</given-names></name><name><surname>Vogels</surname><given-names>R</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Cortical correlate of pattern backward masking</article-title><source>PNAS</source><volume>92</volume><fpage>5587</fpage><lpage>5591</lpage><pub-id pub-id-type="doi">10.1073/pnas.92.12.5587</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koyluoglu</surname><given-names>OO</given-names></name><name><surname>Pertzov</surname><given-names>Y</given-names></name><name><surname>Manohar</surname><given-names>S</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fundamental bound on the persistence and capacity of short-term memory stored as graded persistent activity</article-title><source>eLife</source><volume>6</volume><elocation-id>e22225</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.22225</pub-id><pub-id pub-id-type="pmid">28879851</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Wei</surname><given-names>XX</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural tuning and representational geometry</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>703</fpage><lpage>718</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00502-3</pub-id><pub-id pub-id-type="pmid">34522043</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname><given-names>VA</given-names></name><name><surname>Supèr</surname><given-names>H</given-names></name><name><surname>Spekreijse</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Feedforward, horizontal, and feedback processing in the visual cortex</article-title><source>Current Opinion in Neurobiology</source><volume>8</volume><fpage>529</fpage><lpage>535</lpage><pub-id pub-id-type="doi">10.1016/s0959-4388(98)80042-1</pub-id><pub-id pub-id-type="pmid">9751656</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname><given-names>VA</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The distinct modes of vision offered by feedforward and recurrent processing</article-title><source>Trends in Neurosciences</source><volume>23</volume><fpage>571</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1016/s0166-2236(00)01657-x</pub-id><pub-id pub-id-type="pmid">11074267</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LaRocque</surname><given-names>JJ</given-names></name><name><surname>Lewis-Peacock</surname><given-names>JA</given-names></name><name><surname>Drysdale</surname><given-names>AT</given-names></name><name><surname>Oberauer</surname><given-names>K</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Decoding attended information in short-term memory: an EEG study</article-title><source>Journal of Cognitive Neuroscience</source><volume>25</volume><fpage>127</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00305</pub-id><pub-id pub-id-type="pmid">23198894</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>BB</given-names></name><name><surname>Martin</surname><given-names>PR</given-names></name><name><surname>Valberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Sensitivity of macaque retinal ganglion cells to chromatic and luminance flicker</article-title><source>The Journal of Physiology</source><volume>414</volume><fpage>223</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1989.sp017685</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>PC</given-names></name><name><surname>Ward</surname><given-names>EJ</given-names></name><name><surname>Vickery</surname><given-names>TJ</given-names></name><name><surname>Johnson</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Not-so-working memory: drift in functional magnetic resonance imaging pattern representations during maintenance predicts errors in a visual working memory task</article-title><source>Journal of Cognitive Neuroscience</source><volume>31</volume><fpage>1520</fpage><lpage>1534</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01427</pub-id><pub-id pub-id-type="pmid">31112474</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loftus</surname><given-names>GR</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Gehrig</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>On the time course of perceptual information that results from a brief visual presentation</article-title><source>Journal of Experimental Psychology</source><volume>18</volume><fpage>530</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.18.2.530</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>ZL</given-names></name><name><surname>Neuse</surname><given-names>J</given-names></name><name><surname>Madigan</surname><given-names>S</given-names></name><name><surname>Dosher</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Fast decay of iconic memory in observers with mild cognitive impairments</article-title><source>PNAS</source><volume>102</volume><fpage>1797</fpage><lpage>1802</lpage><pub-id pub-id-type="doi">10.1073/pnas.0408402102</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id><pub-id pub-id-type="pmid">17057707</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Changing concepts of working memory</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>347</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1038/nn.3655</pub-id><pub-id pub-id-type="pmid">24569831</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>On the time relations of mental processes: An examination of systems of processes in cascade</article-title><source>Psychological Review</source><volume>86</volume><fpage>287</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.86.4.287</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McMaster</surname><given-names>JMV</given-names></name><name><surname>Tomić</surname><given-names>I</given-names></name><name><surname>Schneegans</surname><given-names>S</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Swap errors in visual working memory are fully explained by cue-feature variability</article-title><source>Cognitive Psychology</source><volume>137</volume><elocation-id>101493</elocation-id><pub-id pub-id-type="doi">10.1016/j.cogpsych.2022.101493</pub-id><pub-id pub-id-type="pmid">35777189</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Müller</surname><given-names>JR</given-names></name><name><surname>Metha</surname><given-names>AB</given-names></name><name><surname>Krauskopf</surname><given-names>J</given-names></name><name><surname>Lennie</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Information conveyed by onset transients in responses of striate cortical neurons</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>6978</fpage><lpage>6990</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-17-06978.2001</pub-id><pub-id pub-id-type="pmid">11517285</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Neisser</surname><given-names>U</given-names></name></person-group><year iso-8601-date="1967">1967</year><source>Cognitive Psychology. Number 1966 in Century Psychology Series Award</source><publisher-name>Appleton-Century-Crofts</publisher-name></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>AM</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatially tuned normalization explains attention modulation variance within neurons</article-title><source>Journal of Neurophysiology</source><volume>118</volume><fpage>1903</fpage><lpage>1913</lpage><pub-id pub-id-type="doi">10.1152/jn.00218.2017</pub-id><pub-id pub-id-type="pmid">28701536</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberauer</surname><given-names>K</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A formal model of capacity limits in working memory</article-title><source>Journal of Memory and Language</source><volume>55</volume><fpage>601</fpage><lpage>626</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2006.08.009</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oberauer</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Removal of irrelevant information from working memory: sometimes fast, sometimes slow, and sometimes not at all</article-title><source>Annals of the New York Academy of Sciences</source><volume>1424</volume><fpage>239</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1111/nyas.13603</pub-id><pub-id pub-id-type="pmid">29532484</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohshiro</surname><given-names>T</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A normalization model of multisensory integration</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>775</fpage><lpage>782</lpage><pub-id pub-id-type="doi">10.1038/nn.2815</pub-id><pub-id pub-id-type="pmid">21552274</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oram</surname><given-names>MW</given-names></name><name><surname>Perrett</surname><given-names>DI</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Time course of neural responses discriminating different views of the face and head</article-title><source>Journal of Neurophysiology</source><volume>68</volume><fpage>70</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1152/jn.1992.68.1.70</pub-id><pub-id pub-id-type="pmid">1517829</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panichello</surname><given-names>MF</given-names></name><name><surname>DePasquale</surname><given-names>B</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Error-correcting dynamics in visual working memory</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>3366</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-11298-3</pub-id><pub-id pub-id-type="pmid">31358740</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasternak</surname><given-names>T</given-names></name><name><surname>Greenlee</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Working memory in primate sensory systems</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>97</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1038/nrn1603</pub-id><pub-id pub-id-type="pmid">15654324</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pertzov</surname><given-names>Y</given-names></name><name><surname>Manohar</surname><given-names>S</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Rapid forgetting results from competition over time between items in visual working memory</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>43</volume><fpage>528</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1037/xlm0000328</pub-id><pub-id pub-id-type="pmid">27668485</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Zemel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Information processing with population codes</article-title><source>Nature Reviews. Neuroscience</source><volume>1</volume><fpage>125</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1038/35039062</pub-id><pub-id pub-id-type="pmid">11252775</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pratte</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Iconic memories die a sudden death</article-title><source>Psychological Science</source><volume>29</volume><fpage>877</fpage><lpage>887</lpage><pub-id pub-id-type="doi">10.1177/0956797617747118</pub-id><pub-id pub-id-type="pmid">29671682</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Constraints on the source of short-term motion adaptation in macaque area MT. I. the role of input and intrinsic mechanisms</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>354</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1152/jn.00852.2001</pub-id><pub-id pub-id-type="pmid">12091560</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rademaker</surname><given-names>RL</given-names></name><name><surname>Park</surname><given-names>YE</given-names></name><name><surname>Sack</surname><given-names>AT</given-names></name><name><surname>Tong</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Evidence of gradual loss of precision for simple features and complex objects in visual working memory</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>44</volume><fpage>925</fpage><lpage>940</lpage><pub-id pub-id-type="doi">10.1037/xhp0000491</pub-id><pub-id pub-id-type="pmid">29494191</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rademaker</surname><given-names>RL</given-names></name><name><surname>Chunharas</surname><given-names>C</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Coexisting representations of sensory and mnemonic information in human visual cortex</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1336</fpage><lpage>1344</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0428-x</pub-id><pub-id pub-id-type="pmid">31263205</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rerko</surname><given-names>L</given-names></name><name><surname>Oberauer</surname><given-names>K</given-names></name><name><surname>Lin</surname><given-names>HY</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatial transposition gradients in visual working memory</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>67</volume><fpage>3</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1080/17470218.2013.789543</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>JH</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The normalization model of attention</article-title><source>Neuron</source><volume>61</volume><fpage>168</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.002</pub-id><pub-id pub-id-type="pmid">19186161</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ricker</surname><given-names>TJ</given-names></name><name><surname>Spiegel</surname><given-names>LR</given-names></name><name><surname>Cowan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Time-based loss in visual short-term memory is from trace decay, not temporal distinctiveness</article-title><source>Journal of Experimental Psychology</source><volume>40</volume><fpage>1510</fpage><lpage>1523</lpage><pub-id pub-id-type="doi">10.1037/xlm0000018</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringach</surname><given-names>DL</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name><name><surname>Shapley</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Dynamics of orientation tuning in macaque V1: the role of global and tuned suppression</article-title><source>Journal of Neurophysiology</source><volume>90</volume><fpage>342</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1152/jn.01018.2002</pub-id><pub-id pub-id-type="pmid">12611936</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolfs</surname><given-names>M</given-names></name><name><surname>Schweitzer</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Coupling perception to action through incidental sensory consequences of motor behaviour</article-title><source>Nature Reviews Psychology</source><volume>1</volume><fpage>112</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1038/s44159-021-00015-x</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Tovee</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Processing speed in the cerebral cortex and the neurophysiology of visual masking</article-title><source>Proceedings of the Royal Society of London. Series B</source><volume>257</volume><fpage>9</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1098/rspb.1994.0087</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneegans</surname><given-names>S</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural architecture for feature binding in visual working memory</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>3913</fpage><lpage>3925</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3493-16.2017</pub-id><pub-id pub-id-type="pmid">28270569</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneegans</surname><given-names>S</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Drift in neural population activity causes working memory to deteriorate over time</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>4859</fpage><lpage>4869</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3440-17.2018</pub-id><pub-id pub-id-type="pmid">29703786</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneegans</surname><given-names>S</given-names></name><name><surname>Taylor</surname><given-names>R</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Stochastic sampling provides a unifying account of visual working memory limits</article-title><source>PNAS</source><volume>117</volume><fpage>20959</fpage><lpage>20968</lpage><pub-id pub-id-type="doi">10.1073/pnas.2004306117</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semedo</surname><given-names>JD</given-names></name><name><surname>Jasper</surname><given-names>AI</given-names></name><name><surname>Zandvakili</surname><given-names>A</given-names></name><name><surname>Krishna</surname><given-names>A</given-names></name><name><surname>Aschner</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Feedforward and feedback interactions between visual cortical areas use different population activity patterns</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>1099</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-28552-w</pub-id><pub-id pub-id-type="pmid">35232956</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural mechanisms of information storage in visual short-term memory</article-title><source>Vision Research</source><volume>128</volume><fpage>53</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2016.09.010</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sewell</surname><given-names>DK</given-names></name><name><surname>Lilburn</surname><given-names>SD</given-names></name><name><surname>Smith</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An information capacity limitation of visual short-term memory</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>40</volume><fpage>2214</fpage><lpage>2242</lpage><pub-id pub-id-type="doi">10.1037/a0037744</pub-id><pub-id pub-id-type="pmid">25222469</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shibuya</surname><given-names>H</given-names></name><name><surname>Bundesen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Visual selection from multielement displays: measuring and modeling effects of exposure duration</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>14</volume><fpage>591</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1037//0096-1523.14.4.591</pub-id><pub-id pub-id-type="pmid">2974870</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shih</surname><given-names>SI</given-names></name><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Measuring and modeling the trajectory of visual spatial attention</article-title><source>Psychological Review</source><volume>109</volume><fpage>260</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.109.2.260</pub-id><pub-id pub-id-type="pmid">11990319</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Zou</surname><given-names>Q</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The effects of delay duration on visual working memory for orientation</article-title><source>Journal of Vision</source><volume>17</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.1167/17.14.10</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sit</surname><given-names>YF</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Geisler</surname><given-names>WS</given-names></name><name><surname>Miikkulainen</surname><given-names>R</given-names></name><name><surname>Seidemann</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Complex dynamics of V1 population responses explained by a simple gain-control model</article-title><source>Neuron</source><volume>64</volume><fpage>943</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.041</pub-id><pub-id pub-id-type="pmid">20064399</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>PL</given-names></name><name><surname>Ratcliff</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>An integrated theory of attention and decision making in visual signal detection</article-title><source>Psychological Review</source><volume>116</volume><fpage>283</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1037/a0015156</pub-id><pub-id pub-id-type="pmid">19348543</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Souza</surname><given-names>AS</given-names></name><name><surname>Rerko</surname><given-names>L</given-names></name><name><surname>Oberauer</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Unloading and reloading working memory: attending to one item frees capacity</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>40</volume><fpage>1237</fpage><lpage>1256</lpage><pub-id pub-id-type="doi">10.1037/a0036331</pub-id><pub-id pub-id-type="pmid">24730737</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>The information available in brief visual presentations</article-title><source>Psychological Monographs</source><volume>74</volume><fpage>1</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1037/h0093759</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sperling</surname><given-names>G</given-names></name><name><surname>Weichselgartner</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Episodic theory of the dynamics of spatial attention</article-title><source>Psychological Review</source><volume>102</volume><fpage>503</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.503</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sperling</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title>A brief overview of computational models of spatial, temporal, and feature visual attention</chapter-title><person-group person-group-type="editor"><name><surname>Lachmann</surname><given-names>T</given-names></name><name><surname>Weis</surname><given-names>T</given-names></name></person-group><source>Invariances in Human Information Processing</source><publisher-name>Routledge</publisher-name><fpage>143</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.4324/9781315169903</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Reconstructions of information in visual spatial working memory degrade with memory load</article-title><source>Current Biology</source><volume>24</volume><fpage>2174</fpage><lpage>2180</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.07.066</pub-id><pub-id pub-id-type="pmid">25201683</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>R</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Theory of neural coding predicts an upper bound on estimates of memory variability</article-title><source>Psychological Review</source><volume>127</volume><fpage>700</fpage><lpage>718</lpage><pub-id pub-id-type="doi">10.1037/rev0000189</pub-id><pub-id pub-id-type="pmid">32191074</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>R</given-names></name><name><surname>Tomić</surname><given-names>I</given-names></name><name><surname>Aagten-Murphy</surname><given-names>D</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Working memory is updated by reallocation of resources from obsolete to new items</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>85</volume><fpage>1437</fpage><lpage>1451</lpage><pub-id pub-id-type="doi">10.3758/s13414-022-02584-2</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teeuwen</surname><given-names>RRM</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Schnabel</surname><given-names>UH</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A neuronal basis of iconic memory in macaque primary visual cortex</article-title><source>Current Biology</source><volume>31</volume><fpage>5401</fpage><lpage>5414</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.09.052</pub-id><pub-id pub-id-type="pmid">34653360</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomić</surname><given-names>I</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Internal but not external noise frees working memory resources</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006488</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006488</pub-id><pub-id pub-id-type="pmid">30321172</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomić</surname><given-names>I</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Perceptual similarity judgments do not predict the distribution of errors in working memory</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>50</volume><fpage>535</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1037/xlm0001172</pub-id><pub-id pub-id-type="pmid">36442045</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tomić</surname><given-names>I</given-names></name><name><surname>Girones</surname><given-names>Z</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name><name><surname>Bays</surname><given-names>PM</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Natural statistics and stimulus representations in visual working memory</article-title><conf-name>Computational and Systems Neuroscience (CoSyNe)</conf-name></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuchiya</surname><given-names>N</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Continuous flash suppression reduces negative afterimages</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1096</fpage><lpage>1101</lpage><pub-id pub-id-type="doi">10.1038/nn1500</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turvey</surname><given-names>MT</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>On peripheral and central processes in vision: inferences from an information-processing analysis of masking with patterned stimuli</article-title><source>Psychological Review</source><volume>80</volume><fpage>1</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1037/h0033872</pub-id><pub-id pub-id-type="pmid">4689202</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title><source>Psychological Review</source><volume>108</volume><fpage>550</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.108.3.550</pub-id><pub-id pub-id-type="pmid">11488378</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Ede</surname><given-names>F</given-names></name><name><surname>Chekroud</surname><given-names>SR</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Concurrent visual and motor selection during visual working memory guided action</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>477</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0335-6</pub-id><pub-id pub-id-type="pmid">30718904</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Anderson</surname><given-names>CH</given-names></name><name><surname>Felleman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Information processing in the primate visual system: an integrated systems perspective</article-title><source>Science</source><volume>255</volume><fpage>419</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1126/science.1734518</pub-id><pub-id pub-id-type="pmid">1734518</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Layer-specificity in the effects of attention and working memory on activity in primary visual cortex</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>13804</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13804</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogel</surname><given-names>EK</given-names></name><name><surname>Woodman</surname><given-names>GF</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The time course of consolidation in visual working memory</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>32</volume><fpage>1436</fpage><lpage>1451</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.32.6.1436</pub-id><pub-id pub-id-type="pmid">17154783</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>M</given-names></name><name><surname>Hong</surname><given-names>SW</given-names></name><name><surname>Kang</surname><given-names>MS</given-names></name><name><surname>Carlisle</surname><given-names>NB</given-names></name><name><surname>Woodman</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The benefit of forgetting</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>20</volume><fpage>348</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.3758/s13423-012-0354-3</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Nykamp</surname><given-names>DQ</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Bump attractor dynamics in prefrontal cortex explains behavioral precision in spatial working memory</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>431</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1038/nn.3645</pub-id><pub-id pub-id-type="pmid">24487232</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Jochim</surname><given-names>J</given-names></name><name><surname>Akyürek</surname><given-names>EG</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Drifting codes within a stable coding scheme for working memory</article-title><source>PLOS Biology</source><volume>18</volume><elocation-id>e3000625</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000625</pub-id><pub-id pub-id-type="pmid">32119658</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reevaluating the sensory account of visual working memory storage</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>794</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.06.013</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Q</given-names></name><name><surname>Panichello</surname><given-names>MF</given-names></name><name><surname>Cai</surname><given-names>Y</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name><name><surname>Buschman</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Delay-period activity in frontal, parietal, and occipital cortex tracks noise and biases in visual working memory</article-title><source>PLOS Biology</source><volume>18</volume><elocation-id>e3000854</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000854</pub-id><pub-id pub-id-type="pmid">32898172</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>W</given-names></name><name><surname>Luck</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sudden death and gradual decay in visual working memory</article-title><source>Psychological Science</source><volume>20</volume><fpage>423</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02322.x</pub-id><pub-id pub-id-type="pmid">19320861</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Predicting neuronal dynamics with a delayed gain control model</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007484</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007484</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimmermann</surname><given-names>E</given-names></name><name><surname>Morrone</surname><given-names>MC</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial position information accumulates steadily over time</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>18396</fpage><lpage>18401</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1864-13.2013</pub-id><pub-id pub-id-type="pmid">24259564</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Mindlin</surname><given-names>GB</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neurophysiological bases of exponential sensory decay and top-down memory retrieval: a model</article-title><source>Frontiers in Computational Neuroscience</source><volume>3</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.10.004.2009</pub-id><pub-id pub-id-type="pmid">19325713</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Minimizing retinal after-effects</title><p>We assessed the method of minimizing retinal afterimages by repeating all measurements, with the exception of not using phase shift of stimuli (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). We predicted retinal afterimages could serve as an additional source of information, but only for a brief period after stimuli offset. Therefore, here we expected to see better performance for brief delays compared to conditions with phase shift. <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref> shows recall error increased with both set size and delay. Both of these effects were statistically significant, as well as their interaction (set size: <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>18</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>47.3</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.31</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; delay time: <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>45</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>48.4</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.26</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; interaction: <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>90</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>21.3</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.14</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>), reminiscent of findings for data with phase shift.</p><p>Next, we focused on the comparison of conditions with and without phase shift of stimuli (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B</xref>). We illustrate the difference in performance by subtracting RMSE obtained in the condition without phase shift (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) from RMSE shown in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>. Negative values indicate better performance in a condition without phase shift. As predicted, the overall pattern of data suggested performance was comparable for 1 item across all delays, and for all set sizes for extreme delays (simultaneous presentation and 1000 ms), indicated by the difference values around 0. We confirmed the difference in recall error for 1 item across all delays did not differ consistently with and without phase shift, as neither phase shift (<inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.03</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.86</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.143</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) nor the interaction of phase shift and delay (<inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>45</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.41</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.89</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.00</mml:mn><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.042</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) reached significance. Based on this result, we conducted all remaining analyses using only the remaining two set sizes. We ran separate repeated measures ANOVAs for each delay using phase shift and set size as factors. The pattern of results we observed was clear: performance was comparable with and without phase shift with the simultaneous presentation and 1000 ms delay (phase shift, <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>1.08</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mn>0.33</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mn>0.002</mml:mn><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>3.62</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; interaction, <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>18</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.8</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mn>0.44</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>3.39</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>), while for the remaining intermediate delays recall error was consistently lower when phase shift was omitted (phase shift, <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>5.8</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:mn>0.039</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≥</mml:mo><mml:mn>0.06</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>; interaction, <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>2.8</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≥</mml:mo><mml:mn>0.13</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mn>0.001</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Minimizing retinal after-effects.</title><p>Cancelling retinal afterimages. (<bold>A</bold>) Experiment 1 RMSE for trials without phase shift. (<bold>B</bold>) Differences in RMSE between trials with and without phase shift across set size and delay conditions. Negative values indicate better performance in the condition without phase shift. Error bars indicate ±1 SEM. N = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app1-fig1-v1.tif"/></fig><p>Taken together, performance with and without phase shift of stimuli was comparable in perceptual condition (simultaneous presentation) and with the longest delay, suggesting phase shift did not change visibility or encoding of information into VWM. In contrast, we found strong evidence that observers had access to an additional source of information over intermediate delays when phase shift was not used, demonstrated by a better recall performance from 0 ms to 400 ms delay. Specifically, this source of information was available immediately after stimuli offset and was short-lived, consistent with the theoretical description of retinal afterimages (<xref ref-type="bibr" rid="bib104">Tsuchiya and Koch, 2005</xref>).</p></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Swap error estimates</title><fig id="app2fig1" position="float"><label>Appendix 2—figure 1.</label><caption><title>Swap error estimates.</title><p>(<bold>A and B</bold>) Probability of swap errors estimated from empirical data using the three-component mixture model (<xref ref-type="bibr" rid="bib4">Bays et al., 2009</xref>) in Experiment 1 (<bold>A</bold>) and Experiment 2 (<bold>B</bold>). (<bold>C and D</bold>) Probability of swap errors in best-fitting dynamic neural resource (DyNR) model in Experiment 1 (N = 10) (<bold>C</bold>) and Experiment 2 (N = 13) (<bold>D</bold>). Error bars indicate ±1 SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app2-fig1-v1.tif"/></fig></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Alternative models’ fits</title><fig id="app3fig1" position="float"><label>Appendix 3—figure 1.</label><caption><title>Experiment 1 behavioral data and model fit for the dynamic neural resource (DyNR) model without sensory persistence after stimulus offset.</title><p>(<bold>A</bold>) A version of the DyNR model with equal diffusion across set sizes. (<bold>B</bold>) A version of the DyNR model with diffusion that scales with set size. Error bars and patches indicate ±1 SEM. N = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app3-fig1-v1.tif"/></fig><fig id="app3fig2" position="float"><label>Appendix 3—figure 2.</label><caption><title>Experiment 2 behavioral data and model fit for the neural model without sensory persistence after stimulus offset.</title><p>(<bold>A</bold>) A version of the dynamic neural resource (DyNR) model without sensory persistence. (<bold>B</bold>) Separate fits of the simplified neural model to each exposure time. Error bars and patches indicate ±1 SEM. N = 13.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app3-fig2-v1.tif"/></fig><fig id="app3fig3" position="float"><label>Appendix 3—figure 3.</label><caption><title>Behavioral data and model fit for a neural model with the direct read-out of information from sensory memory for (<bold>A</bold>) Experiment 1 (N = 10) and (<bold>B</bold>) Experiment 2 (N = 13).</title><p>Error bars and patches indicate ±1 SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app3-fig3-v1.tif"/></fig><fig id="app3fig4" position="float"><label>Appendix 3—figure 4.</label><caption><title>Behavioral data and model fit for the dynamic neural resource (DyNR) model without the cue processing time for (<bold>A</bold>) Experiment 1 (N = 10) and (<bold>B</bold>) Experiment 2 (N = 13).</title><p>Error bars and patches indicate ±1 SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app3-fig4-v1.tif"/></fig><fig id="app3fig5" position="float"><label>Appendix 3—figure 5.</label><caption><title>Behavioral data and model fit for a neural model with constant accumulation of information into working memory (WM) for (<bold>A</bold>) Experiment 1 (N = 10) and (<bold>B</bold>) Experiment 2 (N = 13).</title><p>Error bars and patches indicate ±1 SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app3-fig5-v1.tif"/></fig></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>Additional dataset 1</title><p>To further investigate the role of diffusion in memory dynamics, we analyzed an additional dataset collected in our lab (<xref ref-type="bibr" rid="bib103">Tomić et al., 2024</xref>). In this experiment we varied the set size and delay duration similar to Experiment 1. In contrast to Experiment 1, we used longer memory delays, which allowed us to examine the diffusion mechanism on a more suitable time scale. Moreover, memory delays used in this study are out of reach of the decaying sensory information, enabling us to investigate the diffusion without changes in the neural signal strength post-cue.</p></sec><sec sec-type="appendix" id="s12"><title>Methods</title><p>Ten observers (six females, four males, aged 18–34) took part in this experiment. The data for this experiment was collected using the same equipment and the testing setting as described for the main experiments. A typical trial sequence is illustrated in <xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>. Each trial began with the presentation of a central annulus which served as a fixation point. Once a stable fixation was achieved, the inner annulus radius changed indicating that stimuli would appear in 500 ms. The memory sample array was then presented for a duration of 500 ms. The array consisted of one or three randomly oriented black bars (length 2.8°). Each bar was positioned in one of six predetermined locations equally distributed around the circle with a radius of 5° around center of the screen. Each bar was presented along with a placeholder circle (radius 1.5°).</p><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>Experimental procedure.</title><p>Stimuli are not drawn to scale.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app4-fig1-v1.tif"/></fig><p>Memory array presentation was followed by a memory delay during which fixation circle and placeholders stayed visible. The retention interval was either 1 s or 7 s long. After that, one stimulus was randomly cued for recall. The cue consisted of a second, larger circle drawn around one of the placeholders. Observers were instructed to start rotating a response dial (Griffin Technology PowerMate USB) once they were ready to respond. After the rotation of the response dial was detected, a randomly oriented black bar was displayed within the placeholder. Observers were instructed to rotate the dial until the displayed bar matched the remembered orientation of the cued item. Observers confirmed their response by pressing the dial. Trials with different set sizes and delay durations were randomly interleaved.</p><p>Eye movements were monitored from the beginning of the trial until stimuli offset, and observers were required to hold steady fixation during that period. If the gaze position deviated by more than 2° a message appeared on the screen and the trial was aborted and restarted with new orientations. Each observer completed 700 trials, divided into two sessions and each consisting of seven equal blocks. Two sessions were separated by at least 1 day, and each lasted approximately 1 hr. At the beginning of each session observers familiarized themselves with the task and experimental setup by doing at most 50 practice trials.</p></sec><sec sec-type="appendix" id="s13"><title>Results</title><sec sec-type="appendix" id="s13-1"><title>Behavioral data</title><p>Recall performance is shown in <xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2</xref>. As predicted, response error increased with set size and memory delay. A repeated measures ANOVA revealed a significant effect of set size (<inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>111.17</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.76</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) and memory interval (<inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>58.14</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.12</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>), and their interaction (<inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10.66</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) on response error. Moreover, conducting paired t-tests within each set size revealed recall error increased with the delay with set size 1 (<inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5.83</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1.84</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) and set size 3 (<inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5.78</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1.83</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). The interaction effect was a consequence of a larger increase in error with delay for set size 3 compared to set size 1 (<inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mn>7000</mml:mn><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mn>1000</mml:mn><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). These results are consistent with Experiment 1, corroborating our finding that increasing the set size and delay time have a disadvantageous effect on memory fidelity.</p><fig id="app4fig2" position="float"><label>Appendix 4—figure 2.</label><caption><title>Behavioral data and model fit for Experiment 1a.</title><p>Error bars and patches indicate ±1 SEM. N = 10.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app4-fig2-v1.tif"/></fig></sec><sec sec-type="appendix" id="s13-2"><title>Neural model</title><p>We fitted the DyNR model to the data to test whether noise-driven diffusion is sufficient to account for changes in recall fidelity with longer memory intervals. We applied a simplified version of the model without sensory decay and VWM accumulation components. This was justified given that estimate of sensory decay from Experiment 1 was shorter (mean life  <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math></inline-formula> = 0.21) than the shortest interval used in this experiment (1 s). Moreover, based on our findings in Experiment 2, we argue that a display duration of 500 ms is sufficient to fully encode objects into VWM.</p><p>Curves in <xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2</xref> show fits of the model with ML parameters (mean ± SE: population gain  <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> = 385.02 ± 208.3, tuning width  <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> = 2.67 ± 0.43, cue processing constant  <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>b</mml:mi></mml:mstyle></mml:math></inline-formula> = 0.68 ± 0.67, base diffusion  <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> = 0.009 ± 0.001, swap probability p = 0.005 ± 0.002). The model provided an excellent quantitative fit to response distributions and summary statistics (<xref ref-type="fig" rid="app4fig2">Appendix 4—figure 2</xref>), successfully explaining the adverse effects of set size and memory interval on recall fidelity. Critically, and consistent with results from Experiment 1, the proposed DyNR model provided a better fit to human response error compared to the matching model without diffusion (ΔAIC = 144.75) or the model in which diffusion rate increases with set size (ΔAIC = 42.3). In conclusion, this result shows that variability in representations over longer memory intervals can be fully accounted for by noise-driven accumulation without changes in the representational signal (<xref ref-type="bibr" rid="bib83">Schneegans and Bays, 2018</xref>; <xref ref-type="bibr" rid="bib68">Panichello et al., 2019</xref>; <xref ref-type="bibr" rid="bib113">Wolff et al., 2020</xref>).</p></sec></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s14"><title>Additional dataset 2</title><p>To further validate predictions of the DyNR model we fitted it to an existing WM study (Experiment 1 in <xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>). This study focused on the role of temporal dynamics during WM encoding, thereby addressing the same question as our Experiment 2. In contrast to our Experiment 2, <xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>, used a longer delay period (1100 ms), precluding the strengthening influence of decaying sensory information on recall. This dataset therefore isolates the initial information accumulation process during stimuli presentation.</p></sec><sec sec-type="appendix" id="s15"><title>Methods</title><p>The observers (<italic>N</italic>=32) performed a continuous report task in which a variable number of oriented bars was presented for a variable duration, followed by a pattern mask (100 ms) and a 1 s delay period after which one of the items was probed for recall. Set size was manipulated between observers and exposure duration was manipulated within observers. Each observer performed 100 trials per exposure duration, for a total of 25,600 trials in the study. A more detailed description of the experiment is provided in <xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>.</p></sec><sec sec-type="appendix" id="s16"><title>Analysis</title><p>Considering only exposure duration in this experiment was manipulated at the observer level, we decided to expand our modeling approach by employing a Bayesian hierarchical method as a compromise between fitting the data for each observer (i.e. set size) independently and pooling the data across all observers. Using a Bayesian hierarchical modeling, individual-observer parameters are considered samples from population distributions, whose means and variances are estimated based on all available data. In general, this approach has a desirable characteristic of constraining individual-level parameters with the population-level distribution and producing meaningful parameter estimates when a model is fitted across separate groups. The dynamic neural model fitted to the data is identical to the model fitted in Experiment 2, with the exception that here we assumed any existing post-stimulus sensory activity completely diminished by the time of the cue (1100 ms post-stimulus offset), and therefore we did not model sensory decay here. To obtain the hierarchical fit, we used the differential evolution Markov chain algorithm (<xref ref-type="bibr" rid="bib18">Braak, 2006</xref>). All individual-level parameters were samples drawn from normal (i.e. Gaussian) distributions, with corresponding mean and standard deviation being constrained by uniform hyperprior distributions. We collected 240,000 post-warmup samples across 12 chains and computed median and 95% equal-tailed intervals (ETI) of posterior distributions to obtain the group and individual-level parameter estimates. Prior specifications and empirical data for all analyses can be found along with the published code.</p></sec><sec sec-type="appendix" id="s17"><title>Results</title><p><xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref> and <xref ref-type="fig" rid="app5fig2">Appendix 5—figure 2</xref> show empirical distributions and summary statistics across all conditions. Similar to Experiment 2, increasing the exposure duration (<inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>7</mml:mn><mml:mo>,</mml:mo><mml:mn>196</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>110.9</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.188</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) and decreasing the set size (<inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>28</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>22.83</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.53</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>) had beneficial effect on response error. Interaction of exposure duration and set size was significant (<inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>21</mml:mn><mml:mo>,</mml:mo><mml:mn>196</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3.13</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>). Critically, the pattern of memory fidelity dynamics largely matches the pattern observed in Experiment 2, with response errors decreasing rapidly as presentation duration was increased from the minimum duration, saturating at longer durations. This pattern was consistent across all set sizes, which only differed in the absolute error.</p><p>These dynamics were accurately predicted by the DyNR model, both at the level of response distributions (curves in <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>) and summary statistics (curves in <xref ref-type="fig" rid="app5fig2">Appendix 5—figure 2</xref>). The parameters used to generate model predictions were obtained by taking the individual observer’s posterior medians. We observed the following hyperparameters (median and 95% ETI of hyperposterior): population gain  <inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>γ</mml:mi></mml:mstyle></mml:math></inline-formula> = 109.47 (88.1–133.57), tuning width  <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> = 3.23 (2.6–4.03), sensory rise time constant  <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.0049 (0.0019–0.0091), VWM accumulation time constant  <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">W</mml:mi><mml:mi mathvariant="normal">M</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.067 ±(0.051–0.087), cue processing constant  <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>b</mml:mi></mml:mstyle></mml:math></inline-formula> = 0.423 (0.093–0.8436), base diffusion  <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> = 0.095 (0.057–0.149), spatial uncertainty time constant  <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>τ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> = 0.031 (0.022–0.041), swap probability p = 0.02 (0.011–0.034).</p><fig id="app5fig1" position="float"><label>Appendix 5—figure 1.</label><caption><title>Empirical recall error distributions (black circles) from Experiment 1 in <xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref>, and the dynamic neural resource (DyNR) model fits to the data (colored curves).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app5-fig1-v1.tif"/></fig><fig id="app5fig2" position="float"><label>Appendix 5—figure 2.</label><caption><title>Summary statistics (black circles) from Experiment 1 in <xref ref-type="bibr" rid="bib5">Bays et al., 2011</xref> and the dynamic neural resource (DyNR) model fits to the data (colored curves).</title><p>The DyNR model was fit to the distributions of recall errors shown in <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>. Error bars and patches indicate ±1 SEM. N = 32.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-91034-app5-fig2-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.91034.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Wake Forest School of Medicine</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This study presents <bold>important</bold> insights into the dynamical process whereby sensory information is converted from stimulus-driven activity to a working memory representation from which the information can be recalled later. The evidence supporting the claims is <bold>convincing</bold>, using detailed fits and model-comparison techniques applied to new and existing psychophysical data sets to evaluate a wide variety of potential mechanisms. The overall conclusion, that iconic memory and working memory are not distinct mechanisms but rather two slightly different regimes of the same circuitry, will be of interest to neuroscientists and psychologists studying sensory systems and/or working memory.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.91034.3.sa1</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Previous work has shown subjects can use a form of short-term sensory memory, known as 'iconic memory', to accurately remember stimuli over short periods of time (several hundred milliseconds). Working memory maintains representations for longer periods of time but is strictly limited in its capacity. While it has long been assumed that sensory information acts as the input to working memory, a process model of this transfer has been missing. To address this, Tomic and Bays present the Dynamic Neural Resource (DyNR) model. The DyNR model captures the dynamics of processing sensory stimuli, transferring that representation into working memory, the diffusion of representations within working memory, and the selection of a memory for report.</p><p>The DyNR model captures many of the effects observed in behavior. Most importantly, psychophysical experiments found the greater the delay between stimulus presentation and the selection of an item from working memory, the greater the error. This effect also depended on working memory load. In the model, these effects are captured by the exponential decay of sensory representations (i.e., iconic memory) following the offset of the stimulus. Once the selection cue is presented, residual information in iconic memory can be integrated into working memory, improving the strength of the representation and reducing error. This selection process takes time, and is slower for larger memory loads, explaining the observation that memory seems to decay instantly. The authors compare the DyNR model to several variants, demonstrating the importance of persistence of sensory information in iconic memory, normalization of representations with increasing memory load, and diffusion of memories over time.</p><p>Strengths:</p><p>The manuscript provides a convincing argument for the interaction of iconic memory and working memory, as captured by the DyNR model. The analyses are cutting-edge and the results are well captured by the DyNR model. In particular, a strength of the manuscript is the comparison of the DyNR model to several alternative variants.</p><p>The results provide a process model for interactions between iconic memory and working memory. This will be of interest to neuroscientists and psychologists studying working memory. I see this work as providing a foundation for understanding behavior in continuous working memory tasks, from either a mechanistic, neuroscience, perspective or as a high-water mark for comparison to other psychological process models.</p><p>Finally, the manuscript is well written. The DyNR model is nicely described and an intuition for the dynamics of the model are clearly shown in Figures 2 and 4.</p><p>Weaknesses:</p><p>The manuscript appropriately acknowledges and addresses several minor weaknesses that are due to the limited ability of the approach to disambiguate underlying neural mechanisms. Nevertheless, the manuscript adds significant value to the literature on working memory.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.91034.3.sa2</article-id><title-group><article-title>Reviewer #3 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary</p><p>The authors set out to formally contrast several theoretical models of working memory, being particularly interested in comparing the models regarding their ability to explain cueing effects at short cue durations. These benefits are traditionally attributed to the existence of a high capacity, rapidly decaying sensory storage which can be directly read out following short latency retro-cues. Based on the model fits, the authors alternatively suggest that cue-benefits arise from a freeing of working memory resources, which at short cue latencies can be utilized to encode additional sensory information into VWM.</p><p>A dynamic neural population model consisting of separate sensory and VWM populations was used to explain temporal VWM fidelity of human behavioral data collected during several working memory tasks. VWM fidelity was probed at several timepoints during encoding, while sensory information was available and maintenance, when sensory information was no longer available. Furthermore, set size and exposure durations were manipulated to disentangle contributions of sensory and visual working memory.</p><p>Overall, the model explained human memory fidelity well, accounting for set size, exposure time, retention time, error distributions and swap errors. Crucially the model suggests that recall at short delays is due to post-cue integration of sensory information into VWM as opposed to direct readout from sensory memory. The authors formally address several alternative theories, demonstrating that models with reduced sensory persistence, direct readout from sensory memory, no set-size dependent delays in cue processing and constant accumulation rate provide significantly worse fits to the data.</p><p>I congratulate the authors for this rigorous scientific work. All my remarks were thoroughly addressed.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.91034.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Tomic</surname><given-names>Ivan</given-names></name><role specific-use="author">Author</role><aff><institution>Department of Psychology, Faculty of Humanities and Social Sciences, University of Zagreb</institution><addr-line><named-content content-type="city">Zagreb</named-content></addr-line><country>Croatia</country></aff></contrib><contrib contrib-type="author"><name><surname>Bays</surname><given-names>Paul</given-names></name><role specific-use="author">Author</role><aff><institution>University of Cambridge</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>I only have a few minor suggestions:</p><p>Abstract: I really liked the conclusion (that IM and VWM are two temporal extremes of the same process) as articulated in lines 557--563. (It is always satisfying when the distinction between two things that seem fundamentally different vanishes). If something like this but shorter could be included in the Abstract, it would highlight the novel aspects of the results a little more, I think.</p></disp-quote><p>Thank you for this comment. We have added the following to the abstract:</p><p>“A key conclusion is that differences in capacity classically thought to distinguish IM and VWM are in fact contingent upon a single resource-limited WM store.”</p><disp-quote content-type="editor-comment"><p>L 216: There's an orphan parenthesis in &quot;(justifying the use)&quot;.</p></disp-quote><p>Fixed.</p><disp-quote content-type="editor-comment"><p>L 273: &quot;One surprising result was the observed set size effect in the 0 ms delay condition&quot;. In this paragraph, it might be a good idea to remind the reader of the difference between the simultaneous and zero-delay conditions. If I got it right, the results differ between these conditions because it takes some amount of processing time to interpret the cue and free the resources associated with the irrelevant stimuli. Recalling that fact would make this paragraph easier to digest.</p></disp-quote><p>That is correct. However, at this point in the text, we have not yet fitted the DyNR model to the data. Therefore, we believe that introducing cue processing and resource reallocation as concepts that differentiate between those two conditions would disrupt the flow of this paragraph. We address these points soon after, in a paragraph starting on line 341.</p><disp-quote content-type="editor-comment"><p>Figures 3, 5: The labels at the bottom of each column in A would be more clear if placed at the top of each column instead. That way, the x-axis for the plots in A could be labeled appropriately, as &quot;Error in orientation estimate&quot; or something to that effect.</p></disp-quote><p>We edited both figures, now Figure 4 and Figure 6, as suggested.</p><disp-quote content-type="editor-comment"><p>L 379: It should be &quot;(see Eq 6)&quot;, I believe.</p></disp-quote><p>That is correct, line 379 (currently line 391) should read ‘Eq 6’. Fixed.</p><disp-quote content-type="editor-comment"><p>L 379--385: I was a bit mystified as to why the scaled diffusion rate produced a worse fit than a constant rate. I imagine the scaled version was set to something like</p><p>sigma^2_diff_scaled = sigma^2_base + K*(N-1)</p><p>where N is the set size and sigma^2_base and K are parameters. If this model produced a similar fit as with a constant diffusion rate, the AIC would penalize it because of the extra parameter. But why would the fit be worse (i.e., not match the pattern of variability)? Shouldn't the fitter just find that the K=0 solution is the best? Not a big deal; the Nelder-Mead solutions can wobble when that many parameters are involved, but if there's a simple explanation it might be worth commenting on.</p></disp-quote><p>The scaled diffusion was implemented by extending Eq 6 in the following way:</p><p>σ(t)2 = (t-toffset) * σ̇ 2diff * N</p><p>where N is set size. Therefore, the scaling was not associated with a free parameter that could become 0 if set size did not affect diffusion rate, but variability rather mandatory increased with set size. We now clarify this in the text:</p><p>“The second variant was identical to the proposed model, except that we replaced the constant diffusion rate with a set size scaled diffusion rate by multiplying the right side of Eq 6 by N.“</p><disp-quote content-type="editor-comment"><p>Figure 4 is not mentioned in the main text. Maybe the end of L 398 would be a good place to point to it. The paragraph at L 443-455 would also benefit from a couple of references to it.</p></disp-quote><p>Thank you for this suggestion. Figure 4 (now Figure 5) was previously mentioned on line 449 (previously line 437), but now we have included it on line 410 (previously line 398), within the paragraph spanning lines 455-467 (previously 443-455), and also on line 136 where we first discuss masking effects.</p><disp-quote content-type="editor-comment"><p>L 500: Figure S7 is mentioned before Figures S5 and S6. Quite trivial, I know....</p></disp-quote><p>Thank you for this comment. There was no specific reason for Figure S7 to appear after S5 &amp; S6, so we simply swapped their order to be consistent with how they are referred to in the manuscript (i.e., S7 became S5, S5 became S6, and S6 became S7).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>(1) One potential weakness is that the model assumes sensory information is veridical. However, this isn't likely the case. Acknowledging noise in sensory representations could affect the model interpretation in a couple of different ways. First, neurophysiological recordings have shown normalization affects sensory representations, even when a stimulus is still present on the screen. The DyNR model partially addresses this concern because reports are drawn from working memory, which is normalized. However, if sensory representations were also normalized, then it may improve the model variant where subjects draw directly from sensory representations (an alternative model that is currently described but discarded).</p></disp-quote><p>Thank you for this suggestion. We can consider two potential mechanisms through which divisive normalization might be incorporated into sensory processing within the DyNR model.</p><p>The first possibility involves assuming that normalization is pre-attentive. In this scenario, the sensory activity of each object would be rescaled at the lowest level of sensory processing, occurring before the allocation of attentional or VWM resources. One strong prediction of such an implementation is that recall error in the simultaneous cue condition (Experiment 1) should vary with set size. However, this prediction is inconsistent with the observed data, which failed to show a significant difference between set sizes, and is more closely aligned with the hypothesis of no-difference (F(2,18) = 1.26, p = .3, η2 = .04, BF10 = 0.47). On that basis, we anticipate that introducing normalization as a pre-attentive mechanism would impair the model fit.</p><p>An alternative scenario is to consider normalization as post-attentive. In the simultaneous cueing condition, only one item is attended (i.e., the cued one), regardless of the displayed set size. Here, we would expect normalized activity for a single item, regardless of the number of presented objects, which would then be integrated into VWM. This expanded DyNR model with post-attentive normalization would make exactly the same predictions as the proposed DyNR for recall fidelity, so distinguishing between these models would not be possible based on working memory experiments.</p><p>To acknowledge the possibility that sensory signals could undergo divisive normalization and to motivate future research, we have added the following to our manuscript:</p><p>“As well as being implicated in higher cognitive processes including VWM (Buschman et al, 2011; Sprague et al., 2014), divisive normalization has been shown to be widespread in basic sensory processing (Bonin et al., 2005; Busse et al., 2009; Ni et al., 2017). The DyNR model presently incorporates the former but not the latter type of normalization. While the data observed in our experiments do not provide evidence for normalization of sensory signals (note comparable recall errors across set size in the simultaneous cue condition of Experiment 1), this may be because sensory suppressive effects are localized and our stimuli were relatively widely separated in the visual field: future research could explore the consequences of sensory normalization for recall from VWM using, e.g., centre-surround stimuli (Bloem et al., 2018).”</p><p>Bloem, I. M., Watanabe, Y. L., Kibbe, M. M., &amp; Ling, S. (2018). Visual Memories Bypass Normalization. Psychological Science, 29(5), 845–856. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797617747091">https://doi.org/10.1177/0956797617747091</ext-link></p><p>Bonin, V., Mante, V., &amp; Carandini, M. (2005). The Suppressive Field of Neurons in Lateral Geniculate Nucleus. The Journal of Neuroscience, 25(47), 10844–10856. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3562-05.2005">https://doi.org/10.1523/JNEUROSCI.3562-05.2005</ext-link></p><p>Buschman, T. J., Siegel, M., Roy, J. E., &amp; Miller, E. K. (2011). Neural substrates of cognitive capacity limitations. Proceedings of the National Academy of Sciences, 108(27), 11252–11255. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1104666108">https://doi.org/10.1073/pnas.1104666108</ext-link></p><p>Busse, L., Wade, A. R., &amp; Carandini, M. (2009). Representation of Concurrent Stimuli by Population Activity in Visual Cortex. Neuron, 64(6), 931–942. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.11.004">https://doi.org/10.1016/j.neuron.2009.11.004</ext-link></p><p>Ni, A. M., &amp; Maunsell, J. H. R. (2017). Spatially tuned normalization explains attention modulation variance within neurons. Journal of Neurophysiology, 118(3), 1903–1913. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00218.2017">https://doi.org/10.1152/jn.00218.2017</ext-link></p><p>Sprague, T. C., Ester, E. F., &amp; Serences, J. T. (2014). Reconstructions of Information in Visual Spatial Working Memory Degrade with Memory Load. Current Biology, 24(18), 2174–2180. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2014.07.066">https://doi.org/10.1016/j.cub.2014.07.066</ext-link></p><disp-quote content-type="editor-comment"><p>Second, visual adaptation predicts sensory information should decrease over time. This would predict that for long stimulus presentation times, the error would increase. Indeed, this seems to be reflected in Figure 5B. This effect is not captured by the DyNR model.</p></disp-quote><p>Indeed, neural responses in the visual cortex have been observed to quickly adapt during stimulus presentation, showing reduced responses to prolonged stimuli after an initial transient (Groen et al., 2022; Sawamura et al., 2006; Zhou et al., 2019). This adaptation typically manifests as (1) reduced activity towards the end of stimulus presentation and (2) a faster decay towards baseline activity after stimulus offset.</p><p>In the DyNR model, we use an idealized solution in which we convolve the presented visual signal with a response function (i.e., temporal filter). At the longest presentation durations, in DyNR, the sensory signal plateaus and remains stable until stimulus offset. Because our psychophysical data does not allow us to identify the exact neural coding scheme that underlies the sensory signal, we tend to favour this simple implementation, which is broadly consistent with some previous attempts to model temporal dynamics in sensory responses (e.g., Carandini and Heeger, 1994). However, we agree with the reviewer that some adaptation of the sensory signal with prolonged presentation would also be consistent with our data.</p><p>We have added the following to the manuscript:</p><p>“In Experiment 2, the longest presentation duration shows an upward trend in error at set sizes 4 and 10. While this falls within the range of measurement error, it is also possible that this is a meaningful pattern arising from visual adaptation of the sensory signal, whereby neural populations reduce their activity after prolonged stimulation. This would mean less residual sensory signal would be available after the cue to supplement VWM activity, predicting a decline in fidelity at higher set sizes. Visual adaptation has previously been successfully accounted for by a type of delayed normalization model in which the sensory signal undergoes a series of linear and nonlinear transformations (Zhou et al., 2019). Such a model could in future be incorporated into DyNR and validated against psychophysical and neural data.”</p><p>Carandini, M., &amp; Heeger, D. J. (1994). Summation and division by neurons in primate visual cortex. Science, 264(5163), 1333–1336. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.8191289">https://doi.org/10.1126/science.8191289</ext-link></p><p>Groen, I. I. A., Piantoni, G., Montenegro, S., Flinker, A., Devore, S., Devinsky, O., Doyle, W., Dugan, P., Friedman, D., Ramsey, N. F., Petridou, N., &amp; Winawer, J. (2022). Temporal Dynamics of Neural Responses in Human Visual Cortex. The Journal of Neuroscience, 42(40), 7562–7580. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1812-21.2022">https://doi.org/10.1523/JNEUROSCI.1812-21.2022</ext-link></p><p>Sawamura, H., Orban, G. A., &amp; Vogels, R. (2006). Selectivity of Neuronal Adaptation Does Not Match Response Selectivity: A Single-Cell Study of the fMRI Adaptation Paradigm. Neuron, 49(2), 307–318. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.11.028">https://doi.org/10.1016/j.neuron.2005.11.028</ext-link></p><p>Zhou, J., Benson, N. C., Kay, K., &amp; Winawer, J. (2019). Predicting neuronal dynamics with a delayed gain control model. PLOS Computational Biology, 15(11), e1007484. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1007484">https://doi.org/10.1371/journal.pcbi.1007484</ext-link></p><disp-quote content-type="editor-comment"><p>(2) A second potential weakness is that, in Experiment 1, the authors briefly change the sensory stimulus at the end of the delay (a 'phase shift', Fig. 6A). I believe this is intended to act as a mask. However, I would expect that, in the DyNR model, this should be modeled as a new sensory input (in Experiment 2, 50 ms is plenty of time for the subjects to process the stimuli). One might expect this change to disrupt sensory and memory representations in a very characteristic manner. This seems to make a strong testable hypothesis. Did the authors find evidence for interference from the phase shift?</p></disp-quote><p>The phase shift was implemented with the intention of reducing retinal after-effects, essentially acting as a mask for retinal information only; crucially the orientation of the stimulus is unchanged by the phase shift, so from the perspective of the DyNR model, it transmits the same orientation information to working memory as the original stimulus.</p><p>If our objective were to model sensory input at the level of individual neurons and their receptive fields, we would indeed need to treat this phase shift as a novel input. Nevertheless, for DyNR, conceived as an idealization of a biological system for encoding orientation information, we can safely assume that visual areas in biological organisms have a sufficient number of phase-sensitive simple cells and phase-indifferent complex cells to maintain the continuity of input to VWM.</p><p>When comparing conditions with and without the phase shift of stimuli (Fig S1B), we found performance to be comparable in the perceptual condition (simultaneous presentation) and with the longest delay (1 second), suggesting that the phase shift did not change the visibility or encoding of information into VWM. In contrast, we found strong evidence that observers had access to an additional source of information over intermediate delays when the phase shift was not used. This was evident through enhanced recall performance from 0 ms to 400 ms delay. Based on this, we concluded that the additional source of information available in the absence of a phase shift was accessible immediately following stimulus offset and had a brief duration, aligning with the theoretical concept of retinal afterimages.</p><disp-quote content-type="editor-comment"><p>(3) It seems odd that the mask does not interrupt sensory processing in Experiment 2. Isn't this the intended purpose of the mask? Should readers interpret this as all masks not being effective in disrupting sensory processing/iconic memory? Or is this specific to the mask used in the experiment?</p></disp-quote><p>Visual masks are often described as instantly and completely halting the visual processing of information that preceded the mask. We also anticipated the mask would entirely terminate sensory processing, but our data indicate the effect was not complete (as indicated by model variants in Experiment 2). Nevertheless, we believe we achieved our intended goal with this experiment – we observed a clear modulation of response errors with changing stimulus duration, indicating that the post-stimulus information that survived masking did not compromise the manipulation of stimulus duration. Moreover, the DyNR model successfully accounted for the portion of signal that survived the mask.</p><p>We can identify two possible reasons why masking was incomplete. First, it is possible that the continuous report measure used in our experiments is more sensitive than the discrete measures (e.g., forced-choice methods) commonly employed in experiments that found masks to be 100% effective. Second, despite using a flickering white noise mask at full contrast, it is possible that it may not have been the most effective mask; for instance, a mask consisting of many randomly oriented Gabor patches matched in spatial frequency to the stimuli could prove more effective. We decided against such a mask because we were concerned that it could potentially act as a new input to orientation-sensitive neurons, rather than just wiping out any residual sensory activity.</p><disp-quote content-type="editor-comment"><p>(4) I apologize if I missed it, but the authors did not compare the DyNR model to a model without decaying sensory information for Experiment 1.</p></disp-quote><p>We tested two DyNR variants in which the diffusion process was solely responsible for memory fidelity dynamics. These models assumed that the sensory signal terminates abruptly with stimuli offset, and the VWM signal encoding the stimuli was equal to the limit imposed by normalization, independent of the delay duration.</p><p>As variants of this model failed to account for the observed response errors both quantitatively (see 'Fixed neural signal' under Model variants) and qualitatively (Figure S3), we decided not to test any more restrictive variants, such as the one without sensory decay and diffusion.</p><disp-quote content-type="editor-comment"><p>(5) In the current model, selection is considered to be absolute (all or none). However, this need not be the case (previous work argues for graded selection). Could a model where memories are only partially selected, in a manner that is mediated by load, explain the load effects seen in behavior?</p></disp-quote><p>Thank you for this point. If attentional selection was partial, it would affect the observers’ efficiency in discarding uncued objects to release allocated resources and encode additional information about the cued item. We and others have previously examined whether humans can efficiently update their VWM when previous items become obsolete. For example, Taylor et al. (2023) showed that observers could efficiently remove uncued items from VWM and reallocate the released resources to new visual information. These findings align with results from other studies (e.g., Ecker, Oberauer, &amp; Lewandowsky, 2014; Kessler &amp; Meiran, 2006; Williams et al., 2013).</p><p>Based on these findings, we feel justified in assuming that observers in our current task were capable of fully removing all uncued objects, allowing them to continue the encoding process for the cued orientation that was already partially stored in VWM, such that the attainable limit on representational precision for the cued item equals the maximum precision of VWM.</p><p>Partial removal could in principle be modelled in the DyNR model by introducing an additional plateau parameter specifying a maximum attainable precision after the cue. Our concern would be that such a plateau parameter would trade off with the parameter associated with Hick’s law (i.e., cue interpretation time). The former would control the amount of information that can be encoded into VWM, while the latter regulates the amount of sensory information available for encoding. We are wary of adding additional parameters, and hence flexibility, to the model where we do not have the data to sufficiently constrain them.</p><p>Ecker, U. K. H., Oberauer, K., &amp; Lewandowsky, S. (2014b). Working memory updating involves item-specific removal. Journal of Memory and Language, 74, 1–15. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jml">https://doi.org/10.1016/j.jml</ext-link>. 2014.03.006</p><p>Kessler, Y., &amp; Meiran, N. (2006). All updateable objects in working memory are updated whenever any of them are modified: Evidence from the memory updating paradigm. Journal of Experimental Psychology: Learning, Memory, and Cognition, 32, 570–585. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0278-7393.32.3.570">https://doi.org/10.1037/0278-7393.32.3.570</ext-link></p><p>Taylor, R., Tomić, I., Aagten-Murphy, D., &amp; Bays, P. M. (2023). Working memory is updated by reallocation of resources from obsolete to new items. Attention, Perception, &amp; Psychophysics, 85(5), 1437–1451. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-022-02584-2">https://doi.org/10.3758/s13414-022-02584-2</ext-link></p><p>Williams, M., &amp; Woodman, G. F. (2012). Directed forgetting and directed remembering in visual working memory. Journal of Experimental Psychology. Learning, Memory, and Cognition, 38(5), 1206–1220. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0027389">https://doi.org/10.1037/a0027389</ext-link></p><disp-quote content-type="editor-comment"><p>(6) Previous work, both from the authors and others, has shown that memories are biased as if they are acted on by attractive/repulsive forces. For example, the memory of an oriented bar is biased away from horizontal and vertical and biased towards diagonals. This is not accounted for in the current model. In particular, this could be one mechanism to generate a non-uniform drift rate over time. As noted in the paper, a non-uniform drift rate could capture many of the behavioral effects reported.</p></disp-quote><p>The reviewer is correct that the model does not currently include stimulus-specific effects, although our work on that topic provides a clear template for incorporating them in future (e.g. Taylor &amp; Bays, 2018). Specifically on the question of generating a non-uniform drift, we have another project that currently looks at this exact question (cited in our manuscript as Tomic, Girones, Lengyel, and Bays; in prep.). By examining various datasets with varying memory delays, including the Additional Dataset 1 reported in the Supplementary Information, we found that stimulus-specific effects on orientation recall remain constant with retention time. Specifically, although there is a clear increase in overall error over time, estimation biases remain constant in direction and amplitude, indicating that the bias does not manifest in drift rates (see also Rademaker et al., 2018; Figure S1).</p><p>Taylor, R., &amp; Bays, P. M. (2018). Efficient coding in visual working memory accounts for stimulus-specific variations in recall. The Journal of Neuroscience, 1018–18. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1018-18.2018">https://doi.org/10.1523/JNEUROSCI.1018-18.2018</ext-link></p><p>Rademaker, R. L., Park, Y. E., Sack, A. T., &amp; Tong, F. (2018). Evidence of gradual loss of precision for simple features and complex objects in visual working memory. Journal of Experimental Psychology: Human Perception and Performance. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/xhp0000491">https://doi.org/10.1037/xhp0000491</ext-link></p><disp-quote content-type="editor-comment"><p>(7) Finally, the authors use AIC to compare many different model variants to the DyNR model. The delta-AICs are high (&gt;10), indicating a strong preference for the DyNR model over the variants. However, the overall quality of fit to the data is not clear. What proportion of the variance in data was the model able to explain? In particular, I think it would be helpful for the reader if the authors reported the variance explained on withheld data (trials, conditions, or subjects).</p></disp-quote><p>Thank you for this comment.</p><p>Below we report the estimates of r2, representing the goodness of fit between observed data (i.e., RMSE) and the DyNR model predictions.</p><p>In Experiment 1, the r2 values between observations and predictions were computed across delays for each set size, yielding the following estimates: r2ss1 = 0.60; r2ss4 = 0.87; r2ss10 = 0.95. Note that lower explained variance for set size 1 arises from both data and model predictions having near-constant precision.</p><p>In Experiment 2, we calculated r2 between observations and predictions across presentation durations, separately for each set size, resulting in the following estimates: r2ss1 = 0.88; r2ss4 = 0.71; r2ss10 = 0.70. Note that in this case the decreasing percentage of explained variance with set size is a consequence of having less variability in both data and model predictions with larger set sizes.</p><p>While these estimates suggest that the DyNR model effectively fits the psychophysical data, a more rigorous validation approach would involve cross-validation checks across all conditions with a withheld portion of trials. Regrettably, due to the large number of conditions in each experiment, we could only collect 50 trials per condition. We are sceptical that fitting the model to even fewer trials, as necessary for cross-validation, would provide a reliable assessment of model performance.</p><disp-quote content-type="editor-comment"><p>Minor: It isn't clear to me why the behavioral tasks are shown in Figure 6. They are important for understanding the results and are discussed earlier in the manuscript (before Figure 3). This just required flipping back and forth to understand the task before I could interpret the results.</p></disp-quote><p>Thank you for this comment. We have now moved the behavioural task figure to appear early in the manuscript (as Figure 3).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>(1) Dynamics of sensory signals during perception</p><p>I believe that the modeled sensory signal is a reasonable simplification and different ways to model the decay function are discussed. I would like to ask the authors to discuss the implications of slightly more complex initial sensory transients such as the ones shown in Teeuwen (2021). Specifically for short exposure times, this might be particularly relevant for the model fits as some of the alternative models diverge from the data for short exposures. In addition, the role of feedforward (initial transient?) and feedback signaling (subsequent &quot;plateau&quot; activity) could be discussed. The first one might relate more strongly to sensory signals whereas the latter relates more to top-down attention/recurrent processing/VWM.</p><p>Particularly, this latter response might also be sensitive to the number of items present on the screen which leads to a related question pertaining to the limitations of attention during perception. Some work suggests that perception is similarly limited in the amount of information that can be represented concurrently (Tsubomi, 2013). Could the authors discuss the implications of this hypothesis? What happens if maximum sensory amplitude is set as a free parameter in the model?</p><p>Tsubomi, H., Fukuda, K., Watanabe, K., &amp; Vogel, E. K. (2013). Neural limits to representing objects still within view. Journal of Neuroscience, 33(19), 8257-8263.</p></disp-quote><p>Thank you for this question. Below, we unpack it and answer it point by point.</p><p>While we agree our model of the sensory response is justified as an idealization of the biological reality, we also recognise that recent electrophysiological recordings have illuminated intricacies of neuronal responses within the striate cortex, a critical neural region associated with sensory memory (Teeuwen et al, 2021). Notably, these recordings reveal a more nuanced pattern where neurons exhibit an initial burst of activity succeeded by a lower plateau in firing rate, and stimulus offset elicits a second small burst in the response of some neurons, followed by a gradual decrease in activity after the stimulus disappears (Teeuwen et al, 2021).</p><p>In general, asynchronous bursts of activity in individual neurons will tend to average out in the population making little difference to predictions of the DyNR model. Synchronized bursts at stimulus onset could affect predictions for the shortest presentations in Exp 2, however the model appears to capture the data very well without including them. We would be wary of incorporating these phenomena into the model without more clarity on their universality (e.g., how stimulus-dependent they are), their significance at the population level (as opposed to individual neurons), and most importantly, their prominence in visual areas outside striate cortex. Specifically, while Teeuwen et al. (2021) described activity in V1, our model does not make strong assumptions about which visual areas are the source of the sensory input to WM. Based on these uncertainties we believe the idealized sensory response is justified for use in our model.</p><p>Next, thank you for the comment on feedforward and feedback signals. We have added the following to our manuscript:</p><p>“Following onset of a stimulus, the visual signal ascends through visual areas via a cascade of feedforward connections. This feedforward sweep conveys sensory information that persists during stimulus presentation and briefly after it disappears (Lamme et al., 1998). Simultaneously, reciprocal feedback connections carry higher-order information back towards antecedent cortical areas (Lamme and Roelfsema, 2000). In our psychophysical task, feedback connections likely play a critical role in orienting attention towards the cued item, facilitating the extraction of persisting sensory signals, and potentially signalling continuous information on the available resources for VWM encoding. While our computational study does not address the nature of these feedforward and feedback signals, a challenge for future research is to describe the relative contributions of these signals in mediating transmission of information between sensory and working memory (Semedo et al., 2022).”</p><p>Lamme, V. A., Supèr, H., &amp; Spekreijse, H. (1998). Feedforward, horizontal, and feedback processing in the visual cortex. Current Opinion in Neurobiology, 8(4), 529–535. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0959-4388(98)80042-1">https://doi.org/10.1016/S0959-4388(98)80042-1</ext-link></p><p>Lamme, V. A. F., &amp; Roelfsema, P. R. (2000). The distinct modes of vision offered by feedforward and recurrent processing. Trends in Neurosciences, 23(11), 571–579. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0166-2236(00)01657-X">https://doi.org/10.1016/S0166-2236(00)01657-X</ext-link></p><p>Semedo, J. D., Jasper, A. I., Zandvakili, A., Krishna, A., Aschner, A., Machens, C. K., Kohn, A., &amp; Yu, B. M. (2022). Feedforward and feedback interactions between visual cortical areas use different population activity patterns. Nature Communications, 13(1), 1099. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41467-022-28552-w">https://doi.org/10.1038/s41467-022-28552-w</ext-link></p><p>Finally, both you and Reviewer 2 raised a similar interesting question regarding capacity limitations of attention during perception Such a limitation could be modelled by freely estimating sensory amplitude and implementing divisive normalization to that signal, similar to how VWM is constrained. We can consider two potential mechanisms through which divisive normalization might be incorporated into sensory processing within the DyNR model.</p><p>The first possibility involves assuming that normalization is pre-attentive. In this scenario, the sensory activity of each object would be rescaled at the lowest level of sensory processing, occurring before the allocation of attentional or VWM resources. One strong prediction of such an implementation is that recall error in the simultaneous cue condition (Experiment 1) should vary with set size. However, this prediction is inconsistent with the observed data, which failed to show a significant difference between set sizes, and is more closely aligned with the hypothesis of no-difference (F(2,18) = 1.26, p = .3, η2 = .04, BF10 = 0.47). On that basis, we anticipate that introducing normalization as a pre-attentive mechanism would impair the model fit.</p><p>An alternative scenario is to consider normalization as post-attentive. In the simultaneous cueing condition, only one item is attended (i.e., the cued one), regardless of the displayed set size. Here, we would expect normalized activity for a single item, regardless of the number of presented objects, which would then be integrated into VWM. This expanded DyNR model with post-attentive normalization would make exactly the same predictions as the proposed DyNR for recall fidelity, so distinguishing between these models would not be possible based on working memory experiments.</p><p>To acknowledge the possibility that sensory signals could undergo divisive normalization and to motivate future research, we have added the following to our manuscript:</p><p>“As well as being implicated in higher cognitive processes including VWM (Buschman et al, 2011; Sprague et al., 2014), divisive normalization has been shown to be widespread in basic sensory processing (Bonin et al., 2005; Busse et al., 2009; Ni et al., 2017). The DyNR model presently incorporates the former but not the latter type of normalization. While the data observed in our experiments do not provide evidence for normalization of sensory signals (note comparable recall errors across set size in the simultaneous cue condition of Experiment 1), this may be because sensory suppressive effects are localized and our stimuli were relatively widely separated in the visual field: future research could explore the consequences of sensory normalization for recall from VWM using, e.g., centre-surround stimuli (Bloem et al., 2018).”</p><p>Bloem, I. M., Watanabe, Y. L., Kibbe, M. M., &amp; Ling, S. (2018). Visual Memories Bypass Normalization. Psychological Science, 29(5), 845–856. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797617747091">https://doi.org/10.1177/0956797617747091</ext-link></p><p>Bonin, V., Mante, V., &amp; Carandini, M. (2005). The Suppressive Field of Neurons in Lateral Geniculate Nucleus. The Journal of Neuroscience, 25(47), 10844–10856. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3562-05.2005">https://doi.org/10.1523/JNEUROSCI.3562-05.2005</ext-link></p><p>Buschman, T. J., Siegel, M., Roy, J. E., &amp; Miller, E. K. (2011). Neural substrates of cognitive capacity limitations. Proceedings of the National Academy of Sciences, 108(27), 11252–11255. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1104666108">https://doi.org/10.1073/pnas.1104666108</ext-link></p><p>Busse, L., Wade, A. R., &amp; Carandini, M. (2009). Representation of Concurrent Stimuli by Population Activity in Visual Cortex. Neuron, 64(6), 931–942. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.11.004">https://doi.org/10.1016/j.neuron.2009.11.004</ext-link></p><p>Ni, A. M., &amp; Maunsell, J. H. R. (2017). Spatially tuned normalization explains attention modulation variance within neurons. Journal of Neurophysiology, 118(3), 1903–1913. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00218.2017">https://doi.org/10.1152/jn.00218.2017</ext-link></p><p>Sprague, T. C., Ester, E. F., &amp; Serences, J. T. (2014). Reconstructions of Information in Visual Spatial Working Memory Degrade with Memory Load. Current Biology, 24(18), 2174–2180. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2014.07.066">https://doi.org/10.1016/j.cub.2014.07.066</ext-link></p><disp-quote content-type="editor-comment"><p>(2) Effectivity of retro-cues at long delays</p><p>Can the authors discuss how cues presented at long delays (&gt;1000 ms) can still lead to increased memory fidelity when sensory signals are likely to have decayed? A list of experimental work demonstrating this can be found in Souza &amp; Oberauer (2016).</p></disp-quote><p>Souza, A. S., &amp; Oberauer, K. (2016). In search of the focus of attention in working memory: 13 years of the retro-cue effect. Attention, Perception, &amp; Psychophysics, 78, 1839-1860.</p><p>The increased memory fidelity observed with longer delays between memory array offset and cue does not result from integrating available sensory signals into VWM because the sensory signal would have completely decayed by that time. Instead, research so far has indicated several alternative mechanisms that could lead to higher recall precision for cued items, and we can briefly summarize some of them, which are also reviewed in more detail in Souza and Oberauer (2016).</p><p>One possibility is that, after a highly predictive retro-cue indicates the to-be-tested item, uncued items can simply be removed from VWM. This could result in decreased interference for the cued item, and consequently higher recall precision. Secondly, the retro-cue could also indicate which item can be selectively attended to, and thereby differentially strengthening it in memory. Furthermore, the retro-cue could allow evidence to accumulate for the target item ahead of decision-making, and this could increase the probability that the correct information will be selected for response. Finally, the retro-cued stimulus could be insulated from interference by subsequent visual input, while the uncued stimuli may remain prone to such interference.</p><p>A neural account of this retro-cue effect based on the original neural resource model has been proposed in Bays &amp; Taylor, Cog Psych, 2018. However, as we did not use a retro-cue design in the present experiments, we have decided not to elaborate on this in the manuscript.</p><disp-quote content-type="editor-comment"><p>(3) Swap errors</p><p>I am somewhat surprised by the empirically observed and predicted pattern of swap errors displayed in Figure S2. For set size 10, swap probability does not consistently increase with the duration of the retention interval, although this was predicted by the author's model. At long intervals, swap probability is significantly higher for large compared to small set sizes, which also seems to contrast with the idea of shared, limited VWM resources. Can the authors provide some insight into why the model fails to reproduce part of the behavioral pattern for swap errors? The sentence in line 602 might also need some reconsideration in this regard.</p></disp-quote><p>Determining the ground truth for swap errors poses a challenge. The prevailing approach has been to employ a simpler model that estimates swap errors, such as a three-component mixture model, and use those estimates as a proxy for ground truth. However, this method is not without its shortcomings. For example, the variability of swap frequency estimates tends to increase with variability in the report feature dimension (here, orientation). This is due to the increasing overlap of response probability distributions for swap and non-swap responses. Consequently, the discrepancy between any two methods of swap estimation is most noticeable when there is substantial variability in orientation reports (e.g., 10 items and long delay or short exposure).</p><p>When modelling swap frequency in the DyNR model, our aim was to provide a parsimonious account of swap errors while implementing similar dynamics in the spatial (cue) feature as in the orientation (report) feature. This parametric description captured the overall pattern of swap frequency with set size and retention and encoding time, but is still only an approximation of the predictions if we fully modelled memory for the conjunction of cue and report features (as in e.g. Schneegans &amp; Bays, 2017; McMaster et al, 2020).</p><p>We expanded the existing text in the section ‘Representational dynamics of cue-dimension features’ of our manuscript:</p><p>“… Although we did not explicitly model the neural signals representing location, the modelled dynamics in the probability of swap errors were consistent with those of the primary memory feature. We provided a more detailed neural account of swap errors in our earlier works that is theoretically compatible with the DyNR model (McMaster et al., 2020; Schneegans &amp; Bays, 2017).</p><p>The DyNR model successfully captured the observed pattern of swap frequencies (intrusion errors). The only notable discrepancy between DyNR and the three-component mixture model (Fig. S2) arises with the largest set size and longest delay, although with considerable interindividual variability. As the variability in report-dimension increases, the estimates of swap frequency become more variable due to the growing overlap between the probability distributions of swap and non-swap responses. This may explain apparent deviations from the modelled swap frequencies with the highest set size and longest delay where orientation response variability was greatest. “</p><p>McMaster, J. M. V., Tomić, I., Schneegans, S., &amp; Bays, P. M. (2022). Swap errors in visual working memory are fully explained by cue-feature variability. Cognitive Psychology, 137, 101493. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cogpsych.2022.101493">https://doi.org/10.1016/j.cogpsych.2022.101493</ext-link></p><p>Schneegans, S., &amp; Bays, P. M. (2017). Neural Architecture for Feature Binding in Visual Working Memory. The Journal of Neuroscience, 37(14), 3913–3925. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3493-16.2017">https://doi.org/10.1523/JNEUROSCI.3493-16.2017</ext-link></p><disp-quote content-type="editor-comment"><p>(4) Direct sensory readout</p><p>The model assumes that readout from sensory memory and from VWM happens with identical efficiency. Currently, we don't know if these two systems are highly overlapping or are fundamentally different in terms of architecture and computation. In the case of the latter, it might be less reasonable to assume that information readout would happen at similar efficiencies, as it is currently assumed in the manuscript. Perhaps the authors could briefly discuss this possibility.</p></disp-quote><p>In the direct sensory read-out model, we did not explicitly model the efficiency of readout from either sensory or VWM store. However, the distinctive prediction of this model is that the precision of recall changes exponentially with delay at every set size, including one item. This prediction does not depend on the relative efficiency of readout from sensory and working memory, but only on the principle that direct readout from sensory memory bypasses the capacity limit on working memory. This prediction is inconsistent with the pattern of results observed in Experiment 1, where early cues did not show a beneficial effect on recall error for set size 1. While the proposal raised by the reviewer is intriguing, even if we were to model the process of readout from both the sensory and VWM stores with different efficiencies, the direct read-out model could not account for the near-constant recall error with delay for set size one.</p><disp-quote content-type="editor-comment"><p>(5) Encoding of distractors</p><p>One of the model assumptions is that, for simultaneous presentations of memory array and cue only the cued feature will be encoded. Previous work has suggested that participants often accidentally encode distractors even when they are cued before memory array onset (Vogel 2005). Given these findings, how reasonable is this assumption in the authors' model?</p><p>Vogel, E. K., McCollough, A. W., &amp; Machizawa, M. G. (2005). Neural measures reveal individual differences in controlling access to working memory. Nature, 438(7067), 500-503.</p></disp-quote><p>Although previous research suggested that observers can misinterpret the pre-cue and encode one of the uncued items, our results argue against this being the case in the current experiment. Such encoding failures would manifest in overall recall error, resulting in a gradient of error with set size, owing to the presence of more adjacent distractors in larger set sizes. However, when we compared recall errors between set sizes in the simultaneous cue condition, we did not find a significant difference between set sizes, and moreover, our results were more likely under the hypothesis of no-difference (F(2,18) = 1.26, p = .3, η2 = .04, BF10 = 0.47). If observers occasionally encoded and reported one of the uncued items in the simultaneous cue condition, those errors were extremely infrequent and did not affect the overall error distributions.</p></body></sub-article></article>