<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">81499</article-id><article-id pub-id-type="doi">10.7554/eLife.81499</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Contrasting action and posture coding with hierarchical deep neural network models of proprioception</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-308513"><name><surname>Sandbrink</surname><given-names>Kai J</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-308514"><name><surname>Mamidanna</surname><given-names>Pranav</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-308515"><name><surname>Michaelis</surname><given-names>Claudio</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-122748"><name><surname>Bethge</surname><given-names>Matthias</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6417-7812</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-187946"><name><surname>Mathis</surname><given-names>Mackenzie W</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7368-4456</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-200232"><name><surname>Mathis</surname><given-names>Alexander</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3777-2202</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Brain Mind Institute</institution>, <institution>École Polytechnique Fédérale de Lausanne</institution>, <addr-line><named-content content-type="city">Genève</named-content></addr-line>, <country>Switzerland</country></aff><aff id="aff2"><institution content-type="dept">Tübingen AI Center</institution>, <institution>Eberhard Karls Universität Tübingen</institution>, <addr-line><named-content content-type="city">Tübingen</named-content></addr-line>, <country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-196287"><name><surname>Ba</surname><given-names>Demba</given-names></name><role>Reviewing editor</role><aff><institution>Harvard University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>mackenzie@post.harvard.edu</email> (MM);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>alexander.mathis@epfl.ch</email> (AM);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>31</day><month>05</month><year>2023</year></pub-date><volume>12</volume><elocation-id>e81499</elocation-id><history><date date-type="received"><day>30</day><month>06</month><year>2022</year></date><date date-type="accepted"><day>16</day><month>05</month><year>2023</year></date></history><permissions><copyright-statement>© 2023, Sandbrink et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Sandbrink et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-81499-v1.pdf"/><abstract><p>Biological motor control is versatile, efficient, and depends on proprioceptive feedback. Muscles are flexible and undergo continuous changes, requiring distributed adaptive control mechanisms that continuously account for the body's state. The canonical role of proprioception is representing the body state. We hypothesize that the proprioceptive system could also be critical for high-level tasks such as action recognition. To test this theory, we pursued a task-driven modeling approach, which allowed us to isolate the study of proprioception. We generated a large synthetic dataset of human arm trajectories tracing characters of the Latin alphabet in 3D space, together with muscle activities obtained from a musculoskeletal model and model-based muscle spindle activity. Next, we compared two classes of tasks: trajectory decoding and action recognition, which allowed us to train hierarchical models to decode either the position and velocity of the end-effector of one's posture or the character (action) identity from the spindle firing patterns. We found that artificial neural networks could robustly solve both tasks, and the networks'units show tuning properties similar to neurons in the primate somatosensory cortex and the brainstem. Remarkably, we found uniformly distributed directional selective units only with the action-recognition-trained models and not the trajectory-decoding-trained models. This suggests that proprioceptive encoding is additionally associated with higher-level functions such as action recognition and therefore provides new, experimentally testable hypotheses of how proprioception aids in adaptive motor control.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>Swiss National Science Foundation</institution></institution-wrap></funding-source><award-id>310030_201057</award-id><principal-award-recipient><name><surname>Mathis</surname><given-names>Mackenzie W</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Swiss National Science Foundation</institution></institution-wrap></funding-source><award-id>310030_212516</award-id><principal-award-recipient><name><surname>Mathis</surname><given-names>Alexander</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009835</institution-id><institution>Rowland Institute at Harvard</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Sandbrink</surname><given-names>Kai J</given-names></name><name><surname>Mathis</surname><given-names>Mackenzie W</given-names></name><name><surname>Mathis</surname><given-names>Alexander</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf2"><p>Mackenzie W Mathis, Reviewing editor, <italic>eLife</italic>.</p></fn><fn fn-type="conflict" id="conf1"><p>The other authors declare that no competing interests exist.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>The computational dataset and code to create it is available at https://github.com/amathislab/DeepDraw</p></sec><supplementary-material><ext-link xlink:href="elife-81499-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>