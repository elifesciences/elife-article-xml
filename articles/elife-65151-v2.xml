<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">65151</article-id><article-id pub-id-type="doi">10.7554/eLife.65151</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Microbiology and Infectious Disease</subject></subj-group></article-categories><title-group><article-title>Misic, a general deep learning-based method for the high-throughput cell segmentation of complex bacterial communities</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-218173"><name><surname>Panigrahi</surname><given-names>Swapnesh</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-218204"><name><surname>Murat</surname><given-names>Dorothée</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5809-9267</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-218205"><name><surname>Le Gall</surname><given-names>Antoine</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-218206"><name><surname>Martineau</surname><given-names>Eugénie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-218214"><name><surname>Goldlust</surname><given-names>Kelly</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-218215"><name><surname>Fiche</surname><given-names>Jean-Bernard</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-218217"><name><surname>Rombouts</surname><given-names>Sara</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-218218"><name><surname>Nöllmann</surname><given-names>Marcelo</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-22606"><name><surname>Espinosa</surname><given-names>Leon</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1923-2069</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-5082"><name><surname>Mignot</surname><given-names>Tâm</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4338-9063</contrib-id><email>tmignot@imm.cnrs.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf3"/></contrib><aff id="aff1"><label>1</label><institution>CNRS-Aix-Marseille University, Laboratoire de Chimie Bactérienne, Institut de Microbiologie de la Méditerranée and Turing Center for Living Systems</institution><addr-line><named-content content-type="city">Marseille</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Centre de Biochimie Structurale, CNRS UMR 5048, INSERM U1054, Université de Montpellie</institution><addr-line><named-content content-type="city">Marseille</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Xiao</surname><given-names>Jie</given-names></name><role>Reviewing Editor</role><aff><institution>Johns Hopkins University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Storz</surname><given-names>Gisela</given-names></name><role>Senior Editor</role><aff><institution>National Institute of Child Health and Human Development</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>09</day><month>09</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e65151</elocation-id><history><date date-type="received" iso-8601-date="2020-11-24"><day>24</day><month>11</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-09-07"><day>07</day><month>09</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-10-07"><day>07</day><month>10</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.10.07.328666"/></event></pub-history><permissions><copyright-statement>© 2021, Panigrahi et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Panigrahi et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-65151-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-65151-figures-v2.pdf"/><abstract><p>Studies of bacterial communities, biofilms and microbiomes, are multiplying due to their impact on health and ecology. Live imaging of microbial communities requires new tools for the robust identification of bacterial cells in dense and often inter-species populations, sometimes over very large scales. Here, we developed MiSiC, a general deep-learning-based 2D segmentation method that automatically segments single bacteria in complex images of interacting bacterial communities with very little parameter adjustment, independent of the microscopy settings and imaging modality. Using a bacterial predator-prey interaction model, we demonstrate that MiSiC enables the analysis of interspecies interactions, resolving processes at subcellular scales and discriminating between species in millimeter size datasets. The simple implementation of MiSiC and the relatively low need in computing power make its use broadly accessible to fields interested in bacterial interactions and cell biology.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>Deep learning</kwd><kwd>image analysis</kwd><kwd>microscopy</kwd><kwd>myxococcus xanthus</kwd><kwd>biofilms</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>B. subtilis</italic></kwd><kwd><italic>E. coli</italic></kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>ERC advanced grant</institution></institution-wrap></funding-source><award-id>JAWS 885145</award-id><principal-award-recipient><name><surname>Mignot</surname><given-names>Tâm</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>AMIDEX</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Martineau</surname><given-names>Eugénie</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>ANR</institution></institution-wrap></funding-source><award-id>IBM (ANR-14-CE09-0025-01)</award-id><principal-award-recipient><name><surname>Nöllmann</surname><given-names>Marcelo</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>ANR</institution></institution-wrap></funding-source><award-id>HiResBacs (ANR-15-CE11-0023)</award-id><principal-award-recipient><name><surname>Nöllmann</surname><given-names>Marcelo</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>CNRS 80-prime</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Panigrahi</surname><given-names>Swapnesh</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A broadly applicable deep-learning based method that recognizes rod-shaped bacteria of virtually any species in complex bacterial communities.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Bacterial biofilms and microbiomes are now under intense study due to their importance in health and environmental issues. Within these spatially structured communities, analysis of cell-cell interactions requires powerful descriptive tools to link molecular mechanisms in single cells to cellular processes at community scales. Microscopy-based imaging methods combining multiple imaging modalities (e.g. bright-field, phase-contrast microscopy, fluorescence microscopy) directly record morphological, spatio-temporal, and intracellular molecular data in a single experiment. However, extraction of quantitative high-resolution information at high-throughput requires accurate computational tools to detect bacterial cells and correctly assign analyzed properties to these cells. While this task might seem trivial to the naked eye, it is a significant computational challenge to detect bacterial cells in a 2D image with high accuracy in dense microcolonies where the cells are in tight contact and under various imaging modalities.</p><p>Semantic segmentation of an image assigns pixels to the object that it belongs to, for example bacterial cells or background (<xref ref-type="bibr" rid="bib8">Jeckel and Drescher, 2021</xref>). Traditionally in an image, pixel intensities that exceed a given threshold are assigned to detected objects while pixels with intensities lower than the threshold are assigned to background, producing so-called segmented masks. Detecting bacterial cells among the objects can be obtained in a number of ways using morphometric procedures. This is a fast moving field and an extensive list of available methods is described by <xref ref-type="bibr" rid="bib8">Jeckel and Drescher, 2021</xref>. In 2D, broadly used example methods such as MicrobeJ (<xref ref-type="bibr" rid="bib3">Ducret et al., 2016</xref>) and Oufti (<xref ref-type="bibr" rid="bib13">Paintdakhi et al., 2016</xref>) use characteristic morphometric parameters (length, area, circularity, feature detection (ie septa) etc...) to filter non-cell objects from the segmented image and fit the remaining objects to embedded cell models, allowing cell pole detection, septa detection, protein localization etc… While these methods are highly performant to study isolated bacterial cells, they are ill-suited to perform segmentation of dense bacterial communities, mostly because adjacent cells are not easily resolved by intensity-thresholding when bacteria are in tight contact due to lower contrast at the interior of the colony (the so-called shade-off artifact). At best, when performed with Oufti, segmentation of single bacteria within micro-colonies requires extensive manual-tuning of multiple parameters limiting its robustness for high-throughput automatic data extraction (<xref ref-type="bibr" rid="bib13">Paintdakhi et al., 2016</xref>; <xref ref-type="bibr" rid="bib19">Stylianidou et al., 2016</xref>).</p><p>Machine-learning-based techniques are powerful alternatives to overcome the above limitations of traditional segmentation approaches. For example, one of them, Supersegger, combines intensity-based thresholding with supervised cell boundary recognition on phase contrast images, successfully resolving individuals cells at low contrast at the colony interior (<xref ref-type="bibr" rid="bib19">Stylianidou et al., 2016</xref>). This method is, however, limited to phase contrast images and requires a number of filter applications (ie thresholding, contrast filter and watershed) to appropriately segment these images. Such tuning which may need to be adjusted for each field of view (in addition to image intensity normalization) renders Supersegger difficult to use for the segmentation of large colonies of various bacterial species captured under various imaging modalities. Deep-learning algorithms called Convolutional Neural-Networks (CNNs) have recently shown great promise for image classification and in particular semantic segmentation with reasonable computational power (<xref ref-type="bibr" rid="bib22">Van Valen et al., 2016</xref>). Van Valen and collaborators (<xref ref-type="bibr" rid="bib22">Van Valen et al., 2016</xref>) provided a general proof of concept that CNNs (DeepCell) could be used to segment both eukaryotic and bacterial cells in dense contexts with limited training datasets. However, while the study provides important tips toward the successful training of a CNN for a specialized cell segmentation task, it does not provide a trained CNN for the general segmentation of dense bacterial communities. Nevertheless, the approach provided promising perspectives to segment <italic>E. coli</italic> microcolonies on agar and confirming this, a CNN-based tool (DeLTA, <xref ref-type="bibr" rid="bib10">Lugagne et al., 2020</xref>) was recently developed to detect and track <italic>E. coli</italic> cells immobilized in microfluidic devices (the so-called mother machine, <xref ref-type="bibr" rid="bib10">Lugagne et al., 2020</xref>). Inspired by these methods, we decided to develop MiSiC (<italic>Mi</italic>crobial <italic>S</italic>egmentation <italic>i</italic>n dense <italic>C</italic>olonies), a general CNN-based tool to segment bacteria in single or multispecies 2D bacterial communities at very high throughput. MiSiC is based on U-net, a CNN encoder-decoder architecture that has previously been applied for detection and counting of eukaryotic cells (<xref ref-type="bibr" rid="bib5">Falk et al., 2019</xref>), that relies on shape rather than intensity information and thus performs semantic segmentation of microbial colonies under any microscope modality. Thus, contrarily to most other softwares, MiSiC is insensitive to specific imaging conditions which often require tailored training data sets. Operating MiSiC requires minimal parameter tuning and can be run with standard computational power, in a Napari Graphic User Interface (GUI, a complete user handbook for installation and use is provided) under Python (<ext-link ext-link-type="uri" xlink:href="https://napari.org/">https://napari.org/</ext-link>). Both semantic segmentation and instance segmentation (in which each cell is defined as a distinct object [<xref ref-type="bibr" rid="bib8">Jeckel and Drescher, 2021</xref>]) masks can thus be easily obtained with minimal computational expertise, making MiSiC broadly applicable to the field of bacterial cell biology.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The MiSiC workflow</title><p>We sought to develop a prediction workflow that converts an input image taken under phase contrast, fluorescence, or bright field into a binary mask for cell bodies. However, when microscopy is performed under different modalities, pixel intensity variations between imaging conditions make it difficult to perform semantic segmentation with a single procedure. Thus, to minimize the impact of image intensity fluctuations that inevitably arise from varying imaging sources, the input images were transformed into intermediate image representations obtained from the shape and curvature (the Hessian or second-order differentiation) of the imaged objects. This strategy is possible because in rod-shaped bacteria, the characteristic dome-shaped curvature of the poles is remarkably conserved across division cycles (<xref ref-type="bibr" rid="bib2">Campos et al., 2014</xref>). The curvature changes in the intensity field of an image are thus represented in a so-called Shape Index map (SI) derived from the eigenvalues of the Hessian of the image (<xref ref-type="bibr" rid="bib9">Koenderink and van Doorn, 1992</xref>) (see Materials and methods section). Therefore, all microscopy images can be transformed into SI images with pixel intensity values varying as a function of object curvature and ranging from –1 to +1, a –1 value representing a negative dome-shape and +1 representing a positive dome-shape (<xref ref-type="bibr" rid="bib9">Koenderink and van Doorn, 1992</xref>, <xref ref-type="fig" rid="fig1">Figure 1A</xref>). SI images of bacterial cells acquired under various experimental conditions were used to train a U-Net.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>MiSiC: A U-netbased bacteria segmentation tool.</title><p>(<bold>a</bold>) Examples of Shape index maps (SI) calculated from Phase Contrast, Bright Field and Fluorescence images of the same field of <italic>Myxococcus xanthus</italic> cells. (<bold>b</bold>) A set of annotated bright-field images of <italic>Escherichia coli and Myxococcus xanthus</italic> along with synthetic labeled data with additive Gaussian noise was used to generate a training dataset of input images, X, consisting of Shape Index Map of intensity images (at three scales) and segmented images, Y, consisting of contours (<bold>Y1</bold>) and cell body (<bold>Y2</bold>). A CNN with U-net architecture was trained to segment the Shape Index Maps into cell body and contour of bacterial cells. Prediction using MiSiC requires that the mean width of the bacteria in the input image is close to 10 pixels, which is easily obtained by rescaling the input image based on the average width of the bacteria under consideration. Gaussian noise may be added to the input image to reduce false positives (Materials and methods).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Background noise can lead to spurious cell detection by MiSiC.</title><p>SI images retain the shape/curvature information of the intensities in a raw image through eigenvalues of the hessian of the image and an arctan function, creating the smooth areas corresponding to cell bodies and propagating noisy regions where there is no shape information. Thus, MiSiC segments the cells by discriminating between ‘smooth’ and ‘rough’ regions. In effect, when adjusting the size parameter, scaling smooths out the image noise, leading to background regions that have a smoother SI than in the raw image. Some of these areas could be falsely detected as bacterial cells. This effect is shown here: When an image with uniform and random intensity values is segmented with MiSiC with increasing smoothening (here using a gaussian blur filter), spurious cell detection becomes apparent. In addition, since the SI keeps the shape information and not the intensity values, background objects that are of relatively low contrast (i.e. dead cells or debris) may be detected as cells. All these artifacts can be mitigated by adding synthetic noise to the scaled images.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig1-figsupp1-v2.tif"/></fig></fig-group><p>U-net type architectures allow fast learning from a relatively small body of labeled data because the embedded skip-connections allow the convolutional kernels between both encoder and decoder ends to be shared (<xref ref-type="bibr" rid="bib5">Falk et al., 2019</xref>). Nevertheless, the labeled data must be representative of the broadly varying experimental conditions to produce reliable outputs: in our case, different bacterial species recorded under varying imaging modalities. A schematic of the training strategy is shown in <xref ref-type="fig" rid="fig1">Figure 1</xref> and detailed in the Materials and methods section. Specifically, the U-Net was trained to segment cells by learning shapes of individual bacteria and patterns emerging from the tight contact between cells. Accordingly, we curated a hand-segmented dataset of 350 bright-field images (n = 34807 cells) of two rod-shaped bacterial species, <italic>Escherichia coli</italic> and <italic>Myxococcus xanthus</italic>. This annotated data was however insufficient for the robust segmentation of bacterial cells, thus it was further enriched with synthetic representations of rod-shaped bacteria of varying length but fixed 10 pixels width corresponding to ≈ 0.6 µm. Overall, the ground truth data used for training had two classes: one corresponding to bacteria cell bodies and the other corresponding to the contour of the detected cell (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). This makes post-processing possible when there is not enough edge information for the proper separation of tightly connected bacterial cells, using algorithms like watershed, conditional random fields, or snake segmentation (<xref ref-type="bibr" rid="bib24">Yang and Cao, 2013</xref>, see below).</p><p>Prior to segmentation, two parameters must be adjusted to generate a SI image from an input image. Because the width of bacterial cells was set to 10 pixels in the training data set, the input image must be scaled similarly so that the width of bacterial cells is also contained in 10 pixels. However, this scaling often smoothens the original image, which in turns smoothens the corresponding SI Image (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). This is potentially problematic because the U-Net distinguishes smooth curvatures with well-defined boundaries and noise reduction can lead to increased false positive segmentation in the scaled images. Such false positive detection is more frequent in images where the number of bacteria is sparse. This problem can be solved by adding synthetic noise to the scaled images. In total, the MiSiC workflow takes raw input images of any imaging modality, scales them and adds noise to generate SI that are then segmented with the above described U-Net (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). For the users, scaling and potential addition of noise can be easily adjusted in the Napari GUI, which is explained in detail in a dedicated handbook.</p></sec><sec id="s2-2"><title>MiSiC can segment bacteria under varying microscope modalities</title><p>We first tested whether MiSiC can efficiently segment images of bacteria of distinct shapes (<italic>E. coli,</italic> smaller and thicker cells and <italic>M. xanthus</italic>, longer and thinner cells) in dense colonies, captured by phase contrast, fluorescence or brightfield. To quantify the accuracy of segmentation and compare the relative performance of MiSiC for each modality, we compared the obtained MiSiC masks with hand-annotated masks (considered ground truth masks) of the same images and measured the Jaccard index (JI) as a function of the Intersection-over-Union (IoU) threshold for each modality (see Materials and methods, <xref ref-type="fig" rid="fig2">Figure 2a and b</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> a,b). In all cases, high JI values ( ≥ 0.8) were observed for IoU thresholds 0–0.6, indicating that MiSiC can robustly segment all modalities. In fact, MiSiC performance was comparable to the observer’s eye for each modality (or even slightly better) because similar JI scores were obtained when the same ground-truth data (generated by the same observer consistently throughout the study) was compared to data annotated by another independent observer (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c</xref>). As would be expected, the quality of the segmentation was nevertheless variable (albeit slightly) as a function of the imaging modality, the best results being obtained for fluorescence (if the fluorescence is homogenous between cells as seen in <italic>E. coli</italic>, less so for <italic>Myxococcus</italic> cells where the fluorescence levels were more variable), followed by phase contrast and bright field.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>MiSiC predictions under various imaging modalities.</title><p>(<bold>a</bold>) MiSiC masks and corresponding annotated masks of fluorescence, phase contrast and bright field images of a dense <italic>E. coli</italic> microcolony. (<bold>b</bold>) Jaccard index as a function of IoU threshold for each modality determined by comparing the MiSiC masks to the ground truth (see Materials and methods). The obtained Jaccard score curves are the average of analyses conducted over three biological replicates and n = 763, 811, 799 total cells for Fluorescence, Phase Contrast and Bright Field, respectively (bands are the maximum range, the solid line is the median). The fluorescence images were pre-processed using a Gaussian of Laplacian filter to improve MiSiC prediction (describe in Materials and methods).</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title><italic>E. coli</italic> IoU over threshold -Brightfield.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><label>Figure 2—source data 2.</label><caption><title><italic>E. coli</italic> IoU over threshold -Fluorescence.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-data2-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2sdata3"><label>Figure 2—source data 3.</label><caption><title><italic>E. coli</italic> IoU over threshold – Phase contrast.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-data3-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>MiSiC predictions under various imaging modalities.</title><p>(<bold>a</bold>) MiSiC masks and corresponding annotated masks of fluorescence, phase contrast and bright-field images of a dense <italic>M. xanthus</italic> microcolony. (<bold>b</bold>) Jaccard index as a function of IoU threshold for each modality determined by comparing the MiSiC masks to the ground truth (see Materials and methods). The obtained curves are the average of analyses conducted over three biological replicates and n = 193,206,211 total cells for Fluorescence, Phase Contrast, and Bright Field, respectively. The fluorescence (bands are the maximum range, the solid line is the median) images were pre-processed using a Gaussian of Laplacian filter to improve MiSiC prediction (see Materials and methods). (<bold>c</bold>) A human observer is slightly less performant than MiSiC. The same ground truth as used in <xref ref-type="fig" rid="fig2">Figure 2</xref> (dashed lines) was compared to an independent observer’s annotation (solid lines) and Jaccard score curves were constructed as shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. BF: Bright Field, PC: Phase Contrast, Fluo: Fluorescence.</p><p><supplementary-material id="fig2s1sdata1"><label>Figure 2—figure supplement 1—source data 1.</label><caption><title><italic>Myxococcus</italic> IoU over threshold -Brightfield for panel b.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata2"><label>Figure 2—figure supplement 1—source data 2.</label><caption><title><italic>Myxococcus</italic> IoU over threshold -Phase Contrast for panel b.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data2-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata3"><label>Figure 2—figure supplement 1—source data 3.</label><caption><title><italic>Myxococcus</italic> IoU over threshold-Fluorescence for panel b.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data3-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata4"><label>Figure 2—figure supplement 1—source data 4.</label><caption><title>Threshold for panel 1 c.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data4-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata5"><label>Figure 2—figure supplement 1—source data 5.</label><caption><title>Ground truth IoU over threshold-Brightfield for panel c.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data5-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata6"><label>Figure 2—figure supplement 1—source data 6.</label><caption><title>Ground truth IoU over threshold-Phase contrast for panel c.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data6-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata7"><label>Figure 2—figure supplement 1—source data 7.</label><caption><title>Ground truth IoU over threshold-Fluorescence for panel c.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data7-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata8"><label>Figure 2—figure supplement 1—source data 8.</label><caption><title>Observer IoU over threshold-Brightfield for panel c.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data8-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata9"><label>Figure 2—figure supplement 1—source data 9.</label><caption><title>Observer IoU over threshold-Phase contrast for panel c.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data9-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2s1sdata10"><label>Figure 2—figure supplement 1—source data 10.</label><caption><title>Observer IoU over threshold-Fluorescence for panel c.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig2-figsupp1-data10-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig2-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-3"><title>MiSiC can segment colonies of various species and is tolerant to shape deviations</title><p>We next tested if MiSiC can segment bacterial species other than those that it was trained on (<italic>E. coli</italic> and <italic>M. xanthus</italic>), other rod shapes (<italic>Pseudomonas aeruginosa</italic>), curved shapes (<italic>Caulobacter crescentus</italic>) and filamentous shapes (<italic>Bacillus subtilis</italic>) (<xref ref-type="fig" rid="fig3">Figure 3a and b</xref>). For each analysis, we derived JI scores based on the comparison between MiSiC masks and hand-annotated data as described above. MiSiC predicted accurate masks for each bacterial species with JI scores ≥ 0.8 up to 0.5 IoU thresholds for all cases. Nevertheless, and as expected the segmentation accuracy was lower for curved bacteria than rod shaped bacteria (compare <italic>P. aeruginosa</italic> and <italic>C. crescentus</italic>). For filamentous bacteria, the filaments were remarkably well resolved but that was not always the case for cell separations (septa) within the filaments, likely because of insufficient edge information at cell septa in the raw image. Note that this problem may be resolved by post-processing, for example by applying a watershed algorithm to the MiSiC mask (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), which effectively resolves additional undetected septa. Although MiSiC can thus detect a number of bacterial species, a current limitation lies in its ability to segment round or oval cells. In fact, such shapes were initially omitted from the original training dataset to omit the spurious detection of round non-cell objects that are frequently observed in background images.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>MiSiC predictions in various bacterial species and shapes.</title><p>(<bold>a</bold>) MiSiC masks and corresponding annotated masks of phase contrast images of another <italic>Pseudomonas aeruginosa</italic> (rod-shape), <italic>Caulobacter crescentus</italic> (crescent shape) and <italic>Bacillus subtilis</italic> (filamentous shape). (<bold>b</bold>) Jaccard index as a function of IoU threshold for each species determined by comparing the MiSiC masks to the ground truth (see Materials and methods). The obtained Jaccard score curves are the average of analyses conducted over three biological replicates and n = 1149,101, 216 total cells for <italic>P. aeruginosa</italic>, <italic>B. subtilis</italic> and <italic>C. crescentus</italic>, respectively (bands are the maximum range, solid line the median). Note that the <italic>B. subtilis</italic> filaments are well predicted but edge information is missing for optimal detection of the cell separations.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>IoU over threshold -<italic>Bacillus subtilis</italic>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig3-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><label>Figure 3—source data 2.</label><caption><title>IoU over threshold -<italic>Caulobacter crescentus</italic>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig3-data2-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig3sdata3"><label>Figure 3—source data 3.</label><caption><title>IoU over threshold – <italic>Pseudomonas aeruginosa</italic>.</title><p>Thresholds are the same in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig3-data3-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Refining cell separations with watershed.</title><p>Watershed methods may be used to obtain a more accurate segmentation of septate filaments such as <italic>Bacillus subtilis</italic>. In this example, applying this method to the MiSiC mask effectively resolves cell boundaries that are not captured in the prediction but are visible by eye (arrows).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig3-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-4"><title>MiSiC as a tool to study dynamic bacterial communities</title><p>Encouraged by these results, we tested whether MiSiC could be further used to study bacterial multicellular organization and inter-species interactions accurately at very large scales. As a model system we used <italic>Myxococcus xanthus,</italic> a delta proteobacterium living in soil, that predates collectively in a process whereby thousands of cells move together to invade and kill prey colonies (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="bibr" rid="bib14">Pérez et al., 2016</xref>). In the laboratory, spotting a <italic>Myxococcus</italic> colony next to a prey colony (here <italic>E. coli</italic>) results in invasion and complete digestion of prey cells in 48 H (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). To capture predator-prey interactions at single cell resolution, we set up a predation assay where <italic>Myxococcus</italic> and <italic>E. coli</italic> interact on a 1 cm<sup>2</sup> agar surface directly on a microscope slide (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>). Under these conditions, the entire invasion process occurs over a single prey cell layer allowing identification of single predator and prey cells at any given stage. This area is nevertheless quite large, and to record it with cell-level resolution, we implemented a multi-modal imaging technique termed ’Bacto-Hubble’ (in reference to the Hubble telescope and its use for the reconstruction of large scale images of the galaxies) that scans the entire bacterial community with a 100 X microscope objective and reconstructs a single image by near neighbor end-joining of multiple tiles of 80 nm/pixel resolution images (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b</xref>). Application of this method requires addressing practical considerations that are detailed in the methods section. Bacto-Hubble images (phase contrast and multi-channel fluorescence) thus capture cellular processes in a native community environment. We next tested whether MiSiC addresses the computational challenges posed by the analysis of such complex (dense population and mixed species) and large size data sets.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>MiSiC can be applied to the study of cellular processes at the mesoscale.</title><p>(<bold>a</bold>) The <italic>Myxococcus xanthus</italic> predation cycle. <italic>Myxococcus</italic> cells use motility (yellow colony) to form so-called rippling waves to invade and consume prey colonies (gray). When encountering starvation (outside the prey) or after the prey is consumed, the Myxcococcus cells form aggregate that matures into fruiting bodies (black dots) where the cells differentiate into spores. These spores remain dormant until another prey is encountered which provokes the cycle to resume (see <xref ref-type="bibr" rid="bib14">Pérez et al., 2016</xref> for details about the cycle).(<bold>b</bold>) The <italic>Myxococcus xanthus</italic> cycle can be observed directly on a Petri dish. Shown are 24 H and 48 H time points. At 48 H, spore-filled fruiting bodies are observed forming in the nutrient depleted area but not in the former prey area where the <italic>Myxococcus</italic> cells are actively growing. This stage corresponds to the rippling stage shown in (<bold>a</bold>). Scale bar = 0.5 mm. (<bold>c–e</bold>) MiSiC can segment dense bacterial swarms.(c) An <italic>M. xanthus</italic> swarm expressing SgmX-GFP, observed at colony edges and captured under phase contrast, fluorescence and corresponding magnified images.(<bold>d</bold>) MiSiC prediction mask obtained on the phase contrast image shown in b (<bold>e</bold>) Demograph representation of the segmented cells in the MiSiC mask (<bold>d</bold>) and corresponding localization of the SgmX-GFP fluorescent clusters. The horizontal axis represents the number of cells ordered by cell length. The vertical axis represents cell coordinates in µm and aligned such that polar fluorescence clusters have positive values (with respect to the position of the cell middle set to 0). The color of the clusters reflects the number of cells for each given cell length (bins = 0.05 µm, maximum = 20 cells for [3.9–3.95] µm). n = 1672 detected cells after filtering the MiSiC mask. (<bold>f–j</bold>) Mapping of <italic>M. xanthus</italic> cell division in the <italic>M. xanthus-E. coli</italic> community. (<bold>f–g</bold>) Bacto-Hubble image of a predatory field containing FtsZ-NG labeled <italic>Myxococcus xanthus</italic> cells and unlabeled <italic>Escherichia coli</italic> prey cells. The composite image results from the assembly of 15 × 15 Tile images. The dotted circle marks the limits of the original prey colony. The white line (mean profile) indicates the axis used for the analysis shown in (<bold>i</bold>). (<bold>f</bold>), a single image tile showing a representative density of fluorescent cells. (<bold>h</bold>) Detection of dividing cells. FtsZ-NG fluorescent clusters are detected at midcell. The FtsZ clusters can be detected as fluorescence intensity maxima. Shown is a projection of the position of fluorescence intensity on a mean cell contour for a subset of n = 3490 cells (representing 14 % of the total detected cells with a cluster), revealing that as expected, the clusters form at mid-cell. The blue square marks the cell shown as an example in (<bold>h</bold>). (<bold>i</bold>) Counting dividing cells. The example shows segmentation of the field shown in (<bold>h</bold>). The position of Z-ring foci detected as fluorescent maxima was linked to all fluorescent cells segmented in the MiSiC mask. (<bold>j</bold>) <italic>Myxococcus</italic> cells divide in the prey colony. The spatial density of dividing cells, the total fluorescent cells (Materials and methods) and the proportion of dividing cells (density of dividing cells/density of total cells, Materials and methods) were determined all across the prey area shown in (<bold>e</bold>) (dotted circle). The mean ratio and standard deviation are plotted along a spatial axis (distance along profile) corresponding to areas outside and inside (dotted rectangle) of the prey area (mean profile, white segment in (<bold>e</bold>)).</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Fluorescence maxima – <xref ref-type="fig" rid="fig4">Figure 4e</xref>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig4-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig4sdata2"><label>Figure 4—source data 2.</label><caption><title>Cell length – <xref ref-type="fig" rid="fig4">Figure 4e</xref>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig4-data2-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig4sdata3"><label>Figure 4—source data 3.</label><caption><title>Z-ring positioning for <xref ref-type="fig" rid="fig4">Figure 4h</xref>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig4-data3-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Bacto-Hubble captures millimeter size images of bacterial communities which can be segmented with MiSiC.</title><p>(<bold>a</bold>) Bacto-hubble microscope set-up. The inverted microscope and the sample holder have been optimized to increase the speed of tile acquisition and the stability of focus. The key point is to replace as many moving parts as possible, such as shutters, and replace them with diode sources. The agar pad is blocked by a flat coverslip that, combined with the continuous focus control (in our case a Nikon PFS system), makes it possible to maintain the focus over millimeter and up to centimeter distances. The motorized stage is equipped with optical encoders, allowing precise x, y movements across the specimen. (<bold>b</bold>) Bacto-Hubble image of an entire predator-prey colony. The area shows an <italic>M. xanthus</italic> community 96 hours after it started invading an <italic>E. coli</italic> prey colony. At this stage, the prey has been entirely consumed. Following growth and starvation, <italic>M. xanthus</italic> cells aggregate (phase-bright dots in the image, top panels) and form fruiting bodies. The entire image corresponds to the assembly of 40 × 40 tiles for a total surface of 9 mm<sup>2</sup>. Top right panel is a close up of the region framed in light blue in the top left panel. Bottom left panel is a close up of the region framed in yellow in the top right panel. Bottom right panel is a close up of the region framed in red in the bottom left panel showing individual <italic>M. xanthus</italic> cells. (<bold>c–d</bold>) Robustness of MiSiC to noise and comparison with SuperSegger. (<bold>d</bold>) Resulting images with added noise and corresponding segmentation with MiSiC and SuperSegger for comparison. An <italic>E. coli</italic> dataset was processed with SuperSegger and MiSiC in the presence of increasing amounts of Gaussian noise added to the images while keeping segmentation parameters constant (Materials and methods). (<bold>e</bold>) Relative performance of SuperSegger and MiSiC to increasing noise. For each amount of noise, the complete datasets (141 images) were processed and the Dice index (Materials and method) was calculated with respect to the segmentation results (ie panel D). Each dot on the lines represents the mean Dice value while the shaded error bars represent its standard deviation across the dataset. Note that while Superseger and MiSiC perform equally well at low noise on this data set (a Supersegger optimized dataset, Materials and methods), MiSiC remains robust in the presence of noise, showing that it is especially adequate for the segmentation of multi-tile images here noise varies significantly between tiles.</p><p><supplementary-material id="fig4s1sdata1"><label>Figure 4—figure supplement 1—source data 1.</label><caption><title>DICE index as a function of noise for panel d.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-65151-fig4-figsupp1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig4-figsupp1-v2.tif"/></fig></fig-group><p>First, we tested the capacity of MiSiC to segment closely-packed swarms of <italic>Myxococcus xanthus</italic> cells captured in a single image tile. To test the fidelity of segmentations in these conditions, we imaged a swarm composed of cells expressing SgmX-sfGFP, a motility protein that localizes to the cell pole (<xref ref-type="bibr" rid="bib12">Mercier et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Potapova et al., 2020</xref>) in both fluorescence and phase contrast modalities (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). Phase contrast images were used to obtain a MiSiC segmentation mask (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Subsequently, the mask was processed under MicrobeJ (<xref ref-type="bibr" rid="bib3">Ducret et al., 2016</xref>) to remove objects that do not correspond to cells (Materials and methods, less than 1.4%, n = 1695) and calculate the localization pattern of SgmX-GFP foci with respect to the long axis of each segmented cell (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). As expected, SgmX-GFP loci localized to a cell pole, consistent with most <italic>Myxococcus</italic> cells in swarms being properly segmented by MiSiC.</p><p>Second, to show that MiSiC can be used to quantitatively study cellular processes in entire Bacto-Hubble images, we mapped a <italic>Myxococcus</italic> cellular process directly during prey invasion. Cell division is expected to occur mostly in prey-areas in absence of any other source of nutrients. Like all rod-shaped bacteria, dividing <italic>Myxococcus</italic> cells assemble a polymeric FtsZ bacterial tubulin ring to initiate cell division (<xref ref-type="bibr" rid="bib17">Schumacher et al., 2017</xref>). When it is fused to fluorescent proteins, the FtsZ ring is observed as a dot at mid-cell (<xref ref-type="bibr" rid="bib21">Treuner-Lange et al., 2013</xref>), which can be used as a proxy to determine which cells enter division. Thus, we first engineered <italic>M. xanthus</italic> cells expressing FtsZ fused to Neon-Green (NG, Materials and methods) and mixed <italic>Myxococcu</italic>s FtsZ-NG+ (5%) with non-labeled cells (95%) in the presence of an <italic>Escherichia coli</italic> prey cell colony. A fluorescence Bacto-Hubble image spanning ~5 mm<sup>2</sup> (representing 225 tiles of 500 × 500 pixels images) of the community during the invasion phase (<xref ref-type="fig" rid="fig4">Figure 4f</xref>) was then captured and segmented tile-by-tile using MiSiC (<xref ref-type="fig" rid="fig4">Figure 4f–g</xref>). Due to the fact that MiSiC uses SI, it is remarkably insensitive to noise and intensity variations between images (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c,d</xref>) and thus it easily allows segmentation of multi-tile images where signal intensity variations between tiles is to a large extent unavoidable. Cells with mid-cell FtsZ-NG fluorescence clusters were clearly observed suggesting that cell division is ongoing (<xref ref-type="fig" rid="fig4">Figure 4h</xref>). Dividing cells were therefore counted across the entire image (<xref ref-type="fig" rid="fig4">Figure 4i</xref>, Materials and methods) to determine where they localize spatially within the community. <xref ref-type="fig" rid="fig4">Figure 4j</xref>, shows that cell division is markedly increased in the prey area, demonstrating directly that <italic>Myxococcus</italic> grows during prey invasion. Thus, MiSiC is appropriate for the automated detection of cellular processes (detected at subcellular resolution) at community scales.</p><p>Third, we explored how MiSiC could be further adapted to segment and classify multiple bacterial species intermingling and interacting in space; here <italic>Myxococcus</italic> cell groups invading the tightly-knitted <italic>E. coli</italic> prey colony. To segment each bacterial species directly from unlabeled phase contrast-images, new training datasets were produced and used to retrain the U-NET. These labeled datasets were obtained by imaging GFP-labeled <italic>Myxococcus</italic> and mCherry-labeled <italic>E. coli</italic> (see Materials and methods). Images were captured for each channel (GFP, mCherry) and segmented separately with MiSiC to obtain masks for each species (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). These masks were used to retrain the U-NET, the predictive value of which was tested by deriving classification masks directly from a phase-contrast image of a mixed <italic>Myxococcus</italic> (GFP) - <italic>E. coli</italic> (mCherry) population (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Comparison of the MiSiC classification to hand annotated GFP (<italic>Myxococcus</italic>) and mCherry (<italic>E. coli</italic>) images over selected fields where each species interact (n = 4, ie <xref ref-type="fig" rid="fig5">Figure 5b</xref>) respectively yielded JI scores of 0.95 ± 0.036 (n = 200 cells) and 0.89 ± 0.047 (n = 545 cells), suggesting that the classification is highly accurate despite the tight interactions between <italic>Myxococcus</italic> and <italic>E. coli</italic> cells. To further show that species classification is reliable in a large dataset, we next classified <italic>Myxococcus</italic> from <italic>E. coli</italic> cells directly in a phase contrast Bacto-Hubble image (840 tiles, 2.1.10<sup>9</sup> pixels). We could thus discriminate cells belonging to each species in the predation area (<xref ref-type="fig" rid="fig5">Figure 5c</xref>) for a total detection of ~402,000 <italic>Myxococcus</italic> and ~630,000 <italic>E</italic>. <italic>coli</italic> cells in the entire image. Given the large size of the dataset, it would be impossible to test the accuracy of the classification procedure exhaustively by comparing it to the ground truth, instead, we tested whether the distribution of shape descriptors, such as the extent (E = area/bounding box area), solidity (S = area/convex area) and minor axis length, matched the distribution of these descriptors obtained from images of each single bacterial species (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). The observed distributions were indeed consistent with an efficient separation of species in the mixed community, suggesting that the classification is also robust in large images. Inevitably, infrequent ambiguous classifications arise in the areas where the cells interact tightly due to low contrast in these areas. These instances generally appear as bi-color objects because the prediction is not homogeneous inside such objects. Given that <italic>Myxococcus</italic> cells and <italic>E. coli</italic> cells have clear morphometric differences, these uncertain cells can be easily eliminated by filtering with discriminating parameters (i.e. each of them or combined, <xref ref-type="fig" rid="fig5">Figure 5d</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Semantic segmentation of <italic>M</italic>. <italic>xanthus</italic> and <italic>E. coli</italic> from single phase contrast images.</title><p>(<bold>a</bold>) Semantic classification network. A U-Net was trained to discriminate <italic>M. xanthus</italic> cells from <italic>E. coli</italic> cells. The training dataset consisted of GFP<sup>+</sup> <italic>M. xanthus</italic> cells mixed with <italic>mCherry</italic><sup>+</sup> <italic>E. coli</italic> cells, which were imaged in distinct fluorescent channels (GFP and mCherry) and segmented using MiSiC to produce ground truth data for each species. The network uses unlabeled phase contrast images as input (<bold>X</bold>) and produces one output for each labeled species (Y, Mx or Ec). (<bold>b</bold>) Semantic classification of intermixed <italic>Myxococcus</italic> and <italic>E. coli</italic> cells. Shown is a mixed population of GFP<sup>+</sup> Myxococcus and mCherry<sup>+</sup> <italic>E. coli</italic> cells. The classification (Myxococcus, Mx) and <italic>E. coli</italic> (Ec) were obtained directly from the phase contrast image. Corresponding fluorescence images of GFP<sup>+</sup> and mCherry<sup>+</sup> are shown for comparison and were used to estimate the accuracy of the classification. (<bold>c–d</bold>) Direct semantic classification of <italic>M. xanthus</italic> interacting with <italic>E. coli</italic> in a Bacto-Hubble image. (<bold>c</bold>) Bacto-Hubble image of <italic>M. xanthus</italic> cells invading an <italic>E. coli</italic> colony after 24 hours. The composite image corresponds to 20 × 42 image tiles captured by phase contrast and segmented tile-by-tile to produce the resulting classification. Inset: zoom of an area where <italic>M. xanthus</italic> cells interact tightly with <italic>E. coli</italic> cells within the <italic>E. coli</italic> colony. Phase Contrast and corresponding predictions (<italic>M. xanthus</italic> in orange and <italic>E. coli</italic> in blue) are shown. (<bold>d</bold>) Morphological analyses of the classified cell population and comparison with the ground truth data. Morphological parameters (Extent, Solidity and minor axis length) were determined for the cells predicted in the <italic>M. xanthus</italic> (Mx mixed) and <italic>E. coli</italic> masks (<italic>E. coli</italic> mixed) in the context of a mixed colony and compared to the same parameters obtained from MiSiC segmented from images of pure cultures (Mx/<italic>E. coli</italic> pure).</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title><italic>E. coli</italic> only for <xref ref-type="fig" rid="fig5">Figure 5d</xref>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig5-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata2"><label>Figure 5—source data 2.</label><caption><title><italic>E. coli</italic> in mixed colony for <xref ref-type="fig" rid="fig5">Figure 5d</xref>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig5-data2-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata3"><label>Figure 5—source data 3.</label><caption><title><italic>M</italic>.<italic>xanthus</italic> only for <xref ref-type="fig" rid="fig5">Figure 5d</xref>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig5-data3-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata4"><label>Figure 5—source data 4.</label><caption><title><italic>M</italic>.<italic>xanthus</italic> in mixed colony for <xref ref-type="fig" rid="fig5">Figure 5d</xref>.</title></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-65151-fig5-data4-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-fig5-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this article, we have presented MiSiC, a deep-learning based bacteria segmentation tool capable of segmenting bacteria in dense colonies imaged through different imaging modalities. The main novelty of our method is the use of a shape index map (SI) as a preprocessing step before network training and segmentation. The SI depends on the Hessian of the image, thus preserving the shape of bacterial masks rather than the raw intensity values, which vary as a function of microscopy modalities. In general, the use of SIs rather than image intensity is a promising lead for any deep learning approach to cell segmentation that relies on shape, which could also solve modality issues for eukaryotic cell and cellular organelle segmentation. Another important asset of MiSiC is the use of synthetic data to enrich training data sets, greatly facilitating ground truth annotations. Combined with the use of SIs, we show that this strategy only requires two adjustment parameters (scaling and noise addition) and it makes segmentation agnostic to imaging modality, and adapted to different bacterial species with different morphologies, provided that they do not deviate too largely from rod shapes. We have currently omitted detection of oval or round cells, to avoid false positive detection of round objects, but in theory, MiSiC could be adapted to such application by simple retraining with an adapted model using both real images and synthetic data. Currently, such retraining requires computational expertise but it is imaginable that a future version of MiSiC would include a GUI to generate training data depending on the needs of the community.</p><p>MiSiC is appropriate for the automated analysis of complex images, such as fluorescence (Bacto-Hubble) images tiles. In our hands, FtsZ-NG-expressing cells could not be properly segmented across tiles with intensity-based methods. In fact, due to the large size of the sample and probable issues with its overall flatness, fluorescence intensities vary across tiles, which required parameter adjustment for each tile, making the task overly complex. These problems are solved in MiSiC because image tiles conversion into SIs cancels fluorescence intensity fluctuations and MiSiC is quite robust to noise (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c</xref>,d). Tile-by-tile segmentation in MiSiC can thus also allow extraction of high-resolution information from large size data sets while allowing prediction of large images with no exceptional memory requirements Typically, a large data set containing up to 3,000 tiles of 500 × 500 pixels (7.5.10<sup>9</sup> pixels) may be segmented in ≈ 50 minutes on a GPU-equipped (Quadro P5000) computer (RAM 64 Gb, Intel Xeon 2.10 GHz). In addition, the Napari environment provides a simple GUI, allowing the generation of MiSiC masks from any image by any user without the need of computational expertise.</p><p>MiSiC is therefore broadly applicable to diverse applications in bacterial cell biology and generates prediction masks that can be used with other available softwares. For example, Supersegger which corrects improper segmentation based on cell contours may likely be used to correct aberrant segmentations in a MiSiC mask, combining the advantage of SI-based segmentation and contour correction. Along similar lines, non-cell or improperly separated cell objects an appear in the MiSiC masks and while some can be removed by the introduction of noise, an easy way to do it is to apply a post-processing filter using morphometric parameters to remove objects that are not bacteria. This can be easily done using Fiji, MicrobeJ or Oufti. MicrobeJ also contains a GUI and associated toolbox to cure improper cell contours manually. MicrobeJ and Oufti are especially useful from downstream analyses of the masks because they both allow cell tracking as well as determining protein localization at sub-diffraction resolution.</p><p>Finally, we show that MiSiC can be further implemented for the semantic classification of bacterial cell types directly from phase contrast images. While the network developed herein works specifically for <italic>M. xanthus</italic> and <italic>E. coli</italic> discrimination, it provides a proof of concept that the approach can be extended to segment and classify any number of bacterial species provided that a dataset (i.e. fluorescence labeling) is available to train a U-Net with ground truth generated in MiSiC. Given that these tasks must be tailored to specific applications, we did not implement them in this package but in principle, adapting MiSiC for such applications could be developed by any laboratory without deep expertise of CNNs. This is an exciting prospect at a time where tremendous efforts are injected to reconstruct micro communities in synthetic contexts for mechanistic studies (<xref ref-type="bibr" rid="bib23">Wolfe et al., 2014</xref>) . Although MiSiC is designed for the analysis of bacteria that develop in 2D, recent toolboxes for the study of micro communities in 3D are also emerging (<xref ref-type="bibr" rid="bib6">Hartmann et al., 2021</xref>; <xref ref-type="bibr" rid="bib25">Zhang et al., 2020</xref>); we therefore foresee that quantitative microscopy approaches will profoundly impact microbiome research of health and environmental significance.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Bacterial strains and predation assays</title><p>The complete list of the strains used for the study is compiled in Table S1 <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. For predation assays, cells of <italic>Myxococcus xanthus</italic> (DZ2, Table S1, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) were grown overnight in 100 mL flasks in 10–20 mL of CYE (<xref ref-type="bibr" rid="bib1">Bustamante et al., 2004</xref>) media without antibiotics at 32°C with shaking. In parallel a colony of <italic>Escherichia coli</italic> (MG1655, Table S1) was grown in 5 mL LB medium in a glass tube at 37°C with shaking. The next day, OD<sub>600 nm</sub> were measured and cultures of both strains were washed twice at 5000 rpm in CF (<xref ref-type="bibr" rid="bib1">Bustamante et al., 2004</xref>) minimal media to discard CYE and LB traces. After the washes, the density of the cultures was brought to 5 OD units in CF media. Pads of CF agar 0.5% were poured in precast frames (in situ GeneFrame, 65 µL, ABGene, AB-0577) that were mounted on glass slides and briefly dried. One µL of both <italic>Myxococcus xanthus</italic> and prey cell suspensions were spotted as close as possible to one another on the pad making sure that they would not merge. Glass slides were kept in a sealed humid dish for 6, 24, 48, or 72 hr at 32°C. Thirty min before observation, the agar pad around the colonies was cut out and discarded and the pad was sealed with a cover slip and observed by microscopy.</p><p><italic>Bacillus subtilis</italic> strains were grown in LB medium at 37°C until they reached an OD<sub>600 nm</sub> of 0.6, were transferred into wells and covered in a low melting LB-based agarose suspension (2%) before observation. <italic>Pseudomonas aeruginosa</italic> was grown in LB medium and cells were observed at an OD<sub>600 nm</sub> of 0.5. <italic>Caulobacter crescentus</italic> was cultured in PYE on the benchtop without shaking for 3–4 days. Cells were imaged from disrupted fragments of a pellicle biofilm and were transferred from the air-liquid interface to glass slides for imaging (<xref ref-type="bibr" rid="bib11">Marks et al., 2010</xref>). <italic>Anabaena nostoc</italic> was grown in BG11 medium at 30°C with illumination (40 µE m-2s-1). Finally, <italic>Desulfovibrio vulgaris</italic> cells were grown until mid-exponential phase (OD<sub>600 nm</sub> of approximately 0.4–0.5) in LS4D medium supplemented with 1 g/L of yeast extract (LS4D-YE) at 33 °C in an anaerobic chamber (COY Laboratory Products) filled with a 10% H<sub>2</sub>-90% N<sub>2</sub> mixed-gas atmosphere. Cultures (200 µL) were centrifuged, and the pellet was resuspended in 100 µl of 10 mM Tris-HCl (pH 7.6), 8 mM MgSO<sub>4</sub> and 1 mM KH<sub>2</sub>PO<sub>4</sub> buffer (TPM buffer). The cells were placed between a coverslip and an agar pad containing 2% of agarose.</p></sec><sec id="s4-2"><title>Molecular biology and strain construction</title><p>To follow cell cycle progression in single cells of <italic>Myxococcus xanthus</italic>, a merodiploid strain of DZ2 expressing both native FtsZ and the fusion protein FtsZ-neonGreen (FtsZ-NG, Table S3 <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>) was built (DM14, Table S1, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). To do so, the coding sequence of DZ2 <italic>ftsZ</italic> gene (MXAN_5597) along with its predicted promoter sequence was amplified by PCR with primers oDM1 and oDM2 (Table S2, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>) and cloned in the non-replicative plasmid pKA32 (<xref ref-type="bibr" rid="bib21">Treuner-Lange et al., 2013</xref>) allowing for its site-specific integration at the DZ2 <italic>attmx8</italic> phage attachment site on the <italic>M. xanthus</italic> chromosome. The coding sequence of the neonGreen protein was amplified from a plasmid (<xref ref-type="bibr" rid="bib18">Shaner et al., 2013</xref>) using primers oDM16 and oDM17 (Table S2 <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>) allowing the in frame addition of neonGreen at the C-terminus of the FtsZ protein. When grown in CYE rich medium, DM14 did not present any significant defect in growth rate or cell shape. DM14 cell size is not significantly different from that of the isogenic wild type DZ2 strain. DM14 cells were spotted on thin CF agar pads to follow FtsZ localization in axenic cultures and allowed us to confirm that cell cycle progression was accompanied with the relocalization of Ftsz-nG from being diffuse in the cytoplasm to forming a discrete fluorescent focus at mid-cell before cell septation as previously described (<xref ref-type="bibr" rid="bib21">Treuner-Lange et al., 2013</xref>).</p><p>To generate Dataset 2 (see below), strains of <italic>E. coli</italic> (EC500, Table S1 <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) and <italic>M. xanthus</italic> (DM31, Table S1 <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) expressing soluble versions of mCherry and sfGFP fluorophores respectively were used. To generate DM31, a plasmid allowing for the constitutive expression of sfGFP was built (pDM14 Table S3 <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). To obtain a high and constitutive expression of sfGFP in <italic>M. xanthus</italic>, we sought for the closest homolog of the constitutively expressed <italic>E. coli</italic> EF-TU (Translation elongation factor) in <italic>M. xanthus</italic> genome which is MXAN_3068. The 1000 bp region upstream of MXAN_3068 (<italic>p3068</italic>) was amplified by PCR using oDM53 and oDM54 and cloned upstream the coding sequence of sfGFP (amplified using primers oDM61 and oDM62) in a pSWU19 plasmid. The transcriptional fusion was then integrated on DZ2 chromosome at the <italic>attmx8</italic> site through transformation. DM31 cells display a constitutive bright diffuse fluorescent signal in our growth conditions.</p></sec><sec id="s4-3"><title>Microscopy and image acquisition</title><p>All microscopy images were acquired with an inverted optical microscope (Nikon TiE) and a 100 x NA = 1.45 Phase Contrast objective. Camera used was Orca-EM CCD 1000 × 1000 (Hamamatsu) camera mostly set with binning 2 × 2. Acquisition software was Nikon NIS-Elements with specific module JOBS. Fluorescence acquisition used a diode-based excitation device (Spectra-X Lumencore).</p><p>The Bacto-Hubble image is a composite image of rasters of the entire area and requires that the scanning speed must be sufficiently fast to avoid image shifts due to ongoing cell dynamics. To minimize the shift in focus from tile to tile we used Nikon perfect focus system (PFS) equipped with servo-control of the focus with an infrared LED. This is especially challenging because continuous focus alignment of the microscope slows down the acquisition times dramatically. To obtain a satisfactory compromise allowing both fast scanning and correct focusing we: (i) reduced the number of dynamic elements on the microscope set up: we replaced shutters by Light Emitting Diodes (LEDs, Spectra-X for fluorescence source and a white diode for transmitted light) which could be switched with a high-frequency rate (100 kHz). In addition, a double band dichroic mirror for the fluorescent cube was used to avoid switching the filters’ turret for each snapshot. (ii) used an EM-CCD camera set to a 2 × 2 binning mode to reduce the size of images (500 × 500 pixels at 0.16 µm/px) and acquisition time, and (iii) sped up the vertical movements by means of a piezoelectric stage. In its largest scanning mode, Bacto-Hubble thus captures 80 × 40 raster images covering a total surface of 20 mm2 (containing up to 0.8 billion pixels, an acquisition-time up to 4 hr), enabling a continuous magnification display from eye visible structures to single-cells. Individual tiles for Bacto-Hubble images were acquired with the scan large field capabilities of NIS-Elements software. A key point for Bacto-Hubble large images was the quality of the sample slide mounting. The samples were placed on a glass slide with a thin double-sided sticky frame (in situ GeneFrame, 65 µL, ABGene, AB-0577). An agar pad was poured inside the frame and a microliter of cells was placed on it. The chamber was closed with a glass cover slide. This assembly allows very good flatness and rigidity.</p></sec><sec id="s4-4"><title>U-NET as base architecture</title><p>We implement a U-net inspired in encoder-decoder architecture with skip-connections and use it as a base network for segmentation tasks. This architecture is now widely used for segmentation tasks and has many advantages that are discussed in previous articles (<xref ref-type="bibr" rid="bib5">Falk et al., 2019</xref>; <xref ref-type="bibr" rid="bib16">Ronneberger et al., 2015</xref>). The original U-net architecture (<xref ref-type="bibr" rid="bib5">Falk et al., 2019</xref>) was modified to include relu activation for all layers except for the output layer where sigmoid activation was used. The general U-net was implemented in Python programming language using tensorflow (<ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org/tutorials/images/segmentation">https://www.tensorflow.org/tutorials/images/segmentation</ext-link>), where the number of input channels (say, n) and output classes (say, m ) could be varied as required by different models. The number of encoder layers were fixed to four with filter lengths [32,64,128,256] for the encoder side. The loss function was also modified from the original implementation. A combination binary cross entropy and the <xref ref-type="bibr" rid="bib7">Jaccard, 1912</xref> index was used as the loss function with Adams optimizer (learning rate = 0.001) for the minimization.</p><p>For brevity, we denote the network as a mapping between input X and output y as,, where X is a set of images with n channels and y is the output with m classes. Thus given a training data set of X<sub>train</sub> with sizes (N × S × S× n) and multiclass images y<sub>train</sub> (of size N × S × S× m), the generalized implementation of U-NET learns to predict the segmented image from unknown images X.</p></sec><sec id="s4-5"><title>Training datasets</title><p>Two training datasets were used for this study. Dataset one to segment bacterial cells (MiSiC) and Dataset two to classify <italic>Myxococcus</italic> and <italic>E. coli</italic> cells in mixed cultures.</p><sec id="s4-5-1"><title>Dataset 1</title><p>Combination of hand-annotated data with synthetic data provided the most accurate segmentation after training. When the network was trained with synthetic data only, segmentation was less performant presumably due to the fact that the synthetic data was generated by randomly throwing cell-shaped objects onto an image, which does not capture the intricate patterns created by cell-cell interactions observed in real images of dense cell populations.</p><p>This training dataset consists of three parts:</p><list list-type="alpha-lower"><list-item><p>A hand annotated dataset corresponding to: 263(training) +87(test) cases of Bright-field images of <italic>Escherichia coli</italic> and <italic>Myxococcus xanthus</italic> with segmented masks. This data set corresponds to images sizing from 157 × 157 to 217 × 217 pixels and containing a variable number of cells (up to 400 cells per image) for a total number of cells of 34,807 manually drawn cells.</p></list-item><list-item><p>200 null cases that contain background images without bacteria taken from bright-field, fluorescence and phase contrast data.</p></list-item><list-item><p>A synthetic data set consisting of 600 cases was generated, 30% containing 16 cells per image (256 × 256 pixels) for sparse densities and 70% containing a maximum of 327 cells for high densities per image. Furthermore, 200 null cases, generated by inclusion of random gaussian noise and circular objects, were also included in the dataset. The synthetic data was generated with a simple model for rod-shaped bacteria with a width ranging from 8 to 10 pixels. An overlap threshold of 2% was used to obtain a dense cell population. The binary mask created was then smoothed with a Gaussian filter and Gaussian noise was added to emulate noise in real images.</p></list-item></list><p>The ground truth in this training dataset (denoted as [X′,y ]) has two classes: one with the mask of bacteria and the other with the contour of the detected cell. The test set consists of 87 cases of labeled bright-field images unseen by the trained network. The accuracy of the network is calculated over this test set.</p></sec><sec id="s4-5-2"><title>Dataset 2</title><p>This dataset was used to train the classification network to discriminate <italic>Myxococcus xanthus</italic> and <italic>Escherichia coli</italic> cells directly from phase contrast images. To construct the data set, we obtained images from predatory interactions of <italic>M. xanthus</italic> and <italic>E. coli</italic>, where <italic>M. xanthus</italic> is tagged with green fluorescence (GFP, DM31, Table S1, <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) and <italic>Escherichia coli</italic> with red fluorescence (mCherry, EC500 -Shaner et al. 2004- Table S1). The fluorescence images were then processed with a gamma adjustment and segmented using MiSiC to produce clean masks and contours of two classes, namely, <italic>Myxococcus xanthus</italic> and <italic>Escherichia coli</italic>. Thus, y in dataset two contains two channels corresponding to a mask of each class. A total of 4,000 such pseudo-annotated images of size (256 × 256) were used for dataset 2. These images were obtained after random cropping of microscope images (1000 × 1000) and the number of cells varied from image to image.</p></sec></sec><sec id="s4-6"><title>MiSiC, shape-index map-based segmentation</title><p><inline-formula><mml:math id="inf1"><mml:mi>σ</mml:mi></mml:math></inline-formula>The shape index (SI) map of an image, x, calculated over a scale , is defined as<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mi>S</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mfrac><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <italic>k<sub>1</sub></italic>, <italic>k<sub>2</sub></italic> (with <italic>k<sub>1</sub></italic>&gt; <italic>k<sub>2</sub></italic>) are the eigenvalues of the Hessian of the image,<inline-formula><mml:math id="inf2"><mml:mi>x</mml:mi></mml:math></inline-formula>, calculated over a scale <inline-formula><mml:math id="inf3"><mml:mi>σ</mml:mi></mml:math></inline-formula>(<xref ref-type="bibr" rid="bib9">Koenderink and van Doorn, 1992</xref>). The SI map remains within the range [−1, 1] and preserves the MiSiC shape information while being independent of the intensity values of the original image. Using the Dataset 1, we pre-process the input images X′ to generate a train set: X<sub>train</sub> of size 1260 × 256 × 256 × 3. Each channel in X<sub>train</sub> is the shape-index map calculated at three different scales [1,1.5,2] to obtain shape index information of the cells at various scales. An instance of the U-net is trained over this data set to produce a network able to map data represented by X<sub>train</sub> → y<sub>train</sub>. The network learns to reject the noise in the shape-index map and produces masks and boundaries of the cell like structures in the shape-index map. The trained network was tested over 87 cases of labelled bright-field images, that were previously unseen by the network leading to a segmentation accuracy of 0.76 computed with <xref ref-type="bibr" rid="bib7">Jaccard, 1912</xref> coefficient.</p></sec><sec id="s4-7"><title>Preprocessing</title><p>Preprocessing the input image to enhance the edge contrast and homogenising intensities helps in obtaining a good segmentation via MiSiC. Some of the preprocessing that gave good results are gamma correction for homogenising, unsharp masking for sharpening the image and sometimes a gaussian of laplace of the image that removes intensity variations in the entire image and keeps edge-like features.</p></sec><sec id="s4-8"><title>Parameters: scale and noise variance</title><p>The dataset one used to train the MiSiC contains cells with a width in the range of 8–10 pixels.Thus, to obtain a satisfactory segmentation, the input image must be scaled so that the average bacteria width is around 10 pixels. However, the scaling often modifies the original image leading to a smoother shape index map. Since, MiSiC has basically learnt to distinguish between smooth curvatures with well-defined boundaries from noisy background. A smooth image without inherent noise leads to a lot of false positive segmentations. Therefore, counterintuitively, synthetic noise must be added to the scaled or original image for a proper segmentation. It must be kept in mind that the noise variance should not reduce the contrast of the edges in the original image while it should be enough to discard spurious detections. Gaussian noise of a constant variance may be added to the entire image or alternatively, the variance could be a function of the edges in the input image.</p></sec><sec id="s4-9"><title><italic>Myxococcus xanthus</italic> and <italic>Escherichia coli</italic> classification</title><p>A U-NET was trained on dataset two to segment a single channel phase-contrast image into an image containing semantic classification of each species. The probability map for each label is color coded (blue = <italic>E. coli. coli</italic>, orange = <italic>M. xanthus</italic>) such that each pixel has a probability value to be part of a given class. In rare instances, bi-color objects are obtained because in these cases the prediction is not homogeneous inside the predicted objects. For subsequent analysis, these objects were filtered for the morphometric analysis shown in <xref ref-type="fig" rid="fig5">Figure 5c</xref>. A trained model and a python script illustrating how it was used is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/pswapnesh/MyxoColi">https://github.com/pswapnesh/MyxoColi</ext-link>.</p></sec><sec id="s4-10"><title>Image analysis and statistics</title><p>The validation of the automated MiSiC results shown in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, was performed by comparing MiSiC masks to hand-annotated masks obtained by a single observer, herein referred to as ground-truth. This ground truth was also compared to data annotated by a second observer to test variability between observers. For comparison, curves of Jaccard Index vs. IoU threshold were constructed based on <xref ref-type="bibr" rid="bib8">Jeckel and Drescher, 2021</xref>. Such curves allow a precise estimate of the accuracy and quality of shape detection and prediction.</p><p>For this, the <inline-formula><mml:math id="inf4"><mml:mi>I</mml:mi><mml:mi>o</mml:mi><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>X</mml:mi><mml:mo>∩</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mo>∪</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula> (<italic>X = Ground Truth object; Y = Predicted object</italic> ) was determined by overlaying each predicted MiSiC mask with its corresponding ground truth mask and the number of True Positives (TP), False Positives (FP) and False Negatives (FN) that remain above varying IoU thresholds, applied from values ranging from 0.00 to 1.00 in 0.01 intervals, was determined so as to calculate the Jaccard index defined by the ratio <inline-formula><mml:math id="inf5"><mml:mi>J</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula> for a given threshold value.</p><p>To estimate the accuracy of classification, JIs were determined directly by comparing hand-annotated (ground truth) datasets obtained from fluorescence image of GFP (<italic>Myxocococus</italic>) and mCherry (<italic>E. coli</italic>).</p><p>Analysis of MiSiC performance in the presence of noise and comparison with Supersegger.</p><p>To illustrate MiSiC performances in the presence of noise and in comparison with SuperSegger (<xref ref-type="bibr" rid="bib19">Stylianidou et al., 2016</xref>), datasets consisting of 141 <italic>E. coli</italic> microcolony images were retrieved from the SuperSegger website. These images were analysed with the provided parameters with SuperSegger and with the following parameters with MiSiC: Cell width = 9, Scaling factor = Auto, Noise = 0.001, Unsharp = 0.6 and Gamma = 0.1. To assess the segmentation robustness to noise for each program, datasets were normalized by the maximum intensity value recorded in the first frame of the dataset and Gaussian noise was added with varying variance. The resulting datasets were then analysed with the initial parameters used to compute reference segmented images except for MiSiC where the noise parameter was set to 0. The relative performance of each program was then evaluated by computing Dice indices (<xref ref-type="bibr" rid="bib26">Zijdenbos et al., 1994</xref>).<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">A</mml:mi><mml:mo>∩</mml:mo><mml:mi mathvariant="normal">B</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">B</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-11"><title>Morphological analyses</title><p>Classic morphological features: Area, Perimeter, Bounding Box (Width, Height), Circularity, Feret diameter, minimum Feret diameter, MajorAxis (ellipse), MinorAxis (ellipse), (n) number of objects.</p><p>Special calculated morphological features: Solidity = Area / Convex Area; AR = MajorAxis / MinorAxis; Extend = Area / (Width*Height).</p></sec><sec id="s4-12"><title>Demograph construction</title><p>To construct the plot shown in <xref ref-type="fig" rid="fig4">Figure 4e</xref> (demograph), the cells bodies were obtained with MiSiC segmentation and the binary mask was analyzed with the MicrobeJ software (<xref ref-type="bibr" rid="bib3">Ducret et al., 2016</xref>), with a cell model set to parameters (area &gt;0.5 µm<sup>2</sup>, Circularity &lt;0.8, ‘poles’ = 2) to filter all remaining segmented objects that do not correspond to cells. The localization of the centroid (cell middle) and length of longitudinal axis was then determined for each cell under MicrobeJ. The fluorescent clusters were detected with a local maxima filter and their position relative to the middle of the cell was plotted along the axis with a positive sign. Negative sign clusters are therefore the manifestation of rare cells with bi-polar foci. The fluorescent clusters are plotted as dots with a color scale based on spatial density.</p></sec><sec id="s4-13"><title>Cell division detection</title><p>In <xref ref-type="fig" rid="fig4">Figure 4i</xref>, clusters of fluorescent protein FtsZ-NG were used as cell division markers. The clusters were detected by local maxima detection (scikits-image.peak_local_max(image = fluorescence image, label = MiSiC mask, num_peaks = 1)).</p></sec><sec id="s4-14"><title>Calculation of cell division ratios</title><p>The cell division ratio in <xref ref-type="fig" rid="fig4">Figure 4j</xref> was calculated using the spatial 2D density derived from (i) the mask of the total fluorescent cell population across the entire image and (ii), the mask of the total number of fluorescent maxima (reflecting dividing cells) across the entire image. Spatial densities were calculated with sklearn.neighbors.KernelDensity(), with a bandwidth of 1% of the image width. The proportion of dividing cells was obtained by dividing the spatial density maps: density of fluorescent maxima/density of total cells.</p></sec><sec id="s4-15"><title>Code availability</title><p>A MiSiC pip installable python package is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/pswapnesh/MiSiC">https://github.com/pswapnesh/MiSiC</ext-link> (<xref ref-type="bibr" rid="bib20">Swapnesh, 2021</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:dd2682324256d122fd777278ac798b1ca766633e;origin=https://github.com/pswapnesh/misic;visit=swh:1:snp:adfe20ee79d737909cf5b0dcbe238cb921e43c14;anchor=swh:1:rev:45f659124a8e207f78296d77664fb96de5472708">swh:1:rev:45f659124a8e207f78296d77664fb96de5472708</ext-link>).</p><p>A Graphic user Interface pip installable as python package is available at <ext-link ext-link-type="uri" xlink:href="https://githubcom/leec13/MiSiCgui">https://github.com/leec13/MiSiCgui</ext-link> (<xref ref-type="bibr" rid="bib4">Espinosa, 2021</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="swh:1:dir:3a84dbf0d149b04b5b056187cf73e3083700bb11; origin=https://github.com/leec13/MiSiCgui; visit=swh:1:snp:8aa006fa20ad9f3776b826b300e97fa817bafc6e; anchor=swh:1:rev:97401bedd44aa7b28d22f8cf87e76b521f15f40a">swh:1:rev:97401bedd44aa7b28d22f8cf87e76b521f15f40a</ext-link>).</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf3"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Investigation, Methodology, Software, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation, Data curation</p></fn><fn fn-type="con" id="con3"><p>Data curation, Visualization</p></fn><fn fn-type="con" id="con4"><p>Funding acquisition, Methodology</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Funding acquisition, Investigation, Methodology, Data curation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Funding acquisition, Project administration, Investigation, Methodology, Supervision, Validation, Data curation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Funding acquisition, Project administration, Investigation, Methodology, Supervision, Validation, Data curation, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Funding acquisition, Project administration, Investigation, Methodology, Supervision, Validation, Data curation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Funding acquisition, Project administration, Investigation, Methodology, Supervision, Validation, Data curation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con10"><p>Conceptualization, Funding acquisition, Project administration, Investigation, Methodology, Supervision, Validation, Data curation, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-65151-transrepform1-v2.docx"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Table S1 - Bacterial strains used in this study.</title></caption><media mime-subtype="pdf" mimetype="application" xlink:href="elife-65151-supp1-v2.pdf"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Table S2 - Primers.</title></caption><media mime-subtype="pdf" mimetype="application" xlink:href="elife-65151-supp2-v2.pdf"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>Table S3 - Plasmids.</title></caption><media mime-subtype="pdf" mimetype="application" xlink:href="elife-65151-supp3-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The tensorflow model describe in this article is available in GitHub: https://github.com/pswapnesh/MiSiC (copy archived at https://archive.softwareheritage.org/swh:1:rev:45f659124a8e207f78296d77664fb96de5472708); https://github.com/leec13/MiSiCgui (copy archived at https://archive.softwareheritage.org/swh:1:rev:97401bedd44aa7b28d22f8cf87e76b521f15f40a). Source data files have been provided for Figures 2, 3, 4 and 5.</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Anke Treuner-Lange in Lotte Sogaard-Andersen lab for sharing the plasmid pKA32 with us (<xref ref-type="bibr" rid="bib21">Treuner-Lange et al., 2013</xref>). MiSiC robustness was tested on microscope images showing various bacterial strains that were kindly shared with us. For that, we thank Anne Galinier and Thierry Doan (<italic>Bacillus subtilis</italic>), Christophe Bordi (<italic>Pseudomonas aeruginosa</italic>), Aretha Fiebig (<italic>Caulobacter crescentus</italic>) and Romain Mercier (SgmX-GFP images of <italic>Myxococcus xanthus</italic>). We also thank Baptiste Piguet-Ruinet and Célia Jonas for constructing the pDM14 plasmid during their internship. We thank Jean Raphael Fantino for the design of the MiSiC Logo. SP, LE, and TM are funded by CNRS within a 80-Prime initiative. TM is funded by an ERC Advanced Grant (JAWS EM is funded by an AMIDEX-PhD program from Aix-Marseille University). MN, JBF, AL and SR are funded by two ANR grants IBM (ANR-14-CE09-0025-01) and HiResBacs (ANR-15-CE11-0023).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bustamante</surname><given-names>VH</given-names></name><name><surname>Martínez-Flores</surname><given-names>I</given-names></name><name><surname>Vlamakis</surname><given-names>HC</given-names></name><name><surname>Zusman</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Analysis of the Frz signal transduction system of Myxococcus xanthus shows the importance of the conserved c-terminal region of the cytoplasmic chemoreceptor FRZCD in sensing signals</article-title><source>Molecular Microbiology</source><volume>53</volume><fpage>1501</fpage><lpage>1513</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2958.2004.04221.x</pub-id><pub-id pub-id-type="pmid">15387825</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campos</surname><given-names>M</given-names></name><name><surname>Surovtsev</surname><given-names>IV</given-names></name><name><surname>Kato</surname><given-names>S</given-names></name><name><surname>Paintdakhi</surname><given-names>A</given-names></name><name><surname>Beltran</surname><given-names>B</given-names></name><name><surname>Ebmeier</surname><given-names>SE</given-names></name><name><surname>Jacobs-Wagner</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A constant size extension drives bacterial cell size homeostasis</article-title><source>Cell</source><volume>159</volume><fpage>1433</fpage><lpage>1446</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.11.022</pub-id><pub-id pub-id-type="pmid">25480302</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ducret</surname><given-names>A</given-names></name><name><surname>Quardokus</surname><given-names>EM</given-names></name><name><surname>Brun</surname><given-names>YV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>MICROBEJ, a tool for high throughput bacterial cell detection and quantitative analysis</article-title><source>Nature Microbiology</source><volume>1</volume><elocation-id>16077</elocation-id><pub-id pub-id-type="doi">10.1038/nmicrobiol.2016.77</pub-id><pub-id pub-id-type="pmid">27572972</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Espinosa</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>MiSiCgui</data-title><version designator="swh:1:rev:97401bedd44aa7b28d22f8cf87e76b521f15f40a">swh:1:rev:97401bedd44aa7b28d22f8cf87e76b521f15f40a</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:3a84dbf0d149b04b5b056187cf73e3083700bb11;origin=https://github.com/leec13/MiSiCgui;visit=swh:1:snp:8aa006fa20ad9f3776b826b300e97fa817bafc6e;anchor=swh:1:rev:97401bedd44aa7b28d22f8cf87e76b521f15f40a">https://archive.softwareheritage.org/swh:1:dir:3a84dbf0d149b04b5b056187cf73e3083700bb11;origin=https://github.com/leec13/MiSiCgui;visit=swh:1:snp:8aa006fa20ad9f3776b826b300e97fa817bafc6e;anchor=swh:1:rev:97401bedd44aa7b28d22f8cf87e76b521f15f40a</ext-link></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Falk</surname><given-names>T</given-names></name><name><surname>Mai</surname><given-names>D</given-names></name><name><surname>Bensch</surname><given-names>R</given-names></name><name><surname>Çiçek</surname><given-names>Ö</given-names></name><name><surname>Abdulkadir</surname><given-names>A</given-names></name><name><surname>Marrakchi</surname><given-names>Y</given-names></name><name><surname>Böhm</surname><given-names>A</given-names></name><name><surname>Deubner</surname><given-names>J</given-names></name><name><surname>Jäckel</surname><given-names>Z</given-names></name><name><surname>Seiwald</surname><given-names>K</given-names></name><name><surname>Dovzhenko</surname><given-names>A</given-names></name><name><surname>Tietz</surname><given-names>O</given-names></name><name><surname>Dal Bosco</surname><given-names>C</given-names></name><name><surname>Walsh</surname><given-names>S</given-names></name><name><surname>Saltukoglu</surname><given-names>D</given-names></name><name><surname>Tay</surname><given-names>TL</given-names></name><name><surname>Prinz</surname><given-names>M</given-names></name><name><surname>Palme</surname><given-names>K</given-names></name><name><surname>Simons</surname><given-names>M</given-names></name><name><surname>Diester</surname><given-names>I</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name><name><surname>Ronneberger</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>U-net: Deep learning for cell counting, detection, and morphometry</article-title><source>Nature Methods</source><volume>16</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0261-2</pub-id><pub-id pub-id-type="pmid">30559429</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartmann</surname><given-names>R</given-names></name><name><surname>Jeckel</surname><given-names>H</given-names></name><name><surname>Jelli</surname><given-names>E</given-names></name><name><surname>Singh</surname><given-names>PK</given-names></name><name><surname>Vaidya</surname><given-names>S</given-names></name><name><surname>Bayer</surname><given-names>M</given-names></name><name><surname>Rode</surname><given-names>DKH</given-names></name><name><surname>Vidakovic</surname><given-names>L</given-names></name><name><surname>Díaz-Pascual</surname><given-names>F</given-names></name><name><surname>Fong</surname><given-names>JCN</given-names></name><name><surname>Dragoš</surname><given-names>A</given-names></name><name><surname>Lamprecht</surname><given-names>O</given-names></name><name><surname>Thöming</surname><given-names>JG</given-names></name><name><surname>Netter</surname><given-names>N</given-names></name><name><surname>Häussler</surname><given-names>S</given-names></name><name><surname>Nadell</surname><given-names>CD</given-names></name><name><surname>Sourjik</surname><given-names>V</given-names></name><name><surname>Kovács</surname><given-names>ÁT</given-names></name><name><surname>Yildiz</surname><given-names>FH</given-names></name><name><surname>Drescher</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Quantitative image analysis of microbial communities with Biofilmq</article-title><source>Nature Microbiology</source><volume>6</volume><fpage>151</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1038/s41564-020-00817-4</pub-id><pub-id pub-id-type="pmid">33398098</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaccard</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1912">1912</year><article-title>The distribution of the flora in the alpine zone.1</article-title><source>New Phytologist</source><volume>11</volume><fpage>37</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8137.1912.tb05611.x</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeckel</surname><given-names>H</given-names></name><name><surname>Drescher</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Advances and opportunities in image analysis of bacterial cells and communities</article-title><source>FEMS Microbiology Reviews</source><volume>45</volume><elocation-id>fuaa062</elocation-id><pub-id pub-id-type="doi">10.1093/femsre/fuaa062</pub-id><pub-id pub-id-type="pmid">33242074</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koenderink</surname><given-names>JJ</given-names></name><name><surname>van Doorn</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Surface shape and curvature scales</article-title><source>Image and Vision Computing</source><volume>10</volume><fpage>557</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1016/0262-8856(92)90076-F</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lugagne</surname><given-names>JB</given-names></name><name><surname>Lin</surname><given-names>H</given-names></name><name><surname>Dunlop</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>DELTA: Automated cell segmentation, tracking, and lineage reconstruction using deep learning</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007673</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007673</pub-id><pub-id pub-id-type="pmid">32282792</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marks</surname><given-names>ME</given-names></name><name><surname>Castro-Rojas</surname><given-names>CM</given-names></name><name><surname>Teiling</surname><given-names>C</given-names></name><name><surname>Du</surname><given-names>L</given-names></name><name><surname>Kapatral</surname><given-names>V</given-names></name><name><surname>Walunas</surname><given-names>TL</given-names></name><name><surname>Crosson</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The genetic basis of laboratory adaptation in Caulobacter crescentus</article-title><source>Journal of Bacteriology</source><volume>192</volume><fpage>3678</fpage><lpage>3688</lpage><pub-id pub-id-type="doi">10.1128/JB.00255-10</pub-id><pub-id pub-id-type="pmid">20472802</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mercier</surname><given-names>R</given-names></name><name><surname>Bautista</surname><given-names>S</given-names></name><name><surname>Delannoy</surname><given-names>M</given-names></name><name><surname>Gibert</surname><given-names>M</given-names></name><name><surname>Guiseppi</surname><given-names>A</given-names></name><name><surname>Herrou</surname><given-names>J</given-names></name><name><surname>Mauriello</surname><given-names>EMF</given-names></name><name><surname>Mignot</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The polar ras-like gtpase MGLA activates type IV pilus via SGMX to enable twitching motility in Myxococcus xanthus</article-title><source>PNAS</source><volume>117</volume><fpage>28366</fpage><lpage>28373</lpage><pub-id pub-id-type="doi">10.1073/pnas.2002783117</pub-id><pub-id pub-id-type="pmid">33093210</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paintdakhi</surname><given-names>A</given-names></name><name><surname>Parry</surname><given-names>B</given-names></name><name><surname>Campos</surname><given-names>M</given-names></name><name><surname>Irnov</surname><given-names>I</given-names></name><name><surname>Elf</surname><given-names>J</given-names></name><name><surname>Surovtsev</surname><given-names>I</given-names></name><name><surname>Jacobs-Wagner</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>OUFTI: An integrated software package for high-accuracy, high-throughput quantitative microscopy analysis</article-title><source>Molecular Microbiology</source><volume>99</volume><fpage>767</fpage><lpage>777</lpage><pub-id pub-id-type="doi">10.1111/mmi.13264</pub-id><pub-id pub-id-type="pmid">26538279</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pérez</surname><given-names>J</given-names></name><name><surname>Moraleda-Muñoz</surname><given-names>A</given-names></name><name><surname>Marcos-Torres</surname><given-names>FJ</given-names></name><name><surname>Muñoz-Dorado</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Bacterial predation: 75 years and counting!</article-title><source>Environmental Microbiology</source><volume>18</volume><fpage>766</fpage><lpage>779</lpage><pub-id pub-id-type="doi">10.1111/1462-2920.13171</pub-id><pub-id pub-id-type="pmid">26663201</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Potapova</surname><given-names>A</given-names></name><name><surname>Carreira</surname><given-names>LAM</given-names></name><name><surname>Søgaard-Andersen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The small gtpase MGLA together with the TPR domain protein SGMX stimulates type iv pili formation in M. Xanthus</article-title><source>PNAS</source><volume>117</volume><fpage>23859</fpage><lpage>23868</lpage><pub-id pub-id-type="doi">10.1073/pnas.2004722117</pub-id><pub-id pub-id-type="pmid">32900945</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O</given-names></name><name><surname>Fischer</surname><given-names>P</given-names></name><name><surname>Brox</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>U-Net: Convolutional Networks for Biomedical Image Segmentation</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1505.04597">https://arxiv.org/abs/1505.04597</ext-link></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schumacher</surname><given-names>D</given-names></name><name><surname>Bergeler</surname><given-names>S</given-names></name><name><surname>Harms</surname><given-names>A</given-names></name><name><surname>Vonck</surname><given-names>J</given-names></name><name><surname>Huneke-Vogt</surname><given-names>S</given-names></name><name><surname>Frey</surname><given-names>E</given-names></name><name><surname>Søgaard-Andersen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The POMXYZ proteins self-organize on the bacterial nucleoid to stimulate cell division</article-title><source>Developmental Cell</source><volume>41</volume><fpage>299</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1016/j.devcel.2017.04.011</pub-id><pub-id pub-id-type="pmid">28486132</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaner</surname><given-names>NC</given-names></name><name><surname>Lambert</surname><given-names>GG</given-names></name><name><surname>Chammas</surname><given-names>A</given-names></name><name><surname>Ni</surname><given-names>Y</given-names></name><name><surname>Cranfill</surname><given-names>PJ</given-names></name><name><surname>Baird</surname><given-names>MA</given-names></name><name><surname>Sell</surname><given-names>BR</given-names></name><name><surname>Allen</surname><given-names>JR</given-names></name><name><surname>Day</surname><given-names>RN</given-names></name><name><surname>Israelsson</surname><given-names>M</given-names></name><name><surname>Davidson</surname><given-names>MW</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A bright monomeric green fluorescent protein derived from branchiostoma lanceolatum</article-title><source>Nature Methods</source><volume>10</volume><fpage>407</fpage><lpage>409</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2413</pub-id><pub-id pub-id-type="pmid">23524392</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stylianidou</surname><given-names>S</given-names></name><name><surname>Brennan</surname><given-names>C</given-names></name><name><surname>Nissen</surname><given-names>SB</given-names></name><name><surname>Kuwada</surname><given-names>NJ</given-names></name><name><surname>Wiggins</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Supersegger: Robust image segmentation, analysis and lineage tracking of bacterial cells</article-title><source>Molecular Microbiology</source><volume>102</volume><fpage>690</fpage><lpage>700</lpage><pub-id pub-id-type="doi">10.1111/mmi.13486</pub-id><pub-id pub-id-type="pmid">27569113</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Swapnesh</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Misic</data-title><version designator="swh:1:rev:45f659124a8e207f78296d77664fb96de5472708">swh:1:rev:45f659124a8e207f78296d77664fb96de5472708</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:dd2682324256d122fd777278ac798b1ca766633e;origin=https://github.com/pswapnesh/misic;visit=swh:1:snp:adfe20ee79d737909cf5b0dcbe238cb921e43c14;anchor=swh:1:rev:45f659124a8e207f78296d77664fb96de5472708">https://archive.softwareheritage.org/swh:1:dir:dd2682324256d122fd777278ac798b1ca766633e;origin=https://github.com/pswapnesh/misic;visit=swh:1:snp:adfe20ee79d737909cf5b0dcbe238cb921e43c14;anchor=swh:1:rev:45f659124a8e207f78296d77664fb96de5472708</ext-link></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treuner-Lange</surname><given-names>A</given-names></name><name><surname>Aguiluz</surname><given-names>K</given-names></name><name><surname>van der Does</surname><given-names>C</given-names></name><name><surname>Gómez-Santos</surname><given-names>N</given-names></name><name><surname>Harms</surname><given-names>A</given-names></name><name><surname>Schumacher</surname><given-names>D</given-names></name><name><surname>Lenz</surname><given-names>P</given-names></name><name><surname>Hoppert</surname><given-names>M</given-names></name><name><surname>Kahnt</surname><given-names>J</given-names></name><name><surname>Muñoz-Dorado</surname><given-names>J</given-names></name><name><surname>Søgaard-Andersen</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>POMZ, a para-like protein, regulates z-ring formation and cell division in myxococcus xanthus</article-title><source>Molecular Microbiology</source><volume>87</volume><fpage>235</fpage><lpage>253</lpage><pub-id pub-id-type="doi">10.1111/mmi.12094</pub-id><pub-id pub-id-type="pmid">23145985</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Valen</surname><given-names>DA</given-names></name><name><surname>Kudo</surname><given-names>T</given-names></name><name><surname>Lane</surname><given-names>KM</given-names></name><name><surname>Macklin</surname><given-names>DN</given-names></name><name><surname>Quach</surname><given-names>NT</given-names></name><name><surname>DeFelice</surname><given-names>MM</given-names></name><name><surname>Maayan</surname><given-names>I</given-names></name><name><surname>Tanouchi</surname><given-names>Y</given-names></name><name><surname>Ashley</surname><given-names>EA</given-names></name><name><surname>Covert</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deep learning automates the quantitative analysis of individual cells in live-cell imaging experiments</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005177</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005177</pub-id><pub-id pub-id-type="pmid">27814364</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname><given-names>BE</given-names></name><name><surname>Button</surname><given-names>JE</given-names></name><name><surname>Santarelli</surname><given-names>M</given-names></name><name><surname>Dutton</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cheese rind communities provide tractable systems for in situ and in vitro studies of microbial diversity</article-title><source>Cell</source><volume>158</volume><fpage>422</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.05.041</pub-id><pub-id pub-id-type="pmid">25036636</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Cao</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><conf-name>Combining watersheds and conditional random fields for image classification</conf-name><article-title>2013 10th International Conference on Fuzzy Systems and Knowledge Discovery</article-title><fpage>805</fpage><lpage>810</lpage><pub-id pub-id-type="doi">10.1109/FSKD.2013.6816304</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Achimovich</surname><given-names>AM</given-names></name><name><surname>Acton</surname><given-names>ST</given-names></name><name><surname>Gahlmann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Non-invasive single-cell morphometry in living bacterial biofilms</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>6151</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-19866-8</pub-id><pub-id pub-id-type="pmid">33262347</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zijdenbos</surname><given-names>AP</given-names></name><name><surname>Dawant</surname><given-names>BM</given-names></name><name><surname>Margolin</surname><given-names>RA</given-names></name><name><surname>Palmer</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Morphometric analysis of white matter lesions in MR images: Method and validation</article-title><source>IEEE Transactions on Medical Imaging</source><volume>13</volume><fpage>716</fpage><lpage>724</lpage><pub-id pub-id-type="doi">10.1109/42.363096</pub-id><pub-id pub-id-type="pmid">18218550</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.65151.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Xiao</surname><given-names>Jie</given-names></name><role>Reviewing Editor</role><aff><institution>Johns Hopkins University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Hensel</surname><given-names>Zach</given-names></name><role>Reviewer</role><aff><institution>ITQB NOVA</institution><country>Portugal</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.10.07.328666">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.10.07.328666v1">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Your work of developing the MiSiC package to segment single cells in crowded bacterial colonies and identify different species in the colonies is of great importance to the community. The final version of the manuscript incorporated all reviewers' comments with improved readability. An updated user guide is provided. We are also pleased with your commitment to disseminate this important tool to other research labs in the community.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;MiSiC, a general deep learning-based method for the high-throughput cell segmentation of complex bacterial communities&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Gisela Storz as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Zach Hensel (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted the following to help you prepare a revised submission.</p><p>Essential revisions:</p><p>All three reviewers recognize the significance and potential impact of the work and would like to see this work being implemented and disseminated to a wider bacterial cell biology field. However, the following essential revisions are required before the work could be considered for publication at <italic>eLife</italic>. These essential revisions were discussed and agreed upon among the reviewers and the reviewing editor during the consultation. In addition to these essential revisions, detailed comments from the three reviewers should also be addressed in the revision.</p><p>1. Please benchmark the performance of MiSiC against currently available segmentation methods using similar approaches such as Supersegger, DeepCell and DeLTA.</p><p>2. Please provide a detailed description of the working principle of MiSiC, and a ready-to-use workflow (or a handbook/guide) for users. These descriptions should include not only the essential steps, but also detailed parameters lists/ranges/considerations, such as cell density, size, pixel size, signal-to-noise ratio, and cell shape range etc. The goal of this essential revision is to ensure that the MiSiC tool can be easily disseminated and implemented by other non-technical-driven users in order to maximize the impact of the work.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>1. It is surprising to see that the authors have not applied the same algorithm to oval or round-shaped cells. Based on the principle of SIM, I do not see why MiSiC cannot be applied to those cells. Could the authors comment further on the limitations or show some results of round cells?</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The results applying U-Net to the SIM images are very interesting and I look forward to seeing if it will improve performance of the segmentation method (based on DeLTA) that we are using in our lab now; alone or input together with the unprocessed image.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>– The authors should emphasize that MiSiC is a 2D image analysis tool. It cannot handle 3D image data and it cannot handle 3D+time image data natively at the moment. This needs to be clearly stated.</p><p>– The introduction is rather short and does not provide sufficient context for most readers in my opinion. Particularly the 2nd paragraph is so short that the arguments are not clear. The second sentence criticizes machine learning techniques for requiring large amounts of training data. But the method presented in this paper is also a machine learning technique that requires a large amount of training data. I recommend that the authors significantly expand this paragraph to clarify and motivate their methodology.</p><p>– More generally, the introduction would benefit by placing the paper into the context of other image analysis tools for bacterial segmentation and colonies. There has been a lot of activity in image analysis for microbiology recently, and I think it would be helpful to readers to learn about this context.</p><p>– Results, paragraph 1 +2: Can the authors explain why the images need to be scaled so that the average cell size is set to 10 pixels? I guess this is based on the implicit assumption that there are sufficient intensity gradients on the 2x2 pixel scale used by the Hessian. As the SIM approach is a critical component of the MiSiC method, a clear explanation is needed here.</p><p>– A major advantage of MiSiC is that it uses the SIM images as training data for the CNN, which seems to result in a trained CNN model that can produce accurate segmentations for phase contrast, brightfield and fluorescence images. Is this true? Can the authors please very clearly state if this is true? The statements regarding this point in the manuscript are not completely unambiguous in my opinion. If true, this would be a major advance for bacterial image segmentation. Therefore, the authors should also state if the trained CNN model results in equal performance on all 3 imaging modalities. Or does a different CNN model need to be trained for each of the 3 imaging modalities with the same MiSiC workflow?</p><p>– Figure 2: In order for MiSiC to perform better on non-rod-shaped bacteria (filamentous bacteria, spirochetes, or cocci) – would the user need to generate new training data and re-train the model? I think this needs to be clarified.</p><p>– The authors supplemented their manually annotated data with synthetic data created by images of model rods with synthetic noise. Can the authors explain why this was done? Is the training with the manual annotation not sufficient? If the authors only used this synthetic data, does MiSiC also produce accurate segmentations, or is the real data needed?</p><p>– The semantic segmentation obtained by MiSiC (Figure 4) is impressive and works well. It is unclear whether this semantic segmentation also works in cases of strong intermixing between the cell types. Can the authors comment on that?</p><p>– Any development of a single cell segmentation method should include a graph of the Jaccard coefficient (and/or Dice index) as a function of the intersection over union, with error bars. The authors need to add such a graph to the manuscript so that authors can judge the quality of the segmentation.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;MiSiC, a general deep learning-based method for the high-throughput cell segmentation of complex bacterial communities&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Jie Xiao as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Gisela Storz as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Zach Hensel (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and wished the authors to provide the following before the work can be accepted for publication:</p><p>1. Update User Guide to address issues and miscellaneous bugs related to file installations, encoding, handling of multiple images and etc as specified in reviewers 1 and 2's comments.</p><p>2. Expand the introductory or Discussion section to include a more detailed comparison with existing algorithms with a focus on the strength and weakness of each method, as specified in Reviewers 1 and 3's comments.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>The revised manuscript by Panigrahi et al. addresses our major concerns. We are especially pleased to see the handbook created for the github page. Not only will the handbook be a valuable resource to users, but also the handbook can be updated as improvements and additions are made to the MiSiC GUI. Also, the new supplemental figure S1 is a helpful illustration of the two user-set parameters. We understand the difficulty in comparing MiSiC to different methods and appreciate the quantification of MiSiC's performance. Outlining the appropriate uses and limitations of MiSiC in the discussion is also appreciated. We hope the authors could further address the following concerns. The goal is to maximize the usability of MiSic for the community.</p><p>1. Cell density should be explicitly addressed in 1a of the handbook to match the heading. The new example of Caulobacter in Figure 3a is less dense than the images from the previous manuscript version, indicating that MiSiC can segment less dense cell populations. Since the majority of the images are still very dense clusters, it is still worth addressing density in the handbook if not in the manuscript text.</p><p>2. Suggesting specific preprocessing methods is useful, but the names alone might not be enough detail for the target MiSiC user. Either referencing FIJI plugins that accomplish the recommended processing or adding citations to the methods section would clarify these suggestions.</p><p>3. MiSiC is not expected to be absolutely accurate, and sometimes the binary mask output will require manual edits. For example, two cells recognized as one might need to be manually separated by pixels. If the GUI could incorporate the ability to manually modify the mask, that would tremendously increase the functionality of MiSiC. However, if that is too labor intensive, the post-processing section of the handbook should address how to make these manual adjustments to the output. This could also be mentioned in the discussion.</p><p>4. Could the authors expand the comparison between MiSiC with DeltaT, DeeptCell and Supersegger in the third paragraph of introduction be incorporating some of the language in the rebuttal letter? The goal is to give a bird's eye view of the current field so readers will have a clear assessment of which is good for what and understand MiSiC's uniqueness better.</p><p>5. There are some errors in GUI. They are not related to the segmentation algorithm, but confusing for users sometimes. For instance, the cell width measuring function is not always returning the right measurement. The way to break this function is to draw an extremely long line before actually tracing the short axis of any cell. Furthermore, MiSiC should be able to analyze all images belong to the same directory with just &quot;one click&quot;, in theory. However, this was not the case today when we fed the GUI with multiple images. New masks could not be generated unless previous/existing images and masks are all cleared from the workspace. We also realized that applying the same parameter settings based on only one image does not guarantee accurate segmentation for other images, even though these images belong to the same experiment/run. It would be great if the authors could fix these bugs to enhance user experience.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I think that the authors have sufficiently addressed issues raised in the reviews. The examples of preprocessing/parameter choices in the handbook will be very useful.</p><p>In my opinion, the availability workflows to generate synthetic data and train the models would strengthen the manuscript since some potential users will want to sacrifice general for specific performance. However, anyone with the expertise to do that also has the expertise to reinvent the wheel to some degree based on what is reported in the manuscript.</p><p>The only other issue I have now is installation instructions (MiSiCgui page) no longer work for me (Windows 10; following instructions for conda). I created a python environment as specified, installed the misic package, and tried to install the GUI. (1) I think that the &quot;use package&quot; instructions should be updated, because add_noise for example is now in extras.py; (2) The GUI pip install command raised an error regarding file encoding. I don't know whether the 2nd error is specific to my system and did not spend much time trying to diagnose it. Lastly, the screenshots on the github page are the old version (noise=0.0001 rather than 1).</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>Author's response to the general comment 1 (page 1+2 of the rebuttal letter): I now understand better how it can be difficult to benchmark MiSiC against the other segmentation software. I also appreciate that the authors now discuss these other tools in lines 73-84 of the manuscript. However, the essential points that make the other tools unsuitable for the analysis that was desired by the authors are not mentioned in the main text (only in the rebuttal letter). For me, as a potential user of all of these tools, and probably for anyone who reads such a paper, it is important to know the strengths and weaknesses of these tools and why the other tools are not suitable for the authors' application. Therefore, I recommend that the authors should expand further the relevant paragraph in the main text, to more clearly describe why the other tools are not suitable. This doesn't have to be overly critical of the other tools, but it would be helpful to the readers.</p><p>All other comments were addressed nicely by the authors in my opinion.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.65151.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>All three reviewers recognize the significance and potential impact of the work and would like to see this work being implemented and disseminated to a wider bacterial cell biology field. However, the following essential revisions are required before the work could be considered for publication at eLife. These essential revisions were discussed and agreed upon among the reviewers and the reviewing editor during the consultation. In addition to these essential revisions, detailed comments from the three reviewers should also be addressed in the revision.</p><p>1. Please benchmark the performance of MiSiC against currently available segmentation methods using similar approaches such as Supersegger, DeepCell and DeLTA.</p></disp-quote><p>These software packages are machine (or Deep) learning-based but they do not address similar needs and none was designed or proven to be able to perform semantic segmentation on cells with different shapes. DeLTA was designed for the tracking of <italic>E. coli</italic> cells over many generations constrained in a so-called microfluidics device (called the mother machine) where cells are aligned on a microfluidics channel. Thus, DeLTa was not shown to work for semantic segmentation and is likely too specialized for a broad application.</p><p>Supersegger is an alternative to MiSiC for the segmentation of bacteria in dense colonies. Before developing MiSiC, we actually evaluated Supersegger extensively to attempt segmentation of <italic>Myxococcus</italic> cells in dense environments. During this experience, we observed that to produce acceptable results with Supersegger we had to train the network for each individual field-of-view (FOV). This was a lengthy process that required manual segmentations to produce reliable ground truths for each FOV and therefore made Supersegger unusable for the segmentation of large experiments with tens of FOVs displaying highly heterogeneous cell densities, as this would have required the separate training of each FOV for each experiment. We have never attempted to segment both Myxococcus and <italic>E. coli</italic> cells with Supersegger as this software tool was not designed to handle several cell types with different shapes at once.</p><p>DeepCell is a general-purpose tool developed mainly for the segmentation of eukaryotic cells, not of bacteria. Nevertheless, we installed DeepCell and attempted to segment a typical field of view containing Myxococcus and <italic>E. coli</italic> cells using the most closely applicable network provided by DeepCell (i.e. NuclearSegmentation). Unfortunately, the network was unable to converge to a prediction. The most likely reason is that DeepCell was developed to detect a single kind of eukaryotic cell at a time, not to perform semantic segmentation on cells with different shapes. We did not test DelTa as its design was specific to detect cells in microfluidic channels.</p><p>Our conclusion from this limited testing is that it is unlikely that software packages that were designed for very different purposes, and that were not designed or shown to work for semantic segmentation, would perform efficiently. Of course, it is likely that intense network retraining and/or parameter tuning would improve performance of these algorithms, but even in that case this would only demonstrate that these methods are ill suited for the semantic segmentation of cells in dense environments at high throughputs.</p><p>A major asset of MiSiC is its simple use, efficiency under several image modalities, ability to identify multiple bacterial species and robustness to noise and intensity variations for complex dataset segmentation. For these reasons, we think that will be a preferable alternative to the aforementioned softwares for these applications. To make this clear and rather than conducting disputable analyses between softwares for this revision, we rigorously quantified MiSiC performance by comparing it to the ground truth using an established statistical method as recommended by the reviewers. These analyses now demonstrate that MiSiC performs well under various modalities and on numerous species. In addition, it also allows comparing performance for the various conditions and species and thus an estimate of its advantages and limitations. This allows the user to evaluate the use of MiSiC for a given application, a type of analysis which to our knowledge has not been provided by the other softwares. The manuscript is now deeply modified in many instances to discuss the points raised in this response.</p><disp-quote content-type="editor-comment"><p>2. Please provide a detailed description of the working principle of MiSiC, and a ready-to-use workflow (or a handbook/guide) for users. These descriptions should include not only the essential steps, but also detailed parameters lists/ranges/considerations, such as cell density, size, pixel size, signal-to-noise ratio, and cell shape range etc. The goal of this essential revision is to ensure that the MiSiC tool can be easily disseminated and implemented by other non-technical-driven users in order to maximize the impact of the work.</p></disp-quote><p>Thank you for this recommendation. We now provide a detailed handbook for the correct segmentation of bacterial cells under MiSiC, including advice for installation under Napari, pre-processing, segmentation and post-segmentation analyses.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>1. It is surprising to see that the authors have not applied the same algorithm to oval or round-shaped cells. Based on the principle of SIM, I do not see why MiSiC cannot be applied to those cells. Could the authors comment further on the limitations or show some results of round cells?</p></disp-quote><p>We now provide data showing that the quality of the segmentation decays as cell shape deviates from the rod shape (see Figure 3). This is clear for <italic>Bacillus</italic> filaments, which are well resolved but only partially septated and for <italic>Caulobacter</italic>, which is crescent shaped and segmented by MiSiC with an accuracy inferior to that of typical rod-shaped like <italic>E. coli</italic>, <italic>Myxococcus</italic> or <italic>Pseudomonas</italic>. As for round cells, the initial training data was such that round objects (see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>) would be excluded since it is frequent in images that there are spurious background objects that are also round. Thus, training the network to detect round cells is certainly feasible and will indeed make it useful to segment round bacteria, but it will also increase the spurious detections of background objects. For these reasons, we have not implemented round cells’ detection in this version.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>Note the presence of a round object (perhaps a round cell) in the PC image.</title><p>MiSiC excludes this object because it deviates too much from the training data set only to retain the rod shape objects.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65151-sa2-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>– The authors should emphasize that MiSiC is a 2D image analysis tool. It cannot handle 3D image data and it cannot handle 3D+time image data natively at the moment. This needs to be clearly stated.</p></disp-quote><p>This is correct, we now make this unambiguously clear in the introduction and refer to other approaches for 3D analyses.</p><disp-quote content-type="editor-comment"><p>– The introduction is rather short and does not provide sufficient context for most readers in my opinion. Particularly the 2nd paragraph is so short that the arguments are not clear. The second sentence criticizes machine learning techniques for requiring large amounts of training data. But the method presented in this paper is also a machine learning technique that requires a large amount of training data. I recommend that the authors significantly expand this paragraph to clarify and motivate their methodology.</p></disp-quote><p>Agreed. We significantly expanded this part to contextualize the study better in terms of existing approaches and needs that motivated the development of MiSiC;</p><disp-quote content-type="editor-comment"><p>– More generally, the introduction would benefit by placing the paper into the context of other image analysis tools for bacterial segmentation and colonies. There has been a lot of activity in image analysis for microbiology recently, and I think it would be helpful to readers to learn about this context.</p></disp-quote><p>Agreed. We now discuss recent image analysis tools that allow bacterial cell segmentation in 2D but also 3D communities with added references to Hartmann, 2021 and Zhang et al. 2020.</p><disp-quote content-type="editor-comment"><p>– Results, paragraph 1 +2: Can the authors explain why the images need to be scaled so that the average cell size is set to 10 pixels? I guess this is based on the implicit assumption that there are sufficient intensity gradients on the 2x2 pixel scale used by the Hessian. As the SIM approach is a critical component of the MiSiC method, a clear explanation is needed here.</p></disp-quote><p>This is now explained in the text. Briefly, the cell size must be set to pixels to approximately match the width of the artificial cells used to enrich the training data set.</p><disp-quote content-type="editor-comment"><p>– A major advantage of MiSiC is that it uses the SIM images as training data for the CNN, which seems to result in a trained CNN model that can produce accurate segmentations for phase contrast, brightfield and fluorescence images. Is this true? Can the authors please very clearly state if this is true? The statements regarding this point in the manuscript are not completely unambiguous in my opinion. If true, this would be a major advance for bacterial image segmentation. Therefore, the authors should also state if the trained CNN model results in equal performance on all 3 imaging modalities. Or does a different CNN model need to be trained for each of the 3 imaging modalities with the same MiSiC workflow?</p></disp-quote><p>This comment was also raised by reviewer 1. We now provide quantification of how “true” this is. The results now provided in a new Figure 2b show that a single CNN resolves bacterial cells in CP, Fluo and BF with efficiency comparable to the naked eye and almost similar accuracy. Although clearly images are more accurately segmented in the following order: Fluo, CP and BF.</p><disp-quote content-type="editor-comment"><p>– Figure 2: In order for MiSiC to perform better on non-rod-shaped bacteria (filamentous bacteria, spirochetes, or cocci) – would the user need to generate new training data and re-train the model? I think this needs to be clarified.</p></disp-quote><p>As shown in the new Figure 3b, with our general training method, the accuracy of segmentation declines as cell shape deviates from rod-shapes. Nevertheless the system still accurately segments curved cells such as <italic>Caulobacter</italic> cells. For filamentous cells, as shown in Figure 3—figure supplement 1, using post processing methods like watershed, it is possible to refine to cell masks that also detect cell separations within the filaments. As discussed in our response to reviewer 1, round cell detection will require fine tuning of the network with a small number of new annotated data. In this version we omitted that data to avoid the detection of spurious non-cell objects. Given that training uses synthetic data, it is quite straightforward to implement new training data in MiSiC based on the needs, which we now explain in text.</p><disp-quote content-type="editor-comment"><p>– The authors supplemented their manually annotated data with synthetic data created by images of model rods with synthetic noise. Can the authors explain why this was done? Is the training with the manual annotation not sufficient? If the authors only used this synthetic data, does MiSiC also produce accurate segmentations, or is the real data needed?</p></disp-quote><p>Unet-based segmentation methods generally require annotated datasets that sample the diversity of images that may be encountered in ‘real-life’ for segmentation. In our case, synthetic data was mainly used for the following reasons:</p><p>a) Generalization of segmentation model to unseen imaging modalities and bacterial shapes. The ability to use synthetic data circumvents the necessity of a well annotated dataset that spans over different experimental conditions (different imaging modalities, bacterial shapes, background noise and spurious objects ). Such a dataset is necessary for an end-to-end deep learning model (raw image input and segmented image output). The synthetic data also adds examples of various cell densities that may be encountered in unseen images.</p><p>b) Smooth cell shapes: Secondly, the synthetic masks help the decoder side of U-Net to fit a smooth cell shape to the segmented bacteria.</p><p>The “real annotated” data is nevertheless necessary: when only trained with synthetic data, the segmentation works but it is not as accurate as with additional ‘real images’. This is presumably due to the fact that the synthetic data was generated by randomly throwing cell-shaped objects onto an image. In this case, the intricate patterns created by cell-cell interactions in ‘real-life’ situations are not sampled. Hence, ‘real’ images, even from a single imaging modality, are required to ‘capture’ the patterns created by dense cell communities. An alternative could have been to use a synthetic cell model with cell-cell interactions, but this is an active field of research and beyond the scope of this work.</p><p>We now explain the benefits of this approach in the methods section.</p><disp-quote content-type="editor-comment"><p>– The semantic segmentation obtained by MiSiC (Figure 4) is impressive and works well. It is unclear whether this semantic segmentation also works in cases of strong intermixing between the cell types. Can the authors comment on that?</p></disp-quote><p>We believe that by “strong intermixing” the reviewer refers to the areas where <italic>Myxococcus</italic> cells actively penetrate the <italic>E. coli</italic> colony and interact very tightly with the <italic>E. coli</italic> cells as shown for example in zoom inset in Figure 5c. Our analysis in a Figure 5b and Figure 5d shows that indeed classification works well for a large majority of the population. There are nevertheless ambiguous classifications which are observed as a minor overlap between the two populations. These ambiguities are also apparent in the zoomed image Figure 5c where it is visible that a few classifications events are uncertain. This is inevitable in the tight interaction areas due to low contrast in these areas. The ambiguous cells can be easily eliminated from analysis by filtering with discriminating parameters as shown in Figure 5d. We now discuss these limitations in the text.</p><disp-quote content-type="editor-comment"><p>– Any development of a single cell segmentation method should include a graph of the Jaccard coefficient (and/or Dice index) as a function of the intersection over union, with error bars. The authors need to add such a graph to the manuscript so that authors can judge the quality of the segmentation.</p></disp-quote><p>See our answer above for this particular point, which we believe is a major addition in this revision.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>The revised manuscript by Panigrahi et al. addresses our major concerns. We are especially pleased to see the handbook created for the github page. Not only will the handbook be a valuable resource to users, but also the handbook can be updated as improvements and additions are made to the MiSiC GUI. Also, the new supplemental figure S1 is a helpful illustration of the two user-set parameters. We understand the difficulty in comparing MiSiC to different methods and appreciate the quantification of MiSiC's performance. Outlining the appropriate uses and limitations of MiSiC in the discussion is also appreciated. We hope the authors could further address the following concerns. The goal is to maximize the usability of MiSic for the community.</p><p>1. Cell density should be explicitly addressed in 1a of the handbook to match the heading. The new example of Caulobacter in Figure 3a is less dense than the images from the previous manuscript version, indicating that MiSiC can segment less dense cell populations. Since the majority of the images are still very dense clusters, it is still worth addressing density in the handbook if not in the manuscript text.</p></disp-quote><p>Thank you for the comment. The handbook now addresses how noise adjustment can help segment images with low cell densities:</p><p>“MiSiC can segment bacterial cells at both high and low density. Importantly, in low cell density images, the smoothening of background noise after scaling (see main text ) can lead to spurious cell detection, which can be resolved by adding synthetic noise (see section 1d to set up the noise parameter).”</p><disp-quote content-type="editor-comment"><p>2. Suggesting specific preprocessing methods is useful, but the names alone might not be enough detail for the target MiSiC user. Either referencing FIJI plugins that accomplish the recommended processing or adding citations to the methods section would clarify these suggestions.</p></disp-quote><p>The handbook now links these methods to the FIJI software.</p><disp-quote content-type="editor-comment"><p>3. MiSiC is not expected to be absolutely accurate, and sometimes the binary mask output will require manual edits. For example, two cells recognized as one might need to be manually separated by pixels. If the GUI could incorporate the ability to manually modify the mask, that would tremendously increase the functionality of MiSiC. However, if that is too labor intensive, the post-processing section of the handbook should address how to make these manual adjustments to the output. This could also be mentioned in the discussion.</p></disp-quote><p>Incorporating these tools to the GUI could be interesting in a future version, but it is not immediately necessary as other existing softwares provide these means to correct the MiSiC masks.</p><p>We now mention these methods in more details in the handbook:</p><p>“The MiSiC mask can occasionally contain predicted cells with imperfect separation or poorly detected septa. […] Manual correction is also feasible in that software using a very practical GUI and associated toolbox that allows editing the contours directly on the mask.”</p><p>As well as in the Discussion section lines 443-449:</p><p>“Along similar lines, non-cell or improperly separated cell objects an appear in the MiSiC masks and while some can be removed by the introduction of noise, an easy way to do it is to apply a post-processing filter using morphometric parameters to remove objects that are not bacteria. […] MicrobeJ and Oufti are especially useful from downstream analyses of the masks because they both allow cell tracking as well as determining protein localization at sub-diffraction resolution.”</p><disp-quote content-type="editor-comment"><p>4. Could the authors expand the comparison between MiSiC with DeltaT, DeeptCell and Supersegger in the third paragraph of introduction be incorporating some of the language in the rebuttal letter? The goal is to give a bird's eye view of the current field so readers will have a clear assessment of which is good for what and understand MiSiC's uniqueness better.</p></disp-quote><p>We have now introduced these what these softwares provide and explained their merits as well as their current limitations justifying the development of MiSiC. This new text is now in the introduction Lines 72-101.</p><p><bold>“</bold>Machine-learning based techniques are powerful alternatives to overcome the above limitations of traditional segmentation approaches. […] Inspired by these methods, we decided to develop MiSiC (Microbial Segmentation in dense Colonies), a general CNN-based tool to segment bacteria in single or multispecies 2D bacterial communities at very high throughput.”</p><disp-quote content-type="editor-comment"><p>5. There are some errors in GUI. They are not related to the segmentation algorithm, but confusing for users sometimes. For instance, the cell width measuring function is not always returning the right measurement. The way to break this function is to draw an extremely long line before actually tracing the short axis of any cell.</p></disp-quote><p>We have not been able to reproduce this bug, so we could not fix it.</p><p>Rare bugs like these may be environment-specific, we now wrote in the handbook that upon such problems users should feel free to contact us directly.</p><disp-quote content-type="editor-comment"><p>Furthermore, MiSiC should be able to analyze all images belong to the same directory with just &quot;one click&quot;, in theory. However, this was not the case today when we fed the GUI with multiple images. New masks could not be generated unless previous/existing images and masks are all cleared from the workspace.</p></disp-quote><p>For multiple images, we chose to provide a « process all » option that allows the segmentation of an image stack rather that multiple image files. This is especially convenient to process images of time lapse recordings. For multiple independent images the users just need to assemble them as an stack, for example under ImageJ/FIJI. We added a “Processing of multiple images” paragraph in the handbook to make this clear.</p><disp-quote content-type="editor-comment"><p>We also realized that applying the same parameter settings based on only one image does not guarantee accurate segmentation for other images, even though these images belong to the same experiment/run. It would be great if the authors could fix these bugs to enhance user experience.</p></disp-quote><p>Unfortunately, even when images belong to the same experiment they are not identical and setting up the parameters on a single image does not guarantee that all images will be segmented with similar accuracy. Nevertheless, we found that for an image stack from a time lapse or from images of a same experiment it is often possible to set “mean_width” and “noise” parameters that will be largely effective for the entire stack. For this several parameter combinations might need to be tested to find the best compromise. If the images vary a lot across a single experiment it might be a solution to split them in distinct related image sets for better prediction.</p><p>We added tips for the segmentation of image stacks in the “processing of multiple images” paragraph of the handbook to make this clear.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>I think that the authors have sufficiently addressed issues raised in the reviews. The examples of preprocessing/parameter choices in the handbook will be very useful.</p><p>In my opinion, the availability workflows to generate synthetic data and train the models would strengthen the manuscript since some potential users will want to sacrifice general for specific performance. However, anyone with the expertise to do that also has the expertise to reinvent the wheel to some degree based on what is reported in the manuscript.</p></disp-quote><p>We also think that anyone with the computational skills to train the CNN with a new data set will be able to generate this set without being directed to a specific workflow.</p><disp-quote content-type="editor-comment"><p>The only other issue I have now is installation instructions (MiSiCgui page) no longer work for me (Windows 10; following instructions for conda). I created a python environment as specified, installed the misic package, and tried to install the GUI.</p></disp-quote><p>To correct this problem, we have now removed all dependencies of MiSiCgui on the MiSiC package. However the installation of the MiSiC package in the same environment as MiSiCgui may raise an incompatibility. Thus, in some cases it will be necessary to remove the old environments of MiSiC and MiSiCgui and force pip install to re-install the package:</p><p>pip install <monospace>--upgrade</monospace> <monospace>--force-reinstall</monospace> git+https://github.com/leec13/MiSiCgui.git</p><p>We have added this tip to the handbook and the GitHub page.</p><disp-quote content-type="editor-comment"><p>(1) I think that the &quot;use package&quot; instructions should be updated, because add_noise for example is now in extras.py;</p></disp-quote><p>Correct, the &quot;use package » was updated to include the extras.py module in the imports that provide the add_noise function.</p><disp-quote content-type="editor-comment"><p>(2) The GUI pip install command raised an error regarding file encoding. I don't know whether the 2nd error is specific to my system and did not spend much time trying to diagnose it. Lastly, the screenshots on the github page are the old version (noise=0.0001 rather than 1).</p></disp-quote><p>Correct we fixed these issues.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>Author's response to the general comment 1 (page 1+2 of the rebuttal letter): I now understand better how it can be difficult to benchmark MiSiC against the other segmentation software. I also appreciate that the authors now discuss these other tools in lines 73-84 of the manuscript. However, the essential points that make the other tools unsuitable for the analysis that was desired by the authors are not mentioned in the main text (only in the rebuttal letter). For me, as a potential user of all of these tools, and probably for anyone who reads such a paper, it is important to know the strengths and weaknesses of these tools and why the other tools are not suitable for the authors' application. Therefore, I recommend that the authors should expand further the relevant paragraph in the main text, to more clearly describe why the other tools are not suitable. This doesn't have to be overly critical of the other tools, but it would be helpful to the readers.</p><p>All other comments were addressed nicely by the authors in my opinion.</p></disp-quote><p>Thank you for the positive feedback and final recommendation. See our answer to reviewer 1 to see how we modified the text to introduce the available tools.</p></body></sub-article></article>