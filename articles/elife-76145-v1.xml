<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">76145</article-id><article-id pub-id-type="doi">10.7554/eLife.76145</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural dynamics of causal inference in the macaque frontoparietal circuit</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-264539"><name><surname>Qi</surname><given-names>Guangyao</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0479-7320</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-264540"><name><surname>Fang</surname><given-names>Wen</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-264541"><name><surname>Li</surname><given-names>Shenghao</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-264542"><name><surname>Li</surname><given-names>Junru</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-52172"><name><surname>Wang</surname><given-names>Liping</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2038-0234</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Institute of Neuroscience</institution>, <institution>Chinese Academy of Sciences</institution>, <addr-line><named-content content-type="city">Shanghai</named-content></addr-line>, <country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-15643"><name><surname>Merchant</surname><given-names>Hugo</given-names></name><role>Reviewing editor</role><aff><institution>National Autonomous University of Mexico</institution>, <country>Mexico</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>wenfang@ion.ac.cn</email> (WF);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>Liping.wang@ion.ac.cn</email> (LW);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>24</day><month>10</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e76145</elocation-id><history><date date-type="received"><day>06</day><month>12</month><year>2021</year></date><date date-type="accepted"><day>23</day><month>10</month><year>2022</year></date></history><permissions><copyright-statement>Â© 2022, Qi et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Qi et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-76145-v1.pdf"/><abstract><p>Natural perception relies inherently on inferring causal structure in the environment. However, the neural mechanisms and functional circuits essential for representing and updating the hidden causal structure and corresponding sensory representations during multisensory processing are unknown. To address this, monkeys were trained to infer the probability of a potential common source from visual and proprioceptive signals based on their spatial disparity in a virtual reality system. The proprioceptive drift reported by monkeys demonstrated that they combined previous experience and current multisensory signals to estimate the hidden common source and subsequently updated the causal structure and sensory representation. Single-unit recordings in premotor and parietal cortices revealed that neural activity in the premotor cortex represents the core computation of causal inference, characterizing the estimation and update of the likelihood of integrating multiple sensory inputs at a trial-by-trial level. In response to signals from the premotor cortex, neural activity in the parietal cortex also represents the causal structure and further dynamically updates the sensory representation to maintain consistency with the causal inference structure. Thus, our results indicate how the premotor cortex integrates previous experience and sensory inputs to infer hidden variables and selectively updates sensory representations in the parietal cortex to support behavior. This dynamic loop of frontal-parietal interactions in the causal inference framework may provide the neural mechanism to answer long-standing questions regarding how neural circuits represent hidden structures for body awareness and agency.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>National Science and Technology Innovation 2030 Major Program</institution></institution-wrap></funding-source><award-id>2021ZD0204204</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Wen</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Shanghai Municipal Science and Technology Major Project</institution></institution-wrap></funding-source><award-id>2021SHZDZX</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution>Lingang Laboratory Grant</institution></institution-wrap></funding-source><award-id>LG202105-02-01</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution>Strategic Priority Research Programs</institution></institution-wrap></funding-source><award-id>XDB32070201</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Liping</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32100830</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Wen</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All animal procedures were approved by the Animal Care Committee of Center for Excellence in Brain Science and Intelligence Technology, Institute of Neuroscience, Chinese Academy of Sciences (Permit Number: CEBSIT-2020034).</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study are included in the manuscript and supporting file; Source Data files have been provided for Figures 1-6. Datasets Generated: Code and dataset have been uploaded to Dryad</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Qi G</collab><collab>Fang W</collab><collab>Li S</collab><collab>Li J</collab><collab>Wang L</collab></person-group><year iso-8601-date="2022">2022</year><source>Code and dataset for neural dynamics of causal inference in the macaque frontoparietal circuit</source><ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.5061/dryad.rr4xgxd9h">https://dx.doi.org/10.5061/dryad.rr4xgxd9h</ext-link><comment>Dryad Digital Repository, doi:10.5061/dryad.rr4xgxd9h</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-76145-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>