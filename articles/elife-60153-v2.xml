<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">60153</article-id><article-id pub-id-type="doi">10.7554/eLife.60153</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Dissociation of task engagement and arousal effects in auditory cortex and midbrain</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-194571"><name><surname>Saderi</surname><given-names>Daniela</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6109-0367</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-194572"><name><surname>Schwartz</surname><given-names>Zachary P</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-194573"><name><surname>Heller</surname><given-names>Charles R</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-194574"><name><surname>Pennington</surname><given-names>Jacob R</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-192021"><name><surname>David</surname><given-names>Stephen V</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4135-3104</contrib-id><email>davids@ohsu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Oregon Hearing Research Center, Oregon Health and Science University</institution><addr-line><named-content content-type="city">Portland</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Neuroscience Graduate Program, Oregon Health and Science University</institution><addr-line><named-content content-type="city">Portland</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Department of Mathematics and Statistics, Washington State University</institution><addr-line><named-content content-type="city">Vancouver</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>11</day><month>02</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e60153</elocation-id><history><date date-type="received" iso-8601-date="2020-06-17"><day>17</day><month>06</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-02-10"><day>10</day><month>02</month><year>2021</year></date></history><permissions><copyright-statement>Â© 2021, Saderi et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Saderi et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-60153-v2.pdf"/><abstract><p>Both generalized arousal and engagement in a specific task influence sensory neural processing. To isolate effects of these state variables in the auditory system, we recorded single-unit activity from primary auditory cortex (A1) and inferior colliculus (IC) of ferrets during a tone detection task, while monitoring arousal via changes in pupil size. We used a generalized linear model to assess the influence of task engagement and pupil size on sound-evoked activity. In both areas, these two variables affected independent neural populations. Pupil size effects were more prominent in IC, while pupil and task engagement effects were equally likely in A1. Task engagement was correlated with larger pupil; thus, some apparent effects of task engagement should in fact be attributed to fluctuations in pupil size. These results indicate a hierarchy of auditory processing, where generalized arousal enhances activity in midbrain, and effects specific to task engagement become more prominent in cortex.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>auditory</kwd><kwd>arousal</kwd><kwd>behavior</kwd><kwd>encoding</kwd><kwd>cortex</kwd><kwd>midbrain</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>F31 DC014888</award-id><principal-award-recipient><name><surname>Saderi</surname><given-names>Daniela</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 DC04950</award-id><principal-award-recipient><name><surname>David</surname><given-names>Stephen V</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 EB028155</award-id><principal-award-recipient><name><surname>David</surname><given-names>Stephen V</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>F31 DC016204</award-id><principal-award-recipient><name><surname>Schwartz</surname><given-names>Zachary P</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>GVPRS0015A2</award-id><principal-award-recipient><name><surname>Heller</surname><given-names>Charles R</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006668</institution-id><institution>Oregon Health and Science University</institution></institution-wrap></funding-source><award-id>Tartar Trust Fellowship</award-id><principal-award-recipient><name><surname>Saderi</surname><given-names>Daniela</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Data collected from two important auditory brain areas distinguish effects of generalized arousal and specific task engagement on neural sensory coding.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Hearing is a dynamic process that requires integration of the sensory evidence provided by physical attributes of sound with information about the behavioral context in which auditory perception occurs (<xref ref-type="bibr" rid="bib10">Bizley and Cohen, 2013</xref>; <xref ref-type="bibr" rid="bib21">Fritz et al., 2007</xref>). As sound information passes through the brain, coordinated activity in auditory areas extracts information necessary to guide behavior. Compared to passive listening, engaging in a task that requires auditory discrimination leads to changes in neural excitability, as well as in spectral and spatial selectivity (<xref ref-type="bibr" rid="bib15">Downer et al., 2015</xref>; <xref ref-type="bibr" rid="bib20">Fritz et al., 2005</xref>; <xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib39">Knudsen and Gentner, 2013</xref>; <xref ref-type="bibr" rid="bib41">Kuchibhotla et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Lee and Middlebrooks, 2011</xref>; <xref ref-type="bibr" rid="bib53">Otazu et al., 2009</xref>; <xref ref-type="bibr" rid="bib60">Ryan and Miller, 1977</xref>; <xref ref-type="bibr" rid="bib81">Yin et al., 2014</xref>). These changes are often attributed to the specific task demands, enhancing the representation of important sound features by selectively increasing or decreasing the activity across neural populations (<xref ref-type="bibr" rid="bib4">Bagur et al., 2018</xref>; <xref ref-type="bibr" rid="bib14">David et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Kuchibhotla et al., 2017</xref>). In some studies, changes have been reported to persist for several minutes after the active behavior, while in others, activity and tuning changes were observed to rapidly return to baseline (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>).</p><p>The substantial variability of effects across studies suggests that task engagement activates a constellation of non-auditory signals that comprise a complex internal state. Task-related changes in the activity of auditory neurons have been attributed to temporal expectation (<xref ref-type="bibr" rid="bib34">Jaramillo and Zador, 2011</xref>), reward associations (<xref ref-type="bibr" rid="bib7">Beaton and Miller, 1975</xref>; <xref ref-type="bibr" rid="bib14">David et al., 2012</xref>), self-generated sound (<xref ref-type="bibr" rid="bib17">Eliades and Wang, 2008</xref>), and non-sound related variables, such as motor planning (<xref ref-type="bibr" rid="bib9">Bizley et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Huang et al., 2019</xref>), motor activity (<xref ref-type="bibr" rid="bib63">Schneider et al., 2014</xref>; <xref ref-type="bibr" rid="bib83">Zhou et al., 2014</xref>), degree of engagement (<xref ref-type="bibr" rid="bib13">Carcea et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Knyazeva et al., 2020</xref>), and behavioral choice (<xref ref-type="bibr" rid="bib75">Tsunada et al., 2016</xref>). Even in the absence of explicit behavior, fluctuations in neural activity are observed throughout the forebrain, including primary sensory regions (<xref ref-type="bibr" rid="bib57">Ringach, 2009</xref>; <xref ref-type="bibr" rid="bib73">Stringer et al., 2019</xref>). This activity is related to cognitive states such as arousal and may also modulate sensitivity to sensory inputs (<xref ref-type="bibr" rid="bib23">Fu et al., 2014</xref>; <xref ref-type="bibr" rid="bib77">Wimmer et al., 2015</xref>). Therefore, attempting to interpret changes in neuronal activity solely in light of a single binary variable, such as being engaged in a task or not, will lead to an incomplete and even incorrect understanding of how sensory information is processed.</p><p>A straightforward way to monitor some task-independent changes in behavioral state is by measuring pupil size (<xref ref-type="bibr" rid="bib36">Kahneman and Beatty, 1966</xref>; <xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib82">Zekveld et al., 2018</xref>). In humans, luminance independence changes in pupil size have been shown to correlate with mental effort (<xref ref-type="bibr" rid="bib8">Beatty, 1982</xref>; <xref ref-type="bibr" rid="bib79">Winn et al., 2015</xref>), changes in states of arousal (<xref ref-type="bibr" rid="bib36">Kahneman and Beatty, 1966</xref>), aspects of decision-making (<xref ref-type="bibr" rid="bib24">Gilzenrat et al., 2010</xref>), and task performance (<xref ref-type="bibr" rid="bib64">Schriver et al., 2018</xref>). In animals, fluctuations in pupil size closely track locomotion and neural activity throughout the mouse forebrain (<xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">Stringer et al., 2019</xref>). Pupil size also tracks the degree of neural synchronization observed in local field potentials, which is commonly used to measure arousal (<xref ref-type="bibr" rid="bib65">Schwartz et al., 2020</xref>; <xref ref-type="bibr" rid="bib76">Vinck et al., 2015</xref>). Thus, while this single variable is unlikely to completely characterize such a complex phenomenon as arousal, pupil provides a window into a global brain state that is activated during demanding behaviors.</p><p>The degree to which pupil size co-varies with task engagement, and whether these variables account for independent changes in neural activity, remains to be determined. To study the interaction of task engagement and pupil size on auditory neural coding, we recorded extracellular spiking activity and pupil size of ferrets during an auditory task and during passive presentation of task stimuli. Single- and multiunit activity was recorded from the primary auditory cortex (A1) and midbrain inferior colliculus (IC). We used a generalized linear model to quantify the unique contributions of task engagement and pupil size to neural activity. Using this approach, we found that independent subpopulations of neurons were modulated uniquely by task or by pupil size, suggesting that these effects are mediated by distinct inputs. Our analysis also revealed that in many neurons, pupil size could account for variability in firing rate that might otherwise be attributed to task engagement. Thus, some previously reported effects of task engagement may in fact be explained by changes in pupil-indexed arousal. In addition, the relative effects of task engagement and pupil size varied between cortex and midbrain. Pupil-related changes occurred in both areas, but task engagement effects were more prominent in A1. This work highlights the value of accounting for multiple state variables in studies of sensory coding (<xref ref-type="bibr" rid="bib50">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib73">Stringer et al., 2019</xref>), both in identifying the source of task-related effects and inÂ locating where in the sensory processing hierarchy they emerge.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Changes in pupil size track task engagement</title><p>To study interactions between pupil-indexed arousal and task engagement, we trained four adult ferrets on a go/no-go auditory detection task (<xref ref-type="bibr" rid="bib14">David et al., 2012</xref>; <xref ref-type="bibr" rid="bib80">Yin et al., 2010</xref>). Animals reported the presence of a target tone following a random number of broadband noise reference stimuli (<xref ref-type="fig" rid="fig1">Figure 1A,B</xref>). They were required to withhold licking a water spout during the reference sounds and were given liquid reward for licking during the target window (0.1â1.5 s after target onset). Targets were pure tones, either presented alone (tone versus noise discrimination, ferret L) or embedded in reference stimuli (tone-in-noise detection, ferrets R, B, and T). After training, all animals performed consistently above chance (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Pupil size correlates with task engagement.</title><p>(<bold>A</bold>) Schematic of behavioral setup, including free-field speaker for sound presentation, piezo spout to register licks and deliver reward, and infrared video camera for pupillometry. (<bold>B</bold>) Spectrogram of example trial (top) and task structure (bottom). False alarmsÂ (FAs) before the target window were punished with a timeout and hits resulted in a liquid reward. (<bold>C</bold>) Swarm plot showing behavioral performance (hit rate or FAÂ rate) for each animal. Each point corresponds to a behavioral block. Red lines indicate mean and standard error of the mean (SEM) of the sensitivity (<italic>d</italic>') for each animal. All animals performed above chance on average (<italic>d</italic>âÂ &gt;Â 1). (<bold>D</bold>) Mean timeÂ course of pupil size aligned to trial onset for active and passive blocks during neurophysiological recordings, averaged across all animals and recording days, normalized to maximum size per day. Shading indicates SEM. Gray dashed lines indicate sound onset. (<bold>E</bold>) Average timeÂ course of change in pupil size, normalized to 0.35 s pre-trial period for active and passive behavioral blocks. Shading indicates SEM. Gray dashed lines indicate sound onset. (<bold>F</bold>) Scatter plot compares pre-trial pupil size and mean change per trial (3 s post-onset window). Each dot represents a behavioral block. Passive and active blocks within the same session are connected by a line.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 1.</label><caption><title>Pupil size correlates with task engagement and performance.</title><p>(<bold>A</bold>) Histogram of pupil size during passive and active blocks, averaged across all animals and physiological recording sessions (<italic>n</italic>Â =Â 35 sessions). Pupil size is normalized to maximum per session. (<bold>B</bold>) Mean timeÂ course of pupil size during behavior, grouped according to trial outcome (hit, miss, or false alarmÂ [FA]), averaged across sessions. Mean pupil size was not significantly different for FA and hit trials (<italic>pÂ </italic>=Â 0.220, hierarchical bootstrap), but it was smaller during miss trials (<italic>pÂ </italic>=Â 0.0183). Shading indicates SEM. (<bold>C</bold>) Trial timeÂ course of average pupil change during active behavioral blocks and grouped according to performance, plotted as in <bold>B</bold>. Evoked pupil size did not differ between any of the trial outcome conditions (<italic>pÂ </italic>&gt;Â 0.05, hierarchical bootstrap).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig1-figsupp1-v2.tif"/></fig></fig-group><p>To track and record changes in pupil size, an infrared video camera was used to image the eye contralateral to the speaker emitting auditory stimuli (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Constant luminance was maintained throughout the experiment so that fluctuations in pupil size reflected only changes in internal state (<xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib65">Schwartz et al., 2020</xref>). Pupil was recorded continuously as animals passively listened to the task stimuli and actively performed the task. The distribution of pupil size differed between passive and active conditions (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1A</xref>). Mean pupil size (measured by the major axis diameter) was consistently larger during the active condition (<italic>n</italic>Â =Â 35 sites total, ferret L: <italic>n</italic>Â =Â 13, B: <italic>n</italic>Â =Â 5, R: <italic>n</italic>Â =Â 16, T: <italic>n</italic>Â =Â 1, <italic>p</italic>Â =Â 0.0133, hierarchical bootstrap, <xref ref-type="fig" rid="fig1">Figure 1D</xref>). Within active blocks, pupil size also varied with task performance. Average pupil size was similar for false alarmÂ (FA) and hit trials, but it was smaller during miss trials, more closely resembling passive trials (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1B</xref>). In addition, the short-term dynamics of pupil depended strongly on task condition. During behavior, trial onset evoked a rapid increase in pupil size, which was consistently larger than any evoked change during the passive condition (<italic>pÂ </italic>=Â 4.00Â xÂ 10<sup>â6</sup>, hierarchical bootstrap, <xref ref-type="fig" rid="fig1">Figure 1E,F</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1C</xref>). Thus, pupil size tracked slow changes in task-engagement (active versus passive blocks) as well as more rapid changes in trial-by-trial performance during the active condition.</p></sec><sec id="s2-2"><title>Distinct task engagement and pupil size effects in A1 and IC neurons</title><p>We recorded extracellular spiking activity from A1 (<italic>n</italic>Â =Â 129 units total, ferret B: six sites/88 units, R: one site/13 units, T: one site/28 units) and IC (<italic>n</italic>Â =Â 66 units total, ferret B: four sites/7 units, L: 13 sites/46 units, R: 10 sites/13 units) of ferrets, while they switched between active engagement and passive listening. In the IC, we recorded from central (ICC, <italic>n</italic>Â =Â 18 units) and non-central regions (NCIC, <italic>n</italic>Â =Â 48 units), distinguished by their functional topography (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). Results from the IC are presented jointly between the two sub-regions, unless otherwise specified.</p><p>To study how behavior state modulated auditory neural activity over time, we recorded activity in the same units over multiple passive and active blocks and recorded pupil size throughout each experiment as a measure of the animalâs state of arousal. For analysis, the peristimulus time histogram (PSTH) response to the reference stimuli was averaged across passive and correct (hit) active trials, and data from target periods were excluded. On hit trials, animals did not lick during the reference stimuli; thus this approach reduced the possibility that lick-related motor signals confounded our results (<xref ref-type="bibr" rid="bib12">Brosch et al., 2005</xref>; <xref ref-type="bibr" rid="bib63">Schneider et al., 2014</xref>; <xref ref-type="bibr" rid="bib73">Stringer et al., 2019</xref>).</p><p>For many units, activity appeared to be modulated by changes in task engagement, as would be expected from previous behavioral studies (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib41">Kuchibhotla et al., 2017</xref>; <xref ref-type="bibr" rid="bib52">Niwa et al., 2012</xref>; <xref ref-type="bibr" rid="bib53">Otazu et al., 2009</xref>). During active behavior, responses to the noise stimuli either increased or decreased, and then returned to their baseline passive state during subsequent passive periods (<xref ref-type="fig" rid="fig2">Figure 2A,B</xref>). For other units, however, no consistent change in activity was observed between active and passive conditions. In these cases, firing rate could change between behavioral blocks, but the effect was not consistent across engagement conditions (<xref ref-type="fig" rid="fig2">Figure 2D,E</xref>). Thus, despite our controls for sound acoustics and motor activity, the firing rates of some units varied over time in a way that did not appear to be related to task engagement.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Simultaneously recorded units showing task versus pupil-related changes.</title><p>(<bold>A</bold>) Firing rate (gray) of one unit in primary auditory cortex (A1) and time-aligned pupil size (green) during reference stimuli over one entireÂ experiment (total recording timeÂ ~1 hr, inter-trial and target periods removed). Purple shading highlights active blocks. Dashed lines delineate boundaries between half of each behavioral block. (<bold>B</bold>) Peri-stimulus time histogram (PSTH) responses to reference noise averaged separately across the first and second half of each behavior block (black). Dashed gray lines are responses predicted by the null model, <italic>i.e</italic>., the PSTH averaged across all blocks. Model prediction accuracy is indicated by fraction variance explained (<italic>r</italic><sup>2</sup>). (<bold>C</bold>) Top: PSTH response for the example unit averaged across passive and active blocks (left, dark and light purple, solid lines) and averaged across large and small pupil size trials (right, dark and light green, solid lines). Predictions of the task-only model are overlaid (same color pattern, dashed lines). Middle: Active/passive and large/small PSTH responses plotted with predictions by the pupil-only model, which only accounts for pupil-related changes. Bottom: Active/passive and large/small PSTH responses plotted with predictions by the full model, accounting for both task and pupil-related changes. (<bold>D</bold>) Firing rate and pupillometry for a second A1 unit, recorded simultaneously to the first example. (<bold>EÂ andÂ F</bold>) PSTH responses for the second unit, plotted as in <bold>BÂ andÂ C</bold>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig2-v2.tif"/></fig><p>We wondered if changes in activity that could not be attributed to task engagement could instead be explained by fluctuations in pupil-indexed arousal (<xref ref-type="bibr" rid="bib45">Lin et al., 2019</xref>; <xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib65">Schwartz et al., 2020</xref>). A simple way to investigate if pupil size predicts changes in neural firing rate is to divide all trials (pooled across active and passive) into two groups, based on the mean pupil size, and compute a separate PSTH for each group (<xref ref-type="fig" rid="fig2">Figure 2C,F</xref>). In the example A1 units, activity was often enhanced when pupil was larger than median (large versus small pupil PSTH, <xref ref-type="fig" rid="fig2">Figure 2C,F</xref>), indicating that pupil size was positively correlated with firing rate.</p><p>Because changes in pupil size were correlated with transitions between active and passive blocks (<xref ref-type="fig" rid="fig1">Figure 1E</xref>), we could not dissociate the effects of task engagement and pupil size using just the raw PSTH. Therefore, to test our hypothesis that pupil size accounted for changes in neural activity following task engagement, we fit a generalized linear model (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) in which the response to each presentation of the reference stimuli was modulated by task engagement and pupil size. Each of these variables could additively modulate the baseline (mean) firing rate or multiplicatively modulate response gain. Task engagement was modeled as a discrete regressor (active or passive) and pupil size as a continuous regressor. This approach allowed us to dissociate effects of pupil size and task engagement on firing rate.</p><p>Model performance was measured by the fraction variance explained (squared correlation coefficient, <italic>r</italic><sup>2</sup>) between the predicted and actual single-trial spike rates, using nested cross-validation. To test for significant contributions of each regressor, we introduced these variables stepwise (<xref ref-type="bibr" rid="bib22">Fritz et al., 2010</xref>; <xref ref-type="bibr" rid="bib50">Musall et al., 2019</xref>). The full model included both task engagement and pupil size variables. We compared performance of the full model to the performance of a state-independent model, for which both task and pupil variables were shuffled in time (null model), and of two partial models, which accounted for effects of a single state variable while shuffling the values of the other variable in time (task- or pupil partial models).</p><p>The regression analysis revealed substantial variability in effects of task engagement and pupil size on auditory responses. For one example A1 unit, the modulation of firing rate between active and passive blocks was almost completely accounted for by the task variable, with little contribution of pupil size (<xref ref-type="fig" rid="fig2">Figure 2AâC</xref>). When we incorporated the task variable, predictions significantly improved with respect to the state-independent null model (null model, <italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.12; task partial model, <italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.30; jackknifed <italic>t</italic>-test, <italic>pÂ </italic>&lt;Â 0.05; <xref ref-type="fig" rid="fig2">Figure 2C</xref>, top). Pupil size was also able to account for some changes in firing rate (pupil partial model, <italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.21; <xref ref-type="fig" rid="fig2">Figure 2C</xref>, middle), but the full model incorporating both task engagement and pupil size showed no additional improvement over the task partial model (<italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.30, <italic>pÂ </italic>&gt;Â 0.05; <xref ref-type="fig" rid="fig2">Figure 2C</xref>, bottom). Thus, all behavior-dependent changes for this unit were accounted for by task engagement. The apparent pupil-related effects were in fact explained by correlations between pupil size and task engagement.</p><p>Conversely, for other units, changes in firing rate were uniquely accounted for by pupil size. For a second example A1 unit (<xref ref-type="fig" rid="fig2">Figure 2DâF</xref>), the task partial model (<italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.39) indicated a small improvement over the null model (<italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.40, <italic>pÂ </italic>&gt;Â 0.05, jackknifed <italic>t</italic>-test). However, the pupil partial model showed a significant improvement over the null model, and it was able to account for changes in the PSTH between passive and active conditions (<italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.51, <italic>pÂ </italic>&lt;Â 0.05, <xref ref-type="fig" rid="fig2">Figure 2F</xref>, middle). The full model showed no additional improvement over the pupil partial model (<italic>r</italic><sup>2</sup><italic>Â =</italic>Â 0.53, <italic>pÂ </italic>&gt;Â 0.05; <xref ref-type="fig" rid="fig2">Figure 2F</xref>, bottom). Thus, we found evidence for A1 units whose activity could be modulated either by task engagement or by pupil size.</p><p>Next, we investigated the prevalence of task- and pupil-related modulation across the population of A1 and IC units. To quantify the relative contribution of each variable to model performance, we compared the variance in single-trial spike rate explained by each of the four models (<italic>r</italic><sup>2</sup>). Across the entire dataÂ set, 66/129 (51%) A1 units and 37/66 (56%) IC units showed a significant increase in <italic>r</italic><sup>2</sup> for the full model over the null model, indicating an effect of either task engagement or pupil size (<italic>pÂ </italic>&lt;Â 0.05, jackknife <italic>t</italic>-test; <xref ref-type="fig" rid="fig3">Figure 3A</xref>). By computing the difference between the cross-validated <italic>r</italic><sup>2</sup> for the full model and for the two partial models separately, we determined the variance that could be uniquely explained by either pupil size or task engagement in each unit. This produced four categories of state-modulated neurons (<xref ref-type="fig" rid="fig3">Figure 3A</xref>): units for which both task and pupil uniquely contributed to the modulation (black); units for which only one variable, task (purple, example unit in <xref ref-type="fig" rid="fig2">Figure 2A</xref>) or pupil (green, example unit in <xref ref-type="fig" rid="fig2">Figure 2D</xref>), contributed uniquely; and units for which changes in activity could not be uniquely attributed to either task or pupil (dark gray).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Task and pupil-related modulation of firing rates in primaryÂ auditory cortex (A1) and inferior colliculusÂ (IC).</title><p>(<bold>A</bold>) Doughnut plots indicate number of units significantly modulated by task engagement, pupil size, or both in A1 (left) and IC (right, <italic>pÂ </italic>&lt;Â 0.05, jackknifed <italic>t</italic>-test). Total number of recorded units reported in the center. Purple and green: significant unique modulation by task or pupil, respectively. Black: unique modulation by both task and pupil. Dark gray: ambiguous task or pupil modulation. Light gray: no significant change in accuracy between full and null models. (<bold>B</bold>) Scatter plot of variance explained (<italic>r</italic><sup>2</sup>) in single-trial activity by full model versus null model. Each symbol represents a unit in AC (left) or IC (right). Colors as in <bold>A</bold>. (<bold>C</bold>) Unique variance explained by pupil size (horizontal axis) plotted against unique variance explained by task engagement (vertical axis) for each unit. Stars correspond to examples in <xref ref-type="fig" rid="fig2">Figure 2A</xref> (purple) and D (green).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>Unique effects of task and pupil on neural activity did not differ across single units (SU) and multiunits (MU).</title><p>(<bold>A</bold>) Unique variance explained by task separated for units categorized as MU (dark blue circles) and SU (light blue circles) inÂ primary auditory cortex (A1) and inferior colliculusÂ (IC). Median variance explained was not different between unit categories in either area (A1, SU median: 0.011, MU median: 0.010, <italic>pÂ </italic>=Â 0.374; IC, SU median: 0.016, MU median: 0.021, <italic>pÂ </italic>=Â 0.410, hierarchical bootstrap). (<bold>B</bold>) Data for unique variance explained by pupil, plotted as in <bold>A</bold>. Again, median effects were not different between unit categories in either area (A1, SU median: 0.006, MU median: 0.006, <italic>pÂ </italic>=Â 0.453; IC, SU median: 0.015, MU median: 0.018, <italic>pÂ </italic>=Â 0.583, hierarchical bootstrap).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig3-figsupp1-v2.tif"/></fig></fig-group><p>A comparison of variance explained across the entire dataÂ set shows consistent improvement by the full model over the null model in both A1 (mean <italic>r</italic><sup>2</sup> null: 0.282, full: 0.340, <italic>p</italic>Â &lt;Â 10<sup>â5</sup>, hierarchical bootstrap test, <xref ref-type="bibr" rid="bib61">Saravanan et al., 2020</xref>) and IC (mean <italic>r</italic><sup>2</sup> null: 0.290, full: 0.399, <italic>p</italic>Â &lt;Â 10<sup>â5</sup>, <xref ref-type="fig" rid="fig3">Figure 3B</xref>). Although the proportion of units with any significant state-related modulation was comparable between A1 and IC, only about a quarter of those A1 units showed unique pupil-dependent modulation (15/66), compared to about a half for IC (20/37). The average variance uniquely explained by each state variable also differed between areas. In A1, the variance explained by task (mean <italic>r</italic><sup>2</sup> task-unique: 0.017) was significantly greater than variance explained by pupil (mean <italic>r</italic><sup>2</sup> pupil-unique: 0.007, <italic>p</italic> = 0.0335, hierarchical bootstrap, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). In IC, the variance explained was not significantly different between task and pupil (mean <italic>r</italic><sup>2</sup> task-unique: 0.016, mean <italic>r</italic><sup>2</sup> pupil-unique: 0.019, <italic>p</italic> = 0.769). These effects were not significantly different between single- and multiunit data in either area (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>). Together, these results suggest that in A1, both the magnitude and prevalence of modulation by task engagement are more pronounced than by pupil size. In IC, modulationÂ is equal between the two state variables.</p><p>The analysis above treated task engagement as a discrete, binary variable, switching between active and passive states. However, behavioral performance, measured by <italic>d</italic>â, varied substantially between animals and behavior blocks (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We reasoned that performance represents a more graded measure of task engagement and thus may explain variability in task-related changes across experiments. Indeed, we found a significant correlation between <italic>d</italic>â and the unique variance explained by task in A1 (<italic>r</italic><sup>2</sup> task-unique; <italic>r</italic>Â =Â 0.303, <italic>pÂ </italic>=Â 0. 007, hierarchical bootstrap; <xref ref-type="fig" rid="fig4">Figure 4A</xref>, left). The same relationship was not observed in IC (<italic>r</italic>Â =Â 0.069, <italic>pÂ </italic>=Â 0.318; <xref ref-type="fig" rid="fig4">Figure 4A</xref>, right), nor was there a relationship between <italic>d</italic>â and unique variance explained by pupil in either area (<italic>r</italic><sup>2</sup> pupil-unique; A1: <italic>r</italic>Â =Â 0.113, <italic>pÂ </italic>=Â 0.158; IC: <italic>r</italic>Â =Â â0.017, <italic>pÂ </italic>=Â 0.552, <xref ref-type="fig" rid="fig4">Figure 4B</xref>). Thus, in A1, effects of task engagement cannot be described by a binary variable, even after dissociating effects of pupil. Instead, effects of task engagement are comprised of at least one process that varies continuously between more and less accurate behavior.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Task- and pupil-related modulation of firing rate as a function of behavioral performance inÂ primary auditory cortex (A1) and inferior colliculusÂ (IC).</title><p>(<bold>A</bold>) Scatter plot of unique variance explained by task plotted against behavioral sensitivity (<italic>d</italic>â) in A1 (left) and IC (right). Each point represents a unit/target pair. When a unit was recorded across blocks with different target conditions, <italic>dâ</italic>Â and variance explained were measured separately in each block. Different colors refer to different animal subjects. Points with the same <italic>d</italic>â align on the horizontal axis because they belong to experiments in which multiple units were recorded at the same time using an array (0.015 standard deviation jitter added to <italic>d</italic>' to facilitate visualization). Regression analysis shows a significant correlation between unique variance explained by task and performance in A1 (<italic>n</italic>Â =Â 132 unit/target pairs, <italic>r</italic>Â =Â 0.303, *<italic>pÂ </italic>=Â 0.007, hierarchical bootstrap) but not in IC (<italic>n</italic>Â =Â 85 unit/target pairs, <italic>r</italic>Â =Â 0.069, <italic>pÂ </italic>=Â 0.318). (<bold>B</bold>) Scatter plot of unique variance explained by pupil plotted against performance for each unit in A1 (left) and IC (right) as in <bold>A</bold>. Regression analysis shows no significant correlation between unique variance explained by pupil and performance in either A1 (<italic>r</italic>Â =Â 0.113, <italic>pÂ </italic>=Â 0.158) or IC (<italic>r</italic>Â =Â â0.17, <italic>pÂ </italic>=Â 0.552).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 1.</label><caption><title>Variability of neural behavior state effects and task performance across animals.</title><p>(<bold>A</bold>) Unique variance explained by task engagement (<italic>r</italic><sup>2</sup> task-unique) inÂ primary auditory cortex (A1; left) and inferior colliculusÂ (IC; right) for each unit, grouped by animal. Mean variance explained did not differ significantly between animals in either area (A1 animal R: 0.025, T: 0.023, B: 0.017, <italic>F</italic>Â =Â 0.606, <italic>p</italic>Â =Â 0.547; IC animal R: 0.028, B: 0.021, L: 0.022, <italic>F</italic>Â =Â 0.221, <italic>p</italic>Â =Â 0.803, ANOVA). (<bold>B</bold>) Task performance (<italic>d</italic>â) for each behavior block, grouped by animal and recordings in A1 (left) and IC (right). Mean <italic>d</italic>â differed between animals in both groups of experiments (A1 animal R: 1.55, T: 1.35, B: 0.93, <italic>F</italic>Â =Â 15.8, <italic>p</italic>Â &lt;Â 0.0001; IC animal R: 1.52, B: 1.61, L: 2.48, <italic>F</italic>Â =Â 23.9, <italic>pÂ </italic>&lt;Â 0.0001, ANOVA). Interactions between animal and <italic>d</italic>â on neural behavior state effects are reported in <xref ref-type="fig" rid="fig4">Figure 4</xref> in the main text. (<bold>C</bold>) Unique variance explained by changes in pupil size (<italic>r</italic><sup>2</sup> pupil-unique), plotted as in <bold>A</bold>. Mean variance explained differed between animals in A1, but not in IC (A1 animal R: 0.011, T: 0.030, B: 0.012, <italic>F</italic>Â =Â 10.9, <italic>pÂ </italic>&lt;Â 0.0001; IC animal R: 0.018, B: 0.038, L: 0.022, <italic>F</italic>Â =Â 1.82, <italic>pÂ </italic>=Â 0.170, ANOVA). (<bold>D</bold>) Scatter plots show <italic>r</italic><sup>2</sup> pupil-unique as a function of variance of pupil size during each experiment. This relationship is significant in both A1 (left, <italic>r</italic>Â =Â 0.341, <italic>p</italic>Â <italic>â¤Â </italic>10<sup>â5</sup>, hierarchical bootstrap) and IC (right, <italic>r</italic>Â =Â 0.409, <italic>pÂ </italic>=Â 0.02). Dashed line shows regression fit. Multivariate regression shows that <italic>r</italic><sup>2</sup> pupil-unique depends significantly on both animal and pupil variance but not on <italic>d</italic>â in A1 (animal: <italic>F</italic>Â =Â 11.5, <italic>pÂ </italic>=Â 0.000021; pupil variance: <italic>F</italic>Â =Â 11.4, <italic>pÂ </italic>=Â 0.00092; <italic>d</italic>â: <italic>F</italic>Â =Â 0.145, <italic>p</italic>Â =Â 0.703, ANOVA). In IC, <italic>r</italic><sup>2</sup> pupil-unique depends significantly only on pupil variance (animal: <italic>F</italic>Â =Â 2.23, <italic>pÂ </italic>=Â 0.116; pupil variance: <italic>F</italic>Â =Â 16.2, <italic>pÂ </italic>=Â 0.00016; <italic>d</italic>â: <italic>F</italic>Â =Â 0.032, <italic>pÂ </italic>=Â 0.86, ANOVA).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig4-figsupp1-v2.tif"/></fig></fig-group><p>We also observed that both <italic>d</italic>â and task engagement effects in A1 differed between animals (<xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>). We wondered if the differences in neural modulation could be fully explained by behavioral performance or if they reflected additional between-animal differences. To answer this question, we performed a multiple regression with both <italic>d</italic>â and animal identity as independent variables. This analysis revealed that in A1 <italic>d</italic>â could fully explain the differences in modulation for task engagement (<italic>d</italic>â: <italic>F</italic>Â =Â 16.0, <italic>pÂ </italic>=Â 0.000093; animal: <italic>F</italic>Â =Â 0.66, <italic>pÂ </italic>=Â 0.52). Neither <italic>d</italic>â or animal significantly predicted task engagement effects in IC (<italic>d</italic>â: <italic>F</italic>Â =Â 1.11, <italic>pÂ </italic>=Â 0.29; animal: <italic>F</italic>Â =Â 0.22, <italic>p</italic>Â =Â 0.80). A similar analysis of pupil-related effects revealed that <italic>r</italic><sup>2</sup> pupil-unique did not depend on <italic>d</italic>â, although it did depend on the amount of pupil variability within an experiment (<xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>). Thus, differences in task engagement effects between animals could be explained by differences in the accuracy with which they performed the task.</p></sec><sec id="s2-3"><title>Pupil size accounts for apparent task engagement effects in both A1 and IC</title><p>So far, we have shown that neurons in A1 and IC show state-dependent modulation of activity that can be explained variably by task engagement and/or pupil size. The observation that pupil size is correlated with task engagement (<xref ref-type="fig" rid="fig1">Figure 1</xref>) suggests previous characterizations of task-related plasticity that did not measure pupil might have attributed changes in neural activity to task engagement when they could, in fact, be better explained by pupil size (<xref ref-type="bibr" rid="bib15">Downer et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib39">Knudsen and Gentner, 2013</xref>; <xref ref-type="bibr" rid="bib41">Kuchibhotla et al., 2017</xref>; <xref ref-type="bibr" rid="bib44">Lee and Middlebrooks, 2011</xref>; <xref ref-type="bibr" rid="bib53">Otazu et al., 2009</xref>; <xref ref-type="bibr" rid="bib60">Ryan and Miller, 1977</xref>; <xref ref-type="bibr" rid="bib81">Yin et al., 2014</xref>). Therefore, we asked to what extent pupil-related modulation could explain changes in activity between active and passive blocks that would otherwise be attributed to task engagement alone.</p><p>To quantify the magnitude and sign of the modulation by task engagement, we used a modulation index (<italic>MI<sub>AP</sub></italic>), which measured the fraction change in mean predicted firing rate between active and passive conditions (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>,Â <xref ref-type="bibr" rid="bib53">Otazu et al., 2009</xref>; <xref ref-type="bibr" rid="bib66">Schwartz and David, 2018</xref>). In previous work, <italic>MI</italic> was measured directly from differences in the raw firing rate. However, pupil size was correlated with task engagement, and both could contribute to changes in firing rate. To tease apart their respective contributions, we used logic similar to the calculation of unique variance explained (above, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). To measure task-related modulation while ignoring possible effects of pupil size, <italic>MI</italic> was computed from predictions of the task only model (<italic>MI<sub>AP</sub> task-only</italic>). To account for effects of both task engagement and pupil size, <italic>MI</italic> was computed from predictions by the full model (<italic>MI<sub>AP</sub> full</italic>). Modulation that could be explained by pupil size was computed using the pupil-only model (<italic>MI<sub>AP</sub> pupil-only</italic>). Then the unique task-related change, <italic>MI<sub>AP</sub> task-unique</italic>, was computed as the difference between <italic>MI<sub>AP</sub> full</italic> and <italic>MI<sub>AP</sub> pupil-only</italic> (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>). We used a converse approach to quantify modulation uniquely attributable to pupil between large and small pupil states (<italic>MI<sub>LS</sub></italic>, see below).</p><p>The model predictions for the example A1 units above (<xref ref-type="fig" rid="fig2">Figure 2</xref>) illustrate the method for dissociating contributions of pupil and task engagement to <italic>MI<sub>AP</sub></italic>. The first example shows a strong task engagement effect that cannot be explained by pupil size (<italic>MI<sub>APÂ </sub>task-unique</italic>Â =Â 0.25, <xref ref-type="fig" rid="fig2">Figure 2C</xref>), and the second shows weak task-only modulation that can be completely explained by pupil (<italic>MI<sub>AP</sub>task-unique</italic>Â =Â â0.07, <xref ref-type="fig" rid="fig2">Figure 2F</xref>).</p><p>A comparison of <italic>MI<sub>AP</sub> task-only</italic> and <italic>MI<sub>AP</sub> task-unique</italic> across the entire dataÂ set showed that a task-only model often overestimated the magnitude of changes due to task engagement (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). To measure this effect, we normalized the sign of <italic>MI</italic> for each unit so that the means of <italic>MI<sub>AP</sub> task-only</italic> and <italic>MI<sub>AP</sub> task-unique</italic> were always positive. This normalization accounted for the bidirectionality of modulation while avoiding bias that would result from normalizing sign for just a single condition. After sign normalization, accounting for pupil size led to a decrease in <italic>MI<sub>AP</sub></italic> magnitude across units in A1 and IC (A1: <italic>pÂ </italic>&lt;Â 10<sup>â5</sup>; IC: <italic>pÂ </italic>=Â 0.0140, hierarchical bootstrap). Effectively, accounting for pupil size led to a 33% reduction in the magnitude of <italic>MI<sub>AP</sub></italic> in both areas (A1: mean magnitude <italic>MI<sub>APÂ </sub>task-only</italic>Â =Â 0.141; <italic>MI<sub>APÂ </sub>task-unique</italic>Â =Â 0.095; IC: <italic>MI<sub>APÂ </sub>task-only</italic>Â =Â 0.069; <italic>MI<sub>APÂ </sub>task-unique</italic>Â =Â 0.046). The effect of removing pupil-related activity on the magnitude of active versus passive modulation was also not different between central and non-central regions of IC (ICC versus NCIC, <italic>pÂ </italic>=Â 0.467, hierarchical bootstrap, <xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplement 1</xref>). Taken together these results show that pupil-indexed arousal accounted for a significant portion of the change in activity between passive and active blocks in A1 and both regions of IC.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Changes in pupil size account for apparent task engagement effects.</title><p>(<bold>A</bold>) Active versus passive modulation index, <italic>MI<sub>AP</sub> task-only</italic>, computed from responses predicted by the task only model, in which pupil size is shuffled, plotted against <italic>MI<sub>AP</sub> task-unique</italic>, in which pupil-dependent modulation is regressed out, forÂ primary auditory cortex (A1; left, <italic>n</italic>Â =Â 132 unit/target pairs) and inferior colliculusÂ (IC; right; circles for NCIC, <italic>n</italic>Â =Â 24 unit/target pairs, triangles for ICC units, <italic>n</italic>Â =Â 61). Colors indicate significant unique variance explained by one or two state variables, as in <xref ref-type="fig" rid="fig3">Figure 3</xref> (<italic>pÂ </italic>&lt;Â 0.05, jackknife <italic>t</italic>-test). (<bold>B</bold>) Overlaid histograms of <italic>MI<sub>AP</sub> task-only</italic> and <italic>MI<sub>AP</sub> task-unique</italic>, sorted according to their magnitude for each unit in A1 and IC. Accounting for pupil size reduced the absolute magnitude of <italic>MI<sub>AP</sub></italic> by about 33% in both areas (A1: <italic>pÂ </italic>&lt;Â 10<sup>â5</sup>; IC: <italic>pÂ </italic>=Â 0.0140, hierarchical bootstrap). The prevalence of gray shading on the right side of the horizontal axis indicates that units with large, positive <italic>MI<sub>AP</sub></italic> were most affected by this adjustment, and <italic>MI<sub>AP</sub></italic> shifted to more negative values on average (A1 median <italic>MI<sub>APÂ </sub>task-only</italic>Â =Â 0.069, <italic>MI<sub>APÂ </sub>task-unique</italic>Â =Â 0.027, pÂ =Â 0.0005; IC: median <italic>MI<sub>APÂ </sub>task-only</italic>Â =Â â0.010, <italic>MI<sub>APÂ </sub>task-unique</italic>Â =Â â0.037, <italic>pÂ </italic>=Â 0.049, hierarchical bootstrap).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5âfigure supplement 1.</label><caption><title>Task-related changes in central versus external inferior colliculus.</title><p>Histograms of <italic>MI<sub>AP</sub> task-only</italic> and <italic>MI<sub>AP</sub> task-unique</italic> sorted according to their magnitude for each unit in ICC (left) and NCIC (right). The median magnitude of <italic>MI<sub>AP</sub> task-unique</italic> was reduced by 43% relative to <italic>MI<sub>AP</sub> task-only</italic> in ICC (<italic>pÂ </italic>=Â 0.0020, hierarchical bootstrap). Units in NCIC also showed a trend toward reduction, but the decrease was not significant (median decrease 31%, <italic>pÂ </italic>=Â 0.231). Among ICC units with significant unique task modulation, <italic>n</italic>Â =Â 9/13 showed increased activity (<italic>MI<sub>AP</sub> task-unique</italic>Â &gt;Â 0) during behavior, and the median was significantly different from zero (median 0.012, <italic>pÂ </italic>=Â 0.010, hierarchical bootstrap). Among NCIC units, only <italic>n</italic>Â =Â 8/36 were enhanced during behavior, but median was not significantly different from zero (median â0.049, <italic>pÂ </italic>=Â 0.07).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig5-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Task engagement and pupil-indexed arousal modulate independent neural populations</title><p>In some units, the effects of task engagement and pupil size on firing rate were difficult to dissociate by simply looking at raw activity (<italic>e.g</italic>., <xref ref-type="fig" rid="fig2">Figure 2D</xref>). However, the regression analysis could disambiguate their unique contributions and showed that often only one state variable, task or pupil, modulated the activity of individual units. Based on this observation, we wondered if effects of task engagement and pupil size operated via functionally distinct or common pathways. While identifying specific anatomical circuits was outside the scope of this work, we reasoned that if the two modulations were mediated by the same inputs to A1 and IC, a unit modulated by task engagement would also tend to be modulated by pupil size. To test this prediction, we measured the correlation between modulation that could be uniquely attributed either to task engagement or pupil. To measure modulation by pupil, we computed changes in spike rate associated with pupil size by measuring <italic>MI<sub>LS</sub></italic> (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>), analogous to <italic>MI<sub>AP</sub></italic>, but dividing trials according to whether pupil size was larger or smaller than the median for the experiment, respectively. For calculation of task-unique effects, <italic>MI<sub>LS</sub> pupil-unique</italic> was the difference between <italic>MI<sub>LS</sub> full</italic> and <italic>MI<sub>LS</sub> task-only</italic> (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>). Thus, we could compare the change in firing rate uniquely attributable to a change in task engagement to a change in pupil size for each unit (<xref ref-type="fig" rid="fig6">Figure 6</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Unique task and pupil modulate independent neural populations.</title><p>Scatter plot compares firing rate modulation attributed to task engagement (<italic>MI<sub>AP</sub> task-unique</italic>) against modulation attributed to pupil (<italic>MI<sub>LS</sub> pupil-unique</italic>) for each unit inÂ primary auditory cortex (A1; left) and inferior colliculusÂ (IC; right). The two quantities showed a weak negative correlation in A1 (<italic>rÂ =</italic>Â â0.281, <italic>pÂ </italic>=Â 0.040, hierarchical bootstrap) and were uncorrelated in IC (<italic>rÂ =</italic>Â â0.104, <italic>pÂ </italic>=Â 0.191). Colors indicate significant model performance as in <xref ref-type="fig" rid="fig3">Figure 3</xref>, and stars indicate examples from <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6âfigure supplement 1.</label><caption><title>Frequency tuning versus task-related modulation of neural activity.</title><p>Strip plots compare task-unique changes in activity (<italic>MI<sub>AP</sub> task-unique</italic>) between units with best frequency similar to the target tone (on-BF,&lt;0.5 octave difference, blue) and different from the target tone (off-BF,&gt;0.5 octave difference, orange) inÂ primary auditory cortex (A1; left) and inferior colliculusÂ (IC; right). Data are further broken down by units with no task-unique changes (left) and significant changes (<italic>pÂ </italic>&lt;Â 0.05, permutation test, right). In A1, there was no difference in median <italic>MI<sub>AP</sub> task-unique</italic> between modulated on- and off-BF units (on-BF: median 0.082, <italic>n</italic>Â =Â 28; off-BF: â0.012, <italic>n</italic>Â =Â 24; <italic>pÂ </italic>=Â 0.221, hierarchical bootstrap) or unmodulated units (on-BF: â0.002, <italic>n</italic>Â =Â 44; off-BF: â0.019, <italic>n</italic>Â =Â 77; <italic>pÂ </italic>=Â 0.136). Similarly, in IC, there were no differences between on- and off-BF units in the modulated (on-BF: median 0.05, <italic>n</italic>Â =Â 9; off-BF: 0.088, <italic>n</italic>Â =Â 6; <italic>pÂ </italic>=Â 0.771, hierarchical bootstrap) or unmodulated groups (on-BF: 0.006, <italic>n</italic>Â =Â 25; off-BF: 0.005, <italic>n</italic>Â =Â 27; <italic>pÂ </italic>=Â 0.347). The relatively small number of significantly modulated IC units makes it difficult to interpret the absence of a significant on- versus off-BF difference (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>), although it confirms that units with task-unique modulation are relatively rare in IC (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6âfigure supplement 2.</label><caption><title>Task difficulty versus task-related modulation of neural activity.</title><p>Swarm plots compare task-unique changes in activity (<italic>MI<sub>AP</sub> task-unique</italic>) broken down by task difficulty, area (primaryÂ auditory cortex [A1] or inferior colliculusÂ [IC]) and significance of task-unique modulation, plotted as in <xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1</xref>. We found no difference in <italic>MI<sub>AP</sub> task-unique</italic> between any pair of difficulty conditions in any group (p&gt;0.05, hierarchical bootstrap).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig6-figsupp2-v2.tif"/></fig></fig-group><p>We found a negative correlation between these quantities in A1 (<italic>rÂ =</italic>Â â0.281, <italic>pÂ </italic>=Â 0.040, hierarchical bootstrap, <xref ref-type="fig" rid="fig6">Figure 6</xref>, left) and no correlation in IC (<italic>r</italic>Â =Â 0.104, <italic>pÂ </italic>=Â 0.191, <xref ref-type="fig" rid="fig6">Figure 6</xref>, right). The absence of a positive correlation between task- and pupil-related effects suggests that independent populations of neurons in A1 and IC are modulated by these variables. To test directly for dependence between task engagement and pupil size, we performed a permutation analysis, estimating the number of units that would show both task- and pupil-unique effects if the likelihood of these effects was independent (<italic>pÂ </italic>&lt;Â 0.05, jackknife <italic>t</italic>-test, counts from <xref ref-type="fig" rid="fig3">Figure 3</xref>). The frequency of joint occurrences was no greater than expected for independent distributions in both areas (A1: <italic>pÂ </italic>=Â 0.41, IC: <italic>pÂ </italic>=Â 0.59, permutation test). This independence is consistent with the hypothesis that separate neural mechanisms mediate effects of task engagement and pupil-indexed arousal.</p><p>Based on previous studies that used a similar positive reinforcement structure, we expected the average sign of task-related modulation to be positive in A1 (<xref ref-type="bibr" rid="bib14">David et al., 2012</xref>) and negative in IC (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). In A1, <italic>MI<sub>AP</sub> task-only</italic>, computed without accounting for effects of pupil, was in fact positive on average (median 0.069, <italic>pÂ </italic>=Â 0.0240, hierarchical bootstrap). However, <italic>MI<sub>AP</sub> task-unique</italic>, which accounted for pupil size, was not significantly different from zero (40/69 positive, median <italic>MI</italic><sub>AP</sub> <italic>task-unique</italic>Â =Â 0.027; <italic>pÂ </italic>=Â 0.232). In IC, average <italic>MI<sub>AP</sub> task-only</italic> was not different from zero (<italic>MI<sub>AP</sub> task-only</italic> median: â0.010, <italic>pÂ </italic>=Â 0.310), but <italic>MI<sub>AP</sub> task-unique</italic> showed a trend toward being negative (17/49 positive, median: â0.037; <italic>pÂ </italic>=Â 0.062). In contrast to the variable task-related effects, the average effect of increased pupil size was positive in A1 (55/69 positive, median <italic>MI</italic><sub>LS</sub> <italic>pupil-unique</italic>Â =Â 0.0139, <italic>pÂ </italic>=Â 0.032, hierarchical bootstrap). In IC, there was also a trend toward increased firing rate with larger pupil (31/49 positive, median <italic>MI</italic><sub>LS</sub> <italic>pupil-unique</italic>Â =Â 0.022; <italic>pÂ </italic>=Â 0.090). Thus, in both areas, accounting for higher firing rate during larger pupil led to decreased in <italic>MI</italic> associated with task engagement (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><p>Some previous work has also reported that the effect of task engagement can depend on the relationship between task-relevant sound features and the receptive field of individual neurons (<xref ref-type="bibr" rid="bib14">David et al., 2012</xref>; <xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). During a tone detection task, response gain in IC is selectively suppressed for neurons with best frequencyÂ (BF) near the target tone frequency (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). In A1, frequency tuning is suppressed at the target frequency, despite there being no systematic difference in overall response gain between units with BF near or far from the target (<xref ref-type="bibr" rid="bib14">David et al., 2012</xref>). After accounting for pupil size, we observed similar trends in the data but no significant effects, likely due to the small sample size in the on-BF and off-BF groups (<xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1</xref>). Task engagement effects could also depend on the difficulty or other structural elements of the task (<xref ref-type="bibr" rid="bib13">Carcea et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Knyazeva et al., 2020</xref>). We considered whether state-dependent effects varied with task difficulty but found no differences between pure tone, high SNR tone-in-noise (easy), and low SNR tone-in-noise (hard) conditions (<xref ref-type="fig" rid="fig6s2">Figure 6âfigure supplement 2</xref>).</p></sec><sec id="s2-5"><title>Relationship between state modulation and auditory responsiveness</title><p>While all units were recorded from areas functionally and anatomically characterized as auditory, neurons within a single auditory field can vary substantially in their tendency to respond to sound (<xref ref-type="bibr" rid="bib3">Atiani et al., 2014</xref>; <xref ref-type="bibr" rid="bib28">Gruters and Groh, 2012</xref>). We noticed that some units, particularly in IC, did not show strong auditory responses but were modulated during behavior. We asked whether the magnitude of the state-dependent modulation in each recorded unit was related to how reliably it responded to repeated presentations of the same auditory stimulus. Auditory responsiveness was quantified by the variance explained by the null model, since it described how accurately the PSTH response to the reference stimuli, averaged across the entire recording, predicted responses on single trials. Larger or smaller values of null model <italic>r</italic><sup>2</sup> were associated with units whose auditory responses were more or less reliable across the experiment, respectively. We compared this measure of auditory responsiveness to the change in <italic>r</italic><sup>2</sup> between the full and null models, which indicates additional variance explained by the state variables. In IC, but not in A1, units that responded less reliably to sound also showed greater dependence on state (A1: <italic>rÂ =</italic>Â â0.134, <italic>pÂ </italic>=Â 0.130; IC: <italic>rÂ =</italic>Â â0.323, <italic>pÂ </italic>=Â 0.0129, hierarchical bootstrap; <xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Task- and pupil-related modulation inÂ primary auditory cortex (A1) and inferior colliculusÂ (IC).</title><p>Mean variance in firing rate explained by behavioral state variables, broken down by portions attributed to task (purple), attributed to pupil (green), and not uniquely attributable to either state variable (gray) for A1 (left) and IC (right). Data are grouped in quintiles by <italic>r</italic><sup>2</sup> for the null model performance, a measure of auditory responsiveness. Variance explained by state was not correlated with null model performance in A1 (<italic>rÂ =</italic>Â â0.134, <italic>pÂ </italic>=Â 0.130, hierarchical bootstrap), but these values were negatively correlated in IC (<italic>rÂ =</italic>Â â0.323, <italic>pÂ </italic>=Â 0.0129). Colors as in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7âfigure supplement 1.</label><caption><title>Auditory responsiveness predicts state-dependent modulation in inferior colliculusÂ (IC).</title><p>(<bold>A</bold>) Scatter plots compare variance explained by the null model, a measure of auditory responsiveness for each neuron, against additional variance explained by the full model, which incorporates modulation by task engagement and pupil size. InÂ primary auditory cortex (A1; left), the additional variance explained by the full model is uncorrelated with null model performance (<italic>n</italic>Â =Â 129, <italic>r</italic>Â =Â â0.134, <italic>pÂ </italic>=Â 0.130, hierarchical bootstrap). In IC, the change is negatively correlated (IC: <italic>n</italic>Â =Â 66, <italic>r</italic>Â =Â â0.323, <italic>pÂ </italic>=Â 0.0129), indicating a larger behavior effect in units with weaker auditory responses. Dashed diagonal line shows the theoretical limit on additional variance explained by the full model. If the additional variance explained is normalized by this limit, the data are positively correlated in A1 (<italic>rÂ =</italic>Â 0.301, <italic>p</italic>Â =Â 0.0360) and not correlated in IC (<italic>rÂ =</italic>Â 0.124, <italic>pÂ </italic>=Â 0.178). (<bold>B</bold>) Scatter plots compare log signal-to-noise ratio (SNR) of response evoked by reference noise-evoked, an alternative measure of auditory responsiveness, against additional variance explained by the full model. Again, there is no significant correlation in A1 (<italic>r</italic>Â =Â â0.121, <italic>pÂ </italic>=Â 0.335), but the correlation is negative in IC (<italic>r</italic>Â =Â â0.252, <italic>pÂ </italic>=Â 0.0367). (<bold>C</bold>) Variance explained by the null model versus additional variance explained by a behavior-dependent model for larger populations of neurons. Some data did not include pupillometry and the model accounted only for task engagement. Again, there was no correlation in A1 (<italic>n</italic>Â =Â 254, <italic>r</italic>Â =Â â0.106, <italic>pÂ </italic>=Â 0.0761), but there is a negative correlation in IC (<italic>n</italic>Â =Â 201, <italic>r</italic>Â =Â â0.317, <italic>pÂ </italic>&lt;Â 10<sup>â5</sup>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig7-figsupp1-v2.tif"/></fig></fig-group><p>These same relationships were observed when auditory responsiveness was defined as the signal-to-noise ratio (SNR) of the spectro-temporal receptive field (STRF) measured during passive listening (<xref ref-type="fig" rid="fig7s1">Figure 7âfigure supplement 1B</xref>; <xref ref-type="bibr" rid="bib38">Klein et al., 2000</xref>). The results also held true for a larger pool of neurons, which included data collected without pupillometry and analyzed with the task-only model (<xref ref-type="fig" rid="fig7s1">Figure 7âfigure supplement 1C</xref>). High prediction accuracy by the null model limits the variance that can be explained by behavioral state (note relatively weak state effect in highest quintile in <xref ref-type="fig" rid="fig7">Figure 7</xref>). To explore how this bound might impact the analysis of auditory responsiveness, we performed a similar analysis but measured the correlation between null model performance and the fraction of remaining variance explained by pupil size and task engagement. In this case, the null model performance was positively correlated with the remaining variance explained in A1 (<italic>rÂ =</italic>Â 0.301, <italic>pÂ </italic>=Â 0.0360, hierarchical bootstrap) and not correlated in IC (<italic>rÂ =</italic>Â 0.124, <italic>pÂ </italic>=Â 0.178, <xref ref-type="fig" rid="fig7s1">Figure 7âfigure supplement 1A</xref>). In this case the overall slope of the relationships changed, but the effects were still relatively larger for IC units with low auditory responsiveness. Thus, across multiple measures of sensory responsiveness, we observed that effects of behavior state in IC were more common in units with weak sensory responses, while in A1, state-dependent modulation was independent of sensory responsiveness.</p></sec><sec id="s2-6"><title>Changes in pupil size explain some persistent post-behavior state effects</title><p>Previous studies in both A1 (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>) and IC (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>) have reported examples of task-related modulation persisting in passive blocks following active engagement (referred to as post-passive blocks). These effects have been interpreted as persistent task-related plasticity, but they are highly variable and difficult to attribute to any specific aspect of the behavior. We observed these effects in our data as well. In addition to units in A1 (<italic>e.g.</italic>, <xref ref-type="fig" rid="fig2">Figure 2D</xref>), some units in IC showed persistent changes in activity during passive blocks following behavior. These changes sometimes lasted through the entire post-passive block (<xref ref-type="fig" rid="fig8">Figure 8A</xref>) and other times gradually reverted to pre-passive levels (<xref ref-type="fig" rid="fig8">Figure 8B</xref>). The timeÂ course of these changes often tracked fluctuations in pupil size.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Pupil size explains some persistent task-related modulation.</title><p>(<bold>A</bold>) Top: activity of ICC unit and concurrent pupil size recorded over passive and active blocks, plotted as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Bottom: peri-stimulus time histogram (PSTH) response to reference noise averaged over each half block (black) with null model prediction overlaid (dashed gray). The response was enhanced slightly during the post-passive (P2) block relative to pre-passive (P1). Without accounting for effects of pupil size, this suggests a sustained firing rate increase after behavior, <italic>MI<sub>P1P2Â </sub>block-only</italic>Â =Â 0.25. After accounting for changes in pupil, the task-related effect is reduced, <italic>MI<sub>P1P2Â </sub>block-unique</italic>Â =Â 0.02. (<bold>B</bold>) Data from example NCIC unit, plotted as in <bold>A</bold>. The PSTH shows a weak, suppressive response to the reference stimuli, but a large increase in mean firing rate that persists into the first half of the post-passive block (<italic>MI<sub>P1P2Â </sub>block-only</italic>Â =Â 0.37). Again, the persistent change in firing rate can be accounted for by the very large pupil during the first half of P2 (<italic>MI<sub>P1P2Â </sub>block-unique</italic>Â =Â â0.04). (<bold>C</bold>) Scatter plot compares <italic>MI<sub>P1P2</sub> block-only</italic> and <italic>MI<sub>P1P2</sub> block-unique</italic> forÂ primary auditory cortex (A1; left) and inferior colliculusÂ (IC; right). Colors as in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Accounting for pupil reduces <italic>MI</italic> attributed to persistent effects after behavior in both areas (A1: <italic>pÂ </italic>&lt;Â 10<sup>â5</sup>, IC: <italic>pÂ </italic>&lt;Â 10<sup>â5</sup>, hierarchical bootstrap).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60153-fig8-v2.tif"/></fig><p>To measure the presence of persistent task-related modulationâand the extent to which pupil size accounts for itâwe compared the activity between passive blocks before (P1) and after (P2) a behavior block. We performed a regression analysis similar to that used for measuring task engagement effects, but treating passive block identity (P1 or P2) as a state variable in addition to pupil size. <italic>MI</italic> was computed for predictions by a model based only on block identity, ignoring pupil (<italic>MI<sub>P1P2</sub> block-only</italic>), and for the unique contribution of passive block after accounting for pupil effects (<italic>MI<sub>P1P2</sub> block-unique</italic>, <xref ref-type="fig" rid="fig8">Figure 8A</xref>). We assessed the magnitude of <italic>MI</italic> using the same sign normalization as for the task-unique <italic>MI</italic> analysis above (<xref ref-type="fig" rid="fig5">Figure 5</xref>). In both A1 and IC, the magnitude of firing rate modulation between passive blocks was significantly reduced after accounting for effects of pupil (A1: <italic>pÂ </italic>&lt;Â 10<sup>â5</sup>, IC: <italic>pÂ </italic>&lt;Â 10<sup>â5</sup>, hierarchical bootstrap). Accounting for pupil size led to a 20% and a 48% reduction in P1 versus P2 modulation in A1 and IC, respectively (A1: mean signed-normalized <italic>MI<sub>P1P2Â </sub>block-only</italic>Â =Â 0.140, <italic>MI<sub>P1P2Â </sub>block-unique</italic>Â =Â 0.100; IC: mean signed-normalized <italic>MI<sub>P1P2Â </sub>block-only</italic>Â =Â 0.100, <italic>MI<sub>P1P2Â </sub>block-unique</italic>Â =Â 0.052). This change was not significantly different between animals in A1 (<italic>F</italic>Â =Â 0.669, <italic>pÂ =Â </italic>0.516, one-way ANOVA) or in IC (<italic>F</italic>Â =Â 0.446, <italic>pÂ =Â </italic>0.643). While there was decrease in post-behavior effects on average, there were distinct groups of units in both A1 and IC that showed changes between P1 and P2, even after accounting for pupil size (compare units falling on the unity line versus x-axis in <xref ref-type="fig" rid="fig8">Figure 8C</xref>). Thus, while some post-behavior effects previously reported as persistent plasticity induced by behavior can in fact be explained by fluctuations in pupil size, a small number of units showed persistent post-behavior changes, even after accounting for pupil.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>This study determined how pupil-indexed arousal contributes to task-related spiking activity in A1 and IC. Several previous studies have shown that transitioning from passive listening to active behavior leads to sizable changes in neural activity in A1 (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib52">Niwa et al., 2012</xref>; <xref ref-type="bibr" rid="bib53">Otazu et al., 2009</xref>) and IC (<xref ref-type="bibr" rid="bib60">Ryan and Miller, 1977</xref>; <xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). The specific changes depend on properties of the task stimuli (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib34">Jaramillo and Zador, 2011</xref>; <xref ref-type="bibr" rid="bib44">Lee and Middlebrooks, 2011</xref>) and on structural elements of the task, such as reward contingencies (<xref ref-type="bibr" rid="bib14">David et al., 2012</xref>), task difficulty (<xref ref-type="bibr" rid="bib2">Atiani et al., 2009</xref>), the degree of engagement (<xref ref-type="bibr" rid="bib13">Carcea et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Knyazeva et al., 2020</xref>), and the focus of selective attention (<xref ref-type="bibr" rid="bib31">Hocherman et al., 1976</xref>; <xref ref-type="bibr" rid="bib43">Lakatos et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Schwartz and David, 2018</xref>). In the current study, we were able to use pupil size to explain changes in neural activity across both passive and active conditions. Changes in neural activity explained by pupil size are likely to account for some differences previously reported between task conditions, where different levels of arousal are required (<italic>e.g.</italic>, <xref ref-type="bibr" rid="bib13">Carcea et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Knyazeva et al., 2020</xref>; <xref ref-type="bibr" rid="bib58">Rodgers and DeWeese, 2014</xref>). The effects of task engagement reported here are specific to the tone detection task and are likely to differ if task structure is changed. In contrast, pupil size explains changes in activity throughout active and passive states, and its effects are likely to be similar in different task conditions (<xref ref-type="bibr" rid="bib65">Schwartz et al., 2020</xref>). By isolating aspects of behavioral state that can be explicitly attributed to changes in pupil, this study moves toward a coherent theory of how a constellation of variables interact to influence sensory coding during behavior.</p><p>Aspects of behavioral state, such as arousal, locomotion, and whisking rate, have been shown to change gradually over the course of an experiment, tracking changes in cortical spiking and performance on operant tasks (<xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib51">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib55">Poulet and Petersen, 2008</xref>). A major obstacle to understanding the relationship between behavioral state and neural activity is that state variables often covary (<xref ref-type="bibr" rid="bib50">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib73">Stringer et al., 2019</xref>). To dissociate effects of pupil size and task engagement here, we used a stepwise approach in which pupil size and task engagement provided separate regressors (<xref ref-type="bibr" rid="bib22">Fritz et al., 2010</xref>; <xref ref-type="bibr" rid="bib50">Musall et al., 2019</xref>). In about half of A1 and IC units, some combination of task engagement and/or pupil size explained changes in spiking activity between blocks of active engagement and passive listening. These behavioral state variables were correlated; that is, pupil size tended to increase during task engagement. However, these changes affected independent neural populations, suggesting that effects of pupil-indexed arousal and other aspects of task engagement operate via distinct feedback circuits.</p><sec id="s3-1"><title>Defining meaningful state variables</title><p>The correlation between pupil size and task engagement demonstrates the importance of accounting for interactions between state variables when measuring their effects on neural activity. This observation also leads to a more fundamental question: what constitutes a meaningful measure of behavioral state? Concepts like task engagement and arousal make intuitive sense, but they become slippery when one attempts to pin them to distinct physiological processes. The current results illustrate that a commonly used binary task engagement variable is better described by a combination of pupil size and accuracy of behavioral performance. Other characterizations of task engagement have argued similarly that the degree of engagement can vary, even when relevant acoustic stimuli are held fixed (<xref ref-type="bibr" rid="bib2">Atiani et al., 2009</xref>; <xref ref-type="bibr" rid="bib13">Carcea et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Knyazeva et al., 2020</xref>; <xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib83">Zhou et al., 2014</xref>). Larger dataÂ sets that track continuous fluctuations in performance are likely to be able to measure fluctuations of engagement effects within behavior blocks. It remains unclear how smoothly internal state can vary. Theories of network attractors suggest that there may in fact be discrete changes in brain state associated with different behavioral contexts (<xref ref-type="bibr" rid="bib42">La Camera et al., 2019</xref>). Thus, while task engagement is clearly not binary, it could still comprise multiple metastable states.</p><p>As a behavioral state variable, arousal also has multiple definitions, including the transition from wakefulness to sleep, the response to emotionally salient stimuli, and a generalized activation of the autonomic nervous system (<xref ref-type="bibr" rid="bib62">Satpute et al., 2019</xref>). This relatively nonspecific behavioral concept contrasts with pupil size, which has a clear link to neurophysiology (<xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib56">Reimer et al., 2016</xref>; <xref ref-type="bibr" rid="bib82">Zekveld et al., 2018</xref>). The detailed circuits that link pupil size to cognitive state are not fully understood, but a connection to behavioral state has been demonstrated repeatedly. Thus, while pupil size may not map trivially onto the concept of arousal, it has a clear link to brain mechanisms.</p><p>A clearer understanding of the relationship between behavioral state and sensory processing may be achieved with models that incorporate additional well-defined variables like pupil size, which can be linked to well-defined neurophysiological processes. For example, motor- and reward-related activity are associated with specific neural circuits (<xref ref-type="bibr" rid="bib5">Bakin and Weinberger, 1990</xref>; <xref ref-type="bibr" rid="bib40">Knyazeva et al., 2020</xref>; <xref ref-type="bibr" rid="bib63">Schneider et al., 2014</xref>). The current study excluded epochs that contained licking activity to avoid motor confounds, but motor signals can be included as additional model inputs that reflect aspects of signal detection and decision making (<xref ref-type="bibr" rid="bib59">Runyan et al., 2017</xref>). These variables may not be directly related to an experimentally imposed task structure, but they capture processes involved in the behavior and can be quantified more concretely than abstract variables based on experimentally imposed task conditions.</p></sec><sec id="s3-2"><title>Reinterpreting previous studies of auditory behavior</title><p>Our findings indicate that changes in firing rate previously attributed to task engagement might instead reflect fluctuations in pupil-indexed arousal, particularly in IC, where pupil-related changes predominate. Changes in pupil size can also explain some modulation that persists after behavior ceases (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). However, pupil size does not account for all the modulation between active and passive blocks; instead, it appears that both pupil-indexed arousal and task engagement act on independent neural populations to shape sound processing.</p><p>Previous studies that measured the effects of task engagement on auditory neuronal activity described different effects on overall excitability between A1 and IC. In A1 the effects of task engagement were shown to be enhancing (<xref ref-type="bibr" rid="bib14">David et al., 2012</xref>), while in IC these changes were predominantly suppressive (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). Separate studies have shown that pupil size is positively correlated with excitability in both A1 and IC (<xref ref-type="bibr" rid="bib35">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib65">Schwartz et al., 2020</xref>). Here we also found that increased pupil size enhanced excitability in both areas. However, after accounting for pupil-related changes, task-engagement effects were no longer enhancing in A1, and they were more suppressive in IC. Pupil-related changes did not depend on tuning for the target tone. These nonspecific effects of pupil size contrasted with theÂ effects of task engagement, which can be selective for task-relevant features (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib41">Kuchibhotla et al., 2017</xref>; <xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>).</p><p>In the current study, significant state-dependent A1 units were equally likely to be modulated by task engagement, by pupil size, or by both. In IC, however, we found that a larger portion of state-dependent changes could be explained by pupil size. Furthermore, in IC but not in A1, units with less reliable auditory responsiveness were those with a stronger state-modulation component. This result is perhaps not surprising given that the majority of IC units in our sample were recorded from non-central regions of the IC (NCIC). These are dorsal and lateral regions of IC that receive feedback from cortex (<xref ref-type="bibr" rid="bib78">Winer, 2006</xref>), input from neuromodulatory nuclei such as the pedunculopontine and latero-dorsal tegmental nuclei (<xref ref-type="bibr" rid="bib49">Motts and Schofield, 2009</xref>), as well as multisensory information from somatosensory, visual, and oculomotor centers (<xref ref-type="bibr" rid="bib28">Gruters and Groh, 2012</xref>). These results suggest that the auditory midbrain is not a passive sound processor. Instead, the network of midbrain nuclei in the IC plays an active role enhancing behaviorally relevant signals. Experiments that sample more units across the different subregions would be needed to confirm the interplay of behavioral and sensory signals across IC.</p><p>Multiple regression has been used previously to dissociate effects of pupil size and movement on neural activity (<xref ref-type="bibr" rid="bib50">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib73">Stringer et al., 2019</xref>). This study used this approach to dissociate the effects of state-related variables and differentiate where effects emerge. Several other variables have been shown to impact auditory responses during behavior, including selective attention, temporal expectation, reward value, and motor responses (<xref ref-type="bibr" rid="bib14">David et al., 2012</xref>; <xref ref-type="bibr" rid="bib32">Huang et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Jaramillo and Zador, 2011</xref>; <xref ref-type="bibr" rid="bib43">Lakatos et al., 2013</xref>; <xref ref-type="bibr" rid="bib47">Metzger et al., 2006</xref>). The same method can be adopted to explore the contribution of other state variables measured in normal conditions as well as in perturbation experiments to identify the circuits through which such variables operate.</p></sec><sec id="s3-3"><title>The role of neuromodulation in effects of task engagement and pupil-indexed arousal in A1 and IC</title><p>The correlation between task engagement and pupil size may help explain a number of results related to neuromodulation in the auditory system. It is well established that neuromodulators can induce short-term changes in activity and sensory tuning in cortex (<xref ref-type="bibr" rid="bib6">Bakin and Weinberger, 1996</xref>; <xref ref-type="bibr" rid="bib26">Goard and Dan, 2009</xref>) and midbrain (<xref ref-type="bibr" rid="bib25">Gittelman et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Habbicht and Vater, 1996</xref>; <xref ref-type="bibr" rid="bib33">Hurley and Pollak, 2005</xref>). Cholinergic fibers projecting to A1 from the nucleus basalis play a key role in rapid switching between passive listening and active engagement by modulating the activity of different populations of cortical inhibitory interneurons (<xref ref-type="bibr" rid="bib41">Kuchibhotla et al., 2017</xref>). In addition, the activity of cholinergic and noradrenergic terminals in A1 was found to be elevated during pupil dilation and reduced during pupil constriction (<xref ref-type="bibr" rid="bib56">Reimer et al., 2016</xref>). Thus, these neuromodulatory systems have been implicated in effects of both task engagement and pupil-indexed arousal. The correlation between these state variables could be explained by shared cholinergic and noradrenergic signaling.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>All procedures were approved by the Oregon Health and Science University Institutional Animal Care and Use Committee (protocol IP1561) and conform to National Institutes of Health standards.</p><sec id="s4-1"><title>Surgical procedure</title><p>Animal care and procedures were similar to those described previously for neurophysiological recordings from awake behaving ferrets (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>). Four young adult male ferrets were obtained from an animal supplier (Marshall Farms, North Rose, NY). After a 2-week quarantine, a sterile surgery was performed under isoflurane anesthesia to mount two head-posts for head fixation and to permit access to auditory brain regions for recordings. A UV light-cured composite (Charisma, Heraeus Kulzer International) was used to mount two custom-made stainless-steel head-posts spaced approximately 1 cm apart along the sagittal crest of the skull. The stability of the implant was achieved using 8â10 stainless steel bone screws mounted in the skull (Depuy Synthes, Raynham, MA), which were covered along with the headpost in additional Charisma and acrylic denture material (Co-oral-ite Dental, Diamond Springs. CA). Two 1.2 Ã 1.2 cm wells over A1 in the implant were covered with only a thin layer of Charisma to allow access to auditory regions.</p><p>Following surgery, animals were treated with prophylactic antibiotics (Baytril 10 mg/kg) and analgesics (Buprenorphin 0.02 mg/kg) under the supervision of University veterinary staff. For the first 2Â weeks the wound was cleaned with antiseptics (Betadine 1:4 in saline and Chlorhexidine 0.2%) and bandaged daily with application of topic antibiotic ointment (Bacitracin). After the wound margin was healed, cleaning and bandaging occurred every 2â3 days throughout the life of the animals. This method revealed to be very effective in minimizing infections of the wound margin. After recovery (~2 weeks), animals were habituated to a head-fixed posture inside the sound-booth chamber for about 2 weeks prior to the beginning of the training.</p></sec><sec id="s4-2"><title>Behavioral paradigm and training</title><p>The animals were trained by instrumental conditioning to perform a positively reinforced, tone versus noise discrimination task (ferret L) (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>) or tone-in-noise detection task (ferrets R, B, andÂ T). During training, animals were provided access to water ad libitum on weekends, but were placed on water restriction during the weekdays (Monday through Friday), allowing them to maintainÂ &gt;90% of their baseline body weight longÂ term. On weekdays, they were given the opportunity to receive liquid reward during behavioral training. Each behavioral trial consisted of a sequence of twoÂ toÂ five broadband noise reference sounds (TORCs; 30 samples, five octaves, 0.75 s duration, 0.7 s inter-stimulus interval) (<xref ref-type="bibr" rid="bib38">Klein et al., 2000</xref>), followed by a target tone, either alone (tone versus noise task) or overlapping with another TORC (tone-in-noise task). Animals reported the occurrence of the target by licking a water spout (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Licks were detected by a piezoelectric sensor glued to the spout. Licks occurring within the target window, 0.1â1.5 s after target onset, were rewarded with oneÂ toÂ three drops of a 2:1 solution of water and a high-protein, high-calorie dietary supplement (Ensure). FAs, licks occurring before the target window, and misses, a failure to lick during the target window, resulted in a 5â8 s timeout. Regardless of trial outcome, the next trial began only after animals did not lick for a random period (2.5Â Â±Â 0.5 s), reducing the prevalence of accidental, short-latency FAs. The number of TORCs per trial was distributed randomly with a flat hazard function to prevent behavioral timing strategies (<xref ref-type="bibr" rid="bib30">Heffner and Heffner, 1995</xref>). Behavioral performance was measured using <italic>dâ</italic>, the z-scored difference between hit rateÂ (HR) and FA rate (<xref ref-type="bibr" rid="bib27">Green and Swets, 1966</xref>).</p><p>A behavioral block consisted of 60â100 trials with the same target tone frequency (100â20,000 Hz) and same distribution of target SNR. Animals completed oneÂ toÂ three behavioral blocks per day, between which target frequency and/or SNR could change. During training, target frequency was chosen at random to span the audiogram of a ferret (<xref ref-type="bibr" rid="bib37">Kelly et al., 1986</xref>). During electrophysiological recordings, target tone frequency was selected to match the BF of the recording site.</p><p>During the training on the tone-in-noise variant of the task, the TORC sample masking the target varied randomly in each trial to prevent animals from using TORCsâ spectro-temporal features to identify targets. At the beginning of training, the tone was presented at +40 dB SNR (ratio of peak-to-peak amplitude) relative to the TORCs. This difference was gradually reduced over the course of 2â3 weeks until the animal consistently performed above chance (three behavioral blocks with performance yielding <italic>d</italic>â&gt;1, see below) at 0 dB SNR.</p><p>For the tone-in-noise task, the SNR of the tone with respect to the overall level of the TORCs (fixed at 55 or 60 dB SPL depending on the animal) varied between +5 and â20 dB SNR, in 5 dB steps. Each session included five target/noise SNRs. To manipulate task difficulty within each session, the probability of each of the five target/noise SNRs varied, yielding two difficulty conditions: a high SNR (âeasyâ) condition in which 60% of the trials the target/noise SNR was either the highest or the second to the highest SNR within the target/noise SNR distribution; and a low SNR (âhardâ) condition in which the two lowest target/noise SNRs occurred in 60% of the trials. For example, for ferret B, the distribution after training was completed andÂ kept between 0 and â20 dB SNR, so that in the easy condition 0 and â5 dB SNR targets would appear 60% of the time, â10 dB SNR 20% of the time, and the remaining â15 and â20 dB SNR would be presented another 20% of the trials. During electrophysiological tone-in-noise experiments, the tone was embedded in a single TORC sample, which also occurred in the reference period. We confirmed that animals were not biased to respond to this TORC exemplar in the reference phase.</p></sec><sec id="s4-3"><title>Sound presentation</title><p>Behavioral training and subsequent neurophysiological recording took place in a sound-attenuating chamber (Gretch-Ken) with a custom double-wall insert. Stimulus presentation and behavior were controlled by custom MATLAB software (code available at <ext-link ext-link-type="uri" xlink:href="https://bitbucket.org/lbhb/baphy">https://bitbucket.org/lbhb/baphy</ext-link>). Digital acoustic signals were transformed to analog (National Instruments), amplified (Crown), and delivered through two free-field speakers (Manger, 50â35 000 Hz flat gain) positionedÂ Â±30Â° azimuth and 80 cm distant from the animal. Stimuli were presented either from the left or the right speaker, contralaterally to the recording site. Sound level was equalized and calibrated against a standard reference (BrÃ¼el and KjÃ¦r).</p></sec><sec id="s4-4"><title>Pupil recording</title><p>During experiments, infrared video of one eye was collected for offline measurement of pupil size as an index of arousal (pupil-indexed arousal). Ambient light was maintained at a constant level to prevent light-evoked changes in pupil and to maximize the dynamic range of pupil-related changes (<xref ref-type="bibr" rid="bib65">Schwartz et al., 2020</xref>). Recordings were collected using a CCD camera (Adafruit TTL Serial Camera 397) fitted with a lens (M12 Lenses PT-2514BMP 25.0 mm) whose focal length allowed placement of the camera 10 cm from the eye. To improve contrast, the imaged eye was illuminated by a bank of infrared LEDs. Ambient luminance was provided using a ring light (AmScope LED-144S). At the start of each recording day, the intensity of the ring light was set to a level (~1500 lux measured at the recorded eye) chosen to give a maximum dynamic range of pupil sizes. Light intensity remained fixed across the recording session. Pupil size was measured from the video signal offline using custom MATLAB software, which is detailed in <xref ref-type="bibr" rid="bib65">Schwartz et al., 2020</xref>.</p></sec><sec id="s4-5"><title>Neurophysiology</title><p>Data were recorded during behavior and pupillometry from 129 units in A1 and 66 units in IC. For one supplementary analysis (<xref ref-type="fig" rid="fig7s1">Figure 7âfigure supplement 1</xref>), additional data were collected during behavior but without pupillometry (IC: 135 additional units, A1: 125 additional units). After animals demonstrated consistent above-chance performance (target versus reference <italic>d</italic>âÂ &gt;Â 1, see below), a small craniotomy was opened to access either A1 or IC. Extracellular neuronal activity was recorded in non-anesthetized ferrets either using a tetrode (Thomas Recording Inc) or a linear 64-channel silicon probe (<xref ref-type="bibr" rid="bib69">Shobe et al., 2015</xref>). The impedance of the tetrode was measured to be 1â2 MOhm, and the 64-channel probe was electroplated to reach a 0.7-MOhm impedance in each channel. The tetrode and probe were inserted using a motorized electrode positioning system (Alpha-Omega).</p><p>Amplified (tetrodes, AM Systems; arrays, Intan) and digitized (National Instruments) electrophysiological signals were stored using the open-source data acquisition software MANTA (<xref ref-type="bibr" rid="bib18">Englitz et al., 2013</xref>) or Open Ephys (<xref ref-type="bibr" rid="bib11">Black et al., 2017</xref>). Recording sites in A1 and IC were initially targeted stereotactically (<xref ref-type="bibr" rid="bib48">Moore et al., 1983</xref>; <xref ref-type="bibr" rid="bib68">Shamma et al., 1993</xref>). Sites in A1 were confirmed based on tonotopyâwhich changes from high to low BF as one moves from dorso-medial to ventro-lateral regionsâand relatively reliable and simple frequency tuning (<xref ref-type="bibr" rid="bib68">Shamma et al., 1993</xref>). Recording sites in the IC were classified based on tonotopy and response properties (<xref ref-type="bibr" rid="bib1">Aitkin et al., 1975</xref>; <xref ref-type="bibr" rid="bib48">Moore et al., 1983</xref>). Neurons in the central nucleus of the IC (here referred to as ICC) receive input from the auditory brainstem, and have a characteristic short response latency, dorsal-ventral tonotopy, and narrow bandwidth tuning. Conversely, regions around the central nucleus do not receive direct ascending input and present longer response latencies, considerably less sharp tuning, lack consistent tonotopic organization; these areas were grouped together as NCIC (<xref ref-type="bibr" rid="bib71">Slee and David, 2015</xref>).</p><p>For tetrode recordings, upon unit isolation, a series of brief (100 ms duration, 200â400 ms inter-stimulus interval, 50 dB SPL) tones and/or narrowband noise bursts were used to determine the range of frequencies that evoked the strongest response, the BF of the unit(s). If a unit(s) in the site did not respond to the sound stimuli (an evoked increase or decrease in activity compared to spontaneous activity either during or after sound presentation), the electrode was moved to a new recording depth with small, 5 Âµm incremental steps. For the 64-channel recordings, we lowered the probe so that its entire extent (1 mm) spanned the target region (A1 or IC).</p></sec><sec id="s4-6"><title>Spike sorting</title><p>Putative spikes were sorted offline by band-pass filtering the raw trace (300â6000 Hz) and extracting events from the continuous signal that deviated â¥4 standard deviations from zero. To separate single units and stable multiunits from the electrode signal, we used the Catamaran clustering program (kindly provided by D. Schwarz and L. Carney) (<xref ref-type="bibr" rid="bib67">Schwarz et al., 2012</xref>) for tetrode recordings and the software KiloSort (<xref ref-type="bibr" rid="bib54">Pachitariu et al., 2016</xref>) for array recordings. In both cases, units were defined based on visual inspection of traces and by having less than 1% of inter-spike intervals shorter than 0.75 ms (single units) and less than 2.5% inter-spike intervals shorter than 0.75Â ms (multiunits). Stability of single-unit isolation was verified by examining waveforms and interval histograms. If isolation was lost during an experiment, only activity during the stable period was analyzed.</p></sec><sec id="s4-7"><title>Analysis</title><p>Data preprocessing and analysis were performed using custom MATLAB and Python scripts. All analyses were performed on biological replicates, either different behavior sessions, different neurons (single- or multiunit, see above), or different neuron-behavior condition pairs. Neural and pupil activity were binned at 20 samples/s before analysis. A Python library used for the modeling portion of this analysis is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/LBHB/NEMS/">https://github.com/LBHB/NEMS/</ext-link>. Sample size (number of animals, number of units per condition) was determined based on norms established in previous studies of neural activity in awake, behaving animals (<xref ref-type="bibr" rid="bib19">Fritz et al., 2003</xref>; <xref ref-type="bibr" rid="bib52">Niwa et al., 2012</xref>; <xref ref-type="bibr" rid="bib53">Otazu et al., 2009</xref>).</p></sec><sec id="s4-8"><title>Task performance</title><p>Behavioral performance was measured using signal detection theory (<xref ref-type="bibr" rid="bib27">Green and Swets, 1966</xref>; <xref ref-type="bibr" rid="bib72">Stanislaw and Todorov, 1999</xref>). Hits or <italic>FAs</italic> occurred when the animal licked the piezo waterspout upon presentation of the target or the reference stimuli, respectively. Misses or correct rejections (<italic>CRs</italic>) occurred when the animal did not lick following presentation of the target or reference. <italic>HR</italic> was calculated as the proportion of licks that occurred upon presentation of the target during the response window (0.1â1.5 s after target onset), <italic>HR</italic> = <italic>hits</italic>/(<italic>hits+misses</italic>). FA rate (<italic>FAR</italic>) was calculated as the proportion of reference stimuli that elicited a lick, during the same window following reference onset, <italic>FAR</italic> = <italic>FAs</italic>/(<italic>FAs + CRs</italic>). Sensitivity (<italic>d</italic>â), a measure of the animalsâ ability to discriminate between target tone and reference noise, was measured by the difference between the z-scored HR and the FA rate, <italic>d</italic>â = <italic>HR<sub>z</sub>â FAR<sub>z</sub></italic>. No discrimination, that is, equal likelihood of responding to target and reference is indicated by <italic>d</italic>âÂ =Â 0. Animals were considered trained to the task and ready to undergo electrophysiological recordings when they performed consistently above chance (<italic>d</italic>âÂ &gt;Â 1) for three consecutive sessions.</p></sec><sec id="s4-9"><title>Auditory tuning properties</title><p>Tuning properties of A1 and IC units were characterized using the STRF estimated by reverse correlation between time-varying neuronal spike rate and the rippled noise used as reference sounds during behavior (<xref ref-type="bibr" rid="bib38">Klein et al., 2000</xref>). The STRF provides a quick and efficient measure of stimulus frequencies that enhance or suppress neural firing. In the current study, the STRF was used to measure BF as the center of mass of a spectral tuning curve computed from the first principle component of the STRF matrix (<xref ref-type="bibr" rid="bib70">Simon et al., 2007</xref>). Auditory responsiveness was computed as the SNR of single trial responses to the reference noise stimuli during passive listening (<xref ref-type="bibr" rid="bib38">Klein et al., 2000</xref>).</p></sec><sec id="s4-10"><title>State-dependent models</title><p>We fit a generalized linear model in which time-varying state variables pupil size, <inline-formula><mml:math id="inf1"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>, and task engagement,Â <inline-formula><mml:math id="inf2"> <mml:mi/><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>, were used to re-weight each unitâs mean evoked response to each noise stimulus, <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, and spontaneous rate, <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, to generate a prediction of the single-trial spike rate, <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, at each point in time. The model included multiplicative gain parameters (<inline-formula><mml:math id="inf6"><mml:mi>g</mml:mi></mml:math></inline-formula>) and DC offset parameters (<inline-formula><mml:math id="inf7"><mml:mi>d</mml:mi></mml:math></inline-formula>) to capture both types of modulation. We refer to this model as the <italic>full model</italic>:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To account for nonlinear threshold and saturation of state effects, the summed state signal was passed through a sigmoid nonlinearity, <italic>F<sub>d</sub></italic> or <italic>F<sub>g</sub></italic>, before scaling response baseline or gain, respectively (difference of exponentials) (<xref ref-type="bibr" rid="bib74">Thorson et al., 2015</xref>). With additional constant terms <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, this model required a total of six free parameters. For comparison, we calculated a state-independent model here referred to as the <italic>null model</italic>, in which the state variable regressors were shuffled in time. Because shuffling removes any possible correlation between state and neural activity, gain and offset parameters are reduced to <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>=<inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>=1 and <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=<inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=<inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=<inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>=0, effectively reducing the model to<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In practice, fitting to the shuffled data produces parameter values slightly different from zero, and controls for noise in the regression procedure.</p><p>We also considered two <italic>partial models</italic>, one to predict responses based on pupil size only, <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, and theÂ otherÂ to predict responses based on behavior only,Â <inline-formula><mml:math id="inf17"> <mml:mi/><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></inline-formula> in which the other regressor was shuffled in time. Thus, the pupil-only model accounted only for effects of pupil size,<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced> <mml:mi/></mml:math></disp-formula>and the task-only model accounted only for task engagement,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mi>b</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mi>b</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>These models tested the effects of a single state variable while ignoring the other.</p><p>By comparing performance of the full model to each partial model, we determined the unique contribution of each state variable to the neuronâs activity. We used a 20-fold, nested cross-validation procedure to evaluate model performance, which permitted using the full dataÂ set for both model fitting and validation without introducing bias from over-fitting. The model was fit to 95% of the data and used to predict the remaining 5%. Fit and test data were taken from interleaved trials. This procedure was repeated 20 times with nonoverlapping test sets, so that the final result was a prediction of the entire response. Model performance was then quantified by the fraction of variance explained, thatÂ is, the squared correlation coefficient, <italic>r</italic><sup>2</sup>, between the predicted and actual time-varying response. Variance uniquely explained by single state variables was calculated as the difference between <italic>r</italic><sup>2</sup> for the full model and for the partial model in which the relevant variable was shuffled in time.</p><p>When comparing pupil and neural data, a 750 ms offset was applied to pupil trace to account for the lagged relationship between changes in pupil size and neural activity in A1 (<xref ref-type="bibr" rid="bib46">McGinley et al., 2015</xref>).</p></sec><sec id="s4-11"><title>Modulation Index</title><p>To quantify the modulatory effects of task and pupil size on the firing rate of A1 and IC units, we computed a modulation index, <italic>MI</italic> (<xref ref-type="bibr" rid="bib53">Otazu et al., 2009</xref>; <xref ref-type="bibr" rid="bib66">Schwartz and David, 2018</xref>). The sound-evoked response was computed by averaging firing rate over the 750 ms duration of a stimulus presentation. <italic>MI</italic> was defined as the difference between the mean response to the same stimulus in two conditions, <italic>Î±</italic> and <italic>Î²</italic>, normalized by the sum,<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>Î±</mml:mi><mml:mi>Î²</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>Î±</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>Î±</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p><italic>MI</italic> could be calculated between different behavioral blocks or between state conditions. In the case of task engagement, <italic>MI</italic> was calculated between active and passive conditions, <italic>MI<sub>AP</sub></italic>. For pupil-dependent changes, data from an experiment were divided at the median pupil diameter, and <italic>MI<sub>LS</sub></italic> was computed between large pupil (above median, high arousal) and small pupil (below median, low arousal). To quantify theÂ differences between the first and the second passives, <italic>MI<sub>P1P2</sub></italic> was computed between the first and second passive blocks.</p><p>To quantifyÂ the changes in firing rates due to unique contributions of task condition or pupil size, we used <italic>MI</italic> to test how well the regression model could predict state-related changes in neural activity. The modulation between conditions <italic>Î±</italic> and <italic>Î²</italic> predicted by the full model is denotedÂ as <italic>MI<sub>Î±Î²</sub>Â full</italic>, where <italic>Î±</italic> and <italic>Î²</italic> are either active/passive (<italic>MI<sub>AP</sub>Â full</italic>) or large/small pupil (<italic>MI<sub>LS</sub>Â full</italic>). Similarly, modulations between conditions <italic>Î±</italic> and <italic>Î²</italic> predicted by the pupil partial model or the behavior partial model are denoted <italic>MI<sub>Î±Î²</sub> pupil-only</italic> and <italic>MI<sub>Î±Î²</sub> task-only</italic>, respectively. The <italic>MI</italic>Â uniquely predicted by including task engagement as a regressor is<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>â</mml:mo><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>that is, <italic>MIÂ </italic>predicted by the full model minus <italic>MIÂ </italic>predicted by a model in which behavior condition, but not pupil, is shuffled. The net result is the <italic>MIÂ </italic>predicted by task engagement above and beyond modulation predicted by changes in pupil size alone. Similarly, <italic>MIÂ </italic>uniquely predicted by including pupil size as a regressor is<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>â</mml:mo><mml:mi>M</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>l</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Significant effects of regressing out pupil size were quantified by comparing the signed-normalized differences between <italic>MI<sub>AP</sub> task-unique</italic> and <italic>MI<sub>AP</sub> task-only</italic> and differences of the same quantities across areas were quantified using a hierarchical bootstrap test (<xref ref-type="bibr" rid="bib61">Saravanan et al., 2020</xref>). Sign normalization was achieved by multiplying the difference between <italic>MI<sub>AP</sub> task-unique</italic> and <italic>MI<sub>AP</sub> task-only</italic> in each unit by the sign of their mean.</p><p>Significantly modulated units were determined by comparing Pearsonâs <italic>R</italic> coefficients associated with the full model and with the difference between the full model and the task and pupil partial models using jackknifed <italic>t</italic>-test with Î±Â =Â 0.05 (<xref ref-type="bibr" rid="bib16">Efron and Tibshirani, 1986</xref>).</p></sec><sec id="s4-12"><title>Statistical tests</title><p>Several analyses assessed changes in the median of repeatedly sampled data, <italic>e.g.</italic>, average pupil size measured across multiple behavior blocks (<xref ref-type="fig" rid="fig1">Figure 1</xref>) or average state-dependent modulation measured across multiple units (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig5">5</xref>â<xref ref-type="fig" rid="fig8">8</xref>). In this case, significant differences were assessed using a hierarchical bootstrap test (<xref ref-type="bibr" rid="bib61">Saravanan et al., 2020</xref>). The hierarchical bootstrap is nonparametric, like the more traditional Wilcoxon signed-rank test, but it accounts for potential bias resulting from the relatively small number of array recordings in the dataÂ set. A statistical test that treats each unit as an independent measure could potentially be biased if a single array recording produced spuriously large effects, and the hierarchical bootstrap controls for this possibility. The bootstrap analysis was run for 10,000 iterations, so that the minimum measurable <italic>p-</italic>value was 10<sup>â5</sup>. Thus, results that returned <italic>pÂ </italic>=Â 0 after this many iterations are reported as <italic>p</italic>Â &lt;Â 10<sup>â5</sup>.</p><p>State-dependent changes in individual neurons were assessed using a combination of nested cross-validation and a jackknife <italic>t</italic>-test (see above, <xref ref-type="bibr" rid="bib16">Efron and Tibshirani, 1986</xref>). To determine if any population-level effects depended on task performance or between animal differences, we used multivariate ANOVA (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This study was supported by NIH grants F31 DC014888 (DS),Â F31 DC016204Â (ZPS),Â R01 EB028155Â (SVD)Â and R01 DC0495 (SVD), by NSF grant GVPRS0015A2 (CRH) and byÂ the Tartar Trust at Oregon Health &amp; Science University (DS).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Formal analysis, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Software, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Software, Supervision, Funding acquisition, Methodology, Writing - original draft, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures were approved by the Oregon Health and Science University Institutional Animal Care and Use Committee (protocol IP1561) and conform to National Institutes of Health standards.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-60153-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Neurophysiology data is available via Zenodo. Software used for analysis is available via GitHub.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Saderi</surname><given-names>D</given-names></name><name><surname>Schwartz</surname><given-names>ZP</given-names></name><name><surname>Heller</surname><given-names>CR</given-names></name><name><surname>Pennington</surname><given-names>JR</given-names></name><name><surname>David</surname><given-names>SV</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Dissociation of task engagement and arousal effects in auditory cortex and midbrain -- dataset.</data-title><source>Zenodo</source><pub-id assigning-authority="Zenodo" pub-id-type="doi">10.5281/zenodo.4437077</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aitkin</surname> <given-names>LM</given-names></name><name><surname>Webster</surname> <given-names>WR</given-names></name><name><surname>Veale</surname> <given-names>JL</given-names></name><name><surname>Crosby</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Inferior colliculus. I. comparison of response properties of neurons in central, Pericentral, and external nuclei of adult cat</article-title><source>Journal of Neurophysiology</source><volume>38</volume><fpage>1196</fpage><lpage>1207</lpage><pub-id pub-id-type="doi">10.1152/jn.1975.38.5.1196</pub-id><pub-id pub-id-type="pmid">1177012</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atiani</surname> <given-names>S</given-names></name><name><surname>Elhilali</surname> <given-names>M</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Task difficulty and performance induce diverse adaptive patterns in gain and shape of primary auditory cortical receptive fields</article-title><source>Neuron</source><volume>61</volume><fpage>467</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.027</pub-id><pub-id pub-id-type="pmid">19217382</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atiani</surname> <given-names>S</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Elgueda</surname> <given-names>D</given-names></name><name><surname>Locastro</surname> <given-names>M</given-names></name><name><surname>Radtke-Schuller</surname> <given-names>S</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Emergent selectivity for task-relevant stimuli in higher-order auditory cortex</article-title><source>Neuron</source><volume>82</volume><fpage>486</fpage><lpage>499</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.02.029</pub-id><pub-id pub-id-type="pmid">24742467</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagur</surname> <given-names>S</given-names></name><name><surname>Averseng</surname> <given-names>M</given-names></name><name><surname>Elgueda</surname> <given-names>D</given-names></name><name><surname>David</surname> <given-names>S</given-names></name><name><surname>Fritz</surname> <given-names>J</given-names></name><name><surname>Yin</surname> <given-names>P</given-names></name><name><surname>Shamma</surname> <given-names>S</given-names></name><name><surname>Boubenec</surname> <given-names>Y</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Go/No-Go task engagement enhances population representation of target stimuli in primary auditory cortex</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2529</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04839-9</pub-id><pub-id pub-id-type="pmid">29955046</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakin</surname> <given-names>JS</given-names></name><name><surname>Weinberger</surname> <given-names>NM</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Classical conditioning induces CS-specific receptive field plasticity in the auditory cortex of the guinea pig</article-title><source>Brain Research</source><volume>536</volume><fpage>271</fpage><lpage>286</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(90)90035-A</pub-id><pub-id pub-id-type="pmid">2085753</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakin</surname> <given-names>JS</given-names></name><name><surname>Weinberger</surname> <given-names>NM</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Induction of a physiological memory in the cerebral cortex by stimulation of the nucleus basalis</article-title><source>PNAS</source><volume>93</volume><fpage>11219</fpage><lpage>11224</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.20.11219</pub-id><pub-id pub-id-type="pmid">8855336</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaton</surname> <given-names>R</given-names></name><name><surname>Miller</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Single cell activity in the auditory cortex of the unanesthetized, behaving monkey: correlation with stimulus controlled behavior</article-title><source>Brain Research</source><volume>100</volume><fpage>543</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(75)90157-2</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beatty</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Task-evoked pupillary responses, processing load, and the structure of processing resources</article-title><source>Psychological Bulletin</source><volume>91</volume><fpage>276</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.91.2.276</pub-id><pub-id pub-id-type="pmid">7071262</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Walker</surname> <given-names>KM</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Auditory cortex represents both pitch judgments and the corresponding acoustic cues</article-title><source>Current Biology</source><volume>23</volume><fpage>620</fpage><lpage>625</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.03.003</pub-id><pub-id pub-id-type="pmid">23523247</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Cohen</surname> <given-names>YE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The what, where and how of auditory-object perception</article-title><source>Nature Reviews Neuroscience</source><volume>14</volume><fpage>693</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1038/nrn3565</pub-id><pub-id pub-id-type="pmid">24052177</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Black</surname> <given-names>C</given-names></name><name><surname>Voigts</surname> <given-names>J</given-names></name><name><surname>Agrawal</surname> <given-names>U</given-names></name><name><surname>Ladow</surname> <given-names>M</given-names></name><name><surname>Santoyo</surname> <given-names>J</given-names></name><name><surname>Moore</surname> <given-names>C</given-names></name><name><surname>Jones</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Open ephys electroencephalography (Open ephys + EEG): a modular, low-cost, open-source solution to human neural recording</article-title><source>Journal of Neural Engineering</source><volume>14</volume><elocation-id>035002</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/aa651f</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brosch</surname> <given-names>M</given-names></name><name><surname>Selezneva</surname> <given-names>E</given-names></name><name><surname>Scheich</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Nonauditory events of a behavioral procedure activate auditory cortex of highly trained monkeys</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>6797</fpage><lpage>6806</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1571-05.2005</pub-id><pub-id pub-id-type="pmid">16033889</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carcea</surname> <given-names>I</given-names></name><name><surname>Insanally</surname> <given-names>MN</given-names></name><name><surname>Froemke</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamics of auditory cortical activity during behavioural engagement and auditory perception</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>14412</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms14412</pub-id><pub-id pub-id-type="pmid">28176787</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Task reward structure shapes rapid receptive field plasticity in auditory cortex</article-title><source>PNAS</source><volume>109</volume><fpage>2144</fpage><lpage>2149</lpage><pub-id pub-id-type="doi">10.1073/pnas.1117717109</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Downer</surname> <given-names>JD</given-names></name><name><surname>Niwa</surname> <given-names>M</given-names></name><name><surname>Sutter</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Task engagement selectively modulates neural correlations in primary auditory cortex</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>7565</fpage><lpage>7574</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4094-14.2015</pub-id><pub-id pub-id-type="pmid">25972181</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Efron</surname> <given-names>B</given-names></name><name><surname>Tibshirani</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy</article-title><source>Statistical Science</source><volume>1</volume><fpage>54</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1214/ss/1177013815</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eliades</surname> <given-names>SJ</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural substrates of vocalization feedback monitoring in primate auditory cortex</article-title><source>Nature</source><volume>453</volume><fpage>1102</fpage><lpage>1106</lpage><pub-id pub-id-type="doi">10.1038/nature06910</pub-id><pub-id pub-id-type="pmid">18454135</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Englitz</surname> <given-names>B</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Sorenson</surname> <given-names>MD</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MANTA--an open-source, high density electrophysiology recording suite for MATLAB</article-title><source>Frontiers in Neural Circuits</source><volume>7</volume><elocation-id>69</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2013.00069</pub-id><pub-id pub-id-type="pmid">23653593</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname> <given-names>J</given-names></name><name><surname>Shamma</surname> <given-names>S</given-names></name><name><surname>Elhilali</surname> <given-names>M</given-names></name><name><surname>Klein</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>1216</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1038/nn1141</pub-id><pub-id pub-id-type="pmid">14583754</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>Elhilali</surname> <given-names>M</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Differential dynamic plasticity of A1 receptive fields during multiple spectral tasks</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>7623</fpage><lpage>7635</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1318-05.2005</pub-id><pub-id pub-id-type="pmid">16107649</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>Elhilali</surname> <given-names>M</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Does attention play a role in dynamic receptive field adaptation to changing acoustic salience in A1?</article-title><source>Hearing Research</source><volume>229</volume><fpage>186</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2007.01.009</pub-id><pub-id pub-id-type="pmid">17329048</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>Radtke-Schuller</surname> <given-names>S</given-names></name><name><surname>Yin</surname> <given-names>P</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Adaptive, behaviorally gated, persistent encoding of task-relevant auditory information in ferret frontal cortex</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1011</fpage><lpage>1019</lpage><pub-id pub-id-type="doi">10.1038/nn.2598</pub-id><pub-id pub-id-type="pmid">20622871</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname> <given-names>Y</given-names></name><name><surname>Tucciarone</surname> <given-names>JM</given-names></name><name><surname>Espinosa</surname> <given-names>JS</given-names></name><name><surname>Sheng</surname> <given-names>N</given-names></name><name><surname>Darcy</surname> <given-names>DP</given-names></name><name><surname>Nicoll</surname> <given-names>RA</given-names></name><name><surname>Huang</surname> <given-names>ZJ</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A cortical circuit for gain control by behavioral state</article-title><source>Cell</source><volume>156</volume><fpage>1139</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.01.050</pub-id><pub-id pub-id-type="pmid">24630718</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilzenrat</surname> <given-names>MS</given-names></name><name><surname>Nieuwenhuis</surname> <given-names>S</given-names></name><name><surname>Jepma</surname> <given-names>M</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>10</volume><fpage>252</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.3758/CABN.10.2.252</pub-id><pub-id pub-id-type="pmid">20498349</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gittelman</surname> <given-names>JX</given-names></name><name><surname>Perkel</surname> <given-names>DJ</given-names></name><name><surname>Portfors</surname> <given-names>CV</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dopamine modulates auditory responses in the inferior colliculus in a heterogeneous manner</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>14</volume><fpage>719</fpage><lpage>729</lpage><pub-id pub-id-type="doi">10.1007/s10162-013-0405-0</pub-id><pub-id pub-id-type="pmid">23835945</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goard</surname> <given-names>M</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Basal forebrain activation enhances cortical coding of natural scenes</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1444</fpage><lpage>1449</lpage><pub-id pub-id-type="doi">10.1038/nn.2402</pub-id><pub-id pub-id-type="pmid">19801988</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname> <given-names>DM</given-names></name><name><surname>Swets</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruters</surname> <given-names>KG</given-names></name><name><surname>Groh</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sounds and beyond: multisensory and other non-auditory signals in the inferior colliculus</article-title><source>Frontiers in Neural Circuits</source><volume>6</volume><elocation-id>96</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2012.00096</pub-id><pub-id pub-id-type="pmid">23248584</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Habbicht</surname> <given-names>H</given-names></name><name><surname>Vater</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A microiontophoretic study of acetylcholine effects in the inferior colliculus of horseshoe bats: implications for a modulatory role</article-title><source>Brain Research</source><volume>724</volume><fpage>169</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(96)00224-7</pub-id><pub-id pub-id-type="pmid">8828565</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Heffner</surname> <given-names>HE</given-names></name><name><surname>Heffner</surname> <given-names>RS</given-names></name></person-group><year iso-8601-date="1995">1995</year><chapter-title>Conditioned Avoidance</chapter-title><person-group person-group-type="editor"><name><surname>Klump</surname> <given-names>G. M</given-names></name><name><surname>Dooling</surname> <given-names>R. J</given-names></name><name><surname>Fay</surname> <given-names>R. R</given-names></name><name><surname>Stebbins</surname> <given-names>W. C</given-names></name></person-group><source>Methods in Comparative PsychoacousticsÂ </source><publisher-loc>Basel</publisher-loc><publisher-name>Birkhauser Verlag</publisher-name><fpage>79</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1007/978-3-0348-7463-2</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hocherman</surname> <given-names>S</given-names></name><name><surname>Benson</surname> <given-names>DA</given-names></name><name><surname>Goldstein</surname> <given-names>MH</given-names></name><name><surname>Heffner</surname> <given-names>HE</given-names></name><name><surname>Hienz</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Evoked unit activity in auditory cortex of monkeys performing a selective attention task</article-title><source>Brain Research</source><volume>117</volume><fpage>51</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(76)90555-2</pub-id><pub-id pub-id-type="pmid">825193</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>Y</given-names></name><name><surname>Heil</surname> <given-names>P</given-names></name><name><surname>Brosch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Associations between sounds and actions in early auditory cortex of nonhuman primates</article-title><source>eLife</source><volume>8</volume><elocation-id>e43281</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.43281</pub-id><pub-id pub-id-type="pmid">30946010</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hurley</surname> <given-names>LM</given-names></name><name><surname>Pollak</surname> <given-names>GD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Serotonin shifts first-spike latencies of inferior colliculus neurons</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>7876</fpage><lpage>7886</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1178-05.2005</pub-id><pub-id pub-id-type="pmid">16120790</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaramillo</surname> <given-names>S</given-names></name><name><surname>Zador</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The auditory cortex mediates the perceptual effects of acoustic temporal expectation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>246</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1038/nn.2688</pub-id><pub-id pub-id-type="pmid">21170056</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname> <given-names>S</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Kalwani</surname> <given-names>RM</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, Colliculi, and cingulate cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahneman</surname> <given-names>D</given-names></name><name><surname>Beatty</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Pupil diameter and load on memory</article-title><source>Science</source><volume>154</volume><fpage>1583</fpage><lpage>1585</lpage><pub-id pub-id-type="doi">10.1126/science.154.3756.1583</pub-id><pub-id pub-id-type="pmid">5924930</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname> <given-names>JB</given-names></name><name><surname>Kavanagh</surname> <given-names>GL</given-names></name><name><surname>Dalton</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Hearing in the ferret (Mustela putorius): thresholds for pure tone detection</article-title><source>Hearing Research</source><volume>24</volume><fpage>269</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(86)90025-0</pub-id><pub-id pub-id-type="pmid">3793642</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname> <given-names>DJ</given-names></name><name><surname>Depireux</surname> <given-names>DA</given-names></name><name><surname>Simon</surname> <given-names>JZ</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Robust spectrotemporal reverse correlation for the auditory system: optimizing stimulus design</article-title><source>Journal of Computational Neuroscience</source><volume>9</volume><fpage>85</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1023/a:1008990412183</pub-id><pub-id pub-id-type="pmid">10946994</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knudsen</surname> <given-names>DP</given-names></name><name><surname>Gentner</surname> <given-names>TQ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Active recognition enhances the representation of behaviorally relevant information in single auditory forebrain neurons</article-title><source>Journal of Neurophysiology</source><volume>109</volume><fpage>1690</fpage><lpage>1703</lpage><pub-id pub-id-type="doi">10.1152/jn.00461.2012</pub-id><pub-id pub-id-type="pmid">23303858</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knyazeva</surname> <given-names>S</given-names></name><name><surname>Selezneva</surname> <given-names>E</given-names></name><name><surname>Gorkin</surname> <given-names>A</given-names></name><name><surname>Ohl</surname> <given-names>FW</given-names></name><name><surname>Brosch</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Representation of auditory task components and of their relationships in primate auditory cortex</article-title><source>Frontiers in Neuroscience</source><volume>14</volume><elocation-id>306</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2020.00306</pub-id><pub-id pub-id-type="pmid">32372903</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuchibhotla</surname> <given-names>KV</given-names></name><name><surname>Gill</surname> <given-names>JV</given-names></name><name><surname>Lindsay</surname> <given-names>GW</given-names></name><name><surname>Papadoyannis</surname> <given-names>ES</given-names></name><name><surname>Field</surname> <given-names>RE</given-names></name><name><surname>Sten</surname> <given-names>TA</given-names></name><name><surname>Miller</surname> <given-names>KD</given-names></name><name><surname>Froemke</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Parallel processing by cortical inhibition enables context-dependent behavior</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>62</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1038/nn.4436</pub-id><pub-id pub-id-type="pmid">27798631</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>La Camera</surname> <given-names>G</given-names></name><name><surname>Fontanini</surname> <given-names>A</given-names></name><name><surname>Mazzucato</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical computations via metastable activity</article-title><source>Current Opinion in Neurobiology</source><volume>58</volume><fpage>37</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.06.007</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>Musacchia</surname> <given-names>G</given-names></name><name><surname>O'Connel</surname> <given-names>MN</given-names></name><name><surname>Falchier</surname> <given-names>AY</given-names></name><name><surname>Javitt</surname> <given-names>DC</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The spectrotemporal filter mechanism of auditory selective attention</article-title><source>Neuron</source><volume>77</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.034</pub-id><pub-id pub-id-type="pmid">23439126</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>CC</given-names></name><name><surname>Middlebrooks</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Auditory cortex spatial sensitivity sharpens during task performance</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>108</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1038/nn.2713</pub-id><pub-id pub-id-type="pmid">21151120</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>PA</given-names></name><name><surname>Asinof</surname> <given-names>SK</given-names></name><name><surname>Edwards</surname> <given-names>NJ</given-names></name><name><surname>Isaacson</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Arousal regulates frequency tuning in primary auditory cortex</article-title><source>PNAS</source><volume>116</volume><fpage>25304</fpage><lpage>25310</lpage><pub-id pub-id-type="doi">10.1073/pnas.1911383116</pub-id><pub-id pub-id-type="pmid">31757852</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname> <given-names>MJ</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name><name><surname>McCormick</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title><source>Neuron</source><volume>87</volume><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.038</pub-id><pub-id pub-id-type="pmid">26074005</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Metzger</surname> <given-names>RR</given-names></name><name><surname>Greene</surname> <given-names>NT</given-names></name><name><surname>Porter</surname> <given-names>KK</given-names></name><name><surname>Groh</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Effects of reward and behavioral context on neural activity in the primate inferior colliculus</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>7468</fpage><lpage>7476</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5401-05.2006</pub-id><pub-id pub-id-type="pmid">16837595</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname> <given-names>DR</given-names></name><name><surname>Semple</surname> <given-names>MN</given-names></name><name><surname>Addison</surname> <given-names>PD</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Some acoustic properties of neurones in the ferret inferior colliculus</article-title><source>Brain Research</source><volume>269</volume><fpage>69</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(83)90963-0</pub-id><pub-id pub-id-type="pmid">6871703</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Motts</surname> <given-names>SD</given-names></name><name><surname>Schofield</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Sources of cholinergic input to the inferior colliculus</article-title><source>Neuroscience</source><volume>160</volume><fpage>103</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2009.02.036</pub-id><pub-id pub-id-type="pmid">19281878</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname> <given-names>S</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Juavinett</surname> <given-names>AL</given-names></name><name><surname>Gluf</surname> <given-names>S</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niwa</surname> <given-names>M</given-names></name><name><surname>Johnson</surname> <given-names>JS</given-names></name><name><surname>O'Connor</surname> <given-names>KN</given-names></name><name><surname>Sutter</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Active engagement improves primary auditory cortical neurons' ability to discriminate temporal modulation</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>9323</fpage><lpage>9334</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5832-11.2012</pub-id><pub-id pub-id-type="pmid">22764239</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otazu</surname> <given-names>GH</given-names></name><name><surname>Tai</surname> <given-names>LH</given-names></name><name><surname>Yang</surname> <given-names>Y</given-names></name><name><surname>Zador</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Engaging in an auditory task suppresses responses in auditory cortex</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>646</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1038/nn.2306</pub-id><pub-id pub-id-type="pmid">19363491</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Kadir</surname> <given-names>S</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/061481</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulet</surname> <given-names>JF</given-names></name><name><surname>Petersen</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internal brain state regulates membrane potential synchrony in barrel cortex of behaving mice</article-title><source>Nature</source><volume>454</volume><fpage>881</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1038/nature07150</pub-id><pub-id pub-id-type="pmid">18633351</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname> <given-names>J</given-names></name><name><surname>McGinley</surname> <given-names>MJ</given-names></name><name><surname>Liu</surname> <given-names>Y</given-names></name><name><surname>Rodenkirch</surname> <given-names>C</given-names></name><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>McCormick</surname> <given-names>DA</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13289</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id><pub-id pub-id-type="pmid">27824036</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringach</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spontaneous and driven cortical activity: implications for computation</article-title><source>Current Opinion in Neurobiology</source><volume>19</volume><fpage>439</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2009.07.005</pub-id><pub-id pub-id-type="pmid">19647992</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodgers</surname> <given-names>CC</given-names></name><name><surname>DeWeese</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural correlates of task switching in prefrontal cortex and primary auditory cortex in a novel stimulus selection task for rodents</article-title><source>Neuron</source><volume>82</volume><fpage>1157</fpage><lpage>1170</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.031</pub-id><pub-id pub-id-type="pmid">24908492</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Runyan</surname> <given-names>CA</given-names></name><name><surname>Piasini</surname> <given-names>E</given-names></name><name><surname>Panzeri</surname> <given-names>S</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct timescales of population coding across cortex</article-title><source>Nature</source><volume>548</volume><fpage>92</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1038/nature23020</pub-id><pub-id pub-id-type="pmid">28723889</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ryan</surname> <given-names>A</given-names></name><name><surname>Miller</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Effects of behavioral performance on single-unit firing patterns in inferior colliculus of the rhesus monkey</article-title><source>Journal of Neurophysiology</source><volume>40</volume><fpage>943</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1152/jn.1977.40.4.943</pub-id><pub-id pub-id-type="pmid">407335</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Saravanan</surname> <given-names>V</given-names></name><name><surname>Berman</surname> <given-names>GJ</given-names></name><name><surname>Sober</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Application of the hierarchical bootstrap to Multi-Level data in neuroscience</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/819334</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satpute</surname> <given-names>AB</given-names></name><name><surname>Kragel</surname> <given-names>PA</given-names></name><name><surname>Barrett</surname> <given-names>LF</given-names></name><name><surname>Wager</surname> <given-names>TD</given-names></name><name><surname>Bianciardi</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Deconstructing arousal into wakeful, autonomic and affective varieties</article-title><source>Neuroscience Letters</source><volume>693</volume><fpage>19</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1016/j.neulet.2018.01.042</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname> <given-names>DM</given-names></name><name><surname>Nelson</surname> <given-names>A</given-names></name><name><surname>Mooney</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A synaptic and circuit basis for corollary discharge in the auditory cortex</article-title><source>Nature</source><volume>513</volume><fpage>189</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature13724</pub-id><pub-id pub-id-type="pmid">25162524</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schriver</surname> <given-names>BJ</given-names></name><name><surname>Bagdasarov</surname> <given-names>S</given-names></name><name><surname>Wang</surname> <given-names>Q</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupil-linked arousal modulates behavior in rats performing a whisker deflection direction discrimination task</article-title><source>Journal of Neurophysiology</source><volume>120</volume><fpage>1655</fpage><lpage>1670</lpage><pub-id pub-id-type="doi">10.1152/jn.00290.2018</pub-id><pub-id pub-id-type="pmid">29995602</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname> <given-names>ZP</given-names></name><name><surname>Buran</surname> <given-names>BN</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil-associated states modulate excitability but not stimulus selectivity in primary auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>123</volume><fpage>191</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1152/jn.00595.2019</pub-id><pub-id pub-id-type="pmid">31721652</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname> <given-names>ZP</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Focal suppression of distractor sounds by selective attention in auditory cortex</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>323</fpage><lpage>339</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx288</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname> <given-names>DM</given-names></name><name><surname>Zilany</surname> <given-names>MS</given-names></name><name><surname>Skevington</surname> <given-names>M</given-names></name><name><surname>Huang</surname> <given-names>NJ</given-names></name><name><surname>Flynn</surname> <given-names>BC</given-names></name><name><surname>Carney</surname> <given-names>LH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Semi-supervised spike sorting using pattern matching and a scaled mahalanobis distance metric</article-title><source>Journal of Neuroscience Methods</source><volume>206</volume><fpage>120</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2012.02.013</pub-id><pub-id pub-id-type="pmid">22387262</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamma</surname> <given-names>SA</given-names></name><name><surname>Fleshman</surname> <given-names>JW</given-names></name><name><surname>Wiser</surname> <given-names>PR</given-names></name><name><surname>Versnel</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Organization of response Areas in ferret primary auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>69</volume><fpage>367</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.69.2.367</pub-id><pub-id pub-id-type="pmid">8459273</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shobe</surname> <given-names>JL</given-names></name><name><surname>Claar</surname> <given-names>LD</given-names></name><name><surname>Parhami</surname> <given-names>S</given-names></name><name><surname>Bakhurin</surname> <given-names>KI</given-names></name><name><surname>Masmanidis</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Brain activity mapping at multiple scales with silicon microprobes containing 1,024 electrodes</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>2043</fpage><lpage>2052</lpage><pub-id pub-id-type="doi">10.1152/jn.00464.2015</pub-id><pub-id pub-id-type="pmid">26133801</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname> <given-names>JZ</given-names></name><name><surname>Depireux</surname> <given-names>DA</given-names></name><name><surname>Klein</surname> <given-names>DJ</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Temporal symmetry in primary auditory cortex: implications for cortical connectivity</article-title><source>Neural Computation</source><volume>19</volume><fpage>583</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.3.583</pub-id><pub-id pub-id-type="pmid">17298227</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slee</surname> <given-names>SJ</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rapid Task-Related plasticity of spectrotemporal receptive fields in the auditory midbrain</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>13090</fpage><lpage>13102</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1671-15.2015</pub-id><pub-id pub-id-type="pmid">26400939</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanislaw</surname> <given-names>H</given-names></name><name><surname>Todorov</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Calculation of signal detection theory measures</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><volume>31</volume><fpage>137</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.3758/BF03207704</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Reddy</surname> <given-names>CB</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>eaav7893</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorson</surname> <given-names>IL</given-names></name><name><surname>LiÃ©nard</surname> <given-names>J</given-names></name><name><surname>David</surname> <given-names>SV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The essential complexity of auditory receptive fields</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004628</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004628</pub-id><pub-id pub-id-type="pmid">26683490</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsunada</surname> <given-names>J</given-names></name><name><surname>Liu</surname> <given-names>AS</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Cohen</surname> <given-names>YE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Causal contribution of primate auditory cortex to auditory perceptual decision-making</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>135</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1038/nn.4195</pub-id><pub-id pub-id-type="pmid">26656644</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname> <given-names>M</given-names></name><name><surname>Batista-Brito</surname> <given-names>R</given-names></name><name><surname>Knoblich</surname> <given-names>U</given-names></name><name><surname>Cardin</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id><pub-id pub-id-type="pmid">25892300</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname> <given-names>RD</given-names></name><name><surname>Schmitt</surname> <given-names>LI</given-names></name><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Nakajima</surname> <given-names>M</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Halassa</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Thalamic control of sensory selection in divided attention</article-title><source>Nature</source><volume>526</volume><fpage>705</fpage><lpage>709</lpage><pub-id pub-id-type="doi">10.1038/nature15398</pub-id><pub-id pub-id-type="pmid">26503050</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winer</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Decoding the auditory corticofugal systems</article-title><source>Hearing Research</source><volume>212</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2005.06.014</pub-id><pub-id pub-id-type="pmid">16555378</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winn</surname> <given-names>MB</given-names></name><name><surname>Edwards</surname> <given-names>JR</given-names></name><name><surname>Litovsky</surname> <given-names>RY</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The impact of auditory spectral resolution on listening effort revealed by pupil dilation</article-title><source>Ear &amp; Hearing</source><volume>36</volume><fpage>e153</fpage><lpage>e165</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000000145</pub-id><pub-id pub-id-type="pmid">25654299</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname> <given-names>P</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Do ferrets perceive relative pitch?</article-title><source>The Journal of the Acoustical Society of America</source><volume>127</volume><fpage>1673</fpage><lpage>1680</lpage><pub-id pub-id-type="doi">10.1121/1.3290988</pub-id><pub-id pub-id-type="pmid">20329865</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname> <given-names>P</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name><name><surname>Shamma</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Rapid spectrotemporal plasticity in primary auditory cortex during behavior</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>4396</fpage><lpage>4408</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2799-13.2014</pub-id><pub-id pub-id-type="pmid">24647959</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zekveld</surname> <given-names>AA</given-names></name><name><surname>Koelewijn</surname> <given-names>T</given-names></name><name><surname>Kramer</surname> <given-names>SE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The pupil dilation response to auditory stimuli: current state of knowledge</article-title><source>Trends in Hearing</source><volume>22</volume><elocation-id>233121651877717</elocation-id><pub-id pub-id-type="doi">10.1177/2331216518777174</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>M</given-names></name><name><surname>Liang</surname> <given-names>F</given-names></name><name><surname>Xiong</surname> <given-names>XR</given-names></name><name><surname>Li</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>H</given-names></name><name><surname>Xiao</surname> <given-names>Z</given-names></name><name><surname>Tao</surname> <given-names>HW</given-names></name><name><surname>Zhang</surname> <given-names>LI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Scaling down of balanced excitation and inhibition by active behavioral states in auditory cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>841</fpage><lpage>850</lpage><pub-id pub-id-type="doi">10.1038/nn.3701</pub-id><pub-id pub-id-type="pmid">24747575</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60153.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Carr</surname><given-names>Catherine Emily</given-names></name><role>Reviewer</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This study distinguishes effects of generalized arousal and specific task engagement on the activity of neurons in the inferior colliculus and auditory cortex of ferrets as they engaged in a tone detection task while monitoring arousal via pupillometry. The authors found that arousal effects were more prominent in IC, while arousal and engagement effects were equally likely in A1. Task engagement was correlated with increased arousal. The authors propose that there is a hierarchy such that generalized arousal enhances activity in the midbrain, and task engagement effects are more prominent in cortex, showing that the effects of brain state and behavioral context are area specific.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Dissociation of task engagement and arousal effects in auditory cortex and midbrain&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Catherine Emily Carr as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Andrew King as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require a modest amount of additional new data, as they do with your paper, we are asking that the manuscript be revised to either limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Summary</p><p>Saderi and her colleagues have attempted to determine whether and how two behavior-related variables â arousal and task engagement â differently influence activity in two stages of the auditory neuraxis, IC and A1. They define arousal as pupil diameter and task-engagement as a binary variable determined by the experimental block design. They find that although these two parameters often co-vary, they sometimes do not. They find that IC was more influenced by arousal and A1 was modulated by both arousal and engagement. One of their main findings is that previous reports of task-engagement effects may in fact be attributed to arousal state.</p><p>Essential revisions</p><p>1) The major concern is the use of a continuous readout of arousal (i.e. pupil diameter) with a binary readout of task-engagement (i.e. the block the animal is in at any moment). The reviewers would like to know if task engagement be explained more rigorously as a continuous rather than binary variable. One notes that when training and testing animals on appetitive behaviors, task engagement can wax and wane within a single block, across an experimental recording session, or across days of behavioral testing. Such changes in engagement can be inferred, for example, as strings of (seemingly) easy trials in which the animal does not answer correctly. The authors should attempt to quantify through behavioral analysis (running lapse rate, lick latency, etc) whether and how task engagement may be changing within and across task blocks. Alternatively, the authors could clearly explain that their binary encoding of engagement has limitations and may not actually describe the animal's engagement at any given moment.</p><p>2) Can a continuous readout of task engagement better explain neural activity? For many neurons, task-engagement does not provide unique predictive information, yet for others it does (e.g. Figure 3C). If task engagement can be modeled as a continuous rather than binary variable, is it still true that &quot;some apparent effects of task engagement should in fact be attributed to fluctuations in arousal&quot; (Abstract)? There is a concern that the current analysis maybe a floor on task-related modulations since it assumes constant engagement throughout a task block.</p><p>3) Can neural heterogeneity be attributed to animal-to-animal behavioral variability? Even if task engagement does not vary within a task block for any one animal, it may indeed vary across animals. In theory, the actual task engagement of some animals might more closely mirror the block design that the experimenters are imposing, and some animals may simply have a higher level of engagement than others. This could mean that some results that are currently attributed to population-level heterogeneity (e.g. some A1 neurons do this, while others do that) might actually be attributed to animal-to-animal heterogeneity as opposed to distinct neural populations. For example, the authors state that for a subset of neurons, persistent task-like activity after a block change can be accounted for by pupil size, whereas for other neurons this effect cannot (Figure 7). The authors should confirm that key findings are consistent across animals and not related to degrees of task engagement (see point #1). If the findings are not consistent across animals but can be explained by each animals' unique behavior, this would also be really cool.</p><p>4) With respect to recordings, the authors should clearly distinguish single units from multi-units. This is described in the Materials and methods, but referred to later in the manuscript.</p><p>5) With respect to analyses, there are questions regarding the independence of many of the data points (e.g. neurons recorded simultaneously or from the same animals, same sessions, etc.), and how this interdependence might contribute to some of the findings. Relatedly, could some neural effects can be accounted for by the animals from which they were recorded (and from that particular animal's behavior)?</p><p>6) With respect to novelty, some of the ground covered in this report has been covered before. Using a different experimental approach, the study of Knyazeva et al., 2020, Front Neurosci. 14: 306 already suggested that the discharges of many neurons in AC are affected by arousal, that task effects can disappear if effects of arousal have been accounted for, and that there is no systematic difference in response modulation between neurons tuned, or not tuned, to task-relevant sounds. Dissociations of the effects of different non-auditory factors on sound responses in AC have also been described by Zhou et al., 2014, and by Carcea et al., 2017. This work should be discussed.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your article &quot;Dissociation of task engagement and arousal effects in auditory cortex and midbrain&quot; for consideration by <italic>eLife</italic>. Your revised article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Andrew King as the Senior Editor.</p><p>A concern remains. One reviewer noted âit appears that data from only about 20 behavioral sessions entered analysesâ. The reviewer was concerned that neurons simultaneously recorded in the same session were statistically more dependent than neurons recorded in different sessions. In your revised manuscript please include the number of animals from which the pupil data and the neuronal data were obtained, state why one animal was not considered for neuronal data (it appears that there were four animals in total of which three provided neuronal data) and include the total number of sessions for pupil data and the total number of sessions for neuronal data in each animal. The reviewer was concerned about what can be inferred from these sample sizes. Please also include a statement that the results on the effects of task engagement may not apply to all auditory tasks.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60153.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions</p><p>1) The major concern is the use of a continuous readout of arousal (i.e. pupil diameter) with a binary readout of task-engagement (i.e. the block the animal is in at any moment). The reviewers would like to know if task engagement be explained more rigorously as a continuous rather than binary variable. One notes that when training and testing animals on appetitive behaviors, task engagement can wax and wane within a single block, across an experimental recording session, or across days of behavioral testing. Such changes in engagement can be inferred, for example, as strings of (seemingly) easy trials in which the animal does not answer correctly. The authors should attempt to quantify through behavioral analysis (running lapse rate, lick latency, etc) whether and how task engagement may be changing within and across task blocks. Alternatively, the authors could clearly explain that their binary encoding of engagement has limitations and may not actually describe the animal's engagement at any given moment.</p></disp-quote><p>We agree completely that treating task engagement as a binary variable is problematic. In fact, this concern was a key motivation for the current study, which determined how much of a canonical âtask engagementâ effect (reported in many studiesâDowner et al., 2015; Fritz et al., 2005, 2003; Knudsen and Gentner, 2013; Kuchibhotla et al., 2017; Lee and Middlebrooks, 2011; Otazu et al., 2009; Ryan and Miller, 1977; Yin et al., 2014) can be explained by pupil-indexed arousal. A change in pupil size may itself also not reflect a single neural process, but we argue in the Discussion that it is closer constituent of a behavioral state than the binary task engagement variable.</p><p>More to the reviewerâs point, the effects of task engagement that cannot be explained by pupil size are still likely not to reflect a single, binary variable. Early in the project, we explored several more fine-grained models that broke down engagement based on behavioral performance, but these were not pursued because they did not provide additional explanatory power in our initial dataset. However, we revisited this question for the full dataset and identified an effect of task performance that was not apparent earlier.</p><p>In the revised manuscript, we compared the magnitude of task engagement effects on neural activity to behavioral performance (measured by sensitivity, <italic>d</italic>â) on each behavioral block. <italic>d</italic>â is higher when animals tend to respond correctly (high hit rate, low false alarm rate). When we tested the relationship between <italic>d</italic>â and engagement effects, we found a correlation in A1 but not IC. We also found no relationship between behavioral performance and pupil-related changes in neural activity in either area.</p><p>To study performance-dependent variability on a finer timescale, we formulated a more complex model with two additional regressorsâthe moving average of hit rate and false alarm rate over a 3 minute window (~25 trials). A model including these new regressors explained some additional neural variability over the original binary engagement model. However, it did not improve accuracy over the block-wise performance-dependent model described in the previous paragraph. We elected to not include this model in the revision because of its complexity and the fact that the block-wise performance model demonstrated the critical result that some task-related effects depend on behavioral performance.</p><p>In sum, our new analysis confirms that, even after accounting for pupil-related effects on neural activity, task engagement is in fact not a binary variable. This result also provides additional evidence for functional differences between A1 and IC. We now include the analysis of performance dependence in a new Figure (Figure 4):</p><p>These results are also described in the text:</p><p>âThe analysis above treated task engagement as a discrete, binary variable, switching between active and passive states. However, behavioral performance, measured by dâ, varied substantially between animals and behavior blocks (Figure 1C). We reasoned that performance represents a more graded measure of task engagement and thus may explain variability in task-related changes across experiments. Indeed, we found a significant correlation between dâ and the unique variance explained by task in A1 (<italic>r</italic><sup>2</sup> task unique; <italic>r</italic> = 0.303, <italic>p</italic> = 0.00019; Figure 4A, left). The same relationship was not observed in IC (<italic>r</italic> = 0.069, <italic>p</italic> = 0.580; Figure 4A, right), nor was there a relationship between dâ and unique variance explained by pupil in either area (<italic>r</italic><sup>2</sup> pupil unique; A1: <italic>r</italic> = 0.113, <italic>p</italic> = 0.139; IC: r = -0.017, <italic>p</italic> = 0.892, Figure 4B). Thus, in A1, effects of task engagement cannot be described by a binary variable, even after dissociating effects of pupil. Instead, effects of task engagement are comprised of at least one process that varies continuously between more and less accurate behavior.â</p><p>To emphasize that finer timescale analysis such as the moving average model might be valuable when adequate data are available, we highlight this as a valuable future direction for identifying important task-related state variables:</p><p>âLarger datasets that track continuous fluctuations in performance are likely to be able to measure fluctuations of task engagement effects within behavior blocks.â</p><disp-quote content-type="editor-comment"><p>2) Can a continuous readout of task engagement better explain neural activity? For many neurons, task-engagement does not provide unique predictive information, yet for others it does (e.g. Figure 3C). If task engagement can be modeled as a continuous rather than binary variable, is it still true that &quot;some apparent effects of task engagement should in fact be attributed to fluctuations in arousal&quot; (Abstract)? There is a concern that the current analysis maybe a floor on task-related modulations since it assumes constant engagement throughout a task block.</p></disp-quote><p>We agree that âtask engagementâ is not a discrete, binary variable. Our formulation was a simplification, motivated by the limited statistical power available in the experimental data. However, the analysis described above demonstrates an additional dependence on task performance that we have added in a new figure in the revised manuscript. See reply to #1 for details.</p><p>We would also like to point out that theories have been developed around network attractor states, and that engaging in a task could actually produce a stable shift in neural network dynamics (Le Camera et al. 2019). Thus, while unlikely to be the whole story, the idea of a discrete (if not binary) variable is not completely far-fetched. We have also clarified issues around the meaning of âtask engagementâ in the Discussion.</p><p>âIt remains unclear how smoothly internal state can vary. Theories of network attractors suggest that there may in fact be discrete changes in brain state associated with different behavioral context (La Camera et al., 2019). Thus, while clearly task engagement is not binary, it could still comprise multiple metastable states.â</p><disp-quote content-type="editor-comment"><p>3) Can neural heterogeneity be attributed to animal-to-animal behavioral variability? Even if task engagement does not vary within a task block for any one animal, it may indeed vary across animals. In theory, the actual task engagement of some animals might more closely mirror the block design that the experimenters are imposing, and some animals may simply have a higher level of engagement than others. This could mean that some results that are currently attributed to population-level heterogeneity (e.g. some A1 neurons do this, while others do that) might actually be attributed to animal-to-animal heterogeneity as opposed to distinct neural populations. For example, the authors state that for a subset of neurons, persistent task-like activity after a block change can be accounted for by pupil size, whereas for other neurons this effect cannot (Figure 7). The authors should confirm that key findings are consistent across animals and not related to degrees of task engagement (see point #1). If the findings are not consistent across animals but can be explained by each animals' unique behavior, this would also be really cool.</p></disp-quote><p>Thanks for raising this point. When we went back to the data to look at the relationship between performance and task effects, we also observed differences in both the size of task engagement effects in A1 and behavioral performance (<italic>d</italic>â) between animals. These were correlated, and when we performed multiple regression, we found that the differences in neural activity between animals could be explained completely by <italic>d</italic>â. So indeed, as the reviewer suggests, there are differences between animals, which are reflected in <italic>d</italic>â. These analyses are detailed in new figures and in the Results (Figure 4):</p><p>âWe also observed that both <italic>d</italic>â and task engagement effects in A1 differed between animals (Figures 4, Figure 4âfigure supplement 1). We wondered if the differences in neural modulation could be fully explained by behavioral performance or if they reflected additional between-animal differences. To answer this question, we performed a multiple regression with both <italic>d</italic>â and animal identity as independent variables. This analysis revealed that in A1 <italic>d</italic>â could fully explain the differences in modulation for task engagement (<italic>d</italic>â: <italic>F</italic> = 16.0, <italic>p</italic> = 0.000093; animal: <italic>F</italic> = 0.66, <italic>p</italic> = 0.52). Neither <italic>d</italic>â or animal significantly predicted task engagement effects in IC (<italic>d</italic>â: <italic>F</italic> = 1.11, <italic>p</italic> = 0.29; animal: <italic>F</italic> = 0.22, <italic>p</italic> = 0.80). A similar analysis of pupil-related effects revealed that <italic>r</italic><sup>2</sup> pupil unique did not depend on <italic>d</italic>â, although it did depend on the amount of pupil variability within an experiment (Figure 4âfigure supplement 1). Thus, differences in task engagement effects between animals could be explained by differences in the accuracy with which they performed the task.â</p><p>As suggested, we also compared changes in post- versus pre-passive responses across animals and found no significant difference. This is reported in the revision:</p><p>âThis change was not significantly different between animals in A1 (<italic>F</italic> = 0.669, <italic>p</italic> = 0.516, one-way ANOVA) or in IC (<italic>F</italic> = 0.446, <italic>p</italic> = 0.643).â</p><disp-quote content-type="editor-comment"><p>4) With respect to recordings, the authors should clearly distinguish single units from multi-units. This is described in the Materials and methods, but referred to later in the manuscript.</p></disp-quote><p>This is a good question. We compared multi- and single-unit data and didnât find significant differences between arousal or engagement effects in either A1 or IC. We include this analysis in a new supplemental figure.</p><p>âThese effects were not significantly different between single- and multi-unit data in either area (Figure 3âfigure supplement 1).â</p><disp-quote content-type="editor-comment"><p>5) With respect to analyses, there are questions regarding the independence of many of the data points (e.g. neurons recorded simultaneously or from the same animals, same sessions, etc.), and how this interdependence might contribute to some of the findings. Relatedly, could some neural effects can be accounted for by the animals from which they were recorded (and from that particular animal's behavior)?</p></disp-quote><p>We agree, it is important to consider potential differences between animals. Our new analysis finds that there are in fact differences in behavioral performance (<italic>d</italic>â) between animals. While there are no significant differences in task engagement effects between animals, there is a relationship between performance (<italic>d</italic>â) and neural effects (see reply to #1 and #3 above). We have added figures describing these results (Figures 4, Figure 4âfigure supplement 1). See quoted figure/text in the reply to #1 above.</p><disp-quote content-type="editor-comment"><p>6) With respect to novelty, some of the ground covered in this report has been covered before. Using a different experimental approach, the study of Knyazeva et al., 2020 already suggested that the discharges of many neurons in AC are affected by arousal, that task effects can disappear if effects of arousal have been accounted for, and that there is no systematic difference in response modulation between neurons tuned, or not tuned, to task-relevant sounds. Dissociations of the effects of different non-auditory factors on sound responses in AC have also been described by Zhou et al., 2014, and by Carcea et al., 2017. This work should be discussed.</p></disp-quote><p>The studies cited by the reviewer are quite relevant to the current study, in having demonstrated effects of behavioral state that are distinct from task engagement. In the case of Zhou et al., the motor activation is likely to be closely related to pupil-indexed arousal measured in our study. In the case of Knyazeva et al. and Carea et al., it is clear that changing the rules of behavior impacts neural coding and further amplifies the points that âtask engagementâ is not a binary variable. While none of these studies measured pupil, it is likely that some of the changes they report could be explained by pupil-indexed arousal while others may be explained by mechanisms that produce performance-dependent changes during task engagement.</p><p>In the spirit of the task structure effects (Knyazeva and Carea studies), we tested for a dependence on task difficulty in the original manuscript (now Figure 6âfigure supplement 2). We now cite these previous studies in our description of this analysis in the Results, as well as incorporate all of this literature into more general points in the Introduction and Discussion:</p><p>âIntroduction: Task-related changes in the activity of auditory neurons have been attributed to temporal expectation (Jaramillo and Zador, 2011), reward associations (Beaton and Miller, 1975; David et al., 2012), self-generated sound (Eliades and Wang, 2008), and non-sound related variables, such as motor planning (Bizley et al., 2013; Huang et al., 2019), motor activity (Schneider et al., 2014; Zhou et al., 2014), degree of engagement (Carcea et al., 2017; Knyazeva et al., 2020), and behavioral choice (Tsunada et al., 2015).â</p><p>âResults: Task engagement effects could also depend on the difficulty or other structural elements of the task (Carcea et al., 2017; Knyazeva et al., 2020). We considered whether state-dependent effects varied with task difficulty but found no differences between pure tone, high SNR tone-in-noise (easy), and low SNR tone-in-noise (hard) conditions (Figure 6âfigure supplement 2).â</p><p>âDiscussion: The current results illustrate that a binary task engagement variable is better described by a combination of pupil size and accuracy of behavioral performance. Other characterizations of task engagement have argued similarly that the degree of engagement can vary, even when relevant acoustic stimuli are held fixed (Atiani et al., 2009; Carcea et al., 2017; Knyazeva et al., 2020; McGinley et al., 2015; Zhou et al., 2014). Larger datasets that track continuous fluctuations in performance are likely to be able to measure fluctuations of task engagement effects within behavior blocks. It remains unclear how smoothly internal state can vary. Theories of network attractors suggest that there may in fact be discrete changes in brain state associated with different behavioral contexts (La Camera et al., 2019). Thus, while task engagement is clearly not binary, it could still comprise multiple metastable states.â</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>A concern remains. One reviewer noted âit appears that data from only about 20 behavioral sessions entered analysesâ. The reviewer was concerned that neurons simultaneously recorded in the same session were statistically more dependent than neurons recorded in different sessions. In your revised manuscript please include the number of animals from which the pupil data and the neuronal data were obtained, state why one animal was not considered for neuronal data (it appears that there were four animals in total of which three provided neuronal data) and include the total number of sessions for pupil data and the total number of sessions for neuronal data in each animal.</p></disp-quote><p>Thanks for bringing these questions to light. Some of this information was implicit in the text, but we agree, it is much clearer to report it explicitly, as suggested. A total of four animals were included in the study (as shown in Figure 1). Neurophysiological data was collected from both A1 and IC in two animals (animals B and R) and only from A1 or IC in the remaining two (animals T and L, respectively). We have added information about animal and site count to the Results:</p><p>Pupil data sessions: âMean pupil size (measured by the major axis diameter) was consistently larger during the active condition (n=35 sites total, animal L: n=13, B: n=5, R: n=16, T: n=1, p = 0.0133, hierarchical bootstrap, Figure 1D).â</p><p>Neural data sessions: âWe recorded extracellular spiking activity from the primary auditory cortex (A1, n = 129 units total, animal B: 6 sites/88 units, R: 1 site/13 units, T: 1 site/28 units) and the inferior colliculus (IC, n = 66 units total, animal B: 4 sites/7 units, L: 13 sites/46 units, R: 10 sites/13 units) of ferrets, while they switched between active engagement and passive listening.â</p><disp-quote content-type="editor-comment"><p>The reviewer was concerned about what can be inferred from these sample sizes.</p></disp-quote><p>General observations in the current data alleviated concerns about the main results, namely the large variability of effects within a single array recording (e.g., Figure 4), exemplified by the examples in Figure 2, where two neurons recorded simultaneously show very different effects of behavioral state.</p><p>However, this comment did motivate us to investigate a more rigorous statistical approach. We implemented a hierarchical bootstrap analysis developed explicitly to control for the type of bias that can arise in array recordings (Saravanan et al., 2020 <italic>arXiv</italic>), and we used it to assess significance of differences across populations in different experimental conditions. Because of this, reports of statistical tests have been updated in several places. Note that the hierarchical bootstrap method allows us to directly calculate the probability of the tested hypothesis being true. With 10000 bootstrap resamples, the minimum possible probability (or p-value) is 10<sup>-5</sup>, and therefore we report âp&lt;10<sup>-5</sup>â when zero bootstrap samples provide evidence supporting the null hypothesis.</p><p>We have revised the presentation of statistical tests to highlight the new approach:</p><p>âSeveral analyses assessed changes in the median of repeatedly sampled data, <italic>e.g.</italic>, average pupil size measured across multiple behavior blocks (Figure 1) or average state-dependent modulation measured across multiple units (Figures 3, 5-8). In this case, significant differences were assessed using a hierarchical bootstrap test (Saravanan et al., 2020). The hierarchical bootstrap is nonparametric, like the more traditional Wilcoxon signed-rank test. However, a traditional test that treats each unit as an independent measure could potentially be biased if a single array recording produced spuriously large effects. The hierarchical bootstrap controls for this possibility by resampling first across recording sessions and then within each of those sessions. The bootstrap analysis was run for 10,000 iterations, so that the minimum measurable p-value was 10<sup>-5</sup>. Results that returned <italic>p</italic>=0 after this many iterations are reported as <italic>p</italic> &lt; 10<sup>-5</sup>.â</p><p>We made numerous small changes to report the new test. Rather than detailing all the changes, following is a list of analyses where a Wilcoxon signed-rank test or permutation test (for correlation coefficient) was replaced by a hierarchical bootstrap. In these cases, the basic result (<italic>p</italic>&lt;0.05 or p&gt;0.05) was unchanged:</p><p>There were two instances where the hierarchical bootstrap test produced a different result than the previous version of the manuscript. Neither of these analyses is critical to the main findings in the study:</p><p>Figure 5: In IC, the average change in spike rate uniquely attributable to task engagement (<italic>MI<sub>AP</sub></italic> task-unique) was previously reported to be significantly less than zero but now tests at p = 0.062. We have revised the text: âIn IC, average <italic>MIAP task-only</italic> was not different from zero (<italic>MIAP task-only</italic> median: -0.010, <italic>p</italic> = 0.310), but <italic>MI<sub>AP</sub> task-unique</italic> showed a trend toward being negative (17/49 positive, median: -0.037; <italic>p</italic> = 0.062).â</p><p>We did find that accounting for effects of pupil consistently decreased <italic>MI<sub>AP</sub></italic> (i.e., <italic>MI<sub>AP</sub></italic> task unique &lt; <italic>MI<sub>AP</sub></italic> task-only) in both A1 and IC. We report that in the legend for Figure 5: â<italic>MI<sub>AP</sub></italic> shifted to more negative values on average (A1 median <italic>MI<sub>AP</sub> task-only</italic> = 0.069, <italic>MI<sub>AP</sub> task-unique</italic> = 0.027, <italic>p</italic> =0.0005; IC: median <italic>MI<sub>AP</sub> task-only</italic> = -0.010, <italic>MI<sub>AP</sub> task-unique</italic> = -0.037, <italic>p</italic> = 0.049, hierarchical bootstrap).â</p><p>Figure 6âfigure supplement 1: The comparison between <italic>MI<sub>AP</sub></italic> task-unique for on- versus off-BF units in A1 was previously reported as significant, but now we find p=0.221. We have revised the text: âIn A1, there was no difference in median <italic>MI<sub>AP</sub></italic> task-unique between modulated on- and off-BF units (on-BF: median 0.082, n = 28; off-BF: -0.012, n = 24; p = 0.221, hierarchical bootstrap) or unmodulated units (on-BF: -0.002, n = 44; off-BF: -0.019, n = 77; p = 0.136).â</p><disp-quote content-type="editor-comment"><p>Please also include a statement that the results on the effects of task engagement may not apply to all auditory tasks.</p></disp-quote><p>As suggested, we have clarified this point in the Discussion:</p><p>âThe effects of task engagement reported here are specific to the tone detection task and are likely to differ if task structure is changed. In contrast, effects of pupil modulate activity throughout active and passive states, and are likely to be similar in different task conditions (Schwartz et al., 2020). â</p></body></sub-article></article>