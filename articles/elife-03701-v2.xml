<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">03701</article-id><article-id pub-id-type="doi">10.7554/eLife.03701</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural mechanisms of economic commitment in the human medial prefrontal cortex</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-14838"><name><surname>Tsetsos</surname><given-names>Konstantinos</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-16082"><name><surname>Wyart</surname><given-names>Valentin</given-names></name><xref ref-type="aff" rid="aff2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-16083"><name><surname>Shorkey</surname><given-names>S Paul</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-16084"><name><surname>Summerfield</surname><given-names>Christopher</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Department of Experimental Psychology</institution>, <institution>University of Oxford</institution>, <addr-line><named-content content-type="city">Oxford</named-content></addr-line>, <country>United Kingdom</country></aff><aff id="aff2"><institution content-type="dept">Département d’Etudes Cognitives</institution>, <institution>Ecole Normale Supérieure</institution>, <addr-line><named-content content-type="city">Paris</named-content></addr-line>, <country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Reviewing editor</role><aff><institution>Brandeis University</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>konstantinos.tsetsos@psy.ox.ac.uk</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>21</day><month>10</month><year>2014</year></pub-date><pub-date pub-type="collection"><year>2014</year></pub-date><volume>3</volume><elocation-id>e03701</elocation-id><history><date date-type="received"><day>16</day><month>06</month><year>2014</year></date><date date-type="accepted"><day>16</day><month>10</month><year>2014</year></date></history><permissions><copyright-statement>© 2014, Tsetsos et al</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Tsetsos et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-03701-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.03701.001</object-id><p>Neurobiologists have studied decisions by offering successive, independent choices between goods or gambles. However, choices often have lasting consequences, as when investing in a house or choosing a partner. Here, humans decided whether to commit (by acceptance or rejection) to prospects that provided sustained financial return. BOLD signals in the rostral medial prefrontal cortex (rmPFC) encoded stimulus value only when acceptance or rejection was deferred into the future, suggesting a role in integrating value signals over time. By contrast, the dorsal anterior cingulate cortex (dACC) encoded stimulus value only when participants rejected (or deferred accepting) a prospect. dACC BOLD signals reflected two decision biases–to defer commitments to later, and to weight potential losses more heavily than gains–that (paradoxically) maximised reward in this task. These findings offer fresh insights into the pressures that shape economic decisions, and the computation of value in the medial prefrontal cortex.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.001">http://dx.doi.org/10.7554/eLife.03701.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.03701.002</object-id><title>eLife digest</title><p>Humans, in general, are not particularly good at making economic decisions. People can be influenced by unhelpful biases: such as ‘loss aversion’ where a person views losses as more significant than gains. Sometimes these biases stop us making the decisions that offer the best reward, as such, they raise the question: why do these biases exist at all?</p><p>One way to examine this question is by looking at the brain activity of people making economic decisions. Two regions near the front of the brain are known to be involved in human decision-making in response to rewards. However, many researchers disagree as to what these two regions are actually doing when we make economic decisions.</p><p>Much of the research in this area has asked participants to essentially gamble on a series of independent events, which typically provide a one-off instant reward with no further positive consequences. However, these tasks do not accurately reflect real economic decisions. In real life situations, people tend to take time to make a decision, and weigh up the potential long-term costs and benefits of an investment. Indeed the decision itself may be deferred until enough information is gathered; for example, very few people would choose to buy a house on the spur of the moment.</p><p>Now Tsetsos et al. have attempted to bridge the gap between previous studies and everyday experiences by designing a task that encompasses many of the factors involved in real life decision-making. In this task, participants were given the option of deciding whether to commit to, or reject, an investment opportunity immediately; or to choose to defer making the decision until later—similar to how a person might wait to view different properties before deciding which house to buy. Using brain imaging, Tsetsos et al. found that one of the two brain regions (called the dorsal ACC for short) was involved in weighing up the cost of rejecting an offer, but not accepting it. The other region (called the rostromedial prefrontal cortex or rmPFC) was involved in assessing the value of an offer only when the participant decided to defer making a decision, and not when they decided to commit.</p><p>Furthermore, by using computer simulations, Tsetsos et al. found that, with this more realistic task, biases such as loss aversion were in fact beneficial and helped participants to make decisions that increased their financial payoff. This suggests that the ‘unhelpful biases’ often seen in traditional decision making tasks may be a result of participants’ real life strategies failing to work when applied to an artificial situation. In other words, perhaps humans are not so bad at economic decision-making after all.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.002">http://dx.doi.org/10.7554/eLife.03701.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>decision-making</kwd><kwd>neuroeconomics</kwd><kwd>prefrontal cortex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>ERC 281628 - URGENCY</award-id><principal-award-recipient><name><surname>Summerfield</surname><given-names>Christopher</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>NIH R01MH097965 Subaward 13-NIH-1039</award-id><principal-award-recipient><name><surname>Summerfield</surname><given-names>Christopher</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A striking dissociation exists in the medial prefrontal cortex, with different brain regions responding to value when commitments are deferred to the future and when prospects are judged to be undesirable.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Animals make choices that enhance their chances of positive reinforcement (<xref ref-type="bibr" rid="bib49">Thorndike, 1898</xref>). Laboratory-based tasks have investigated reward-guided decision-making by requiring successive, independent choices to be made in pursuit of a primary reinforcer (e.g., juice) or a flexible resource (e.g., money). For example, on each trial participants might be asked to choose between one of two abstract symbols to obtain a variable monetary reward (<xref ref-type="bibr" rid="bib8">Daw et al., 2006</xref>), or decide which of two snacks they would like to eat upon completion of the experiment (<xref ref-type="bibr" rid="bib30">Lim et al., 2011</xref>). In these tasks, decisions are often characterised by stereotyped biases that hinder outcome maximisation, including a tendency to weight losses more heavily than gains (loss aversion) (<xref ref-type="bibr" rid="bib53">Tversky and Kahneman, 1991</xref>; <xref ref-type="bibr" rid="bib50">Tom et al., 2007</xref>), or an undue preference for an already endowed or ‘default’ option (status quo bias) (<xref ref-type="bibr" rid="bib23">Kahneman et al., 1991</xref>; <xref ref-type="bibr" rid="bib9">De Martino et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">Fleming et al., 2010</xref>). In conjunction with single-cell recordings (<xref ref-type="bibr" rid="bib51">Tremblay and Schultz, 1999</xref>; <xref ref-type="bibr" rid="bib47">Shidara and Richmond, 2002</xref>; <xref ref-type="bibr" rid="bib35">Padoa-Schioppa and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib18">Hayden et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Kennerley et al., 2011</xref>) or functional neuroimaging (<xref ref-type="bibr" rid="bib38">Plassmann et al., 2007</xref>; <xref ref-type="bibr" rid="bib1">Basten et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Hare et al., 2011</xref>; <xref ref-type="bibr" rid="bib30">Lim et al., 2011</xref>; <xref ref-type="bibr" rid="bib19">Hunt et al., 2012</xref>; <xref ref-type="bibr" rid="bib26">Kolling et al., 2012</xref>; <xref ref-type="bibr" rid="bib5">Boorman et al., 2013</xref>), studies have revealed that two interconnected medial cortical regions, the dorsal anterior cingulate cortex (dACC) and the rostromedial prefrontal cortex (rmPFC), play a pivotal role in reward-guided decision-making, although the relative contribution of these regions remains a focus of lively debate (<xref ref-type="bibr" rid="bib22">Kable and Glimcher, 2009</xref>; <xref ref-type="bibr" rid="bib39">Rangel and Hare, 2010</xref>; <xref ref-type="bibr" rid="bib43">Rushworth et al., 2011</xref>).</p><p>Tasks involving successive, independent decisions (e.g., standard ‘bandit’ tasks) allow researchers to simulate key behaviours such as foraging, where an animal makes repeated choices about which food item to consume (<xref ref-type="bibr" rid="bib43">Rushworth et al., 2011</xref>). These decisions depend on the momentary utility of a stimulus, that is, the reward that would accrue if that stimulus were to be consumed or disbursed all at once, whether immediately or (as in inter-temporal choice) after a delay (<xref ref-type="bibr" rid="bib21">Kable and Glimcher, 2007</xref>). However, many (perhaps most) economic behaviours are not well captured by this paradigm, because rather than involving successive, independent choices, they require <italic>investment</italic>—that is, long-term commitment to a prospect in anticipation of sustained economic return, and with penalties incurred by any future change of mind. For example, the benefits of choosing the right employment could persist for many years into the future, whereas a poor decision about which mobile telephone to purchase might cause frustration for several months. Other decisions reverse a previous commitment, for example when deciding to sell stock options or to end a failing relationship. In these types of decision, which we refer to as economic ‘commitments’, prospects are irreversibly ‘ruled in’ (i.e., by acceptance) or ‘ruled out’ (i.e., by rejection) of a portfolio of assets that yield sustained positive or negative return to the individual. Unlike the choices made in most current lab-based approaches, economic commitments are not independent: a decision made at a time <italic>t</italic> continues to contribute to economic return at a later time <italic>t</italic> + 1, and may influence other choices made at that time. The aim of the current work was to understand the computational mechanisms by which economic commitments are made in humans, and to investigate their neural implementation in the reward circuitry of the medial prefrontal cortex.</p><p>Commitments often follow a period of deliberation, during which items are considered but final acceptance or rejection is deferred to a later moment (<xref ref-type="bibr" rid="bib46">Shafir and Tversky, 1992</xref>; <xref ref-type="bibr" rid="bib45">Shafir, 1993</xref>). For example, a university student might decide to opt for a course after attending an interesting first seminar (acceptance, or ‘ruling in’); or she might decide to wait until after a second seminar to make a commitment. Equally, the student might decide to drop a course after attending a particularly boring lecture (rejection, or ‘ruling out’); or she might give the lecturer another chance, and defer the decision until later. In other words, many behaviours involve choosing between either acceptance and deferral, or rejection and deferral. The notion that deliberation incurs a dual demand associated with selection (what to decide, either option A or B) and commitment (when to decide, either now or later) has received detailed consideration in psychophysical studies, in particular via the modelling of reaction time distributions (<xref ref-type="bibr" rid="bib3">Bogacz et al., 2006</xref>). However, studies requiring fast category judgments make it hard to disentangle the mechanisms determining what to decide and when to commit. In description-based judgment tasks, framing a choice as ‘accept’ or ‘reject’ provokes well-described biases in choice behavior (<xref ref-type="bibr" rid="bib54">Tversky and Kahneman, 1981</xref>). However, the issue of how commitments to prospects are made by acceptance or rejection has received less attention in the domain of neuroeconomics (<xref ref-type="bibr" rid="bib15">Furl and Averbeck, 2011</xref>; <xref ref-type="bibr" rid="bib16">Gluth et al., 2012</xref>).</p><p>During choices among two or more options with uncertain value, activity in anterior rmPFC has been shown to signal the relative advantage of the chosen or attended option over its competitors (<xref ref-type="bibr" rid="bib35">Padoa-Schioppa and Assad, 2006</xref>; <xref ref-type="bibr" rid="bib30">Lim et al., 2011</xref>; <xref ref-type="bibr" rid="bib19">Hunt et al., 2012</xref>), whereas the dACC often shows the reverse pattern. This may be because dACC preferentially responds to decision entropy or conflict (<xref ref-type="bibr" rid="bib6">Botvinick et al., 1999</xref>), or alternatively because it encodes the value of disengaging from a current or default state to explore a novel course of action (<xref ref-type="bibr" rid="bib18">Hayden et al., 2011</xref>; <xref ref-type="bibr" rid="bib26">Kolling et al., 2012</xref>). In either case however, it remains unknown whether this value difference coding depends on whether stimuli are accepted or rejected, because when deciding between two prospects, an option may be chosen either because it was preferred, or because the alternative was dispreferred. Moreover, it remains unknown how value encoding in the medial prefrontal cortex depends on whether decisions involve economic commitment or not.</p><p>Here, thus, we investigated the neural mechanisms that accompany commitment (acceptance, rejection), and deferral (failure to accept or reject) during economic choice, using a multi-alternative choice task in which decisions had financial ramifications that persisted over prolonged episodes, and could not be reversed. In half of the blocks, participants had to choose between accepting (<italic>inclusion by commitment</italic>) and deferring acceptance of a prospect (<italic>exclusion by deferral</italic>). In the other half of the blocks, participants chose between rejecting (<italic>exclusion by commitment</italic>) and deferring rejection (<italic>inclusion by deferral</italic>). Therefore, preference for a bandit would be implied by commitment in rule-in and deferral in rule-out. Our task, thus, allowed us to probe value encoding in the prefrontal cortex as a function of whether a stimulus was preferred (i.e., included or excluded) and whether commitment was made now or deferred until later. Further, the task captured many aspects of economic decisions in the real world: uncertainty about the true value of a prospect, sustained yield accruing from the investment, economic benefit determined collectively by current assets, and the need to trade-off exploration and exploitation.</p><p>To preview our findings, whole-brain functional neuroimaging during performance of the task revealed a striking dissociation in the medial prefrontal cortex. The dorsal anterior cingulate cortex (dACC) encoded value when a prospect was excluded (not included) while the rmPFC encoded value only during deferral (not commitment). Furthermore, joint consideration of the behavioural data and the dACC activity allowed us to pinpoint two pressures that shaped decisions in the task: a bias to defer until a later date, and a bias to weight unfavourable (excluded) options more heavily. Although similar biases typically hinder reward harvesting in standard tasks, for our ecologically valid setting we show that they actually allow participants to perform closer to a reward-maximizing agent.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Task summary</title><p>On each block, participants (<italic>n</italic> = 20, performing the task in the fMRI scanner) viewed spirals of variable length associated with four options (bandits, indexed <italic>i</italic>). On each trial, each spiral of length <italic>s</italic><sub><italic>i</italic></sub> was drawn from a Gaussian distribution with mean <italic>v</italic><sub><italic>i</italic></sub> that remained unchanged for that bandit during a block of 12 trials (see <xref ref-type="fig" rid="fig1">Figure 1A</xref> and ‘Materials and methods’). On each trial of a given block, a virtual <italic>pool of assets</italic> contained the preferred bandits thus far. The contents of the asset pool were converted to monetary reward, as we describe below. Each bandit yielded a monetary <italic>payoff</italic> (<italic>μ</italic><sub><italic>i</italic></sub>) determined by the rank of its mean <italic>v</italic><sub><italic>i</italic></sub> relative to the mean of all four bandits in the block (longer spirals were associated with greater payoff). After viewing the spiral participants chose whether to <italic>commit</italic> to that bandit, or to <italic>defer</italic>. Critically, commitment engendered a sustained alteration in the per-trial economic yield, in a manner that varied according to <italic>rule type</italic> (‘rule-in’ vs ‘rule-out’). On rule-in blocks, participants began the block with an empty pool of assets and the per-trial momentary yield was determined by the average payoff of all bandits committed to (<italic>accepted</italic>) thus far (<xref ref-type="fig" rid="fig1">Figure 1A</xref>: upper panel and ‘Materials and methods’). On rule-out blocks, participants' asset pool initially included all four alternatives and the per-trial yield was the average of the payoff of all bandits not yet committed to (not yet <italic>rejected</italic>, <xref ref-type="fig" rid="fig1">Figure 1A</xref>: lower panel). The total yield at the end of a block was the sum of the per-trial yields (see example in ‘Materials and methods’). Per-block yield was converted to a real financial incentive via a lottery procedure at the end of each run of the experiment.<fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.03701.003</object-id><label>Figure 1.</label><caption><title>Block timeline and task design.</title><p>(<bold>A</bold>) Upper left inset box: in the two examples, preference and anti-preference for a bandit is indicated with an open circle and triangle, respectively. Upper right inset box: showing the mapping between mean spiral length and payoff (<italic>H</italic> for high and <italic>L</italic> for low) of the four bandits in the example blocks. Upper panel: example of a rule-in block. Following an instruction screen, on each trial (grey panels) four bandits (colored boxes) were presented. A spiral in one box provided a noisy estimate of bandit mean length. Bandits that were accepted were made unavailable (greyed out) for future choices (trial 4). Accepted bandits were brought irrevocably into a virtual ‘asset pool’ (light gray circle) that began empty (trial 3). The per-trial yield, that is, the average of the payoffs of all bandits in the asset pool, was aggregated to provide the block-end yield. After 12 trials a feedback screen revealed each bandit’s nominal length and winnings. Bottom panel: same as upper, but for a rule-out block. All bandits began in the asset pool. Rejection eliminated one bandit from the pool (trials 2 and 5). Per-trial yield reflected the average payoff of bandits not yet eliminated from the asset pool. (<bold>B</bold>) The bandits’ length distributions could vary across 2-variance level (purple/grey). Payoff reflected the rank order of a bandit‘s mean spiral length within the block. The average mean length of the 4 bandits ranged from 2.5 to 5 (see ‘Materials and methods’) and was manipulated across 3 levels corresponding to three different context types.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.003">http://dx.doi.org/10.7554/eLife.03701.003</ext-link></p></caption><graphic xlink:href="elife-03701-fig1-v2"/></fig></p><p>Following commitment (by acceptance or rejection) a bandit was made unavailable for future decisions and on each subsequent trial offers were drawn randomly from the bandits still in play. Thus bandits could not be definitively accepted in rule-out blocks or definitively rejected in rule-in blocks, but commitment could be continually deferred until the end of the block. Each block used one of three <italic>context types</italic> that determined the average lengths of the presented spirals (short, medium, long), ensuring that participants had to learn afresh the relationship between mean spiral length and payoff in each block. This variable block-dependent mapping from spiral length to payoff (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) discouraged the use of fixed strategies (such as ruling in all bandits greater than a single value across the experiment). The task is described in more detail in the ‘Materials and methods’ section.</p></sec><sec id="s2-2"><title>Identifying the decision variable</title><p>Our first goal was to identify the quantity (decision variable or DV) on which participants based their economic commitments. Participants could optimize performance by averaging momentary samples <italic>s</italic><sub><italic>i</italic></sub> to estimate the underlying mean lengths <italic>v</italic><sub><italic>i</italic></sub> and the corresponding payoffs (according to the rank-order of <italic>v</italic><sub><italic>i</italic></sub>), trading off speed and accuracy (or exploration/exploitation) in making economic commitments. One well-described solution to speeded choice among multiple uncertain alternatives is to respond when the accumulated evidence supporting the currently favoured alternative is sufficiently larger than that for its nearest rival (<xref ref-type="bibr" rid="bib7">Busemeyer and Rapoport, 1988</xref>; <xref ref-type="bibr" rid="bib32">McMillen and Holmes, 2006</xref>), that is, to compare the average spiral lengths for the current and next-best bandits. A robust approximation to this is to compare the current bandit to the mean of the other options (<xref ref-type="bibr" rid="bib33">Niwa and Ditterich, 2008</xref>).</p><p>We compared the ability of these <italic>current-minus-next</italic> and <italic>current-minus-average</italic> policies (as well as of other policies, see ‘Materials and methods’) to predict human commitment probability across the block under different rules and contexts (<xref ref-type="table" rid="tbl1">Table 1</xref>). Although both the <italic>current-minus-next</italic> and <italic>current-minus-average</italic> provided a good fit, there was a statistical advantage for the latter (comparing negative log-likelihoods: <italic>t</italic><sub>(19)</sub> = 3.22, p &lt; 0.005). When a decision criterion was fit to the <italic>current-minus-average</italic> quantity separately for rule-in and rule-out blocks (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) to produce discrete model choices, they bore a striking resemblance to human behaviour, capturing the proportion, the timing, and secondary aspects of commitments for all the various combinations of rule context-type (<xref ref-type="fig" rid="fig2">Figure 2A–C</xref>).<table-wrap id="tbl1" position="float"><object-id pub-id-type="doi">10.7554/eLife.03701.004</object-id><label>Table 1.</label><caption><p>Negative log-likelihood (−<italic>LL</italic>; mean and standard deviation) for the eight decision variables, combing differently anchoring and integration processes</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.004">http://dx.doi.org/10.7554/eLife.03701.004</ext-link></p></caption><table frame="hsides" rules="groups"><thead><tr><th colspan="2">Anchor</th><th colspan="4">Integration</th></tr></thead><tbody><tr><td/><td/><td colspan="2">No</td><td colspan="2">Yes</td></tr><tr><td/><td><italic>r</italic>(<italic>t</italic>)</td><td><italic>DV</italic>(<italic>t</italic>)</td><td>−<italic>LL</italic></td><td><italic>DV</italic>(<italic>t</italic>)</td><td>−<italic>LL</italic></td></tr><tr><td>No</td><td>N/A</td><td><italic>s</italic><sub><italic>i</italic></sub>(<italic>t</italic>)</td><td>200 ± 25</td><td><inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula></td><td>195 ± 26</td></tr><tr><td>Previous</td><td><italic>s</italic><sub><italic>j</italic></sub>(<italic>t</italic> − 1)</td><td><italic>s</italic><sub><italic>i</italic></sub>(<italic>t</italic>) − <italic>r</italic>(<italic>t</italic>)</td><td>211 ± 24</td><td><inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula></td><td>208 ± 23</td></tr><tr><td>Max-next</td><td><inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula></td><td><italic>s</italic><sub><italic>i</italic></sub>(<italic>t</italic>) − <italic>r</italic>(<italic>t</italic>)</td><td>183 ± 24</td><td><inline-formula><mml:math id="inf4"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula></td><td>178 ± 25</td></tr><tr><td>Average</td><td><inline-formula><mml:math id="inf5"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mi mathvariant="italic">ϵ</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula></td><td><italic>s</italic><sub><italic>i</italic></sub>(<italic>t</italic>) − <italic>r</italic>(<italic>t</italic>)</td><td>189 ± 23</td><td><inline-formula><mml:math id="inf6"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula></td><td>167 ± 28</td></tr></tbody></table><table-wrap-foot><fn><p>The best fitting DV (Anchor: <italic>average</italic>, Integration: <italic>Yes</italic>) is highlighted with bold. We refer to this DV in the text as <italic>current-minus-average</italic>. The second best DV (Anchor: <italic>Max-next</italic>, Integration: <italic>Yes</italic>) is mentioned in the text as <italic>current-minus-next</italic>.</p></fn></table-wrap-foot></table-wrap><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.03701.005</object-id><label>Figure 2.</label><caption><title>Behavioral results (N = 20) and model predictions.</title><p>(<bold>A</bold>) Commitment probability in different contexts (short, medium and long blocks) as a function of mean bandit spiral length for rule-in (top) and rule-out blocks (bottom) and (<bold>B</bold>) probability of commitment as a function of trial number, context-type and rule. Black lines: human data; filled gray circles: model fits. (<bold>C</bold>) Mean number of commitments in rule-in and rule-out (and their sum), in the three different contexts. Moving from short to long contexts, commitments increased in rule-in (<italic>F</italic><sub>(2,38)</sub> = 6.73, p &lt; 0.01) and decreased in rule-out (<italic>F</italic><sub>(2,38)</sub> = 4.95, p &lt; 0.05). The model predicts this pattern (filled circles) by initializing the block reference to the mean spiral length in the experiment (see ‘Materials and methods’), thus over(under)-estimating the DV at trial 1 in long (short) contexts. The sum of commitments exceeded the number of available bandits (4.5 ± 0.6; <italic>t</italic><sub>(19)</sub> = 3.64, p &lt; 0.005), mainly due to more than one commitments made in rule-in. (<bold>D</bold>) Fitted decision criteria (filled circles) did not significantly differ from reward-maximizing criteria (solid vertical lines) under the current-minus-average model for rule-in (blue) and rule-out (purple). Gray curves show the distributions of the estimated pay-off for each of the four bandits under different numbers of samples (different shades). Values larger (smaller) than the rule-in criterion provoke inclusion by commitment (exclusion by deferral). Values smaller (larger) than the rule-out criterion result in exclusion by commitment (inclusion by deferral). Bars are 95% confidence intervals (C.I.). <italic>H</italic> and <italic>L</italic> stand for bandits with high and low absolute pay-off, respectively.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.005">http://dx.doi.org/10.7554/eLife.03701.005</ext-link></p></caption><graphic xlink:href="elife-03701-fig2-v2"/></fig></p></sec><sec id="s2-3"><title>Brain imaging data</title><p>Next, we turned to the neuroimaging data to validate our modelling approach and measure how value was coded in medial prefrontal cortex during acceptance, rejection and deferral. We conceived of the task as a factorial design crossing rule type (rule-in, rule-out), decision (commit, defer) and the parametrically varying (signed) quantity <italic>DV</italic><sub><italic>cur</italic> − <italic>ave</italic></sub> that indexes the estimated payoff of the available bandit under the current-minus-average policy implied by our behavioural modelling (hereafter, ‘value’). We further validated this DV by testing for distinct neural correlates between the estimated average value of the offered bandit and the block reference in brain regions implicated in the maintenance of contextual information relevant to action selection, including the lateral prefrontal and parietal cortices (<xref ref-type="bibr" rid="bib25">Koechlin and Summerfield, 2007</xref>) (<xref ref-type="fig" rid="fig3">Figure 3A–B</xref>).<fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.03701.006</object-id><label>Figure 3.</label><caption><title>Imaging data: model validation and rmPFC.</title><p>(<bold>A</bold>). Overlapping activations in the parietal cortex elicited by the current bandit running average (yellow; peak: 58, −60, 26; t<sub>(19)</sub> = 4.78, p &lt; 0.0002) and reference (red; peak: 34, −68, 22; t<sub>(19)</sub> = 6.17, p &lt; 0.00001). (<bold>B</bold>) In the right caudate nucleus, we also observed a representation of the difference between these two quantities, that is, voxels that co-varied with the <italic>DV</italic><sub><italic>cur</italic> − <italic>ave</italic></sub> but did not vary according to the rule type or decision (main effect of the value signal; peak: 18, 20, 2; t<sub>(19)</sub> = 6.63, p &lt; 0.00001). (<bold>C</bold>) Voxels responding to the interaction of rule and value on defer trials (left, at p &lt; 0.0001) and commit trials (right, at p &lt; 0.001). Value is encoded (in the frame of reference of the rule) only on defer trials. (<bold>D</bold>) Mean parameter estimates, derived by regressing bandit value on the BOLD signal from within an independently-defined ROI in the rmPFC, separately for defer and commit decision under each rule. To ensure independence, ROIs were defined individually for each participant as the peak voxel responding within the region in the remaining 19 participants. All significant voxels are visualized at p &lt; 0.001 and survive correction for multiple comparisons across the brain. (<bold>E</bold>) Parameter estimates from a regressor encoding the value of the asset pool (estimated final payoff).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.006">http://dx.doi.org/10.7554/eLife.03701.006</ext-link></p></caption><graphic xlink:href="elife-03701-fig3-v2"/></fig></p></sec><sec id="s2-4"><title>The rmPFC encodes value only when commitment is deferred</title><p>In standard paradigms involving one-shot decisions between two alternatives, BOLD signals in more rostral portions of the medial frontal cortex tend to correlate positively with the value of a preferred (or chosen) option relative to an anti-preferred or unchosen option (<xref ref-type="bibr" rid="bib4">Boorman et al., 2009</xref>; <xref ref-type="bibr" rid="bib19">Hunt et al., 2012</xref>). We were thus surprised to find that no voxels in this region varied inversely with the three-way interaction between rule, decision and value (i.e., encoded decision x value inversely under the two rules). Thus, we searched across the brain for voxels that correlated with value on defer and commit trials separately (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Whereas no voxels responded to the rule x value interaction on commit trials (right panel), a prominent cluster in rmPFC was sensitive to the interaction of rule and value when participants made deferral choices (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, left panel; peak at −2, 56, 18; rule x value interaction on defer trials: <italic>t</italic><sub>(19)</sub> = 5.47, p &lt; 0.00003; <xref ref-type="fig" rid="fig3">Figure 3D</xref>). In this region, value encoding on defer trials differed from zero on rule-in (<italic>t</italic><sub>(19)</sub> = 5.21, p &lt; 0.0001) and rule-out (<italic>t</italic><sub>(19)</sub> = 3.41, p &lt; 0.002) blocks, but failed to diverge from zero when commitments were made for either rule-in (p = 0.13) or rule-out (p = 0.07) blocks (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). A statistically indistinguishable pattern of activity was observed more ventrally in the medial orbitofrontal cortex (BA 10), a region that has been labeled arMFC or vmPFC (rule x value interaction on defer trials: peak −2, 52, −10; <italic>t</italic><sub>(19)</sub> = 4.85, p &lt; 0.00006) and where activity typically correlates the expected value during independent choices (<xref ref-type="bibr" rid="bib34">O’Doherty et al., 2001</xref>; <xref ref-type="bibr" rid="bib38">Plassmann et al., 2007</xref>). This sensitivity to value during deliberation but not at commitment in the rmPFC is reminiscent of single neurons in the parietal cortex that parametrically encode confidence about sensory signals but drop off precipitously at the choice point (<xref ref-type="bibr" rid="bib41">Roitman and Shadlen, 2002</xref>).</p></sec><sec id="s2-5"><title>The rmPFC encodes the collective value of current assets</title><p>One possibility is that the rmPFC is involved in integrating value signals across prospects and time. If so, one might expect that it also encodes the current value of the asset pool—a quantity that signals the likely total reward that will be received at the end of the block. We calculated asset pool value in a trialwise fashion and included it as an additional predictor of the BOLD signal alongside the value, choice, rule and other nuisance factors such as the number of trials elapsed thus far in the block (see ‘Materials and methods’). Asset pool value captured unique variance in the BOLD signal in an overlapping region of posterior rmPFC (peak 2, 60, 6; <italic>t</italic><sub>(19)</sub> = 4.30, p &lt; 0.0004; see <xref ref-type="fig" rid="fig3">Figure 3E</xref>). This provides corroborating evidence that the rmPFC is involved in value integration, encoding the most likely estimate of the forthcoming monetary yield to be received at the end of the block.</p></sec><sec id="s2-6"><title>The dACC responds during economic commitment</title><p>Next, we compared brain activity when decisions were made to commit or defer. Commitments in both rule-in and rule-out blocks (commit &gt; defer) were associated with strong increases in the BOLD signal in a number of brain regions (<xref ref-type="supplementary-material" rid="SD1-data">Figure 4—source data 1</xref>), but most prominently in a dorsomedial prefrontal region encompassing the dACC (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Extracting data from an independently-defined ROI, we plotted parameters reflecting the average dACC response in each condition (see <xref ref-type="fig" rid="fig4">Figure 4B</xref>). Average BOLD signals differed between commit and defer decisions, with no difference according to rule type (p <italic>&gt;</italic> 0.5) and no interaction (p <italic>&gt;</italic> 0.9).<fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.03701.007</object-id><label>Figure 4.</label><caption><title>Imaging data: dACC.</title><p>(<bold>A</bold>) Voxels responding to commit &gt; defer, rendered onto a sagittal slice of a template brain (see also <xref ref-type="supplementary-material" rid="SD1-data">Figure 4—source data 1</xref>). The red-white scale shows t-values. (<bold>B</bold>) Average BOLD responses for defer (<bold>D</bold>) and commit (<bold>C</bold>) trials on rule-in (blue) and rule-out (magenta) blocks. (<bold>C</bold>) Voxels responding to the three-way interaction of rule, decision and value, in the ACC. (<bold>D</bold>) Bar plots showing average parameter estimates for a regression of value on BOLD activity in regions of interest (ROI) in the ACC, separately for defer and commit decision under each rule. Legend as for 3D. (<bold>E</bold>) Response times (seconds) were overall slower during commitment and this difference was pronounced in rule-in trials. This pattern is comparable with ACC average bold for defer and commit (<bold>B</bold>). Error bars are 95% confidence intervals (C.I.).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.007">http://dx.doi.org/10.7554/eLife.03701.007</ext-link></p><p><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.03701.008</object-id><label>Figure 4—source data 1.</label><caption><title>Local maxima responding to commit &gt; pass, at a FWE-corrected threshold of p &lt; 0.05.</title><p>Columns show cluster and peak statistics as well as the x, y, z coordinates of the peaks.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.03701.008">http://dx.doi.org/10.7554/eLife.03701.008</ext-link></p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-03701-fig4-data1-v2.docx"/></supplementary-material></p></caption><graphic xlink:href="elife-03701-fig4-v2"/></fig></p></sec><sec id="s2-7"><title>The dACC encodes the value of rejection and of failure to accept</title><p>Secondly, only the dACC and interconnected bilateral anterior insular cortex (AINS) were responsive to the three-way interaction between rule type, decision and value, with a peak in activation at −6, 32, 34 (<italic>t</italic><sub>(19)</sub> = 5.81, p &lt; 0.00002; <xref ref-type="fig" rid="fig4">Figure 4C</xref>). The dACC BOLD signal correlated positively with value when participants made commitments in rule-out blocks (<italic>t</italic><sub>(19)</sub> = 7.87, p &lt; 0.000001) or deferred in rule-in blocks (<italic>t</italic><sub>(19)</sub> = 4.57, p &lt; 0.0002), but did not diverge from zero when participants committed in rule-in blocks (accept, p = 0.12) or deferred in rule-out blocks (failed to reject, p = 0.09). Note that the parameter estimates plotted in <xref ref-type="fig" rid="fig4">Figure 4D</xref> are correlations with bandit value, not raw BOLD amplitudes, and thus very unlikely to reflect cognitive demand or other nuisance factors that might conceivably vary across the block. The functional significance of this pattern of dACC activity is discussed below.</p></sec><sec id="s2-8"><title>A computational account of economic commitment</title><p>Our task emphasises two key axes that characterise economic choices. Firstly, should I definitely accept a prospect, or reject it? Secondly, should I commit now or defer my choice to later? Our behavioural findings indicate that humans made economic commitments when the <italic>current-minus-average</italic> DV exceeded (rule-in blocks) or failed to surpass (rule-out blocks) a relevant criterion (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Next, we used numeric simulations to specify where that criterion should be placed for rewards to be maximised, and tested how this account compared to human performance.</p></sec><sec id="s2-9"><title>Human commitment criteria maximise reward</title><p>Model-derived best-fitting commitment criteria for individual participants under the <italic>current-minus-average</italic> model are shown in <xref ref-type="fig" rid="fig2">Figure 2D</xref>, separately for rule-in blocks (blue dots) and rule-out blocks (pink dots). These are superimposed upon the average estimate of the value distribution for each of the four bandits (ranked low-high) as it evolved with increasing number of samples (shaded grey lines). To understand the best policy for criterion setting, we varied the decision criterion gradually as a free parameter, and plotted the reward-maximising criterion value separately for rule-in (blue line) and rule-out blocks (pink line). Critically, average human performance did not differ from that of the simulated reward-maximising account—blue and pink dots cluster around the respective lines denoting reward-maximising performance in each condition (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This was confirmed by statistical comparison of the human and reward-maximizing criteria (rule-in: <italic>t</italic><sub>(19)</sub> = −1.00, p &gt; 0.3; rule-out: <italic>t</italic><sub>(19)</sub> = −0.17, p &gt; 0.8). In other words, humans set their criterion in a fashion that maximised overall reward.</p></sec><sec id="s2-10"><title>Rewards are maximised via exclusion proneness and a deferral bias</title><p>Several aspects of criterion placement are worthy of comment. Firstly, criteria for both rule-in and rule-out blocks lie to the right of zero. In other words, participants were more prone to reject offers (in rule out blocks) or fail to accept them (in rule in blocks) than vice versa (this <italic>exclusion proneness</italic> corresponds to a bias to reject offers in rule out blocks, and fail to accept them in rule in blocks; we use the term ‘exclusion’ rather than ‘rejection’ to avoid confusion over terminology). This was confirmed by statistical analysis: human commitments were made more frequently (total 2.7 ± 0.3 vs 1.8 ± 0.5; <italic>t</italic><sub>(19)</sub> = 6.23, p &lt; 0.0001), and first commitment occurred earlier (trial 3.4 ± 1.3 vs 4.6 ± 1.5; <italic>t</italic><sub>(19)</sub> = 3.92, p &lt; 0.001) in rule-out blocks (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). This bias helps maximise rewards because in our task participants will ideally accept (or fail to reject) only the single most valuable bandit.</p><p>Secondly, the reward-maximising criteria are not perfectly aligned for rule-in and rule-out blocks. In combination with exclusion proneness, this occurs due to an overall bias to defer commitment and thereby promote exploration. This brings the criterion closer to zero in rule-out blocks (where deferral indicates preference), and pushes it further from zero in rule-in blocks (where deferral indicates anti-preference). Indeed, participants deferred more frequently than they committed, with commitments occurring on 15% of trials on rule-in blocks and 22% of trials on rule-out blocks (with the difference reflecting the need for more commitments in rule-out). Response times were also prolonged on decisions to commit (<xref ref-type="fig" rid="fig4">Figure 4E</xref>), as if participants were overcoming a default tendency to defer (<italic>F</italic><sub>(1,19)</sub> = 77.9, p &lt; 0.0001). This effect was stronger in rule-in blocks, leading to a rule type (rule-in, rule-out) x decision (commit, defer) interaction on response times (<italic>F</italic><sub>(1,19)</sub> = 27.8, p &lt; 0.0001) with no main effect of rule type (<italic>F</italic><sub>(1,19)</sub> = 1.1, p = 0.3).</p></sec><sec id="s2-11"><title>An adaptive explanation for economic ‘framing’ effects</title><p>Thus, in our task the reward-maximising criteria for acceptance and rejection are not perfectly aligned—the criterion for rejection is somewhat lower than that for acceptance, and this is also the case for best-fitting human criteria (<italic>in</italic> = 0.39 ± 0.29, <italic>out</italic> = 0.12 ± 0.25; <italic>t</italic><sub>(19)</sub> = 3.40, p &lt; 0.01). In other words, humans are willing to prefer an offer that they might, under a different frame, not prefer. This preference reversal in one-shot tasks would violate the rational axiom of description-invariance (<xref ref-type="bibr" rid="bib45">Shafir, 1993</xref>; <xref ref-type="bibr" rid="bib56">Yaniv and Schul, 1997</xref>). However, in our task this policy is the one that maximises reward, with the criteria misalignment reflecting a deferral bias that promotes exploration before commitment.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Previous studies have examined the neural mechanisms of economic behavior by offering participants a succession of independent gambles or unrelated consumer choices (<xref ref-type="bibr" rid="bib8">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib38">Plassmann et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Lim et al., 2013</xref>). Here, we devised a task in which decisions involved commitment to an asset with enduring financial consequences. Whereas previous tasks have sought to mimic the experience of a gambler choosing which one-armed bandit has the highest yield, our experiment captures that of a consumer deciding to sell an ageing car or of an animal electing whether to accept a prospective mate. This approach thus allowed us to model the factors that drive everyday economic commitments, and to measure how brain activity differed when commitments were made relative to when they were deferred to a later time.</p><p>This approach allowed us to investigate how value was coded according to two key axes: whether decisions expressed preference or anti-preference; and whether a commitment (acceptance or rejection) was made immediately, or deferred into the future. We found a striking dissociation in the neural data; the dACC encoded value differentially as a function of the former axis (encoding value only when a prospect was anti-preferred i.e., rejected or not accepted). By contrast, the rmPFC encoded value differentially along the latter axis, covarying with value only when acceptance or rejection was deferred into the future, and not at the point of commitment.</p><p>This latter profile of activity was maximal over posterior rostromedial (rmPFC) sites in Brodmann’s area nine that have been previously implicated in forecasting the value of future behaviour (<xref ref-type="bibr" rid="bib2">Bechara et al., 1994</xref>), for example contributing to episodic future thinking (<xref ref-type="bibr" rid="bib44">Schacter and Addis, 2007</xref>). BOLD activity in this region resembles firing rates of ‘integration’ neurons that build up to the point of choice and then falls away (<xref ref-type="bibr" rid="bib41">Roitman and Shadlen, 2002</xref>). The wider function of the rmPFC in humans may be to integrate value across time and assets, potentially to calculate the value of prospective states or investments. Other studies have emphasised that the rmPFC may contribute to the integration of reward values across time (<xref ref-type="bibr" rid="bib37">Philiastides et al., 2010</xref>; <xref ref-type="bibr" rid="bib19">Hunt et al., 2012</xref>) and across goods (<xref ref-type="bibr" rid="bib13">Fellows, 2006</xref>; <xref ref-type="bibr" rid="bib29">Lim et al., 2013</xref>).</p><p>Modelling of behavioural performance suggested that economic commitments were made when the normalised bandit value fell above (in rule in blocks) or below (in rule out blocks) a fixed criterion. Empirically observed criteria for ruling-in and ruling-out differed, allowing the same offer to be both perceived as both ‘good’ and ‘bad’, depending on the framing of the task. Similar preference reversals due to violations of the rational principle of description-invariance have been previously described in one-shot multi-attribute choices (<xref ref-type="bibr" rid="bib45">Shafir, 1993</xref>). However, in our ecologically valid task, this misalignment of the criteria for acceptance and rejection is the policy that maximises reward. Intuitively, this asymmetry reflects a default bias towards deferring commitments, and the fact that this bias shifts the criterion in opposite directions in rule-in and rule-out. To revert to a consumer example, when purchasing a house one may wish to begin with a critical eye (stringent criterion), not accepting impulsively any one property before obtaining an overview of the market and its options; but when selling a house, one might wish to be less critical (less stringent criterion) so as not to reject early offers before enough information is collected. Our finding thus provides an adaptive explanation for violations of description invariance, or preference reversal due to ‘framing effects’ in economic choice tasks (<xref ref-type="bibr" rid="bib45">Shafir, 1993</xref>; <xref ref-type="bibr" rid="bib10">De Martino et al., 2006</xref>; <xref ref-type="bibr" rid="bib52">Tsetsos et al., 2012</xref>).</p><p>The dACC was sensitive to the main effect of commit vs defer, but dACC BOLD signals also correlated with value when participants rejected (or failed to accept) a prospect. In other words, the dACC is a good candidate for encoding the two biases observed in behavioural data: an overall (additive) proneness to defer, and a heightened gain of encoding value when participants dispreferred a prospect. BOLD signals may have been higher for commit than defer because participants had a higher threshold for commit decisions, leading to greater deliberation and more overall decision-related activity on these trials, consistent with prolonged reaction times observed for commit than defer decisions. We thus speculate that the two key decision biases described here on choice can be accounted for with discrete additive (deferral bias; e.g., biasing the deferral threshold) and multiplicative (exclusion proneness; e.g., modulating the rate of accumulation for negative values) parameters under mechanistic models of choice (<xref ref-type="bibr" rid="bib3">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib28">Krajbich and Rangel, 2011</xref>), and that the dACC may implement these biases in our task. These findings concur with the previously-noted sensitivity of dACC to value difference, but also with reports that the dACC and co-activated anterior insula are prominent among those regions that signal a switch away from a current or ‘default’ task (<xref ref-type="bibr" rid="bib20">Hyafil et al., 2009</xref>) or status quo position (<xref ref-type="bibr" rid="bib14">Fleming et al., 2010</xref>).</p><p>Of note, the two biases reported here bear a striking resemblance to the previously described tendency to favour a currently-endowed or status quo economic position (deferral bias) and loss aversion, the tendency to weight potential losses more heavily than potential gains in economic choice (exclusion proneness). In other words, one possibility is that three key economic suboptimalities catalogued in one-shot decision tasks—framing effects, endowment effects, and loss aversion—are all ‘rational’ biases when a more ecologically valid task is employed, in which decisions do not all have independent consequences (<xref ref-type="bibr" rid="bib11">Erev and Roth, 2014</xref>; <xref ref-type="bibr" rid="bib12">Fawcett et al., 2014</xref>).</p><p>In summary, asking participants to commit to economic alternatives revealed a striking dissociation between the dACC and rmPFC, two brain structures whose contribution to economic choice in the primate remains highly contentious (<xref ref-type="bibr" rid="bib22">Kable and Glimcher, 2009</xref>; <xref ref-type="bibr" rid="bib39">Rangel and Hare, 2010</xref>; <xref ref-type="bibr" rid="bib43">Rushworth et al., 2011</xref>). BOLD signals in the rmPFC and dACC both correlate with the relative value of two prospects under consideration, but do so with opposite sign, which has led researchers to puzzle over their unique contributions to decision-making. Some theories have proposed that rmPFC and dACC encode the value of stimuli and actions respectively (<xref ref-type="bibr" rid="bib42">Rudebeck et al., 2008</xref>), or the value and saliency of stimuli (<xref ref-type="bibr" rid="bib31">Litt et al., 2011</xref>), or the value of choosing a food item relative to that of foraging elsewhere (<xref ref-type="bibr" rid="bib26">Kolling et al., 2012</xref>). However, past work has precluded the segregation of neural activity on trials where a commitment was made, relative to those where commitment was deferred into the future.</p><p>Our findings suggests that the rmPFC is involved in integrating value in the service of prospective states, whereas the value coding in the dACC is relevant to whether a currently-available prospect is preferred or not. As such, these findings support the view that the hierarchy of control signals observed in the lateral prefrontal cortex is similarly instated in the medial prefrontal cortex (<xref ref-type="bibr" rid="bib27">Kouneiher et al., 2009</xref>; <xref ref-type="bibr" rid="bib48">Summerfield and Koechlin, 2009</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>21 healthy right-handed adults (mean age = 26.8 ± 3.7 years; 10 females) gave informed consent to participate in two experimental sessions (a practice session, and an fMRI session) conducted on different days, and were compensated £40 plus up to £20 in performance-dependent bonuses. One participant was excluded from subsequent analyses because of failure to comply with the task instructions.</p></sec><sec id="s4-2"><title>Stimulus and task design</title><p>On practice and fMRI sessions, participants performed a task on which they decided whether to accept or reject stimuli (‘bandits’) on the basis of visual signals (spirals). On each trial (<italic>t</italic>), they viewed a spiral of variable length (<italic>s</italic><sub><italic>i</italic></sub>(<italic>t</italic>)) that appeared in one (<italic>i</italic>) of four pink or blue boxes (‘bandits’), placed in the four quadrants of the screen. Bandits were randomly assigned the following four <italic>payoffs</italic> (<italic>μ</italic><sub><italic>i</italic></sub>):£15/24, £5/24, −£5/25, −£15/24 corresponding to the symbols <italic>H(high), L(low), −L, −H</italic> in the figures. Although payoffs were fixed, the mapping from payoff to the nominal mean spiral length changed block-by-block, so that bandit payoff was relative to the other spiral lengths observed in any given block. Each bandit’s spiral length was drawn from a normal distribution <italic>N</italic>(<italic>v</italic><sub><italic>i</italic></sub>, <italic>σ</italic><sub><italic>i</italic></sub>) where <italic>v</italic><sub><italic>i</italic></sub> was related ordinally to the payoff <italic>μ</italic><sub><italic>i</italic></sub> of the <italic>i</italic>th bandit, and <italic>σ</italic><sub><italic>i</italic></sub> stood for the standard deviation of the distribution. There were six possible mean spiral lengths,<italic>v</italic><sub><italic>i</italic></sub>, in the experiment: 2.5, 3.0, 3.5, 4.0, 4.5 and 5 (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Splitting these six means into contiguous groups of four resulted in three different <italic>context types</italic>, presented in pseudorandom order: (a) ‘short’ blocks comprised of bandits with mean lengths (from least to most valuable) of 2.5, 3.0, 3.5 and 4.0, (b) ‘medium’ blocks with bandits with spiral length means 3.0, 3.5, 4.0 and 4.5, and (c) ‘long’ blocks with bandits with spiral length means 3.5, 4.0, 4.5, and 5.0. Additionally, on each trial, two of the bandits had a standard deviation of 0.5 while the other two had a standard deviation of 1.0 (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Since the only determinant of a bandit’s payoff, <italic>μ</italic><sub><italic>i</italic></sub>, was the rank of its mean length within the block context, the bandit whose spirals had mean length <italic>v</italic><sub><italic>i</italic></sub> = 4.0 would be second in rank and be worth <italic>μ</italic><sub><italic>i</italic></sub> = £5/24 (<italic>L</italic>) in a ‘short’ block and would rank third, yielding <italic>μ</italic><sub><italic>i</italic></sub> = −£5/24 (−<italic>L</italic>) in a ‘long’ block. This approach precluded fixed strategies such as accepting or rejecting all bandits below or above a single spiral length. The presentation order of the blocks was pseudo-randomized such that there where 4 blocks of each length type within a scanner run (12 blocks per run).</p><p>Trials occurred in 48 blocks distributed in four runs. The reward assignment of the task varied according to the rule type. On ‘rule-in’ blocks, a spiral was presented in one of the four bandits and participants chose whether to ‘accept’ that bandit, or ‘defer’. The per-trial yield was equal to the average payoff of all the bandits ruled in up to that point: <inline-formula><mml:math id="inf7"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="italic">ϵ</mml:mi><mml:mtext> </mml:mtext><mml:mi>I</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>I</mml:mi><mml:mi>N</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> at trial <italic>t</italic>, with <italic>IN</italic> standing for the set of the bandits that had been ruled-in up to <italic>t</italic> We refer to the items thus far ruled-in as the <italic>asset pool</italic>. On ‘rule-out’ blocks, participants chose whether to ‘reject’ that bandit or to ‘defer’, and their per-trial yield was equal to the average payoff of all bandits not yet ruled out at that point <inline-formula><mml:math id="inf8"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mtext> </mml:mtext><mml:mo>∉</mml:mo><mml:mtext> </mml:mtext><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:mi>O</mml:mi><mml:mi>U</mml:mi><mml:mi>T</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, with <italic>OUT</italic> being the set of bandits that had been ruled out up to that point. Items not yet ruled-out are contained in the virtual asset pool. For both rule-in and rule-out the block-end yield was the sum of the per-trial yields of all trials (with the last trial of the block indicated by <italic>k</italic> ∈ [4, 12]), rounded to the nearest half or whole number: <inline-formula><mml:math id="inf9"><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. For example, in a rule-in block, if after <italic>t</italic> = 8 trials the participant had ruled in bandits with payoffs £5/24 and £−5/24, the yield on that trial would be: <inline-formula><mml:math id="inf10"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>8</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>£</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>15</mml:mn><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mrow><mml:mn>24</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. Similarly, in a rule-out block if at trial t = 8 participants had rule out bandits worth £−15/24 and £−5/24 the yield on that trial would be the average of the remaining bandits: <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>8</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>£</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>15</mml:mn><mml:mo>+</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mrow><mml:mn>24</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>Payoffs were calibrated so that selecting no bandits, or selecting all the bandits, would bring per-trial payoff to zero.</p></sec><sec id="s4-3"><title>Time course of a block</title><p>Rule-in and rule-out blocks were interleaved in pseudorandom order. On each experimental run (corresponding to 12 blocks) 6 blocks of each rule type were presented. Each block began with a fixation cross presented for 2 s under the words ‘Rule In’ or ‘Rule Out’ that announced the rule type of the block. Immediately after, four coloured boxes, one for each bandit, were presented in the four quadrants of the screen against dark grey background. The initial color of all bandits was either blue or pink, indicating the rule type of the block (counterbalanced across participants). Bandits that had not yet ruled in or out, and were thus available for future decisions, were set <italic>active</italic> and kept their initial color. On each trial, a spiral of variable length appeared randomly at the centre of one of the active boxes (bandits). Participants had a maximum of 2 s to either commit (rule in/rule out) to the bandit under offer or to defer. Committing to a bandit altered its status to inactive and resulted in the corresponding box being colored gray until the end of the block. In both rule-in and rule-out blocks, participants indicated their choice with a key press (practice task) or button press (fMRI session). Spirals disappeared from the screen immediately after participants pressed a button. Failure to respond within the deadline (2 s) resulted in forced commit or defer choices made automatically and randomly. After the response was registered, the next spiral was presented after a delay between 1 and 3 s. A block ended either when there were no more active bandits left or after 12 trials.</p></sec><sec id="s4-4"><title>Reward screen</title><p>At the end of the block the four bandits (turned into or) remained gray between 3 and 5 s (jittered). Immediately after, participants received a feedback screen indicating their earnings. Inside the box, corresponding to each bandit, the mean spiral length was shown together with the time that had elapsed (presented as a filled pie chart) before participants had made a committing decision. Centrally on the screen, the block-end monetary yield was shown (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). In the scanning session the feedback screen remained present until 85 s from the beginning of the block (presentation of the fixation cross) had elapsed. Thus, in the worse case scenario where all presentation and response events took the maximum possible time, the feedback screen stayed on for 15 s. On the other hand, in the behavioral sessions participants could advance by hitting any button. After an inter-block interval of between 2 and 4 s (jittered) the new block began. Every 12 blocks (i.e., at the end of one scanner run) participants viewed a ‘wheel of fortune’ consisting of 12 segments (1 for the block-end reward of each block) coloured proportionally to each block-end yield (red to green for negative to positive respectively). Participants pressed a button to spin the wheel of fortune and then another button to stop it. On average, participants won £3.0 per block (<italic>SD</italic> = 0.7). There was no significant difference between the rewards in the rule-in and rule-out trials (<italic>t</italic><sub>(19)</sub> = 0.50, p = 0.620). The value of the obtained segment was shown on the screen and then added to participants’ earnings obtained in previous runs. The overall earnings in a session could not exceed £10.</p></sec><sec id="s4-5"><title>Decision Variables</title><p>For parsimony, we considered decision variables (corresponding to the payoff estimate of each bandit) that avoid latent or hierarchical inferences that might take place in the course of the experiment. These variables varied across two features: (a) <italic>integration</italic> or computation of the <italic>absolute value</italic> of a bandit through averaging the spiral lengths presented thus far for that bandit and (b) <italic>anchoring</italic> of the absolute value (integrated or not) for each bandit to a reference value that represents the value of the other bandits in the block. For any given variable, integration (averaging) was either present or absent. Absence of integration means considering the momentary length presented at a bandit while ignoring all previous spirals encountered before at the same bandit. Anchoring could be omitted (‘absolute’ DV) or manifest itself by means of subtracting an implicit reference value from the absolute value of a given bandit. The reference value (<italic>r</italic>) changes trial-by-trial as new information is presented. Thus, at trial <italic>t</italic>, <italic>r</italic>(<italic>t</italic>) could be the absolute value (integrated or not) of the temporally previous bandit, the absolute value of the next-best bandit, or the average of the absolute values of all bandits in the block. For DV’s that involved anchoring the reference on the very first trial of a block was set to <italic>v</italic><sub><italic>prior</italic></sub> = 3.75, which reflected the mean spiral length in the experiment given the distributions in <xref ref-type="fig" rid="fig1">Figure 1B</xref>. The formulas associated with each DV are given at <xref ref-type="table" rid="tbl1">Table 1</xref>. We define with <italic>S</italic><sub><italic>i</italic></sub><sup><italic>t</italic></sup> the set of trials, up to trial <italic>t</italic>, in which spirals were presented at bandit <italic>i</italic>. The average value estimate for bandit <italic>i</italic> at trial <italic>t</italic> is <inline-formula><mml:math id="inf12"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mi mathvariant="italic">ϵ</mml:mi><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:mrow></mml:munder><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>, with <italic>s</italic><sub><italic>i</italic></sub> (<italic>j</italic>) being the spiral length in trials (<italic>j</italic>) where value information was presented for bandit <italic>i</italic>. In <xref ref-type="table" rid="tbl1">Table 1</xref>, we refer with <italic>S</italic><sub><italic>pres</italic></sub> to the set of bandits for which value information was presented at least once in the block.</p></sec><sec id="s4-6"><title>Model comparison and fitting</title><p>Using logistic regressions, we assessed how well each of the eight DV’s of <xref ref-type="table" rid="tbl1">Table 1</xref> predicted participant’s probabilities to commit. Separate regressions were performed for rule-in and rule-out trials:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>Φ</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>Φ</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>D</mml:mi><mml:mi>V</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula>where Φ is the cumulative normal function. These logistic fits assume that commitments are made once the DV exceeds a criterion threshold (reflected at the intercept, <italic>b</italic>). The negative log-likelihoods (summed for rule-in and rule-out) for each DV were calculated for each participant and compared using <italic>t</italic> tests. In order to generate discrete choices for the exact same sequences that participants saw in the experiment, the best-fitting <italic>DV</italic><sub><italic>cur</italic> − <italic>ave</italic></sub> was used to fit the probabilities of commiting in 24 conditions: four bandits’ rank-ordered lengths (–<italic>H</italic>, –<italic>L</italic>, <italic>L</italic>, <italic>H</italic>) × 3 context types (short, medium, long) × 2 rule types (rule-in, rule-out). The purpose of generating discrete choices using the <italic>DV</italic><sub><italic>cur</italic> − <italic>ave</italic></sub> was to assess the adequacy of the model in predicting qualitative aspects of the data (<xref ref-type="fig" rid="fig2">Figure 2A–C</xref>). The only free parameters were the decision criterion in rule-in and rule-out. We adopted a Maximum likelihood parameter estimation approach. This simple model was also compared to two models with additional free parameters: (a) a leaky averaging model that implemented an exponantial moving average when calculating the absolute integrated value of each bandit, (b) a leaky averaging model, in which the initial value of the reference (<italic>v</italic><sub><italic>prior</italic></sub>) was a free parameter. Bayesian information criterion analyses revealed no advantage of the two extended models over the simple <italic>DV</italic><sub><italic>cur</italic> − <italic>ave</italic></sub> one.</p></sec><sec id="s4-7"><title>Behaviour</title><p>Each participant completed a one-hour long practice session outside the scanner between 2 weeks and 3 days prior to his or her scanning session. The experimental task completed during practice was identical to the task performed in the scanner, with two exceptions. First, participants in the practice session made committing choices by pressing the ‘m’ button on a standard PC keyboard and made defer choices by pressing the ‘k’ button, as opposed to using the a MRI-safe response pad in the scanning session (left or right button, counterbalanced across participants). Second, participants during practice controlled the time at which they advanced through the feedback screen (and on to the next block) by pressing any computer keyboard button, instead of having to wait a specified amount of time as was required during the fMRI session. Stimulus presentation was conducted and behavioral responses were acquired using Matlab 7.4 (MathWorks, Natick, MA) and Psychophysics toolbox extension (<xref ref-type="bibr" rid="bib6a">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib35a">Pelli, 1997</xref>) on a standard PC.</p></sec><sec id="s4-8"><title>Behavioural analysis</title><p>For behavioral analysis an alpha value of 0.05 was used except where otherwise noted and all tests were two-sided. Dependent variables in different analyses involved the probability of committing (defined as the number of commitments divided by the number of trials in which a certain bandit was under offer), the trial number of the first commitment, and the per-block total number of committing decisions, for different bandit means and across different rules (rule in/rule out) and context types (short/medium/long).</p></sec><sec id="s4-9"><title>fMRI data acquisition</title><p>Neuroimaging data was acquired with an echo planar imaging (EPI) sequence on a Siemens Tim Trio 3.0T scanner with a 32-channel head coil. Scans were acquired with a repetition time (TR) of 2000 milliseconds (ms), an echo time (TE) of 30 ms, a voxel size of 3 × 3 × 3.5 mm, and a flip angle of 90°. One image volume consisted of 36 adjacent slices of 3 mm thickness, allowing most of the brain (not all of the cerebellum) to be fit into the field of view. Each of the four experimental runs in the fMRI session lasted approximately 17 min and participants were given 1 min of rest between blocks. Additionally, a structural scan using a Magnetization Prepared Rapid Acquisition Gradient Echo (MP-RAGE) sequence (RT of 2040 ms, TE of 4.7 ms, flip angle of 8°, voxel size of 1 × 1 × 1 mm) was acquired immediately following the four experimental blocks. This structural scan took approximately 6 min and resulted in a total scanning time of approximately 78 min.</p></sec><sec id="s4-10"><title>fMRI preprocessing</title><p>fMRI data was preprocessed according to a standard pipeline in SPM8 (Statistical Parametric Mapping; <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">www.fil.ion.ucl.ac.uk/spm</ext-link>). Preprocessing of the imaging data included correction for head motion and slice acquisition timing, followed by spatial normalization to the standard template brain of the Montreal Neurological Institute (MNI brain). Images were resampled to 4 mm cubic voxels and spatially smoothed with a 8 mm full width at half-maximum isotropic Gaussian kernel. A 128 s temporal high-pass filter was applied in order to exclude low-frequency artifacts. Temporal correlations were estimated using restricted maximum likelihood estimates of variance components using a first-order autoregressive model. The resulting nonsphericity was used to form maximum likelihood estimates of the activations. Importantly, SPM8 orthogonalises sequentially-entered regressors in the design matrix, but we ensured that this option was turned off for all analyses. All statistical analysis of imaging data included, in addition to regressors of interest, nuisance parameters encoding (i) the fixation screen that signaled block onset, (ii) the reward screen that indicated monetary earnings, (iii) an instruction screen stating rule type, and (iv) a regressor encoding the ‘grey’ period at the end of any blocks in which all bandits had been ruled in or out or the maximum number of trials had been reached, as well as six regressors coding movement parameters estimated from the realignment stage of preprocessing.</p><p>For comparing parameter estimates across the experimental conditions, independent samples <italic>t</italic> tests were used, while one-sample <italic>t</italic> tests were employed to assess whether these parameter estimates differed significantly from zero. All statistical anlayses reported in the text were corrected for multiple comparisons across the entire brain using a clusterwise threshold of p &lt; 0.05, although plots are rendered at p &lt; 0.001 uncorrected. To ensure independence, bar graphs were generated using a ‘leave one out’ procedure, as follows: (1) the ROI from the group analysis at a threshold of p &lt; 0.001 was used to define a search area, (2) each subject was set aside in turn, and the peak voxel sensitive to the statistical comparison for the remaining 19 subjects was identified; (3) the (independent) contrast value for subject s was logged; (4) bar graphs and accompanying stats were produced using only independent contrast values.</p></sec><sec id="s4-11"><title>fMRI analysis</title><p>We conceived of our experiments as a factorial design crossing factors (i) rule (rule-in vs rule-out), (ii) decision (commit vs defer) and (iii) value (<italic>DV</italic><sub><italic>cur</italic> − <italic>ave</italic></sub>) as a parametric regressor encoding the value estimate of a bandit under offer. These regressors, plus their interactions (seven regressors total) were entered into the design matrix alongside additional regressors encoding (i) the reference value for that block (<italic>r</italic> defined in <italic>Decision Variables</italic>), (ii) the trial number (1–12), that is, the time elapsed since the start of the block, and (iii) estimated aggregated yield, that is, the estimate of the most likely cumulative payoff for that trial, given the history of bandits and decisions. This was calculated by accumulating estimated per trial yield of the bandits included in the assets pool (for each bandit defined as the difference between the its average length estimate, <inline-formula><mml:math id="inf13"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, and reference value, <italic>r</italic>). In addition to the regressors of interest we included a series of nuisance regressors (see above). In a subsequent analysis (<xref ref-type="fig" rid="fig4">Figure 4B,D</xref>), we additionally extracted the BOLD timeseries from the peak group response to rule x decision x value in the dACC (−6, 32, 34) and included it (and its interaction with defer vs commit) as an additional regressor.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Tim Behrens, Demis Hassabis and Etienne Koechlin for comments on a draft manuscript. This work was funded by a European Research Council award to CS.</p></ack><sec sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>KT, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>VW, Conception and design, Contributed unpublished essential data or reagents</p></fn><fn fn-type="con" id="con3"><p>SPS, Conception and design, Acquisition of data, Analysis and interpretation of data</p></fn><fn fn-type="con" id="con4"><p>CS, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants gave informed consent to participate in the experiment, agreeing also that we would store anonymously their data, analyse them, and publish the corresponding results in peer-reviewed journals. Ethical approval was provided by the local committee in Oxford: NRES Committee South Central–Oxford A, identifier 09/H0604/11. All procedures accorded with the Declaration of Helsinki.</p></fn></fn-group></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basten</surname><given-names>U</given-names></name><name><surname>Biele</surname><given-names>G</given-names></name><name><surname>Heekeren</surname><given-names>HR</given-names></name><name><surname>Fiebach</surname><given-names>CJ</given-names></name></person-group><year>2010</year><article-title>How the brain integrates costs and benefits during decision making</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>107</volume><fpage>21767</fpage><lpage>21772</lpage><pub-id pub-id-type="doi">10.1073/pnas.0908104107</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bechara</surname><given-names>A</given-names></name><name><surname>Damasio</surname><given-names>AR</given-names></name><name><surname>Damasio</surname><given-names>H</given-names></name><name><surname>Anderson</surname><given-names>SW</given-names></name></person-group><year>1994</year><article-title>Insensitivity to future consequences following damage to human prefrontal cortex</article-title><source>Cognition</source><volume>50</volume><fpage>7</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(94)90018-3</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name><name><surname>Moehlis</surname><given-names>J</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year>2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boorman</surname><given-names>ED</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><year>2009</year><article-title>How green is the grass on the other side? Frontopolar cortex and the evidence in favor of alternative courses of action</article-title><source>Neuron</source><volume>62</volume><fpage>733</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.05.014</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boorman</surname><given-names>ED</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year>2013</year><article-title>Ventromedial prefrontal and anterior cingulate cortex Adopt choice and default reference frames during sequential multi-alternative choice</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>2242</fpage><lpage>2253</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3022-12.2013</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>M</given-names></name><name><surname>Nystrom</surname><given-names>LE</given-names></name><name><surname>Fissell</surname><given-names>K</given-names></name><name><surname>Carter</surname><given-names>CS</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year>1999</year><article-title>Conflict monitoring versus selection-for-action in anterior cingulate cortex</article-title><source>Nature</source><volume>402</volume><fpage>179</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1038/46035</pub-id></element-citation></ref><ref id="bib6a"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year>1997</year><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>443</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busemeyer</surname><given-names>JR</given-names></name><name><surname>Rapoport</surname><given-names>A</given-names></name></person-group><year>1988</year><article-title>Psychological models of deferred decision-making</article-title><source>Journal of Mathematical Psychology</source><volume>32</volume><fpage>91</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/0022-2496(88)90042-9</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year>2006</year><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nature04766</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname><given-names>B</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Holt</surname><given-names>B</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year>2009</year><article-title>The neurobiology of reference-dependent value computation</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>3833</fpage><lpage>3842</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4832-08.2009</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname><given-names>B</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year>2006</year><article-title>Frames, biases, and rational decision-making in the human brain</article-title><source>Science</source><volume>313</volume><fpage>684</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1126/science.1128356</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erev</surname><given-names>I</given-names></name><name><surname>Roth</surname><given-names>AE</given-names></name></person-group><year>2014</year><article-title>Maximization, learning, and economic behavior</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>111</volume><supplement>Suppl 3</supplement><fpage>10818</fpage><lpage>10825</lpage><pub-id pub-id-type="doi">10.1073/pnas.1402846111</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fawcett</surname><given-names>TW</given-names></name><name><surname>Fallenstein</surname><given-names>B</given-names></name><name><surname>Higginson</surname><given-names>AD</given-names></name><name><surname>Houston</surname><given-names>AI</given-names></name><name><surname>Mallpress</surname><given-names>DE</given-names></name><name><surname>Trimmer</surname><given-names>PC</given-names></name><name><surname>McNamara</surname><given-names>JM</given-names></name></person-group><year>2014</year><article-title>The evolution of decision rules in complex environments</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>153</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.12.012</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fellows</surname><given-names>LK</given-names></name></person-group><year>2006</year><article-title>Deciding how to decide: ventromedial frontal lobe damage affects information acquisition in multi-attribute decision making</article-title><source>Brain</source><volume>129</volume><fpage>944</fpage><lpage>952</lpage><pub-id pub-id-type="doi">10.1093/brain/awl017</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname><given-names>SM</given-names></name><name><surname>Thomas</surname><given-names>CL</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year>2010</year><article-title>Overcoming status quo bias in the human brain</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>107</volume><fpage>6005</fpage><lpage>6009</lpage><pub-id pub-id-type="doi">10.1073/pnas.0910380107</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furl</surname><given-names>N</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year>2011</year><article-title>Parietal cortex and insula relate to evidence seeking relevant to reward-related decisions</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>17572</fpage><lpage>17582</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4236-11.2011</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gluth</surname><given-names>S</given-names></name><name><surname>Rieskamp</surname><given-names>J</given-names></name><name><surname>Buchel</surname><given-names>C</given-names></name></person-group><year>2012</year><article-title>Deciding when to decide: time-variant sequential sampling models explain the emergence of value-based decisions in the human brain</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>10686</fpage><lpage>10698</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0727-12.2012</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hare</surname><given-names>TA</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Camerer</surname><given-names>CF</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><year>2011</year><article-title>Transformation of stimulus value signals into motor commands during simple choice</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>108</volume><fpage>18120</fpage><lpage>18125</lpage><pub-id pub-id-type="doi">10.1073/pnas.1109322108</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayden</surname><given-names>BY</given-names></name><name><surname>Pearson</surname><given-names>JM</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name></person-group><year>2011</year><article-title>Neuronal basis of sequential foraging decisions in a patchy environment</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>933</fpage><lpage>939</lpage><pub-id pub-id-type="doi">10.1038/nn.2856</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Kolling</surname><given-names>N</given-names></name><name><surname>Soltani</surname><given-names>A</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year>2012</year><article-title>Mechanisms underlying cortical activity during value-guided choice</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>470</fpage><lpage>476</lpage><comment>S1-3</comment><pub-id pub-id-type="doi">10.1038/nn.3017</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyafil</surname><given-names>A</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year>2009</year><article-title>Two mechanisms for task switching in the prefrontal cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>5135</fpage><lpage>5142</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2828-08.2009</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year>2007</year><article-title>The neural correlates of subjective value during intertemporal choice</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1625</fpage><lpage>1633</lpage><pub-id pub-id-type="doi">10.1038/nn2007</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year>2009</year><article-title>The neurobiology of decision: consensus and controversy</article-title><source>Neuron</source><volume>63</volume><fpage>733</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.003</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name><name><surname>Knetsch</surname><given-names>JL</given-names></name><name><surname>Thaler</surname><given-names>RH</given-names></name></person-group><year>1991</year><article-title>Anomalies - the endowment effect, loss aversion, and status-quo bias</article-title><source>The Journal of Economic Perspectives</source><volume>5</volume><fpage>193</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1257/jep.5.1.193</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kennerley</surname><given-names>SW</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Wallis</surname><given-names>JD</given-names></name></person-group><year>2011</year><article-title>Double dissociation of value computations in orbitofrontal and anterior cingulate neurons</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1581</fpage><lpage>1589</lpage><pub-id pub-id-type="doi">10.1038/nn.2961</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koechlin</surname><given-names>E</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year>2007</year><article-title>An information theoretical approach to prefrontal executive function</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>229</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.04.005</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolling</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><year>2012</year><article-title>Neural mechanisms of foraging</article-title><source>Science</source><volume>336</volume><fpage>95</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1126/science.1216930</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kouneiher</surname><given-names>F</given-names></name><name><surname>Charron</surname><given-names>S</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year>2009</year><article-title>Motivation and cognitive control in the human prefrontal cortex</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>939</fpage><lpage>945</lpage><pub-id pub-id-type="doi">10.1038/nn.2321</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname><given-names>I</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><year>2011</year><article-title>Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>108</volume><fpage>13852</fpage><lpage>13857</lpage><pub-id pub-id-type="doi">10.1073/pnas.1101328108</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>SL</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><year>2013</year><article-title>Stimulus value signals in ventromedial PFC reflect the integration of attribute value signals computed in fusiform gyrus and posterior superior temporal gyrus</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>8729</fpage><lpage>8741</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4809-12.2013</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>SL</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><year>2011</year><article-title>The decision value computations in the vmPFC and striatum use a relative value code that is guided by visual attention</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>13214</fpage><lpage>13223</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1246-11.2011</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litt</surname><given-names>A</given-names></name><name><surname>Plassmann</surname><given-names>H</given-names></name><name><surname>Shiv</surname><given-names>B</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><year>2011</year><article-title>Dissociating valuation and saliency signals during decision-making</article-title><source>Cerebral Cortex</source><volume>21</volume><fpage>95</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq065</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McMillen</surname><given-names>T</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name></person-group><year>2006</year><article-title>The dynamics of choice among multiple alternatives</article-title><source>Journal of Mathematical Psychology</source><volume>50</volume><fpage>30</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2005.10.003</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niwa</surname><given-names>M</given-names></name><name><surname>Ditterich</surname><given-names>J</given-names></name></person-group><year>2008</year><article-title>Perceptual decisions between multiple directions of visual motion</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>4435</fpage><lpage>4445</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5564-07.2008</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Doherty</surname><given-names>J</given-names></name><name><surname>Kringelbach</surname><given-names>ML</given-names></name><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Hornak</surname><given-names>J</given-names></name><name><surname>Andrews</surname><given-names>C</given-names></name></person-group><year>2001</year><article-title>Abstract reward and punishment representations in the human orbitofrontal cortex</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>95</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1038/82959</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padoa-Schioppa</surname><given-names>C</given-names></name><name><surname>Assad</surname><given-names>JA</given-names></name></person-group><year>2006</year><article-title>Neurons in the orbitofrontal cortex encode economic value</article-title><source>Nature</source><volume>441</volume><fpage>223</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1038/nature04676</pub-id></element-citation></ref><ref id="bib35a"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><year>1997</year><article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title><source>Spatial Vision</source><volume>10</volume><fpage>437</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1163/156856897X00366</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Philiastides</surname><given-names>MG</given-names></name><name><surname>Biele</surname><given-names>G</given-names></name><name><surname>Heekeren</surname><given-names>HR</given-names></name></person-group><year>2010</year><article-title>A mechanistic account of value computation in the human brain</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>107</volume><fpage>9430</fpage><lpage>9435</lpage><pub-id pub-id-type="doi">10.1073/pnas.1001732107</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plassmann</surname><given-names>H</given-names></name><name><surname>O’Doherty</surname><given-names>J</given-names></name><name><surname>Rangel</surname><given-names>A</given-names></name></person-group><year>2007</year><article-title>Orbitofrontal cortex encodes willingness to pay in everyday economic transactions</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>9984</fpage><lpage>9988</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2131-07.2007</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rangel</surname><given-names>A</given-names></name><name><surname>Hare</surname><given-names>T</given-names></name></person-group><year>2010</year><article-title>Neural computations associated with goal-directed choice</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>262</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.03.001</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>JD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year>2002</year><article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>9475</fpage><lpage>9489</lpage></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rudebeck</surname><given-names>PH</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Kennerley</surname><given-names>SW</given-names></name><name><surname>Baxter</surname><given-names>MG</given-names></name><name><surname>Buckley</surname><given-names>MJ</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MF</given-names></name></person-group><year>2008</year><article-title>Frontal cortex subregions play distinct roles in choices between actions and stimuli</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>13775</fpage><lpage>13785</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3541-08.2008</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname><given-names>MF</given-names></name><name><surname>Noonan</surname><given-names>MP</given-names></name><name><surname>Boorman</surname><given-names>ED</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year>2011</year><article-title>Frontal cortex and reward-guided learning and decision-making</article-title><source>Neuron</source><volume>70</volume><fpage>1054</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.014</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Addis</surname><given-names>DR</given-names></name></person-group><year>2007</year><article-title>The cognitive neuroscience of constructive memory: remembering the past and imagining the future</article-title><source>Philosophical Transactions of the Royal Society of London Series B, Biological Sciences</source><volume>362</volume><fpage>773</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1098/rstb.2007.2087</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafir</surname><given-names>E</given-names></name></person-group><year>1993</year><article-title>Choosing versus rejecting: why some options are both better and worse than others</article-title><source>Memory &amp; Cognition</source><volume>21</volume><fpage>546</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.3758/BF03197186</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafir</surname><given-names>E</given-names></name><name><surname>Tversky</surname><given-names>A</given-names></name></person-group><year>1992</year><article-title>Choice under conflict: the dynamics of deferred decision</article-title><source>Psychological Science</source><volume>6</volume><fpage>358</fpage><lpage>361</lpage></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shidara</surname><given-names>M</given-names></name><name><surname>Richmond</surname><given-names>BJ</given-names></name></person-group><year>2002</year><article-title>Anterior cingulate: single neuronal signals related to degree of reward expectancy</article-title><source>Science</source><volume>296</volume><fpage>1709</fpage><lpage>1711</lpage><pub-id pub-id-type="doi">10.1126/science.1069504</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year>2009</year><article-title>Decision-making and prefrontal executive function</article-title><person-group person-group-type="editor"><name><surname>Gazzaniga</surname><given-names>MS</given-names></name></person-group><source>The Cognitive Neurosciences</source><publisher-name>MIT Press</publisher-name><fpage>1019</fpage><lpage>1030</lpage></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorndike</surname><given-names>EL</given-names></name></person-group><year>1898</year><article-title>Some experiments on animal intelligence</article-title><source>Science</source><volume>8</volume><fpage>520</fpage><pub-id pub-id-type="doi">10.1126/science.8.198.520</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tom</surname><given-names>SM</given-names></name><name><surname>Fox</surname><given-names>CR</given-names></name><name><surname>Trepel</surname><given-names>C</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year>2007</year><article-title>The neural basis of loss aversion in decision-making under risk</article-title><source>Science</source><volume>315</volume><fpage>515</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1126/science.1134239</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tremblay</surname><given-names>L</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year>1999</year><article-title>Relative reward preference in primate orbitofrontal cortex</article-title><source>Nature</source><volume>398</volume><fpage>704</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1038/19525</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Chater</surname><given-names>N</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name></person-group><year>2012</year><article-title>Salience driven value integration explains decision biases and preference reversal</article-title><source>Proceedings of the National Academy of Sciences of USA</source><volume>109</volume><fpage>9659</fpage><lpage>9664</lpage><pub-id pub-id-type="doi">10.1073/pnas.1119569109</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>A</given-names></name><name><surname>Kahneman</surname><given-names>D</given-names></name></person-group><year>1991</year><article-title>Loss aversion in riskless choice - a reference-dependent model</article-title><source>The Quarterly Journal of Economics</source><volume>106</volume><fpage>1039</fpage><lpage>1061</lpage><pub-id pub-id-type="doi">10.2307/2937956</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>A</given-names></name><name><surname>Kahneman</surname><given-names>D</given-names></name></person-group><year>1981</year><article-title>The framing of decisions and the psychology of choice</article-title><source>Science</source><volume>211</volume><fpage>453</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1126/science.7455683</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yaniv</surname><given-names>I</given-names></name><name><surname>Schul</surname><given-names>Y</given-names></name></person-group><year>1997</year><article-title>Elimination and inclusion procedures in judgment</article-title><source>Journal of Behavioral Addictions</source><volume>10</volume><fpage>211</fpage><lpage>220</lpage></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.03701.009</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Reviewing editor</role><aff><institution>Brandeis University</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>eLife posts the editorial decision letter and author response on a selection of the published articles (subject to the approval of the authors). An edited version of the letter sent to the authors after peer review is shown, indicating the substantive concerns or comments; minor concerns are not usually shown. Reviewers have the opportunity to discuss the decision before the letter is sent (see <ext-link ext-link-type="uri" xlink:href="http://elifesciences.org/review-process">review process</ext-link>). Similarly, the author response typically shows only responses to the major concerns raised by the reviewers.</p></boxed-text><p>Thank you for sending your work entitled “Neural mechanisms of economic commitment in the human medial prefrontal cortex” for consideration at <italic>eLife</italic>. Your article has been favorably evaluated by Eve Marder (Senior editor) and 3 peer reviewers.</p><p>The Senior editor and the reviewers discussed their comments before we reached this decision, and the Senior editor has assembled the following comments to help you prepare a revised submission.</p><p>While all of the reviewers found significant value in the experimental part of your work, the consultation among the reviewers revealed an essential difference of opinion about the value of the model and its analysis. A number of proposals surfaced in the consultation session, but these are summarized briefly as two options that I can offer you: Option 1) Strip down the paper to its essential and interesting experimental component, resulting in a strong and far simpler paper. Then, at your leisure, develop a second paper for a computational journal fleshing out how different competing models satisfactorily or not account for the data.</p><p>Option 2) More fully develop the modeling component so that you do a fair comparison of how a number of different models capture the essential features of the data.</p><p>The most extreme statement of this position comes from this comment from the consultation session, “If they do want to decide how best to model their empirical data, my feeling is that this would make a decent second paper for a modeling journal. To do that right they ought to consider, at the least, the main competitors to the DDM: The Cisek Model and the Stuphorn Model, also they might consider Usher-Mclelland. And of course if they want to do a really good job they should include a normative benchmark like the Beck/Ma/Pouget Bayesian modelling process. Were they to fit all of these that would be an incredibly interesting exercise. My guess is that (looking at their data) Pouget will way outperform the others.”</p><p>As it stands now, there is consensus that the experimental work is more satisfying than the modeling work, and that the latter either needs to be removed or strengthened.</p><p>Ordinarily we don't include the full reviews in this consensus review, but in this case, I think it might be instructive for you to see where the reviewers were coming from initially, as long as you understand that their initial positions and attitudes all changed during the consultative discussion. The Minor Comments are those that you would ordinarily see verbatim in an <italic>eLife</italic> review. Some of these comments will obviously be irrelevant if you take the simpler Option 1.</p><p><italic>Reviewer #1:</italic></p><p>The paper by Tsetos and colleagues represents an interesting and important contribution to decision neuroscience. As the authors point out, the psychological and neural mechanisms underlying decisions involving long-term commitments and interrelated choices are largely unknown and understudied. The authors have designed a novel and suitable decision paradigm in which to examine this type of choice. Moreover, their use of computational modeling methods at the behavioral level and the integration of those computationally defined parameters and values into the neuroimaging analysis yields results at both the descriptive and mechanistic levels. In general, the work is great and I think it will be quite influential in the field. There are a few puzzling aspects of the results, especially with regards to the specificity of value (DVcur-DVave) representations in the brain for different contexts and choice types. Puzzling results are not at all bad, quite the opposite as they often promote better understanding. However, there is one straightforward analysis that the authors have not presented in the paper, but could readily apply to the current data, and may be relevant to this issue. I outline this analysis and present two minor points below.</p><p>The value term used in the neuroimaging analysis is always the difference between current and average payoff estimates. This is a perfectly reasonable definition of value and numerous fMRI papers have reported that such a difference term is reflected in mPFC, PCC, or striatal BOLD signals. However, there are also a number of fMRI (e.g. <xref ref-type="bibr" rid="bib38">Plassman et al., 2007</xref>; Wunderlich et al., 2009) and single unit recording papers (e.g. <xref ref-type="bibr" rid="bib35">Padoa-Schioppa &amp; Assad 2006</xref>) that describe BOLD activity or firing rates as correlating with offer or chosen values rather than or in addition to difference values. Therefore, I wonder whether there might be regions in the brain that represent DVcur as opposed to DVcur-DVave and whether those regions also show choice and context specificity? Although testing this idea would require a small amount of additional work, I believe either positive findings or null results will provide a basis for a more complete interpretation of the currently reported results.</p><p>Minor Comments: In the Introduction, <xref ref-type="bibr" rid="bib38">Plassmann et al 2007</xref> is described as a binary food choice task. It is not, the participants bid money in an auction to receive the foods. The <xref ref-type="bibr" rid="bib30">Lim et al., 2011</xref> paper cited later in the Introduction is a good example of a binary food choice task the authors could cite here instead.</p><p>There is some disagreement in parameter values between the main text and SI. In the main text, the y-out value is listed as 7.19+/-0.35, but in the SI y-out is mislabeled as y-in and the SD is given as 2.35. These inconsistencies/typos should be corrected.</p><p><italic>Reviewer #2:</italic></p><p>I really enjoyed reading the paper “Neural mechanisms of economic commitment in the human medial prefrontal cortex” by Tsetsos and colleagues. The work is elegant and uses a sophisticated approach that combines modelling with neuroimaging data to address an important issue in decision theory (i.e. commitment vs. deferral). I am already familiar with this paper since I have reviewed it for a previous submission to a different journal. Since their original submission the authors have done a great job in reanalysing their data so as to address the concerns I had at the time. Furthermore in this current submission the authors have also extended their work to provide an intriguing explanation of how the framing bias observed in many classical decision tasks might be adaptive (increase reward maximisation) in the context of a more ecological task in which decisions are not taken in isolation. In this regard, I suggest that the authors look at the recent paper by Erev and Roth (just out in PNAS) that puts forward a similar case for reward maximisation in the context of learning. In this version of the manuscript Tsetsos and colleagues have also fitted a drift diffusion model to their data so as to provide an algorithmic description of the computational process preformed in PFC. I am happy to recommend this paper for publication in <italic>eLife</italic> and I am sure it will spark great interest in the community.</p><p>Minor Comments:</p><p>In its current form the paper is really dense in terms of results and therefore a few more lines in the Discussion section which recapitulate the main points and their significance would be of great help to many readers.</p><p><italic>Reviewer #3:</italic></p><p>Honestly, I struggled with this paper at a couple of levels and wanted to share with the authors what are somewhat conflicting views of the paper as written. At its core, the paper seeks to study a kind of decision that has not been too heavily studied within the area of decision neuroscience; the study of long-term commitments that yield variable income streams. Of course a number of papers have been published that look at 'investing' in stock-like objects (Cami Kuhnen was probably the first to do this a decade ago) that yield income on each trial of an experiment, but in most of those experiments subjects can change their 'investments' on each trial. A number of people have also looked at foraging decisions, which also have a similar flavor. In those experiments (and Ben Hayden's postdoc papers are probably the best early example) subjects have to decide whether to stay and harvest declining rewards or to leave and search for new, possibly better, rewards. In these experiments subjects do need to make a commitment, because deciding to switch costs them something in time and reward rates. So in these studies (which include work by Newsome's group and a lovely recent paper from Rushworth's group) there is a commitment being studied, but it is a costly rather than an irreversible commitment.</p><p>So I would have to say that the key novelty of this paper is not its study of commitment per se, but rather what is fairly unique is that it is a study of commitments that are 'irreversible' (at least for the remaining trials of the round).</p><p>Still, that is a novel area and the authors should get clear credit for exploring this new area. One could complain that they have overstated the novelty of the study by not acknowledging that studies which impose costs for 'changing your mind' (as in the matching law experiments of Newsome and Co, the foraging experiments of Hayden and Platt, or of Rushworth and Co.) are studies of commitment, but those are criticisms of exposition rather than core content.</p><p>With regard to core content, the most interesting result in the paper is the finding that 'committing' vs 'passing' yields differential activation in the ACC. That is an interesting finding and one that accords well (as noted in the paper) with previous findings by Rushworth's and Platt's groups. But even with regard to this finding, I was torn. The task that the authors used is, at heart, quite complicated. The subjects are asked to address a set of 4 uncertain bandits and to decide whether and when to commit to those bandits. So a number of phenomena are happening in parallel. First, the subjects face uncertainty which diminishes with each sample. Second, the subjects face bandits of different values. Finally, the subjects commit and face two commitment rules. So in essence one has a pile of variables moving in the task: value, certainty + probability of reward, rule, and a diminishing horizon to the end of the block. The subject adds to these her two decisions. And I think that there is enough going on these that one can’t be completely certain what is being represented at any point in time. That doesn't by any means make their findings uninteresting, not in the least, but it does make the experiment hard to interpret. Does the fact that the anterior MPFC responds more strongly in pass trials than on commit trials tell us about conditional value coding as the authors suggest or about something related to the decision other than value coding? It’s just hard to be certain.</p><p>The authors try to help us resolve this ambiguity by fitting their data with two decision rules and selecting the better fit of the two (current-minus-average) as a benchmark of sorts. But one cannot help but worry that the model they use is somewhat arbitrary. And here the fits were not has helpful to me as I might have hoped. The fits certainly capture the trends in the data, but in a subjective way. I really didn't know if the fits were 'good' in some objective sense.</p><p>Finally, the paper settles into a drift diffusion model of what the authors suggest might be the underlying process. Drift diffusion models are often used in this way, fit to the data as a demonstration that they can capture variance in a decision paper, but I wasn't honestly sure what the DDM added here. The DDM doesn't enhance our understanding of the scanner data, I don't think. And it isn't compared with any other reaction time model so the paper isn't arguing that the DDM is superior to some of other set of models for reaction time commitment decisions.</p><p>Specific Suggestions: Going forward, the paper would be improved if it began with a very clear statement of what is novel in this work. That begins, of necessity, with a clear statement of what a 'commitment' is. What is a commitment? To an economist it is a cost of some kind imposed for future 'switches'. That cost could be a few seconds as in the old Baum-Herrnstein matching law experiments, something more complicated as in the Hayden Platt experiments or a financial cost as in some of the studies of people trading in stock markets. This is a very high cost commitment and that is novel.</p><p>Next, we really need a normative theory of what a commitment does to the value of an option. That's not too hard. The model needs to ask, on each trial, what is the value of committing (on average) under the current conditions. What is the value of passing. These are aggregate discounted expectations, so there is some subtlety here, and risk aversion must be taken into account, but this is pretty standard stuff from finance 101. Then one needs to try and relate these standard finance assessments to neural activation. What one needs to show is that these standard normative models FAIL to account for what is going on and that some alternative framework exceeds the predictive neural power of this standard benchmark model.</p><p>Minor Comments: The authors use the word normative in an odd way and this leads them, occasionally, to say things that seem false. The note, for instance, Shafir's axiomatic proof about preference reversals and then go on to argue that their data show that under these conditions such preference reversals are normative. This is super tangled. The normative question is: are there times when you would rule out/rule in asymmetrically in this task. That really calls for an axiomatic proof, which would be quite do-able. But instead they use a simulation to try and show that they get good maximization with an asymmetric rule. This gets confusing fast. I would urge the authors to try and do the axiomatic proof for their environment or to just stay away from axiomatics altogether. Mixing them haphazardly with numerics is just making the story hard to follow.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.03701.010</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>In the revised submission, we followed your suggestion (1), i.e. to strip the paper to its empirical findings, removing the diffusion modeling component. Although our original aim was to use the diffusion model as a descriptive tool to jointly capture patterns in mean choice, response times and neural activity (rather than to claim the superiority of the diffusion model over more realistic counterparts), we do agree that mechanistic modeling and model comparison issues can and should be addressed in a separate paper. Therefore, we have removed all references to the diffusion modeling part from the manuscript and eliminated the relevant figures. Whilst there a few references to a “model” do remain, these pertain to the current-minus-average model of value coding, which was unrelated to the sequential sampling assumptions that the reviewers called into question.</p><p>Removing the sequential sampling modeling somewhat weakens the claim that the two behavioural biases (deferral bias and exclusion proneness) are dissociable at the computational level. Accordingly, we have toned down our language in asserting this claim; nevertheless, in the Discussion section we continue to call upon the neural data from the dACC (<xref ref-type="fig" rid="fig4">Figure 4</xref>) which show both a main effect (of commit vs. defer) and an interaction exclude/include x value to support the argument that there are separable additive and multiplicative biases, and that the dACC signals encode these biases.</p><p>Finally, as per editorial request, we removed the Supplementary Information and incorporated condensed parts of it to the main text (mainly as Materials and methods while some of the secondary results are now concisely given in figure captions).</p><p>To facilitate your processing of our revision, we outline below the main structural changes in the paper. We also point to minor changes we did to correct lapses and omissions, based on some of the reviewers’ constructive suggestions.</p><p>The whole section “Mechanistic model of commitment and deferral” and the relevant subsections were removed.</p><p>The Discussion part was modified to reflect the removal of the diffusion modeling. One full paragraph was removed and we instead added a new paragraph. This new paragraph, based on the qualitative patterns in dACC, mentions the possibility that the biases in our task are computationally dissociable.</p><p>Both reviewers 1 and 3 asked for clarification about the term “commitment” and noted that part of the interest of our task is that decisions cannot be reversed.</p><p>We have thus added to our definition of this term in the Introduction accordingly, and clarified that in our task a decision to accept or reject is final. We have taken reviewer’s 1 suggestion and replaced in the Introduction the reference to <xref ref-type="bibr" rid="bib38">Plassman et. al (2007)</xref> with <xref ref-type="bibr" rid="bib30">Lim et. al (2011)</xref>.</p><p>Regarding reviewer’s 2 suggestion about complementary fMRI analyses we would like to point to the new <xref ref-type="fig" rid="fig3">Figure 3</xref> (A and B) and the corresponding caption. There, we show the distinct neural encoding of the average value of the bandit under offer as well as the encoding of the block’s reference value.</p><p>Following reviewer’s 2 recommendation, we now cite <xref ref-type="bibr" rid="bib11">Erev and Roth (2014)</xref>.</p><p>We have replaced the term “normative” with the term “adaptive” or “reward-maximizing” in several parts, taking on board reviewer’s 3 concern that the term normative might lead to misunderstandings.</p><p>We have removed Figures 5 and 6 that corresponded to the diffusion modeling part. Note that Figure 5D, showing the average response times in the task, has been moved to <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p><p>We completely removed the Supplementary Information.</p><p>Figure S1B is now <xref ref-type="fig" rid="fig2">Figure 2C</xref>. Ex-<xref ref-type="fig" rid="fig2">Figure 2C</xref> is <xref ref-type="fig" rid="fig2">Figure 2D</xref>. We removed Figure S1A because it was redundant given Table S1 (currently <xref ref-type="table" rid="tbl1">Table 1</xref>). We removed Figure S1C because it conveyed information of secondary importance.</p><p>Figure S2 has now moved to <xref ref-type="fig" rid="fig3">Figure 3</xref>. Also Table S2 is now submitted as source data linked to <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></body></sub-article></article>