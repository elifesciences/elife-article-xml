<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="hwp">eLife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">18372</article-id><article-id pub-id-type="doi">10.7554/eLife.18372</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>An extended retinotopic map of mouse cortex</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-59997"><name><surname>Zhuang</surname><given-names>Jun</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6237-3270</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-59998"><name> <surname>Ng</surname><given-names>Lydia</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-59999"><name> <surname>Williams</surname><given-names>Derric</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-60000"><name><surname>Valley</surname><given-names>Matthew</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-60001"><name> <surname>Li</surname><given-names>Yang</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-60002"><name><surname>Garrett</surname><given-names>Marina</given-names> </name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-30294"><name> <surname>Waters</surname><given-names>Jack</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2312-4183</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>Allen Institute for Brain Science</institution>, <addr-line><named-content content-type="city">Seattle</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kleinfeld</surname><given-names>David</given-names></name><role>Reviewing editor</role><aff id="aff2"><institution>University of California, San Diego</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><email>jackw@alleninstitute.org</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>06</day><month>01</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>6</volume><elocation-id>e18372</elocation-id><history><date date-type="received"><day>01</day><month>06</month><year>2016</year></date><date date-type="accepted"><day>21</day><month>11</month><year>2016</year></date></history><permissions><copyright-statement>© 2017, Zhuang et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Zhuang et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-18372-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.18372.001</object-id><p>Visual perception and behavior are mediated by cortical areas that have been distinguished using architectonic and retinotopic criteria. We employed fluorescence imaging and GCaMP6 reporter mice to generate retinotopic maps, revealing additional regions of retinotopic organization that extend into barrel and retrosplenial cortices. Aligning retinotopic maps to architectonic borders, we found a mismatch in border location, indicating that architectonic borders are not aligned with the retinotopic transition at the vertical meridian. We also assessed the representation of visual space within each region, finding that four visual areas bordering V1 (LM, P, PM and RL) display complementary representations, with overlap primarily at the central hemifield. Our results extend our understanding of the organization of mouse cortex to include up to 16 distinct retinotopically organized regions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.001">http://dx.doi.org/10.7554/eLife.18372.001</ext-link></p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.18372.002</object-id><title>eLife digest</title><p>Our eyes send information about the world around us to a region on the surface of the brain called the visual cortex, which is made up of a series of interconnected areas. Researchers have studied the anatomy and activity of these areas to generate maps that show how these areas are arranged. For example, architectonic borders are drawn where there are abrupt changes in the density of cells, or the degree to which they are stained by certain chemicals. Maps based on architectonics and those based on brain activity are thought to exhibit matching borders between visual areas.</p><p>Zhuang et al. used animaging approach to produce detailed maps of the visual cortex of mice. The approach uses a fluorescent protein called GCaMP6 to indicate levels of activity in the brain while the mice were exposed to visual cues. Furthermore, Zhuang et al. added a second step to this approach to reveal the architectonic borders of the areas in the visual cortex. This made it possible to compare the locations of activity-based and anatomical borders in a single mouse.</p><p>Zhuang et al. found that maps of the visual cortex based on architectonics do not completely match those based on activity. These findings help reconcile the differences between maps of mouse visual cortex produced by other studies. It is not clear whether a similar mismatch in architectonic and activity-based border locations exists in other animals, such as primates.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.002">http://dx.doi.org/10.7554/eLife.18372.002</ext-link></p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author Keywords</title><kwd>cortex</kwd><kwd>topographic map</kwd><kwd>visual map</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research Organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>Allen Institute for Brain Science</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Zhuang</surname><given-names>Jun</given-names></name><name> <surname>Ng</surname><given-names>Lydia</given-names></name><name> <surname>Williams</surname><given-names>Derric</given-names></name><name> <surname>Li</surname><given-names>Yang</given-names></name><name><surname>Garrett</surname><given-names>Marina</given-names> </name><name> <surname>Waters</surname><given-names>Jack</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NS078067</award-id><principal-award-recipient><name> <surname>Waters</surname><given-names>Jack</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2.5</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>An expanded map of mouse cortex reveals the expansion of retinotopic organization into barrel and retrosplenial cortices.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Mammalian visual cortex consists of a series of interconnected areas, which correspond to topographically-organized collections of neurons with similar functional properties and patterns of connectivity (<xref ref-type="bibr" rid="bib46">Van Essen, 2003</xref>). In mouse neocortex, 12 visual areas have been identified, each corresponding to a retinotopically-organized map of the visual field (<xref ref-type="bibr" rid="bib7">Dräger, 1975</xref>; <xref ref-type="bibr" rid="bib48">Wagor et al., 1980</xref>; <xref ref-type="bibr" rid="bib28">Olavarria et al., 1982</xref>; <xref ref-type="bibr" rid="bib29">Olavarria and Montero, 1989</xref>; <xref ref-type="bibr" rid="bib38">Schuett et al., 2002</xref>; <xref ref-type="bibr" rid="bib15">Kalatsky and Stryker, 2003</xref>; <xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>; <xref ref-type="bibr" rid="bib22">Marshel et al., 2011</xref>; <xref ref-type="bibr" rid="bib51">Wang and Burkhalter, 2013</xref>; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib43">Tohmi et al., 2014</xref>).</p><p>The borders between visual areas have been located using architectonic and retinotopic criteria. Architectonic borders are associated with changes in staining (chemoarchitectonics), cell density (cytoarchitectonics), or myelination patterns (myeloarchitechtonics). Retinotopic borders are associated with a change in chirality of the retinotopic map and have been identified anatomically by labeling projections between visual areas, and functionally by recording the responses of neurons with electrodes or imaging techniques. The architectonic and retinotopic borders of visual areas in the mouse are generally thought to be co-aligned, but the shapes and locations of visual areas can differ across studies.</p><p>We generated retinotopic maps from GCaMP6 transgenic mice (<xref ref-type="bibr" rid="bib5">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib20">Madisen et al., 2015</xref>) and compared functional retinotopic, anatomical retinotopic, chemoarchitectonic, cytoarchitectonic and myeloarchitechtonic maps. Our results revealed new regions of retinotopic organization in mouse neocortex, some within and some outside the accepted boundaries of mouse visual cortex, and a mismatch between retinotopic and architectonic maps that may help reconcile the differences between visual area maps generated by these complementary approaches.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>GCaMP6 expression patterns and fluorescence signals</title><p>We mapped visual areas in three GCaMP6 reporter lines: Ai95(RGL-GCaMP6f), Ai96(RGL-GCaMP6s) and Ai93(TITL-GCaMP6f). Each reporter line was crossed with the Emx1-IRES-Cre line, driving GCaMP6 expression in pyramidal neurons in all layers of neocortex (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). We imaged through a 5 mm diameter glass window implanted over visual areas (<xref ref-type="fig" rid="fig1">Figure 1A,B</xref>). The time-averaged fluorescence, measured in primary visual cortex in the absence of visual stimuli, was greater in all three reporter lines than in wild-type mice (<xref ref-type="fig" rid="fig1">Figure 1H</xref>; fluorescence normalized to wild-type, Emx1-Ai95 10.3 ± 1.3, Emx1-Ai96 4.7 ± 0.5, Emx1-Ai93 49.7 ± 5.9).<fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.003</object-id><label>Figure 1.</label><caption><title>Amplitude and kinetics of fluorescence transients to brief visual stimuli.</title><p>(<bold>A</bold>) Fluorescence image focused on the cortical surface of an Emx1-Ai95 mouse. Approximate edge of 5 mm diameter craniotomy is marked with a dashed line. (<bold>B</bold> and <bold>C</bold>) Baseline (<bold>B</bold>) and peak (<bold>C</bold>) change in fluorescence for the field of view shown in <bold>A</bold>. In <bold>C</bold>, dashed line and circle indicate the regions used to extract values for <bold>D</bold> and <bold>E</bold>, respectively. (<bold>D</bold>) Spatial extent of the fluorescence change along line marked in panel <bold>C</bold>. Width of response at half height (dashed line) is 190 µm. (<bold>E</bold>) Fluorescence time course for a single trial, from the region marked in panel <bold>C</bold>. <bold>D</bold> and <bold>E</bold> are in arbitrary fluorescence units. (<bold>F</bold>) Mean ± SEM fractional fluorescence changes for each mouse line. Four wild-type mice (black), 6 Emx1-Ai95 mice (red), 4 Emx1-Ai96 mice (green), 4 Emx1-Ai93 mice (blue). Stimulus indicated with black bar. (<bold>G</bold>) Mean change in fluorescence (△F) for each mouse line, normalized to the peak amplitude of the fluorescence change in wild-type mice (△F<sub>WT</sub>). Shaded areas denote ± SEM. (<bold>H</bold>) Time-averaged baseline fluorescence, normalized to wild-type mice. Bears denote mean ± SEM from four wild-type mice, 6 Emx1-Ai95 mice, 4 Emx1-Ai96 mice, 4 Emx1-Ai93 mice. (<bold>I</bold>) Peak fractional fluorescence change. (<bold>J</bold>) Time to peak fluorescence, measured from the onset of the stimulus.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.003">http://dx.doi.org/10.7554/eLife.18372.003</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig1-v1"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Expression of GCaMP6 in Emx1-Ai95, Emx1-Ai96 and Emx1-Ai93 mice under the Emx1-IRES-Cre driver.</title><p>Images of GCaMP6 fluorescence in 100 µm-thick coronal sections. (<bold>A</bold>) Two-photon image of GCaMP6 fluorescence throughout the depth of cortex in an Emx1-Ai93 mice. White matter is to the left of the image, pia to the right. Three stitched images in a single optical plane. Note the absence of GCaMP6 from the nuclei; we observed nuclear exclusion in all neurons examined (271 neurons in layer 2/3 of visual cortex, 1 Emx1-Ai93 mouse). (<bold>B</bold>) Widefield images of visual cortices of an Emx1-Ai95, an Emx1-Ai96 and a wild-type mouse. Same spatial and intensity scale for all images. (<bold>C</bold>) Widefield image from an Emx1-Ai93 mouse. Same spatial scale, but a different intensity scale from the images in <bold>B</bold>. (<bold>D</bold>) Summary of laminar variations in fluorescence intensity in visual cortex. Bars represent mean ± SEM fluorescence (arbitrary units). n = 4 (two hemispheres from two mice for each line). Emx1-Ai93: asterisks denote significant difference in intensity compared to layer 4 (p&lt;0.05, two-tailed t-test). (<bold>E</bold>) Widefield fluorescence images of three 100 µm-thick coronal sections from an Emx1-Ai95 mouse. (<bold>F</bold>) Widefield fluorescence images of three coronal sections from an Emx1-Ai93 mouse. Approximate of cortical areas (arrow heads) were derived from <xref ref-type="bibr" rid="bib8">Franklin and Paxinos (2007)</xref>. M motor cortex, S1a anterior primary somatosensory cortex (likely jaw and forepaw representations), S1p posterior primary somatosensory cortex (likely trunk and hindpaw representations), S1v vibrissal primary somatosensory cortex, S2 secondary somatosensory cortex, V visual cortex, A auditory cortex. (<bold>G</bold>) Summary of areal variations in fluorescence intensity. Bars represent mean ± SEM fluorescence (arbitrary units). n = 4 (two hemispheres from two mice for each line). In Emx1-Ai95 mice, GCaMP6 was evenly distributed across the layers of neocortex (<xref ref-type="fig" rid="fig1">Figure 1B,D</xref>) and across neocortical areas (<xref ref-type="fig" rid="fig1">Figure 1E,G</xref>). Fluorescence displayed laminar and areal variations in Emx1-Ai93 mice (<xref ref-type="fig" rid="fig1">Figure 1C,D,F,G</xref>), likely due to use of the CaMK2a-tTA line to enhance expression of GCaMP6 (<xref ref-type="bibr" rid="bib23">Mayford et al., 1996</xref>; <xref ref-type="bibr" rid="bib16">Krestel et al., 2001</xref>); Allen Mouse Brain Connectivity Atlas, Transgenic Characterization <ext-link ext-link-type="uri" xlink:href="http://connectivity.brain-map.org/transgenic">http://connectivity.brain-map.org/transgenic</ext-link>).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.004">http://dx.doi.org/10.7554/eLife.18372.004</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig1-figsupp1-v1"/></fig></fig-group></p><p>To measure response amplitudes and kinetics, we presented mice with a brief visual stimulus consisting of a white circle on a black background (diameter 20 degrees; center location 60° azimuth, 0° altitude; 50 ms duration). In wild-type mice, brief stimuli evoked a decrease in fractional fluorescence of −2.3 ± 0.3% △F/F (four mice, <xref ref-type="fig" rid="fig1">Figure 1F</xref>). In all three mouse lines we observed transient activation of visual areas (<xref ref-type="fig" rid="fig1">Figure 1C-E</xref>) that was larger and faster than autofluorescence signals in wild-type mice (<xref ref-type="fig" rid="fig1">Figure 1F,G,I,J</xref>), followed by a decline in fluorescence that may result from vasodilation (<xref ref-type="bibr" rid="bib34">Pisauro et al., 2013</xref>). In Emx1-Ai93 mice, brief stimuli evoked a peak fractional fluorescence change of 10 ± 2.4% △F/F (range 5.7–15.0% △F/F, 4 mice, <xref ref-type="fig" rid="fig1">Figure 1F</xref>) and a mean peak change in absolute GCaMP6 fluorescence that was 216 times the peak fluorescence change observed in wild-type mice (<xref ref-type="fig" rid="fig1">Figure 1G</xref>). All GCaMP6 mice displayed kinetics that were faster than the autofluorescence signal in wild-type mice (latency to peak from stimulus onset of 252 ± 49 ms, 6 Emx1-Ai95mice; 414 ± 60 ms, 4 Emx1-Ai96 mice; 219 ± 60 ms, 4 Emx1-Ai93 mice; 1.37 ± 0.3 s, four wild-type mice; mean 10–90% rise and decay times 71 and 536 ms in Emx1-Ai95 mice, 225 and 1151 ms in Emx1-Ai96 mice, 69 and 752 ms in Emx1-Ai93 mice). In summary, all three Emx1-GCaMP6 mouse lines displayed brighter fluorescence and faster fluorescence changes than wild-type mice with the result that the changes in fluorescence were dominated by GCaMP6.</p></sec><sec id="s2-2"><title>Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization</title><p>To generate retinotopic maps, we employed a spherically-corrected checkerboard visual stimulus drifting across the visual field at 0.043–0.048 Hz (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) (<xref ref-type="bibr" rid="bib15">Kalatsky and Stryker, 2003</xref>; <xref ref-type="bibr" rid="bib22">Marshel et al., 2011</xref>) and mapped retinotopy in Emx1-GCaMP6 mice that were head-restrained and free to run on a rotating disk. The mean fluorescence change was greatest in visual cortex (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), where the signal-to-noise ratio was sufficient to identify visually-evoked changes in fluorescence in individual trials (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). To generate retinotopic maps, we averaged 10–40 presentations of the stimulus in each of the four cardinal directions, thereby reducing the potential effects of ongoing activity (<xref ref-type="fig" rid="fig2">Figure 2D</xref>; <xref ref-type="other" rid="media1">Video 1</xref>). We generated azimuth and altitude position maps (<xref ref-type="bibr" rid="bib15">Kalatsky and Stryker, 2003</xref>) that included retinotopic locations across the visual field from approximately −20 to +30 degrees in altitude and −10 to +90 degrees in azimuth (<xref ref-type="fig" rid="fig2">Figure 2E,F</xref>). As described previously (<xref ref-type="bibr" rid="bib40">Sereno et al., 1994</xref>; <xref ref-type="bibr" rid="bib39">1995</xref>; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>), phase maps were consolidated into a visual field sign map (<xref ref-type="fig" rid="fig2">Figure 2G</xref>).<media content-type="glencoe play-in-place height-250 width-310" id="media1" mime-subtype="mp4" mimetype="video" xlink:href="elife-18372-media1.mp4"><object-id pub-id-type="doi">10.7554/eLife.18372.005</object-id><label>Video 1.</label><caption><title>Example fluorescence movies from retinotopic mapping experiment.</title><p>Example of fluorescence changes during retinotopic mapping. Left: response to checkerboard travelling from the lower to the upper visual field. Right response to checkerboard travelling from the nasal to temporal visual field. Each movie is the mean change in fluorescence (△F) of 40 trials.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.005">http://dx.doi.org/10.7554/eLife.18372.005</ext-link></p></caption></media><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.006</object-id><label>Figure 2.</label><caption><title>Example of a GCaMP6 fluorescence-based retinotopic map.</title><p>Example of a GCaMP6 fluorescence-based retinotopic mapping data set from an awake mouse, generated with the drifting checkerboard stimulus on a grey background. (<bold>A</bold>) A single image from the visual stimulus movie used to map in the nasal to temporal (azimuth) direction in an Emx1-Ai96 mouse. The checkerboard pattern was swept from left to right (arrow) on a grey background. (<bold>B</bold>) Greyscale image illustrating the amplitude of the fluorescence change at 0.043 Hz during azimuth mapping, normalized to the maximum amplitude in the image. Dashed white circle approximates the border of the cranial window. (<bold>C</bold>) Spatial average fluorescence during nasal (N) to temporal (T) mapping from the region of interest outlined in green in panel <bold>B</bold>. The timing of stimulus presentation is indicated below, where the black segments indicate the center position of the checkerboard bar from −14 to 132 degrees (azimuth) and the grey segments indicate that no stimulus was on the monitor. (<bold>D</bold>) Fractional fluorescence changes from the three regions marked in panel <bold>B</bold>. Each trace is the average of 10 presentations of the stimulus. (<bold>E</bold> and <bold>F</bold>) Altitude and azimuth maps for the same cranial window. (<bold>G</bold>) Field sign map derived from the altitude and azimuth maps. (<bold>H</bold>) The result of automated border identification, drawn on a brightfield image of the brain surface over visual areas. Named visual areas were identified manually, based on published maps of visual areas.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.006">http://dx.doi.org/10.7554/eLife.18372.006</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig2-v1"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.007</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Schematic summary of border identification routine.</title><p>Summary of analysis steps for the generation of borders from altitude and azimuth maps. The left column summarizes the steps from altitude and azimuth maps to the sign map. The right column summarizes generation of borders from the sign map. Image names match those in the example Python notebook available at <ext-link ext-link-type="uri" xlink:href="https://github.com/zhuangjun1981/retinotopic_mapping">https://github.com/zhuangjun1981/retinotopic_mapping</ext-link> Blue text indicates the main variables employed at each step. Variables are described in the example notebook.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.007">http://dx.doi.org/10.7554/eLife.18372.007</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig2-figsupp1-v1"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.008</object-id><label>Figure 2—figure supplement 2.</label><caption><title>Effects of sign map threshold on patch size, shape and visual coverage.</title><p>(<bold>A</bold>) Comparison of borders (black lines), calculated using threshold values (variable signMapThr in analysis code) of 0.2, 0.3 and 0.4. For each panel, borders were calculated (and are overlaid onto) the mean sign map (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), with all variables within the analysis code held constant except the sign map threshold. Thresholds of 0.2 and 0.4 are the limits of the range of values employed in the analysis of our data sets and a threshold of 0.3 is close to the mean value (mean = 0.32). (<bold>B</bold>) Overlaid images of patches. Patches are shown in black, with the result that invariant borders are readily visible in white. Note that borders between two patches are generally stable unless the threshold is raised enough to eliminate the border. For example, all the borders of V1 are virtually invariant across the threshold range from 0.2 to 0.4; borders between RL and LM and between LM and P are unaffected by the change in threshold from 0.2 to 0.3, but are absent at a threshold of 0.4. (<bold>C</bold>) Borders overlaid in color to emphasize the sensitivity the exterior borders of the map to changes in threshold. Exterior borders typically retract as the threshold is raised. (<bold>D</bold>) Effects of threshold on the visual coverage of each patch. For most patches, the change in coverage with threshold is mild and is less than the difference in coverage between patches. As expected, the change in coverage is more pronounced for patches on the periphery of the map that display weaker changes in fluorescence to the visual stimulus, such as patches LLA and RLL.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.008">http://dx.doi.org/10.7554/eLife.18372.008</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig2-figsupp2-v1"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.009</object-id><label>Figure 2—figure supplement 3.</label><caption><title>Eye movements and pupil area during retinotopic mapping.</title><p>(<bold>A</bold>) Example of pupil position and area in an anesthetized mouse during azimuth mapping on a black background on which the stimulus moved in the nasal-to-temporal direction. Stimulus is shown schematically (top left). Images of the pupil at time points 1 and 2 are overlaid with circles fit by analysis software that locates the reflection of the infrared LED (inner, black circle) and the perimeter of the pupil (outer, white circle). Pupil position in horizontal and vertical dimensions were measured relative to the mean position, with ten individual traces in grey and the mean in black. Stimulus position is indicated as in <xref ref-type="fig" rid="fig4">Figure 4</xref>. (<bold>B</bold>) Example of pupil position and area in an awake mouse during azimuth mapping on a black background. (<bold>C</bold>) Example of pupil position and area in an awake mouse during azimuth and altitude mapping on a grey background of 50% of maximum luminance. (<bold>D</bold>) Mean pupil location and area during grey-background retinotopic mapping with all four stimulus directions. Mean (black line) ± SEM (grey area) results from 11 mice. Horizontal lines indicate mean horizontal or vertical pupil position.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.009">http://dx.doi.org/10.7554/eLife.18372.009</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig2-figsupp3-v1"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.010</object-id><label>Figure 2—figure supplement 4.</label><caption><title>Comparison of maps with and without eye movements.</title><p>Maps from an Emx1-Ai96 mouse, generated after sorting trials into those with and those without eye movement of two degrees or greater. (<bold>A</bold>) Eye position for individual trails, sorted by stimulus direction. (<bold>B</bold>) Resulting sign maps and border locations. (<bold>C</bold>) Comparison of patches. Borders between visual areas (e.g. between V1 and LM/RL) were largely unaffected by eye movements. The exterior borders of the sign map display greater differences, either as a result of eye movements or of averaging across the relatively small number of trials without eye movements.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.010">http://dx.doi.org/10.7554/eLife.18372.010</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig2-figsupp4-v1"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.011</object-id><label>Figure 2—figure supplement 5.</label><caption><title>Comparison of fluorescence changes and V1 coverage with stimuli on black and grey backgrounds.</title><p>(<bold>A</bold>) Fractional fluorescence changes from three regions in V1 (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>) from mice mapped under three conditions: mouse anesthetized, stimulus on black background; mouse awake, stimulus on black background; and mouse awake, stimulus on grey background. Each trace is the average of 10 presentations of the stimulus. Dashed vertical line marks the initial fluorescence transient following appearance of the stimulus at the nasal edge of the monitor. The timing of stimulus presentation is indicated below. When presented on a black background, the initial appearance of the checkerboard stimulus evoked an increase in fluorescence across much of cortex (and a decrease in pupil size; see <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3A,B</xref>). This global fluorescence transient could shift the calculated phases of the peak responses, resulting in miscalculation of retinotopic position. (<bold>B</bold>) Comparison of coverage for V1 in one mouse, mapped with black and grey backgrounds. The apparent coverage of V1 was reduced when the stimulus was presented on a black background. The coverage was 3481 degrees<sup>2</sup> with black background and 4032 degrees<sup>2</sup> with grey background. (<bold>C</bold>) Population average of V1 coverage for 11 mice (mean ± SEM, black and grey bars indicate black and grey backgrounds, respectively, p&lt;0.05, two-tailed t-test). Mapping using a black background resulted in a 21% reduction in coverage of V1 relative to mapping with a grey background (coverage 2902 ± 349 degrees<sup>2</sup> with a black background and 3655 ± 313 degrees<sup>2</sup> with a grey background, 11 mice, p&lt;0.05, paired t-test).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.011">http://dx.doi.org/10.7554/eLife.18372.011</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig2-figsupp5-v1"/></fig></fig-group></p><p>The borders between field sign patches (<xref ref-type="fig" rid="fig2">Figure 2H</xref>) were identified using a numerical routine (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Briefly, the sign map was lightly filtered and thresholded to create an initial parcellation of cortex into patches. The threshold was tuned manually, with little change in the incidence, shape, border locations and area of most patches over the range of threshold values employed (0.2–0.4, mean ± SEM of 0.32 ± 0.004, 14 mice; <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Patches were split and merged to ensure that neighboring patches with the same sign had redundant representation of visual space of ≤10% (see Materials and methods).</p><p>If sufficiently large and stereotyped, changes in pupil location or size might confound generation of accurate retinotopic maps in awake mice. During mapping, we observed abrupt eye movements of up to ~5–10 degrees vertically and up to ~15–20 degrees horizontally (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3C</xref>). Movements occurred during all phases of the stimulus and mean displacement was &lt;~1 degree (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3D</xref>), leading us to conclude that movement-related effects were eliminated by averaging in our experiments (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). To minimize systematic changes in pupil size, we employed a stimulus with a constant mean luminance, delivering the moving checkerboard pattern on a grey background with 50% of the maximum luminance (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>, <xref ref-type="other" rid="media2">Videos 2</xref>,<xref ref-type="other" rid="media3">3</xref>). Hence, in our experiments maps were largely unaffected by eye movements or changes in pupil size.<media content-type="glencoe play-in-place height-250 width-310" id="media2" mime-subtype="mp4" mimetype="video" xlink:href="elife-18372-media2.mp4"><object-id pub-id-type="doi">10.7554/eLife.18372.012</object-id><label>Video 2.</label><caption><title>Lower-to-upper visual field visual stimulus.</title><p>Lower to upper visual field moving checkerboard stimulus used for retinotopic mapping. </p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.012">http://dx.doi.org/10.7554/eLife.18372.012</ext-link></p></caption></media><media content-type="glencoe play-in-place height-250 width-310" id="media3" mime-subtype="mp4" mimetype="video" xlink:href="elife-18372-media3.mp4"><object-id pub-id-type="doi">10.7554/eLife.18372.013</object-id><label>Video 3.</label><caption><title>Nasal-to-temporal visual stimulus.</title><p>Nasal-to-temporal moving checkerboard stimulus used for retinotopic mapping. </p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.013">http://dx.doi.org/10.7554/eLife.18372.013</ext-link></p></caption></media></p><p>Twelve discrete areas have been identified in mouse visual cortex: primary visual cortex (V1), lateromedial area (LM), rostrolateral area (RL), anterior area (A), anteromedial area (AM), posteromedial area (PM), medial area (M), posterior area (P), postrhinal area (POR), laterointermediate area (LI), anterolateral area (AL), and laterolateral anterior area (LLA) (<xref ref-type="bibr" rid="bib7">Dräger, 1975</xref>; <xref ref-type="bibr" rid="bib48">Wagor et al., 1980</xref>; <xref ref-type="bibr" rid="bib28">Olavarria et al., 1982</xref>; <xref ref-type="bibr" rid="bib29">Olavarria and Montero, 1989</xref>; <xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>). Each area contains one retinotopic map and therefore appears in field sign maps as a single, distinct, positive or negative field sign patch (<xref ref-type="bibr" rid="bib40">Sereno et al., 1994</xref>, <xref ref-type="bibr" rid="bib39">1995</xref>). Across mice these patches are arranged in a stereotyped configuration with consistent positioning relative to each other. To identify regions in our maps objectively, we used the automated image analysis approach described by <xref ref-type="bibr" rid="bib9">Garrett et al. (2014)</xref>, which identifies field sign patches that each contain one and only one map of retinotopic space.</p><p>Most field sign patches were visible after only 15 min of imaging (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; 10 sweeps of the stimulus in each direction) and maps were stable across imaging sessions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The ability to quickly generate maps that are comparable to those resulting from 1–2 hr of red-wavelength reflectance-based imaging under anesthesia (<xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>) is a practical advantage of GCaMP6 fluorescence-based mapping. Typically, we further reduced the effects on ongoing activity by presenting 20–40 sweeps of the stimulus in each direction (imaging for 30–60 min). Like previous authors, we found that maps displayed consistent structure across mice (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The arrangement of areas was broadly consistent with published maps of the mouse visual system (e.g. <xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>; <xref ref-type="bibr" rid="bib22">Marshel et al., 2011</xref>; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>), but differed in several respects. Key differences include additional visual field sign patches, particularly medial to AM and PM (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The narrow strip of tissue between AM/PM and retrosplenial cortex is generally termed MM or V2MM and is considered part of visual cortex (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>; <xref ref-type="bibr" rid="bib8">Franklin and Paxinos, 2007</xref>), but its retinotopic structure remains uncharacterized. GCaMP6 fluorescence-based maps revealed consistent structure in MM, with a positive field sign patch medial to AM (MMA) and a negative field sign patch medial to PM (MMP). Furthermore, there were one or more positive field sign patches medial to MMA and MMP, likely in retrosplenial cortex. The most consistent was a positive field sign region which our automated segmentation routine generally failed to separate from PM. Finally, in lateral visual cortex, we observed a negative field sign patch anterior and lateral to RL, which we termed RLL.<fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.014</object-id><label>Figure 3.</label><caption><title>Retinotopic organization of mouse visual cortex.</title><p>(<bold>A</bold>) Field sign maps from six mice, illustrating differences between mouse lines and individual mice. The mouse line and duration of imaging are indicated on each map. Scale bar 0.5 mm. (<bold>B</bold>) Mean field sign maps for 4 Emx1-Ai96 and 10 Emx1-Ai93 mice, from 30–75 min of imaging. (<bold>C</bold>) Mean of the Emx1-Ai96 and Emx1-Ai93 field sign maps in panel B, with borders and area labels. (<bold>D</bold>) Map of variance of the visual field sign. Variance was calculated from visual field sign maps from 14 mice, after alignment as described for calculation of the mean field sign map. Whiter areas denote higher variance. Area borders are overlaid in white. (<bold>E</bold>) The probability of mapping different visual areas with GCaMP6 fluorescence in awake mice. Blue and red bars denote areas with negative and positive field signs, respectively. Results were derived from 14 mice (4 Emx1-Ai96, 10 Emx1-Ai93). Mouse numbers: V1 14/14, LM 14/14, LI 10/10, AL 14/14, LLA 10/13, RL 14/14, RLL 6/14, AM 13/14, PM 14/14, MMA 14/14, MMP 14/14, M 5/9, P 14/14, POR 1/3, where, for each area, the denominator indicates the number of mice in which the area was visible within the cranial window, determined manually. (<bold>F</bold>) Mean ± SEM fluorescence change for each visual area, derived from the △F/F spectral power. For each map power was normalized to that in V1. S1 region was drawn manually towards the anterior extent of the cranial window. Mouse numbers: LM 14, LI 10, AL 14, LLA 10, RL 14, RLL 5, AM 12, PM 14, MMA 12, MMP 12, M 5, P 14, S1 14; from 14 mice (4 Emx1-Ai96, 10 Emx1-Ai93).</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.014">http://dx.doi.org/10.7554/eLife.18372.014</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.015</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Map stability.</title><p>(<bold>A</bold> and <bold>B</bold>) Field sign maps generated from two Emx1-Ai96 mice, one at postnatal days 116 and 203 and a second at postnatal days 97 and 181. (<bold>C</bold> and <bold>D</bold>) Images of surface vasculature, with border positions overlaid in white. (<bold>E</bold> and <bold>F</bold>) Comparison of the area of each patch across imaging sessions.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.015">http://dx.doi.org/10.7554/eLife.18372.015</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig3-figsupp1-v1"/></fig></fig-group></p><p>MMA, MMP and RLL appear in the mean field sign map, which summarizes the locations of field sign patches that mapped consistently across 14 Emx1-Ai96 and Emx1-Ai93 mice (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Across these 14 mice, the maximum numbers of patches in an individual map were nine for positive and seven for negative field sign patches. Maps from Emx1-Ai96 and Emx1-Ai93 mice were similar (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), with 11.75 field sign patches in Emx1-Ai96 (range 11–14, 4 Emx1-Ai96 mice) and 12 field sign patches in Emx1-Ai93 mice (range 9–14, 10 Emx1-Ai93 mice).</p><p>Our results indicate that there is retinotopic organization in regions of the mouse cortex in which retinotopy had not been reported. In our mouse lines, GCaMP6 is present in neuronal somata and dendrites (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) and presumably in axons. Accordingly, some of these new field sign patches may result from retinotopically-organized projections originating in surrounding visual areas. Since our results do not indicate whether somata in these regions are retinotopically-organized, we refer to these regions of extended retinotopic organization as 'patches' rather than visual 'areas'.</p><p>We performed further calculations to characterize and visualize mouse-to-mouse variability and test the consistency of each field sign patch. To visualize mouse-to-mouse variability, we calculated a variance map in which the intensity of each pixel represents the variance of the field sign (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Variance was lower towards the centers of field sign patches and higher towards the borders, but there was little difference in the mean variance per unit area between areas (not shown), except for V1, which displayed low variance per unit area.</p><p>To quantify mouse-to-mouse consistency in area identification, we calculated the incidence of each field sign patch (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). 10 field sign patches (V1, LM, LI, AL, RL, AM, PM, MMA, MMP, P) occurred in &gt;85% of Emx1-Ai93 and Emx1-Ai96 mice (≥12 of 14 mice). LI and LLA were frequently along the lateral edge of the cranial window, which may account for the lower incidence of LLA in our maps (10 of 13 mice). Similarly, M was near the postero-medial edge of the window and was observed in 5 of 9 mice (in 4 of 7 Emx1-Ai93 and 1 of 4 Emx1-Ai96 mice). POR was absent from our maps, probably because it was invariably outside the cranial window.</p><p>Of the areas that were within the cranial window, the anterior patches A and RLL occurred least consistently. Area A is a putative negative field sign region medial to RL (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>) which maps inconsistently with red-wavelength reflectance and autofluorescence imaging in anesthetized mice (<xref ref-type="bibr" rid="bib22">Marshel et al., 2011</xref>; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib43">Tohmi et al., 2014</xref>). We observed a negative field sign patch in this location in 1 of 14 mice and a positive field sign patch (which segmented separately from RL) in 3 of 14 mice (2 of 10 Emx1-Ai93 mice and 1 of 4 Emx1-Ai96 mice). The presence of area A in GCaMP6 fluorescence maps from only 1 of 14 mice probably reflects the difficulty of mapping this area, in which projections from V1 are diffuse and their topographic organization appears weaker than that of many other areas (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>). RLL was observed in 60% of mice (3 of 10 Emx1-Ai93 and 3 of 4 Emx1-Ai96 mice). In summary, of the three new field sign patches, MMA and MMP appeared consistently across mice, whereas RLL was less consistent.</p><p>We further tested the consistency of location of each patch in the mean sign map using k-means cluster analysis, as described previously (<xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>). Cluster metric (C<sub>k</sub>) values were LM 0.23; LI 0.42; AL 0.36; LLA 1.17; RL 0.42; RLL 1.29; AM 0.77; PM 0.63; MMA 0.69; MMP 1.0; P 0.39. (Maps were aligned to the centroid of V1.) Of the three new patches, MMA and MMP were each associated with a tightly-packed cluster of patch centroids that differed from a shuffled distribution. In contrast, and consistent with its relatively low incidence, RLL was associated with a non-significant cluster (C<sub>k</sub> = 1.29).</p><p>To summarize our results for the three new field sign patches, MMA and MMP mapped consistently: they appear on the mean field sign map, were present in almost every mouse and their locations relative to other field sign patches were sufficiently consistent that they were associated with a significant k-means cluster. In contrast, RLL was consistent enough to appear on the mean field sign map, but was present in only 6 of 14 mice and was associated with a non-significant k-means cluster.</p><p>Our ability to map additional regions of retinotopic organization likely results from the superior signal-to-noise ratio of GCaMP6 fluorescence-based maps relative to intrinsic signals. Consistent with this hypothesis, the amplitudes of fluorescence changes were smaller in MMA, MMP, RLL and LLA than for other visual field sign patches (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). Of these four patches, LLA was first mapped recently with red reflectance-based imaging and extensive averaging (<xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>) and the remaining three have now been revealed with GCaMP6 fluorescence mapping. RLL exhibits the smallest mean change in fluorescence of any of the visual regions within our maps (<xref ref-type="fig" rid="fig3">Figure 3F</xref>) and this weak activation, and resulting low signal-to-noise ratio, likely accounts for the inconsistency of RLL in our maps (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p></sec><sec id="s2-3"><title>Relationship between retinotopic and architectonic borders</title><p>The new field sign patches identified in our GCaMP6 fluorescence-based maps extend far beyond the borders of V1, in some cases by &gt;2 mm. It is likely that some of these newly-mapped patches extend into architectonically-defined cortical areas surrounding visual cortex. For example, AM and PM are separated from retrosplenial cortex by V2MM. This narrow strip of tissue would appear large enough to accommodate MMA and MMP, but not the long medial extension of PM, which is likely, therefore, to be within retrosplenial cortex. Similarly, the architectonically-defined borders of V1 and barrel cortex are separated by a thin band of tissue, raising the possibility that RLL, and perhaps RL, might extend into barrel cortex.</p><p>To compare retinotopic and chemoarchitectonic borders, after retinotopic mapping we processed tissue for cytochrome C oxidase staining. We labeled surface vasculature with a fluorescent dye by transcardial perfusion immediately before fixation, used the vasculature to align images acquired in vivo (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), after fixation (whole mount, <xref ref-type="fig" rid="fig4">Figure 4B</xref>), after flattening (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) and after sectioning parallel to the cortical surface and staining (<xref ref-type="fig" rid="fig4">Figure 4D</xref>) and compared retinotopic and chemoarchitectonic borders from 4 Emx1-Ai96 mice (<xref ref-type="fig" rid="fig4">Figure 4G–J</xref>). The results confirm that the retinotopic map extends into primary somatosensory cortex and retrosplenial cortex (<xref ref-type="fig" rid="fig4">Figure 4G–I</xref>), with RLL mapping to the posterior whiskers (posterior barrels) of barrel columns B and C.<fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.016</object-id><label>Figure 4.</label><caption><title>Registration of functional retinotopic maps to chemoarchitectonic borders.</title><p>(<bold>A</bold>–<bold>D</bold>) Images from key stages in the processing of tissue from an Emx1-Ai96 mouse, each aligned to the cytochrome C oxidase (CO) image. (<bold>A</bold>) Brightfield image of surface vasculature with overlaid field sign map. (<bold>B</bold>) Fluorescence image of whole-mount brain, after perfusion, in which a subset of the surface vasculature is labeled with DyLight 649-lectin conjugate. (<bold>C</bold>) fluorescence image of the flattened cortex. D: brightfield image of a section through layer four after CO staining. (<bold>E</bold>) Overlaid fluorescence images of surface vasculature in whole-mount (red, panel <bold>B</bold>) and after flattening (green, panel <bold>C</bold>). (<bold>F</bold>) Overlaid images of the surface vasculature and CO staining in posterior barrel cortex and anterior V1. The contrast of the vasculature image is inverted for clarity. Arrowheads indicate small, circular regions that do not stain for CO and likely result from transverse cuts through ascending/descending vessels. Note the alignment of these putative vessels with likely locations of ascending/descending vessels in the fluorescence image of surface vasculature. (<bold>G</bold>) Field sign map (panel <bold>A</bold>) aligned to chemoarchitectonic borders from the CO image (panel <bold>D</bold>). Borders of primary visual cortex, auditory cortex, and of barrels in primary somatosensory cortex) were drawn manually. Barrels in putative columns <bold>B</bold> and <bold>C</bold> are shaded grey. (<bold>H</bold>–<bold>J</bold>) Alignment of functional retinotopic maps and chemoarchitectonic borders for three additional Emx1-Ai96 mice.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.016">http://dx.doi.org/10.7554/eLife.18372.016</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig4-v1"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.017</object-id><label>Figure 4—figure supplement 1.</label><caption><title>Vessels common to images from live and fixed tissue.</title><p>Example of vessel tracing through the series of images used for registration of sign maps to fixed tissue. Major vessels common to multiple images are traced on the images of <xref ref-type="fig" rid="fig4">Figure 4</xref>. Green lines mark vessels that are present in all four images. Blue lines mark vessels that extend beyond the borders of the cytochrome oxidase image, but are visible in the other images. Note that not all vessels are labeled after fixation, with the result that some large vessels are visible only in the in vivo image.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.017">http://dx.doi.org/10.7554/eLife.18372.017</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig4-figsupp1-v1"/></fig></fig-group></p><p>Another prominent feature of the comparison between cytochrome oxidase-based chemoarchitectonic and GCaMP6-based functional maps is a mismatch in the location of the lateral border of V1. The lateral border of chemoarchitectonically-defined V1 runs through functionally-defined areas RL and LM. The distance between the chemoarchitectonically-defined lateral border of V1 and that defined by functional retinotopy, measured along the LM/RL border, was 312 ± 88 µm (4 Emx1-Ai96 mice).</p><p>One possible explanation for the mismatch is that the cytochrome oxidase-rich region of visual cortex extends beyond the reversal in retinotopy that defines the functional border of V1. Alternatively, the apparent mismatch in border locations might be an experimental artifact arising from misalignment of the maps during fixation and subsequent histological processing, but misalignment on this scale is unlikely given our fluorescent marker-based registration process and direct alignment of images from live and fixed tissue.</p><p>To further clarify the alignment of functional and architectonic boundaries, we identified cytoarchitectonic borders in Rorb-Ai93 mice. Rorb drives expression preferentially in layer four and upper layer five pyramidal neurons, leading to stronger labeling of primary sensory areas than of surrounding cortex (<ext-link ext-link-type="uri" xlink:href="http://connectivity.brain-map.org/transgenic/search?page_num=0&amp;page_size=29&amp;no_paging=false&amp;search_type=line-name&amp;search_term=Rorb-IRES2-Cre">http://connectivity.brain-map.org/transgenic/search?page_num=0&amp;page_size=29&amp;no_paging=false&amp;search_type=line-name&amp;search_term=Rorb-IRES2-Cre</ext-link>). Resting GCaMP6 fluorescence was greater in primary sensory areas than in surrounding regions (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), enabling cytoarchitectonic borders to be identified by thresholding GCaMP6 fluorescence images (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Consequently, GCaMP6 fluorescence-based retinotopic maps were inherently aligned to cytoarchitectonic borders in Rorb-Ai93 mice, eliminating the potential for misalignment resulting from tissue processing. Comparison of cytoarchitectonic and functional retinotopic borders again indicated a mismatch, with the lateral border of cytoarchitectonically-defined V1 being lateral of the functionally-defined border and running through functionally-defined areas RL and LM (<xref ref-type="fig" rid="fig5">Figure 5C,D</xref>). The distance between the cytoarchitectonically-defined lateral border of V1 and that defined by functional retinotopy, measured along the LM/RL border, was 120 ± 38 µm (10 Rorb-Ai93 mice).<fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.018</object-id><label>Figure 5.</label><caption><title>Registration of functional retinotopic maps to cytoarchitectonic borders.</title><p>(<bold>A</bold>) GCaMP6 fluorescence image from a Rorb-Ai93 mouse. Primary sensory areas are marked: S1v barrel cortex, V1 primary visual cortex. (<bold>B</bold>) Image in panel A after filtering and semi-automated identification of major cytoarchitectonic borders. (<bold>C</bold>) Mean retinotopic map/cytoarchitectonic border registration for 10 Rorb-Ai93 mice. Retinotopic maps and cytoarchitectonic borders were pooled across mice as described in the Materials and methods. Cytoarchitectonic borders are shown in black. (<bold>D</bold>) Mean sign map with patch notation, from <xref ref-type="fig" rid="fig3">Figure 3C</xref>. (<bold>E</bold>) Mean fluorescence image from 10 Emx1-Ai93 mice, after filtering, alignment and semi-automated identification of the borders of primary sensory areas and retrosplenial cortex (RS). (<bold>F</bold>) Mean map/border registration for 10 Emx1-Ai93 mice.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.018">http://dx.doi.org/10.7554/eLife.18372.018</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig5-v1"/></fig></p><p>A similar change in resting GCaMP6 fluorescence was observed at the borders of primary sensory areas in Emx1-Ai93 mice (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F,G</xref>). The change in fluorescence was less pronounced than in Rorb-Ai93 mice, but borders were visible after averaging images of the resting GCaMP6 fluorescence from 10 Emx1-Ai93 mice (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). Here again, the lateral border of cytoarchitectonically-defined V1 was lateral of the functionally-defined border of V1 (<xref ref-type="fig" rid="fig5">Figure 5F</xref>), by 236 µm (measured along the LM/RL border).</p><p>Three methods have been particularly influential in the generation of established maps of the mouse visual cortex: architectonics, using various stains, including cytochrome oxidase; functional retinotopy, primarily measured with electrodes; and projection-based retinotopy, in which axonal projections between visual areas were used to identify locations with matching retinotopy. Having measured the mismatch between borders based on architectonics and on functional retinotopy, we next sought to determine whether borders based on projection-based retinotopy more closely match functional retinotopic borders or architectonic borders, and particularly to determine whether there is a mismatch between the lateral border of V1 from projection-based retinotopy and that based on architectonics.</p><p>To investigate the alignment of architectonic and projection-based retinotopic borders, we used data from the Allen Mouse Brain Connectivity Atlas (<xref ref-type="bibr" rid="bib27">Oh et al., 2014</xref>; <ext-link ext-link-type="uri" xlink:href="http://connectivity.brain-map.org/">http://connectivity.brain-map.org/</ext-link>). We selected projection data from 99 mice, each with a single injection of anterograde fluorescent tracer into V1. These injections, and the resulting projection maps, were registered to a three-dimensional reference atlas of the mouse brain built from serial section image data sets from 1675 mice. The reference atlas includes tissue autofluorescence images and in the top projection, the major cytoarchitectonic areas (including primary visual cortex, whisker and digit barrels in primary sensory cortex, primary auditory cortex and retrosplenial cortex) are readily visible (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) due to the enhanced autofluorescence of regions with increased myelination.<fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.019</object-id><label>Figure 6.</label><caption><title>Retinotopy of projections from V1.</title><p>(<bold>A</bold>) Locations of injections into V1 in 99 mice, selected from the Allen Brain Connectivity Atlas. Each point indicates an injection. Injection locations were registered to a 3D model of the mouse brain generated from 1675 brains and injections are illustrated on a top projection of the mean autofluorescence from the 3D model. Variations in autofluorescence clearly delineate major architectonic boundaries, including barrels in primary somatosensory cortex, primary auditory cortex, primary visual cortex and retrosplenial cortex. (<bold>B</bold> and <bold>C</bold>) Projection-based maps of connectivity with ipsilateral V1. Colors indicate the distance from the geometric center of V1 (black circle) from which the strongest projection arises, along the anterior (a) – posterior (p) and medial (m) – lateral (l) axes of V1. These maps are projection-based homologues of the azimuth and altitude maps generated from functional mapping (<xref ref-type="fig" rid="fig4">Figure 4E,F</xref>). (<bold>D</bold>) Projection sign map generated from the maps in panels <bold>B</bold> and <bold>C</bold>. (<bold>E</bold>) Automated borders generated from the projection sign maps of panel <bold>D</bold>, overlaid onto the autofluorescence top projection from panel <bold>A</bold>. (<bold>F</bold>) Subregion corresponding to the box in panel <bold>E</bold>. A lower threshold was used to generate the visual area borders from the sign map, eliminating the gap between areas V1, AL, RL and LM.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.019">http://dx.doi.org/10.7554/eLife.18372.019</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig6-v1"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.020</object-id><label>Figure 6—figure supplement 1.</label><caption><title>Generation of projection-based retinotopy maps.</title><p>Schematic indicating the steps in generating the projection-based retinotopy map. References are provided where methods are published (including the collection of the source data set). Information on data formats are provided and key steps are illustrated graphically.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.020">http://dx.doi.org/10.7554/eLife.18372.020</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig6-figsupp1-v1"/></fig></fig-group></p><p>For each mouse with an injection into V1, we calculated the density of projections from V1 and combined the results across mice to derive the location within V1 with which each voxel within the brain was most strongly connected (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). After projecting the maximum connectivity in superficial cortex to the brain surface, we plot two pseudo-colored top-views in which color indicates the location in V1 to which each pixel in the image was most strongly connected (<xref ref-type="fig" rid="fig6">Figure 6B,C</xref>). Due to the retinotopic organization of V1, these two plots are analogous to maps of altitude and azimuth retinotopy (<xref ref-type="fig" rid="fig3">Figure 3E,F</xref>). From these plots we generated the projection-based equivalent of a field sign map, a 'projection sign map' (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), used our numerical routine to derive area borders (<xref ref-type="fig" rid="fig6">Figure 6E</xref>) and overlaid these borders onto the autofluorescence top projection from the reference atlas (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). Due to the registration of all images in the Connectivity Atlas to the 3D reference atlas, the projection sign map and area borders are inherently aligned.</p><p>Again, the results indicate that retinotopy extends into primary somatosensory and retrosplenial cortices, with RLL mapping to the posterior whiskers in posterior barrel cortex. LLA also appears to extend into auditory cortex. Regarding the relative positions of the borders of V1, the myeloarchitectonically-defined lateral border of V1 (here visible as a transition between relatively bright autofluorescence in V1 and dimmer autofluorescence more laterally) was lateral to the lateral border of V1 defined by projection-based retinotopy (<xref ref-type="fig" rid="fig6">Figure 6E,F</xref>). The distance between the myeloarchitectonically-defined lateral border of V1 and that defined by projection-based retinotopy, measured along the LM/RL border, was 180 µm.</p><p>The above comparisons of retinotopic maps with architectonic borders using three different methods lead us to two main conclusions. Firstly, retinotopic organization extends into retrosplenial and primary somatosensory cortices in the mouse. RLL is entirely within barrel cortex. The retinotopic map observed in retrosplenial cortex was often continuous with the map in PM, and was not segmented into two distinct regions by our algorithm. The lateral architectonic boundary of retrosplenial cortex extends from the posterior extent of MMP and separates the patch identified as PM into two pieces: a lateral portion that runs parallel to the medial border of V1 and is similar to PM as described previously, and a medial extension within retrosplenial cortex. In subsequent figures we separate these two portions of PM along the approximate lateral boundary of retrosplenial cortex. Secondly, there is a mismatch between the borders of V1 as defined by architectonic markers and by retinotopy, with the architectonically-defined border of V1 lateral to the retinotopic border of V1 by up to ~300 µm (four measurements: 312, 120, 236 and 180 µm; mean 212 µm).</p></sec><sec id="s2-4"><title>Single-cell retinotopy along the V1-LM border</title><p>With what precision can we locate borders with widefield imaging, which presumably reports the mean retinotopy of many neurons at each location? To answer this question, we compared widefield retinotopic maps with the receptive fields of layer 2/3 pyramidal neurons, measured using 2-photon microscopy in Emx1-Ai93 mice. After mapping cortex, we placed the mouse under a 2-photon microscope, directing the field of view to the V1-LM border. Before performing 2-photon measurements, we generated a local widefield retinotopic map through the microscope objective using an LED and camera (<xref ref-type="fig" rid="fig7">Figure 7A–D</xref>), which confirmed that we had located the border region. By mapping through the microscope objective, we ensured that widefield and 2-photon measurements were aligned.<fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.021</object-id><label>Figure 7.</label><caption><title>Widefield borders match single-cell retinotopy at the V1-LM border.</title><p>(<bold>A</bold>, <bold>B</bold> and <bold>C</bold>) Local altitude and azimuth and field sign maps generated under the 2-photon microscope by widefield imaging through the x16 objective. Images were acquired with the objective focused 200 µm below the pial surface of cortex. (<bold>D</bold> and <bold>E</bold>) Images of surface vasculature acquired with the objective focused on the pial surface. Borders of V1 and LM derived from the field sign map are marked in blue and red, respectively. (<bold>F</bold>) 2-photon fluorescence image acquired with the microscope objective focused 200 µm below the pial surface of cortex. Borders of V1 and LM derived from the field sign map are marked in blue and red, respectively. White outlines indicate 366 somatic ROIs. (<bold>G</bold>) Example fluorescence traces extracted from the three somatic regions (before neuropil subtraction) marked with arrowheads in panel <bold>F</bold> (grey traces) and the corresponding neuropil regions (black traces). Fluorescence scale is in arbitrary units. A black horizontal line indicates zero fluorescence for each pair of traces. (<bold>H</bold>) On and Off receptive fields from an example cell, extending from −6 to 60 degrees in azimuth and −24 to 54 degrees in altitude. (<bold>I</bold>) Altitude and azimuth maps (from summed receptive fields) for the experiment illustrated in panel <bold>F</bold>. The color of each soma represents its receptive field center location. Of the 366 somata identified in this field of view, 336 displayed significant receptive fields (maximum z-score ≥ 2) and are illustrated in panel <bold>I</bold>. Black lines mark the borders of V1 and LM. (<bold>J</bold>) Plots illustrating the distribution of single-cell altitude and azimuth as a function of minimum distance to the V1-LM border. Each point represents a single soma from the field of view illustrated in panel <bold>F</bold>. (<bold>K</bold>) Single-cell altitude and azimuth as a function of distance to the V1-LM border. Results from three experiments were pooled, yielding 964 somata with receptive fields. Each bar represents the mean and standard deviation of cells binned by distance from the border, in 20 µm bins.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.021">http://dx.doi.org/10.7554/eLife.18372.021</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18372-fig7-v1"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.022</object-id><label>Figure 7—figure supplement 1.</label><caption><title>On and Off receptive fields for an example cell.</title><p>(<bold>A</bold>) ΔF/F traces displaying On (red) and Off (blue) responses for each pixel in the nasal receptive field. Each pixel of the stimulus subtended six degrees in altitude and six in azimuth. Each trace represents the mean (line) and standard error (shaded area) of 60 trials. Horizontal lines indicate zero ΔF/F and vertical line the onset of the stimulus. (<bold>B</bold>) Receptive field maps derived from the example in panel <bold>A</bold>. Lines represent 40%, 50%, 60%, 70%, 80% and 90% of the maximum z-score.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.022">http://dx.doi.org/10.7554/eLife.18372.022</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig7-figsupp1-v1"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.023</object-id><label>Figure 7—figure supplement 2.</label><caption><title>Neuropil tuning and subtraction.</title><p>(<bold>A</bold>) Somatic ROIs (grey) and corresponding neuropil ROIs (black) for the three cells highlighted in <xref ref-type="fig" rid="fig7">Figure 7F and G</xref>. (<bold>B</bold>) Neuropil On and Off receptive fields for the cell illustrated in <xref ref-type="fig" rid="fig7">Figure 7H</xref>. (<bold>C</bold>) Plots illustrating the distribution of neuropil altitude and azimuth as a function of distance to the V1-LM border. Each point represents a single neuropil ROI from the field of view illustrated in <xref ref-type="fig" rid="fig7">Figure 7F</xref> and can be directly compared to the equivalent plot for somatic tuning in <xref ref-type="fig" rid="fig7">Figure 7J</xref>. (<bold>D</bold>) Distribution of the difference in somatic and neuropil tuning for V1 (blue bars) and LM (red bars). Black line is the cumulative distribution (right axis). These results indicate that most somata display similar tuning to the local neuropil, with a difference of &lt;5 degrees for &gt;90% of neurons. (<bold>E</bold>) Results of a numerical simulation to illustrate the effectiveness of neuropil subtraction. We examined the effects of adding an additional contaminating signal to each somatic trace. The additional signal was a neuropil trace tuned to 24.15 and 24.28 degrees in altitude and azimuth. To increase the effect of this additional contamination, we first multiplied the amplitude of the contaminating trace by 10. From the modified traces, we recalculated the somatic altitude and azimuth maps with and without neuropil subtraction. As expected, in the absence of neuropil subtraction, the added signal shifted all somatic tuning towards the coordinates of the added signal, whereas with neuropil subtraction enabled, the somatic altitude and azimuth maps were almost identical to the unmodified maps). Left column: somatic altitude and azimuth maps. Center column: somatic altitude and azimuth maps after addition of enlarged neuropil signal, with no neuropil subtraction. Right column: somatic altitude and azimuth maps after addition of enlarged neuropil trace, with neuropil subtraction. The results of this test indicate that our neuropil subtraction routine corrects for neuropil contamination several times larger than that observed in our results.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.023">http://dx.doi.org/10.7554/eLife.18372.023</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig7-figsupp2-v1"/></fig></fig-group></p><p>We then measured the receptive fields of layer 2/3 pyramidal neurons in the same field of view using 2-photon excitation and a sparse noise visual stimulus. In the example illustrated in <xref ref-type="fig" rid="fig7">Figure 7</xref>, we identified 366 neuronal somata in layer 2/3 (<xref ref-type="fig" rid="fig7">Figure 7F</xref>) and summing three experiments, identified 1276 somata. Neuropil contamination, the presence of fluorescence from surrounding GCaMP-labeled processes in the somatic pixels, is a characteristic of densely labeled tissue. We extracted fluorescence from the neuropil surrounding each neuron and, as expected, found that these local regions of neuropil displayed receptive fields (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). Many of the neuropil regions displayed similar retinotopy to their parent somata. To correct for neuropil contamination, for each soma we measured and subtracted neuropil fluorescence from the surrounding pixels. Numerical simulations indicated that this approach was effective in removing neuropil contamination from somatic fluorescence measurements and confirmed that the map of somatic retinotopy was not an artifact of neuropil contamination (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>).</p><p>Most somata displayed On and Off receptive subfields after neuropil subtraction (e.g. <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Further analysis was performed on cells with a receptive field with a maximum z-score ≥ 2, which included 92% of neurons (336 of 366) in the example in <xref ref-type="fig" rid="fig7">Figure 7</xref> and 76% (964 of 1276) of neurons across three experiments. For each neuron, we summed On and Off subfields and determined the center of the summed receptive field, then created somatic altitude and azimuth maps (<xref ref-type="fig" rid="fig7">Figure 7I</xref>). Receptive field centers formed an orderly map of retinotopy with a progression of altitudes along the V1-LM border and azimuth changing parallel to the V1-LM border. Importantly, the gradient in somatic azimuth reversed at the border measured by widefield mapping.</p><p>For most neurons, somatic altitude and azimuth were similar to the altitude and azimuth in the local widefield maps (<xref ref-type="fig" rid="fig7">Figure 7A,B</xref>). For a more quantitative comparison, for each neuron we plot somatic altitude and azimuth as a function of distance from the V1-LM border (defined by widefield fluorescence; <xref ref-type="fig" rid="fig7">Figure 7J</xref>). Somata with zero azimuth were close to the border (distance = 0) and azimuth increased approximately linearly with distance from the border, into V1 and into LM. As expected, the gradient of the relationship between somatic azimuth and distance to the border was steeper in LM than in V1, indicating greater cortical magnification in V1 than in LM near the border.</p><p>Finally, we pooled results from three experiments, calculating the mean somatic altitude and azimuth as a function of distance from the V1-LM border in 20 µm bins. The relationship displayed an orderly progression of somatic azimuth with distance from the border (<xref ref-type="fig" rid="fig7">Figure 7K</xref>). The lowest-azimuth bin was centered at −30 µm, indicating that the single-cell border was 30 µm lateral of the widefield retinotopic border. This 30 µm difference in retinotopic border locations is insufficient to account for the 100–300 µm mismatch between retinotopic and architectonic border locations.</p></sec><sec id="s2-5"><title>Arrangement and visual coverage of higher visual areas in the mouse</title><p>In addition to the new field sign patches and medial displacement of the lateral border of V1, GCaMP6 fluorescence-based retinotopic maps differ from previous maps in two respects. Firstly, area P extends across the posterior border of V1, from LM to PM. Secondly, area M is displaced medially relative to the location reported in <xref ref-type="bibr" rid="bib9">Garrett et al. (2014)</xref>. One result of these differences is an almost continuous ring of field sign positive areas surrounding V1, broken only by the field sign negative area AM.</p><p>To assess the representation of visual space in V1 and of the surrounding extrastriate regions in the mouse, we plot the coverage of these regions in retinotopic coordinates (<xref ref-type="fig" rid="fig8">Figure 8</xref>). V1 included representation of the right visual hemifield between ~0 (the vertical meridian) and 90° azimuth and ~25–35° above and below the horizontal meridian (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). The 4 positive field sign patches around V1 (LM, RL, PM, P; <xref ref-type="fig" rid="fig8">Figure 8A</xref>) each represented a portion of the visual field and each was biased towards a different quadrant: LM was biased towards the upper nasal visual field, RL the lower nasal field, P upper temporal field and PM lower temporal field (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). The summed coverage of these four patches approximated that of V1 with modest overlap in coverage in two narrow strips of visual space ~0–15° above the horizon and ~40–50° from the vertical meridian. The intersection of these zones of overlap included the center of coverage of V1 (altitude 7.4 ± 2.1 degrees, azimuth 37.8 ± 1.4 degrees, 14 mice), which was represented in areas LM, RL and PM. This overlap was also observed in maps of eccentricity, where a representation of the center of visual coverage was present for each area (<xref ref-type="fig" rid="fig9">Figure 9B</xref>).<fig-group><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.024</object-id><label>Figure 8.</label><caption><title>Visual coverage across areas.</title><p>(<bold>A</bold>) Coverage map of visual space by V1 and surrounding positive field sign patches. Top left, overview map of V1 (grey) and the four surrounding positive field sign patches (red; LM, RL, PM, P). Top right, V1 coverage map. Locations represented in V1 are indicated in grey. Circle indicates the center of coverage of V1 at 7.4° altitude, 37.8° azimuth. Dashed line indicates the horizontal meridian. Center panels, coverage maps of positive field sign patches that border V1 (LM, RL, PM, P). Each coverage map illustrates the one positive field sign patch (in red), overlaid on the coverage of V1 (black outline). Note that coverage of PM excludes retrosplenial cortex. Lowest panel, overlapping coverage of 5 areas (V1 in grey; LM, RL, PM, P in red). (<bold>B</bold>) Coverage of negative field sign patches LI, AL and AM. Coverage of each patch (blue) is overlaid on the coverage of V1 (black outline). (<bold>C</bold>) Coverage of remaining positive and negative field sign patches.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.024">http://dx.doi.org/10.7554/eLife.18372.024</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig8-v1"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.18372.025</object-id><label>Figure 8—figure supplement 1.</label><caption><title>Expanded coverage.</title><p>Plots illustrating the expansion of visual field coverage, based on published receptive field sizes. (<bold>A</bold>) Upper panels: visual field coverage for areas LM, P, RL and PM (from <xref ref-type="fig" rid="fig8">Figure 8A</xref>) and expanded coverage (red shading). For each area, coverage expanded by the mean radius of single-cell receptive fields, taken from <xref ref-type="bibr" rid="bib50">Wang and Burkhalter (2007)</xref>. The receptive field radius employed is in the lower right corner of each plot. Lower panel: overlapping coverage of LM, P, RL and PM. Circle indicates the center of coverage of V1 at 7.4° altitude, 37.8° azimuth. (<bold>B</bold>) Coverage and expanded coverage of V1 (grey) and of AL, AM and LI. (<bold>C</bold>) Coverage and expanded coverage of MMA and MMP. For MMA and MMP, the receptive field radius employed (40°) was that of MM in <xref ref-type="bibr" rid="bib50">Wang and Burkhalter (2007)</xref>. No expanded coverage estimates are provided for LLA, RS and RLL as their receptive field sizes were not provided by <xref ref-type="bibr" rid="bib50">Wang and Burkhalter (2007)</xref>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.025">http://dx.doi.org/10.7554/eLife.18372.025</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-fig8-figsupp1-v1"/></fig></fig-group><fig id="fig9" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.026</object-id><label>Figure 9.</label><caption><title>Magnification and representation of visual space across visual cortex.</title><p>(<bold>A</bold>) Color map of visual space in eccentricity coordinates. Color (bar) indicates the distance (in degrees) from the center of coverage of V1 (7.4 ± 2.1 degrees altitude, 37.8 ± 1.4 degrees azimuth). (<bold>B</bold>) Eccentricity map of mouse visual areas, using the color scheme indicated in panel <bold>A</bold>. (<bold>C</bold>,<bold>D</bold>) Altitude and azimuth contour plots of mouse visual cortex, overlaid on mean field sign borders. Dashed line represents horizontal meridian. Contours are at 5° intervals from −25 to 30° in altitude and 0 to 90° in azimuth. (<bold>E</bold>) Colored sector map of visual space, with the division between upper and lower visual fields at 7.4° altitude, 37.8° azimuth, which corresponds to the center of coverage of V1. (<bold>F</bold>) Colored sector map of mouse visual cortex, with colors corresponding to those in panel <bold>B</bold> and denoting representation of the four quadrants of the visual field.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.026">http://dx.doi.org/10.7554/eLife.18372.026</ext-link></p></caption><graphic mime-subtype="postscript" mimetype="application" xlink:href="elife-18372-fig9-v1"/></fig></p><p>Like the ring of four positive field sign patches, negative field sign patches LI, AL and AM exhibited coverage that overlapped at the center of coverage of V1 (<xref ref-type="fig" rid="fig8">Figure 8B</xref>). LI represented the upper visual field at ~30–40° azimuth; AL represented the nasal visual field at ~0–15° altitude; and AM represented the lower visual field at 10–30° azimuth (<xref ref-type="fig" rid="fig8">Figure 8B</xref>).</p><p>Of the field sign patches newly identified by GCaMP6 fluorescence mapping, the positive field sign patches MMA and in retrosplenial cortex exhibited the largest coverage, extending in a ~10° strip ~30–40° along and ~5–10° above the horizontal meridian, respectively, and the negative field sign patches RLL and MMP each represented ≤10° x 20° of the visual field (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). Like other patches towards the periphery of the mouse visual cortex (areas POR and LLA; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>), the newly-identified field sign patches each represented smaller regions of the visual field around the center of coverage of V1.</p><p>The limited coverage of most field sign patches is also visible in eccentricity maps, in which representation of the peripheral visual field is limited to V1 and its immediate neighbors (<xref ref-type="fig" rid="fig8">Figures 8A</xref> and <xref ref-type="fig" rid="fig9">9B</xref>). Furthermore, neighboring field sign patches generally share a similar bias, with the lower visual field represented primarily in anterior field sign patches and upper visual field in posterior patches, the nasal visual field primarily in lateral patches and temporal visual field in medial patches (<xref ref-type="fig" rid="fig9">Figure 9C–F</xref>). In short, almost all higher visual areas in the mouse display a strong bias in representation which is shared with their immediate neighbors, but all share a representation of the center of coverage which corresponds approximately to the center of gaze.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our results establish GCaMP6 fluorescence as a tool for generating retinotopic maps of mouse cortex. The exquisite signal-to-noise ratio of GCaMP6 permitted rapid mapping and also revealed several new field sign patches, enabling us to map the medial extent of visual cortex. Adding the four new field sign patches (MMA, MMP, RLL, RS) to 12 published areas (V1, LM, LI, AL, LLA, RL, A, AM, PM, M, P, POR), mouse cortex contains 16 distinct retinotopically-organized regions.</p><sec id="s3-1"><title>Extension of retinotopic organization</title><p>Our results indicate that retinotopic organization is more extensive in mouse cortex than previously appreciated. We observed five instances of extended retinotopy. Firstly, area P extends across the posterior extent of V1. Tracer injections into V1 have revealed projections into this region in rat and mouse (<xref ref-type="bibr" rid="bib30">Olavarria and Montero, 1981</xref>, <xref ref-type="bibr" rid="bib31">1984</xref>; <xref ref-type="bibr" rid="bib29">1989</xref>; <xref ref-type="bibr" rid="bib6">Coogan and Burkhalter, 1993</xref>; <xref ref-type="bibr" rid="bib53">Wang et al., 2012</xref>) and recent maps have suggested the presence of one or more positive field sign patches posterior to V1 (<xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>). The signal-to-noise ratio of our measurements may be particularly limited in this posterior region, along the edge of our cranial window. Furthermore, at its posterior extent cortex is folded and abuts the transverse sinus, and there may be additional retinotopic structure under the sinus or in the folded region that we were unable to access. This additional region may include representation of the center of coverage of V1, which is absent from our map of coverage of P.</p><p>We identified two field sign patches in the anterior and posterior aspects of MM, the narrow strip of visual cortex immediately lateral to retrosplenial cortex (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>). These two patches were labeled MMA and MMP. Variations in the density of neurons immunoreactive for nonphosphorylated neurofilament protein across medial visual areas have led to the suggestion that MM contains multiple distinct regions (<xref ref-type="bibr" rid="bib45">Van der Gucht et al., 2007</xref>). Furthermore, MM receives direct projections from V1 that terminate in distinct anterior and posterior regions (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>) and likely correspond to MMA and MMP.</p><p>Retinotopy extends into retrosplenial and barrel cortices. Retinotopic organization presumably facilitates the processing of multimodal information in these areas (<xref ref-type="bibr" rid="bib32">Olcese et al., 2013</xref>). For example, like RL (<xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>), RLL is biased towards the nasal, lower field and may convey to barrel cortex visual information on whisker location and nearby objects. Similarly, the presence of a visual map in retrosplenial cortex is consistent with its visual responsiveness (<xref ref-type="bibr" rid="bib25">Murakami et al., 2015</xref>) and its role in spatial memory and navigation (<xref ref-type="bibr" rid="bib47">Vann et al., 2009</xref>).</p></sec><sec id="s3-2"><title>Limitations of mapping with population imaging and simple visual stimuli</title><p>We used a flickering checkerboard to drive cortical activity during retinotopic mapping, but some areas might be activated more effectively, and mapped more readily, with other visual stimuli. In primates, for example, neurons in higher visual areas are more strongly activated by complex stimuli (<xref ref-type="bibr" rid="bib26">Nassi and Callaway, 2009</xref>). In the mouse, some higher areas are preferentially activated by high or low spatial and temporal frequencies (<xref ref-type="bibr" rid="bib22">Marshel et al., 2011</xref>; <xref ref-type="bibr" rid="bib2">Andermann et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Roth et al., 2012</xref>; <xref ref-type="bibr" rid="bib43">Tohmi et al., 2014</xref>), leading to the suggestion that simple stimuli with different spatial and temporal frequency characteristics might preferentially activate different regions of cortex. However, the checkerboard pattern includes sharp borders between black and white regions of the checkerboard that naturally include a broad band of spatial and temporal frequencies. Furthermore, retinotopically-organized regions occupy most of the territory between primary sensory areas in posterior cortex, suggesting that there are few additional visual areas to be discovered in the mouse. As a result, we would not expect substantial differences in maps of higher visual areas generated with checkerboards with distinct spatial or temporal frequency band characteristics.</p><p>Our maps are derived from population imaging, which naturally imposes limits on the resolution with which we can map areas and borders. Furthermore, imaging of widefield fluorescence signals at the brain surface is strongly contaminated by vasculature artifacts, which we address by focusing below the surface of cortex. Defocusing has a blurring effect and can limit effective resolution. Widefield fluorescence signals in Emx1 mice are presumably the average of fluorescence from many neurons, with dendrites and axons providing fluorescence signals far from the soma. Processes probably cross regional borders, making it likely that dendritic and axonal signals from neurons on one side of the border contribute to fluorescence on the other side of the border. It is unclear the extent to which border-crossing processes blur borders since blurring will depend on many factors, including whether stimulus-locked changes in the fluorescence of processes more closely match stimulus-locked changes of the parent soma or of the local network into which the processes extend. Given the potential for blurring of borders, it is perhaps surprising that widefield and 2-photon images give border locations which are separated by only a few tens of micrometers.</p></sec><sec id="s3-3"><title>Cortical regions, field sign patches and visual areas</title><p>The cellular and laminar origins of visually-evoked changes in widefield GCaMP6 fluorescence remain unknown. GCaMP6 is likely expressed throughout excitatory neurons, including their axons, and it is possible that some of the observed retinotopic organization, such as that in retrosplenial and barrel cortices, results from retinotopically-organized axons. Indeed, the lack of retinotopy in retrosplenial and barrel cortices of Rorb-Ai93 mice suggests a lack of somatic retinotopy in layer four and upper layer five in these regions.</p><p>We have used the term 'patch' to refer to regions of cortex identified by our analysis routine. We define patches as regions of cortex with retinotopic organization that are distinct from neighboring patches, either because of a reversal of chirality in the visual map or because the neighboring patches contain redundant representations of visual space. We use the term 'patch' to avoid implying any specific mechanistic basis for the retinotopic organization, such as somatic retinotopy. We have used 'region' simply to refer to part of cortex, with no intended implications regarding structure or properties.</p><p>'Visual area' is a more established term that implies the consistent identification of borders with multiple approaches, including anatomical and functional measurements (<xref ref-type="bibr" rid="bib33">Orban et al., 2004</xref>; <xref ref-type="bibr" rid="bib49">Wandell et al., 2007</xref>). Furthermore, we consider somatic retinotopy necessary in a visual area. In the absence of evidence of somatic retinotopy and supporting evidence from other techniques, we have, where possible, avoided using 'area' to refer to some patches.</p></sec><sec id="s3-4"><title>Retinotopic and architectonic borders</title><p>In maps of mouse visual areas drawn with the assistance of architectonic boundaries, the borders of V1, AL, LM and RL all intersect at a common point (e.g. <xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>). Our results indicate that in retinotopic maps obtained with functional imaging and with projection-based mapping, the lateral border of V1 is more medial than the architectonic boundary. As a result, V1 and AL lack a common border. The territory between V1 and AL is occupied by RL and LM, which share a border extending ~100–300 µm. The architectonic border of V1 runs through RL and LM and typically intersects the medial tip of AL. Hence the medial tip of AL intersects the lateral border of architectonically-defined V1, but not retinotopically-defined V1. The border mismatch helps explain why the relative positions of visual areas, and their points of intersection, can differ on maps based on results from different techniques.</p><p>The mismatch between the architectonic and retinotopic borders of V1 is consistent in our results across three methods, indicating that the architectonic border of V1 may correlate with functions other than retinotopic reversal. One possibility is that the cytochrome oxidase-rich region includes the binocular region around the lateral border of V1, which would help explain the mismatch since areas RL and LM include representations of the binocular zone (<xref ref-type="bibr" rid="bib48">Wagor et al., 1980</xref>). Another possibility is that there is a thin, largely monocular zone along the medial edge of LM and RL which is cytochrome oxidase-rich (<xref ref-type="bibr" rid="bib18">Laing et al., 2015</xref>). It is unclear whether there is a mismatch in the architectonic and retinotopic borders of other visual areas, such as between LM and LI (<xref ref-type="bibr" rid="bib52">Wang et al., 2011</xref>) and further studies will be required to establish the similarity of architectonic and retinotopic border locations for other visual areas.</p></sec><sec id="s3-5"><title>Representation of visual space and the organization of mouse visual areas</title><p>A prominent feature of GCaMP6-based retinotopic maps is the four positive field sign areas (RL, LM, P and PM) neighboring V1 that form an almost continuous ring, broken only by the negative field sign area AM. This arrangement resembles early visual areas in primates, in which V1 is a negative field sign region surrounded by V2, and V2 is a continuous strip of positive field sign tissue broken only at a single point (anterior tip of the calcarine sulcus; <xref ref-type="bibr" rid="bib10">Gattass et al., 2005</xref>; <xref ref-type="bibr" rid="bib39">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib54">Warnking et al., 2002</xref>; <xref ref-type="bibr" rid="bib41">Silver and Kastner, 2009</xref>; <xref ref-type="bibr" rid="bib55">Wilms et al., 2010</xref>; <xref ref-type="bibr" rid="bib19">Laumann et al., 2015</xref>).</p><p>Early studies of mouse visual cortex revealed a retinotopic map in V1 and a second map anterior and lateral to V1, leading this second region to be named V2 (<xref ref-type="bibr" rid="bib48">Wagor et al., 1980</xref>). Further studies revealed several overlapping maps within mouse and rat V2, which was therefore split into several named visual areas, including LM and RL (<xref ref-type="bibr" rid="bib30">Olavarria and Montero, 1981</xref>, <xref ref-type="bibr" rid="bib31">1984</xref>, <xref ref-type="bibr" rid="bib29">1989</xref>; <xref ref-type="bibr" rid="bib21">Malach, 1989</xref>; <xref ref-type="bibr" rid="bib28">Olavarria et al., 1982</xref>; <xref ref-type="bibr" rid="bib42">Thomas and Espinoza, 1987</xref>; <xref ref-type="bibr" rid="bib6">Coogan and Burkhalter, 1993</xref>; <xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>). Subsequent studies have documented additional distinctions between the four positive field sign areas neighboring V1. For example, a study of the laminar termination patterns of axonal projections between cortical areas suggested that the areas around V1 occupy different positions in the hierarchy of visual areas in rats (<xref ref-type="bibr" rid="bib6">Coogan and Burkhalter, 1993</xref>). Consistent with this suggestion, medial and lateral regions of visual cortex, likely corresponding to LM, RL and PM, display different response latencies in mice (<xref ref-type="bibr" rid="bib35">Polack and Contreras, 2012</xref>), and neurons in these areas differ in their mean receptive field sizes (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>) and in their tuning to the spatial and temporal characteristics of visual stimuli (<xref ref-type="bibr" rid="bib2">Andermann et al., 2011</xref>; <xref ref-type="bibr" rid="bib22">Marshel et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Roth et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Glickfeld et al., 2013</xref>; <xref ref-type="bibr" rid="bib43">Tohmi et al., 2014</xref>). These studies all support the identification of multiple visual areas in the tissue bordering V1, in contrast with primates where the tissue neighboring V1 is considered a single visual area (V2).</p><p>Our results indicate that the visual field representations of the four areas around V1 (LM, P, PM, RL) are complementary, with the outline of the coverage of these four areas matching the outline of V1 coverage. Our results likely underestimate the range of visual coverage in each area and the overlap between areas. V1 included a visual coverage range of ~60° in altitude and ~90° in azimuth, comparable to measurements with reflectance-based imaging (e.g. <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>) but smaller than the range measured with single-cell electrical recordings (~100° in altitude and ~150° in azimuth; <xref ref-type="bibr" rid="bib48">Wagor et al. (1980)</xref>. Single-cell recordings are likely to provide a larger range for two main reasons.</p><p>Firstly, widefield mapping identifies retinotopic position based on the peak of activity, thereby emphasizing the receptive field center. The outer limits at which visual stimuli can evoke activity in V1 will be expanded, by approximately the radius of the largest receptive fields of neurons at the edges of V1. A more pronounced expansion in effective coverage is expected in higher visual areas, where receptive field sizes are larger (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>). Expanded coverage, calculated using published receptive field sizes (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>) is illustrated in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>. For V1, expanded coverage includes ~70° in altitude and ~100° in azimuth. Mean local receptive field size may change across a visual area, which possibly accounts for the mismatch of coverage at the borders of neighboring areas (e.g. the V1-LM border, where the outer limits of the estimated V1 and LM coverage differ).</p><p>Secondly, widefield fluorescence measures the average retinotopy of the local population of neurons. Single-cell receptive field centers vary around the mean retinotopy. For example, in V1 most pyramidal neuron receptive fields are within ~7 degrees of the local population average (<xref ref-type="bibr" rid="bib3">Bonin et al., 2011</xref>). How variability relative to the mean local receptive field center changes towards the borders of V1 or in other visual areas is unknown, but an expansion of coverage of 7 degrees at each border (in addition to the expansion due to receptive field size) would result in total coverage of V1 of ~85° in altitude and ~115° in azimuth, closer to the numbers from single-cell recordings. These differences between population and single-cell coverages may explain the small apparent regions of coverage of many higher visual areas, in which receptive field sizes and perhaps also the scatter in receptive field centers are greater than in V1. Even allowing for some expansion of coverage for each visual area, our results indicate that no higher visual areas (even those immediately surrounding V1) contain a complete description of the visual hemifield. Hence information on features that subtend more than approximately a quarter of the visual field will be routed to different early visual areas, with the result that information on features in different locations within a single visual scene will be processed in regions with different functional properties. Further studies will be needed to understand the advantages and limitations of processing information from different locations in visual space in functionally distinct regions of visual cortex.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Transgenic mice</title><p>In this study we employed six mouse lines:</p><list list-type="bullet"><list-item><p>Ai95(RCL-GCaMP6f): B6;129S-<italic>Gt(ROSA)26Sor<sup>tm95.1(CAG-GCaMP6f)Hze</sup></italic>/J (Jax stock number 024105; <xref ref-type="bibr" rid="bib20">Madisen et al., 2015</xref>)</p></list-item><list-item><p>Ai96(RCL-GCaMP6s): B6;129S6-<italic>Gt(ROSA)26Sor<sup>tm96(CAG-GCaMP6s)Hze</sup></italic>/J (Jax stock number 024106; <xref ref-type="bibr" rid="bib20">Madisen et al., 2015</xref>)</p></list-item><list-item><p>Ai93(TITL-GCaMP6f): <italic>Gt(ROSA)26Sor<sup>tm5(ACTB-tTA)Luo</sup> Igs7<sup>tm93(tetO-GCaMP6f)Hze</sup></italic>/HzeJ (Jax stock number 024107; <xref ref-type="bibr" rid="bib20">Madisen et al., 2015</xref>)</p></list-item><list-item><p>Emx1-IRES-Cre: B6.129S2-<italic>Emx1<sup>tm1(cre)Krj</sup></italic>/J (Jax stock number 005628; <xref ref-type="bibr" rid="bib12">Gorski et al., 2002</xref>)</p></list-item><list-item><p>Rorb-IRES2-Cre (Jax stock number 023526; Allen Mouse Brain Connectivity Atlas: <xref ref-type="bibr" rid="bib27">Oh et al., 2014</xref>; <xref ref-type="bibr" rid="bib13">Harris et al., 2014</xref>)</p></list-item><list-item><p>CaMK2a-tTA: B6.Cg-Tg(Camk2a-tTA)1Mmay/DboJ (Jax stock number 007004; <xref ref-type="bibr" rid="bib23">Mayford et al., 1996</xref>).</p></list-item></list><p>Ai93, Ai95, and Ai96 are floxed GCaMP6 reporter lines (<xref ref-type="bibr" rid="bib20">Madisen et al., 2015</xref>), which differ in the promoter/enhancer used to drive GCaMP6 expression and in the isoforms of GCaMP6 expressed. Ai95 and Ai96 lines employ a ROSA-CAG promoter to drive Cre-dependent expression of GCaMP6f and GCaMP6s, respectively (<xref ref-type="bibr" rid="bib20">Madisen et al., 2015</xref>). Stronger expression of GCaMP6f is achieved in Ai93, using the TIGRE promoter.</p><p>For most experiments reported here, these reporter lines were crossed with Emx1-IRES-Cre mice to drive expression in pyramidal neurons throughout neocortex. Ai95 and Ai96 express GCaMP6 in the presence of Cre and all experiments were performed on double transgenic mice hemizygous for Cre and for GCaMP6. As Ai93 requires the presence of both Cre and tTA to drive expression, Ai93 mice were crossed with Emx1-IRES-Cre and CaMK2a-tTA to yield triple transgenic mice that were hemizygous for all three genes. We refer to these crosses as Emx1-Ai93, Emx1-Ai95 and Emx1-Ai96 mice. For a small sub-set of experiments (<xref ref-type="fig" rid="fig5">Figure 5J–L</xref>), Ai93 was crossed with Rorb-IRES2-Cre and CaMK2a-tTA to yield Rorb-Ai93 mice. Both sexes of mice were used and all mice were maintained on a B6/C57 background.</p></sec><sec id="s4-2"><title>GCaMP6 expression</title><p>The pattern of GCaMP6 expression was examined in two mice of each genotype at postnatal day 67–114 (Emx1-Ai95 P75, Emx1-Ai96 P67, Emx1-Ai93 P67, wild-type P114). Brains were fixed by transcardial perfusion with 4% (w/v) paraformaldehyde. 100 µm-thick coronal sections were cut using a vibratome and mounted in Vectastain. Endogenous GCaMP6 was imaged by widefield or 2-photon fluorescence microscopy. Image analysis was performed in ImageJ.</p></sec><sec id="s4-3"><title>Surgery</title><p>Retinotopic imaging was performed through a 5 mm diameter circular cranial window positioned over visual areas of the left hemisphere. The preparation was similar to that described previously (<xref ref-type="bibr" rid="bib1">Andermann et al., 2010</xref>; <xref ref-type="bibr" rid="bib2">2011</xref>). Briefly, under isoflurane anesthesia, a head restraint bar was attached to the skull using C &amp; B Metabond (Parkell) and a 5 mm craniotomy opened at center coordinates 2.7 mm lateral, 1.3 mm anterior to lambda. The craniotomy was sealed with a stack of three #1 coverslips, attached to each other using optical adhesive (Norland) and to the skull with Metabond. The mouse was permitted to recover for at least seven days and conditioned to the head restraint and running wheel for several days before mapping.</p><p>All experiments and procedures were approved by the Allen Institute Animal Care and Use Committee.</p></sec><sec id="s4-4"><title>Widefield microscopy</title><p>Widefield fluorescence images were acquired with a 1:1 optical relay using two x1 PlanAPO dissecting microscope lenses (Leica, 10450028). Illumination was from a blue LED (M470, Thorlabs), via a bandpass filter (469/35, Semrock) and fluorescence was detected by a CCD camera (Orca R2, Hamamatsu) via a 497 nm dichroic and 525/39 bandpass filter (Semrock). Parts were mounted on a macroscope (THT scope, Scimedia) with its optical axis tilted 22 degrees in the coronal plane such that the optical axis was perpendicular to the cranial window. The focal plane of the microscope was positioned deep in cortex, thereby defocusing the surface vasculature during retinotopic mapping. Illumination and image acquisition were controlled with software written by JW using the Hamamatsu Video Capture Library for Labview, v.2.0.2.</p></sec><sec id="s4-5"><title>Mapping procedure and visual stimuli</title><p>During imaging, the head was restrained via the implanted bar and the eyes were on a horizontal plane. Visual stimuli were displayed on a 40&quot; LED TV (Samsung 6300), placed 13.5 cm from the right eye. The mouse was oriented with its midline at ~30° to the plane of the monitor. Visual coordinates were calculated with respect to the midline (azimuth coordinates) and the horizontal plane through the eyes (altitude coordinates). The monitor covered approximately −10 to 130 degrees in azimuth and −50 to 60 degrees in altitude. The luminance of the stimulus monitor ranged from 0.05 (black) to 177 (white) cd/m<sup>2</sup>.</p><p>Awake mice were free to run on a 16.5 cm diameter disk. For imaging under anesthesia, mice were anesthetized with &lt;1% isoflurane (inhaled) and chlorprothixene (2.5 mg/kg, intramuscular) and silicon oil (10,000 molecular weight) was applied to both eyes to prevent dehydration.</p><p>Retinotopic maps were generated by sweeping a bar across the monitor (<xref ref-type="bibr" rid="bib15">Kalatsky and Stryker, 2003</xref>). The bar contained a flickering black-and-white checkerboard pattern, with spherical correction of the stimulus to stimulate in spherical visual coordinates using a planar monitor (<xref ref-type="bibr" rid="bib22">Marshel et al., 2011</xref>; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>; <xref ref-type="other" rid="media2">Videos 2</xref> and <xref ref-type="other" rid="media3">3</xref>). The pattern subtended 20 degrees in the direction of propagation and filled the monitor in the perpendicular dimension. The checkerboard square size was 25 degrees. Each square alternated between black and white at 6 Hz. To generate a map, the bar was swept across the screen ten times in each of the four cardinal directions, moving at nine degrees per second. To ensure that stimulus-evoked activity had subsided between sweeps, a gap of ≥5 s was inserted between sweeps, resulting in repetition of the stimulus at 0.048 Hz for vertically-moving stimuli and 0.043 Hz for horizontally-moving stimuli.</p><p>During mapping, fluorescence images were acquired at 10 Hz with 2×2 binning, resulting in an effective pixel size of 12.9 µm at the sample. Across different mouse lines, fluorescence varied ~100 fold for each mouse and illumination intensity was adjusted to almost fill the camera well depth during periods of activity. Mean ± SEM illumination intensity for GCaMP mice was 89 ± 21 µW/mm<sup>2</sup> (range 19–210 µW/mm<sup>2</sup>).</p><p>A slight decline in fluorescence was generally observed during mapping, presumably due to photobleaching. Photobleaching was approximately linear with time and intensity, with fluorescence declining at 235% J<sup>−1</sup>mm<sup>2</sup> (11 mice). At the mean illumination intensity during mapping (89 µW/mm<sup>2</sup>), resting fluorescence declined at a mean rate of 0.02% per second or 1.25% per minute.</p><p>Brief stimuli (<xref ref-type="fig" rid="fig1">Figure 1</xref>) consisted of a white circle 20° in diameter, 50 ms in duration, centered at 60° azimuth and 0° altitude, on a black background. The white circle was displayed 20 times at 0.2 Hz. Images were acquired under 1.8 µW/mm<sup>2</sup> illumination at ~64 Hz with 8×8 on-chip binning, resulting in an effective pixel size of 51.6 µm at the sample.</p></sec><sec id="s4-6"><title>Widefield image analysis</title><p>All image analyses were performed in the Python programming environment, with OpenCV/SimpleCV libraries, after subtraction of a camera bias of 100 digitizer units.</p><p>For retinotopic mapping experiments, our analysis followed the methods described by <xref ref-type="bibr" rid="bib9">Garrett et al. (2014)</xref> with minor modifications. We first created △F movies: for each presentation of the checkerboard stimulus, from all frames of the movie we subtracted an image corresponding to the mean of the 2 s before the start of stimulation. We then created a stimulus-triggered mean △F movie for each of the four stimulus directions, averaging 10–40 trials in each direction. To generate azimuth and altitude position maps, from fluorescence versus time data for each pixel we extracted retinotopic positions from the phase of the first harmonic component of the Fourier series, with peak frequencies of 0.043 Hz (0.022–0.065 Hz band) for azimuth and 0.048 Hz for altitude (0.024–0.072 Hz band) maps, corresponding to the periodicity of the stimulus (moving at 9° per second). To cancel the delay from stimulus to response, we calculated a pixel-by-pixel average of the visual response positions derived from movies for stimuli traveling in opposite directions (for altitude, we averaged bottom-to-top and top-to-bottom movies; for azimuth, nasal-to-temporal and temporal-to-nasal movies).</p><p>Azimuth and altitude maps were combined to generate a visual field sign map (<xref ref-type="bibr" rid="bib40">Sereno et al., 1994</xref>; <xref ref-type="bibr" rid="bib39">1995</xref>; <xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>), where the visual field sign at each pixel is the sine of the angle between the local gradients (derived with the numpy.gradient function) in azimuth and altitude. The visual field sign map was converted into borders as described by <xref ref-type="bibr" rid="bib9">Garrett et al. (2014)</xref>, <xref ref-type="bibr" rid="bib14">Juavinett et al. (2016)</xref>, as outlined in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. The visual field sign map was spatially filtered with a Gaussian kernel (standard deviation range 6–10 µm, mean ± SEM of 8.14 ± 0.08 µm, 14 mice) then thresholded to create a binary mask. For each map the threshold was tuned manually over a narrow range (field sign values of 0.2–0.4, mean ± SEM of 0.32 ± 0.004, 14 mice). Each suprathreshold patch was dilated to yield a border width between patches of one pixel. Isolated pixels were eliminated with open/close operations. The binary mask was converted into an initial 'raw' patch map in which each pixel value was −1, 0 or 1. Patches were further processed with a split/merge routine in which patches with &gt;10% redundancy in visual coverage were split using a watershed routine at the local minimum of the visual eccentricity map and, subsequently, adjacent patches with the same sign and &lt;10% redundancy in visual coverage were merged. Patches smaller than 0.00166 mm<sup>2</sup> (100 pixels) were discarded.</p><p>Python code which accepts altitude and azimuth maps and identifies patch borders is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/zhuangjun1981/retinotopic_mapping">https://github.com/zhuangjun1981/retinotopic_mapping</ext-link> and <xref ref-type="supplementary-material" rid="SD1-data">Supplementary file 1</xref>. The code includes an example data set and associated Python notebook illustrating each analysis step. Within the analysis routine, there are 13 variables that are set manually. Further explanation of these variables and the values employed in our analyses are stated in the code.</p><p>Results from multiple mice were pooled to create mean azimuth, altitude and field sign maps. Maps for each mouse were centered on the centroid of V1 and rotated to align the major axis of the azimuth gradient. Differences in relative positions of mouse and monitor were corrected by defining the V1, LM, RL border as 0° in altitude and azimuth, necessitating a correction of 0.3 ± 1.8 degrees in altitude and 14.9 ± 2.0 degrees in azimuth (14 mice). Mean azimuth and altitude maps were then calculated by vector summation (<xref ref-type="bibr" rid="bib9">Garrett et al., 2014</xref>). To create patch borders for pooled results from the average sign map (<xref ref-type="fig" rid="fig3">Figure 3B and C</xref>), we thresholded the sign map at 0.3 and further processed the patches as described above (split, merge, discard small patches).</p><p>For brief, circular stimuli (<xref ref-type="fig" rid="fig1">Figure 1F–J</xref>) twenty trials were averaged and F<sub>rest</sub> was calculated as the mean of the 2 s pre-stimulus period. △F/F movies were generated by subtraction of F<sub>rest</sub> from all pixel intensities, before division by F<sub>rest</sub>. Fluorescence was extracted from the region of the image with the greatest peak △F/F (which was generally V1): after spatial filtering with a Gaussian kernel (σ = 258 µm, corresponding to five pixels) to reduce noise, a 516 µm (10 pixel) square region of interest was centered on the brightest pixel in the maximum intensity projection of the movie (dimmest pixel in wild-type mice, in which fluorescence declined with stimulation). Results in <xref ref-type="fig" rid="fig1">Figure 1</xref> report the fluorescence intensity within this region.</p></sec><sec id="s4-7"><title>Eye tracking</title><p>An image of the right eye was recorded by infrared (IR) imaging. The peri-ocular region was illuminated with an 850 nm LED (Ostar SFH4750) and an image of the right eye was reflected by a low-pass dichroic mirror (Semrock, FF750-SDi02-25×36) placed ~3 cm from the eye and between the eye and the stimulus monitor. Distance from the eye to the camera was ~30 cm. Pupil images were acquired via a Microsoft webcam chip through a Tamron CCTV lens (23FM50SP, focal length: 50 mm) and long-pass filter (Thorlabs FEL0800). Acquisition was at 30 Hz with 320×240 pixels, effective pixel size 18 µm.</p><p>To calculate pupil position and area, we first located and tracked the corneal reflection of the infrared LED (the brightest object in the image). The LED reflection was masked to prevent it from interfering with pupil detection (e.g. in the situation that the LED reflection was inside the image of the pupil). The image was then blurred and edges were detected and exaggerated using the OpenCV 'Canny edge detection' function (<xref ref-type="bibr" rid="bib4">Canny, 1986</xref>). The pupil appeared as a dark, approximately round object. A region containing the pupil was manually selected and all spatially separate dark objects in the selected region were outlined. Each outline was subjected to an 'open' operation and all outlines with an area of less than 0.03 mm<sup>2</sup> were discarded. For each outline, centroid location, area, average intensity and roundness were calculated and rank order similarity to the pupil in the previous frame was calculated for each parameter. The outline with the smallest summed rank across all parameters was identified as the pupil.</p><p>Mice blinked periodically. The reflection of the LED was absent from frames in which the eyelid was closed, permitting automated identification of blink events. In the absence of a previous frame containing the pupil (the first frame of the movie and first frame after a blink) the pupil was identified as the largest, most circular dark outline, again determined with a minimum rank sum criterion.</p><p>After pupil identification, pupil area was calculated by counting the number of pixels within the borders of the extracted outline and multiplying by the area of a single pixel (3.24×10<sup>−4</sup> mm<sup>2</sup>).</p><p>Pupil motion in retinotopic coordinates (changes in gaze angle) was calculated under the assumption that the mouse eye is spherical, with a radius of 1.7 mm (<xref ref-type="bibr" rid="bib36">Remtulla and Hallett, 1985</xref>). First, for each frame we determined the location of the centroid of the pupil and of the reflection of the IR-LED. From these values we calculated the position of the pupil (in pixels) relative to the LED reflection in horizontal and vertical planes (X<sub>i</sub> and Y<sub>i</sub>, where i represents frame number). The cardinal axes of the camera chip, which was mounted parallel to the optical table, were used to define the horizontal and vertical planes of pupil movements. Pupil positions in pixels were converted to changes in azimuth and altitude gaze angles by trigonometry: Δθ<sub>azi</sub> = arcsin(ΔX<sub>i</sub>/r); Δθ<sub>alt</sub> = arcsin(ΔY<sub>i</sub>/r), where ΔX<sub>i</sub> and ΔY<sub>i</sub> represent the deviation of X and Y position in the i<sup>th</sup> frame from the mean location during the movie, and r was set to be 1.7 mm (the average radius of mouse eye ball).</p></sec><sec id="s4-8"><title>Registration of retinotopic maps to chemoarchitectonic and cytoarchitectonic borders</title><p>Retinotopic maps were compared to chemoarchitectonic borders via cytochrome C oxidase (CO)-stained tangential sections of flattened cortex from 4 Emx1-Ai96 mice. For each mouse, the retinotopic map was aligned to the bright field image of the surface vasculature within the cranial window. The mouse was transcardially perfused, sequentially, with saline (10 ml/min for 10 min); 5 µg/ml DyLight 649-lectin conjugate (Vector Laboratory, 5 ml/min for 5 min, to label vascular endothelium); 5 min pause; 1% (w/v) paraformaldehyde (PFA) in PBS (5 ml/min for 20 min). After perfusion, a fluorescence image of labeled vasculature within the cranial window was acquired (640/690 nm excitation emission). The left cortex was isolated, flattened between glass slides, and post-fixed overnight in 4% PFA (<xref ref-type="bibr" rid="bib50">Wang and Burkhalter, 2007</xref>). The fixed cortical sheet was cut into an asymmetrical shape to aid future alignment of fluorescence and brightfield images of the flattened tissue. A fluorescence image of the surface vasculature was acquired and the tissue was cut tangentially into 50 µm sections. Sections were stained for CO as described previously (<xref ref-type="bibr" rid="bib44">Tootell et al., 1988</xref>; <xref ref-type="bibr" rid="bib53">Wang et al., 2012</xref>).</p><p>Images acquired at different stages of tissue processing were sequentially aligned to the CO image by manual warping using the TrakEm2 plug-in in ImageJ. Key registration steps included the alignment of vasculature images across live, whole-mount and flattened preps (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). Alignment of images of surface vasculature and CO-stained tissue, both in the flattened tissue, occurred in two steps: coarse, global alignment was via the edges of the asymmetrically-shaped tissue and fine, local alignment was by matching cross-sections of vertical blood vessels in the CO image to putative entry points of ascending/descending vessels in the fluorescence image (<xref ref-type="fig" rid="fig4">Figure 4F</xref>). Alignment was optimized in anterior V1 and barrel cortex, with the likely result that alignment was most accurate near the visual/somatosensory border. Chemoarchitectonic borders were identified manually.</p><p>Cytoarchitectonic borders were examined in 10 Rorb-Ai93 and 11 Emx1-Ai93 mice. Cytoarchitectonic borders were identified from a fluorescence image of the cortical surface via a semi-automated process. Illumination gradients were first removed by filtering the image with a Gaussian kernel (σ = 1290 µm) and subtracting the result. A median filter was used to remove small structures such as blood vessels and edges were detected using Canny edge detection implemented in Python (OpenCV package). From the set of edges, a subset that best matched the borders of primary sensory areas were selected manually. Distances between borders were measured manually, along the axis of the LM/RL border.</p></sec><sec id="s4-9"><title>Projection-based retinotopic map</title><p>The projection-based map was derived from analysis of data from the Allen Mouse Brain Connectivity Atlas (<xref ref-type="bibr" rid="bib27">Oh et al., 2014</xref>); <ext-link ext-link-type="uri" xlink:href="http://connectivity.brain-map.org/">http://connectivity.brain-map.org/</ext-link>). The Allen Mouse Brain Connectivity Atlas is a large data set derived from many mice, each with a single injection of adenoassociated virus that drives expression of GFP, an anterograde tracer. After fixation, each mouse brain in the atlas was imaged via an automated imaging and sectioning microscope, and registered to a 3-dimensional template derived from the mean autofluorescence of 1675 mouse brains (common coordinate framework v3, <ext-link ext-link-type="uri" xlink:href="http://help.brain-map.org//display/mouseconnectivity/API">http://help.brain-map.org//display/mouseconnectivity/API</ext-link>). Hence the atlas includes the location of each injection site and the distribution of fluorescently-labeled projections from the injection site, with each voxel registered to a three-dimensional template of the mouse brain (<xref ref-type="bibr" rid="bib17">Kuan et al., 2015</xref>).</p><p>We selected data from 99 mice (35 wild-type (Bl6) mice and 64 Cre mice), each with an injection into V1. The data set from each mouse consists of a 3D map of projection density. We processed the data sets through several distinct steps (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>), en route to creating two maps of connectivity anterior-posterior and medial-lateral connectivity which are comparable to maps of altitude and azimuth, respectively. In the first step, we pooled data from 99 mice by creating a weighted 3D map of connectivity, with the entry in each voxel being the center of mass of all source locations weighted by projection strength:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mtext>L</mml:mtext><mml:mrow><mml:mo stretchy="false">⇀</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mover><mml:mtext>L</mml:mtext><mml:mrow><mml:mo stretchy="false">⇀</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mtext>L</mml:mtext><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a vector specifying the estimated source location (in 3D) for this target voxel.</p><p><inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mtext>L</mml:mtext><mml:mo stretchy="false">⇀</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> is a 3D vector specifying the center of an injection site.</p><p><inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a measure of projection strength: <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p><inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the projection density (derived from fluorescence intensity) at the target pixel.</p><p><inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the injection density (derived from fluorescence intensity) at the source pixels (the injection site).</p><p><inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 99 mice</p><p>The output of this procedure was a 3D map (a 3D array) in which each voxel contained a vector (<inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi mathvariant="normal">L</mml:mi><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) with three entries: the x, y and z positions of the location in V1 from which the voxel received the strongest projection.</p><p>From this 3D array, we projected <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi mathvariant="normal">L</mml:mi><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> to the pial surface of cortex. We first calculated equipotential surfaces, using a Laplace transform, with each point on a surface being equidistant on a normalized scale from pia (distance = 0) to white matter (distance = 1) (<ext-link ext-link-type="uri" xlink:href="http://help.brain-map.org/download/attachments/2818171/MouseCCF.pdf?version=1&amp;modificationDate=1432939552497">http://help.brain-map.org/download/attachments/2818171/MouseCCF.pdf?version=1&amp;modificationDate=1432939552497</ext-link>). At each surface location, the voxel with the greatest summed projection strength along a line orthogonal to the equipotential surfaces was identified and its <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi mathvariant="normal">L</mml:mi><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> was projected to the surface, where summed projection strength = <inline-formula><mml:math id="inf11"><mml:mrow><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo movablelimits="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Only <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi mathvariant="normal">L</mml:mi><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> values from 0.1 to 0.5 of the normalized cortical depth were projected to the pial surface. The result was a 2D map of <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mi mathvariant="normal">L</mml:mi><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> entries. This 2D pial surface map was projected to the horizontal plane, yielding a 2D 'top view' of <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mtext>L</mml:mtext><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> entries.</p><p>From the <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mtext>L</mml:mtext><mml:mo stretchy="false">⇀</mml:mo></mml:mover><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> top view, we generated two maps: one displaying the anterior-posterior location in V1 from which each pixel received the strongest projection, and the other displaying the medial-lateral-posterior location in V1 from which each pixel received the strongest projection. As vertical and horizontal retinotopy are represented in orthogonal axes in V1, these two projection maps are comparable to maps of altitude and azimuth. After filtering (σ = 43 μm), we used these two maps to generate the projection-based equivalent of a field sign map, which we term the 'projection sign map' (also filtered, σ = 130 μm).</p><p>We processed the projection sign map to locate borders and, thereby, draw a projection-based retinotopic map of visual cortex using the same numerical routine employed to derive borders from field sign maps. The first step in deriving borders is to threshold the sign map. For projection-based signs maps we employed a threshold of ±0.2. Since a threshold of ±0.2 could leave gaps between visual areas, such as at the intersection of V1, AL, RL and LM (e.g. <xref ref-type="fig" rid="fig6">Figure 6E</xref>), we calculated a second projection-based field sign map using a threshold of ±0.1.</p><p>The locations of injection sites and the projection-based retinotopic map were displayed on a surface projection of autofluorescence derived from 1675 mouse brains, thereby revealing the registration of injection sites and the projection-based retinotopic map to the borders of major architectonically-defined cortical areas.</p></sec><sec id="s4-10"><title>2-photon microscopy and comparison with widefield images</title><p>2-photon experiments were performed on a Sutter MoM. Before 2-photon imaging, a retinotopic map was generated using widefield GCaMP6 fluorescence, as described above. The mouse was then moved to the 2-photon microscope where a 'local' widefield retinotopic map was generated through the microscope objective using LED illumination, a sCMOS camera and the drifting checkerboard stimulus. The V1-LM border location (which was later compared with single-cell retinotopy derived from 2-photon imaging) was derived from the local widefield map.</p><p>To ensure accurate registration of local widefield and 2-photon images, the local widefield map was generated with the microscope objective focused 200 µm below the pial surface of cortex. The 2-photon data set was collected immediately afterwards without axial or transverse translation of the field of view of the microscope, relative to the preparation. The field of view of the widefield image was greater than that of the 2-photon image. For accurate alignment of the two images, images of the surface vasculature were acquired under widefield and 2-photon illumination and used to guide a rigid transform of the widefield image, which was then cropped to the dimensions of the 2-photon image.</p><p>2-photon imaging was performed with 920 nm illumination from a Ti:sapphire laser (Coherent Chameleon II), which was focused onto the prep with a x16/0.8 NA objective (Nikon N16XLWD-PF), providing a 720×720 µm field of view. 512×512 pixel images (1.4 µm per pixel) were acquired at 30 Hz. Emitted light was collected in the epifluorescence configuration through a 735 nm dichroic reflector (FF735-DiO1, Semrock) and a 490–560 bandpass emission filter (ET525/70 m-2P, Chroma Technology). Image acquisition was controlled using ScanImage software. Single-cell receptive field mapping was performed using a sparse noise stimulus consisting of black and white squares on a 50% grey background in pseudorandom order. Each square (6×6 visual degrees, 100 ms duration) was displayed 60 times per polarity on an LCD monitor (ASUS PA248Q, mean luminance: 50 cd/m<sup>2</sup>).</p><p>Fluorescence was extracted from the 2-photon time series by defining weighted somatic regions of interest (ROIs) using a PCA-ICA routine (<xref ref-type="bibr" rid="bib24">Mukamel et al., 2009</xref>, µ = 0.2). A size filter was employed to eliminate ROIs smaller than 59 µm<sup>2</sup> or larger than 395.5 µm<sup>2</sup>. For each somatic ROI, a neuropil ROI was created by dilating the outer border of the somatic ROI by 5 and 15 pixels to define inner and outer limits of the neuropil ROI. The union of somatic ROIs was excluded from all neuropil ROIs. For each neuron we extracted two fluorescence values per time point using the two ROIs: <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> from the somatic ROI and <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> from the neuropil ROI. We then calculated the true somatic fluorescence (Fc, without neuropil contamination) assuming linear summation: <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. We estimated r, the contamination ratio, separately for each soma by gradient descendent regression with a smoothness regularization (<ext-link ext-link-type="uri" xlink:href="http://help.brain-map.org/download/attachments/10616846/VisualCoding_Overview.pdf?version=1&amp;modificationDate=1465258498093">http://help.brain-map.org/download/attachments/10616846/VisualCoding_Overview.pdf?version=1&amp;modificationDate=1465258498093</ext-link>). The mean ± standard deviation value of r for all neurons in our data set was 0.244 ± 0.189.</p><p>After neuropil subtraction, we calculated the stimulus-triggered average fluorescence for each stimulus pixel location and polarity. An example is illustrated in <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2A</xref>). For each stimulus location, ΔF/F integrals during the 300 ms following stimulus onset were calculated for white and black squares, yielding On and Off spatial receptive fields respectively. Baseline was defined as mean fluorescence within the 0.5 s window before stimulus onset. From On and Off receptive fields we calculated On and Off z-score maps by subtracting the mean of the pixel values in the map and dividing by the standard deviation of the pixel values in the map. z-score maps were smoothed with a Gaussian filter (σ = 6 degrees) and up-sampled by a factor of 10 with cubic interpolation. If the maximum of either the On or Off receptive field was greater than two, the neuron was considered responsive to the stimulus and was included in subsequent analyses.</p><p>To calculate the receptive field center of each cell, for each receptive field map pixels with a z-score below a threshold were set to zero. The threshold employed was 40% of the greater of the maximum On and maximum Off z-scores. Pixels with z-scores above the threshold retained their original z-score values. On and Off thresholded receptive field maps were summed and the altitude and azimuth of the cell’s receptive field location were defined as weighted average coordinates of the combined receptive field. The soma-border distance for each soma was the shortest Cartesian distance between the border and the weighted average coordinates of the soma pixels.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>Funding was provided by the Allen Institute for Brain Science and award number NS078067 from the National Institute of Neurological Disorders and Stroke. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the National Institutes of health and the National Institute of Neurological Disorders and Stroke. GCaMP constructs were provided by Janelia Research Campus. We thank the many staff members of the Allen Institute, especially Linda Madisen and Hongkui Zeng for GCaMP6 reporter lines, the In Vivo Sciences team for surgeries, Marc Takeno and Quanxin Wang for advice on histology, and members of the Allen Institute for Brain Science for comments on the manuscript. We thank the Allen Institute founders, Paul G Allen and Jody Allen, for their vision, encouragement and support.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>JZ, Conception and design, Acquisition of data, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con2"><p>LN, YL, Analysis and interpretation of data, Contributed unpublished essential data or reagents</p></fn><fn fn-type="con" id="con3"><p>DW, Contributed unpublished essential data or reagents</p></fn><fn fn-type="con" id="con4"><p>MV, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con5"><p>MG, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn><fn fn-type="con" id="con6"><p>JW, Conception and design, Analysis and interpretation of data, Drafting or revising the article</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: This study was performed in accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to institutional animal care and use committee protocols of the Allen Institute for Brain Science, protocols 1205, 1406 and 1408.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="SD1-data"><object-id pub-id-type="doi">10.7554/eLife.18372.027</object-id><label>Supplementary file 1.</label><caption><title>Retinotopic mapping example analysis.</title><p>Example of derivation of a field sign map from altitude and azimuth maps, in HTML format. The same example is available as a Jupyter notebook at <ext-link ext-link-type="uri" xlink:href="https://github.com/zhuangjun1981/retinotopic_mapping">https://github.com/zhuangjun1981/retinotopic_mapping</ext-link>.</p><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.027">http://dx.doi.org/10.7554/eLife.18372.027</ext-link></p></caption><media mime-subtype="html" mimetype="text" xlink:href="elife-18372-supp1-v1.htm"/></supplementary-material><sec id="s7" sec-type="datasets"><title>Major datasets</title><p>The following previously published dataset was used:</p><p><related-object content-type="generated-dataset" id="data-ro1" source-id="http://connectivity.brain-map.org/" source-id-type="uri"><collab>Oh SW</collab><x>,</x> <collab>Harris JA</collab><x>,</x> <collab>Ng L</collab><x>,</x> <collab>Winslow B</collab><x>,</x> <collab>Cain N</collab><x>,</x> <collab>Mihalas S</collab><x>,</x> <collab>Wang Q</collab><x>,</x> <collab>Lau C</collab><x>,</x> <collab>Kuan L</collab><x>,</x> <collab>Henry AM</collab><x>,</x> <collab>Mortrud MT</collab><x>,</x> <collab>Ouellette B</collab><x>,</x> <collab>Nguyen TN</collab><x>,</x> <collab>Sorensen SA</collab><x>,</x> <collab>Slaughterbeck CR</collab><x>,</x> <collab>Wakeman W</collab><x>,</x> <collab>Li Y</collab><x>,</x> <collab>Feng D</collab><x>,</x> <collab>Ho A</collab><x>,</x> <collab>Nicholas E</collab><x>,</x> <collab>Hirokawa KE</collab><x>,</x> <collab>Bohn P</collab><x>,</x> <collab>Joines KM</collab><x>,</x> <collab>Peng H</collab><x>,</x> <collab>Hawrylycz MJ</collab><x>,</x> <collab>Phillips JW</collab><x>,</x> <collab>Hohmann JG</collab><x>,</x> <collab>Wohnoutka P</collab><x>,</x> <collab>Gerfen CR</collab><x>,</x> <collab>Koch C</collab><x>,</x> <collab>Bernard A</collab><x>,</x> <collab>Dang C</collab><x>,</x> <collab>Jones AR</collab><x>,</x> <collab>Zeng H</collab><x>,</x> <year>2014</year><x>,</x><source>A mesoscale connectome of the mouse brain</source><x>,</x> <ext-link ext-link-type="uri" xlink:href="http://connectivity.brain-map.org/">http://connectivity.brain-map.org/</ext-link><x>,</x> <comment>Publicly available at the Allen Brain Atlas Data Portal</comment></related-object></p></sec></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andermann</surname><given-names>ML</given-names></name><name><surname>Kerlin</surname><given-names>AM</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Chronic cellular imaging of mouse visual cortex during operant behavior and passive viewing</article-title><source>Frontiers in Cellullar Neuroscience</source><volume>4</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2010.00003</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andermann</surname><given-names>ML</given-names></name><name><surname>Kerlin</surname><given-names>AM</given-names></name><name><surname>Roumis</surname><given-names>DK</given-names></name><name><surname>Glickfeld</surname><given-names>LL</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Functional specialization of mouse higher visual cortical areas</article-title><source>Neuron</source><volume>72</volume><fpage>1025</fpage><lpage>1039</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.11.013</pub-id><pub-id pub-id-type="pmid">22196337</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Histed</surname><given-names>MH</given-names></name><name><surname>Yurgenson</surname><given-names>S</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Local diversity and fine-scale organization of receptive fields in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>18506</fpage><lpage>18521</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2974-11.2011</pub-id><pub-id pub-id-type="pmid">22171051</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Canny</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>A computational approach to edge detection</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><volume>8</volume><fpage>679</fpage><lpage>698</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.1986.4767851</pub-id><pub-id pub-id-type="pmid">21869365</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>TW</given-names></name><name><surname>Wardill</surname><given-names>TJ</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Pulver</surname><given-names>SR</given-names></name><name><surname>Renninger</surname><given-names>SL</given-names></name><name><surname>Baohan</surname><given-names>A</given-names></name><name><surname>Schreiter</surname><given-names>ER</given-names></name><name><surname>Kerr</surname><given-names>RA</given-names></name><name><surname>Orger</surname><given-names>MB</given-names></name><name><surname>Jayaraman</surname><given-names>V</given-names></name><name><surname>Looger</surname><given-names>LL</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Kim</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ultrasensitive fluorescent proteins for imaging neuronal activity</article-title><source>Nature</source><volume>499</volume><fpage>295</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1038/nature12354</pub-id><pub-id pub-id-type="pmid">23868258</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coogan</surname><given-names>TA</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Hierarchical organization of areas in rat visual cortex</article-title><source>Journal of Neuroscience </source><volume>13</volume><fpage>3749</fpage><lpage>3772</lpage><pub-id pub-id-type="pmid">7690066</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dräger</surname><given-names>UC</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Receptive fields of single cells and topography in mouse visual cortex</article-title><source>Journal of Comparative Neurology</source><volume>160</volume><fpage>269</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1002/cne.901600302</pub-id><pub-id pub-id-type="pmid">1112925</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Franklin</surname><given-names>KBJ</given-names></name><name><surname>Paxinos</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>The Mouse Brain in Stereotaxic Coordinates</source><publisher-loc>New York</publisher-loc><publisher-name>Elsevier</publisher-name></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname><given-names>ME</given-names></name><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Marshel</surname><given-names>JH</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topography and areal organization of mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12587</fpage><lpage>12600</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1124-14.2014</pub-id><pub-id pub-id-type="pmid">25209296</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Nascimento-Silva</surname><given-names>S</given-names></name><name><surname>Soares</surname><given-names>JGM</given-names></name><name><surname>Lima</surname><given-names>B</given-names></name><name><surname>Jansen</surname><given-names>AK</given-names></name><name><surname>Diogo</surname><given-names>ACM</given-names></name><name><surname>Farias</surname><given-names>MF</given-names></name><name><surname>Botelho</surname><given-names>M. M. , E. P.</given-names></name><name><surname>Mariani</surname><given-names>OS</given-names></name><name><surname>Azzi</surname><given-names>J</given-names></name><name><surname>Fiorani</surname><given-names>M</given-names></name><name><surname>Marcondes</surname><given-names>M</given-names></name><name><surname>Botelho</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cortical visual areas in monkeys: location, topography, connections, columns, plasticity and cortical dynamics</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>360</volume><fpage>709</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1629</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickfeld</surname><given-names>LL</given-names></name><name><surname>Andermann</surname><given-names>ML</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortico-cortical projections in mouse visual cortex are functionally target specific</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>219</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1038/nn.3300</pub-id><pub-id pub-id-type="pmid">23292681</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorski</surname><given-names>JA</given-names></name><name><surname>Talley</surname><given-names>T</given-names></name><name><surname>Qiu</surname><given-names>M</given-names></name><name><surname>Puelles</surname><given-names>L</given-names></name><name><surname>Rubenstein</surname><given-names>JL</given-names></name><name><surname>Jones</surname><given-names>KR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Cortical excitatory neurons and glia, but not GABAergic neurons, are produced in the Emx1-expressing lineage</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>6309</fpage><lpage>6314</lpage><pub-id pub-id-type="pmid">12151506</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Gu</surname><given-names>H</given-names></name><name><surname>Mills</surname><given-names>M</given-names></name><name><surname>Ng</surname><given-names>LL</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Mortrud</surname><given-names>M</given-names></name><name><surname>Ouellette</surname><given-names>B</given-names></name><name><surname>Kidney</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>KA</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Sunkin</surname><given-names>S</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Oh</surname><given-names>SW</given-names></name><name><surname>Madisen</surname><given-names>L</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anatomical characterization of Cre driver mice for neural circuit mapping and manipulation</article-title><source>Frontiers in Neural Circuits</source><volume>8</volume><elocation-id>76</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2014.00076</pub-id><pub-id pub-id-type="pmid">25071457</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juavinett</surname> <given-names>AL</given-names></name><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Garrett</surname><given-names>ME</given-names></name><name><surname>Zhuang</surname><given-names>J</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automated identification of mouse visual areas with intrinsic signal imaging</article-title><source>Nature Protocol</source><volume>12(1)</volume><fpage>32</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1038/nprot.2016.158</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalatsky</surname><given-names>VA</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>New paradigm for optical imaging: temporally encoded maps of intrinsic signal</article-title><source>Neuron</source><volume>38</volume><fpage>529</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00286-1</pub-id><pub-id pub-id-type="pmid">12765606</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krestel</surname><given-names>HE</given-names></name><name><surname>Mayford</surname><given-names>M</given-names></name><name><surname>Seeburg</surname><given-names>PH</given-names></name><name><surname>Sprengel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A GFP-equipped bidirectional expression module well suited for monitoring tetracycline-regulated gene expression in mouse</article-title><source>Nucleic Acids Research</source><volume>29</volume><elocation-id>E39</elocation-id><pub-id pub-id-type="doi">10.1093/nar/29.7.e39</pub-id><pub-id pub-id-type="pmid">11266574</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Sunkin</surname><given-names>SM</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Li Y</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuroinformatics of the allen mouse brain connectivity atlas</article-title><source>Methods</source><volume>73</volume><fpage>4</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1016/j.ymeth.2014.12.013</pub-id><pub-id pub-id-type="pmid">25536338</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laing</surname><given-names>RJ</given-names></name><name><surname>Turecek</surname><given-names>J</given-names></name><name><surname>Takahata</surname><given-names>T</given-names></name><name><surname>Olavarria</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Identification of e-specific domains and their relation to callosal connections in primary visual cortex of long evans rats</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3314</fpage><lpage>3329</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu128</pub-id><pub-id pub-id-type="pmid">24969475</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Adeyemo</surname><given-names>B</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Joo</surname><given-names>SJ</given-names></name><name><surname>Chen</surname><given-names>MY</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name><name><surname>Nelson</surname><given-names>SM</given-names></name><name><surname>Dosenbach</surname><given-names>NU</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional system and areal organization of a highly sampled individual human brain</article-title><source>Neuron</source><volume>87</volume><fpage>657</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.037</pub-id><pub-id pub-id-type="pmid">26212711</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madisen</surname><given-names>L</given-names></name><name><surname>Garner</surname><given-names>AR</given-names></name><name><surname>Shimaoka</surname><given-names>D</given-names></name><name><surname>Chuong</surname><given-names>AS</given-names></name><name><surname>Klapoetke</surname><given-names>NC</given-names></name><name><surname>Li</surname><given-names>L</given-names></name><name><surname>van der Bourg</surname><given-names>A</given-names></name><name><surname>Niino</surname><given-names>Y</given-names></name><name><surname>Egolf</surname><given-names>L</given-names></name><name><surname>Monetti</surname><given-names>C</given-names></name><name><surname>Gu</surname><given-names>H</given-names></name><name><surname>Mills</surname><given-names>M</given-names></name><name><surname>Cheng</surname><given-names>A</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Nguyen</surname><given-names>TN</given-names></name><name><surname>Sunkin</surname><given-names>SM</given-names></name><name><surname>Benucci</surname><given-names>A</given-names></name><name><surname>Nagy</surname><given-names>A</given-names></name><name><surname>Miyawaki</surname><given-names>A</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name><name><surname>Empson</surname><given-names>RM</given-names></name><name><surname>Knöpfel</surname><given-names>T</given-names></name><name><surname>Boyden</surname><given-names>ES</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Li L</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Transgenic mice for intersectional targeting of neural sensors and effectors with high specificity and performance</article-title><source>Neuron</source><volume>85</volume><fpage>942</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.02.022</pub-id><pub-id pub-id-type="pmid">25741722</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Patterns of connections in rat visual cortex</article-title><source>Journal of Neuroscience</source><volume>9</volume><fpage>3741</fpage><lpage>3752</lpage><pub-id pub-id-type="pmid">2479724</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshel</surname><given-names>JH</given-names></name><name><surname>Garrett</surname><given-names>ME</given-names></name><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Functional specialization of seven mouse visual cortical areas</article-title><source>Neuron</source><volume>72</volume><fpage>1040</fpage><lpage>1054</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.004</pub-id><pub-id pub-id-type="pmid">22196338</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayford</surname><given-names>M</given-names></name><name><surname>Bach</surname><given-names>ME</given-names></name><name><surname>Huang</surname><given-names>YY</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Hawkins</surname><given-names>RD</given-names></name><name><surname>Kandel</surname><given-names>ER</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Control of memory formation through regulated expression of a CaMKII transgene</article-title><source>Science</source><volume>274</volume><fpage>1678</fpage><lpage>1683</lpage><pub-id pub-id-type="doi">10.1126/science.274.5293.1678</pub-id><pub-id pub-id-type="pmid">8939850</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukamel</surname><given-names>EA</given-names></name><name><surname>Nimmerjahn</surname><given-names>A</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Automated analysis of cellular signals from large-scale calcium imaging data</article-title><source>Neuron</source><volume>63</volume><fpage>747</fpage><lpage>760</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.08.009</pub-id><pub-id pub-id-type="pmid">19778505</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murakami</surname><given-names>T</given-names></name><name><surname>Yoshida</surname><given-names>T</given-names></name><name><surname>Matsui</surname><given-names>T</given-names></name><name><surname>Ohki</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Wide-field Ca(2+) imaging reveals visually evoked activity in the retrosplenial area</article-title><source>Frontiers in Molecular Neuroscience</source><volume>8</volume><fpage>20</fpage><pub-id pub-id-type="doi">10.3389/fnmol.2015.00020</pub-id><pub-id pub-id-type="pmid">26106292</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassi</surname><given-names>JJ</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Parallel processing strategies of the primate visual system</article-title><source>Nature Reviews Neuroscience</source><volume>10</volume><fpage>360</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1038/nrn2619</pub-id><pub-id pub-id-type="pmid">19352403</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oh</surname><given-names>SW</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Winslow</surname><given-names>B</given-names></name><name><surname>Cain</surname><given-names>N</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Henry</surname><given-names>AM</given-names></name><name><surname>Mortrud</surname><given-names>MT</given-names></name><name><surname>Ouellette</surname><given-names>B</given-names></name><name><surname>Nguyen</surname><given-names>TN</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Slaughterbeck</surname><given-names>CR</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Ho</surname><given-names>A</given-names></name><name><surname>Nicholas</surname><given-names>E</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Joines</surname><given-names>KM</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Hawrylycz</surname><given-names>MJ</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Hohmann</surname><given-names>JG</given-names></name><name><surname>Wohnoutka</surname><given-names>P</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Oh</surname></name></person-group><year iso-8601-date="2014">2014</year><article-title>A mesoscale connectome of the mouse brain</article-title><source>Nature</source><volume>508</volume><fpage>207</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1038/nature13186</pub-id><pub-id pub-id-type="pmid">24695228</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olavarria</surname><given-names>J</given-names></name><name><surname>Mignano</surname><given-names>LR</given-names></name><name><surname>Van Sluyters</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Pattern of extrastriate visual areas connecting reciprocally with striate cortex in the mouse</article-title><source>Experimental Neurology</source><volume>78</volume><fpage>775</fpage><lpage>779</lpage><pub-id pub-id-type="doi">10.1016/0014-4886(82)90090-5</pub-id><pub-id pub-id-type="pmid">7173380</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olavarria</surname><given-names>J</given-names></name><name><surname>Montero</surname><given-names>VM</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Organization of visual cortex in the mouse revealed by correlating callosal and striate-extrastriate connections</article-title><source>Visual Neuroscience</source><volume>3</volume><fpage>59</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1017/S0952523800012517</pub-id><pub-id pub-id-type="pmid">2487092</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olavarria</surname><given-names>J</given-names></name><name><surname>Montero</surname><given-names>VM</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Reciprocal connections between the striate cortex and extrastriate cortical visual areas in the rat</article-title><source>Brain Research</source><volume>217</volume><fpage>358</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(81)90011-1</pub-id><pub-id pub-id-type="pmid">7248793</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olavarria</surname><given-names>J</given-names></name><name><surname>Montero</surname><given-names>VM</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Relation of callosal and striate-extrastriate cortical connections in the rat: morphological definition of extrastriate visual areas</article-title><source>Experimental Brain Research</source><volume>54</volume><fpage>240</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1007/BF00236223</pub-id><pub-id pub-id-type="pmid">6723844</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olcese</surname><given-names>U</given-names></name><name><surname>Iurilli</surname><given-names>G</given-names></name><name><surname>Medini</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular and synaptic architecture of multisensory integration in the mouse neocortex</article-title><source>Neuron</source><volume>79</volume><fpage>579</fpage><lpage>593</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.06.010</pub-id><pub-id pub-id-type="pmid">23850594</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orban</surname><given-names>GA</given-names></name><name><surname>Van Essen</surname><given-names>D</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Comparative mapping of higher visual areas in monkeys and humans</article-title><source>Trends in Cognitive Sciences</source><volume>8</volume><fpage>315</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.05.009</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pisauro</surname><given-names>MA</given-names></name><name><surname>Dhruv</surname><given-names>NT</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Benucci</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Fast hemodynamic responses in the visual cortex of the awake mouse</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>18343</fpage><lpage>18351</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2130-13.2013</pub-id><pub-id pub-id-type="pmid">24227743</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polack</surname><given-names>PO</given-names></name><name><surname>Contreras</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Long-range parallel processing and local recurrent activity in the visual cortex of the mouse</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>11120</fpage><lpage>11131</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6304-11.2012</pub-id><pub-id pub-id-type="pmid">22875943</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remtulla</surname><given-names>S</given-names></name><name><surname>Hallett</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>A schematic eye for the mouse, and comparisons with the rat</article-title><source>Vision Research</source><volume>25</volume><fpage>21</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(85)90076-8</pub-id><pub-id pub-id-type="pmid">3984214</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roth</surname><given-names>MM</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name><name><surname>Kampa</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distinct functional properties of primary and posteromedial visual area of mouse neocortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>9716</fpage><lpage>9726</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0110-12.2012</pub-id><pub-id pub-id-type="pmid">22787057</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuett</surname><given-names>S</given-names></name><name><surname>Bonhoeffer</surname><given-names>T</given-names></name><name><surname>Hübener</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Mapping retinotopic structure in mouse visual cortex with optical imaging</article-title><source>Journal of Neuroscience </source><volume>22</volume><fpage>6549</fpage><lpage>6559</lpage><pub-id pub-id-type="pmid">12151534</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Brady</surname><given-names>TJ</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging</article-title><source>Science</source><volume>268</volume><fpage>889</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1126/science.7754376</pub-id><pub-id pub-id-type="pmid">7754376</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>McDonald</surname><given-names>CT</given-names></name><name><surname>Allman</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Analysis of retinotopic maps in extrastriate cortex</article-title><source>Cerebral Cortex</source><volume>4</volume><fpage>601</fpage><lpage>620</lpage><pub-id pub-id-type="doi">10.1093/cercor/4.6.601</pub-id><pub-id pub-id-type="pmid">7703687</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silver</surname><given-names>MA</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Topographic maps in human frontal and parietal cortex</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>488</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.08.005</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>HC</given-names></name><name><surname>Espinoza</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Relationships between interhemispheric cortical connections and visual areas in hooded rats</article-title><source>Brain Research</source><volume>417</volume><fpage>214</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(87)90445-8</pub-id><pub-id pub-id-type="pmid">3651812</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tohmi</surname><given-names>M</given-names></name><name><surname>Meguro</surname><given-names>R</given-names></name><name><surname>Tsukano</surname><given-names>H</given-names></name><name><surname>Hishida</surname><given-names>R</given-names></name><name><surname>Shibuki</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The extrageniculate visual pathway generates distinct response properties in the higher visual areas of mice</article-title><source>Current Biology</source><volume>24</volume><fpage>587</fpage><lpage>597</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.01.061</pub-id><pub-id pub-id-type="pmid">24583013</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Hamilton</surname><given-names>SL</given-names></name><name><surname>Silverman</surname><given-names>MS</given-names></name><name><surname>Switkes</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Functional anatomy of macaque striate cortex. <italic>I. Ocular dominance, binocular interactions, and baseline</italic> conditions</article-title><source>Journal of Neuroscience</source><volume>8</volume><fpage>1500</fpage><lpage>1530</lpage><pub-id pub-id-type="pmid">3367209</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Gucht</surname><given-names>E</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name><name><surname>Van Brussel</surname><given-names>L</given-names></name><name><surname>Burnat</surname><given-names>K</given-names></name><name><surname>Arckens</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neurofilament protein and neuronal activity markers define regional architectonic parcellation in the mouse visual cortex</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>2805</fpage><lpage>2819</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm012</pub-id><pub-id pub-id-type="pmid">17337746</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2003">2003</year><chapter-title>Organization of visual areas in macaque and human cerebral cortex</chapter-title><person-group person-group-type="editor"><name><surname>Chalupa</surname> <given-names>L. M</given-names></name><name><surname>Werner</surname> <given-names>J. S</given-names></name></person-group><source>The Visual Neurosciences</source><publisher-loc>Boston</publisher-loc><publisher-name>Bradford Books</publisher-name><fpage>507</fpage><lpage>521</lpage></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vann</surname><given-names>SD</given-names></name><name><surname>Aggleton</surname><given-names>JP</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>What does the retrosplenial cortex do?</article-title><source>Nature Reviews Neuroscience</source><volume>10</volume><fpage>792</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1038/nrn2733</pub-id><pub-id pub-id-type="pmid">19812579</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagor</surname><given-names>E</given-names></name><name><surname>Mangini</surname><given-names>NJ</given-names></name><name><surname>Pearlman</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Retinotopic organization of striate and extrastriate visual cortex in the mouse</article-title><source>The Journal of Comparative Neurology</source><volume>193</volume><fpage>187</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1002/cne.901930113</pub-id><pub-id pub-id-type="pmid">6776164</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Brewer</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Visual field maps in human cortex</article-title><source>Neuron</source><volume>56</volume><fpage>366</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.10.012</pub-id><pub-id pub-id-type="pmid">17964252</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Area map of mouse visual cortex</article-title><source>The Journal of Comparative Neurology</source><volume>502</volume><fpage>339</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1002/cne.21286</pub-id><pub-id pub-id-type="pmid">17366604</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Stream-related preferences of inputs to the superior colliculus from areas of dorsal and ventral streams of mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>1696</fpage><lpage>1705</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3067-12.2013</pub-id><pub-id pub-id-type="pmid">23345242</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Gao</surname><given-names>E</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Gateways of ventral and dorsal streams in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>1905</fpage><lpage>1918</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3488-10.2011</pub-id><pub-id pub-id-type="pmid">21289200</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Network analysis of corticocortical connections reveals ventral and dorsal processing streams in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>4386</fpage><lpage>4399</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6063-11.2012</pub-id><pub-id pub-id-type="pmid">22457489</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warnking</surname><given-names>J</given-names></name><name><surname>Dojat</surname><given-names>M</given-names></name><name><surname>Guérin-Dugué</surname><given-names>A</given-names></name><name><surname>Delon-Martin</surname><given-names>C</given-names></name><name><surname>Olympieff</surname><given-names>S</given-names></name><name><surname>Richard</surname><given-names>N</given-names></name><name><surname>Chéhikian</surname><given-names>A</given-names></name><name><surname>Segebarth</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>fMRI retinotopic mapping--step by step</article-title><source>NeuroImage</source><volume>17</volume><fpage>1665</fpage><lpage>1683</lpage><pub-id pub-id-type="doi">10.1006/nimg.2002.1304</pub-id><pub-id pub-id-type="pmid">12498741</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilms</surname><given-names>M</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Hömke</surname><given-names>L</given-names></name><name><surname>Rottschy</surname><given-names>C</given-names></name><name><surname>Kujovic</surname><given-names>M</given-names></name><name><surname>Amunts</surname><given-names>K</given-names></name><name><surname>Fink</surname><given-names>GR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Comparison of functional and cytoarchitectonic maps of human visual areas V1, V2, V3d, V3v, and V4(v)</article-title><source>NeuroImage</source><volume>49</volume><fpage>1171</fpage><lpage>1179</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.09.063</pub-id><pub-id pub-id-type="pmid">19800409</pub-id></element-citation></ref></ref-list></back><sub-article article-type="article-commentary" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18372.033</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kleinfeld</surname><given-names>David</given-names></name><role>Reviewing editor</role><aff id="aff3"><institution>University of California, San Diego</institution>, <country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;An extended retinotopic map of mouse cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by David Kleinfeld as Reviewing Editor and Sabine Kastner as the Senior Editor. Tim Murphy (Reviewer #1) has agreed to reveal his identity.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Overall, the imaging, and you are an expert in this arena, is carefully performed with many technical controls, e.g., autofluorescence, although reviewer 1 has additional requests on this issue. The cytochrome oxidase staining is excellent and the comparisons of this straining, as a measure of the underlying cytoarchitecture, with the functional imaging forms the kernel of the manuscript. The central claim that functional and cytoarchitecural borders do not agree is exhilarating yet at the same time troubling. For that reason, both the reviewers and the Reviewing Editor (BRE) concur that this aspect of the work needs to be both better examined and more fully explained. The BRE has summarized this issue in terms of additional experiments and analysis that should provide clarity. You are not obligated to perform all or even any of these, but you do need to convince the reviewers and BRE that the extension of activation beyond cytological borders is real. Please consider:</p><p>1) As you mention in the text, you are recording calcium signals that are very likely to have dendritic contributions that extend outside somatic boundaries. To echo the comments of reviewer 1, it is imperative to know if these extend past cytological boundaries as they do in other areas (e.g., motor nuclei, to bring up classical structures). Perhaps you can do a number of intracellular fills of somata near the calcium signal and see if these, as opposed to the dendrites, are within the cytological border. Or perhaps you can make maps based on the calcium response to more localized cells, like parvalbumen cells, for at least a few areas.</p><p>2) Related to the above, the wide field imaging technique will yield a signal that extends beyond a cytological boundary as a result of scattering of the excitation as well as emitted light. Perhaps you could examine the border with two-photon imaging of the Ca-response, which will avoid this issue, in a number of cases. A comparison of calcium signaling as captured by wide-field imaging versus 3-D (z-stacks) with two-photo imaging near a few borders would be an excellent technical contribution to the field and settle many issues regarding this and other studies of this type.</p><p>3) Echoing comments of reviewer #2, we are uncomfortable with the analysis based on &quot;visual field sign&quot;, which further needs to be clarified early on in the manuscript and not in the Methods. As you note &quot;…visual field sign at each pixel is the sine of the angle between the local gradients… in azimuth and altitude. To find borders, the visual field map was converted to a binary image using a manually-defined threshold (~0.3-0.5) and the initial visual patches were further processed with a split/merge routine (Garrett et al., 2014)…&quot;. We assume that the threshold is on the absolute value of the visual field sign, which ranges [-1,+1] before binarization. This critical step needs to be justified with a sensitivity analysis, i.e., would a shift in threshold change the extent of overlap.</p><p>4) Related to the above, and again echoing comments of reviewer #2, we are uncomfortable with the smearing of the signal as a result of eye-movement. We appreciate that the SE of the measured mean position is small, but the range of movement is large and this smearing could also appreciably extend the border. Perhaps an extend run should be made on one map and only trials with movement of say &lt; one degree is averaged. This would demonstrate if movement does or does not contribution to a systematic extension of the borders.</p><p>Lastly, we come to the issue of the Glasser et al. (Nature 2016 PMID: 27437579) paper. As paraphrased from reviewer 2's summary: &quot;…the mismatch between field maps and cytoarchitectonic maps has not been convincingly demonstrated. This casts doubts on the most far-reaching conclusion that cytoarchitectonic borders cannot be considered as real borders. If true the much celebrated Brodmann 2.0 myeloarchitectonic area map of human cortex (Glasser et al., Nature 2016) should not be considered a map of functionally distinct areas. So, in the absence of conclusive evidence a more cautious conclusion would be that the registration of visual field maps to the underlying anatomy lacks sufficient spatial resolution to definitively settle the issue…&quot;. We note that the maps in Glaser are based on cytological boundaries, thickness of myelin (myeloarchitectonic), past knowledge of both function projections, and the results of resting state BOLD fMRI. The BRE was surprised that the resting state data in Glasser et al. gave such similar boundaries as those found from cytology, since resting state BOLD is based on parcelating voxels that have similar ultra-low-frequency fluctuations in the BOLD signal (e.g., Smith et al. TiCS 2013). Your method for parcellation is based directly on neuronal (albeit Ca and not spiking) and yields a different result than the resting state BOLD. Thus your conclusions, properly supported, could have profound impact on our thinking of maps derived from resting state BOLD signals versus more direct measures of neuronal activity.</p><p>We also ask that you address each of the additional points raised by reviewers. Please note that we expect to receive a revision within two months time.</p><p><italic>Reviewer #1:</italic> </p><p>By using a new generation of transgenic mice expressing highly sensitive indicators of neuronal activity and combining with multiple anatomical techniques, this study extends our knowledge of the functional organization of mouse visual cortex. This work clearly follows previous important contributions of Marshel et al. 2011 in Neuron or Garrett et al. 2014 in J. Neurosci which revealed the detailed retinotopic mapping of areas beyond primary visual cortex in mice.</p><p>The advantage/novelty of this new work is faster mapping and the identification of additional extra-striate areas and their relationship to other sensory modalities. The authors also effectively use neuronal subset lines for mesoscale mapping. Here, up to 15 putative extrastriate areas have been mapped, some of them, overlapping with territories of other modalities (e.g. barrel cortex). The overlap with other sensory modalities is a new exciting finding. The techniques used here were particularly well implemented and an appropriate amount of controls have been used to validate these findings. Beyond the important descriptive aspect of this work and the high quality of the results, the conclusions open new insight about multimodal processing operating within cortex.</p><p>The first part of the study about the mouse line validation appears out of focus and may weaken the impact. To my opinion, this paper is not a technical report to characterize the lines and <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> could be removed or put in supplementary material. There is no clear conclusion about which mice are best.</p><p>Important:</p><p>The limitation of the mesoscopic imaging on the topographic and territory boundary mapping are not discussed. What could be the influence of the spread (optical or neuropil)? Can the method reveal visually driven areas not retinotopically organized (i.e. can we evoke the same territories with full field gratings)? To validate the method, the authors should provide the consistency of retinotopic mapping within single animals between days so we can see whether these are truly relatively invariant maps or whether reflect the nuances of the statistical analysis. Is there any consistent relationship with the map borders and surface vessels, maybe an example could be shown?</p><p><xref ref-type="fig" rid="fig7">Figure 7</xref> uses anatomical projection data to predict the sign map. However, the results and methods related to <xref ref-type="fig" rid="fig7">Figure 7</xref> are poorly described. The author should present individual tracing data and show how this is used to generate the projection-based maps. This seems to be a very interesting approach but we cannot understand how you go from anatomical projections to the sign map, more explanation and intermediate steps are shown. NB: the URL in the second paragraph of the subsection “Projection-based retinotopic map” doesn't work. Can you also provide interpretation about the absence of projection to M2/AC recently shown by Murakami et al. 2015 in Front. Mol. Neurosci.</p><p>Some information about the origin of the signal could be clarified better: subsection “GCaMP6 expression patterns and fluorescence signals”, third paragraph – “decline in fluorescence that likely results from vasodilation&quot;. Do you have any proof this could not be a neuronal suppression? In the fourth paragraph of the aforementioned subsection: “presumably because our fluorescence measurements were from large populations of neurons, which likely display a distribution of spike times&quot; and “These kinetics are unlikely to offer the necessary temporal resolution to reliably follow the flow of visually-evoked activity through visual cortex, which occurs on a timescale of tens of milliseconds&quot;. Can you provide the information about the neuronal dynamic using 2-photon on similar mice? Describe how fast is it and how mesoscopic imaging could be considered as a simple additive model?</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref> is beautiful example of how to do correlative anatomy and mesoscale imaging. It would be important to show vessels (arterioles) that are marked on the in vivo image in 5A and follow them through to the flattened and the anatomical map. Some confusion arises since not vessels are visible in the fixed prep (arterioles only?). 2-photon cellular imaging may be another way of confirming that cellular retinotopically mapped signals are present in barrel cortex. However, we recognize that it may be difficult to get the mesoscale field of view using 2P.</p><p><italic>Reviewer #2:</italic> </p><p>The paper describes an elegant, fast and deceptively straightforward calcium imaging method for delineating retinotopically organized areas in mouse visual cortex. The results suggest a more complex parcellation scheme with 16 rather than 10 distinct areas. Three of the newly discovered visual areas reside in barrel cortex, encroach onto auditory cortex and take up space in retrosplenial cortex. The results further suggest that retinotopic and cytoarchitectonic borders are misaligned and are therefore ill-suited for delineating cortical areas. Each of the observations is eye-popping and challenges established concepts of cortical parcellation. Although field sign mapping is a powerful tool to provide a rough estimate of visual areas, I am concerned that the method overstates the spatial precision with which this can be achieved. The authors have made an impressive effort to align retinotopic maps with cytoarchitectonically defined areas, but despite the sweat have not crossed the threshold for disposing the long-held notion that cytoarchitectonic borders coincide with retinotopic borders. Three reasons may account for this. First, the eye movements account for up to 375 μm error along azimuth and ~300 μm along elevation, sufficient to account for the suggested misalignment of borders. Second, in the critical <xref ref-type="fig" rid="fig5">Figure 5</xref> it is difficult to match the blood vessels seen during retinotopic mapping with those seen after staining fixed sections for cytochrome oxidase. Further, it is not clear whether these procedures have been applied in all cases. None of the illustrated examples match the maps shown in A, making it difficult to accept the conclusion that borders are mismatched. Third, the patches identified in S1 and retrosplenial cortex map tiny regions of the visual field and resemble more projection fields than separate visual area. Visual projections to both of these regions are well documented. Thus, it appears premature to view RRL and retrosplenial cortex as new visual areas. In summary, the paper makes bold assertions, which if proven correct, have profound consequences.</p><p>Subsection “GCaMP6 expression patterns and fluorescence signals”: “GCaMP6 appears not to be evenly distributed across layers”. The statement is in conflict with <xref ref-type="fig" rid="fig1">Figure 1B, D</xref>. The distribution of GCaMP6 across extrastriate visual cortex is not clearly shown.</p><p>Subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, first paragraph: Provide a detailed description how the &quot;automated routine&quot; identified reliably areal borders. Estimate the precision with which this was done.</p><p>Figure.4: Why is RRL only present inEmx-Ai96 mice? Why is RL so much bigger in Emx-Ai96 than other lines? Why is POR absent in all the images? What is &quot;M&quot;? It seems that the &quot;mean map&quot; (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) is heavily weighted toward Emx-Ai96 and reflects a pattern that depends on the mouse line used for mapping.</p><p>Subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, fourth-sixth paragraphs: The usage of &quot;area&quot;, &quot;region&quot; and &quot;patch&quot; for describing activated parcel is confusing and blurs the definition of an area.</p><p><xref ref-type="fig" rid="fig5">Figure 5</xref>: I am unable to see the overlap in the vascular patterns and therefore cannot match the retinotopic map to the cytochrome oxidase pattern.</p><p><xref ref-type="fig" rid="fig6">Figure 6</xref>: What is the evidence that <italic>Rorb</italic> is restricted to V1?</p><p><xref ref-type="fig" rid="fig7">Figure 7</xref>: The tracing &quot;experiment&quot; lacks the precision required to conclusively demonstrate that cytoarchitectonic and retinotopic maps are misaligned.</p><p>Subsection “Extension of retinotopic organization”, first paragraph: As proposed, area P extends all around the posterior margin of V1. The authors admit that this may be a vascular artifact. Why then is this not acknowledged in <xref ref-type="fig" rid="fig9">Figure 9</xref>?</p><p>Subsection “Representation of visual space and the organization of mouse visual areas”, last paragraph: It is true that none of the higher visual areas were shown to contain a complete visual hemifield representation. But I found that the reported maps are far more complete than those shown in <xref ref-type="fig" rid="fig8">Figure 8</xref>. Thus, the statement is misleading.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.18372.034</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p><italic>Overall, the imaging, and you are an expert in this arena, is carefully performed with many technical controls, e.g., autofluorescence, although reviewer 1 has additional requests on this issue. The cytochrome oxidase staining is excellent and the comparisons of this straining, as a measure of the underlying cytoarchitecture, with the functional imaging forms the kernel of the manuscript. The central claim that functional and cytoarchitecural borders do not agree is exhilarating yet at the same time troubling. For that reason, both the reviewers and BRE concur that this aspect of the work needs to be both better examined and more fully explained. The BRE has summarized this issue in terms of additional experiments and analysis that should provide clarity. You are not obligated to perform all or even any of these, but you do need to convince the reviewers and BRE that the extension of activation beyond cytological borders is real. Please consider:</italic> </p><p><italic>1) As you mention in the text, you are recording calcium signals that are very likely to have dendritic contributions that extend outside somatic boundaries. To echo the comments of reviewer 1, it is imperative to know if these extend past cytological boundaries as they do in other areas (e.g., motor nuclei, to bring up classical structures). Perhaps you can do a number of intracellular fills of somata near the calcium signal and see if these, as opposed to the dendrites, are within the cytological border. Or perhaps you can make maps based on the calcium response to more localized cells, like parvalbumen cells, for at least a few areas.</italic> </p><p>We agree that the likely extension of dendritic signals across boundaries is an important question. We attempted to address this question using Cre lines that drive sparse GCaMP6 labeling. We have been using primarily Cux2-CreERT2 for these experiments, principally because density of labeled neurons is controllable in Cux2-CreERT2. Unfortunately the minimum labeling density has proven too dense. We may return to this question in the near future since we have a mouse line under construction with the specific aim of controlling labeling density over a greater range. In the meantime, we are unable to answer the question of whether dendritic calcium signals extend across borders, but our widefield-2P comparison indicates that if there is extension of dendritic calcium signals across boundaries then this extension does not prevent us from accurately locating boundaries using widefield fluorescence imaging.</p><p>We have added a new section to the Discussion in which we address signals from dendrites that cross borders ('Limitations of mapping with population imaging and simple visual stimuli').</p><p><italic>2) Related to the above, the wide field imaging technique will yield a signal that extends beyond a cytological boundary as a result of scattering of the excitation as well as emitted light. Perhaps you could examine the border with two-photon imaging of the Ca-response, which will avoid this issue, in a number of cases. A comparison of calcium signaling as captured by wide-field imaging versus 3-D (z-stacks) with two-photo imaging near a few borders would be an excellent technical contribution to the field and settle many issues regarding this and other studies of this type.</italic> </p><p>We obtained 2-photon data sets aligned to our widefield maps, focusing on the V1-LM border since this is where we have measured the mismatch in architectonic and retinotopic borders. The comparison confirms that widefield borders accurately report the reversal in somatic retinotopy, with a precision of ~30 µm. This precision is more than adequate to support the measured mismatch between architectonic and retinotopic borders of 100-300 µm.</p><p>The comparison is presented in a new section of the Results (‘Single-cell retinotopy along the V1-LM border’), with a new <xref ref-type="fig" rid="fig7">Figure 7</xref> and two supplementary figures (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplements 1</xref> and <xref ref-type="fig" rid="fig7s2">2</xref>) and we have added 2-photon results to the Github repository.</p><p><italic>3) Echoing comments of reviewer #2, we are uncomfortable with the analysis based on &quot;visual field sign&quot;, which further needs to be clarified early on in the manuscript and not in the Methods. As you note &quot;…visual field sign at each pixel is the sine of the angle between the local gradients… in azimuth and altitude. To find borders, the visual field map was converted to a binary image using a manually-defined threshold (~0.3-0.5) and the initial visual patches were further processed with a split/merge routine (Garrett et al., 2014)…&quot;. We assume that the threshold is on the absolute value of the visual field sign, which ranges [-1,+1] before binarization. This critical step needs to be justified with a sensitivity analysis, i.e., would a shift in threshold change the extent of overlap.</italic> </p><p>The threshold is on the absolute value of the visual field sign. We performed sensitivity analysis to explore the effect of threshold on patch incidence, shape and border location. We compared segmentation of the mean sign map (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) with thresholds of 0.2, 0.3 and 0.4. Thresholds of 0.2 and 0.4 are the limits of the range of values employed in the analysis of our data sets and a threshold of 0.3 is close to the mean value (mean = 0.32). These results are presented in a new figure (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>) and indicate that:</p><p>1) Borders between two patches are generally stable unless the threshold is changed enough to eliminate the border. For example, all the borders of V1 are virtually invariant across the threshold range from 0.2 to 0.4; borders between RL and LM and between LM and P are unaffected by the change in threshold from 0.2 to 0.3, but are absent at a threshold of 0.4; the borders between RL and LLA and between AL and LI are detected by at a threshold of 0.3 or 0.4, but not 0.2. Stable borders are readily identified in the images in panel B, in which persistent borders are in white.</p><p>2) Borders that mark the exterior of the map retract as the threshold is raised. This effect is most readily observed through the images in panel C.</p><p>3) Many patches persist across the range of thresholds. The patches that are lost at the extreme threshold values are merged with neighboring patches. At a threshold of 0.2, previously published areas that are lost by merger include RL and LLA, and AL and LI. At a threshold of 0.4, previously published areas that are lost by merger include RL, LM and P. One might therefore regard 0.2 and 0.4 as beyond the range of appropriate threshold values for our data sets.</p><p>4) For most patches, changing the threshold has little effect on coverage (panel D): the change in coverage is less than the difference in coverage between patches (until the threshold is raised sufficiently to eliminate the patch). As expected, the change in coverage is more pronounced for patches on the periphery of the map that display weaker changes in fluorescence to the visual stimulus, such as patches LLA and RLL.</p><p>The effects of changing the sign map threshold, including the effects on visual coverage, are addressed in the second paragraph of the subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization” of the Results and in the legend to <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>.</p><p>We have also made changes to the manuscript to further explain our analysis routines:</p><p>1) In the Methods, we expanded the description of the processing steps from sign map to borders, including more information on the thresholding step and values of the variables employed (subsection “Widefield image analysis”, third paragraph).</p><p>2) We have added a supplementary figure (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), illustrating with an example the analysis workflow from sign map to borders.</p><p>3) To the Methods, we have added further information about the analysis code placed on Github (subsection “Widefield image analysis”, fourth paragraph).</p><p>4) Within the analysis code on Github, we have added descriptions of all variables and information on the values we used when processing our data sets.</p><p>5) To the Results, we have added a brief description of the analysis routine (subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, second paragraph).</p><p><italic>4) Related to the above, and again echoing comments of reviewer #2, we are uncomfortable with the smearing of the signal as a result of eye-movement. We appreciate that the SE of the measured mean position is small, but the range of movement is large and this smearing could also appreciably extend the border. Perhaps an extend run should be made on one map and only trials with movement of say &lt; one degree is averaged. This would demonstrate if movement does or does not contribution to a systematic extension of the borders.</italic> </p><p>We added a supplementary figure (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>) in which we compared maps in a single imaging session from an Ai96 mouse, sorting trials into those with and without eye movements of greater than 2 degrees. The exterior borders of the sign map displayed some differences between maps, either as a result of eye movements or of averaging across the relatively small number of trials without eye movements. Importantly, the borders between visual areas (including that between V1 and LM/RL) were largely unaffected by eye movements, leading us to conclude that eye movements are not responsible for the mismatch in border locations that we report.</p><p><italic>Lastly, we come to the issue of the Glasser et al. (Nature 2016 PMID: 27437579) paper. As paraphrased from reviewer 2's summary: &quot;…the mismatch between field maps and cytoarchitectonic maps has not been convincingly demonstrated. This casts doubts on the most far-reaching conclusion that cytoarchitectonic borders cannot be considered as real borders. If true the much celebrated Brodmann 2.0 myeloarchitectonic area map of human cortex (Glasser et al., Nature 2016) should not be considered a map of functionally distinct areas. So, in the absence of conclusive evidence a more cautious conclusion would be that the registration of visual field maps to the underlying anatomy lacks sufficient spatial resolution to definitively settle the issue…&quot;. We note that the maps in Glaser are based on cytological boundaries, thickness of myelin (myeloarchitectonic), past knowledge of both function projections, and the results of resting state BOLD fMRI. The BRE was surprised that the resting state data in Glasser et al. gave such similar boundaries as those found from cytology, since resting state BOLD is based on parcelating voxels that have similar ultra-low-frequency fluctuations in the BOLD signal (e.g., Smith et al. TiCS 2013). Your method for parcellation is based directly on neuronal (albeit Ca and not spiking) and yields a different result than the resting state BOLD. Thus your conclusions, properly supported, could have profound impact on our thinking of maps derived from resting state BOLD signals versus more direct measures of neuronal activity.</italic> </p><p>Our new 2P data set indicates that our widefield imaging results offer sufficient precision to measure the mismatch in cytoarchitectonic and functional borders. However, the presence of a mismatch does not mean that 'cytoarchitectonic borders cannot be considered as real borders<italic>'</italic>. Architectonic borders do not necessarily match retinotopic borders, but may align with other functional borders. For example, it is possible that the retinotopic lateral border of V1 marks the lateral extent of retino-geniculate projections from the contralateral eye representing the contralateral visual field, and the architectonic border the lateral extent of retino-geniculate projections from the contralateral eye representing the ipsilateral visual field (Laing et al., 2015).</p><p>With regard to Glaser et al., who report on areas in humans, we would advocate caution when generalizing across species. Although there is evidence of a mismatch in structural and functional border locations for some higher visual areas in humans (Large et al., 2016, Cerebral Cortex 26, 3928–3944), we do not know whether there is a mismatch in the V1-V2 border locations in humans, which might be the equivalent of the V1-LM/RL border mismatch we have observed. If a V1-V2 border mismatch exists in humans, the size of the mismatch will need to be determined. Possibly it may be too small to be determined with fMRI-based functional measurements.</p><p><italic>We also ask that you address each of the additional points raised by reviewers. Please note that we expect to receive a revision within two months time.</italic> </p><p><italic>Reviewer #1:</italic> </p><p><italic>[…] The first part of the study about the mouse line validation appears out of focus and may weaken the impact. To my opinion, this paper is not a technical report to characterize the lines and <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig2">2</xref> could be removed or put in supplementary material. There is no clear conclusion about which mice are best.</italic> </p><p>We have moved <xref ref-type="fig" rid="fig1">Figure 1</xref> into supplementary material (as <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). <xref ref-type="fig" rid="fig2">Figure 2</xref>, describing the amplitude and kinetics of the GCaMP6 impulse-response in our mice, remains in the main body of the paper (as <xref ref-type="fig" rid="fig1">Figure 1</xref>), but we condensed the text associated with this figure.</p><p><italic>Important:</italic> </p><p><italic>The limitation of the mesoscopic imaging on the topographic and territory boundary mapping are not discussed. What could be the influence of the spread (optical or neuropil)? Can the method reveal visually driven areas not retinotopically organized (i.e. can we evoke the same territories with full field gratings)?</italic> </p><p>We have added a section to the Discussion in which we address limitations of mesoscopic imaging, including optical and neuropil spread (subsection “Limitations of mapping with population imaging and simple visual stimuli”).</p><p>Regarding full field gratings and the responsiveness of regions that are not retinotopically-organized, visually-driven regions can be extracted from power maps after pixel-wise FFT analysis (<xref ref-type="fig" rid="fig2">Figure 2</xref>, panel B). However, one would need to threshold the power map to define border locations. The power map is not sensitive to retinotopy, but aligns well to the sign map, leading us to conclude that visual responsiveness and retinotopy tend to correlate. However, the relationship appears weaker in the medial part of the window, where retrosplenial cortex responded to visual stimuli but displayed relatively weak (or noisy) retinotopy (<xref ref-type="fig" rid="fig3">Figure 3</xref> panel A, B, C). In our preparation, optical access to medial cortex is limited due to the placement of the window and the signal-to-noise ratio in this part of the window was probably poorer than in more lateral locations. Further studies, in a modified preparation, would probably be necessary to more fully understand the relationship between the amplitude of visually-evoked responses and retinotopy in medial cortex, although we should note that in a preparation with a more medial window location, the central sinus might limit optical access.</p><p><italic>To validate the method, the authors should provide the consistency of retinotopic mapping within single animals between days so we can see whether these are truly relatively invariant maps or whether reflect the nuances of the statistical analysis. Is there any consistent relationship with the map borders and surface vessels, maybe an example could be shown?</italic> </p><p>We have not performed an extensive or quantitative study of the consistency of maps across sessions, but maps generally appear fairly stable. Stability is typically greater for areas and borders near the center of the map, as we might expect given that the amplitude of the visually-evoked change in fluorescence is greater towards the center of the map (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><p>We have added a new figure in which we display examples of repeated imaging for two Emx1-Ai96 mice, with imaging sessions separated by almost 90 days (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>; subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, fifth paragraph). Even over this long time period, maps acquired from the same mouse appear more similar than maps from different mice (panels A and B). For each mouse, surface vasculature is stable and border positions shift little relative to the surface vasculature (panels C and D). As a simple quantification of variability, we plot patch areas (panels E and F). As expected, areas are fairly stable between sessions with variability being greatest for the small, peripheral patches.</p><p><italic><xref ref-type="fig" rid="fig7">Figure 7</xref> uses anatomical projection data to predict the sign map. However, the results and methods related to <xref ref-type="fig" rid="fig7">Figure 7</xref> are poorly described. The author should present individual tracing data and show how this is used to generate the projection-based maps. This seems to be a very interesting approach but we cannot understand how you go from anatomical projections to the sign map, more explanation and intermediate steps are shown.</italic> </p><p>We have added more information to the Methods section to further explain the processing of projection data sets (subsection “Projection-based retinotopic map”, second to fifth paragraphs). In addition, we have created <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> that lists the intermediate steps, in order, and provides a simple graphical representation intended to illustrate some key steps.</p><p><italic>NB: the URL in the second paragraph of the subsection “Projection-based retinotopic map” doesn't work.</italic> </p><p>We tested the URL on several machines, with Thunderbird, Chrome and Explorer, using the hyperlink and the URL typed manually. In all cases we were directed to the correct GitHub page. When manually entering the URL, we initially typed the wrong URL because the URL was underlined, which obscured an underscore between 'retinotopic' and 'mapping': <ext-link ext-link-type="uri" xlink:href="https://github.com/zhuangjun1981/retinotopic_mapping">https://github.com/zhuangjun1981/retinotopic_mapping</ext-link></p><p>To avoid this problem, in the revised manuscript (subsection “Widefield image analysis”, fourth paragraph) the URL is not underlined, revealing the underscore: <ext-link ext-link-type="uri" xlink:href="https://github.com/zhuangjun1981/retinotopic_mapping">https://github.com/zhuangjun1981/retinotopic_mapping</ext-link>.</p><p><italic>Can you also provide interpretation about the absence of projection to M2/AC recently shown by Murakami et al. 2015 in Front. Mol. Neurosci.</italic> </p><p>M2/AC, as identified by Murakami et al. (2015) is likely outside the cranial window in our experiments. Our window was circular and centered over posterior cortex, 2.7 mm lateral to the midline. Posterior S1 was typically along the anterior edge of the window. M2/AC is slightly anterior to posterior S1 and almost on the midline, with the result that M2/AC is anterior and medial to our window. To further illustrate the relative positions of these regions and our cranial window, <xref ref-type="fig" rid="fig10">Author response image 1</xref> illustrates the approximate position of our 5 mm diameter cranial window (dashed line, to scale). Image taken from <xref ref-type="fig" rid="fig2">Figure 2B</xref> of Murakami et al. (2015).<fig id="fig10" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.028</object-id><label>Author response image 1.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.028">http://dx.doi.org/10.7554/eLife.18372.028</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-resp-fig1-v1"/></fig></p><p><italic>Some information about the origin of the signal could be clarified better: subsection “GCaMP6 expression patterns and fluorescence signals”, third paragraph – “decline in fluorescence that likely results from vasodilation&quot;. Do you have any proof this could not be a neuronal suppression?</italic></p><p>We do not have proof. We have moderated this statement to indicate that vasodilation is one possible explanation for the decline in fluorescence. The text now reads '…that may result from vasodilation'.</p><p><italic>In the fourth paragraph of the aforementioned subsection: “presumably because our fluorescence measurements were from large populations of neurons, which likely display a distribution of spike times&quot; and “These kinetics are unlikely to offer the necessary temporal resolution to reliably follow the flow of visually-evoked activity through visual cortex, which occurs on a timescale of tens of milliseconds&quot;. Can you provide the information about the neuronal dynamic using 2-photon on similar mice? Describe how fast is it and how mesoscopic imaging could be considered as a simple additive model?</italic> </p><p>In the interests of condensing the text associated with the first two figures, we have deleted these sections of text.</p><p><italic><xref ref-type="fig" rid="fig5">Figure 5</xref> is beautiful example of how to do correlative anatomy and mesoscale imaging. It would be important to show vessels (arterioles) that are marked on the in vivo image in 5A and follow them through to the flattened and the anatomical map. Some confusion arises since not vessels are visible in the fixed prep (arterioles only?). 2-photon cellular imaging may be another way of confirming that cellular retinotopically mapped signals are present in barrel cortex. However, we recognize that it may be difficult to get the mesoscale field of view using 2P.</italic> </p><p>The fluorescently-tagged lectin we employed apparently labels only a subset of vessels. We do not know which subset (possibly arterioles), but the labeling is extensive enough to permit accurate alignment of images. To help readers match vessels between images, we have added a supplementary figure in which we have traced some of the labeled vessels that persist from the in vivo image through the perfused, flattened and cytochrome oxidase images (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><p><italic>Reviewer #2:</italic> </p><p><italic>The paper describes an elegant, fast and deceptively straightforward calcium imaging method for delineating retinotopically organized areas in mouse visual cortex. The results suggest a more complex parcellation scheme with 16 rather than 10 distinct areas. Three of the newly discovered visual areas reside in barrel cortex, encroach onto auditory cortex and take up space in retrosplenial cortex. The results further suggest that retinotopic and cytoarchitectonic borders are misaligned and are therefore ill-suited for delineating cortical areas. Each of the observations is eye-popping and challenges established concepts of cortical parcellation. Although field sign mapping is a powerful tool to provide a rough estimate of visual areas, I am concerned that the method overstates the spatial precision with which this can be achieved. The authors have made an impressive effort to align retinotopic maps with cytoarchitectonically defined areas, but despite the sweat have not crossed the threshold for disposing the long-held notion that cytoarchitectonic borders coincide with retinotopic borders. Three reasons may account for this. First, the eye movements account for up to 375 μm error along azimuth and ~300 μm along elevation, sufficient to account for the suggested misalignment of borders.</italic> </p><p>As discussed above (under '(4) Related to the above, and again echoing comments of reviewer #2'), we have addressed eye movements in a new Figure 3—figure supplement 3, concluding that eye movements had little effect on the alignment of borders between visual areas.</p><p><italic>Second, in the critical <xref ref-type="fig" rid="fig5">Figure 5</xref> it is difficult to match the blood vessels seen during retinotopic mapping with those seen after staining fixed sections for cytochrome oxidase. Further, it is not clear whether these procedures have been applied in all cases. None of the illustrated examples match the maps shown in A, making it difficult to accept the conclusion that borders are mismatched.</italic> </p><p>We have made a supplementary figure (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) that highlights some of the vessels that are visible across the sequence of experimental conditions. The same analysis procedures, described in the Methods, were applied in every case. In <xref ref-type="fig" rid="fig4">Figure 4</xref> (previously <xref ref-type="fig" rid="fig5">Figure 5</xref>), panels A to G are from the same mouse. The sign maps in panels A and G are at different scales (scale bars are in panels D and G) and the in vivo images in panel A need to be warped slightly (as described in the methods) to accurately match the images after fixation. To illustrate the match, in <xref ref-type="fig" rid="fig11">Author response image 2</xref> we have scaled and overlaid sign maps from panels A and G of <xref ref-type="fig" rid="fig4">Figure 4</xref> (without the warping that's necessary for precise alignment).<fig id="fig11" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.029</object-id><label>Author response image 2.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.029">http://dx.doi.org/10.7554/eLife.18372.029</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-resp-fig2-v1"/></fig></p><p><italic>Third, the patches identified in S1 and retrosplenial cortex map tiny regions of the visual field and resemble more projection fields than separate visual area. Visual projections to both of these regions are well documented. Thus, it appears premature to view RRL and retrosplenial cortex as new visual areas. In summary, the paper makes bold assertions, which if proven correct, have profound consequences.</italic> </p><p>We agree with the reviewer. Our results indicate that there is retinotopic organization in RLL and retrosplenial cortex, but do not indicate whether somata in these regions are retinotopically organized. We deliberately avoid applying the term 'visual area' to RLL and to retrosplenial cortex, instead referring to them as field sign 'patches' and as regions with retinotopic organization. We have expanded on the discussion of this topic to further clarify our use of the terms 'area', 'patch' and 'region' (subsection “Cortical regions, field sign patches and visual areas”, last paragraph).</p><p><italic>Subsection “GCaMP6 expression patterns and fluorescence signals”: “GCaMP6 appears not to be evenly distributed across layers”. The statement is in conflict with <xref ref-type="fig" rid="fig1">Figure 1B, D</xref>. The distribution of GCaMP6 across extrastriate visual cortex is not clearly shown.</italic> </p><p>Fluorescence is evenly distributed across layers in Emx1-Ai95 mice. The distribution is less clear for Emx1-Ai96, in which expression is weaker, but both show relatively homogenous fluorescence across layers compared to Emx1-Ai93. To avoid confusion, we have re-written this sentence, which is now in the legend for <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>.</p><p>We have not analyzed the laminar distribution across visual areas, beyond determining that GCaMP6 is expressed throughout cortex. In part this is because the borders between areas are difficult to locate in fixed sections, but also because our results (expressed as △F/F changes in fluorescence) should be relatively insensitive to differences in expression of GCaMP6 across areas. Hence our expression data tell us what we need to know for the purposes of our study: that GCaMP6 is expressed throughout cortex in all three Emx1-GCaMP6 lines.</p><p><italic>Subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, first paragraph: Provide a detailed description how the &quot;automated routine&quot; identified reliably areal borders. Estimate the precision with which this was done.</italic> </p><p>We have added further explanation of the automated routine to the manuscript and performed sensitivity analysis on the sign map thresholding step, described above in our responses to the consolidated comments (under '(3) Echoing comments of reviewer #2…'). To address precision, we compare widefield borders to single-cell tuning using 2-photon calcium imaging. Again, these experiments are described in our responses to the consolidated comments (under '(2) Related to the above…').</p><p><italic>Figure.4: Why is RRL only present inEmx-Ai96 mice?</italic> </p><p>RLL was present in 3 of 10 (30%) Emx1-Ai93 mice and 3 of 4 (75%) Emx1-Ai96 mice. We have added these numbers to the Results (subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, tenth paragraph). We're reluctant to speculate on whether this difference in incidence of RLL indicates a biological difference between mouse lines. RLL exhibits the smallest amplitude change in fluorescence of any field sign patch (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). We would speculate that determining whether RLL occurs preferentially in one of other mouse line would require maps from many more mice. Even with additional maps, it may be difficult to distinguish between a difference incidence of RLL between mouse lines and an apparent difference in incidence due to differing signal-to-noise between lines.</p><p><italic>Why is RL so much bigger in Emx-Ai96 than other lines?</italic> </p><p>Comparing Emx1-Ai93 and Emx1-Ai96, there is a difference in the size of some patches, including RL (<xref ref-type="fig" rid="fig12">Author response image 3</xref>). We don't yet know the reason(s) for these differences. We're cautious about interpreting these results since, once split by mouse line, each group contains data from small numbers of mice. Nonetheless, some of these differences are statistically significant. We suspect the differences in area may be related to the laminar expression patterns of GCaMP6. We're looking into this issue further, are currently gathering maps from several Cre lines and plan to address the topic in a future manuscript. Importantly, however, the main conclusions of our manuscript hold across mice and mouse lines, with the size and border locations V1, for example, being invariant.<fig id="fig12" position="float"><object-id pub-id-type="doi">10.7554/eLife.18372.030</object-id><label>Author response image 3.</label><caption><p><bold>DOI:</bold> <ext-link ext-link-type="doi" xlink:href="10.7554/eLife.18372.030">http://dx.doi.org/10.7554/eLife.18372.030</ext-link></p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-18372-resp-fig3-v1"/></fig></p><p><italic>Why is POR absent in all the images?</italic> </p><p>POR was likely outside the cranial window in most, perhaps all of our experiments (subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, ninth paragraph).</p><p><italic>What is &quot;M&quot;?</italic> </p><p>M or 'medial region' is a negative field sign patch located medial to V1 and posterior to PM (Garrett et al., 2014).</p><p><italic>It seems that the &quot;mean map&quot; (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) is heavily weighted toward Emx-Ai96 and reflects a pattern that depends on the mouse line used for mapping.</italic> </p><p>The mean map (now <xref ref-type="fig" rid="fig3">Figure 3C</xref>) is the mean of the Emx1-Ai93 and Emx1-Ai96 maps in panel B. We combined these two maps with equal weighting to avoid biasing the mean map towards Emx1-Ai93 mice. (The data set contains maps from 10 Emx1-Ai93 mice and 4 Emx1-Ai96 mice).</p><p><italic>Subsection “Retinotopic maps from GCaMP6 fluorescence reveal additional patches of retinotopic organization”, fourth-sixth paragraphs: The usage of &quot;area&quot;, &quot;region&quot; and &quot;patch&quot; for describing activated parcel is confusing and blurs the definition of an area.</italic> </p><p>We have used 'area', 'region' and 'patch' deliberately throughout the document, with each having a different meaning. Unfortunately, we had not stated explicitly the meaning of each term, as we had used them. We have added a section to the Discussion (entitled 'Cortical regions, field sign patches and visual areas') in which we address the topic of somatic vs. axonal retinotopy and explicitly state how we have used each of these terms (last paragraph).</p><p><italic><xref ref-type="fig" rid="fig5">Figure 5</xref>: I am unable to see the overlap in the vascular patterns and therefore cannot match the retinotopic map to the cytochrome oxidase pattern.</italic> </p><p>We have made a supplementary figure (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) that highlights some of the vessels that are visible across the sequence of experimental conditions.</p><p><italic><xref ref-type="fig" rid="fig6">Figure 6</xref>: What is the evidence that Rorb is restricted to V1?</italic> </p><p>We have addressed the distribution of fluorescence in <italic>Rorb</italic>-IRES-Cre mice in our responses to reviewer #1, above.</p><p><italic><xref ref-type="fig" rid="fig7">Figure 7</xref>: The tracing &quot;experiment&quot; lacks the precision required to conclusively demonstrate that cytoarchitectonic and retinotopic maps are misaligned.</italic> </p><p>The tracing 'experiment' is one of several methods we employed to compare retinotopic and architectonic border locations. We are not able to quantify the precision of these methods with confidence, but we believe that all are likely to estimate the architectonic border location with sufficient precision to support the conclusions of the manuscript, that borders are mismatched by hundreds of micrometers. Our confidence in these methods is supported by the fact that they each provide a similar estimate of the mismatch.</p><p>For a more precise measure of the precision with which we can locate borders, we have now used single-cell retinotopy, adding a 2-photon data set that indicates our widefield border locations are likely accurate to within a few tens of micrometers.</p><p><italic>Subsection “Extension of retinotopic organization”, first paragraph: As proposed, area P extends all around the posterior margin of V1. The authors admit that this may be a vascular artifact. Why then is this not acknowledged in <xref ref-type="fig" rid="fig9">Figure 9</xref>?</italic> </p><p>We do not believe that the extension of P across the posterior extent of V1 is a vascular artifact since there are projections from V1 into this region of cortex. Functional evidence for retinotopic organization posterior to V1 is more sparse, but Garrett et al. (2014) includes reflectance images in which there appears to be retinotopic organization posterior to V1 (Garrett et al., <xref ref-type="fig" rid="fig2">Figure 2</xref>). We can only speculate on why these posterior regions have not mapped more consistently in the past, but the additional challenges of imaging in this posterior location (the posterior sinus, the folded structure of posterior cortex and, in our experiments, the edge of the cranial window) may reduce the signal-to-noise ratio, relative to other parts of visual cortex, leading to less consistent results. In our maps, there is consistent retinotopic structure posterior to V1, with a field sign-positive strip extending across the posterior extent of V1 in almost every mouse (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Possibly the high signal-to-noise ratio of GCaMP6 imaging (compared to the SNR of reflectance-based imaging employed by many previous authors) may be sufficient to resolve consistent structure posterior to V1.</p><p>We consider this topic, including comparison with the literature, more appropriate for the Discussion than the Results section, hence its exclusion from the text associated with <xref ref-type="fig" rid="fig9">Figure 9</xref> and inclusion in the first paragraph of the Discussion subsection “Extension of retinotopic organization”.</p><p><italic>Subsection “Representation of visual space and the organization of mouse visual areas”, last paragraph: It is true that none of the higher visual areas were shown to contain a complete visual hemifield representation. But I found that the reported maps are far more complete than those shown in <xref ref-type="fig" rid="fig8">Figure 8</xref>. Thus, the statement is misleading.</italic> </p><p>The statement is:</p><p>“Even allowing for some expansion of coverage for each visual area, our results indicate that no higher visual areas (even those immediately surrounding V1) contain a complete description of the visual hemifield.”</p><p>We were careful to limit this statement to our results to ensure that it was accurate. The new <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>, in which we illustrate the effects of expanding coverage by the receptive field radius, further supports the statement. We have difficulty in seeing why this statement might be considered misleading and have therefore not changed the statement in the revised manuscript, but would of course be happy to modify the statement if there's a misleading implication that we have overlooked.</p></body></sub-article></article>