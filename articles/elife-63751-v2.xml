<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">63751</article-id><article-id pub-id-type="doi">10.7554/eLife.63751</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Learning precise spatiotemporal sequences via biophysically realistic learning rules in a modular, spiking network</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-198172"><name><surname>Cone</surname><given-names>Ian</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-33817"><name><surname>Shouval</surname><given-names>Harel Z</given-names></name><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2799-1337</contrib-id><email>harel.shouval@uth.tmc.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Neurobiology and Anatomy, University of Texas Medical School at Houston</institution><addr-line><named-content content-type="city">Houston, TX</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Applied Physics, Rice University</institution><addr-line><named-content content-type="city">Houston, TX</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution>Salk Institute for Biological Studies</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Senior Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>18</day><month>03</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e63751</elocation-id><history><date date-type="received" iso-8601-date="2020-10-06"><day>06</day><month>10</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-02-16"><day>16</day><month>02</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Cone and Shouval</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Cone and Shouval</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-63751-v2.pdf"/><abstract><p>Multiple brain regions are able to learn and express temporal sequences, and this functionality is an essential component of learning and memory. We propose a substrate for such representations via a network model that learns and recalls discrete sequences of variable order and duration. The model consists of a network of spiking neurons placed in a modular microcolumn based architecture. Learning is performed via a biophysically realistic learning rule that depends on synaptic ‘eligibility traces’. Before training, the network contains no memory of any particular sequence. After training, presentation of only the first element in that sequence is sufficient for the network to recall an entire learned representation of the sequence. An extended version of the model also demonstrates the ability to successfully learn and recall non-Markovian sequences. This model provides a possible framework for biologically plausible sequence learning and memory, in agreement with recent experimental results.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>reinforcement learning</kwd><kwd>sequences</kwd><kwd>systems modeling</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap></funding-source><award-id>1R01EB022891-01</award-id><principal-award-recipient><name><surname>Shouval</surname><given-names>Harel Z</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000006</institution-id><institution>Office of Naval Research</institution></institution-wrap></funding-source><award-id>N00014-16-R-BA01</award-id><principal-award-recipient><name><surname>Shouval</surname><given-names>Harel Z</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A computational model shows that it's possible to learn and replay extended temporal sequences in a network of spiking neurons with a modular architecture and a biologically realistic learning rule.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>So long as time flows in one direction, nature itself is fundamentally sequential. To operate in this reality, the brain needs to think, plan, and take action in a temporally ordered fashion. When you sing a song, hit a baseball, or even utter a word, you are engaging in sequential activity. More accurately, you are engaging in sequential recall of a learned activity – your actions not only have 'a' temporal order and duration but 'the' temporal order and duration which you learned. Hence, the question of how sequence representations are learned, stored, and recalled is of fundamental importance to neuroscience. Recent evidence has shown that such learned representations can exist in cortical circuits (<xref ref-type="bibr" rid="bib21">Gavornik and Bear, 2014</xref>; <xref ref-type="bibr" rid="bib63">Xu et al., 2012</xref>; <xref ref-type="bibr" rid="bib10">Cooke et al., 2015</xref>; <xref ref-type="bibr" rid="bib14">Eagleman and Dragoi, 2012</xref>; <xref ref-type="bibr" rid="bib65">Yin et al., 2008</xref>), begging the question: through what sort of circuits and learning paradigms can these representations arise?</p><p>To address these questions, we introduce a modular spiking network that can robustly learn and recall both the order and duration of elements in a sequence, via a local and biophysically realistic eligibility trace-based learning rule. Although the parts of the model’s construction are based upon recent experimental observations in visual cortex (<xref ref-type="bibr" rid="bib21">Gavornik and Bear, 2014</xref>; <xref ref-type="bibr" rid="bib63">Xu et al., 2012</xref>; <xref ref-type="bibr" rid="bib10">Cooke et al., 2015</xref>), utilizing observed cell types (<xref ref-type="bibr" rid="bib54">Shuler and Bear, 2006</xref>; <xref ref-type="bibr" rid="bib38">Liu et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Chubykin et al., 2013</xref>) and laminar structure (<xref ref-type="bibr" rid="bib50">Potjans and Diesmann, 2014</xref>; <xref ref-type="bibr" rid="bib3">Binzegger et al., 2009</xref>), many of its key aspects (modularity, heterogenous representations) are illustrative of general principles of sequence learning. The ability of the network to internally learn and recall both duration and order, along with its use of a local learning rule that bypasses the need for constant and explicit targets, differs from most historical and contemporary models of sequence learning (<xref ref-type="bibr" rid="bib16">Fiete et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Pereira and Brunel, 2019</xref>; <xref ref-type="bibr" rid="bib32">Klos et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Jun and Jin, 2007</xref>; <xref ref-type="bibr" rid="bib39">Liu and Buonomano, 2009</xref>; <xref ref-type="bibr" rid="bib43">Maes et al., 2020</xref>; <xref ref-type="bibr" rid="bib47">Murray and Escola, 2017</xref>; <xref ref-type="bibr" rid="bib44">Martinez et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Rajan et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">DePasquale et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Laje and Buonomano, 2013</xref>; <xref ref-type="bibr" rid="bib56">Sussillo and Abbott, 2009</xref>; <xref ref-type="bibr" rid="bib48">Nicola and Clopath, 2017</xref>). We also present an extended formulation of the model, which is capable of learning and recalling sequences with non-Markovian (i.e. history-dependent) transitions.</p><p>A variety of different models have been proposed to account for the representation and learning of sequences. Most of these models fall into one of two classes: chain structures or recurrent neural networks (RNNs). Chain structure models of neural sequence learning operate in a method akin to synfire chains (<xref ref-type="bibr" rid="bib1">Abeles, 1991</xref>) – that is, representations of different individual stimuli are linked together, in order, via feed-forward synaptic connections (<xref ref-type="bibr" rid="bib16">Fiete et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Pereira and Brunel, 2019</xref>; <xref ref-type="bibr" rid="bib32">Klos et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Jun and Jin, 2007</xref>; <xref ref-type="bibr" rid="bib39">Liu and Buonomano, 2009</xref>). These models can be formulated either via an explicit neuron to neuron chain or via an implicit embedding in a random network. While such a chain-like structure can readily encode order, there is nothing internally encoding start times, stop times, or durations of the individual elements of the sequence. Some models use the resulting activity chain as a temporal basis or ‘clock’, upon which elements and their durations can be learned at the level of the output, but the fragility of the chain itself can make such output representations very sensitive to noise (<xref ref-type="bibr" rid="bib39">Liu and Buonomano, 2009</xref>). Other models have attempted to address these issues via ad hoc solutions such as variable adaptation time constants (<xref ref-type="bibr" rid="bib44">Martinez et al., 2019</xref>), but these typically require the network to have a priori information about the sequence it will be representing.</p><p>RNNs are another common class of sequence learning models (<xref ref-type="bibr" rid="bib13">DePasquale et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Laje and Buonomano, 2013</xref>; <xref ref-type="bibr" rid="bib56">Sussillo and Abbott, 2009</xref>; <xref ref-type="bibr" rid="bib48">Nicola and Clopath, 2017</xref>). Unlike explicit feed-forward chain models, RNNs learn complex sequences by leveraging rich, dynamical representations to approximate target outputs. RNNs are fully capable of encoding duration and order, and can embed multiple sequences at once. However, common learning rules for these models, such as backpropagation through time (BPTT) or FORCE, are biologically unrealistic, as they require some combination of non-local information, precise and symmetrical feedback structures, and/or explicit feedback about the targets at every time point (<xref ref-type="bibr" rid="bib62">Whittington and Bogacz, 2019</xref>). Interestingly, recent work has shown that networks can under some conditions learn inputs via random feedback connections rather than backpropagation (<xref ref-type="bibr" rid="bib35">Lillicrap et al., 2016</xref>), but this random feedback is less effective than BPTT for learning sequences with long time scales (<xref ref-type="bibr" rid="bib46">Murray, 2019</xref>).</p><p>Experimentally, the expression of sequences in the brain often follows a compressed encoding, in which order is represented but duration is not, and sequences are replayed with a time scale dictated by the intrinsic time scales of the circuit (<xref ref-type="bibr" rid="bib17">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib55">Skaggs and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="bib12">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib30">Ji and Wilson, 2007</xref>). Such results can be accounted for by chain-like models. However, there are also many cases where neural sequences are learned and replayed at or near their behavioral time scale (<xref ref-type="bibr" rid="bib21">Gavornik and Bear, 2014</xref>; <xref ref-type="bibr" rid="bib40">Louie and Wilson, 2001</xref>; <xref ref-type="bibr" rid="bib15">Eichenlaub et al., 2020</xref>; <xref ref-type="bibr" rid="bib11">Dave and Margoliash, 2000</xref>), for which a simple ordered chain is insufficient. To account for this latter phenomenon, our model takes elements from both chain and recurrent models in order to establish a new, hybrid framework for sequence learning. Our model’s chain-like, modular structure enables it learn the order of elements, while the recurrent structure within that chain allows it to internally and flexibly learn those elements’ duration. The structure of our network allows us to use a local, biophysically realistic learning rule to adjust the synaptic weights. A transient sequential input is presented during training, and over the course of training, our learning rule causes the weights to reach fixed points. After training, the network can then recall the uncompressed transient activity of the sequential input, complete with both duration and order, upon only partial reactivation (e.g. stimulating only the first element in the sequence).</p></sec><sec sec-type="results" id="s2"><title>Results</title><sec id="s2-1"><title>A model for sequence learning based on modular architecture and eligibility trace learning</title><p>Any model that can account for learning of behavioral temporal sequences must provide answers to a simple set of questions: what measures the timing of each event in a sequence? How is that information passed to the next, or the same computational unit? What mechanism provides the appropriate delay? How are all of these elements, the order, duration, and specific timing, learned from experience? In a traditional ‘chain-like’ network with Hebbian learning, order of presented stimuli can be readily encoded by learning directional feed-forward connections between populations. However, this simple architecture proves insufficient for internally representing the duration of presented stimuli and their specific start and end times, as intrinsic time constants determine the speed at which the signal travels through the network (<xref ref-type="bibr" rid="bib47">Murray and Escola, 2017</xref>; <xref ref-type="bibr" rid="bib44">Martinez et al., 2019</xref>).</p><p>This issue is illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>. In this schematic model, each module responds to a specific external stimulus. An external sequence activates these different modules in a given order and with externally determined durations for each element (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Learning can change the feed-forward synaptic efficacies between modules to reflect the order of the presented stimuli. Upon recall, triggered by activating the first stimulus, each of the encoded stimuli are activated at the correct order. However, the duration of activation within the module, as well as the timing of the activation of the subsequent module, is determined by the intrinsic time constants of the network (<xref ref-type="fig" rid="fig1">Figure 1b</xref>), causing a temporal compression of the recalled sequence. While certain time constants, asymmetrical inhibition, or adaptation with slow time constants could be manually placed in the network to facilitate recall of the particular sequence in <xref ref-type="fig" rid="fig1">Figure 1a</xref>, there does not yet exist a realistic, robust, and general solution to this problem.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Sequence representation in networks.</title><p>(<bold>a</bold>) A network composed of different populations of cells, each population is activated by a specific stimulus, and there are plastic connections between and within these populations. Initially these connections are random and weak. Upon presentation of a sequence of stimuli (filled circles, left), the populations will become activated for the duration and in the order in which they are stimulated (right). (<bold>b</bold>) After many presentations of a particular sequence, successful asymmetric Hebbian learning encodes the order of the stimuli into the synaptic weights of the network. After training, upon presentation of the first element of the sequence (filled circle, left), the network can recall (right) the order of presentation, but the timing and duration of each element is lost. In a generic network such as this, the timing of recall is determined by intrinsic time constants of the system and not the duration in the sequence that was presented.</p></caption><graphic xlink:href="elife-63751-fig1-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><p>In this work we present a network of spiking neurons that can learn the order, duration, and specific timing of sequence elements. This model uses local and biophysically realistic learning rules, in contrast to most RNN models (<xref ref-type="bibr" rid="bib13">DePasquale et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Laje and Buonomano, 2013</xref>; <xref ref-type="bibr" rid="bib56">Sussillo and Abbott, 2009</xref>; <xref ref-type="bibr" rid="bib48">Nicola and Clopath, 2017</xref>). As in the ‘chain-like’ models, the order is learned by modifying the feed-forward synaptic efficacies between modules. Unlike those models, the duration of each element is learned via modification of the recurrent connections within each module (<xref ref-type="bibr" rid="bib16">Fiete et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Pereira and Brunel, 2019</xref>; <xref ref-type="bibr" rid="bib32">Klos et al., 2018</xref>). However, these two components are still not sufficient in order to avoid sequence compression during recall. In order to solve this problem, we assume additional structure within each module and in the allowed connections between modules. This additional structure allows us to avoid compression during recall while using relatively simple local learning rules. Consequently, the cellular response types generated by this network are consistent with experimental observation (<xref ref-type="bibr" rid="bib54">Shuler and Bear, 2006</xref>; <xref ref-type="bibr" rid="bib38">Liu et al., 2015</xref>), as described below.</p><p>Our network is composed of different modules that are selectively activated via feed-forward connections by different external stimuli. Within each module, there are two populations of excitatory cells as well as inhibitory cells (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). The excitatory cells in both populations are identical in their intrinsic properties but differ in their learned and fixed connections with other cells within the module and in different modules. We name these two excitatory populations ‘Timers’ and ‘Messengers’ – the reason for these terms will become clear below as we describe their roles within the network. The ‘Timer’ cells learn strong recurrent connections with other Timer cells within the module. This strong recurrent connectivity results in long-lasting transient activity, which is used to represent the duration of a given stimuli. Previous studies have analyzed in detail the relationship between recurrent connectivity and duration of resulting transient activity following a stimulus (<xref ref-type="bibr" rid="bib20">Gavornik et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>). Timers also excite the inhibitory cells and the ‘Messenger’ cells. Since the inhibitory cells receive input from the Timers, they have roughly the same temporal profile. However, inhibitory cells in the module decay slightly more quickly than their Timer counterparts, thanks to a combination of shorter time constants for synaptic activation (80 ms for excitatory, 10 ms for inhibitory), and small Timer to inhibitory weights (there are a number of degenerate sets of parameters which can facilitate quickly decaying inhibitory cells) (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>) (see 'Materials and methods' and Supplementary materials for more details). Owing to this temporal offset, Messenger cells selectively fire at the end of the Timers’ transient activity, since they receive input from both the Timer cells and the (faster decaying) inhibitory cells. The temporally specific profile of the Messenger cells enables them to convey a temporally specific transition between elements, via learned feed-forward connections to Timer cells in other modules. The Timer/inhibitory/Messenger modular architecture can be constructed in a number of redundant ways, including simply via random distributions of connections (see previous work (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>) for a more detailed analysis).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Microcircuit learns time intervals.</title><p>(<bold>a</bold>) Mean firing rates of Timer (black), Messenger (red), and inhibitory populations (light blue) in a microcircuit before learning (top) and after learning (bottom) to represent an 1100 ms interval. Inset: Core neural architecture (CNA) microcircuit. Solid lines indicate fixed connections, while dotted lines indicate learned connections. (<bold>b</bold>) Timer and Messenger cell type responses to delayed reward task in V1. Green bar represents stimulus and blue bar represents reward. Schematic representation of data from <xref ref-type="bibr" rid="bib38">Liu et al. (2015)</xref>.</p></caption><graphic xlink:href="elife-63751-fig2-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><p>For learning, we use a previously described reinforcement learning rule based on two competing, synapse-specific, Hebbian-activated eligibility traces (<xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">He et al., 2015</xref>): one for long-term potentiation (LTP) and one for long-term depression (LTD) (see 'Materials and methods'). The presence of Hebbian activity at a given synapse activates the two traces at different rates (and to different saturation levels), and the absence of Hebbian activity causes the traces to decay at different rates. The change in synaptic weight is determined simply by the difference in these traces upon presentation of a reinforcement signal. We have assumed that on every transition between external stimuli, a ‘novelty’ signal causes a global release of a neuromodulator, which acts as a reinforcement signal (see 'Materials and methods'). The assumption of a temporally precise but spatially widespread neuromodulatory signal might seem at odds with common notions of temporally broad neuromodulator release, but they are indeed consistent with recent recordings in several neruomodulatory systems (<xref ref-type="bibr" rid="bib27">Howe and Dombeck, 2016</xref>; <xref ref-type="bibr" rid="bib24">Hangya et al., 2015</xref>). Eligibility traces for LTP have been found in multiple brain regions (<xref ref-type="bibr" rid="bib64">Yagishita et al., 2014</xref>; <xref ref-type="bibr" rid="bib4">Bittner et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Brzosko et al., 2017</xref>), and eligibility traces for both LTP and LTD have been found in both visual and prefrontal cortex (<xref ref-type="bibr" rid="bib26">He et al., 2015</xref>). We have used this rule because it can solve the temporal credit assignment problem, allowing the network to associate events distal in time, and because it reaches fixed points in both recurrent and feed-forward learning tasks (<xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>).</p><p>Using this rule and the described architecture within a single module, we find (<xref ref-type="fig" rid="fig2">Figure 2a</xref>) that the network naturally generates cells that learn to be active for the duration of the stimulus (Timers), and other cells that activate toward the end of the stimulus duration (Messengers). The Timer cells learn the duration of the stimulus via changes in the excitatory synaptic efficacies within the Timer population. The Messenger cells evolve their specific temporal profile due to the temporal profiles of their fixed excitatory and inhibitory inputs from the Timer cells and the inhibitory cells. These results are consistent with experimental observations in V1 circuits that learn the duration between a stimulus and a reward (<xref ref-type="bibr" rid="bib54">Shuler and Bear, 2006</xref>; <xref ref-type="bibr" rid="bib38">Liu et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Chubykin et al., 2013</xref>), as shown in <xref ref-type="fig" rid="fig2">Figure 2b</xref>. These results replicate our previous results (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>) which used a learning rule with a single trace (<xref ref-type="bibr" rid="bib20">Gavornik et al., 2009</xref>).</p><p>This modular microcircuit, in which both Timer and Messenger cells emerge from learning, acts as a ‘core neural architecture’ (CNA) (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>), an elemental package of basic temporal neural responses which can then be used within the larger network to create more complicated representations. This CNA functions as the basic microcircuit for our sequence model, and each ‘element’ of an input sequence is represented by one of these CNA circuits. One must note that the individual CNAs are plastic, as their temporal properties are not fixed but adapt to the environment, through recurrent learning in the Timer population. In a structure akin to the microcircuits found in cortical columns (<xref ref-type="bibr" rid="bib50">Potjans and Diesmann, 2014</xref>), this model places distinct CNAs sensitive to particular visual stimuli in a columnar structure, as shown in <xref ref-type="fig" rid="fig3">Figure 3a</xref>. To prevent spurious excitation in our noisy, spiking network, there is soft winner-take-all (WTA) inhibition between the columns (see 'Materials and methods' and 'Discussion' for more details). When presenting a sequence of visual stimuli, different CNAs in turn become activated in sequence. Timer cells within those CNAs learn the duration of their particular stimuli via recurrent connections, while order is learned via feed-forward connections from Messengers in one column to Timers in a subsequently presented column. We will show that this modular architecture can overcome the problem of sequence compression encountered by ‘chain-like’ models.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Sequence learning and recall.</title><p>(<bold>a</bold>) Network of 12 columns, each containing a core neural architecture (CNA) microcircuit selective for a different stimulus. Columns containing microcircuits responding to blue, red, green, and orange stimuli are indicated. (<bold>b–e</bold>) Mean firing rates for Timer cells (light colors) and Messenger cells (dark colors) of four different columns during different stages of learning. Stimuli presented are shown as color bars in the top of plots. During learning, columns are stimulated in the sequence indicated by the color bars (500, 1000, 700, and 1800 ms for blue, red, green, and orange, respectively). (<bold>b</bold>) Before learning, the stimulation of a particular column only causes that column to be transiently active. (<bold>c</bold>) During the first trial of learning, all columns in the sequence become activated by the stimuli but have not yet learned to represent duration (through recurrent learning of Timer cells) or order (through feed-forward learning of the Messenger cells). (<bold>d</bold>) After many trials, the network learns to match the duration and order of presented stimuli. (<bold>e</bold>) After learning, presenting the first element in the sequence is sufficient for recall of the entire sequence. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s6">6</xref> provide additional information on the network’s construction, accuracy, robustness, spiking statistics, dynamics, and limits.</p></caption><graphic xlink:href="elife-63751-fig3-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Input layer dynamics.</title><p>(<bold>a</bold>) Simulations showing response of input layer units to 400 ms stimulus (fixed spot size, seven degrees). The input is approximated as a 50 ms pulse of Poisson spikes. This is the approximation used in the main figures of the paper. (<bold>b</bold>) Same as (a), but with input approximated by a 50 ms pulse of Poisson spikes followed by a decaying exponential tail of Poisson spikes for the remainder of the stimulus time. (<bold>c</bold>) Recall of a learned sequence, in a network with the ‘pulse+decaying tail’ input structure, as in (b).</p></caption><graphic xlink:href="elife-63751-fig3-figsupp1-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Accuracy of learning and recall.</title><p>A network is trained to a sequence of four elements, each 700 ms in duration. Owing to stochastic nature of spiking network, reported times can fluctuate from presentation to presentation, and from learning instance to learning instance. ‘Reported time’ is the time at which the sequence, up to and including that column, drops below 10 Hz. (<bold>a</bold>) Recall fluctuations. Reported times for 100 trials of recall, after one learning instance. Median reported time indicated by red bar. Top and bottom of box indicate 25th and 75th percentiles of reported times. The whiskers indicate the maximum and minimum reported times not considered outliers. Red dots indicate outliers. (<bold>b</bold>) Learning fluctuations. Reported times over 25 learning instances. Each data point in the box and whisker in (<bold>b</bold>) is the median reported time for 100 recall trials (red bars in <bold>a</bold>) for one particular learning instance. (<bold>c</bold>) Evolution of weights in during training for network shown in (a). Top, evolution of mean feed-forward weights from column one to column two. Bottom, evolution of mean recurrent weights in column one.</p></caption><graphic xlink:href="elife-63751-fig3-figsupp2-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Learning of different sequences.</title><p>Left, identity and order of stimuli shown during training. Right, mean firing rate of network after training, upon stimulation of first column in sequence. (<bold>a</bold>) Blue, green, red, and orange columns (numbers 4, 3, 11, 10) stimulated at times of 0, 300, 1200, and 1800 ms, respectively. (<bold>b</bold>) Brown, purple, orange, and red columns (numbers 6, 8, 10, 11) stimulated at times of 0, 1200, 1500, and 2700, respectively.</p></caption><graphic xlink:href="elife-63751-fig3-figsupp3-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Spiking statistics in learned network.</title><p>(<bold>a</bold>) Spike raster of network response to stimulation of first column (light blue bar), after learning a sequence of stimuli (500, 750, 500, and 1250 ms for columns 1, 2, 3, and 4, respectively). Neurons are sorted by population and sequentially by column. Neurons 1–100 are the Timer cells of the first column, neurons 101–200 are the Messenger cells of the first column, neurons 201–300 are the Timer cells of the second column, etc. (<bold>b</bold>) Zoomed in inset of dashed box in (a). (<bold>c</bold>) Histograms of interspike intervals (ISIs), segregated into Timers (dark blue) and Messengers (light blue). Coefficients of variation of the ISIs are 1.01 and 0.75 for the two populations, respectively.</p></caption><graphic xlink:href="elife-63751-fig3-figsupp4-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Eight element sequence recall.</title><p>Recall after learning a sequence of eight elements, each with duration 700 ms. Only the first element is stimulated. Notice that because of stochasticity, some elements (1 and 8) underreport their duration, while others (element 7) overreport their duration. In general, these errors can propagate in recall. For example, even though element 2 reports the correct duration (~700 ms), the sequence still underreports 1400 ms because of the errors in element 1.</p></caption><graphic xlink:href="elife-63751-fig3-figsupp5-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 6.</label><caption><title>Rate-based learning and recall.</title><p>Recreation of <xref ref-type="fig" rid="fig3">Figure 3</xref> from the main text, but using the rate-based formulation described in 'Materials and methods'. Each population of previously spiking neurons (e.g. red Timers) is now represented by one rate neuron. (<bold>a</bold>–d) Firing rates for Timer cells (light colors) and Messenger cells (dark colors) of four different columns during different stages of learning. Stimuli presented are shown as color bars in the top of plots. During learning, columns are stimulated in the sequence indicated by the color bars (500, 1000, 700, and 1800 ms for blue, red, green, and orange, respectively). (<bold>a</bold>) Before learning, the stimulation of a particular column only causes that column to be transiently active. (<bold>b</bold>) During the first trial of learning, all columns in the sequence become activated by the stimuli but have not yet learned to represent duration (through recurrent learning of Timer cells) or order (through feed-forward learning of the Messenger cells). (<bold>c</bold>) After many trials, the network learns to match the duration and order of presented stimuli. (<bold>d</bold>) After learning, presenting the first element in the sequence is sufficient for recall of the entire sequence.</p></caption><graphic xlink:href="elife-63751-fig3-figsupp6-v2.tif" mimetype="image" mime-subtype="tiff"/></fig></fig-group></sec><sec id="s2-2"><title>Learning and recalling the order and variable duration of presented sequences</title><p>Using the above described architecture and learning rule (see 'Materials and methods' for more details), the network is capable of robustly learning sequences of temporal intervals. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows the network learning a sequence of four different elements, of duration 500, 1000, 700, and 1800 ms. The different stimuli here are labeled by color (blue, green, red, orange), and there are four corresponding columns in the network (out of 12) which are sensitive to these stimuli. In this example, the inputs are modeled after lateral geniculate nucleus (LGN) responses to spot stimuli (<xref ref-type="bibr" rid="bib53">Ruksenas et al., 2007</xref>; <xref ref-type="bibr" rid="bib45">Mastronarde, 1987</xref>, see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), but more generally one may consider these stimuli to be oriented gratings, specific natural images in a movie, or non-visual stimuli such as pitches of sounds in a song.</p><p>Before learning, presentation of the blue stimulus only produces a transient response in the CNA microcircuit housed in the blue-sensitive column (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). During learning (<xref ref-type="fig" rid="fig3">Figure 3c,d</xref>), a sequence of stimuli is presented, and microcircuits in their respective columns learn to represent the duration of the stimulus which activates them. The different microcircuits also learn to ‘chain’ together in the order in which they were stimulated. After learning, presentation of the blue stimulus triggers a ‘recall’ of the entire sequence (<xref ref-type="fig" rid="fig3">Figure 3e</xref>): blue for 500 ms, red for 1000 ms, green for 700 ms, and orange for 1800 ms. The network is capable of learning sequences of temporal intervals where the individual elements can be anywhere from ~300 to ~1800 ms (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) in duration, which agrees with the observed ranges used for training V1 circuits (<xref ref-type="bibr" rid="bib21">Gavornik and Bear, 2014</xref>; <xref ref-type="bibr" rid="bib54">Shuler and Bear, 2006</xref>). Additional examples of learned sequences are shown in <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>.</p><p>The network itself shows realistic spiking statistics, with interspike interval coefficients (ISIs) of variation near 1. <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref> shows both spike rasters and ISIs for a single recall trial. The resulting firing rates are also roughly consistent with the experimentally observed Timers and Messengers (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><p>In simulations we have been able to learn a sequence of up to eight elements (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>). The upper limit on the number of elements which can be learned in a sequence has not been fully explored due to the computational time required. For this work, sequences of four elements were chosen to match experimental results (<xref ref-type="bibr" rid="bib21">Gavornik and Bear, 2014</xref>). The model presented here is a high dimensional spiking model, but similar results are obtained with a low dimensional rate model in which the activity of each population is presented by a single dynamical variable (for details, see 'Materials and methods' and <xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>).</p><p>To gain an understanding of why learning succeeds in this model, we focus on the learning occurring between and within two selected modules in a sequence (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Before training, presentation of an isolated stimulus only evokes a transient response of the CNA sensitive to that specific stimulus, since the Timer cells have yet to learn any recurrent connections, and the Messenger cells have yet to establish any feed-forward connections to the Timer cells in other columns (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). During training, a particular sequence of inputs is presented and then repeated over many trials. Hebbian activity in the network triggers activation of synapse-specific LTP and LTD associated eligibility traces, which are then converted into changes in synaptic connections upon neuromodulator release (purple arrows in <xref ref-type="fig" rid="fig4">Figure 4</xref>), occurring here closely after a change in stimuli (see <xref ref-type="disp-formula" rid="equ8 equ14">Equations 8, 9, and 14</xref> in 'Materials and methods'). Each trial pushes the weights in the network toward their fixed points (<xref ref-type="disp-formula" rid="equ17 equ18">Equations 17 and 18</xref> in 'Materials and methods'). Hebbian activity within the Timer population causes activation of their respective eligibility traces, and subsequently an increase in their recurrent connections (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). As these lateral connections grow, Timer cells sustain their activity for longer, ‘extending’ their firing profile out in time toward the neuromodulator signal associated with the start of the subsequent stimulus. As this occurs, Messenger cells get ‘dragged’ along by the Timer cells, eventually coactivating with Timer cells of the column which is stimulated next (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). This Hebbian coactivation triggers the eligibility traces of these feed-forward synaptic connections, before they too are converted into synaptic weight changes by the neuromodulator ‘novelty’ signal (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). After many trials (50–100 for the examples in this paper), weights in the network reach their steady-state values (see 'Materials and methods', <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) and learning is complete. As the result of successful learning, a physical synaptic pathway has been traced out which encodes both the duration and order of the input. After learning, the encoded sequence can be recalled by stimulation of only the first element (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). Importantly, recall does not demonstrate sequence compression, as the Messenger cells’ activation (and thereby the activation of the next element) is appropriately temporally delayed.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Change in connectivity patterns resulting from learning.</title><p>(<bold>a</bold>) Before, (<bold>b</bold>) during, and (<bold>c</bold>) after learning a sequence. Left, view of columnar structure and learned intercolumnar connections. Dotted box indicates region shown in side view, middle. Middle, the detailed view of two columns and their core neural architectures (CNAs) and learned intracolumnar connectivity. Dotted lines indicate learned connections, continuous lines indicate fixed connections. Right, illustration of mean firing rates for color coded columns. Light colors indicate Timer cells, dark colors indicate Messenger cells. Color bars indicate stimulated columns. Purple arrows indicate global neuromodulator release. (<bold>a</bold>) Before learning, stimulus of a column's Timer (<bold>T</bold>) cells only causes that column to be transiently active. (<bold>b</bold>) If another column is stimulated shortly after the first, the Messenger (<bold>M</bold>) cells of the previous column will be coactive with the Timer cells of the stimulated column, thereby increasing the feed-forward synaptic weights between these two populations. (<bold>c</bold>) After learning, a physical synaptic pathway has been traced out which links columns in the temporal order in which they were stimulated during training. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref> demonstrate the dynamics of trace learning in the recurrent and feed-forward cases, respectively.</p></caption><graphic xlink:href="elife-63751-fig4-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Recurrent learning evolution.</title><p>Top row: firing rates of Timer (light colors) and Messenger (dark colors) populations for the first two columns over the course of learning. Bottom row: eligibility traces corresponding to the recurrent weights for the Timer cells in the first column (light blue in top row). (<bold>a</bold>) For initial trials, the long-term potentiation (LTP) eligibility trace (solid red line) dominates the long-term depression (LTD) eligibility trace (dashed blue line) in the reward windows (vertical yellow lines). This leads in a net increase in synaptic efficacy. Learning aims to minimize D, the time between the end of firing in one column and the beginning of firing in the next. (<bold>b</bold>) For intermediate trials, the net difference (LTP-LTD) in the reward windows is still positive but smaller than before. Synaptic efficacy continues to increase but at a slower rate. (<bold>c</bold>) As the Timer population ‘extends’ to represent the appropriate time interval (top), the net difference between the traces during the reward windows goes to zero. The synaptic weights reach a fixed point and learning is complete.</p></caption><graphic xlink:href="elife-63751-fig4-figsupp1-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Feed-forward learning evolution.</title><p>Top row: firing rates of Timer (light colors) and Messenger (dark colors) populations for the first two columns. Bottom row: eligibility traces corresponding to the feed-forward weights between the Messenger cells of the first column (dark blue in top row) and the Timer cells of the second column (light green in top row). (<bold>a</bold>) For initial trials, there is no overlap between the Messenger cells of the first column and the Timer cells of the second column, so there is no activation of the eligibility traces. (<bold>b</bold>) For intermediate trials, as the Timers learn their duration, there starts to be an overlap term which activates the traces. The net difference between the traces (long-term potentiation-long-term depression [LTP-LTD]) in the two reward windows is positive, which causes the amplitude of the feed-forward weights to increase. (<bold>c</bold>) As the Messenger cells of the first column excite the Timer cells of the second column to have an elevated firing rate (top), the traces begin to saturate in the rising phase, and the net difference between the traces during the two reward windows goes to zero. The synaptic weights reach a fixed point and learning is complete.</p></caption><graphic xlink:href="elife-63751-fig4-figsupp2-v2.tif" mimetype="image" mime-subtype="tiff"/></fig></fig-group><p>Properly encoded durations and orders are the result of the fixed points in the learning rule, as described in the 'Materials and methods' section and in previous publications (<xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>; <xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>). Recurrent learning ends in a fixed point which sets the time <italic>D</italic> between the end of firing in one column and the start of firing in the next (see <xref ref-type="disp-formula" rid="equ17">Equation 17</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Feed-forward learning results in a fixed point which determines the connection strength between Messenger and Timer cells in subsequent columns (see <xref ref-type="disp-formula" rid="equ18">Equation 18</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). Formally, the fixed point sets the value of the Hebbian term, <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, between the Messenger cells and the Timer cells in the next column at the time of reward, and implicitly this results in setting the connection strengths <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Both these fixed points depend on the parameters of the learning rule, which can be chosen such that these terms achieve desired values (<italic>D</italic> arbitrarily small, <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to a fixed value at time of reward). Such learning can then correctly encode any presented sequence. Earlier work examines in detail the dependence of <italic>D</italic> on network parameters (<xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>; <xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">He et al., 2015</xref>).</p><p>Empirically, temporal accuracy of recall depends on many non-trivial factors (i.e. length of individual elements, length of entire sequence, placement of short elements near long elements, etc.), owing to the many non-trivial effects of stochasticity of the spiking network (spike rasters are shown in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). In addition to fluctuations in recall accuracy, there can also be fluctuations in learning accuracy, as randomness in spiking can happen to accumulate such that the traces (and therefore the fixed points) are also sufficiently modified over the course of training. Over the whole network, over the course of many trials, and over the course of learning instances, these effects tend to wash out. Reported times in the recalled sequence generally match the times of the input sequence to within 10% (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). This model does not observe any intrinsic bias toward over- or under-predicting, as this can be modulated by network parameters and can change stochastically from trial to trial or from element to element.</p><p>Our model also exhibits robustness to changes in its parameters. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we demonstrate the network successfully recalling a learned four element sequence, in which the fixed connections that establish the Timer and Messenger cells are modified by +/- 20%. Furthermore, the mean reported time in a two-column network is conserved after application of random fluctuations to the learning parameters (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). In addition, the network can also function if the synaptic time constant for excitatory connection is shortened from 80 to 20 ms (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). A long time constant of excitatory connections is often used in models of working memory (<xref ref-type="bibr" rid="bib37">Lisman et al., 1998</xref>) and models of long-lasting but transient recurrent networks (<xref ref-type="bibr" rid="bib20">Gavornik et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>). Such long time constants make the network mode robust, able to learn longer transient durations and to operate in a more physiological range (<xref ref-type="bibr" rid="bib60">Wang, 2001</xref>), and there is evidence for such time constants in some brain regions (<xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>). Nevertheless, our network can operate with faster excitatory time constants (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>), but shorter synaptic time constants limit the duration of elements that can be learned.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Robustness to core neural architecture (CNA) weight changes.</title><p>Firing rates of four columns, after learning a four element sequence, each of 700 ms duration. Only the first element is stimulated for recall. Before learning, static CNA weights W<sub>EE</sub><sup>MT</sup> and W<sub>EI</sub><sup>MT</sup> are either set as in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> (center plot), or independently adjusted +/– 20% from their values in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. In each of the four ‘modified’ cases, sequence learning is still successful and retains the correct timing. The most noticeable difference is along the W<sub>EE</sub><sup>MT</sup> axis, where the amplitude of the Messenger cells can be seen to increase as W<sub>EE</sub><sup>MT</sup> increases. Inset: CNA microcircuit with labeled connections. <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> demonstrates a two-column network’s robustness to random variations in the learning parameters. <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref> shows the success and failure cases for a network with a 20 ms excitatory time constant.</p></caption><graphic xlink:href="elife-63751-fig5-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Robustness of parameter randomization.</title><p>Left, a two-column network learns a two-element sequence (500 ms, 500 ms) over 100 different learning epochs. The mean recalled time (bar) and standard deviation of the recalled times (whiskers) are shown. Right, the same process is performed, but this time for each learning epoch, we draw eight of the learning parameters (<bold>τ<sub>p</sub>, τ<sub>d</sub></bold>, <bold>η<sub>p</sub>, η<sub>d</sub></bold>, <bold>τ<sub>p</sub><sup>FF</sup>, τ<sub>d</sub><sup>FF</sup></bold>, <bold>η<sub>p</sub><sup>FF</sup>, η<sub>d</sub><sup>FF</sup></bold>) independently and randomly from a uniform distribution with bounds of 80–120% around the original value of the given parameter. For each epoch, this randomization is different, so the 100 performed epochs represent 100 different random parameter sets. The resulting mean reported times for the randomized parameter trials closely match the mean reported times for unrandomized trials. The standard deviation of the reported times for the randomized trials increases for both columns when compared to the standard parameters, but the increase is moderate and of the same order of magnitude.</p></caption><graphic xlink:href="elife-63751-fig5-figsupp1-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Sequence learning with 20 ms excitatory time constant.</title><p>(<bold>a</bold>) A network with 20 ms excitatory time constants recalls (only first element stimulated) a learned four element sequence of 500 ms each. Sequence learning is successful and network timing is preserved. (<bold>b</bold>) A network with 20 ms excitatory time constants recalls (only first element stimulated) a learned four element sequence of 1000 ms each. The Timers in the first column reach bistability and are unable to represent 1000 ms, causing failure in sequence learning.</p></caption><graphic xlink:href="elife-63751-fig5-figsupp2-v2.tif" mimetype="image" mime-subtype="tiff"/></fig></fig-group><p>While the results shown in this work were obtained using a two-trace learning (TTL) rule, the network can also be trained with a learning rule based on a single trace (<xref ref-type="bibr" rid="bib20">Gavornik et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>), and the results are similar to those demonstrated here (one-trace results not shown).</p></sec><sec id="s2-3"><title>Learning and recalling non-Markovian sequences</title><p>In the modular network described above, the transitions from each module to the next depend only on the identity of the current module that is active; such a model is formally called a Markovian model (<xref ref-type="bibr" rid="bib23">Gillespie, 1991</xref>). While the Markov property is typically discussed in the context of probabilistic models, here we apply it to deterministic sequences as well. A Markovian model can only reproduce specific types of sequences and is unable to reproduce a sequence in which the same element is repeated more than once and is followed each time by a different element, for example, the sequence ABAC. The columnar network described above is essentially Markovian since activation of a neural population will necessarily feed forward to all other populations it is connected to, no matter the history or context. Behaviorally, learning of non-Markovian sequences is ubiquitous, and cells responsible for producing and learning non-Markovian sequences exhibit non-Markovian activation (<xref ref-type="bibr" rid="bib9">Cohen et al., 2020</xref>).</p><p>To learn non-Markovian sequences, we modify the network structure while maintaining local learning rules. Ideally, the network should be able to learn sequences which are in themselves non-Markovian (ABACAD), as well as simultaneous combinations of sequences which are non-Markovian when learned together (ACE and BCD). We will demonstrate both cases here.</p><p>For the network to learn and recall non-Markovian sequences, it must somehow keep track of its history and use this history to inform transitions during sequence learning and recall. To this end, we include two additional stages to the network (<xref ref-type="fig" rid="fig6">Figure 6</xref>). The first is a fixed (non-learning) recurrent network, sometimes called a ‘reservoir’ (as in reservoir computing) or a ‘liquid’ (as in a liquid state machine) ( <xref ref-type="bibr" rid="bib41">Maass et al., 2002</xref>; <xref ref-type="bibr" rid="bib42">Maass et al., 2004</xref>), which receives inputs from the Messenger cells in the main columnar network. Owing to these inputs and due to its strong recurrent connectivity, the current state of the reservoir network is highly dependent on the history of network activity. Therefore, it acts as a long-term memory of the state of the columnar network. The second additional stage is a high dimensional, sparse, non-linear network which receives input from the reservoir, serving to project the reservoir states into a space where they are highly separated and non-overlapping. The result is that a given pattern in this sparse network at time <italic>t</italic> uniquely identifies the history of the main network up to and including time <italic>t</italic>. Since these patterns are highly non-overlapping (due to the sparsity and non-linearity), a particular pattern at time <italic>t</italic> can use simple, local, and biophysically realistic Hebbian learning to connect to Timer cells firing at time <italic>t + </italic>Δ<inline-formula><mml:math id="inf5"><mml:mo>∆</mml:mo></mml:math></inline-formula>t in the main network (direct Messenger to Timer feed-forward learning is removed in this non-Markovian example).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Non-Markovian sequence learning and recall.</title><p>Three-stage network. Two sequentially activated columns (2–3) learn to connect to each other through a reservoir and sparse pattern net. At time <italic>t</italic>, Messenger cells from column 2 are active and act as inputs into the reservoir (earlier, Messenger cells from column 1 also fed into the reservoir). The sparse pattern net receives input from the reservoir, so as to be a unique representation of the history of the network up to and including time <italic>t</italic>. Timer cells active at <italic>t</italic> + Δ<italic>t</italic> (column 3) connect to the sparse pattern via Hebbian learning.</p></caption><graphic xlink:href="elife-63751-fig6-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><p>We test the ability of this three-stage network to learn long, non-Markovian sequences with repeated elements by presenting a sequence blue-green-blue-red-blue-orange (BGBRBO) during training (<xref ref-type="fig" rid="fig7">Figure 7</xref>). A simplified, rate-based version of the columnar network is used to reduce computation time (see 'Materials and methods). The presented sequence is such that there are three different transitions from blue to another element, and each stimulus is also presented for a different duration, making this a non-trivial problem. Before learning (<xref ref-type="fig" rid="fig7">Figure 7a</xref>), the blue stimulus does not evoke any recall, only triggering a transient response of the blue-responsive column. During learning (<xref ref-type="fig" rid="fig7">Figure 7b,c</xref>), Timer cells learn the duration of their stimulus, as before, but now it is the sparse pattern net which is using Hebbian learning to feed forward to Timers in subsequently stimulated columns. After learning (<xref ref-type="fig" rid="fig7">Figure 7d</xref>), external input to the blue stimulus is sufficient to trigger recall of the entire trained non-Markovian sequence. In this case, each blue element in the sequence has the same duration; this is owing to the fact that our TTL rule currently only supports one dynamic attractor per population. In order for repeated elements to have different durations during recall, an appropriate learning rule must be capable of creating multiple attractors within that element’s Timer population, with each attractor triggering a different duration of activity.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Non-Markovian sequence learning and recall.</title><p>Mean firing rates for Timer cells (light colors) and Messenger cells (dark colors) of four different columns during different stages of learning (before, first trial of learning, last trial of learning, after learning). Stimuli presented are shown in color bars inset in top of plots (500, 700, 500, 1300, 500, and 700 ms for blue, green, blue, red, blue, and orange, respectively).</p></caption><graphic xlink:href="elife-63751-fig7-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><p>We also demonstrate an example of simultaneous learning of two sequences with a shared element (<xref ref-type="fig" rid="fig8">Figure 8</xref>). First, a sequence blue-red-orange (BRO) is trained, and then a sequence green-red-purple (GRP) is also learned. Each of the elements in these sequences has a duration of 500 ms. With both these sequences learned and stored simultaneously in the same network, transitions from red are non-Markovian – red should transition to orange if it was preceded by blue and should transition to purple if it was preceded by green. <xref ref-type="fig" rid="fig8">Figure 8a</xref> shows recall upon stimulation of blue, while <xref ref-type="fig" rid="fig8">Figure 8b</xref> shows recall upon stimulation of green. In both cases, the sequence makes the correct transition from red to the appropriate third element. Recall of both sequences is also robust to perturbations in the initial state of the reservoir, as shown in (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>.)</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Recall of two overlapping sequences.</title><p>Mean firing rates for Timer cells (light colors) and Messenger cells (dark colors) during recall of two sequences. Both blue-red-orange (BRO) and green-red-purple (GRP) have been stored in the network via learning. (<bold>a</bold>) Recall of BRO, following presentation of a blue stimulus. (<bold>b</bold>) Recall of GRP, following presentation of a green stimulus. Note that R transitions to a different element in the two sequences. <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref> demonstrates the network’s robustness to perturbations of the reservoir’s initial state.</p></caption><graphic xlink:href="elife-63751-fig8-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Robustness in non-Markovian recall.</title><p>A three-stage network trained on two non-Markovian sequences (BRO and GRP) recalls the two sequences with and without a perturbation to the initial state of the reservoir. (<bold>a</bold>) The trained network is excited with a 500 ms blue stimulus without an initial perturbation to the reservoir. Top, mean firing rates of Timer cells (light colors) and Messenger cells (dark colors) in the columnar network. Bottom, firing rates in the reservoir. The initial state of each unit in the reservoir is drawn from a normal distribution N(0,1.2), and the dynamics follow the equations in 'Materials and methods'. (<bold>b</bold>) Same as in (a) but a perturbation (normal distribution N(0,0.25)) is applied to the initial state of the reservoir. In this example a slight sequence compression is observed, but the integrity of the transitions is maintained. (<bold>c</bold>) The difference in reservoir firing rates between the perturbed trial and the unperturbed trial (same scale as (a) and (b)). (<bold>d–f</bold>) Same as (a–c), but this time stimulating with a 500 ms green stimulus, as to recall sequence GRP.</p></caption><graphic xlink:href="elife-63751-fig8-figsupp1-v2.tif" mimetype="image" mime-subtype="tiff"/></fig></fig-group><p>Of note in these two simulations is that the ‘incorrect’ transitions do get slightly activated, as the sparse patterns responsible for these transitions are not completely non-overlapping. There is an interplay here between the robustness and uniqueness of these patterns – the sparser they are, the more non-overlapping they are, but also the more sensitive they are to noise. Other parameters in the model, such as the level of recurrence in the reservoir, or the projection strengths from the reservoir to the sparse net, also affect the robustness/uniqueness of the patterns. For the simulations shown, a set of parameters (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>) was empirically chosen so that a handful of non-Markovian transitions could be reliably encoded. Though we have not optimized the network parameters, or fully characterized its properties, these results demonstrate that such an architecture can overcome the problem of non-Markovian sequences.</p><p>The addition of the reservoir and sparse network is essential for the ability to encode and replay non-Markovian sequences, but they alone are not sufficient for sequence learning and recall in our model. One must note that the reservoir receives its input from the modular network, not from the environment, and therefore if the modular network does not learn, the inputs to the reservoir would not be generated appropriately. In this formulation, during learning, the entire sequence is presented as inputs, but to trigger recall after learning, only the first element of the learned sequence is presented. In short, the input during learning and recall is different. Typical reservoir computing models can learn an output, given a specific input signal, but if that input signal changes, then so would the resulting output. This means that typically the reservoir alone cannot learn to recall with only the first element of the sequence as input, given that it was presented the whole sequence during training.</p><p>We use rate-based versions of all three stages for simplicity and computational efficiency, but a spiking based model is likely to have similar results. In our Markovian modular model described above, we use a fully spiking model. The rate-based approximation, which we use here in the non-Markovian case, is shown to produce similar results (<xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>). The reservoir itself does not learn and needs only to be highly recurrent to recapture the demonstrated functionality. Therefore, a spiking implementation is likely to work, albeit using many more neurons and at a much higher computational cost. The sparse network as used here is binary (see 'Materials and methods'), but non-binary sparse representations are likely to produce similar results. Transitioning all three stages to using actual spiking neurons would require much time, computational power, and parameter adjustments, but there are no clear fundamental roadblocks to doing so.</p><p>We have chosen this simple sparse representation of this three-stage network, not because it is a biophysically realistic implementation but in order to demonstrate the concept that such an addition is sufficient for learning and expressing non-Markovian sequences, while still using local learning rules. The viability of this relatively simple, compartmentalized structure demonstrates two things: first, that our original columnar network can be used as a building block in more complicated tasks, and second, that even a complex task such as learning non-Markovian sequences does not require non-local learning rules to perform. There are, in general, likely a large number of architectures which would effectively achieve a similar aim – take a very complex problem like non-Markovian sequence learning and constrain the possible solution space, allowing for a local learning rule to ‘finish the job’. Other groups have approached non-Markovian sequences by including additional hierarchy or long synaptic time constants (<xref ref-type="bibr" rid="bib25">Hawkins and Ahmad, 2016</xref>; <xref ref-type="bibr" rid="bib57">Tully et al., 2016</xref>), and solutions like RNNs handle such sequences natively (albeit with non-local learning rules) since they are continuous systems with a dependence on a relatively long history when compared to the intrinsic time constants. We combine these two methods, using highly recurrent networks in the context of a larger architecture, and this combination allows us to maintain local and biophysically realistic learning rules.</p></sec></sec><sec sec-type="discussion" id="s3"><title>Discussion</title><p>In this work, we demonstrate the ability of a modular, spiking network to use local, biophysically realistic learning rules to learn and recall sequences, correctly reporting the duration and order of the individual elements. In combining modular, heterogenous structure with a learning rule based on eligibility traces, the model can accurately learn and recall sequences of up to at least eight elements, with each element anywhere from ~300 to ~1800 ms in duration. We have also shown a modified architecture that is capable of learning and recalling non-Markovian sequences with multiple history-dependent transitions.</p><p>The capabilities, construction, and rules of our model are significantly different from most contemporary and historical models of sequence learning, such as synfire chains and RNNs. In particular, we are not aware of another model that uses spiking networks and local, biophysically realistic learning rules, along with experimentally observed cell responses, to robustly learn both the order and duration of presented sequences of stimuli. Previous approaches which have attempted to internally learn both duration and order of elements (<xref ref-type="bibr" rid="bib59">Veliz-Cuba et al., 2015</xref>) have been highly sensitive to changes in parameters and/or were not based on experimentally observed cell responses. Other types of hybrid models combine chain structures with additional hierarchy/functionality (<xref ref-type="bibr" rid="bib47">Murray and Escola, 2017</xref>; <xref ref-type="bibr" rid="bib44">Martinez et al., 2019</xref>), but either requires manually set adaptation time constants that are specific for a set duration to represent the duration of elements or do not treat the duration of elements as variable at all. Recently another model has been proposed, based on a periodic and essentially deterministic timing network, which also uses biologically plausible learning rules to learn to represent single non-Markovian sequences (<xref ref-type="bibr" rid="bib43">Maes et al., 2020</xref>). However, it cannot learn arbitrarily long (and self-terminating) sequences, such as those presented in (<xref ref-type="fig" rid="fig7">Figure 7</xref>), nor can it learn several different sequences and replay them separately, such as those presented in (<xref ref-type="fig" rid="fig8">Figure 8</xref>)</p><p>The modified three-stage model is capable of learning non-Markovian sequences because of inclusion of a non-learning recurrent network that stores memory over longer durations than the modular network. However, the model’s ability to generate learned sequences depends crucially on the backbone of the modular network – because of this, we can use a non-plastic, highly recurrent reservoir and maintain biophysically realistic learning rules in the network. This modified model also differs in functionality from traditional RNNs, as in our model, the stimulus presented during training (the entire sequence) is different from the stimulus presented after learning in order to trigger recall (usually the first element is sufficient). In general, the number of elements necessary to trigger recall is the same as the number of elements needed to disambiguate the sequence (i.e. ‘A’ would be sufficient to trigger ABCD in a network embedded with learned sequences ABCD and EFGH, but ‘AB’ would be required to trigger ABCD in a network embedded with learned sequences ABCD and AFGH). In a way, our network acts as an autoencoder, both learning a reduced encoding (e.g. ‘A’ instead of ‘ABCD’) and reconstructing the original external input from this reduced encoding.</p><p>The reservoir and sparse network components of our three-stage model could be thought to arise from a projection from other cortical or subcortical areas. Functionally similar networks (ones that take complex, multimodal, and dynamic context and repackage it into sparse, separated patterns) have been observed in the dentate gyrus (<xref ref-type="bibr" rid="bib34">Leutgeb et al., 2007</xref>; <xref ref-type="bibr" rid="bib58">van Dijk and Fenton, 2018</xref>) and the cerebellum (<xref ref-type="bibr" rid="bib7">Chadderton et al., 2004</xref>; <xref ref-type="bibr" rid="bib2">Billings et al., 2014</xref>). However, these model components could also be thought of as part of the same cortical network, partially segregated in function but not necessarily by location. Pattern separation is likely a common neural computation that might occur in many brain areas, so we make no particular predictions about the locations of these network components.</p><p>Our model suggests that the types of single cell responses in V1 observed in delayed reward tasks (Timers and Messengers) (<xref ref-type="bibr" rid="bib54">Shuler and Bear, 2006</xref>; <xref ref-type="bibr" rid="bib38">Liu et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Chubykin et al., 2013</xref>) will also be present when learning a visual sequence. Furthermore, we predict that distinct populations of these cells are sensitive to and can learn the dynamics of distinct stimuli. This functional modularity could be physically implemented as physically compartmentalized in columns and layers, though this is not strictly required. We present here two equivalent possible configurations of the network. The first, <xref ref-type="fig" rid="fig9">Figure 9a</xref>, shows an architecture that more directly implements the CNA, where inhibitory neurons are physically located next to their associated excitation for clarity, and long-range inhibitory connections exist. <xref ref-type="fig" rid="fig9">Figure 9b</xref> displays a more realistic structure by restricting inhibitory connections to be local. Both architectures are functionally identical, and there are a number of other redundant constructions which recapture the behavior described in this work.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Explicit microcircuit structure.</title><p>(<bold>a,b</bold>) Two examples of complete microcircuit structure displayed in laminar architecture of cortical columns. Dashed lines represented learned connections, while continuous lines represent fixed connections. (<bold>a</bold>) Intercolumn inhibition produces soft winner-take-all dynamics between columns, interlaminar inhibition generates core neural architecture (CNA). (<bold>b</bold>) Same functionality as (a) but rearranged so as to only have local inhibition.</p></caption><graphic xlink:href="elife-63751-fig9-v2.tif" mimetype="image" mime-subtype="tiff"/></fig><p>Recent results showing sequence learning and recall in visual cortex support the idea that these cell types are implicated in sequence learning (<xref ref-type="bibr" rid="bib21">Gavornik and Bear, 2014</xref>). When multiple visual stimuli are presented sequentially, Local Field Potential (LFP) recordings indicate Timer-like responses (long, sustained potentiation) in layer V, with Messenger-like responses (short bursts centered around the transition between elements) arising in layer II/III (see Figure 4 from <xref ref-type="bibr" rid="bib21">Gavornik and Bear, 2014</xref>). These results are consistent with the hypothesis that Timers and Messengers are indeed compartmentalized into different cortical layers.</p><p>Our model makes several testable predictions. It predicts that: (1) After learning a sequence, Messenger cells will more strongly functionally connect to Timer cells that represent subsequent stimuli, than to Timers which represent previous stimuli, or to other Messengers. (2) Learning sequences with long duration elements will increase lateral connection efficacies between Timers within the same modules. However, learning sequences with short duration elements may actually weaken those same lateral connections, depending on initial conditions. (3) There will be a population of inhibitory cells within each module that have firing properties similar to Timers but that decay more quickly (<xref ref-type="fig" rid="fig2">Figure 2a</xref>).</p><p>From a theoretical perspective, the main takeaway is that the architecture of our model enables it to accurately learn and recall sequences while maintaining local learning rules. If we were to start with a homogenous, randomly connected pool of neurons, sequence learning would require precise credit assignment, which is very difficult or impossible to calculate locally. Instead, the modular structure and the functionally heterogeneous cell types of the CNA perform some of this credit assignment implicitly, by breaking down a complex, difficult to learn task into a hierarchy of well-defined and easy to learn tasks. The Timers learn the duration, and the Messengers learn the order (components in the non-Markovian formulation have similarly simple and segregated tasks). While these restrictions end up limiting the types of outputs our network can represent, they enable the use of local learning rules.</p></sec><sec sec-type="materials|methods" id="s4"><title>Materials and methods</title><sec id="s4-1"><title>Network architecture</title><p>In a totally unstructured network, the learning rule described below would be insufficient for the task of sequence learning and memory. In exchange for the freedom of online, biophysically realistic reinforcement learning, we must presuppose some restrictions on the macro structure of the network. The structure imposed on the network has two components: a modular columnar structure with restricted connections and the weight distribution of the non-plastic synaptic efficacies. The weight distribution results in the emergence of distinct Timer and Messenger cell types, and the columnar structure places populations of these cells into stimulus-specific modules.</p><p>The network consists of 12 different ‘columns’, each containing 100 excitatory Timer cells, 100 inhibitory Timer cells, 100 excitatory Messenger cells, and 100 inhibitory Messenger cells, all assembled in a CNA microcircuit. Neither the particular number nor the ratio of the cell types is a strict requirement. These populations can be represented by many spiking neurons, few spiking neurons, or a single mean field neuron, and the populations can emerge even from distributions of random connections (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>). Each column is tuned to be selective for a particular stimulus from the input layer, such that a sequence of external stimuli (e.g. ABCD or ‘red-green-orange-blue’) will trigger a corresponding sequence of input-selective columns.</p><p>To simulate presentation of visual cues, the network is stimulated by an input layer designed to mimic spiking inputs from the LGN. Each stimulus is represented in the input layer by a Poisson spike train with a 50 ms pulsed peak, in accordance with the observed cellular responses in LGN (<xref ref-type="bibr" rid="bib53">Ruksenas et al., 2007</xref>; <xref ref-type="bibr" rid="bib45">Mastronarde, 1987</xref>). In general, this spike train can also include a decaying exponential tail, but short pulses were chosen both for analytical simplicity and to match experimental data (<xref ref-type="bibr" rid="bib53">Ruksenas et al., 2007</xref>; <xref ref-type="bibr" rid="bib45">Mastronarde, 1987</xref>), as shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. The cells of the input layer feed directly into the respective Timer cells of the columnar network.</p><p>Intercolumnar inhibition exists between Timer populations and between Messenger populations in the different columns, for the purposes of soft WTA dynamics between the columns of the network. This WTA inhibition can be thought of functionally as long-range inhibitory connections (<xref ref-type="fig" rid="fig8">Figure 8a</xref>), but in reality, is much more likely to be long-range excitatory connections synapsing onto local inhibition (<xref ref-type="fig" rid="fig8">Figure 8b</xref>). Such inhibition is generally not necessary in the low-noise case (or in a rate-based model), but the stochastic, spiking nature of the network makes it a desirable practical inclusion to guard against spurious runaway excitatory chains.</p><p>For the purposes of this paper, Timer cells can only learn to connect to other Timer cells within their column, and Messenger cells can only learn to connect to (any) Timer cells outside of their column. In case of the extended network that can learn non-Markov sequences, Messenger cells connect to the reservoir and not directly to Timer cells in other columns, as described above. While we include these restrictions for practical purposes, previous publications have shown all possible intracolumnar excitatory connections to be learnable with the use of a single trace eligibility rule (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>). The strengths of non-plastic connections within columns are modeled after those learned in previous publications (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>). These fixed connections serve to establish the Timer and Messenger cells used in the network. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we demonstrate that successful sequence learning is robust to +/– 20% changes in these connections. By only learning task relevant connections, we simplify the computation and analysis while maintaining the complete general functionality of variable sequence learning and recall.</p></sec><sec id="s4-2"><title>Spiking and rate-based dynamics</title><p>The network comprises microcircuits of both excitatory and inhibitory spiking leaky-integrate-and-fire neurons placed in a modular architecture akin to that observed in cortical columns. The following equations describe the membrane dynamics for each model neuron i:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">C</mml:mi></mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">L</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow> <mml:mo/><mml:msub><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow> <mml:mo/><mml:msub><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow> <mml:mo/><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac> <mml:mo/><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here, subscripts L, E, and I refer to leak, excitatory, and inhibitory, respectively. g refers to the corresponding conductance, and E to the corresponding reversal potentials. <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">v</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">s</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are the membrane potential and synaptic activation, respectively, of neuron i. <inline-formula><mml:math id="inf8"><mml:mi mathvariant="normal">σ</mml:mi></mml:math></inline-formula> is a random noise term. Once the membrane potential reaches a threshold <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the neuron spikes and enters a refractory period <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Each spike (at time <inline-formula><mml:math id="inf11"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>) updates the synaptic activation <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> by an amount <inline-formula><mml:math id="inf13"><mml:mi mathvariant="normal">ρ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, and in the absence of spikes, synaptic activation decays exponentially. Conductance <inline-formula><mml:math id="inf14"><mml:mi>g</mml:mi></mml:math></inline-formula> is the product of the synaptic weight matrix with the synaptic activation, summed over all presynaptic neurons:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf15"><mml:mi mathvariant="normal">α</mml:mi></mml:math></inline-formula> can be either <inline-formula><mml:math id="inf16"><mml:mi>E</mml:mi></mml:math></inline-formula> (excitatory) or <inline-formula><mml:math id="inf17"><mml:mi>I</mml:mi></mml:math></inline-formula> (inhibitory), and <inline-formula><mml:math id="inf18"><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">α</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the connection strengths from neuron <italic>j</italic> to neuron <italic>i</italic>. A firing rate estimate for each neuron <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is calculated by an exponential filter of the spikes at times <inline-formula><mml:math id="inf20"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, with a time constant <inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub> <mml:mo/><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Our excitatory time constant is notably long (80 ms), but this is not strictly required for our model. This is shown in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>, in which we set the excitatory time constant to 20 ms and demonstrate successful learning of a sequence with elements 500 ms long each. However, the ability of the Timers to learn long times via their recurrent connections (without prohibitively small learning rates) depends on such large time constants, which are common in working memory literature (<xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>; <xref ref-type="bibr" rid="bib37">Lisman et al., 1998</xref>; <xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>). <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2b</xref> shows that the Timer cells reach bistability when trying to learn 1000 ms with a 20 ms time constant, causing failure in learning. The relationship between reported time, recurrent weights, and time constants in Timer-like cells is analyzed in detail in previous work (<xref ref-type="bibr" rid="bib20">Gavornik et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>; <xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>). Although there is some evidence for a slow time constant in preforntal cortex (PFC) (<xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>), this might not be so in sensory cortex. There are alternative ways to acquire a slow time constant that can facilitate learning of long interval times, such as derivative feedback (<xref ref-type="bibr" rid="bib36">Lim and Goldman, 2013</xref>) or active intrinsic conductance (<xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>; <xref ref-type="bibr" rid="bib18">Fransén et al., 2006</xref>).</p><p>For the rate-based version of these dynamics (used in the three-stage network model), each population of spiking neurons is represented by a single rate-based unit, which is governed by the following equations:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the characteristic time constant and <inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the resulting firing rate for neuron <italic>i</italic>. <inline-formula><mml:math id="inf24"><mml:mi mathvariant="normal">ξ</mml:mi></mml:math></inline-formula> is a piecewise non-linear transfer function used in previous sequential activation models (<xref ref-type="bibr" rid="bib5">Brunel, 2003</xref>): <disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ξ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mi>u</mml:mi><mml:mo>≤</mml:mo><mml:mi>θ</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>v</mml:mi><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mi>θ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>u</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>2</mml:mn><mml:mi>v</mml:mi><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfrac><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mfrac><mml:mn>3</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:msqrt><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>u</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the critical activity level, <inline-formula><mml:math id="inf26"><mml:mi>θ</mml:mi></mml:math></inline-formula> is a lower threshold, and <inline-formula><mml:math id="inf27"><mml:mi>v</mml:mi></mml:math></inline-formula> a scaling parameter.</p></sec><sec id="s4-3"><title>TTL rule</title><p>In place of a pair-based spike timing-dependent rule or rate-based Hebbian rule, which fails to solve the temporal credit assignment problem, the network learns based on ‘eligibility traces’ for both LTP and LTD (<xref ref-type="bibr" rid="bib28">Huertas et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Frémaux and Gerstner, 2015</xref>). These eligibility traces are synapse-specific markers that are activated via a Hebbian coincidence of activity between the pre- and postsynaptic cells. At a maximally allowed activation level, these traces saturate, and in the absence of Hebbian activity, these traces decay. LTP and LTD traces are distinct in that they activate, decay, and saturate at different rates/levels. These dynamics are described in the following equations:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The superscripts <inline-formula><mml:math id="inf28"><mml:mi mathvariant="normal">p</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf29"><mml:mi mathvariant="normal">d</mml:mi></mml:math></inline-formula> indicate LTP or LTD synaptic eligibility traces, respectively. Here, <inline-formula><mml:math id="inf30"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> (where <inline-formula><mml:math id="inf31"><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>) is the eligibility trace located at the synapse between the <inline-formula><mml:math id="inf32"><mml:mi mathvariant="normal">j</mml:mi></mml:math></inline-formula>th presynaptic cell and the <inline-formula><mml:math id="inf33"><mml:mi mathvariant="normal">i</mml:mi></mml:math></inline-formula>th postsynaptic cell. The Hebbian activity, <inline-formula><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, is a simple multiplication <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in this rule, where <inline-formula><mml:math id="inf36"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf37"><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the time averaged firing rates at the pre- and postsynaptic cells. Here, we use a simple case where <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for LTP and LTD are identical, this is the simplest option and it is sufficient here, but experimentally the Hebbian terms are more complex and are different for LTP and LTD traces (<xref ref-type="bibr" rid="bib26">He et al., 2015</xref>). Our Hebbian term is also subject to rate thresholds <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in the recurrent and feed-forward cases, which we further discuss at the end of this section.. The parameter <inline-formula><mml:math id="inf41"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> refers to the saturation level, <inline-formula><mml:math id="inf42"><mml:msup><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> to the characteristic decay time constant of the trace, and <inline-formula><mml:math id="inf43"><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mtext>a</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> to the Hebbian activation constant. If we assume steady-state activity such that <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">H</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&gt;</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is constant (a first-order approximation), we can derive effective saturation levels and effective time constants <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, which vary as a function of the Hebbian term:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>⟨</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf47"><mml:mfenced open="⟨" close="⟩" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> is the mean of Hebbian activity during trace saturation, in cases of prolonged and steady pre- and postsynaptic activation (<xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>). For increasing <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>asymptotically approaches <inline-formula><mml:math id="inf50"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>. In our model this ratio is large for appreciable <inline-formula><mml:math id="inf51"><mml:mfenced open="⟨" close="⟩" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, so practically speaking the traces saturate very close to <inline-formula><mml:math id="inf52"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). <xref ref-type="disp-formula" rid="equ8 equ9">Equations 8 and 9</xref>, using parameters as in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, create traces with a fast, quickly saturating rising phase in the presence of constant activity, and a long, slow falling phase in the absence of activity. The trace dynamics in the rising and falling phases can be approximated using these effective terms to have the simple exponential forms:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf53"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the trace dynamics in the falling phase and <inline-formula><mml:math id="inf54"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> represents the trace dynamics in the rising phase.</p><p>In this rule, synaptic weights are updated upon presentation of a global neuromodulatory signal <inline-formula><mml:math id="inf55"><mml:mi mathvariant="normal">R</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. In general, this signal can be either a traditional reward signal or a ‘novelty’ signal that accompanies the beginning or end of an external stimulus. This neuromodulatory signal then converts eligibility traces into synaptic efficacies, consuming them in the process, via a simple subtraction of the LTD trace from the LTP trace:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the synaptic efficacy between pre- and postsynaptic cells <inline-formula><mml:math id="inf57"><mml:mi mathvariant="normal">j</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf58"><mml:mi mathvariant="normal">i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf59"><mml:mi mathvariant="normal">R</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the neuromodulatory signal, and <inline-formula><mml:math id="inf60"><mml:mi mathvariant="normal">η</mml:mi></mml:math></inline-formula> is the learning rate. Following presentation of the neuromodulatory signal, the eligibility traces are ‘consumed’ and reset to zero, and their activation is set into a short refractory period (25 ms). Synaptic efficacies reach a steady state under the following condition:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> d</mml:mtext><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mn>0</mml:mn><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf61"><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the time at the end of the trial. In our model, each time a stimulus (whether a novel or familiar) starts or ends, a global novelty neuromodulator is released, and this acts as the ‘reward’ in the learning rule. As a result, synaptic efficacies update every time a stimulus is changed, according to the learning rule in <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>, until they reach the fixed point of <xref ref-type="disp-formula" rid="equ15">Equation 15</xref>. Under the simplifying assumption that the reward function <inline-formula><mml:math id="inf62"><mml:mi mathvariant="normal">R</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is a delta function <inline-formula><mml:math id="inf63"><mml:mi mathvariant="normal">δ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>, this fixed point becomes:<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In our model there are two classes of synaptic plasticity, plasticity of recurrent connections to learn duration, and of feed-forward connections between modules to learn order. When feed-forward projections or external input activate a group of neurons, they cause an increase in the firing rates of those neurons, this we call the rising phase. Once input ceases, the activity in these neurons starts decaying, this decaying activity is the falling phase, and its dynamics are determined by recurrent connections. Synaptic eligibility traces follow the activity profiles, they rise or saturate during the rising phase, and decay during the falling phase. Since the traces saturate, the information relating to the feed-forward activity is contained exclusively in the rising phase of the traces, and during the falling phase, such information has been lost due to saturation. On the other hand, the information relating to the recurrent activity is contained in the falling phase, precisely because the input has ceased and the feed-forward information has been lost via saturation, so all that remains is the recurrent information. As such, learning the appropriate order via feed-forward connections needs to happen during the rising phase, and learning appropriate decay times via recurrent connections needs to happen during the falling phase. The differing activation, decay, and saturation rates/levels of the LTP and LTD traces have been chosen such that a fixed point can be reached either during the rising phase or falling phase of the traces (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>).</p><p>We show the fixed points obtained in simulations of sequence learning in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> and demonstrate how learning occurs in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>. To gain intuition of when these fixed points are obtained and how they depend on the learning parameters, we make several simplifying approximations. To solve for the falling phase fixed point, we first assume that the traces are saturated when the underlying Hebbian activity is above a certain threshold, <inline-formula><mml:math id="inf64"><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. We call the time when Hebbian activity crosses below that threshold <inline-formula><mml:math id="inf65"><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Then, combining <xref ref-type="disp-formula" rid="equ12 equ16">Equations 12 and 16</xref> (substituting <inline-formula><mml:math id="inf66"><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in for <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf68"><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in for <inline-formula><mml:math id="inf69"><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), we can solve for <inline-formula><mml:math id="inf70"><mml:mi mathvariant="normal">D</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at the fixed point:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The objective of learning, then, is to move <inline-formula><mml:math id="inf71"><mml:mi mathvariant="normal">D</mml:mi></mml:math></inline-formula> from its starting value to the value in <xref ref-type="disp-formula" rid="equ17">Equation 17</xref>, which is determined by the parameters in the network. The parameters can be chosen such that the fixed-point value of <inline-formula><mml:math id="inf72"><mml:mi mathvariant="normal">D</mml:mi></mml:math></inline-formula> is arbitrarily small. As shown in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, this recaptures the behavior of the Timer cells.</p><p>The rising phase fixed point can be determined by combining <xref ref-type="disp-formula" rid="equ13 equ16">Equations 13 and 16</xref> to give us an implicit function of <inline-formula><mml:math id="inf73"><mml:mi mathvariant="normal">H</mml:mi></mml:math></inline-formula>:<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">T</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>τ</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> both depend on <inline-formula><mml:math id="inf76"><mml:mi mathvariant="normal">H</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ8 equ9">Equations 8 and 9</xref>), given <inline-formula><mml:math id="inf77"><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf78"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf79"><mml:msup><mml:mrow><mml:mi mathvariant="normal">τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf80"><mml:mi mathvariant="normal">H</mml:mi></mml:math></inline-formula> at the time of reward is uniquely determined by this fixed point. Practically, this means feed-forward learning increases synaptic efficacies <inline-formula><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in order to increase postsynaptic firing <inline-formula><mml:math id="inf82"><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, until <inline-formula><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = <inline-formula><mml:math id="inf84"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> = a fixed value at t = <inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, as determined by <xref ref-type="disp-formula" rid="equ18">Equation 18</xref> (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). Qualitatively, successful feed-forward learning in our model uses traces with dominant LTP in the rising phase (<inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mtext>p</mml:mtext></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mtext>d</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) and dominant LTD in the falling phase (<inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) ( see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>).</p><p>Through these learning dynamics, the Timer cells learn to represent the duration of their particular element in the sequence (by decreasing <inline-formula><mml:math id="inf88"><mml:mi mathvariant="normal">D</mml:mi></mml:math></inline-formula> to its fixed-point value), while Messengers learn to feed forward to the Timer cells in the next stimulated column (by increasing <inline-formula><mml:math id="inf89"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> until <inline-formula><mml:math id="inf90"><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> reaches its fixed-point value). Note that for modules that do not have overlapping activation, the Hebbian term <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is zero, and therefore the associated weights <inline-formula><mml:math id="inf92"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> do not change. However, in the presence of noise, modules can have spurious activity overlaps which cause non-zero <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and therefore potentiation of weights <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> which are non-sequential. This can lead to network instability and a failure to encode the presented sequence. To account for this, rate thresholds <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are included in the Hebbian term <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. By setting these thresholds above the effective noise level (see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>), the Hebbian overlap <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> used to activate traces ignores the random, noise-driven overlaps. Crucially, as <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:msub><mml:mi/><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> dictates the sensitivity to inter-columnar overlaps, it is a critical and necessary parameter to enable the all-to-all connectivity of the model. <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c</xref> shows these weights approaching their fixed-point values over the course of learning. Earlier work derives these equations in more detail (<xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>).</p><p>The parameters chosen for the traces are displayed in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. For the recurrent traces, the parameters follow the restrictions derived from analysis in an earlier publication (<xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>). The corresponding analysis for the feed-forward traces, however, is not necessarily applicable in the context of sequence learning, since multiple neuromodulator signals are active during each learning epoch. As a result, the parameters for the feed-forward traces are empirically derived. Multiple different sets were found to work, but the set in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> was the one used for all simulations included in this paper. <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> shows that the mean reported times are robust to random perturbations (ranging from +/– 20%) of the learning parameters. The perturbations are added via independently drawing each parameter randomly from a uniform distribution with bounds of 80–120% of each parameter’s initial value. Note that the standard deviation increases, as expected, but is of the same order of magnitude. One hundred different random sets are used, and the resulting learned times compare favorably to trials with no parameter randomization.</p><p>The above eligibility trace learning rules are referred to as TTL. As described in a previous publication (<xref ref-type="bibr" rid="bib29">Huertas et al., 2016</xref>), and demonstrated throughout this work, TTL allows for both feed-forward and recurrent learning, and as such can robustly encode temporally dependent input patterns. TTL is supported by recent experiments which have found evidence for eligibility traces existing in cortex (<xref ref-type="bibr" rid="bib26">He et al., 2015</xref>), striatum (<xref ref-type="bibr" rid="bib64">Yagishita et al., 2014</xref>), and hippocampus (<xref ref-type="bibr" rid="bib4">Bittner et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Brzosko et al., 2017</xref>). Other eligibility trace rules, such as the one-trace rule demonstrated in earlier work (<xref ref-type="bibr" rid="bib20">Gavornik et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Gavornik and Shouval, 2011</xref>), can also replicate the results of this paper. In general, any rule which can associate distal events/rewards, thereby solving the temporal credit assignment problem, would be likely to work with this network model. TTL was chosen for its biological realism, but the novel capabilities of this model (its ability to learn and recall both the duration and order of elements in a sequence) primarily result from the network architecture, combined with a history-dependent learning rule.</p></sec><sec id="s4-4"><title>Non-Markovian network dynamics</title><p>The three-stage network used to learn and recall non-Markovian sequences comprises the main columnar network, a highly recurrent network (reservoir), and a sparse pattern net. The dynamics of the rate-based columnar network are described above. The dynamics of the units <inline-formula><mml:math id="inf100"><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the reservoir are described by the equation:<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf101"><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the firing rates of the units in the reservoir and <inline-formula><mml:math id="inf102"><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the firing rates of the Messenger cells in the main network. <inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub> <mml:mi/></mml:math></inline-formula> is a K × n binary matrix of projections from the columnar network to the reservoir, where K is the number of units in the reservoir and n is the number of columns in the network. <inline-formula><mml:math id="inf104"><mml:msub><mml:mrow><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is structured such that the first K/n units in the reservoir receive direct input from the Messengers in the first column, the second K/n units receive direct input from the Messengers in the second column, and so on. <inline-formula><mml:math id="inf105"><mml:msub><mml:mrow><mml:mi mathvariant="normal">W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the recurrent weights of the reservoir, each of which is drawn from a normal distribution <inline-formula><mml:math id="inf106"><mml:mi mathvariant="normal">N</mml:mi><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mi>K</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:math></inline-formula>, where g is the ‘gain’ of the network (<xref ref-type="bibr" rid="bib51">Rajan et al., 2010</xref>).</p><p><inline-formula><mml:math id="inf107"><mml:mi mathvariant="normal">ψ</mml:mi></mml:math></inline-formula> is a piecewise linear activation function:<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mi>x</mml:mi><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>x</mml:mi><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>so <inline-formula><mml:math id="inf108"><mml:msub><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the firing threshold. <inline-formula><mml:math id="inf109"><mml:mi mathvariant="normal">ϕ</mml:mi></mml:math></inline-formula> is a sigmoidal activation function:<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mi mathvariant="normal">ϕ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">tanh</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow> <mml:mi/> <mml:mi/> <mml:mi/> <mml:mi/> <mml:mi/><mml:mo>(</mml:mo><mml:mn>21</mml:mn><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>The reservoir projects to a high-dimensional sparse pattern network. Each unit in the sparse pattern net receives input from the reservoir, fed through a sparse matrix <inline-formula><mml:math id="inf110"><mml:msub><mml:mrow><mml:mi mathvariant="normal">O</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, with fraction <inline-formula><mml:math id="inf111"><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mn>04</mml:mn></mml:math></inline-formula> of entries non-zero and drawn from a normal distribution <inline-formula><mml:math id="inf112"><mml:mi mathvariant="normal">N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <italic>M</italic> is the number of units in the sparse pattern net and g is the gain, as described above. The activation of each unit <inline-formula><mml:math id="inf113"><mml:msub><mml:mrow><mml:mi mathvariant="normal">ν</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of the sparse network is determined by the following:<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="normal">O</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">u</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf114"><mml:mi mathvariant="normal">Θ</mml:mi></mml:math></inline-formula> is the Heaviside function. The sparse pattern network is binary in our implementation but this is not essential, as long as its non-linear and sparse. The sparse network feeds back into the main network via weights <inline-formula><mml:math id="inf115"><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, which are learned via a simple Hebbian rule:<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>with the additional restriction <inline-formula><mml:math id="inf116"><mml:msub><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo> <mml:mi mathvariant="normal"/><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">Q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Here, <inline-formula><mml:math id="inf117"><mml:mi>j</mml:mi></mml:math></inline-formula> indexes units in the main network and <inline-formula><mml:math id="inf118"><mml:mi>m</mml:mi></mml:math></inline-formula> indexes units in the sparse pattern net.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We would like to acknowledge conversations with Marshall Hussain Shuler and Nicolas Brunel.</p> </ack><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Investigation, Writing - original draft</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Table of main model parameters.</title><p>For full code, see <ext-link ext-link-type="uri" xlink:href="http://modeldb.yale">http://modeldb.yale</ext-link>.</p></caption><media xlink:href="elife-63751-supp1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Table of reservoir, sparse net, and rate-based model parameters.</title></caption><media xlink:href="elife-63751-supp2-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-63751-transrepform-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All software used for simulations will be available on ModelDb. <ext-link ext-link-type="uri" xlink:href="http://modeldb.yale.edu/266774">http://modeldb.yale.edu/266774</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Cone</surname><given-names>I</given-names></name><name><surname>Shouval</surname><given-names>HZ</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Markovian and non-Markovian learning via biophysically realistic learning rules</data-title><source>ModelDb</source><pub-id assigning-authority="other" pub-id-type="accession" xlink:href="http://modeldb.yale.edu/266774">266774</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Abeles</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1991">1991</year><source>Corticonics: Neural Circuits of the Cerebral Cortex</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Billings</surname> <given-names>G</given-names></name><name><surname>Piasini</surname> <given-names>E</given-names></name><name><surname>Lőrincz</surname> <given-names>A</given-names></name><name><surname>Nusser</surname> <given-names>Z</given-names></name><name><surname>Silver</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Network structure within the cerebellar input layer enables lossless sparse encoding</article-title><source>Neuron</source><volume>83</volume><fpage>960</fpage><lpage>974</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.07.020</pub-id><pub-id pub-id-type="pmid">25123311</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binzegger</surname> <given-names>T</given-names></name><name><surname>Douglas</surname> <given-names>RJ</given-names></name><name><surname>Martin</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Topology and dynamics of the canonical circuit of cat V1</article-title><source>Neural Networks</source><volume>22</volume><fpage>1071</fpage><lpage>1078</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2009.07.011</pub-id><pub-id pub-id-type="pmid">19632814</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname> <given-names>KC</given-names></name><name><surname>Milstein</surname> <given-names>AD</given-names></name><name><surname>Grienberger</surname> <given-names>C</given-names></name><name><surname>Romani</surname> <given-names>S</given-names></name><name><surname>Magee</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Behavioral time scale synaptic plasticity underlies CA1 place fields</article-title><source>Science</source><volume>357</volume><fpage>1033</fpage><lpage>1036</lpage><pub-id pub-id-type="doi">10.1126/science.aan3846</pub-id><pub-id pub-id-type="pmid">28883072</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Dynamics and plasticity of stimulus-selective persistent activity in cortical network models</article-title><source>Cerebral Cortex</source><volume>13</volume><fpage>1151</fpage><lpage>1161</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhg096</pub-id><pub-id pub-id-type="pmid">14576207</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brzosko</surname> <given-names>Z</given-names></name><name><surname>Zannone</surname> <given-names>S</given-names></name><name><surname>Schultz</surname> <given-names>W</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Paulsen</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sequential neuromodulation of hebbian plasticity offers mechanism for effective reward-based navigation</article-title><source>eLife</source><volume>6</volume><elocation-id>e27756</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27756</pub-id><pub-id pub-id-type="pmid">28691903</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chadderton</surname> <given-names>P</given-names></name><name><surname>Margrie</surname> <given-names>TW</given-names></name><name><surname>Häusser</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Integration of quanta in cerebellar granule cells during sensory processing</article-title><source>Nature</source><volume>428</volume><fpage>856</fpage><lpage>860</lpage><pub-id pub-id-type="doi">10.1038/nature02442</pub-id><pub-id pub-id-type="pmid">15103377</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chubykin</surname> <given-names>AA</given-names></name><name><surname>Roach</surname> <given-names>EB</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name><name><surname>Shuler</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A cholinergic mechanism for reward timing within primary visual cortex</article-title><source>Neuron</source><volume>77</volume><fpage>723</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.039</pub-id><pub-id pub-id-type="pmid">23439124</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>Y</given-names></name><name><surname>Shen</surname> <given-names>J</given-names></name><name><surname>Semu</surname> <given-names>D</given-names></name><name><surname>Leman</surname> <given-names>DP</given-names></name><name><surname>Liberti</surname> <given-names>WA</given-names></name><name><surname>Perkins</surname> <given-names>LN</given-names></name><name><surname>Liberti</surname> <given-names>DC</given-names></name><name><surname>Kotton</surname> <given-names>DN</given-names></name><name><surname>Gardner</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hidden neural states underlie canary song syntax</article-title><source>Nature</source><volume>582</volume><fpage>539</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2397-3</pub-id><pub-id pub-id-type="pmid">32555461</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cooke</surname> <given-names>SF</given-names></name><name><surname>Komorowski</surname> <given-names>RW</given-names></name><name><surname>Kaplan</surname> <given-names>ES</given-names></name><name><surname>Gavornik</surname> <given-names>JP</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Visual recognition memory, manifested as long-term habituation, requires synaptic plasticity in V1</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>262</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1038/nn.3920</pub-id><pub-id pub-id-type="pmid">25599221</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dave</surname> <given-names>AS</given-names></name><name><surname>Margoliash</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Song replay during sleep and computational rules for sensorimotor vocal learning</article-title><source>Science</source><volume>290</volume><fpage>812</fpage><lpage>816</lpage><pub-id pub-id-type="doi">10.1126/science.290.5492.812</pub-id><pub-id pub-id-type="pmid">11052946</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Kloosterman</surname> <given-names>F</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hippocampal replay of extended experience</article-title><source>Neuron</source><volume>63</volume><fpage>497</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id><pub-id pub-id-type="pmid">19709631</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DePasquale</surname> <given-names>B</given-names></name><name><surname>Cueva</surname> <given-names>CJ</given-names></name><name><surname>Rajan</surname> <given-names>K</given-names></name><name><surname>Escola</surname> <given-names>GS</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Full-force: a target-based method for training recurrent networks</article-title><source>PLOS ONE</source><volume>13</volume><elocation-id>e0191527</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0191527</pub-id><pub-id pub-id-type="pmid">29415041</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eagleman</surname> <given-names>SL</given-names></name><name><surname>Dragoi</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Image sequence reactivation in awake V4 networks</article-title><source>PNAS</source><volume>109</volume><fpage>19450</fpage><lpage>19455</lpage><pub-id pub-id-type="doi">10.1073/pnas.1212059109</pub-id><pub-id pub-id-type="pmid">23129638</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenlaub</surname> <given-names>JB</given-names></name><name><surname>Jarosiewicz</surname> <given-names>B</given-names></name><name><surname>Saab</surname> <given-names>J</given-names></name><name><surname>Franco</surname> <given-names>B</given-names></name><name><surname>Kelemen</surname> <given-names>J</given-names></name><name><surname>Halgren</surname> <given-names>E</given-names></name><name><surname>Hochberg</surname> <given-names>LR</given-names></name><name><surname>Cash</surname> <given-names>SS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Replay of learned neural firing sequences during rest in human motor cortex</article-title><source>Cell Reports</source><volume>31</volume><elocation-id>107581</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.107581</pub-id><pub-id pub-id-type="pmid">32375031</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname> <given-names>IR</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name><name><surname>Wang</surname> <given-names>CZ</given-names></name><name><surname>Hahnloser</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spike-time-dependent plasticity and heterosynaptic competition organize networks to produce long scale-free sequences of neural activity</article-title><source>Neuron</source><volume>65</volume><fpage>563</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.003</pub-id><pub-id pub-id-type="pmid">20188660</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname> <given-names>DJ</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title><source>Nature</source><volume>440</volume><fpage>680</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/nature04587</pub-id><pub-id pub-id-type="pmid">16474382</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fransén</surname> <given-names>E</given-names></name><name><surname>Tahvildari</surname> <given-names>B</given-names></name><name><surname>Egorov</surname> <given-names>AV</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Alonso</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Mechanism of graded persistent cellular activity of entorhinal cortex layer v neurons</article-title><source>Neuron</source><volume>49</volume><fpage>735</fpage><lpage>746</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.01.036</pub-id><pub-id pub-id-type="pmid">16504948</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frémaux</surname> <given-names>N</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuromodulated Spike-Timing-Dependent plasticity, and theory of Three-Factor learning rules</article-title><source>Frontiers in Neural Circuits</source><volume>9</volume><elocation-id>85</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2015.00085</pub-id><pub-id pub-id-type="pmid">26834568</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gavornik</surname> <given-names>JP</given-names></name><name><surname>Shuler</surname> <given-names>MG</given-names></name><name><surname>Loewenstein</surname> <given-names>Y</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name><name><surname>Shouval</surname> <given-names>HZ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Learning reward timing in cortex through reward dependent expression of synaptic plasticity</article-title><source>PNAS</source><volume>106</volume><fpage>6826</fpage><lpage>6831</lpage><pub-id pub-id-type="doi">10.1073/pnas.0901835106</pub-id><pub-id pub-id-type="pmid">19346478</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gavornik</surname> <given-names>JP</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learned spatiotemporal sequence recognition and prediction in primary visual cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>732</fpage><lpage>737</lpage><pub-id pub-id-type="doi">10.1038/nn.3683</pub-id><pub-id pub-id-type="pmid">24657967</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gavornik</surname> <given-names>JP</given-names></name><name><surname>Shouval</surname> <given-names>HZ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A network of spiking neurons that can represent interval timing: mean field analysis</article-title><source>Journal of Computational Neuroscience</source><volume>30</volume><fpage>501</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1007/s10827-010-0275-y</pub-id><pub-id pub-id-type="pmid">20830512</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gillespie</surname> <given-names>DT</given-names></name></person-group><year iso-8601-date="1991">1991</year><source>Markov Processes: An Introduction for Physical Scientists</source><publisher-name>Elsevier</publisher-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hangya</surname> <given-names>B</given-names></name><name><surname>Ranade</surname> <given-names>SP</given-names></name><name><surname>Lorenc</surname> <given-names>M</given-names></name><name><surname>Kepecs</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Central cholinergic neurons are rapidly recruited by reinforcement feedback</article-title><source>Cell</source><volume>162</volume><fpage>1155</fpage><lpage>1168</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.07.057</pub-id><pub-id pub-id-type="pmid">26317475</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname> <given-names>J</given-names></name><name><surname>Ahmad</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons have thousands of synapses, a theory of sequence memory in neocortex</article-title><source>Frontiers in Neural Circuits</source><volume>10</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2016.00023</pub-id><pub-id pub-id-type="pmid">27065813</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname> <given-names>K</given-names></name><name><surname>Huertas</surname> <given-names>M</given-names></name><name><surname>Hong</surname> <given-names>SZ</given-names></name><name><surname>Tie</surname> <given-names>X</given-names></name><name><surname>Hell</surname> <given-names>JW</given-names></name><name><surname>Shouval</surname> <given-names>H</given-names></name><name><surname>Kirkwood</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct eligibility traces for LTP and LTD in cortical synapses</article-title><source>Neuron</source><volume>88</volume><fpage>528</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.037</pub-id><pub-id pub-id-type="pmid">26593091</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howe</surname> <given-names>MW</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rapid signalling in distinct dopaminergic axons during locomotion and reward</article-title><source>Nature</source><volume>535</volume><fpage>505</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1038/nature18942</pub-id><pub-id pub-id-type="pmid">27398617</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huertas</surname> <given-names>MA</given-names></name><name><surname>Hussain Shuler</surname> <given-names>MG</given-names></name><name><surname>Shouval</surname> <given-names>HZ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A simple network architecture accounts for diverse reward time responses in primary visual cortex</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>12659</fpage><lpage>12672</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0871-15.2015</pub-id><pub-id pub-id-type="pmid">26377457</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huertas</surname> <given-names>MA</given-names></name><name><surname>Schwettmann</surname> <given-names>SE</given-names></name><name><surname>Shouval</surname> <given-names>HZ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The role of multiple neuromodulators in reinforcement learning that is based on competition between eligibility traces</article-title><source>Frontiers in Synaptic Neuroscience</source><volume>8</volume><elocation-id>37</elocation-id><pub-id pub-id-type="doi">10.3389/fnsyn.2016.00037</pub-id><pub-id pub-id-type="pmid">28018206</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname> <given-names>D</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Coordinated memory replay in the visual cortex and Hippocampus during sleep</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>100</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1038/nn1825</pub-id><pub-id pub-id-type="pmid">17173043</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname> <given-names>JK</given-names></name><name><surname>Jin</surname> <given-names>DZ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Development of neural circuitry for precise temporal sequences through spontaneous activity, axon remodeling, and synaptic plasticity</article-title><source>PLOS ONE</source><volume>2</volume><elocation-id>e723</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0000723</pub-id><pub-id pub-id-type="pmid">17684568</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klos</surname> <given-names>C</given-names></name><name><surname>Miner</surname> <given-names>D</given-names></name><name><surname>Triesch</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Bridging structure and function: a model of sequence learning and prediction in primary visual cortex</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006187</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006187</pub-id><pub-id pub-id-type="pmid">29870532</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laje</surname> <given-names>R</given-names></name><name><surname>Buonomano</surname> <given-names>DV</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Robust timing and motor patterns by taming Chaos in recurrent neural networks</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>925</fpage><lpage>933</lpage><pub-id pub-id-type="doi">10.1038/nn.3405</pub-id><pub-id pub-id-type="pmid">23708144</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leutgeb</surname> <given-names>JK</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Pattern separation in the dentate gyrus and CA3 of the Hippocampus</article-title><source>Science</source><volume>315</volume><fpage>961</fpage><lpage>966</lpage><pub-id pub-id-type="doi">10.1126/science.1135801</pub-id><pub-id pub-id-type="pmid">17303747</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname> <given-names>TP</given-names></name><name><surname>Cownden</surname> <given-names>D</given-names></name><name><surname>Tweed</surname> <given-names>DB</given-names></name><name><surname>Akerman</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Random synaptic feedback weights support error backpropagation for deep learning</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13276</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13276</pub-id><pub-id pub-id-type="pmid">27824044</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname> <given-names>S</given-names></name><name><surname>Goldman</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Balanced cortical microcircuitry for maintaining information in working memory</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1306</fpage><lpage>1314</lpage><pub-id pub-id-type="doi">10.1038/nn.3492</pub-id><pub-id pub-id-type="pmid">23955560</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname> <given-names>JE</given-names></name><name><surname>Fellous</surname> <given-names>JM</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A role for NMDA-receptor channels in working memory</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>273</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1038/1086</pub-id><pub-id pub-id-type="pmid">10195158</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>CH</given-names></name><name><surname>Coleman</surname> <given-names>JE</given-names></name><name><surname>Davoudi</surname> <given-names>H</given-names></name><name><surname>Zhang</surname> <given-names>K</given-names></name><name><surname>Hussain Shuler</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Selective activation of a putative reinforcement signal conditions cued interval timing in primary visual cortex</article-title><source>Current Biology</source><volume>25</volume><fpage>1551</fpage><lpage>1561</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.04.028</pub-id><pub-id pub-id-type="pmid">26004763</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>JK</given-names></name><name><surname>Buonomano</surname> <given-names>DV</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Embedding multiple trajectories in simulated recurrent neural networks in a self-organizing manner</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>13172</fpage><lpage>13181</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2358-09.2009</pub-id><pub-id pub-id-type="pmid">19846705</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Louie</surname> <given-names>K</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporally structured replay of awake hippocampal ensemble activity during rapid eye movement sleep</article-title><source>Neuron</source><volume>29</volume><fpage>145</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00186-6</pub-id><pub-id pub-id-type="pmid">11182087</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname> <given-names>W</given-names></name><name><surname>Natschläger</surname> <given-names>T</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Real-time computing without stable states: a new framework for neural computation based on perturbations</article-title><source>Neural Computation</source><volume>14</volume><fpage>2531</fpage><lpage>2560</lpage><pub-id pub-id-type="doi">10.1162/089976602760407955</pub-id><pub-id pub-id-type="pmid">12433288</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname> <given-names>W</given-names></name><name><surname>Natschläger</surname> <given-names>T</given-names></name><name><surname>Markram</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Fading memory and kernel properties of generic cortical microcircuit models</article-title><source>Journal of Physiology-Paris</source><volume>98</volume><fpage>315</fpage><lpage>330</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2005.09.020</pub-id><pub-id pub-id-type="pmid">16310350</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maes</surname> <given-names>A</given-names></name><name><surname>Barahona</surname> <given-names>M</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning spatiotemporal signals using a recurrent spiking network that discretizes time</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007606</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007606</pub-id><pub-id pub-id-type="pmid">31961853</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinez</surname> <given-names>RH</given-names></name><name><surname>Lansner</surname> <given-names>A</given-names></name><name><surname>Herman</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Probabilistic associative learning suffices for learning the temporal structure of multiple sequences</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0220161</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0220161</pub-id><pub-id pub-id-type="pmid">31369571</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastronarde</surname> <given-names>DN</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Two classes of single-input X-cells in cat lateral geniculate nucleus. II. retinal inputs and the generation of receptive-field properties</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>381</fpage><lpage>413</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.57.2.381</pub-id><pub-id pub-id-type="pmid">3559685</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Local online learning in recurrent networks with random feedback</article-title><source>eLife</source><volume>8</volume><elocation-id>e43299</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.43299</pub-id><pub-id pub-id-type="pmid">31124785</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>JM</given-names></name><name><surname>Escola</surname> <given-names>GS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Learning multiple variable-speed sequences in striatum via cortical tutoring</article-title><source>eLife</source><volume>6</volume><elocation-id>e26084</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.26084</pub-id><pub-id pub-id-type="pmid">28481200</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicola</surname> <given-names>W</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Supervised learning in spiking neural networks with FORCE training</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>2208</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-01827-3</pub-id><pub-id pub-id-type="pmid">29263361</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname> <given-names>U</given-names></name><name><surname>Brunel</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Unsupervised learning of persistent and sequential activity</article-title><source>Frontiers in Computational Neuroscience</source><volume>13</volume><elocation-id>97</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2019.00097</pub-id><pub-id pub-id-type="pmid">32009924</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Potjans</surname> <given-names>TC</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The cell-type specific cortical microcircuit: relating structure and activity in a full-scale spiking network model</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>785</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs358</pub-id><pub-id pub-id-type="pmid">23203991</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajan</surname> <given-names>K</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus-dependent suppression of Chaos in recurrent neural networks</article-title><source>Physical Review E</source><volume>82</volume><elocation-id>011903</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.82.011903</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajan</surname> <given-names>K</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Recurrent network models of sequence generation and memory</article-title><source>Neuron</source><volume>90</volume><fpage>128</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.02.009</pub-id><pub-id pub-id-type="pmid">26971945</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruksenas</surname> <given-names>O</given-names></name><name><surname>Bulatov</surname> <given-names>A</given-names></name><name><surname>Heggelund</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dynamics of spatial resolution of single units in the lateral geniculate nucleus of cat during brief visual stimulation</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>1445</fpage><lpage>1456</lpage><pub-id pub-id-type="doi">10.1152/jn.01338.2005</pub-id><pub-id pub-id-type="pmid">16914606</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shuler</surname> <given-names>MG</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reward timing in the primary visual cortex</article-title><source>Science</source><volume>311</volume><fpage>1606</fpage><lpage>1609</lpage><pub-id pub-id-type="doi">10.1126/science.1123513</pub-id><pub-id pub-id-type="pmid">16543459</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname> <given-names>WE</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Replay of neuronal firing sequences in rat Hippocampus during sleep following spatial experience</article-title><source>Science</source><volume>271</volume><fpage>1870</fpage><lpage>1873</lpage><pub-id pub-id-type="doi">10.1126/science.271.5257.1870</pub-id><pub-id pub-id-type="pmid">8596957</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname> <given-names>D</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Generating coherent patterns of activity from chaotic neural networks</article-title><source>Neuron</source><volume>63</volume><fpage>544</fpage><lpage>557</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.018</pub-id><pub-id pub-id-type="pmid">19709635</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tully</surname> <given-names>PJ</given-names></name><name><surname>Lindén</surname> <given-names>H</given-names></name><name><surname>Hennig</surname> <given-names>MH</given-names></name><name><surname>Lansner</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spike-Based Bayesian-Hebbian learning of temporal sequences</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004954</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004954</pub-id><pub-id pub-id-type="pmid">27213810</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Dijk</surname> <given-names>MT</given-names></name><name><surname>Fenton</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On how the dentate gyrus contributes to memory discrimination</article-title><source>Neuron</source><volume>98</volume><fpage>832</fpage><lpage>845</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.04.018</pub-id><pub-id pub-id-type="pmid">29731252</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Veliz-Cuba</surname> <given-names>A</given-names></name><name><surname>Shouval</surname> <given-names>HZ</given-names></name><name><surname>Josić</surname> <given-names>K</given-names></name><name><surname>Kilpatrick</surname> <given-names>ZP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Networks that learn the precise timing of event sequences</article-title><source>Journal of Computational Neuroscience</source><volume>39</volume><fpage>235</fpage><lpage>254</lpage><pub-id pub-id-type="doi">10.1007/s10827-015-0574-4</pub-id><pub-id pub-id-type="pmid">26334992</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Synaptic reverberation underlying mnemonic persistent activity</article-title><source>Trends in Neurosciences</source><volume>24</volume><fpage>455</fpage><lpage>463</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(00)01868-3</pub-id><pub-id pub-id-type="pmid">11476885</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>M</given-names></name><name><surname>Yang</surname> <given-names>Y</given-names></name><name><surname>Wang</surname> <given-names>CJ</given-names></name><name><surname>Gamo</surname> <given-names>NJ</given-names></name><name><surname>Jin</surname> <given-names>LE</given-names></name><name><surname>Mazer</surname> <given-names>JA</given-names></name><name><surname>Morrison</surname> <given-names>JH</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name><name><surname>Arnsten</surname> <given-names>AF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>NMDA receptors subserve persistent neuronal firing during working memory in dorsolateral prefrontal cortex</article-title><source>Neuron</source><volume>77</volume><fpage>736</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.032</pub-id><pub-id pub-id-type="pmid">23439125</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname> <given-names>JCR</given-names></name><name><surname>Bogacz</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Theories of error Back-Propagation in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>235</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.12.005</pub-id><pub-id pub-id-type="pmid">30704969</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>S</given-names></name><name><surname>Jiang</surname> <given-names>W</given-names></name><name><surname>Poo</surname> <given-names>MM</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Activity recall in a visual cortical ensemble</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>449</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1038/nn.3036</pub-id><pub-id pub-id-type="pmid">22267160</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yagishita</surname> <given-names>S</given-names></name><name><surname>Hayashi-Takagi</surname> <given-names>A</given-names></name><name><surname>Ellis-Davies</surname> <given-names>GC</given-names></name><name><surname>Urakubo</surname> <given-names>H</given-names></name><name><surname>Ishii</surname> <given-names>S</given-names></name><name><surname>Kasai</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A critical time window for dopamine actions on the structural plasticity of dendritic spines</article-title><source>Science</source><volume>345</volume><fpage>1616</fpage><lpage>1620</lpage><pub-id pub-id-type="doi">10.1126/science.1255514</pub-id><pub-id pub-id-type="pmid">25258080</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname> <given-names>P</given-names></name><name><surname>Mishkin</surname> <given-names>M</given-names></name><name><surname>Sutter</surname> <given-names>M</given-names></name><name><surname>Fritz</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Early stages of melody processing: stimulus-sequence and task-dependent neuronal activity in monkey auditory cortical fields A1 and R</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>3009</fpage><lpage>3029</lpage><pub-id pub-id-type="doi">10.1152/jn.00828.2007</pub-id><pub-id pub-id-type="pmid">18842950</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63751.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution>Salk Institute for Biological Studies</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper describes how spiking neurons can learn spatio-temporal sequences with flexible duration of intermediate states. Available methods only allowed learning of sequences where duration could not be varied broadly. The proposition put forward in this work solves this long-standing problem in a convincing and in a biologically plausible way.</p><p><bold>Decision letter after peer review:</bold></p><p>[Editors’ note: the authors submitted for reconsideration following the decision after peer review. What follows is the decision letter after the first round of review.]</p><p>Thank you for submitting your work entitled &quot;Learning precise spatiotemporal sequences via biophysically realistic learning rules in a modular, spiking network&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by a Senior Editor, a Reviewing Editor, and two reviewers. The reviewers have opted to remain anonymous.</p><p>Our decision has been reached after consultation between the reviewers. The consensus was that the manuscript raises an interesting problem and provides an interesting but partial solution to it. The reviewers described many analyses that needed to be completed prior to publication. The reviewers thought that once all of that work was completed, the manuscript would be so substantially different that it would qualify as a new submission. Therefore, the consensus decision at this stage is not to consider further this manuscript for publication in <italic>eLife</italic>.</p><p><italic>Reviewer #1:</italic></p><p>In this study authors note that many models of sequential activity in the brain only account for the order in which neurons spike and fail to take into account the duration for which each neuron responds. This is indeed an interesting problem. Authors provide a network architecture that can solve part of the problem.</p><p>They assume that a neural activity sequence is consisted of many events. Neuron groups are tuned to these events and spike in order as these events occur. Each neuron group (Core Neural Architecture or CNA) consists of Timer, Messenger (both excitatory) and inhibitory neurons subgroups. The recurrent connections within Timer neurons encode the duration. The Messenger neurons project to the next CNA and encode the order.</p><p>An important part of the circuit is the inhibitory neurons which stop firing before the timer neurons (even though they are driven by timer neurons) and thereby release the Messenger neurons from inhibition at the end of the duration of the event. Thus, messenger neurons firing maximizes and signals the end of the “duration”.</p><p>Authors then expand the network to have a “reservoir” network and show that their scheme can also generate non-markovian sequences in which a particular neuron group is activated multiple times in the sequence.</p><p>I think the authors have raised an interesting problem and provide a solution that at least partly solves the problem. However, there are a number of shortcomings of the work which reduce the significance of the work.</p><p>1) Here authors are assuming sequences of distinct events. But to facilitate learning it is crucial that the animal is rewarded after each event. I am not convinced that every component of a sequential behavior is rewarded.</p><p>2) The key to indicate the end of duration of a sequence component, is that the inhibitory neurons stop firing before the Timer neurons. Why should this be? Since inhibitory neurons are driven by time neurons and that typically inhibitory neurons have low spike threshold one would expect the inhibitory neurons to remain active as long as Timer neurons are active. This must require fine tuning of the circuit which is beyond synaptic changes. This particular component of the model makes it appear contrived. Authors have not provided biological motivation or evidence of robustness of the mechanism. Authors finally predict that &quot;There will be a population of inhibitory cells within each module that have firing properties similar to Timers but that decay more quickly (Figure 2A).&quot; But is this enough? There will also be other inhibitory neuron type which will not have this exact dynamics -- will that be a problem?</p><p>3) While it is possible to have non-Markovian sequences but still each Timer can show only a single duration. Authors only make passing remark on how this could be amended but the solution is very ad-hoc and very likely will not scale.</p><p>4) The main motivation of the work is to come up with a biologically plausible model of sequence (order and durations). But the addition of reservoir and a sparse readout makes it non-biological. Moreover, authors have not specified the properties of the reservoir, specifically how does it keeps the memory of sequence of different messengers. And if the long-term memory of the messenger sequence is already in the reservoir, then why the sparse-net readout stage is needed.</p><p>5) The whole work is presented as demonstrations of key results, there is no systematic analysis of robustness of the results. I disagree that it is beyond the scope of the current work - I think that is exactly what should have been done, after all this is a computational study.</p><p>Other questions:</p><p>- If the Timer neurons are recurrently connected with excitatory neurons, how come their activity dies out and what determines the decay time constant in a timer circuit. Recurrently connected population of only excitatory neurons (timer cells) has only two fixed points: one at maximum value (and then the activity will sustain for ever) and the zero activity fixed point. So it would require fine tuning to get to the right duration. This again goes back to the issue of the robustness of the results.</p><p>- In a computational study like this it is very important to show the parameter ranges in which the demonstrated phenomenon is observed. Here it is also important to show under what conditions we can get a wide range of timings. Authors have chosen equal number of timer, messenger and inhibitory neurons - how crucial is this? Could we still get the same results if we assume 80-20 ratio of excitatory/inhibitory neurons?</p><p>- What is the min. and maximum duration for each event in the sequence that can be learned and recalled? (This goes back to the issue of the parameter ranges).</p><p>- What happens when the sequence parts overlap?</p><p>- Does the learning automatically stop or it has to be manually stopped.</p><p>- Since the three-stage model is more general, I guess that should be the one implemented in the brain. So I think authors should make predictions at that level? Where are reservoir and sparse net located and how would be the activity in these two modules.</p><p><italic>Reviewer #2:</italic></p><p>In the manuscript &quot;Learning precise spatiotemporal sequences via biophysically realistic learning rules in a modular, spiking network,&quot; the authors propose a plastic spiking network model that learns selective temporal sequences with variable timing.</p><p>The authors propose a novel and tractable plasticity model with separate eligibility traces for LTD and LTP. The normative fixed point approach the authors employ to solve the temporal learning problem is elegant. Further, the writing is clear, the question well-motivated, and relevant literature cited correctly. However, the manuscript lacks a closer comparison to existing experimental data, and several open questions remain related to the network’s temporal dynamics and the robustness of the proposed learning mechanism.</p><p>1) From where do the long time scales in the network model come?</p><p>A crucial property of the timer cells is their slowly decaying firing rate which is the basis of the adjustable decays, presumably linked to the learning of the recurrent connections. It was not entirely clear what causes these slowly decaying rates in the model. The question arises because slow working memory like dynamics are non-trivial to get, especially, in spiking neural networks with physiological time constants. A body of literature tackled this issue with, for instance, attractor models (Amit and Brunel, 1997; Yakovlev et al., 1998), non-normal network dynamics (Goldman, 2009; Hennequin et al., 2012), or negative derivative feedback (Lim and Goldman, 2013). However, the present model does not seem to contain any intrinsically slow time constants. Perhaps the unusual combination of slow excitation ~80ms vs. fast inhibition (~10ms) results in some form of negative derivative feedback? This choice is opposite to the usual fast AMPA vs. slower GABA dynamics. While several potential mechanisms could underlie such slow ramping activity, it is essential to clarify this point and, perhaps, illustrate that the proposed learning scheme is robust to other slow timescale mechanisms.</p><p>2) How plausible is the delay activity state in the network model?</p><p>Although the authors used spiking neural network models for part of the study, the spiking network activity is neither shown nor characterized. How does the spiking activity look like in the present model? The firing rates seems rather high, which raises the question of how compatible the network activity is with cortical networks. For instance, the firing rates during the onset phase of the timer cell do look relatively high (&gt;80Hz). Whereas, in many sensory areas spiking activity is relatively low and asynchronous irregular, possibly linked to a balanced state.</p><p>How does the activity in the present model compare to such balanced models? Would balance and the associated activity pose a problem? The manuscript would benefit if the mechanism proves robust to such presumably more realistic activity regimes.</p><p>3) Comparison to experimental data</p><p>One misses a more detailed treatment of how the proposed learning algorithm can be further verified with experimental data. Although inspired by experiments (Gavornik and Bear, 2014), a closer and perhaps more quantitative comparison to experimentally observable network activity in sensory cortices is desirable. Such verification may be challenging to accomplish solely based on LFP recordings. Maybe there are specific salient dynamical signatures that the present model predicts? One of the strong assumptions of the model is that there are two functionally different excitatory populations (timers and messengers) with a stereotypical interplay in time. How easily can such populations be recovered from (simulated) data?</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Learning precise spatiotemporal sequences via biophysically realistic learning rules in a modular, spiking network&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by Ronald Calabrese as the Senior Editor, a Reviewing Editor, and three reviewers. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional simulations are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>This manuscript addresses the problem of learning sequences of events with variable durations. This is an important problem. The revised manuscript was reviewed by two new reviewers and one previous reviewer. The consensus was that the manuscript will be suitable for publication after the following two points are addressed:</p><p>1) Time constants of inhibitory neurons:</p><p>The choice of synaptic time constants (80ms for exc. and 10ms for inhibition) is very odd. There is no justification provided for these values.</p><p>The solution that was proposed by the reviewers is that to solve this issue by redifining the time scale by, say division by 5. So that what now is 80 milliseconds becomes 16 milliseconds. This has to be done consistently throughout the paper, but new simulations are not absolutely necessary. The point can be addressed by careful re-definition of time scales throughout the manuscript, if this is what the authors prefer.</p><p>2) The emergence of CNA and fine tuning of the model:</p><p>Another crucial parameter is the connections from timer--&gt;messenger and inhibitory neurons--&gt; messenger neurons. These have to be tuned such that messengers only fire when inhibition has gone down. These synapses do not appear to have been learned using the TTL in this model. This point can be addressed by testing robustness with respect to changes in the synaptic weights: what happens if connection weights are change by +/- 29 percent. New simulations are necessary here.</p><p><italic>Reviewer 1:</italic></p><p>One of the main points raised in the previous review was that of the fine tuning of the parameters. In this revision authors have not done much to address that concern (see below for my comments on their reply). So for now, I maintain that the model is contrived and rests on very strong assumptions for which there is little experimental evidence.</p><p>1) The issue of rewards:</p><p>Authors write: We have assumed that on every transition between external stimuli, a “novelty” signal causes a global release of a neuromodulator, which acts as a reinforcement signal (see Materials and methods).</p><p>This is a big assumption. Clearly, we don’t just make sequences of novel events. Familiar events are also added in sequences with novel events.</p><p>2) Time constants of inhibitory neurons:</p><p>The choice of synaptic time constants (80ms for exc. and 10ms for inh) is very odd as also noted by the second reviewer - but this is also crucial to the model. But there is no justification provided for these values.</p><p>3) The emergence of CNA and fine tuning of the model:</p><p>Another crucial parameter is the connections from timer--&gt;messenger and inh neurons--&gt; messenger neurons. These have to be tuned such that messenger only fire when inhibition has gone down - I do not think these synapses have been learned using the TTL in this model.</p><p>Authors argue that these synaptic weights can be learned as they have shown in Huerta et al. But CNA architecture is different from the model studied in Huerta et al. Three types of cells in Huerta et al., are all excitatory and there is a global inhibitory population. But for the CNA here we need two excitatory populations and one inhibitory. Moreover, the third inhibitory population cannot serve the function of global inhibition that may give rise to the timer/messenger cells (e.g. following Huerta et al.,). Furthermore, in the Huerta paper number of messenger cells are way too low but here authors have assumed that there are equal number of timer and messenger cells. Therefore, authors’ claim that they have provided a putative mechanism for the emergence of the CNA structure is not correct.</p><p>Since authors argue that &quot;there are a number of degenerate sets of parameters&quot; they should show some of those. In addition, since the choice of synaptic time constants is so odd, they should show that the model works when exc. synaptic time constant is smaller than inh time constant - or how close these two time constants can be. When a model has so many parameters it is important to question the robustness of the model.</p><p>Authors have shown the robustness of the learning algorithm (Figure 5—figure supplement 1) but there are other parameters in the model that are not associated with plastic synapses. How crucial are they? At the outset it is obvious that the synaptic time constant are crucial and for some reason exc. syn time constant has to be longer than inhibitory time constant. Similarly, the connectivity from timer--&gt;messenger and inh-neurons--&gt;messenger needs to be tuned very carefully.</p><p>4) The issue of other inhibitory neurons:</p><p>My question was not about the detectability. My concern is that besides the inh neurons in the CNA there will be other inhibitory neurons in the network e.g. those needed for the emergence of time/messenger populations. Would their activity cause problems?</p><p>5) Biological realism:</p><p>I agree with the authors that they have a local learning rule and the rule is biologically plausible. My concern was about using reservoir network (which is fine) and still calling the model (Figure 5) biologically realistic. I also do not understand the use of the term “reservoir”. To me it seems like an attractor network. As the authors know, in reservoir computing we need to train the readout of the “reservoir” to get a specific pattern in response to an input.<italic>Reviewer 4:</italic></p><p>The paper addresses the problem of learning sequences composed of events of variable duration. This is an important problem and solution using messenger and timer cells is interesting and novel. I am less convinced of the utility of relying on reservoir computing to solve non-Markovian sequences. I wonder whether this can be done using connections between different CAN.</p><p>It is not clear whether the primary visual cortex (or a primary sensory area) is the best brain area to draw parallels with the proposed framework. Perhaps hippocampus would be more appropriate. In any case, layer 4 and 5 of primary sensory areas have very different properties and assigning them the same properties detracts from biological plausibility. There is some sequence learning in the visual cortex, but this is not the main effect in primary sensory processing.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63751.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the authors resubmitted a revised version of the paper for consideration. What follows is the authors’ response to the first round of review.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>[…]</p><p>I think the authors have raised an interesting problem and provide a solution that at least partly solves the problem. However, there are a number of shortcomings of the work which reduce the significance of the work.</p><p>1) Here authors are assuming sequences of distinct events. But to facilitate learning it is crucial that the animal is rewarded after each event. I am not convinced that every component of a sequential behavior is rewarded.</p></disp-quote><p>We do not claim that the animal is rewarded after every event, simply that there is some neuromodulator released during any change in the input (not “after each event”, what is an event?). This is how it was stated in the Results: “We have assumed that on every transition between external stimuli, a “novelty” signal causes a global release of a neuromodulator, which acts as a reinforcement signal (see Methods). The assumption of a temporally precise but spatially widespread neuromodulatory signal might seem at odds with common notions of temporally broad neuromodulator release, but they are indeed consistent with recent recordings in several neruomodulatory systems<sup>40,41</sup>.” Still, this is an assumption, which can be tested, and might be wrong. Our view is that we need to state our assumptions clearly, as we have done, we also think that this is a reasonable, though not a proven, assumption.</p><disp-quote content-type="editor-comment"><p>2) The key to indicate the end of duration of a sequence component, is that the inhibitory neurons stop firing before the Timer neurons. Why should this be? Since inhibitory neurons are driven by time neurons and that typically inhibitory neurons have low spike threshold one would expect the inhibitory neurons to remain active as long as Timer neurons are active.</p></disp-quote><p>This is addressed directly in the Results: “However, inhibitory cells in the module decay slightly more quickly than their Timer counterparts, thanks to shorter time constants for synaptic activation (80ms for excitatory, 10ms for inhibitory), and small Timer to Inhibitory weights (there are a number of degenerate sets of parameters which can facilitate quickly decaying Inhibitory cells<sup>37</sup>).” In modeling studies, it is indeed easy to generate this form of activity in the inhibitory population, and we have previously shown that such activity profiles can arise in a subpopulation of cells when the weights are chosen from a broad random distribution (Huertas et al., 2015). However, it is true that this is a putative mechanism which has not yet been validated experimentally.</p><disp-quote content-type="editor-comment"><p>This must require fine tuning of the circuit which is beyond synaptic changes. This particular component of the model makes it appear contrived. Authors have not provided biological motivation or evidence of robustness of the mechanism.</p></disp-quote><p>In our previous cited study (Huertas et al., 2015) we have shown that such sub-populations can arise in a network with efficacies chosen randomly from a broad distribution. It therefore does not depend on fine tuning. Further, such subpopulations have been observed experimentally in interval timing experiments, though there is not sufficient data in sequence learning experiments to determine if they arise there as well. We have provided a putative mechanism for how these different sub-populations may arise. The mechanism does not require fine tuning as suggested. However, it is true that it has not yet been validated experimentally.</p><disp-quote content-type="editor-comment"><p>Authors finally predict that &quot;There will be a population of inhibitory cells within each module that have firing properties similar to Timers but that decay more quickly (Figure 2A).&quot; But is this enough? There will also be other inhibitory neuron type which will not have this exact dynamics - will that be a problem?</p></disp-quote><p>In trying to interpret the question we find several options as to what they mean, we will therefore answer all options we can think of:</p><p>a) The ability to experimentally detect this sub-population. Of course, when any experimentalist looks for particular types of neurons (take place cells, or really any functionally specific cell type as an example), there will be plenty of other neurons the experimenter records which do not have the desired dynamics. This problem of detection is a universal problem in neuroscience, and is not unique to our prediction of this particular type of inhibitory neuron existing in visual cortex.</p><p>b) Will the exitance of other inhibitory cell types eliminate the ability of the model to perform. In Huertas et al., (2015) we showed that a wide distribution of inhibitory cell types results in a heterogeneity of excitatory cell types, some of these will be of the “Messenger” cell type. So, this heterogeneity of inhibitory cell types does not eliminate the ability to generate “Messenger” cell types. The harder problem in the context of the sequence learning model, is that only these “Messenger” type cells should have plasticity in their synaptic connections to the “Timers” of the subsequent column. For this we assume actually that there is some structure in the micro-column, so that the “Messenger” cells don’t arise in simply due to the distribution, but to some structure in the microcircuit column, or in other words, they are predestined to become “Messenger”. In that case it will be easier to mark them, and assume they have plastic synapses to Timers.</p><disp-quote content-type="editor-comment"><p>3) While it is possible to have non-Markovian sequences but still each Timer can show only a single duration. Authors only make passing remark on how this could be amended but the solution is very ad-hoc and very likely will not scale.</p></disp-quote><p>The ability to learn several target times within a single recurrent population is indeed currently a general problem with local learning rules. We have changed our language referring to this in the new version to: “In order for repeated elements to have different durations during recall, an appropriate learning rule must be capable of creating multiple attractors within that element’s Timer population, with each attractor triggering a different duration of activity.” Since this issue is not yet resolved for local learning rules, this challenge must still be overcome, and our lab is currently working on this.</p><disp-quote content-type="editor-comment"><p>4) The main motivation of the work is to come up with a biologically plausible model of sequence (order and durations). But the addition of reservoir and a sparse readout makes it non-biological.</p></disp-quote><p>Yes, our ultimate aim is to generate a biologically plausible model for sequence learning. More than that we want to identify the correct model. However, in this paper we do not make the claim that the reservoir structure itself is biologically realistic, nor is that the “main motivation of the work”. Our main focus it to identify architectural constraints that allow for local, biophysically plausible learning rules. From the Results: “To learn non-Markovian sequences, we modify the network structure while maintaining local learning rules.” and the Discussion: “We combine these two methods, using highly recurrent networks in the context of a larger architecture, and this combination allows us to maintain local and biophysically realistic learning rules.” From the very beginning of the Discussion: “In this work, we demonstrate the ability of a modular, spiking network to use biophysically realistic learning rules to learn and recall sequences, correctly reporting the duration and order of the individual elements.”</p><p>The rate-based implementation used here for the reservoir machine is indeed not biophysical. Additionally, the reviewer might still wonder if there is any biophysical realism to reservoir machines. This is indeed debatable and is a current focus of research in many labs. There have been various publications that have tried to implement RNN type architectures with spiking neurons (Abbott et al., 2016, Nicola and Clopath 2016, etc.) Whether this attempt has been successful is beyond the scope of this paper, and this might take years to resolve. However, some network with extended memory dependence is necessary for the formulation outlined here to work for non-Markovian sequences. We have chosen a simple sparse implementation of such a network to demonstrate its utility in solving this problem, not in order to show that this specific implementation is used in the brain. We have tried to clarify this in the current version of the paper.</p><disp-quote content-type="editor-comment"><p>Moreover, authors have not specified the properties of the reservoir, specifically how does it keeps the memory of sequence of different messengers.</p></disp-quote><p>We are not quite sure what the reviewer means by “properties of the reservoir”. However, the key property of the reservoir used here is that its current state depends on a long-term history of its activity. This is the property of reservoir machines explored extensively in the literature. In the paper we state: “For the network to learn and recall non-Markovian sequences, it must somehow keep track of its history, and use this history to inform transitions during sequence learning and recall. To this end, we include two additional “stages” to the network (Figure 5). The first is a fixed (non-learning) recurrent network, sometimes called a “reservoir” (as in reservoir computing) or a “liquid” (as in a liquid state machine)<sup>49,50</sup>, which receives inputs from the Messenger cells in the main columnar network. Owing to these inputs and due to its strong recurrent connectivity, the current state of the reservoir network is highly dependent on the history of network activity. Therefore, it acts as a long-term memory of the state of the columnar network.” Moreover, in the Materials and methods section all implementation details of the reservoir machine are given.</p><disp-quote content-type="editor-comment"><p>And if the long-term memory of the messenger sequence is already in the reservoir, then why the sparse-net readout stage is needed.</p></disp-quote><p>This is directly addressed in the Results: “The second additional stage is a high dimensional, sparse, non-linear network which receives input from the reservoir, serving to project the reservoir states into a space where they are highly separated and non-overlapping. The result is that a given “pattern” in this sparse network at time t uniquely identifies the history of the main network up to and including time t. Since these patterns are highly non-overlapping (due to the sparsity and non-linearity), a particular pattern at time t can use simple, local, and biophysically realistic Hebbian learning to connect to Timer cells firing at time t + ∆t in the main network (Direct Messenger to Timer feed forward learning is removed in this non-Markovian example).”</p><disp-quote content-type="editor-comment"><p>5) The whole work is presented as demonstrations of key results, there is no systematic analysis of robustness of the results. I disagree that it is beyond the scope of the current work -- I think that is exactly what should have been done, after all this is a computational study.</p></disp-quote><p>We have already addressed many aspects of the robustness in the original paper, even though we did not specifically call these results robustness. This might have caused the reviewer to disregard these results. Robustness to stochasticity is addressed directly in Figure 3—figure supplement 2. Robustness to input deviations is addressed directly in Figure 8—figure supplement 1. Many other aspects of the robustness of the learning rule, and of the CNA have been previously addressed in previous papers that are cited here (He et al. 2015, Huertas et al., 2015, 2016). However, we have further extended our robustness analysis and these results are currently shown in Figure 5—figure supplement 1 and cited in the main text. We have also changed our wording in several places to make to clearer to the readers that this model is robust to many parameter variations. We must note however, that the model has 35 parameters, we did not modify all of these in our computational study as this is not feasible</p><disp-quote content-type="editor-comment"><p>Other questions:</p><p>- If the Timer neurons are recurrently connected with excitatory neurons, how come their activity dies out and what determines the decay time constant in a timer circuit. Recurrently connected population of only excitatory neurons (timer cells) has only two fixed points: one at maximum value (and then the activity will sustain for ever) and the zero activity fixed point. So it would require fine tuning to get to the right duration. This again goes back to the issue of the robustness of the results.</p></disp-quote><p>The activity of the Timer neurons is clearly transient. We are not at an activity fixed point, nor do we ever claim to be. Our weights reach fixed points, but these fixed points are not in the bi-stable regime of the network. An activity fixed point is a completely different thing. Our network is given a transient stimulus and produces a transient response. The timer cell network was previously comprehensively analyzed in Gavornik and Shouval, 2011, using mean field theory methods; these previous results are cited in this paper.</p><disp-quote content-type="editor-comment"><p>- In a computational study like this it is very important to show the parameter ranges in which the demonstrated phenomenon is observed. Here it is also important to show under what conditions we can get a wide range of timings. Authors have chosen equal number of timer, messenger and inhibitory neurons -- how crucial is this? Could we still get the same results if we assume 80-20 ratio of excitatory/inhibitory neurons?</p></disp-quote><p>We hope that our modified language, previous cited work, and additional work regarding robustness provide an answer to some of these questions as well. A different ratio of E/I cells would not fundamentally alter these results, neither would a different ratio of T and M cells.</p><disp-quote content-type="editor-comment"><p>- What is the min. and maximum duration for each event in the sequence that can be learned and recalled? (This goes back to the issue of the parameter ranges).</p></disp-quote><p>This is addressed directly in the Discussion of the original paper: “In combining modular, heterogenous structure with a learning rule based on eligibility traces, the model can accurately learn and recall sequences of up to at least 8 elements, with each element anywhere from ~300ms to ~1800ms in duration.” From the Results: “The network is capable of learning sequences of temporal intervals where the individual elements can be anywhere from ~300ms to ~1800ms (see Supplementary Figure 2) in duration, which agrees with the observed ranges used for training V1 circuits<sup>1,6</sup>.” With different sets of parameters, these ranges will likely differ, though we have good reason to believe that ranges beyond ~2000ms cannot be implemented in a stochastic spiking network, without additional mechanisms.</p><disp-quote content-type="editor-comment"><p>- What happens when the sequence parts overlap?</p></disp-quote><p>We are not sure exactly by what they mean by overlap, however we address overlaps directly in subsection “Learning and recalling non-markovian sequences”. In particular Figure 7 is titled: “Recall of Two Overlapping Sequences”.</p><disp-quote content-type="editor-comment"><p>- Does the learning automatically stop or it has to be manually stopped.</p></disp-quote><p>The phrase “fixed point” appears many times in the manuscript in relation to our learning rule. Here are a few examples: “We have used this rule because it can solve the temporal credit assignment problem, allowing the network to associate events distal in time, and because it reaches fixed points in both recurrent and feedforward learning tasks<sup>35</sup>” “Properly encoded durations and orders are the result of the fixed points in the learning rule, as described in the Materials and methods section and in previous publications<sup>35,46</sup>.” “Recurrent learning ends in a fixed point which sets the time D between the end of firing in one column and the start of firing in the next.” “Feed forward learning results in a fixed point which determines the connection strength between Messenger and Timer cells in subsequent columns.” Moreover, Supplementary Figure 2C shows the convergence to these fixed points, and in the Materials and methods section Equations 15-17 define these fixed points, and show analytical results regarding their convergence in a simple case, which has been previously analyzed and is cited here.</p><disp-quote content-type="editor-comment"><p>- Since the three-stage model is more general, I guess that should be the one implemented in the brain.</p></disp-quote><p>Yes, indeed the three-stage model, as the reviewer notes, is more general and can learn and reproduce more types of sequences. Indeed, behaviorally these are problems we can solve, so they must be embedded somewhere in the brain.</p><disp-quote content-type="editor-comment"><p>So I think authors should make predictions at that level? Where are reservoir and sparse net located and how would be the activity in these two modules.</p></disp-quote><p>For the modular network, there is some physiological data suggesting that this network resides already in primary sensory cortex. For the three-stage network, we have almost no physiological information, and therefore cannot meaningfully make specific predictions. However, some brain structures have circuit elements and connectivity that suggest they could be used for these purposes. In the original paper we state: “The reservoir and sparse network components of our three-stage model could be thought to arise from a projection from other cortical or subcortical areas. Functionally similar networks (ones that take complex, multimodal, and dynamic context and repackage it into sparse, separated patterns) have been observed in the dentate gyrus<sup>54,55</sup> and the cerebellum<sup>56,57</sup>. However, these model components could also be thought of as part of the same cortical network, partially segregated in function but not necessarily by location.” The modular network is also a component of the three-stage network. For that network we make very clear predictions about the identity of the modular network, and its properties. The specific predictions we make about this modular network go significantly beyond the typically generic predictions made in most previous models (see Figure 8).</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>In the manuscript &quot;Learning precise spatiotemporal sequences via biophysically realistic learning rules in a modular, spiking network,&quot; the authors propose a plastic spiking network model that learns selective temporal sequences with variable timing.</p><p>The authors propose a novel and tractable plasticity model with separate eligibility traces for LTD and LTP. The normative fixed point approach the authors employ to solve the temporal learning problem is elegant. Further, the writing is clear, the question well-motivated, and relevant literature cited correctly. However, the manuscript lacks a closer comparison to existing experimental data, and several open questions remain related to the network’s temporal dynamics and the robustness of the proposed learning mechanism.</p><p>1) From where do the long time scales in the network model come?</p></disp-quote><p>The long time-scales arise from the strong recurrent weights in the network, and is explicitly stated as such in the paper. From the Results:” The “Timer” cells learn strong recurrent connections with other Timer cells within the module. This strong recurrent connectivity results in long lasting transient activity, which is used to represent the duration of a given stimuli. Previous studies have analyzed in detail the relationship between recurrent connectivity and duration of resulting transient activity following a stimulus<sup>35,36</sup>.” We have previously extensively analyzed the dynamics of such recurrent networks, and this analysis is cited in the paper. We have tried to make this even more clear in this rewritten version of the paper.</p><disp-quote content-type="editor-comment"><p>A crucial property of the timer cells is their slowly decaying firing rate which is the basis of the adjustable decays, presumably linked to the learning of the recurrent connections. It was not entirely clear what causes these slowly decaying rates in the model.</p></disp-quote><p>As the reviewer implies, and as is stated in the model, the slowly decaying activity arises from recurrent connections. The ability of recurrent connections to represent the correct times arises from the learning rule. We have analyzed these aspects of the model previously in our publications (Gavornik and Shouval, 2011, Huertas et al., 2016), and try to make this even more clear in the current version of this paper.</p><disp-quote content-type="editor-comment"><p>The question arises because slow working memory like dynamics are non-trivial to get, especially, in spiking neural networks with physiological time constants. A body of literature tackled this issue with, for instance, attractor models (Amit and Brunel, 1997; Yakovlev et al., 1998), non-normal network dynamics (Goldman, 2009; Hennequin et al., 2012), or negative derivative feedback (Lim and Goldman, 2013). However, the present model does not seem to contain any intrinsically slow time constants. Perhaps the unusual combination of slow excitation ~80ms vs. fast inhibition (~10ms) results in some form of negative derivative feedback? This choice is opposite to the usual fast AMPA vs. slower GABA dynamics. While several potential mechanisms could underlie such slow ramping activity, it is essential to clarify this point and, perhaps, illustrate that the proposed learning scheme is robust to other slow timescale mechanisms.</p></disp-quote><p>The slow dynamics here are a property of a recurrent excitatory network. We have previously shown and mathematically analyzed such a network (Gavornik, Shouval, 2011). In order to carry out this analysis we indeed use the MFT methods developed by Brunel and Amit. Formally, this is the same type of network as a working memory network, only operating slightly below the bifurcation at which the network becomes bi-stable. The slow dynamics are a reflection of the “ghost” of this bifurcation. Synaptic plasticity acts to bring the “source” and “sink” terms to the appropriate distance such that the network decays with the appropriate time. Given the time constants used here, the stochastic spiking network can represent decays of close to 2000ms. For decays within this range we do not need additional mechanisms such as negative derivative feedback. The slow decay of the network can be achieved with normal weight matrixes, and this does not require non-normal dynamics. Additional mechanisms might extend the time ranges that the network can reproduce.</p><disp-quote content-type="editor-comment"><p>2) How plausible is the delay activity state in the network model?</p><p>Although the authors used spiking neural network models for part of the study, the spiking network activity is neither shown nor characterized. How does the spiking activity look like in the present model?</p></disp-quote><p>The reviewer failed to notice Figure 3—figure supplement 4, which shows a spike raster of the entire network for a trial before learning, and a trial after learning. It is referenced in the Results: “Empirically, temporal accuracy of recall depends on many non-trivial factors (i.e. length of individual elements, length of entire sequence, placement of short elements near long elements, etc.), owing to the many non-trivial effects of stochasticity of the spiking network (spike rasters are shown in Figure 3—figure supplement 4).”</p><disp-quote content-type="editor-comment"><p>The firing rates seems rather high, which raises the question of how compatible the network activity is with cortical networks. For instance, the firing rates during the onset phase of the timer cell do look relatively high (&gt;80Hz). Whereas, in many sensory areas spiking activity is relatively low and asynchronous irregular, possibly linked to a balanced state.</p></disp-quote><p>The cell types in our model are based off of findings of interval timing-based cells in visual cortex, such as from Liu et al., (2015). Figure 2 compares our model to these experimentally observed cell types, which also have very high firing rates (~40 Hz) for the Timers.</p><disp-quote content-type="editor-comment"><p>How does the activity in the present model compare to such balanced models? Would balance and the associated activity pose a problem? The manuscript would benefit if the mechanism proves robust to such presumably more realistic activity regimes.</p></disp-quote><p>The model was not set up to be in the balanced regime, however its spike statistics are quire realistic. This can be seen in the additional subplot showing the ISI distributions of Timer and Messenger cells (Figure 3—figure supplement 4). It’s actually quite intriguing and surprising that despite not being in the balanced regime, the model results in reasonable spike statistics. Partially this is due to injected noise into neurons in order to generate spontaneous activity. We primarily included this additional variability in order to make sure that our learning mechanisms are robust enough to handle such noise. We are currently analyzing the source of these surprisingly realistic spike statistics, as part of a different project.</p><disp-quote content-type="editor-comment"><p>3) Comparison to experimental data</p><p>One misses a more detailed treatment of how the proposed learning algorithm can be further verified with experimental data. Although inspired by experiments (Gavornik and Bear, 2014), a closer and perhaps more quantitative comparison to experimentally observable network activity in sensory cortices is desirable. Such verification may be challenging to accomplish solely based on LFP recordings. Maybe there are specific salient dynamical signatures that the present model predicts? One of the strong assumptions of the model is that there are two functionally different excitatory populations (timers and messengers) with a stereotypical interplay in time. How easily can such populations be recovered from (simulated) data?</p></disp-quote><p>Indeed, our model predicts that in sequence learning networks would develop “Timer” and “Messenger” type populations of cells. These cells are indeed found in single unit recording in interval-timing paradigms, but not yet in sequence learning paradigms as most of the data there is based on LFPs. In our simulated data it is easy to distinguished from the data alone these two different populations, even without knowing a priori which cell belong to which group. The statistical properties of these cells even at the single cell level, such as duration of higher firing rate, and the firing rates themselves, are clearly significantly different. Indeed, we make a strong prediction that these two population will exist, and testing experimentally this is essential for experimentally validating, rejecting, or modifying the model.</p><p>[Editors’ note: what follows is the authors” response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>This manuscript addresses the problem of learning sequences of events with variable durations. This is an important problem. The revised manuscript was reviewed by two new reviewers and one previous reviewer. The consensus was that the manuscript will be suitable for publication after the following two points are addressed:</p><p>1) Time constants of inhibitory neurons:</p><p>The choice of synaptic time constants (80ms for exc. and 10ms for inhibition) is very odd. There is no justification provided for these values.</p><p>The solution that was proposed by the reviewers is that to solve this issue by redifining the time scale by, say division by 5. So that what now is 80 milliseconds becomes 16 milliseconds. This has to be done consistently throughout the paper, but new simulations are not absolutely necessary. The point can be addressed by careful re-definition of time scales throughout the manuscript, if this is what the authors prefer.</p></disp-quote><p>Our excitatory time constant is notably long (80 ms), but this is not strictly required for our model. We have included a new figure (Figure 5—figure supplement 2) where we set the excitatory time constant to 20ms and demonstrate successful learning of a sequence with elements 500ms long each. However, the ability of the Timers to learn long times via their recurrent connections (without prohibitively small learning rates) depends on such large time constants, which are common in working memory literature (Wang et al., 2013, Lisman et al., 1998, Gavornik and Shouval, 2011). Figure 5—figure supplement 2B shows that the Timer cells reach bistability when trying to learn 1000ms with a 20ms time constant, causing failure in learning. The relationship between reported time, recurrent weights and time constants in Timer-like cells is analyzed in detail in previous work (Gavornik and Shouval, 2011 in particular). Although there is some evidence for a slow time constant in PFC (Wang et al., 2013), this might not be so in sensory cortex. There are alternative ways to acquire a slow time constant that can facilitate learning of long interval times. Such options include derivative feedback (Lim and Goldman, 2013), and active intrinsic conductance (Fransen et al.,. 2006, Gavornik and Shouval, 2011). Such work is beyond the scope of the current paper.</p><disp-quote content-type="editor-comment"><p>2) The emergence of CNA and fine tuning of the model:</p><p>Another crucial parameter is the connections from timer--&gt;messenger and inhibitory neurons--&gt; messenger neurons. These have to be tuned such that messengers only fire when inhibition has gone down. These synapses do not appear to have been learned using the TTL in this model. This point can be addressed by testing robustness with respect to changes in the synaptic weights: what happens if connection weights are change by +/- 29 percent. New simulations are necessary here.</p></disp-quote><p>These synapses were not learned using TTL in this model, but were learned using single trace learning in Huertas et al., 2015. We demonstrate that sequence learning is robust to +/- 20% changes in these synaptic weights in a new Figure (5). There is very little difference between any of the cases. The most notable is the +20% Timer to Messenger weight case, where the Messengers have a noticeably higher firing rate, but other than that, changes to the network are negligible. These weights do not have to be particularly finely tuned in order to achieve successful sequence learning.</p><disp-quote content-type="editor-comment"><p>Reviewer 1:</p><p>One of the main points raised in the previous review was that of the fine tuning of the parameters. In this revision authors have not done much to address that concern (see below for my comments on their reply). So for now, I maintain that the model is contrived and rests on very strong assumptions for which there is little experimental evidence.</p></disp-quote><p>We hope that our responses to (1) and (2) above help assuage your concerns.</p><disp-quote content-type="editor-comment"><p>1) The issue of rewards:</p><p>Authors write: We have assumed that on every transition between external stimuli, a “novelty” signal causes a global release of a neuromodulator, which acts as a reinforcement signal (see Materials and methods).</p><p>This is a big assumption. Clearly, we don’t just make sequences of novel events. Familiar events are also added in sequences with novel events.</p></disp-quote><p>The neuromodulatory “novelty” signal acts on “every transition between external stimuli”, not just novel external stimuli (as can be seen in the non-Markovian section, where stimuli are repeated).</p><disp-quote content-type="editor-comment"><p>2) Time constants of inhibitory neurons:</p><p>The choice of synaptic time constants (80ms for exc. and 10ms for inh) is very odd as also noted by the second reviewer -- but this is also crucial to the model. But there is no justification provided for these values.</p></disp-quote><p>See response to “Time constants of inhibitory neurons”.</p><disp-quote content-type="editor-comment"><p>3) The emergence of CNA and fine tuning of the model:</p><p>Another crucial parameter is the connections from timer--&gt;messenger and inh neurons--&gt; messenger neurons. These have to be tuned such that messenger only fire when inhibition has gone down - I do not think these synapses have been learned using the TTL in this model.</p><p>Authors argue that these synaptic weights can be learned as they have shown in Huerta et al. But CNA architecture is different from the model studied in Huerta et al. Three types of cells in Huerta et al. are all excitatory and there is a global inhibitory population. But for the CNA here we need two excitatory populations and one inhibitory. Moreover, the third inhibitory population cannot serve the function of global inhibition that may give rise to the timer/messenger cells (e.g. following Huerta et al.,). Furthermore, in the Huerta paper number of messenger cells are way too low but here authors have assumed that there are equal number of timer and messenger cells. Therefore, authors” claim that they have provided a putative mechanism for the emergence of the CNA structure is not correct.</p></disp-quote><p>The CNA we use here is the same as in Huertas et al., see Figure 7 inset from that paper. The “sustained decrease” (SD) cells in Figure 4D from that paper are omitted because they are not necessary for sequence learning. Huertas starts from a global excitatory and inhibitory population, but the main connections that result from trace learning (hence “core” neural architecture) results in a CNA identical to the one we show in Figure 2. It is true that we have assumed an equal number of Timers and Messengers, while Heurtas (and experimental evidence) suggest a smaller number of Messengers than Timers. Our model can still function with a smaller number of Messengers, we simply chose an equal number here for simplicity. Functionally the Messengers will operate the same as long as there are enough neurons to produce a mean response of the population with a high SNR (from some quick simulations this seems to be around 20 or so rather than 100).</p><disp-quote content-type="editor-comment"><p>Since authors argue that &quot;there are a number of degenerate sets of parameters&quot; they should show some of those. In addition, since the choice of synaptic time constants is so odd, they should show that the model works when exc. synaptic time constant is smaller than inh time constant - or how close these two time constants can be. When a model has so many parameters it is important to question the robustness of the model.</p></disp-quote><p>See responses to “Time constants of inhibitory neurons” and “The emergence of CNA and fine tuning of the model”.</p><disp-quote content-type="editor-comment"><p>Authors have shown the robustness of the learning algorithm (supp 9) but there are other parameters in the model that are not associated with plastic synapses. How crucial are they? At the outset it is obvious that the synaptic time constant are crucial and for some reason exc. syn time constant has to be longer than inhibitory time constant. Similarly, the connectivity from timer--&gt;messenger and inh-neurons--&gt;messenger needs to be tuned very carefully.</p></disp-quote><p>See responses to “Time constants of inhibitory neurons” and “The emergence of CNA and fine tuning of the model”. Those weights do not in fact need to be tuned especially carefully.</p><disp-quote content-type="editor-comment"><p>4) The issue of other inhibitory neurons:</p><p>My question was not about the detectability. My concern is that besides the inh neurons in the CNA there will be other inhibitory neurons in the network e.g. those needed for the emergence of time/messenger populations. Would their activity cause problems?</p></disp-quote><p>I do not understand this question. Within each CNA there is only a single class of inhibitory interneurons. The inhibitory neurons in the CNA are the ones responsible for the emergence of the timer/messenger population.</p><disp-quote content-type="editor-comment"><p>5) Biological realism:</p><p>I agree with the authors that they have a local learning rule and the rule is biologically plausible. My concern was about using reservoir network (which is fine) and still calling the model (Figure 5) biologically realistic.</p></disp-quote><p>We explicitly do not use the terms “biologically realistic” or “biophysically realistic” to describe the non-Markovian part of the model (nor do we use them wholesale to describe the Markovian part of the model, either). We only claim that it maintains a local learning rule. From the Results: “We have chosen this simple sparse representation of this three-stage network, not because it is a biophysically realistic implementation but in order to demonstrate the concept that such an addition is sufficient for learning and expressing non-Markovian sequences, while still using local learning rules.”</p><disp-quote content-type="editor-comment"><p>I also do not understand the use of the term “reservoir”. To me it seems like an attractor network. As the authors know, in reservoir computing we need to train the readout of the “reservoir” to get a specific pattern in response to an input.</p></disp-quote><p>Reservoir (or “liquid”) are general terms for the recurrent network used in reservoir computing or in a liquid state machine. We are not performing reservoir computing, but we are using a reservoir (or liquid, or RNN) in our model. From the Results: “The first is a fixed (non-learning) recurrent network, sometimes called a “reservoir” (as in reservoir computing) or a “liquid” (as in a liquid state machine)<sup>49,50</sup>, which receives inputs from the Messenger cells in the main columnar network.” I would not consider it an attractor network since the only fixed points are 0 and saturation (in the limit of large N and large t, but we operate far away from this regime, and therefore far away from the fixed points).</p><disp-quote content-type="editor-comment"><p>Reviewer 4:</p><p>The paper addresses the problem of learning sequences composed of events of variable duration. This is an important problem and solution using messenger and timer cells is interesting and novel. I am less convinced of the utility of relying on reservoir computing to solve non-Markovian sequences. I wonder whether this can be done using connections between different CAN.</p></disp-quote><p>The reviewer offers an interesting alternative approach to learning non-Markovian sequences. We indeed tried approaches similar to the ones he proposes, and have not been able to get them to work. Of course, it might still be possible with different details than the ones we have tried, so this is still an interesting direction for future work. One interesting model of hierarchical non-Markovian sequence processing is Hawkins and Ahmad, 2016.</p><disp-quote content-type="editor-comment"><p>It is not clear whether the primary visual cortex (or a primary sensory area) is the best brain area to draw parallels with the proposed framework. Perhaps hippocampus would be more appropriate. In any case, layer 4 and 5 of primary sensory areas have very different properties and assigning them the same properties detracts from biological plausibility. There is some sequence learning in the visual cortex, but this is not the main effect in primary sensory processing.</p></disp-quote><p>The direct experimental evidence that inspires our model (the results of Gavornik and Bear, the evidence for Timer and Messenger cells) all occurs in visual cortex, hence why we draw parallels there. Hippocampus is certainly more traditionally associated with sequences, but they are often compressed, i.e. during place cell replay. Layer 4/5 were grouped here together because the deep layers appear to be functionally similar for sequence learning in Gavornik and Bear (see Figure 8D). There is some unpublished data that suggests Layer 5 as a more likely candidate for the Timer cells, so we will revise to simply layer 5. Our notation Layer 4/5 was more an indication of our uncertainty on which it was rather than implying that Timers were occurring in both.</p><p>There is also emerging evidence of Timer/Messenger type responses in other brain areas, including PFC (J. Cohen lab, unpublished), and we are currently working on related models in these brain areas.</p></body></sub-article></article>