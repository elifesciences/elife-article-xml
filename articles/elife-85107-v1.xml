<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">85107</article-id><article-id pub-id-type="doi">10.7554/eLife.85107</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>On the normative advantages of dopamine and striatal opponency for learning and choice</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-272987"><name><surname>Jaskir</surname><given-names>Alana</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-24218"><name><surname>Frank</surname><given-names>Michael J</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8451-0523</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><institution content-type="dept">Department of Cognitive, Linguistic and Psychological Sciences</institution>, <institution>Brown University</institution>, <addr-line><named-content content-type="city">Providence</named-content></addr-line>, <country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-97220"><name><surname>Liljeholm</surname><given-names>Mimi</given-names></name><role>Reviewing editor</role><aff><institution>University of California, Irvine</institution>, <country>United States</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>alana_jaskir@brown.edu</email> (AJ);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>Michael_Frank@brown.edu</email> (MF);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>22</day><month>03</month><year>2023</year></pub-date><volume>12</volume><elocation-id>e85107</elocation-id><history><date date-type="received"><day>22</day><month>11</month><year>2022</year></date><date date-type="accepted"><day>14</day><month>03</month><year>2023</year></date></history><permissions><copyright-statement>Â© 2023, Jaskir &amp; Frank</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Jaskir &amp; Frank</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-85107-v1.pdf"/><abstract><p>The basal ganglia (BG) contribute to reinforcement learning (RL) and decision making, but unlike artificial RL agents, it relies on complex circuitry and dynamic dopamine modulaton of opponent striatal pathways to do so. We develop the OpAL* model to assess the normative advantages of this circuitry. In OpAL*, learning induces opponent pathways to differentially emphasize the history of positive or negative outcomes for each action. Dynamic DA modulation then amplifies the pathway most tuned for the task environment. This efficient coding mechanism avoids a vexing explore-exploit tradeoff that plagues traditional RL models in sparse reward environments. OpAL* exhibits robust advantages over alternative models, particularly in environments with sparse reward and large action spaces. These advantages depend on opponent and nonlinear Hebbian plasticity mechanisms previously thought to be pathological. Finally, OpAL* captures risky choice patterns arising from DA and environmental manipulations across species, suggesting that they result from a normative biological mechanism.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Mouse</kwd><kwd>Rat</kwd><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>P50MH119467</award-id><principal-award-recipient><name><surname>Frank</surname><given-names>Michael J</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01 MH084840</award-id><principal-award-recipient><name><surname>Frank</surname><given-names>Michael J</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>S10OD025181</award-id><principal-award-recipient><name><surname>Frank</surname><given-names>Michael J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf2"><p>Michael J Frank, Senior editor, <italic>eLife</italic>.</p></fn><fn fn-type="conflict" id="conf1"><p>The other authors declare that no competing interests exist.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. Simulation code is available on the authors' GitHub repositories https://github.com/amjaskir/opal-star</p></sec><supplementary-material><ext-link xlink:href="elife-85107-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>