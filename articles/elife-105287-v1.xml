<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">105287</article-id><article-id pub-id-type="doi">10.7554/eLife.105287</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.105287.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Pupil dilation offers a time-window on prediction error</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Colizoli</surname><given-names>Olympia</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5288-2437</contrib-id><email>olympia.colizoli@donders.ru.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>van Leeuwen</surname><given-names>Tessa M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7810-6348</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Rutar</surname><given-names>Danaja</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6798-2796</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Bekkering</surname><given-names>Harold</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8957-4817</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University</institution></institution-wrap><addr-line><named-content content-type="city">Nijmegen</named-content></addr-line><country>Netherlands</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04b8v1s79</institution-id><institution>Department of Communication and Cognition, Tilburg University</institution></institution-wrap><addr-line><named-content content-type="city">Tilburg</named-content></addr-line><country>Netherlands</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/056kkbk56</institution-id><institution>Department of Psychology, Sigmund Freud University</institution></institution-wrap><addr-line><named-content content-type="city">Ljubljana</named-content></addr-line><country>Slovenia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Press</surname><given-names>Clare</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>08</day><month>01</month><year>2026</year></pub-date><volume>14</volume><elocation-id>RP105287</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-11-29"><day>29</day><month>11</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-10-31"><day>31</day><month>10</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.10.31.621279"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-02-19"><day>19</day><month>02</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.105287.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-12-16"><day>16</day><month>12</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.105287.2"/></event></pub-history><permissions><copyright-statement>© 2025, Colizoli et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Colizoli et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-105287-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-105287-figures-v1.pdf"/><abstract><p>Task-evoked pupil dilation is notably linked to unexpected events. Building on Zénon’s (2019) information-theory framework, we investigated whether the pupil’s response to feedback on decision outcomes during associative learning reflects a prediction error signal. Operationally, we defined prediction errors as an interaction between stimulus-pair frequency and accuracy. We then tested if these signals correlated with information gain, formally defined as the Kullback-Leibler (KL) divergence between posterior and prior belief distributions of an ideal observer. We reasoned that information gain should be proportional to the precision-weighted prediction error signals potentially arising from neuromodulatory arousal networks. We analyzed two data sets in which participants performed perceptual decision-making tasks while pupil dilation was recorded. Our findings consistently showed that a significant proportion of variability in the post-feedback pupil response was explained by information gain shortly after feedback presentation. For the first time, we present evidence that whether the pupil dilates or constricts along with information gain was context dependent. This study offers empirical evidence that the pupil’s response provides valuable insights into the process of model updating during learning, highlighting its utility as a physiological indicator of internal belief states.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>prediction error</kwd><kwd>pupillometry</kwd><kwd>associative learning</kwd><kwd>information theory</kwd><kwd>decision making</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><funding-statement>No external funding was received for this work.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Pupil dilation provides a physiological readout of information gain during the brain's internal process of belief updating in the context of associative learning.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The human brain is constantly predicting its environment by forming expectations based on the meaningful environmental statistics we encounter in life (e.g. bananas are yellow, sometimes green, but never blue or red; <xref ref-type="bibr" rid="bib2">Aslin, 2017</xref>; <xref ref-type="bibr" rid="bib112">Turk-Browne et al., 2005</xref>; <xref ref-type="bibr" rid="bib105">Siegelman et al., 2019</xref>). Furthermore, perception is largely driven by these expectations (<xref ref-type="bibr" rid="bib22">de Lange et al., 2018</xref>; <xref ref-type="bibr" rid="bib32">Gau and Noppeney, 2016</xref>). In the predictive processing framework, the brain constructs and updates internal models of the world that aim to accurately predict incoming sensory data by minimizing prediction errors (<xref ref-type="bibr" rid="bib108">Sprevak and Smith, 2023</xref>). Prediction errors are abstractly defined as the difference between an expected and obtained outcome and are crucial concepts in models of learning (<xref ref-type="bibr" rid="bib23">den Ouden et al., 2012</xref>; <xref ref-type="bibr" rid="bib71">Montague et al., 2004</xref>; <xref ref-type="bibr" rid="bib101">Schultz, 2006</xref>). Pupil dilation may be a reliable biomarker of neural prediction error signals. Such a biomarker would be advantageous for investigating the neural computations involved in learning and decision-making due to the relative ease of measuring pupil size with a standard eye-tracking device. To achieve this aim, we must investigate the computational signatures reflected in pupil dilation to determine whether they genuinely represent prediction error signals during learning.</p><p>While reaction times (RT) scale with uncertainty, confidence, and reward expectation during perceptual decision-making (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib91">Ratcliff et al., 2016</xref>; <xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>), there is no overt behavioral marker that reflects the brain’s processing of a prediction error following <italic>feedback</italic> on a decision outcome when the brain supposedly updates its internal model(s) of the world (<xref ref-type="bibr" rid="bib108">Sprevak and Smith, 2023</xref>). Pupil dilation under constant luminance is a peripheral marker of the brain’s central arousal system (<xref ref-type="bibr" rid="bib20">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib62">Lloyd et al., 2023</xref>; <xref ref-type="bibr" rid="bib67">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib74">Murphy et al., 2014a</xref>; <xref ref-type="bibr" rid="bib92">Reimer et al., 2016</xref>). Evidence suggests that the brain leverages its arousal system to relay computational variables to circuits that execute inference and action selection (<xref ref-type="bibr" rid="bib71">Montague et al., 2004</xref>; <xref ref-type="bibr" rid="bib20">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib3">Aston-Jones and Cohen, 2005</xref>; <xref ref-type="bibr" rid="bib35">Glimcher, 2011</xref>; <xref ref-type="bibr" rid="bib57">Lak et al., 2017</xref>; <xref ref-type="bibr" rid="bib98">Sara, 2009</xref>; <xref ref-type="bibr" rid="bib100">Schultz, 2002</xref>; <xref ref-type="bibr" rid="bib123">Yu and Dayan, 2005</xref>). A growing body of literature suggests that pupil dilation may be a reliable physiological marker reflecting a prediction error signal in the post-feedback pupil response (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib9">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Kayhan et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Koenig et al., 2018</xref>; <xref ref-type="bibr" rid="bib78">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib87">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib99">Satterthwaite et al., 2007</xref>; <xref ref-type="bibr" rid="bib115">Van Slooten et al., 2018</xref>; <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>). Whether a prediction error signal is detectable in pupil dilation will depend on the specific definition of ‘prediction error’, how it is operationalized, as well as the temporal nature of the signal itself. For instance, an unsigned prediction error is defined as the difference between expected and unexpected events but is agnostic to whether the events are better or worse than expected. In contrast, a signed prediction error indicates whether an outcome was better or worse than expected. Relatedly, reward prediction errors are a type of signed prediction error indicating whether an obtained reward was better or worse than expected (<xref ref-type="bibr" rid="bib23">den Ouden et al., 2012</xref>).</p><p>In recent years, pupil dilation has received increased attention in psychology and human neuroscience research for its ability to reflect cognitive and computational variables involved in memory, attention, perception, and decision-making. For instance, pupil dilation has been shown to reflect stimulus expectancy and surprise (<xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib87">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib1">Alamia et al., 2019</xref>; <xref ref-type="bibr" rid="bib7">Bianco et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Friedman et al., 1973</xref>; <xref ref-type="bibr" rid="bib47">Kamp and Donchin, 2015</xref>; <xref ref-type="bibr" rid="bib50">Kloosterman et al., 2015</xref>; <xref ref-type="bibr" rid="bib51">Knapen et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Kuchinke et al., 2007</xref>; <xref ref-type="bibr" rid="bib59">Lavín et al., 2013</xref>; <xref ref-type="bibr" rid="bib61">Liao et al., 2016</xref>; <xref ref-type="bibr" rid="bib89">Qiyuan et al., 1985</xref>; <xref ref-type="bibr" rid="bib90">Raisig et al., 2010</xref>; <xref ref-type="bibr" rid="bib106">Silvestrin et al., 2021</xref>; <xref ref-type="bibr" rid="bib119">Wetzel et al., 2016</xref>; <xref ref-type="bibr" rid="bib126">Zhao et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Ghilardi et al., 2024</xref>), decision uncertainty (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib115">Van Slooten et al., 2018</xref>; <xref ref-type="bibr" rid="bib30">Friedman et al., 1973</xref>; <xref ref-type="bibr" rid="bib18">de Berker et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Findling et al., 2019</xref>; <xref ref-type="bibr" rid="bib33">Geng et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Fan et al., 2023</xref>; <xref ref-type="bibr" rid="bib53">Krishnamurthy et al., 2017</xref>; <xref ref-type="bibr" rid="bib60">Lempert et al., 2015</xref>; <xref ref-type="bibr" rid="bib75">Murphy et al., 2014b</xref>; <xref ref-type="bibr" rid="bib93">Richer and Beatty, 1987</xref>; <xref ref-type="bibr" rid="bib117">Vincent et al., 2019</xref>), and the updating of belief states in internal models including (reward) prediction errors (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib9">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Kayhan et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Koenig et al., 2018</xref>; <xref ref-type="bibr" rid="bib78">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib87">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib99">Satterthwaite et al., 2007</xref>; <xref ref-type="bibr" rid="bib115">Van Slooten et al., 2018</xref>; <xref ref-type="bibr" rid="bib59">Lavín et al., 2013</xref>; <xref ref-type="bibr" rid="bib26">Filipowicz et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Harris et al., 2022</xref>; <xref ref-type="bibr" rid="bib83">Pajkossy et al., 2023</xref>; <xref ref-type="bibr" rid="bib13">Cheadle et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">He et al., 2024</xref>). <xref ref-type="bibr" rid="bib124">Zénon, 2019</xref> proposed that the plethora of cognitive phenomena reflected in pupil dilation can be unified under an information-theoretic framework. Under Zénon’s hypothesis, the common factor driving all cognitive processes reflected in pupil dilation can be quantified in terms of information gain, defined as the divergence between posterior and prior beliefs. A unified framework that relates pupil dilation to cognition through information theory would be beneficial for several reasons. First, a unified framework would enable us to more accurately quantify cognitive processes by allowing us to connect physiological responses like arousal with cognitive functions. Second, such an approach could reveal how effectively an individual integrates new information and adjusts their predictions. Finally, a unified framework would allow researchers to apply consistent metrics across different contexts and tasks, facilitating comparisons between studies and enhancing our overall understanding of cognitive processes linked to pupil dilation.</p><p>We reasoned that the link between prediction error signals and information gain in pupil dilation is through precision weighting. Precision refers to the amount of uncertainty (inverse variance) of both the prior belief and sensory input in the prediction error signals (<xref ref-type="bibr" rid="bib108">Sprevak and Smith, 2023</xref>; <xref ref-type="bibr" rid="bib14">Clark, 2017</xref>; <xref ref-type="bibr" rid="bib56">Kwisthout et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Iglesias et al., 2013</xref>; <xref ref-type="bibr" rid="bib122">Yon and Frith, 2021</xref>). More precise prediction errors receive more weighting and therefore have greater influence on model updating processes. The precision weighting of prediction error signals may provide a mechanism for distinguishing between known and unknown sources of uncertainty, related to the inherent stochastic nature of a signal versus insufficient information on the part of the observer, respectively (<xref ref-type="bibr" rid="bib56">Kwisthout et al., 2017</xref>; <xref ref-type="bibr" rid="bib122">Yon and Frith, 2021</xref>; <xref ref-type="bibr" rid="bib86">Press et al., 2020</xref>). In Bayesian frameworks, information gain is fundamentally linked to prediction error, modulated by precision (<xref ref-type="bibr" rid="bib56">Kwisthout et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Iglesias et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Mathys et al., 2011</xref>; <xref ref-type="bibr" rid="bib121">Yanagisawa et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Kwisthout, 2017</xref>; <xref ref-type="bibr" rid="bib24">Dijkstra et al., 2025</xref>; <xref ref-type="bibr" rid="bib107">Smith et al., 2022</xref>; <xref ref-type="bibr" rid="bib114">van Lieshout et al., 2025</xref>; <xref ref-type="bibr" rid="bib10">Buckley et al., 2017</xref>). In non-hierarchical Bayesian models, information gain can be derived as a function of prediction errors and the precision of the prior and likelihood distributions, a relationship that can be approximately linear (<xref ref-type="bibr" rid="bib121">Yanagisawa et al., 2019</xref>). In hierarchical Bayesian inference, the update in beliefs (posterior mean changes) at each level is proportional to the precision-weighted prediction error; this update encodes the information gained from new observations (<xref ref-type="bibr" rid="bib56">Kwisthout et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Iglesias et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Mathys et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Kwisthout, 2017</xref>; <xref ref-type="bibr" rid="bib24">Dijkstra et al., 2025</xref>). Neuromodulatory arousal systems are well-situated to act as precision weighting mechanisms in line with predictive processing frameworks (<xref ref-type="bibr" rid="bib31">Friston, 2008</xref>; <xref ref-type="bibr" rid="bib72">Moran et al., 2013</xref>). Empirical evidence suggests that neuromodulatory systems broadcast <italic>precision-weighted</italic> prediction errors to cortical regions (<xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib39">Harris et al., 2022</xref>; <xref ref-type="bibr" rid="bib43">Iglesias et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Haarsma et al., 2021</xref>). Therefore, the hypothesis that feedback-locked pupil dilation reflects a prediction error signal is similarly in line with Zenon’s main claim that pupil dilation generally reflects information gain, through precision weighting of the prediction error. We expected a prediction error signal in pupil dilation to be proportional to the information gain.</p><p>Information gain can be operationalized within information theory as the Kullback-Leibler (KL) divergence between the posterior and prior belief distributions of a Bayesian observer, representing a formalized quantity that is used to update internal models (<xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">Modirshanechi et al., 2023</xref>; <xref ref-type="bibr" rid="bib85">Poli et al., 2024</xref>). <xref ref-type="bibr" rid="bib44">Itti and Baldi, 2005</xref> termed the KL divergence between posterior and prior belief distributions as ‘Bayesian surprise’ and showed a link to the allocation of attention. The KL divergence between posterior and prior belief distributions has been previously considered to be a proxy of (precision-weighted) prediction errors (<xref ref-type="bibr" rid="bib86">Press et al., 2020</xref>; <xref ref-type="bibr" rid="bib24">Dijkstra et al., 2025</xref>). According to Zénon’s hypothesis, if pupil dilation reflects information gain during the observation of an outcome event, such as feedback on decision accuracy, then pupil size will be expected to increase in proportion to how much novel sensory evidence is used to update current beliefs (<xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib124">Zénon, 2019</xref>). To our knowledge, there is a paucity of research on whether the pupil response is correlated with information gain, specifically focused on the interval following decision outcome/feedback presentation (<xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Fleischmann et al., 2025</xref>). Using a saccadic planning task, <xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref> found that pupil dilation scaled negatively with information gain following target onset. While a significant correlation between post-target pupil dilation and information gain was obtained, the direction of this result seems at odds with the hypothesis that an increase in information gain would lead to greater pupil dilation, an issue we will return to in the Discussion. In contrast, <xref ref-type="bibr" rid="bib29">Fleischmann et al., 2025</xref> reported a positive relationship between pupil dilation and information gain, which remained consistent across two auditory tasks requiring participants to predict either the temporal or spatial distributions of auditory sequences. Two other recent studies investigated a relationship between pupil dilation and information gain; however, the pupil dilation interval investigated occurred prior to information about decision outcome (<xref ref-type="bibr" rid="bib125">Zénon et al., 2024</xref>; <xref ref-type="bibr" rid="bib104">Shirama et al., 2024</xref>). <xref ref-type="bibr" rid="bib125">Zénon et al., 2024</xref> similarly found that larger pupil responses were associated with more information gain with respect to the first operand during an arithmetic sum of two numbers. Finally, <xref ref-type="bibr" rid="bib104">Shirama et al., 2024</xref> reported that the covariance between pupil and information gain depended on performance accuracy while participants predicted numbers in a changing environment. Specifically, in the low-performance group, pupil dilation positively tracked information gain. However, in the high-performance group, the direction was reversed. Taken together, there is evidence for both a positive and negative scaling between pupil dilation and information gain, depending on the task context and decision interval investigated.</p><p>The temporal dynamics of the relationship between the pupil response and information gain or prediction errors have not been consistently investigated. The temporal dynamics of prediction error signals in pupil dilation are likely informative because the brain’s process of updating internal models may contain an inherent temporal dimension (<xref ref-type="bibr" rid="bib80">Nienborg and Roelfsema, 2015</xref>). Different temporal components of the pupil signal may correspond to different stages of predictive processing, for instance, as proposed by the hybrid predictive coding model (<xref ref-type="bibr" rid="bib111">Tscshantz et al., 2023</xref>). These temporal dynamics can shed light on the mechanisms of predictive processing by clarifying the timing of learning updates in relation to feedback presentation (<xref ref-type="bibr" rid="bib96">Sales et al., 2019</xref>). The temporal dynamics of prediction error signals may also help differentiate between types of learning, indicate how attention and cognitive load are allocated during tasks, and implicate specific brain regions or neural processes involved in learning (<xref ref-type="bibr" rid="bib15">Colantonio et al., 2023</xref>; <xref ref-type="bibr" rid="bib109">Stemerding et al., 2022</xref>). Previous studies have shown different temporal response dynamics of prediction error signals in pupil dilation following feedback on decision outcome: While some studies suggest that the prediction error signals arise around the peak (~1 s) of the canonical impulse response function of the pupil (<xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib87">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib59">Lavín et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Cheadle et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">He et al., 2024</xref>; <xref ref-type="bibr" rid="bib12">Burlingham et al., 2022</xref>), other studies have shown evidence that prediction error signals (also) arise considerably later with respect to feedback on choice outcome (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib115">Van Slooten et al., 2018</xref>; <xref ref-type="bibr" rid="bib59">Lavín et al., 2013</xref>; <xref ref-type="bibr" rid="bib40">He et al., 2024</xref>). A relatively slower prediction error signal following feedback presentation may suggest deeper cognitive processing, increased cognitive load from sustained attention or ongoing uncertainty, or that the brain is integrating multiple sources of information before updating its internal model. Taken together, the literature on prediction error signals in pupil dilation following feedback on decision outcome does not converge to produce a consistent temporal signature. The specific time window analyzed across different tasks can affect whether a prediction error signal is detected at all. The emergence of consistent results is important for validating the pupil as a biomarker of prediction error, by facilitating comparative research, informing predictive models, uncovering neural mechanisms, as well as improving practical applications. Many factors could potentially explain these discrepant results, such as different task contexts (e.g. stimulus modality, reward-based learning, probabilistic learning vs. perceptual discrimination), different approaches to the pupil analyses such as using simple contrasts or model-based regression, and different interpretations of what constitutes a ‘prediction error’. Given these discrepancies, it is crucial to investigate the specific conditions under which pupil dilation reflects a (precision-weighted) prediction error.</p><sec id="s1-1"><title>Aims of the current study</title><p>The current study was motivated by Zénon’s hypothesis (<xref ref-type="bibr" rid="bib124">Zénon, 2019</xref>) concerning the relationship between pupil dilation and information gain, particularly in light of the varying sources of signal and noise introduced by task context and pupil dynamics. By demonstrating how task context can influence which signals are reflected in pupil dilation, and highlighting the importance of considering their temporal dynamics, we aim to promote a more nuanced and model-driven approach to cognitive research using pupillometry. The literature summarized above prompted us to investigate whether the pupil’s response to decision outcomes during learning aligns with a prediction error signal defined within an information-theoretic framework. While Zénon theoretically proposed a direct link between pupil dilation and information gain, this hypothesis has not been thoroughly tested in empirical studies. We sought to fill this gap in the literature and shed light on the relationship between information gain and uncertainty during learning as reflected in pupil dilation.</p><p>In the current study, we investigated whether the pupil’s response to decision outcome (i.e. feedback) in the context of associative learning reflects a prediction error as defined operationally as an interaction between stimulus-pair frequency and accuracy, while also exploring the time course of this prediction error signal. Thereafter, we tested whether these prediction error signals correlated with information gain, defined formally as the KL divergence between posterior and prior belief distributions of the ideal observer. We reasoned that information gain should be proportional to the (precision-weighted) prediction error signals potentially arising from neuromodulatory arousal networks. To do so, we adapted a simple model of trial-by-trial learning of stimulus probabilities based on information theory from previous literature (<xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib64">Mars et al., 2008</xref>; <xref ref-type="bibr" rid="bib84">Poli et al., 2020</xref>). For completeness, Shannon surprise and entropy were also computed and related to the post-feedback pupil response. We analyzed two independent datasets featuring distinct associative learning paradigms, one characterized by increasing entropy and the other by decreasing entropy as the tasks progressed. By examining these different tasks, we aimed to identify commonalities (if any) in the results across varying contexts. Additionally, the contrasting directions of entropy in the two tasks enabled us to disentangle the correlation between stimulus-pair frequency and information gain in the post-feedback pupil response.</p><p>In the first data set, participants were instructed to predict the upcoming orientation (left vs. right) of a visual target based on the probability of visual and auditory cues. In the second data set, participants were first exposed to letter-color pairs of stimuli in different frequency conditions during an odd-ball detection task. The letter-color pair contingencies were irrelevant to the odd-ball task performance. The participants subsequently completed a decision-making task in which they had to decide which letter was presented together most often with which color during the previous odd-ball detection task (match vs. no match). Pupil dilation was recorded during the decision-making tasks in both data sets, and the post-feedback pupil response was the event of interest. We did not formally compare the results across the two data sets given substantial differences between these two task contexts. We expected the post-feedback pupil dilation to scale with information gain in both tasks in a relatively early time window, following the results of O’Reilly et al. We explored whether later prediction error components in the post-feedback pupil dilation might reflect other information-theoretic variables, such as Shannon surprise or entropy.</p><p>To preview, the results show for the first time that whether the pupil dilates or constricts along with information gain was context dependent. Our findings are overall in line with Zénon’s hypothesis that pupil dilation reflects information-theoretic processing and furthermore suggest that these signatures in pupil dilation are complex and multifaceted. This study provides empirical evidence that the pupil’s response can shed light on model updating during learning, demonstrating the potential of this easily measured physiological indicator for exploring internal belief states.</p></sec></sec><sec id="s2" sec-type="results"><title>Results</title><p>The current study aimed to investigate whether the pupil’s response to decision outcome in the context of associative learning reflects a prediction error (defined operationally as an interaction between stimulus-pair frequency and accuracy) and whether these prediction error signals correlate with information gain. In two independent data sets, the frequency of pairs of stimuli was modulated in different conditions to induce a gradient of uncertain states (associative learning) upon which the participants had to make decisions. Within each data set, we inspected task performance, the evoked pupil time course, and the averaged pupil response in an early as compared with a late time window. A signed prediction error was defined as the interaction between stimulus-pair frequency and performance accuracy averaged across conditions. Finally, we tested the linear relationship between the post-feedback pupil response and information gain in two ways: a trial-by-trial correlation analysis across the pupil time course and a complementary linear mixed model analysis within each time window of interest.</p><sec id="s2-1"><title>Results from the cue-target 2AFC task (data set #1)</title><p>While pupil dilation was recorded, participants predicted the orientation (left or right) of the upcoming target stimulus (Gabor patch) based on the visual and/or auditory cues (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The target stimulus served as the feedback event of interest and was always presented after the participants made a prediction of the upcoming orientation of a Gabor patch by button press with the corresponding finger on the left or right hand. Dependent variables of interest were response accuracy, RT, and feedback-locked pupil response. Note that the results of the statistical tests are reported in the figure alongside the data illustrations (see <xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Data set #1: Cue-target 2AFC task and results.</title><p>(<bold>A</bold>) Events during a single trial. While pupil dilation was recorded, participants predicted the orientation (left/right) of the upcoming target (Gabor patch) based on the visual and/or auditory cues (in the data analyzed here, only the visual cue had predictive validity). Predictions were given by a button press with the corresponding finger on the left or right hand. Two mapping conditions (condition 1 or condition 2) were counterbalanced across participants such that a participant in condition 1 was shown the square cue followed by a left-oriented target on 80% of the trials, while the square cue was followed by a right-oriented target on 20% of the trials. A gray box indicates the feedback event of interest. (<bold>B</bold>) Accuracy (fraction of correct responses) as a function of cue-target frequency. Data points are individual participants; stats, paired-samples Wilcoxon signed-rank t-test. (<bold>C</bold>) RT as a function of both cue-target frequency and accuracy (error/correct); stats, repeated-measures ANOVA. (<bold>D</bold>) Feedback-locked pupil response time course, plotted as a function of cue-target frequency and accuracy. Shading represents the standard error of the mean across participants (N = 24) . Light gray boxes, time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. The black horizontal bar indicates a significant interaction term (cluster-corrected, permutation test). (<bold>E</bold>) Early time window, average feedback-locked pupil response as a function of cue-target frequency and accuracy; stats, repeated-measures ANOVA. (<bold>F</bold>) As <italic>E</italic>, for the late time window. ANOVA results (multiple panels): top, main effect of frequency; middle, main effect of accuracy; bottom, frequency x accuracy interaction. Error bars, standard error of the mean across participants (N = 24). *p &lt; 0.05, **p &lt; 0.01, *** p &lt; 0.001.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Processed behavioral and pupil data used to generate the main results figure for the cue-target 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-fig1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Main effects of frequency and accuracy in the feedback-locked pupil time courses from the cue-target 2AFC task.</title><p>(<bold>A</bold>) Mean feedback-locked pupil response across all trials. (<bold>B</bold>) Feedback-locked pupil response time course plotted as a function of accuracy. (<bold>C</bold>) Feedback-locked pupil response time course plotted as a function of stimulus-pair frequency. Gray boxes, time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. Shading represents the standard error of the mean across participants (N = 24) . The black horizontal bars indicate a significant effect of interest (cluster-corrected using permutation tests).</p><p><supplementary-material id="fig1s1sdata1"><label>Figure 1—figure supplement 1—source data 1.</label><caption><title>Processed pupil data used to generate the figure supplement showing main effects of frequency and accuracy in the feedback-locked pupil time courses from the cue-target 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-fig1-figsupp1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-fig1-figsupp1-v1.tif"/></fig></fig-group><sec id="s2-1-1"><title>Behavioral performance</title><p>We evaluated the behavioral performance of the participants on the cue-target 2AFC task (data set #1). On average, participants were more accurate on the trials in the 80% condition as compared with the 20% condition tested with a Wilcoxon signed-rank t-test (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Notably, the average accuracy within these two frequency conditions approximated the frequency itself but with substantial individual differences across the sample (see individual lines in <xref ref-type="fig" rid="fig1">Figure 1B</xref>). An interaction between frequency condition and accuracy was obtained in RT tested with a two-way repeated-measures ANOVA (<xref ref-type="fig" rid="fig1">Figure 1C</xref>): post-hoc t-tests showed that participants were faster to respond on correct trials as compared with incorrect trials in the 80% condition, while in contrast, participants were slower to respond on correct trials as compared with incorrect trials for the 20% condition. We note that it was impossible for participants to determine from the cues whether the trial was in the 80% or 20% condition at the time when responses were given. Average RTs did not differ between frequency or accuracy conditions overall as indicated by a lack of main effects in the two-way ANOVA (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p></sec><sec id="s2-1-2"><title>Comparing the feedback-locked pupil response between time windows</title><p>We were interested in evaluating the pupil’s response to the feedback event: in the cue-target 2AFC task, feedback occurred with the presentation of the target stimulus following the prediction given by the participant with a button press. The pupil response time course locked to the onset of the target stimulus is shown in <xref ref-type="fig" rid="fig1">Figure 1D</xref> (gray boxes indicate the early and late time windows of interest) with the four conditions of interest defined by the two-way interaction between stimulus-pair frequency and accuracy plotted separately for the 3 s interval of target presentation. A significant interaction between frequency and accuracy emerged later in the trial around 2 s and was sustained until the next trial occurred (3 s; the black bar in <xref ref-type="fig" rid="fig1">Figure 1D</xref> refers to significant time points based on the cluster-based permutation test). The feedback-locked pupil response time courses are plotted for the main effects of stimulus-pair frequency and accuracy (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A–C</xref>).</p><p>We formally tested for a difference on the average feedback-locked pupil response within the early as compared with late time windows in a three-way repeated-measures ANOVA with factors: time window (levels: early vs. late), frequency (levels: 20% vs. 80%), and accuracy (levels: error vs. correct). The results of the three-way repeated-measures ANOVA are presented in <xref ref-type="table" rid="table1">Table 1</xref>. Main effects of time window and frequency were obtained, in addition to a three-way interaction between the time window, frequency, and accuracy factors.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Results of the three-way repeated-measures ANOVA on the feedback-locked pupil response in the cue-target 2AFC task (data set #1).</title><p>The three-way repeated-measures ANOVA included factors: time window (levels: early vs. late), frequency (levels: 20% vs. 80%), and accuracy (levels: error vs. correct).</p><p><supplementary-material id="table1sdata1"><label>Table 1—source data 1.</label><caption><title>Processed behavioral data from the cue-target 2AFC task used for the three-way repeated-measures ANOVA included factors: time window (levels: early vs. late), frequency (levels: 20% vs. 80%), and accuracy (levels: error vs. correct).</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-table1-data1-v1.xlsx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Factor</th><th align="left" valign="top">F(1,23)</th><th align="left" valign="top">p</th><th align="left" valign="top">η²<sub>G</sub></th></tr></thead><tbody><tr><td align="left" valign="top">Time window</td><td align="left" valign="top">7.52</td><td align="left" valign="top"><bold>0.012</bold></td><td align="left" valign="top">0.05</td></tr><tr><td align="left" valign="top">Frequency</td><td align="left" valign="top">9.79</td><td align="left" valign="top"><bold>0.005</bold></td><td align="left" valign="top">0.04</td></tr><tr><td align="left" valign="top">Accuracy</td><td align="left" valign="top">2.67</td><td align="left" valign="top">0.116</td><td align="left" valign="top">0.01</td></tr><tr><td align="left" valign="top">Time window x frequency</td><td align="left" valign="top">0.25</td><td align="left" valign="top">0.621</td><td align="left" valign="top">&lt;0.01</td></tr><tr><td align="left" valign="top">Time window x accuracy</td><td align="left" valign="top">0.26</td><td align="left" valign="top">0.614</td><td align="left" valign="top">&lt;0.01</td></tr><tr><td align="left" valign="top">Frequency x accuracy</td><td align="left" valign="top">3.45</td><td align="left" valign="top">0.076</td><td align="left" valign="top">0.02</td></tr><tr><td align="left" valign="top">Time window x frequency x accuracy</td><td align="left" valign="top">24.97</td><td align="left" valign="top"><bold>&lt;0.001</bold></td><td align="left" valign="top">0.02</td></tr></tbody></table></table-wrap><p>To break down the three-way interaction, the two-way interactions between stimulus-pair frequency and accuracy were tested in independent repeated-measures ANOVAs for the early and late time window (see <xref ref-type="fig" rid="fig1">Figure 1E and F</xref>, respectively). As suggested from the time course analysis (see <xref ref-type="fig" rid="fig1">Figure 1D</xref>), frequency and accuracy did not interact for the average feedback-locked pupil response within the early time window (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). In contrast, the interaction between frequency and accuracy was significant for the average feedback-locked pupil response within the late time window (<xref ref-type="fig" rid="fig1">Figure 1F</xref>): post-hoc t-tests showed that the error trials drove the two-way interaction between frequency and accuracy such that pupils dilated more for error trials as compared with correct trials only in the 20% frequency condition; pupils also dilated more during errors in the 20% frequency condition than errors in the 80% condition. Taken together, the data suggest that the post-feedback pupil response may reflect unsigned prediction errors in the early time window and signed prediction errors in the late time window in the cue-target 2AFC task.</p><p>For both the early and late time windows, a main effect of frequency was obtained in each two-way ANOVA, while no main effect of accuracy was evident (see <xref ref-type="fig" rid="fig1">Figure 1E and F</xref>). Post-hoc t-tests showed that pupils dilated on average more for the 20% frequency condition (<italic>M</italic> = 0.57%, SE = 0.45) as compared with the 80% frequency condition (<italic>M</italic> = –0.49%, SE = 0.31) for the early time window. The frequency effect was in the same direction in the late time window, with larger pupil dilation for the 20% frequency condition (<italic>M</italic> = –0.61%, SE = 0.51) as compared with the 80% frequency condition (<italic>M</italic> = –1.46%, SE = 0.36). Larger pupil dilation in response to errors as compared with correct trials is a consistently reported effect in the literature (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Braem et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Critchley et al., 2005</xref>; <xref ref-type="bibr" rid="bib63">Maier et al., 2019</xref>; <xref ref-type="bibr" rid="bib76">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib94">Rondeel et al., 2015</xref>; <xref ref-type="bibr" rid="bib118">Wessel et al., 2011</xref>); therefore, it is worth noting here that accuracy and frequency were highly correlated in the cue-target 2AFC task (see <xref ref-type="fig" rid="fig1">Figure 1B</xref>), which could explain the lack of a main effect of accuracy obtained here. This is further illustrated by comparing the ‘Error’ time course (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>) with the ‘20%’ time course (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). Likewise, compare the ‘Correct’ time course (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>) with the ‘80%’ time course (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). We note that within the early time window, the frequency effect in accuracy scaled with the frequency effect in the post-feedback pupil dilation across individual participants tested with a Spearman correction. Participants who showed a larger mean difference between the 80% as compared with the 20% frequency conditions in accuracy also showed smaller differences (a larger mean difference in magnitude in the negative direction) in pupil responses between frequency conditions (see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). This monotonic relationship between the frequency effect in accuracy and post-feedback pupil response indicates that the improvement in accuracy (as measured behaviorally) across trials was also reflected in the change in pupil dilation.</p></sec></sec><sec id="s2-2"><title>Results from the letter-color 2AFC task (data set #2)</title><p>While pupil dilation was recorded, participants were administered a letter-color decision 2AFC task: participants indicated whether each letter presented ‘matched’ the subsequently presented colored square with a button press (<xref ref-type="fig" rid="fig2">Figure 2A</xref>; right-hand side). A match was correct when the letter and color had occurred most often together in the preceding odd-ball detection task. Dependent variables of interest were response accuracy, RT, and feedback-locked pupil response. Note that the results of the statistical tests are reported in the figure alongside the data illustrations (see <xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Data set #2: Letter-color 2AFC task and results.</title><p>(<bold>A</bold>) <italic>Left</italic>, an independent learning phase was administered in the form of an odd-ball detection task during which six letters together with six shades of green colors as background (squares) were presented in three frequency conditions (33%, 50%, and 84%) on most trials (91%). Participants had to quickly respond to odd-ball targets (numbers and/or non-green color, 9% of trials). Letter-color mapping conditions were randomized per participant. <italic>Right</italic>, events during a single trial of the subsequent letter-color decision 2AFC task. While pupil dilation was recorded, participants indicated whether the letter “matched” the colored square with a button press. A match was correct when the letter and color had occurred most often together in the preceding odd-ball task. A gray box indicates the feedback event of interest. (<bold>B</bold>) Accuracy (fraction of correct responses) as a function of letter-color frequency. Dashed line represents chance level. Data points are individual participants; stats, repeated-measures ANOVA. (<bold>C</bold>) RT as a function of both letter-color frequency and accuracy; stats, repeated-measures ANOVA. (<bold>D</bold>) Feedback-locked pupil response time course, plotted as a function of letter-color frequency and accuracy. Shading represents the across participants of the mean (N = 47). Dark gray box, duration of the auditory feedback stimulus (0.3 s). Light gray boxes, time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. The purple horizontal bar indicates a significant two-way interaction effect (uncorrected for multiple comparisons). No significant time points remained after correction using the false discovery rate (FDR). (<bold>E</bold>) Early time window, average feedback-locked pupil response as a function of letter-color frequency and accuracy; stats, repeated-measures ANOVA (<bold>F</bold>) As <italic>E</italic>, for the late time window. ANOVA results (multiple panels): top, main effect of frequency; middle, main effect of accuracy; bottom, frequency x accuracy interaction. Error bars, standard error of the mean across participants (N = 47). *p &lt; 0.05, **p &lt; 0.01, *** p &lt; 0.001.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Processed behavioral and pupil data used to generate the main results figure for the letter-color 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-fig2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Main effects of frequency and accuracy in the feedback-locked pupil time courses from the letter-color 2AFC task.</title><p>(<bold>A</bold>) Mean feedback-locked pupil response across all trials. (<bold>B</bold>) Feedback-locked pupil response time course plotted as a function of accuracy. (<bold>C</bold>) Feedback-locked pupil response time course plotted as a function of stimulus-pair frequency. Gray boxes, time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. Shading represents the standard error of the mean across participants (N = 47). The black horizontal bars indicate a significant effect of interest (panels A and B were cluster-corrected using permutation tests; panel C, a one-way repeated-measures ANOVA was conducted on each time point and corrected for multiple comparisons with the false discovery rate).</p><p><supplementary-material id="fig2s1sdata1"><label>Figure 2—figure supplement 1—source data 1.</label><caption><title>Processed pupil data used to generate the figure supplement showing main effects of frequency and accuracy in the feedback-locked pupil time courses from the letter-color 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-fig2-figsupp1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-fig2-figsupp1-v1.tif"/></fig></fig-group><sec id="s2-2-1"><title>Behavioral performance during the odd-ball detection task</title><p>The odd-ball detection task served as an independent learning phase for the letter-color pairs. Participants performed the task as expected: accuracy was lower in identifying trials with an odd-ball present (<italic>M</italic> = 84.0%, SD = 9.9) as compared to regular trials (<italic>M</italic> = 99.8%, SD = 0.3; t<sub>46</sub> = 11.04, p &lt; 0.001, <italic>d</italic> = 1.61). Likewise, RTs were slower for trials with an odd-ball present (<italic>M</italic> = 0.49 s, SD = 0.01) as compared to regular trials (<italic>M</italic> = 0.42, SD = 0.01; t<sub>46</sub> = 16.53, p &lt; 0.001, <italic>d</italic> = 2.41).</p></sec><sec id="s2-2-2"><title>Behavioral performance on the letter-color 2AFC task</title><p>We evaluated the behavioral performance of the participants on the letter-color 2AFC task (data set #2). During the letter-color 2AFC task, participants could accurately indicate whether a letter was presented most often with a given color in the preceding odd-ball detection task: response accuracy (around 80%) was higher than chance level (50%) in each of the three stimulus-pair frequency conditions on average (see bars in <xref ref-type="fig" rid="fig2">Figure 2B</xref>). This was also true for most participants (see individual lines in <xref ref-type="fig" rid="fig2">Figure 2B</xref>); however, neither accuracy (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) nor RTs (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) differed across the frequency conditions tested with repeated-measures ANOVAs (levels: 33%, 50%, and 84%). A main effect of accuracy as well as an interaction between frequency condition and accuracy was obtained in RT tested in a two-way repeated-measures ANOVA (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Post-hoc t-tests showed that participants were slower on error trials (<italic>M</italic> = 0.97 s, SE = 0.04) as compared with correct trials (<italic>M</italic> = 0.72 s, SE = 0.03). Breaking down the interaction in RT, post-hoc t-tests indicated that the accuracy difference between correct and error trials in the 50% frequency condition (<italic>M</italic> = 0.18 s, SE = 0.03) was significantly smaller as compared with that for the 33% frequency condition (<italic>M</italic> = 0.27 s, SE = 0.04; <italic>z</italic> = –2.15, p = 0.031, r<sub>rb</sub> = 0.36) as well as the 84% frequency condition (<italic>M</italic> = 0.28 s, SE = 0.04; <italic>z</italic> = –2.55, p = 0.010, r<sub>rb</sub> = –0.43), while the accuracy difference between the 33% and 84% frequency conditions did not differ on average (<italic>z</italic> = –0.78, p = 0.440, r<sub>rb</sub> = –0.13).</p></sec><sec id="s2-2-3"><title>Comparing the feedback-locked pupil response between time windows</title><p>We were interested in evaluating the pupil’s response to the feedback event: in the letter-color 2AFC task, explicit feedback was administered on each trial in the form of an auditory tone (error vs. correct) following the prediction given by the participant with a button press. The pupil response time course locked to the onset of the auditory feedback stimulus is shown in <xref ref-type="fig" rid="fig2">Figure 2D</xref> (gray boxes indicated the early and late time windows of interest) with the six conditions of interest defined by the two-way interaction between stimulus-pair frequency and accuracy plotted separately for a 3 s post-feedback interval. A two-way repeated-measures ANOVA was computed independently for each time point in the feedback-locked pupil time course in <xref ref-type="fig" rid="fig2">Figure 2D</xref>. Clusters indicating an interaction between frequency and accuracy emerged at three distinct time points, but none of these clusters survived corrections for multiple comparisons using the False Discovery Rate (see purple bar, <xref ref-type="fig" rid="fig2">Figure 2D</xref>). The feedback-locked pupil response time courses are plotted for the main effects of stimulus-pair frequency and accuracy (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Using cluster-based permutation tests, we found that a robust main effect of accuracy spanned the early time window (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>), while no main effect of frequency was obtained at any time points (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C</xref>).</p><p>We formally tested for a difference in the average feedback locked pupil response averaged within the early as compared with late time windows in a three-way repeated-measures ANOVA with factors: time window (levels: early vs. late), frequency (levels: 33%, 50%, and 84%) and accuracy (levels: error vs. correct). The results of the three-way repeated-measures ANOVA are presented in <xref ref-type="table" rid="table2">Table 2</xref>. Main effects of time window and accuracy were obtained. The two-way interactions between time window and accuracy as well as frequency and accuracy were obtained. The three-way interaction between the time window, frequency, and accuracy factors was not significant.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Results of the three-way repeated-measures ANOVA on the feedback-locked pupil response in the letter-color 2AFC task (data set #2).</title><p>The three-way repeated-measures ANOVA included factors: time window (levels: early vs. late), frequency (levels: 33%, 50%, and 84%), and accuracy (levels: error vs. correct). Greenhouse-Geisser statistics are reported when assumptions of sphericity were violated.</p><p><supplementary-material id="table2sdata1"><label>Table 2—source data 1.</label><caption><title>Processed behavioral data from the letter-color 2AFC task used for the three-way repeated-measures ANOVA included factors: time window (levels: early vs. late), frequency (levels: 20% vs. 80%), and accuracy (levels: error vs. correct).</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-table2-data1-v1.xlsx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Factor</th><th align="left" valign="top">df</th><th align="left" valign="top">F</th><th align="left" valign="top">p</th><th align="left" valign="top">η²<sub>G</sub></th></tr></thead><tbody><tr><td align="left" valign="top">Time window</td><td align="left" valign="top">(1, 46)</td><td align="left" valign="top">130.16</td><td align="left" valign="top"><bold>&lt;0.001</bold></td><td align="left" valign="top">0.23</td></tr><tr><td align="left" valign="top">Frequency</td><td align="left" valign="top">(1.639, 75.415)</td><td align="left" valign="top">2.11</td><td align="left" valign="top">0.137</td><td align="left" valign="top">0.01</td></tr><tr><td align="left" valign="top">Accuracy</td><td align="left" valign="top">(1, 46)</td><td align="left" valign="top">4.76</td><td align="left" valign="top"><bold>0.034</bold></td><td align="left" valign="top">0.01</td></tr><tr><td align="left" valign="top">Time window x frequency</td><td align="left" valign="top">(2, 92)</td><td align="left" valign="top">0.22</td><td align="left" valign="top">0.806</td><td align="left" valign="top">&lt;0.01</td></tr><tr><td align="left" valign="top">Time window x accuracy</td><td align="left" valign="top">(1, 46)</td><td align="left" valign="top">61.11</td><td align="left" valign="top"><bold>&lt;0.001</bold></td><td align="left" valign="top">0.06</td></tr><tr><td align="left" valign="top">Frequency x accuracy</td><td align="left" valign="top">(1.480, 68.095)</td><td align="left" valign="top">3.91</td><td align="left" valign="top"><bold>0.036</bold></td><td align="left" valign="top">0.02</td></tr><tr><td align="left" valign="top">Time window x frequency x accuracy</td><td align="left" valign="top">(2, 92)</td><td align="left" valign="top">1.05</td><td align="left" valign="top">0.354</td><td align="left" valign="top">&lt;0.01</td></tr></tbody></table></table-wrap><p>We continued with a post-hoc exploration of the two-way interactions between stimulus-pair frequency (levels: 33%, 50%, 84%) and accuracy (levels: error vs. correct) by testing separate repeated-measures ANOVAs for the early and late time window given our a priori hypotheses about the nature of the three-way interaction. In the early time window, the two-way interaction between frequency and accuracy was obtained for the average feedback-locked pupil response (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). To break down this two-way interaction between frequency and accuracy in the early time window (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), we compared the difference between error as compared with correct trials across each pair of frequency conditions using t-tests: the accuracy difference in the 33% frequency condition (<italic>M</italic> = 1.46%, SE = 0.45) was significantly smaller as compared with that for the 50% frequency condition (<italic>M</italic> = 3.38%, SE = 0.43; <italic>z</italic> = –2.94, p = 0.003, r<sub>rb</sub> = –0.49) as well as the 84% frequency condition (<italic>M</italic> = 3.66%, SE = 0.74; <italic>z</italic> = –2.32, p = 0.020, r<sub>rb</sub> = –0.39), while the accuracy difference between the 50% and 84% frequency conditions did not differ on average (<italic>z</italic> = 0.65, p = 0.525, r<sub>rb</sub> = 0.11). In the late time window, only a trend towards an interaction between frequency and accuracy was evident (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). In both the early and late time windows, the two-way ANOVAs showed that a main effect of accuracy was obtained for the average feedback-locked pupil responses while no main effect of frequency was obtained. Interestingly, the direction of this main effect of accuracy differed per time window indicated by post-hoc t-tests (compare <xref ref-type="fig" rid="fig2">Figure 2F</xref> with <xref ref-type="fig" rid="fig2">Figure 2G</xref>): In the early time window, pupil dilation was larger on average for error trials (<italic>M</italic> = 5.01%, SE = 0.39) as compared with correct trials (<italic>M</italic> = 2.21%, SE = 0.23), while this effect reversed in direction during the late time window with larger pupil dilation for correct trials (<italic>M</italic> = 0.07%, SE = 0.26) as compared with error trials (<italic>M</italic> = –1.09%, SE = 0.55). Taken together, the data suggest that the post-feedback pupil response may reflect signed prediction errors, albeit more strongly within the early as compared with late time window; most striking is the fact that the direction of this interaction reversed across these time intervals.</p><p>In the letter-color 2AFC task, no scaling was evident between the frequency effect in accuracy and the frequency effect in the post-feedback pupil dilation across individual participants tested with a Spearman correlation (see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). In contrast to the cue-target 2AFC task, no relationship between behaviorally accuracy measures and changes in pupil dilation was obtained in the letter-color 2AFC task.</p></sec></sec><sec id="s2-3"><title>Ideal learner model fits to feedback-locked pupil response</title><p>The ideal learner model used the stimulus information on each trial to estimate the information gain, surprise, and entropy during each of the decision-making tasks (see Materials and methods for further details). We fit the feedback-locked pupil response to the resulting model parameters in two complementary analyses: First, the relationship between the ideal learner models and the post-feedback pupil response was assessed by a correlation analysis (see <xref ref-type="fig" rid="fig3">Figure 3</xref> showing the average correlation coefficients across participants). Each time point in the pupil time course was correlated to each of the theoretic variables independently to see which signal the feedback-locked pupil response may be reflecting (if any) and furthermore to see how these patterns developed over time (within the 0–3 s window following feedback). Second, two linear (mixed) models were compared to see which combination of predictor variables best explained the feedback-locked pupil response while accounting for shared variance between predictor variables (see <xref ref-type="table" rid="app2table1 app2table2">Appendix 2—tables 1 and 2</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Correlations between the feedback-locked pupil response time course and the information-theoretic variables.</title><p><italic>Left column</italic>, results for the cue-target 2AFC task. <italic>Right column</italic>, results for the letter-color 2AFC task. (<bold>A</bold>) The information gain, surprise, and entropy parameters are shown as a function of task trial. Model parameter units are in bits. (<bold>B</bold>) The mean information gain, surprise, and entropy parameters are shown as a function of frequency condition. (<bold>C</bold>) Average trial-by-trial correlations at the group level between the ideal learner model parameters (information gain, surprise, and entropy) at each time point in the feedback-locked pupil response. (<bold>D</bold>) Average trial-by-trial correlations at the group level between the information gain parameter and the feedback-locked pupil response separately for the error and correct trials. (<bold>E</bold>) As <italic>D</italic>, for the surprise parameter. (<bold>F</bold>) As <italic>D</italic>, for the entropy parameter. (<bold>G–L</bold>) As <italic>A-F</italic> for the letter-color 2AFC task. (<bold>C–L</bold>) Shading represents the standard error of the mean across participants (cue-target 2AFC task: N = 24; letter-color 2AFC task: N = 47). Light gray boxes, time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. The colored horizontal bars indicate time periods of significant correlation coefficients tested against zero for each model parameter or condition of interest (cluster-corrected, permutation test). The black horizontal bar indicates a difference between conditions (cluster-corrected, permutation test).</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Ideal learner model parameters and correlations between the feedback-locked pupil response time course and the information-theoretic variables (both tasks).</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-fig3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Correlations between the feedback-locked pupil response time course and the information-theoretic variables using a uniform prior distribution in the letter-color 2AFC task.</title><p>(<bold>A</bold>) The information gain, surprise, and entropy parameters are shown as a function of task trial. Model parameter units are in bits. (<bold>B</bold>) The mean information gain, surprise, and entropy parameters are shown as a function of frequency condition. (<bold>C</bold>) Average trial-by-trial correlations at the group level between the ideal learner model parameters (information gain, surprise, and entropy) at each time point in the feedback-locked pupil response. (<bold>D</bold>) Average trial-by-trial correlations at the group level between the information gain parameter and the feedback-locked pupil response separately for the error and correct trials. (<bold>E</bold>) As <italic>D</italic>, for the surprise parameter. (<bold>F</bold>) As <italic>D</italic>, for the entropy parameter. (<bold>C–F</bold>) Shading represents the standard error of the mean across participants (N = 47). Gray boxes, time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. The colored horizontal bars indicate time periods of significant correlation coefficients tested against zero for each model parameter or condition of interest (cluster-corrected, permutation test). No differences between error and correct trials were obtained (cluster-corrected, permutation test).</p><p><supplementary-material id="fig3s1sdata1"><label>Figure 3—figure supplement 1—source data 1.</label><caption><title>Ideal learner model parameters and correlations between the feedback-locked pupil response time course and the information-theoretic variables using a uniform prior distribution in the letter-color 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-fig3-figsupp1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-fig3-figsupp1-v1.tif"/></fig></fig-group><sec id="s2-3-1"><title>Ideal learner model fits for the cue-target 2AFC task: correlation analysis</title><p>The information-theoretic variables are shown as a function of task trial in <xref ref-type="fig" rid="fig3">Figure 3A</xref> and as a function of stimulus-pair frequency in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. Multicollinearity was assessed by the correlations between the model parameters (information gain vs. surprise: <italic>r</italic> = 0.09, p &lt; 0.001; information gain vs. entropy: <italic>r</italic> = 0.36, p &lt; 0.001; surprise vs. entropy: <italic>r</italic> = 0.17, p &lt; 0.001). We independently evaluated the trial-by-trial correlations between the information-theoretic variables and the post-feedback pupil response during the cue-target 2AFC task to investigate the variance explained by each of the three model parameters. The time course of the resulting correlation coefficients showed a pattern in which the pupil scaled negatively with information gain almost immediately after feedback onset until about 1 s into the feedback interval extending into the early time window (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, purple line). The post-feedback pupil response also scaled with surprise starting around 0.5 s with respect to feedback onset and lasted throughout the duration of the feedback interval, notably spanning both the early and late time windows (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, teal line). No scaling between the post-feedback pupil response and entropy was obtained.</p><p>Note that this trial-by-trial analysis considers both error and correct trials simultaneously and is therefore not sensitive to the actual behavioral performance of each participant. To see whether the correlation between the information-theoretic variables and pupil response differed as a function of behavioral performance, we repeated the same correlation analysis of the model parameters to the feedback-locked pupil response separately for error and correct trials. Results showed that the post-feedback pupil response during correct trials scaled negatively with information gain from feedback onset until 1 s within the feedback interval (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, blue line). The correlation between surprise and the feedback-locked pupil response for the error and correct trials diverged around 1.75 s with respect to feedback onset, and this difference persisted into the late time window (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, black line). This suggests that Shannon surprise might be linked to the signed prediction errors (defined by the interaction between accuracy and stimulus-pair frequency) evident in the late time window of the cue-target 2AFC task. No scaling between the post-feedback pupil response and entropy was obtained for either correct or error trials (<xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p></sec><sec id="s2-3-2"><title>Ideal learner model fits for the cue-target 2AFC task: linear mixed model analysis</title><p>The correlation analysis described above did not account for shared variance between model parameters. Therefore, to assess the unique variance explained by each of the model parameters during the cue-target 2AFC task, we compared two linear mixed models with the feedback-locked pupil response as the dependent variable (see Materials and methods section for further details). The model comparison was performed independently for the early and late time windows. For the cue-target 2AFC task, Model 1 performed significantly better than Model 2 for both the early (<italic>R<sup>2</sup></italic> = 0.29, σ = 4.28) and late time window (<italic>R<sup>2</sup></italic> = 0.38, σ = 5.74; see <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref> for the model comparison results), indicating that the inclusion of an interaction term between information gain and entropy did not lead to a better model fit of the post-feedback pupil response. The parameters of Model 1 are presented in <xref ref-type="table" rid="table3">Table 3</xref>. The linear mixed model analysis corroborated the correlation analysis: in the early time window, the predictor variables of surprise and information gain explained significant variance in the feedback-locked pupil response, while in the late time window, only the surprise predictor was significant. As expected, the pre-feedback baseline pupil dilation explained a significant amount of variance in the feedback-locked pupil response in both time windows. RT, however, did not explain significant variance in either time window.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Linear mixed model results for the cue-target 2AFC task.</title><p>Explanation of abbreviations, rows: <italic>I</italic>, Shannon surprise predictor variable; <italic>H</italic>, entropy; <italic>D<sub>KL</sub></italic>, information gain; <italic>Baseline</italic>, pre-feedback baseline pupil dilation; <italic>RT</italic>, reaction times. Columns: <italic>95% CI</italic>, the 95% credible interval of the median posterior distribution; <italic>pd</italic>, the probability (in percentage) of direction; <italic>ESS</italic>, effective sample size; *indicates strong evidence that the parameter has a positive/negative effect on the post-feedback pupil response.</p><p><supplementary-material id="table3sdata1"><label>Table 3—source data 1.</label><caption><title>Processed data input into the linear mixed modeling analysis for the cue-target 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-table3-data1-v1.xlsx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom" colspan="11">Cue-target 2AFC task</th></tr></thead><tbody><tr><td align="left" valign="middle"/><td align="left" valign="bottom" colspan="5">Early time window</td><td align="left" valign="middle"/><td align="left" valign="bottom" colspan="5">Late time window</td></tr><tr><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td></tr><tr><td align="left" valign="middle" rowspan="6">All trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">–3.06</td><td align="left" valign="bottom">[–7.15, 0.93]</td><td align="left" valign="bottom">93.45</td><td align="left" valign="bottom">17,486</td><td align="left" valign="middle" rowspan="6">All trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">1.02</td><td align="left" valign="bottom">[–4.42, 6.48]</td><td align="left" valign="bottom">64.35</td><td align="left" valign="bottom">23,656</td></tr><tr><td align="left" valign="bottom">I</td><td align="left" valign="bottom">0.56</td><td align="left" valign="bottom">[0.41, 0.71]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">23,950</td><td align="left" valign="bottom">I</td><td align="left" valign="bottom">0.58</td><td align="left" valign="bottom">[0.37, 0.79]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">30,658</td></tr><tr><td align="left" valign="bottom">H</td><td align="left" valign="bottom">1.09</td><td align="left" valign="bottom">[–1.23, 3.44]</td><td align="left" valign="bottom">82.45</td><td align="left" valign="bottom">18,259</td><td align="left" valign="bottom">H</td><td align="left" valign="bottom">–1.68</td><td align="left" valign="bottom">[–4.85, 1.49]</td><td align="left" valign="bottom">84.90</td><td align="left" valign="bottom">24,213</td></tr><tr><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">–13.13</td><td align="left" valign="bottom">[-21.48,–4.84]*</td><td align="left" valign="bottom">99.90</td><td align="left" valign="bottom">20,134</td><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">0.49</td><td align="left" valign="bottom">[–10.83, 11.90]</td><td align="left" valign="bottom">53.39</td><td align="left" valign="bottom">29,994</td></tr><tr><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.4</td><td align="left" valign="bottom">[-0.42,–0.38]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">24,410</td><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.71</td><td align="left" valign="bottom">[-0.74,–0.68]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">35,733</td></tr><tr><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">0.02</td><td align="left" valign="bottom">[–0.17, 0.21]</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">23,370</td><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">0.17</td><td align="left" valign="bottom">[–0.09, 0.42]</td><td align="left" valign="bottom">89.89</td><td align="left" valign="bottom">31,833</td></tr><tr><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td></tr><tr><td align="left" valign="middle" rowspan="6">Correct trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">–2.39</td><td align="left" valign="bottom">[–7.43, 2.67]</td><td align="left" valign="bottom">82.29</td><td align="left" valign="bottom">25,551</td><td align="left" valign="middle" rowspan="6">Correct trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">–2.79</td><td align="left" valign="bottom">[–9.75, 4.31]</td><td align="left" valign="bottom">78.18</td><td align="left" valign="bottom">25,261</td></tr><tr><td align="left" valign="bottom">I</td><td align="left" valign="bottom">0.57</td><td align="left" valign="bottom">[0.21, 0.93]*</td><td align="left" valign="bottom">99.91</td><td align="left" valign="bottom">31,617</td><td align="left" valign="bottom">I</td><td align="left" valign="bottom">0.34</td><td align="left" valign="bottom">[–0.16, 0.83]</td><td align="left" valign="bottom">90.98</td><td align="left" valign="bottom">29,758</td></tr><tr><td align="left" valign="bottom">H</td><td align="left" valign="bottom">0.56</td><td align="left" valign="bottom">[–2.42, 3.49]</td><td align="left" valign="bottom">64.42</td><td align="left" valign="bottom">26,985</td><td align="left" valign="bottom">H</td><td align="left" valign="bottom">0.64</td><td align="left" valign="bottom">[–3.51, 4.71]</td><td align="left" valign="bottom">61.97</td><td align="left" valign="bottom">25,637</td></tr><tr><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">–11.97</td><td align="left" valign="bottom">[-22.91,–1.20]*</td><td align="left" valign="bottom">98.41</td><td align="left" valign="bottom">30,657</td><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">–6.54</td><td align="left" valign="bottom">[–21.36, 8.73]</td><td align="left" valign="bottom">79.68</td><td align="left" valign="bottom">31,266</td></tr><tr><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.41</td><td align="left" valign="bottom">[-0.43,–0.38]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">36,828</td><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.68</td><td align="left" valign="bottom">[-0.72,–0.64]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">33,299</td></tr><tr><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">0.07</td><td align="left" valign="bottom">[–0.17, 0.30]</td><td align="left" valign="bottom">71.85</td><td align="left" valign="bottom">32,381</td><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">0.24</td><td align="left" valign="bottom">[–0.08, 0.57]</td><td align="left" valign="bottom">92.58</td><td align="left" valign="bottom">30,517</td></tr><tr><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td></tr><tr><td align="left" valign="middle" rowspan="6">Error trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">–0.79</td><td align="left" valign="bottom">[–8.01, 6.16]</td><td align="left" valign="bottom">58.84</td><td align="left" valign="bottom">20,239</td><td align="left" valign="middle" rowspan="6">Error trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">8.23</td><td align="left" valign="bottom">[–0.33, 16.79]</td><td align="left" valign="bottom">96.97</td><td align="left" valign="bottom">26,770</td></tr><tr><td align="left" valign="bottom">I</td><td align="left" valign="bottom">–0.04</td><td align="left" valign="bottom">[–0.27, 0.19]</td><td align="left" valign="bottom">63.10</td><td align="left" valign="bottom">28,734</td><td align="left" valign="bottom">I</td><td align="left" valign="bottom">0.27</td><td align="left" valign="bottom">[–0.01, 0.56]</td><td align="left" valign="bottom">97.01</td><td align="left" valign="bottom">32,348</td></tr><tr><td align="left" valign="bottom">H</td><td align="left" valign="bottom">1.06</td><td align="left" valign="bottom">[–2.87, 5.13]</td><td align="left" valign="bottom">69.95</td><td align="left" valign="bottom">21,448</td><td align="left" valign="bottom">H</td><td align="left" valign="bottom">–5.15</td><td align="left" valign="bottom">[-9.99,–0.28]*</td><td align="left" valign="bottom">98.09</td><td align="left" valign="bottom">26,886</td></tr><tr><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">–18.52</td><td align="left" valign="bottom">[-31.55,–5.56]*</td><td align="left" valign="bottom">99.71</td><td align="left" valign="bottom">26,800</td><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">11.38</td><td align="left" valign="bottom">[–4.68, 27.60]</td><td align="left" valign="bottom">91.88</td><td align="left" valign="bottom">31,452</td></tr><tr><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.41</td><td align="left" valign="bottom">[-0.44,–0.37]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">28,102</td><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.79</td><td align="left" valign="bottom">[-0.83,–0.74]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">30,943</td></tr><tr><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">–0.24</td><td align="left" valign="bottom">[–0.56, 0.07]</td><td align="left" valign="bottom">93.27</td><td align="left" valign="bottom">28,149</td><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">–0.02</td><td align="left" valign="bottom">[–0.40, 0.38]</td><td align="left" valign="bottom">52.89</td><td align="left" valign="bottom">33,367</td></tr></tbody></table></table-wrap><p>When examining the correct and error trials separately, Model 2 never outperformed Model 1 (see <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref>); therefore, we only report the parameter estimates for Model 1 (<xref ref-type="table" rid="table3">Table 3</xref>). The linear mixed modeling results for the correct trials corroborated the correlation analysis: the early time window (<italic>R<sup>2</sup></italic> = 0.38, σ = 5.74) showed that both the predictor variables of surprise and information gain explained significant variance in the feedback-locked pupil response; for correct trials in the late time window, (<italic>R<sup>2</sup></italic> = 0.33, σ = 6.00), none of the information-theoretic predictor variables were significant. The pattern of linear mixed model results for the error trials differed somewhat from the correlation analysis in the early (<italic>R<sup>2</sup></italic> = 0.34, σ = 4.07) and late time windows (<italic>R<sup>2</sup></italic> = 0.50, σ = 5.00; compare <xref ref-type="table" rid="table3">Table 3</xref> with <xref ref-type="fig" rid="fig3">Figure 3D and E</xref>). First, in the early time window, a trend towards a scaling between information gain and the post-feedback pupil dilation across the early time window is apparent in the error trials in the correlation analysis (see <xref ref-type="fig" rid="fig3">Figure 3D</xref>). This trend became significant in the linear mixed modeling result: the predictor variable of information gain explained significant variance in the early feedback-locked pupil response for error trials. Second, in the late time window, error trials scaled with surprise in the correlation analysis (see <xref ref-type="fig" rid="fig3">Figure 3E</xref>), not entropy (see <xref ref-type="fig" rid="fig3">Figure 3F</xref>). In contrast, entropy explained significant variance in the late time window in the linear mixed model analysis for error trials. This discrepancy suggests that the predictive power of surprise may be due to variance it shares with entropy for the error trials. As expected, the pre-feedback baseline pupil dilation explained a significant amount of variance in the feedback-locked pupil response in both time windows for the correct and error trials (<xref ref-type="table" rid="table3">Table 3</xref>). RT did not explain significant variance in either time window for the correct or error trials.</p></sec><sec id="s2-3-3"><title>Ideal learner model fits for the letter-color 2AFC task: correlation analysis</title><p>We first confirmed that the odd-ball task yielded a gradient of probability distributions according to the task as designed: the 33%, 50%, and 84% stimulus-pair frequency conditions had mean final probabilities of 0.034 (SD = 0.001), 0.050 (SD = 0.003), and 0.112 (SD = 0.004), respectively. For each participant, the final probabilities of each letter-color pair at the end of the odd-ball task corresponded to the prior distribution and were entered into the ideal learner model for the letter-color 2AFC task.</p><p>For the letter-color 2AFC task, the three information-theoretic variables are shown as a function of task trial in <xref ref-type="fig" rid="fig3">Figure 3G</xref> and as a function of stimulus-pair frequency in <xref ref-type="fig" rid="fig3">Figure 3H</xref>. Multicollinearity was again assessed by the correlations between the model parameters (information gain vs. surprise: <italic>r</italic> = 0.33, p &lt; 0.001; information gain vs. entropy: <italic>r</italic> = –0.51, p &lt; 0.001; surprise vs. entropy: <italic>r</italic> = 0.05, p &lt; 0.001). The trial-by-trial correlation of the post-feedback pupil response with the model parameters was repeated for the letter-color 2AFC task. The time course of the resulting correlation coefficients showed a pattern in which the pupil scaled positively with information gain shortly (~0.5 s) after feedback onset until about 1.75 s into the feedback interval spanning across the early time window (<xref ref-type="fig" rid="fig3">Figure 3I</xref>, purple line). The post-feedback pupil response also scaled negatively with entropy across the same interval as for information gain (<xref ref-type="fig" rid="fig3">Figure 3I</xref>, yellow line). No scaling between the post-feedback pupil response and surprise was obtained.</p><p>We repeated the correlation analysis of the information-theoretic variables to the feedback-locked pupil response separately for error and correct trials. The post-feedback pupil response scaled positively with information gain across the early time window for both error and correct trials (<xref ref-type="fig" rid="fig3">Figure 3J</xref>, red and blue lines). While no scaling between the post-feedback pupil response with surprise was obtained for error or correct trials (<xref ref-type="fig" rid="fig3">Figure 3K</xref>), the relationship with information gain was mirrored in a negative scaling with entropy for correct trials only (<xref ref-type="fig" rid="fig3">Figure 3L</xref>).</p></sec><sec id="s2-3-4"><title>Ideal learner model fits for the letter-color 2AFC task: linear mixed model analysis</title><p>To assess the unique variance explained by each of the model parameters during the letter-color 2AFC task, we compared two linear mixed models with the feedback-locked pupil response as the dependent variable (see Materials and methods). The model comparison was performed independently for the early and late time windows. For the letter-color 2AFC task, Model 1 performed slightly better than Model 2 for both the early (<italic>R<sup>2</sup></italic> = 0.16, σ = 8.5) and late time window (<italic>R<sup>2</sup></italic> = 0.31, σ = 11.68; see <xref ref-type="table" rid="app2table2">Appendix 2—table 2</xref> for the model comparison results), indicating that the inclusion of an interaction term between information gain and entropy did not lead to a better model fit of the post-feedback pupil response. The parameters of Model 1 are presented in <xref ref-type="table" rid="table4">Table 4</xref>. The linear mixed model analysis corroborated the correlation analysis: in the early time window, the predictor variables of entropy and information gain explained significant variance in the feedback-locked pupil response; in the late time window, in contrast, none of the information-theoretic predictor variables were significant. As expected, the pre-feedback baseline pupil dilation explained a significant amount of variance in the feedback-locked pupil response in both time windows. In addition to the pre-feedback baseline pupil, reaction time was a significant predictor of the post-feedback pupil response in the early time window of the letter-color 2AFC task.</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Linear mixed model results for the letter-color 2AFC task.</title><p>Explanation of abbreviations, rows: <italic>I</italic>, Shannon surprise predictor variable; <italic>H</italic>, entropy; <italic>D<sub>KL</sub></italic>, information gain; <italic>Baseline</italic>, pre-feedback baseline pupil dilation; <italic>RT</italic>, reaction times. Columns: <italic>95% CI</italic>, the 95% credible interval of the median posterior distribution; <italic>pd</italic>, the probability (in percentage) of direction; <italic>ESS</italic>, effective sample size; *indicates strong evidence that the parameter has a positive/negative effect on the post-feedback pupil response.</p><p><supplementary-material id="table4sdata1"><label>Table 4—source data 1.</label><caption><title>Processed data input into the linear mixed modeling analysis for the letter-color 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-table4-data1-v1.xlsx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom" colspan="11">Letter-color 2AFC task</th></tr></thead><tbody><tr><td align="left" valign="middle"/><td align="left" valign="bottom" colspan="5">Early time window</td><td align="left" valign="middle"/><td align="left" valign="bottom" colspan="5">Late time window</td></tr><tr><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td></tr><tr><td align="left" valign="middle" rowspan="6">All trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">22.1</td><td align="left" valign="bottom">[13.21, 30.86]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">26,356</td><td align="left" valign="middle" rowspan="6">All trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">–3.06</td><td align="left" valign="bottom">[–15.23, 9.09]</td><td align="left" valign="bottom">69.53</td><td align="left" valign="bottom">22,915</td></tr><tr><td align="left" valign="bottom">I</td><td align="left" valign="bottom">–0.02</td><td align="left" valign="bottom">[–0.13, 0.09]</td><td align="left" valign="bottom">64.55</td><td align="left" valign="bottom">34,055</td><td align="left" valign="bottom">I</td><td align="left" valign="bottom">0.09</td><td align="left" valign="bottom">[–0.06, 0.24]</td><td align="left" valign="bottom">87.28</td><td align="left" valign="bottom">26,755</td></tr><tr><td align="left" valign="bottom">H</td><td align="left" valign="bottom">–4.5</td><td align="left" valign="bottom">[-6.40,–2.58]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">25,959</td><td align="left" valign="bottom">H</td><td align="left" valign="bottom">0.59</td><td align="left" valign="bottom">[–2.03, 3.23]</td><td align="left" valign="bottom">67.52</td><td align="left" valign="bottom">23,997</td></tr><tr><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">60.07</td><td align="left" valign="bottom">[39.51, 80.87]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">26,249</td><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">–24.32</td><td align="left" valign="bottom">[–53.07, 4.56]</td><td align="left" valign="bottom">95.10</td><td align="left" valign="bottom">33,991</td></tr><tr><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.26</td><td align="left" valign="bottom">[-0.27,–0.24]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">44,190</td><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.58</td><td align="left" valign="bottom">[−0.60,–0.56]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">26,963</td></tr><tr><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">1.46</td><td align="left" valign="bottom">[1.03, 1.90]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">47,747</td><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">–0.16</td><td align="left" valign="bottom">[–0.75, 0.42]</td><td align="left" valign="bottom">70.89</td><td align="left" valign="bottom">30,625</td></tr><tr><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td></tr><tr><td align="left" valign="middle" rowspan="6">Correct trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">14.94</td><td align="left" valign="bottom">[4.81, 25.11]*</td><td align="left" valign="bottom">99.80</td><td align="left" valign="bottom">24,140</td><td align="left" valign="middle" rowspan="6">Correct trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">–4.35</td><td align="left" valign="bottom">[–18.46, 9.70]</td><td align="left" valign="bottom">72.67</td><td align="left" valign="bottom">19,889</td></tr><tr><td align="left" valign="bottom">I</td><td align="left" valign="bottom">5.15e-03</td><td align="left" valign="bottom">[–0.12, 0.13]</td><td align="left" valign="bottom">53.31</td><td align="left" valign="bottom">30,199</td><td align="left" valign="bottom">I</td><td align="left" valign="bottom">0.14</td><td align="left" valign="bottom">[–0.04, 0.31]</td><td align="left" valign="bottom">93.99</td><td align="left" valign="bottom">21,789</td></tr><tr><td align="left" valign="bottom">H</td><td align="left" valign="bottom">–3.05</td><td align="left" valign="bottom">[-5.25,–0.87]*</td><td align="left" valign="bottom">99.72</td><td align="left" valign="bottom">23,801</td><td align="left" valign="bottom">H</td><td align="left" valign="bottom">0.8</td><td align="left" valign="bottom">[–2.24, 3.85]</td><td align="left" valign="bottom">69.60</td><td align="left" valign="bottom">19,607</td></tr><tr><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">50.58</td><td align="left" valign="bottom">[24.08, 77.54]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">25,756</td><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">–32.31</td><td align="left" valign="bottom">[–69.66, 5.65]</td><td align="left" valign="bottom">95.47</td><td align="left" valign="bottom">19,778</td></tr><tr><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–2.6</td><td align="left" valign="bottom">[-0.27,–0.24]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">37,674</td><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.57</td><td align="left" valign="bottom">[−0.58,–0.55]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">27,486</td></tr><tr><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">1.36</td><td align="left" valign="bottom">[0.86, 1.87]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">28,719</td><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">–0.2</td><td align="left" valign="bottom">[–0.90, 0.49]</td><td align="left" valign="bottom">72.05</td><td align="left" valign="bottom">23,635</td></tr><tr><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td><td align="left" valign="middle"/><td align="left" valign="bottom"><bold>Parameter</bold></td><td align="left" valign="bottom"><bold>Median</bold></td><td align="left" valign="bottom"><bold>95%</bold> CI</td><td align="left" valign="bottom"><bold>pd (%</bold>)</td><td align="left" valign="bottom"><bold>ESS</bold></td></tr><tr><td align="left" valign="middle" rowspan="6">Error trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">15.37</td><td align="left" valign="bottom">[–2.50, 33.00]</td><td align="left" valign="bottom">95.54</td><td align="left" valign="bottom">27,183</td><td align="left" valign="middle" rowspan="6">Error trials</td><td align="left" valign="bottom">(Intercept)</td><td align="left" valign="bottom">–11.89</td><td align="left" valign="bottom">[–35.13, 10.58]</td><td align="left" valign="bottom">84.82</td><td align="left" valign="bottom">23,997</td></tr><tr><td align="left" valign="bottom">I</td><td align="left" valign="bottom">–0.22</td><td align="left" valign="bottom">[–0.46, 0.02]</td><td align="left" valign="bottom">96.50</td><td align="left" valign="bottom">32,906</td><td align="left" valign="bottom">I</td><td align="left" valign="bottom">–0.14</td><td align="left" valign="bottom">[–0.47, 0.17]</td><td align="left" valign="bottom">81.38</td><td align="left" valign="bottom">28,603</td></tr><tr><td align="left" valign="bottom">H</td><td align="left" valign="bottom">–1.84</td><td align="left" valign="bottom">[–5.71, 2.03]</td><td align="left" valign="bottom">82.42</td><td align="left" valign="bottom">26,618</td><td align="left" valign="bottom">H</td><td align="left" valign="bottom">3.12</td><td align="left" valign="bottom">[–1.79, 8.22]</td><td align="left" valign="bottom">89.03</td><td align="left" valign="bottom">23,597</td></tr><tr><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">43.74</td><td align="left" valign="bottom">[11.29, 76.03]*</td><td align="left" valign="bottom">99.63</td><td align="left" valign="bottom">25,265</td><td align="left" valign="bottom">DKL</td><td align="left" valign="bottom">–22.82</td><td align="left" valign="bottom">[–65.81, 20.46]</td><td align="left" valign="bottom">85.06</td><td align="left" valign="bottom">25,965</td></tr><tr><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.29</td><td align="left" valign="bottom">[-0.32,–0.26]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">38,565</td><td align="left" valign="bottom">Baseline</td><td align="left" valign="bottom">–0.68</td><td align="left" valign="bottom">[−0.72,–0.65]*</td><td align="left" valign="bottom">100.00</td><td align="left" valign="bottom">32,302</td></tr><tr><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">–0.59</td><td align="left" valign="bottom">[–1.44, 0.25]</td><td align="left" valign="bottom">91.18</td><td align="left" valign="bottom">30,075</td><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">–0.65</td><td align="left" valign="bottom">[–1.79, 0.48]</td><td align="left" valign="bottom">87.33</td><td align="left" valign="bottom">31,779</td></tr></tbody></table></table-wrap><p>When examining the correct and error trials separately, Model 2 never outperformed Model 1 but was sometimes significantly worse (<xref ref-type="table" rid="app2table2">Appendix 2—table 2</xref>); therefore, we only report the parameter estimates for Model 1 (<xref ref-type="table" rid="table4">Table 4</xref>). The linear mixed modeling results again corroborated the correlation analysis. For the correct trials in the early time window (<italic>R<sup>2</sup></italic> = 0.16, σ = 8.61), showed that both the predictor variables of entropy and information explained significant variance in the feedback-locked pupil response (and scaled in opposite directions); for correct trials in the late time window, (<italic>R<sup>2</sup></italic> = 0.29, σ = 11.96), none of the information-theoretic predictor variables were significant. The linear mixed modeling results for the error trials in the early time window (<italic>R<sup>2</sup></italic> = 0.24, σ = 7.51) showed that the predictor variable of information gain explained significant variance in the feedback-locked pupil response, while none of the information-theoretic predictor variables were significant in the late time window (<italic>R<sup>2</sup></italic> = 0.42, σ = 10.11). Again, as expected, the pre-feedback baseline pupil dilation explained a significant amount of variance in the feedback-locked pupil response in both time windows for the correct and error trials (<xref ref-type="table" rid="table3">Table 3</xref>). In addition to the pre-feedback baseline pupil, reaction time was a significant predictor of the post-feedback pupil response for the correct trials in the early time window of the letter-color 2AFC task.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In the current study, we investigated whether the pupil’s response to decision outcome (i.e., feedback) in the context of associative learning reflects a prediction error defined operationally as an interaction between stimulus-pair frequency and accuracy. Thereafter, we tested whether these prediction error signals correlated with information gain, defined formally as the KL divergence between posterior and prior belief distributions of the ideal observer. We also explored how prediction error signals changed over time (3 s) with respect to the trial-wise feedback on decision outcome across two independent associative learning paradigms. Information-theoretic variables were derived from an ideal learner model and fit to the post-feedback pupil response at the trial-by-trial level. For completeness, we computed Shannon surprise and entropy and examined their relationship with the post-feedback pupil response.</p><p>Results showed that signed prediction error signals, which illustrate the relationship between frequency and accuracy, were evident in distinct time windows: during the later time window for the cue-target 2AFC task and in the early window for the letter-color 2AFC task. The post-feedback pupil response correlated with information gain in the early time window across both tasks, while the direction of this scaling (qualitatively) differed per task. Shannon surprise was associated with the later time window in the cue-target 2AFC task, while entropy (in addition to information gain) related to the early time window in the letter-color 2AFC task. Our findings offer novel insights into the relationship between prediction error signals in post-feedback pupil responses and information processing by investigating how information-theoretic variables reveal the underlying computational processes driving the interactions between stimulus-pair frequency and accuracy.</p><sec id="s3-1"><title>Information gain was reflected in the early post-feedback pupil response</title><p>The results supported our hypothesis that prediction error signals in the post-feedback pupil dilation reflected information gain, indicating that the pupil’s response to decision outcome reflects the amount of information gained during associative learning. Across both task contexts, the post-feedback pupil response correlated with information gain within the early (0.75–1.25 s) but not late time window (2.5–3 s) (see <xref ref-type="fig" rid="fig3">Figure 3C and I</xref>). This early scaling between the pupil response following feedback onset and information gain suggests that the difference between the posterior and prior belief distributions is transiently reflected in pupil dilation shortly after observing the decision outcome about the stimulus pairs.</p><p>For the first time, we show that the direction of the relationship between post-feedback pupil dilation and information gain (defined as the KL divergence between posterior and prior belief distributions) was context dependent. Specifically, in the cue-target 2AFC task, there was a negative effect of information gain on pupil dilation: the pupil response was smaller for larger values of information gain. In contrast, in the letter-color 2AFC task, there was a positive effect of information gain on pupil dilation: the pupil response was larger for larger values of information gain. This pattern of results was apparent in the correlation analysis across the pupil time course as well as in the linear mixed model analysis accounting for shared variance from other explanatory variables on the time windows of interest.</p><p>The entropy as a function of task trial differed between these task contexts (compare <xref ref-type="fig" rid="fig3">Figure 3A</xref> right panel with <xref ref-type="fig" rid="fig3">Figure 3G</xref> right panel): At the end of the odd-ball task, participants were exposed to the letter-color pairs in the high-frequency (84%) more often as compared with the lower-frequency conditions (33% and 50%). Therefore, stronger expectations about letter-color pairs for the 84% letter-color condition are represented by larger priors at the start of the letter-color 2AFC task. This increasing entropy in the letter-color 2AFC task can be attributed to the fact that the letter-color pair conditions are balanced in terms of frequency of presentation while the prior distribution was not uniform. In other words, there is increasing average uncertainty driven by the stronger prior expectations in the subsequent fully balanced letter-color 2AFC task. To verify that the direction of entropy depended on the prior distribution chosen, we ran the ideal learning model on the letter-color 2AFC data using a uniform prior distribution (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Although it is tempting to speculate that the direction of the relationship between pupil dilation and information gain may be due to either increasing or decreasing entropy as the task progressed, we must refrain from this conclusion. We note that the two tasks differ substantially in terms of design with other confounding variables and therefore cannot be directly compared to one another. We expand on these limitations in the section below (see Limitations and future research).</p><p>The results from the cue-target 2AFC task are in line with those reported by <xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref> in which pupil dilation was also smaller for larger values of information gain centered around 1 s following target onset in a saccadic planning task. Although we did not explicitly dissociate surprise and information gain in the cue-target 2AFC task design, as did O’Reilly et al., we found converging results related to the pupil’s response to information gain (or ‘updating’). While O’Reilly et al. also found a positive relationship between pupil dilation and surprise, this surprise effect in their saccadic planning task emerged earlier than the scaling with information gain, unlike in the cue-target 2AFC task here. In the cue-target 2AFC task, we furthermore see a sustained surprise effect that spans most of the post-feedback interval, while the surprise effect in the previous saccadic planning task was transient. The discrepant results further illustrate the importance of task context for interpreting the relationship between pupil dilation and information processes. For instance, saccadic RTs were reported to scale with target expectancy; however, in the current study, we are investigating the post-feedback intervals that did not require any motor responses from the participants. Furthermore, while we found early scaling between the post-feedback pupil response and information gain in both the cue-target and letter-color 2AFC tasks, the presence of a relationship between the post-feedback pupil response with surprise and entropy differed across tasks (compare <xref ref-type="fig" rid="fig3">Figure 3C with I</xref>).</p><p><xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref> suggested that ‘pupil increases during learning are driven by uncertainty, or the influence of uncertainty on learning, rather than by learning or change per se’. The results taken together across these two associative learning paradigms are in line with their suggestion. The results of the current study are also in line with the proposition of <xref ref-type="bibr" rid="bib124">Zénon, 2019</xref> that ‘the ensemble of phenomena that trigger changes in pupil-linked arousal all depend on a basic underlying information theoretic process: the update of the brain internal models’. Furthermore, from the contrast of the two associative learning tasks presented here, we can confirm that the pupil does not respond simply to (Shannon) surprise, because it does not always follow the frequency of occurrence of the stimulus pairs, independently of the task. Instead, the pupil seems to respond to the amount of information provided by stimuli about the task variables. Other studies have shown that the relationship between information gain and surprise reflected in pupil dilation is context dependent. One study testing children found that pupil dilation positively correlated with information gain, but not surprise, only when children were actively making predictions about water displacement, but not when they evaluated outcomes about water displacement without having to make predictions (<xref ref-type="bibr" rid="bib15">Colantonio et al., 2023</xref>). While <xref ref-type="bibr" rid="bib104">Shirama et al., 2024</xref> showed that the covariance of trial-wise pupil dilation and information gain depended on individual differences in accuracy, pupil dilation did not reflect surprise during change points in their study. <xref ref-type="bibr" rid="bib29">Fleischmann et al., 2025</xref> reported that pupil dilation correlated with both surprise and information gain, but information gain was the more accurate predictor. Zénon discusses the negative scaling of pupil dilation with information gain reported by O’Reilly et al. as contradicting the hypothesis that the pupil dilation will increase in proportion to how much novel sensory evidence is used to update current beliefs. Here, we provide additional evidence that the direction of this relationship between pupil dilation and information gain needs more context.</p><p>Interestingly, only in the letter-color 2AFC task, results showed that the post-feedback pupil response negatively correlated with entropy in the early but not late time window, mirroring the positive scaling between the pupil response and information gain (see <xref ref-type="fig" rid="fig3">Figure 3I</xref>). While volatility and entropy describe different phenomena, they are interconnected through their relationship with uncertainty and predictability. High volatility typically corresponds to higher entropy, reflecting a system’s complexity and unpredictability (<xref ref-type="bibr" rid="bib103">Sheraz et al., 2015</xref>). Previous work has shown that both tonic and phasic fluctuations in pupil dilation may track volatility in the environment, sometimes referred to as unexpected uncertainty (<xref ref-type="bibr" rid="bib78">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib117">Vincent et al., 2019</xref>; <xref ref-type="bibr" rid="bib26">Filipowicz et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Harris et al., 2022</xref>; <xref ref-type="bibr" rid="bib83">Pajkossy et al., 2023</xref>; <xref ref-type="bibr" rid="bib77">Murphy et al., 2021</xref>). Furthermore, noradrenaline plays a crucial role in how organisms track and respond to volatility in their environments, as it can signal when to update beliefs and expectations, enhancing the brain’s ability to adapt to fluctuations (<xref ref-type="bibr" rid="bib96">Sales et al., 2019</xref>; <xref ref-type="bibr" rid="bib79">Nassar, 2024</xref>). Using a probabilistic reversal learning task, <xref ref-type="bibr" rid="bib83">Pajkossy et al., 2023</xref> reported that state entropy positively predicted post-feedback pupil size changes and interacted with the reversal probability of stimulus-reward contingencies across three different variations of the experiment. The scaling on entropy with the post-feedback pupil response reported by Pajkossy et al. occurred overall later in time with respect to feedback onset (ranging from feedback onset to 6 s depending on experimental variation) as compared with the letter-color 2AFC task. While more research is needed to understand these discrepant results, certainly differences between the reversal learning tasks in Pajkossy et al. and ‘simple’ associative learning required in the letter-color 2AFC task could play a role, such as the presence or lack of changing stimulus probabilities and the inclusion of a point-based reward system for feedback.</p></sec><sec id="s3-2"><title>The relationship between signed prediction error signals and information gain</title><p>As the term “ideal learner” suggests, the information-theoretic variables are computed based on the stimulus events shown to participants but are not sensitive to their actual behavioral performance. Of course, participants do not always act as ideal learners and make errors of observation, inference, and motor responses. Therefore, as a complementary analysis, we sought to examine the relationship between the performance accuracy and the information-theoretic variables to understand which computational processes may be underlying the stimulus-pair frequency and accuracy interactions reflected in the post-feedback pupil response.</p><p>In the cue-target 2AFC task, a prediction error should occur when the target orientation did not match the expected orientation based on the learned contingencies. A signed prediction error signal was obtained in the late time window, with the low-frequency (20%) error trials driving the interaction effect (see <xref ref-type="fig" rid="fig1">Figure 1F</xref>). Converging with this late signed prediction error signal, the correlations between surprise and the post-feedback pupil response differed for the error as compared with correct trials in the late time window (see <xref ref-type="fig" rid="fig3">Figure 3E</xref>). Specifically, the post-feedback pupil response during error trials showed larger correlation coefficients with surprise as compared with correct trials from about 1.75 to 3 s following the target onset. Thus, a signed prediction error signal defined by the interaction between frequency and accuracy in the late time window task seems to be driven by <italic>surprise</italic> and not information gain for the cue-target 2AFC. In line with this result, <xref ref-type="bibr" rid="bib59">Lavín et al., 2013</xref> also found a surprise-driven effect in pupil dilation specifically following negative feedback presentation during a learning gambling task. This surprise-driven effect was evident in early (~500 ms) and later time windows (1200–1300 and 1700–2400 ms following feedback onset). The direction of this surprise-driven effect could be interpreted in relation to sensory evidence. For instance, <xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref> measured pupil dilation during a random dot discrimination paradigm with hard and easy levels of motion coherence that did not involve probabilistic learning. The signed prediction error signal in pupil dilation was found to depend on sensory evidence within a late time window (3–6 s) following feedback, consistent with findings from the cue-target 2AFC task (see <xref ref-type="fig" rid="fig1">Figure 1D and F</xref>). The relationship between surprise and prediction error signal is partially in line with reward-linked feedback signals in <xref ref-type="bibr" rid="bib115">Van Slooten et al., 2018</xref>. Using a probabilistic value-based reinforcement learning task, van Slooten et al. reported that the early post-feedback pupil response (&lt;~2 s) was modulated by uncertainty about the value of options (with smaller differences between value options resulting in larger pupil dilation) but was not affected by violations of value beliefs (i.e., surprise). In contrast, the later post-feedback pupil response (around 2–3 s) positively reflected the degree to which outcomes violated current value beliefs. However, the direction of the late prediction error signal indicated that worse-than-expected outcomes were related to smaller pupil sizes, which seems to be at odds with other work showing that pupils generally dilate more when performance is worse than expected such as during errors (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Braem et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Critchley et al., 2005</xref>; <xref ref-type="bibr" rid="bib63">Maier et al., 2019</xref>; <xref ref-type="bibr" rid="bib76">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib94">Rondeel et al., 2015</xref>; <xref ref-type="bibr" rid="bib118">Wessel et al., 2011</xref>; however, see also <xref ref-type="bibr" rid="bib59">Lavín et al., 2013</xref>). The authors speculated that the late reward prediction error signal may reflect the firing pattern of phasic dopamine neurons, and other work supports the notion of a significant component of dopamine signaling being reflected in pupil dilation (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Lloyd et al., 2023</xref>; <xref ref-type="bibr" rid="bib19">de Gee et al., 2014</xref>). A key difference between the current study and van Slooten et al. is the absence of reward-driven feedback during associative learning in the current study.</p><p>In the letter-color 2AFC task, a prediction error should occur when the participant expected that the letter-color pair did ‘match’, but in fact they did not match, or vice versa. A signed prediction error signal was significant in the early time window (see <xref ref-type="fig" rid="fig2">Figure 2E</xref>). The direction of this interaction effect indicated that the pupil response difference between errors and correct trials increased as letter-color pair frequency increased (see <xref ref-type="fig" rid="fig2">Figure 2E</xref>). We note that the direction of the signed prediction error might seem counterintuitive as it relates to information gain, because stronger predictions (i.e. higher-frequency observations) often result in less information gain following outcome observation. As discussed above, in the letter-color 2AFC task, the amounts of surprise and information gain are highest for the high-frequency as compared with the lower-frequency conditions related to the increasing entropy across trials (see <xref ref-type="fig" rid="fig3">Figure 3H</xref>, left-hand and middle panels; compare with <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Converging with this early signed prediction error signal, correlations between both information gain and entropy with the post-feedback pupil response were obtained in the early time window (see <xref ref-type="fig" rid="fig3">Figure 3I</xref>); however, no differences between correlations on error as compared with correct trials were obtained for either information-theoretic variable (see <xref ref-type="fig" rid="fig3">Figure 3J and L</xref>). Understanding the information processing in relation to performance accuracy may be crucial for disentangling the early signed prediction error signal. An alternative contributing factor that we did not explicitly test for is the participants’ confidence about the stimulus-pair associations. Using an orientation discrimination task, <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref> reported that the early post-feedback pupil response was largest on error trials and smallest on correct trials when participants were most (subjectively) confident about their choices. Although we did not ask participants to report on their confidence about choices made, both RT and the strength of the stimulus-pair priors could be taken as a proxy for confidence (<xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib97">Sanders et al., 2016</xref>). In line with this, we did obtain interactions between stimulus-pair frequency and accuracy in both RT and the early post-feedback pupil response.</p><p>In sum, since the ideal learner model does not capture participant errors, we aimed to connect these two approaches of analyzing prediction errors by fitting the information-theoretic variables to the pupil response during error and correct trials independently. Signed prediction error signals defined by the interaction between frequency and accuracy were observed in the late time window for the cue-target 2AFC task and in the early window for the letter-color 2AFC task. Shannon surprise was related to the later component in the cue-target 2AFC task, while both information gain and entropy were related to the early component in the letter-color 2AFC task.</p></sec><sec id="s3-3"><title>Limitations and future research</title><p>This study has some limitations. First, the two associative learning paradigms differed in many ways and were not directly comparable. For instance, the shape of the mean pupil response function differed across the two tasks in accordance with a visual or auditory feedback stimulus, and it is unclear whether these overall response differences contributed to any differences obtained between task conditions within each task. We are unable to rule out whether so-called ‘low level’ effects such as the initial constriction to visual stimuli in the cue-target 2AFC task as compared with the dilation in response to auditory stimuli in letter-color 2AFC task could confound correlations with information gain. Future work should strive to disentangle how the specific aspects of the associative learning paradigms relate to prediction errors in pupil dilation by systematically manipulating design elements within each task. Task context clearly determines the relationship between the post-feedback pupil response and the information-theoretic variables, as it determines the uncertainty conditions surrounding decision-making. To determine exactly how the different associative learning tasks relate to different temporal components of model updating is beyond the scope of the current study, but we speculate that hybrid predictive coding models may be able to account for fast (bottom-up) and slow (top-down) prediction errors reflected in pupil dilation (<xref ref-type="bibr" rid="bib111">Tscshantz et al., 2023</xref>). Second, we did not design the associative learning paradigms to orthogonalize the information-theoretic variables, such as was done in O’Reilly et al. Indeed, some multicollinearity was evident between the information-theoretic variables in each of the two tasks. Cleverer associative learning paradigms may be able to overcome this limitation. Third, we are unable to attribute the relationship between computational variables and pupil dilation to specific neural mechanisms or neuromodulatory systems with the current study. Previous work has shown how neuromodulatory systems relate to learning and decision-making under uncertainty and the ability of the pupil to reflect these underlying computational processes (<xref ref-type="bibr" rid="bib20">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Murphy et al., 2014a</xref>; <xref ref-type="bibr" rid="bib78">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib75">Murphy et al., 2014b</xref>; <xref ref-type="bibr" rid="bib117">Vincent et al., 2019</xref>; <xref ref-type="bibr" rid="bib26">Filipowicz et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Harris et al., 2022</xref>; <xref ref-type="bibr" rid="bib83">Pajkossy et al., 2023</xref>; <xref ref-type="bibr" rid="bib77">Murphy et al., 2021</xref>; <xref ref-type="bibr" rid="bib69">Meyniel, 2020</xref>). Future research should aim at identifying the neural mechanisms involved in the processes underlying associative learning as reflected in pupil dilation across all phases of a decision process, ideally through computational theory. Finally, while we acknowledge the potential relevance of subjective factors, such as the participants’ overt confidence reports, in understanding prediction errors and pupil responses, the current study focused on the more objective, model-driven measure of information-theoretic variables. This approach aligns with our use of the ideal learner model, which estimates information-theoretic variables while being agnostic about the observer’s subjective experience itself. Future research is needed to explore the relationship between information-gain signals in pupil dilation and the observer’s reported experience of or awareness about confidence in their decisions.</p><p>Understanding prediction errors through pupil dilation within an information theory framework can illuminate predictive processing mechanisms in several significant ways. Pupil dilation acts as a physiological marker of cognitive and emotional responses, allowing researchers to quantitatively assess how discrepancies between expected and actual outcomes impact cognitive processing (<xref ref-type="bibr" rid="bib9">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib83">Pajkossy et al., 2023</xref>; <xref ref-type="bibr" rid="bib109">Stemerding et al., 2022</xref>). A framework for interpreting pupil dilation in terms of information theory may also enable exploration of how prediction errors function at various levels of a hierarchical model, helping researchers examine the interaction between high-level expectations and lower-level sensory inputs across different timescales, which informs the overall predictive model (<xref ref-type="bibr" rid="bib43">Iglesias et al., 2013</xref>; <xref ref-type="bibr" rid="bib66">Mathys et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Dijkstra et al., 2025</xref>). Analyzing pupil responses in relation to prediction errors can reveal the extent of new information being processed and its influence on future predictions, thereby enhancing our understanding of learning and adaptation dynamics by elucidating feedback mechanisms in predictive processing and demonstrating how the brain adjusts its predictions based on new information. Given that pupil dilation is a peripheral marker of the brain’s central arousal states, understanding its relationship with prediction errors can help disentangle the cognitive and affective components of predictive processing, providing a more comprehensive view of how the brain navigates uncertainty (<xref ref-type="bibr" rid="bib79">Nassar, 2024</xref>; <xref ref-type="bibr" rid="bib88">Pulcu and Browning, 2019</xref>). By integrating such insights, researchers can gain a deeper understanding of the mechanisms underlying predictive processing and how the brain continuously updates its internal models based on new experiences.</p></sec><sec id="s3-4"><title>Conclusion</title><p>To conclude, the results provide evidence for Zénon’s general assumption that pupil dilation can be described by an information-theoretic perspective. Clearly, task context plays a key role in the relationship between the information-theoretic variables and the post-feedback pupil response, as may be expected. The temporal dynamics of these prediction error signals should be carefully considered, as certain components tended to emerge around the peak of the canonical impulse response function and others may be sustained over time. These subtleties highlight the importance of adopting a model-based approach for characterizing the computational processes driving prediction errors as reflected in pupil dilation. Taken together, the post-feedback pupil response is a complex and multifaceted signal that reflects different components of information processing during associative learning. The physiological response of the pupil provides a unique window into the brain’s computations involved in model updating. More work is needed to link the information-theoretic variables reflected in the post-feedback pupil response with their underlying neuromodulatory mechanisms (<xref ref-type="bibr" rid="bib37">Grujic et al., 2024</xref>).</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Data sets: decision-making tasks in associative learning paradigms</title><p>We analyzed two data sets related to associative learning in which pupil dilation was recorded during decision making; one of these data sets was publicly available (<xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>), the other was collected for the study purposes. In the decision-making tasks of both data sets, participants had to make a two-alternative forced choice (2AFC) on each trial based on visual and/or auditory information. For the current analyses, the dependent variables of interest were participants’ accuracy, reaction time (RT), and the feedback-locked pupil response. In the first data set (see Materials and methods section ‘Data set #1: Cue-target 2AFC task’ for further details), participants learned probabilistic contingencies between stimuli during the 2AFC decision-making task itself. In the second data set (see Materials and methods section ‘Data set #2: Letter-color 2AFC task’ for further details), there was an implicit learning phase prior to the 2AFC decision-making task during which the participants completed an odd-ball detection task that was irrelevant to the probabilistic contingencies between pairs of stimuli being presented. Pupil dilation was continuously measured in both data sets during each of the 2AFC decision-making tasks. The data sets consisted of independent samples of participants.</p><p>These data sets were chosen to analyze because we were able to quantify the post-feedback pupil dilation as the interaction between stimulus-pair frequency and accuracy as well as adapt an information-theoretic model of trial-by-trial learning in both task paradigms. The pupil is known to scale positively with errors as compared with correct responses (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Braem et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Critchley et al., 2005</xref>; <xref ref-type="bibr" rid="bib63">Maier et al., 2019</xref>; <xref ref-type="bibr" rid="bib76">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib94">Rondeel et al., 2015</xref>; <xref ref-type="bibr" rid="bib118">Wessel et al., 2011</xref>). In addition, studies have shown that pupil dilation positively scales with unexpected as compared with expected events (<xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib87">Preuschoff et al., 2011</xref>; <xref ref-type="bibr" rid="bib1">Alamia et al., 2019</xref>; <xref ref-type="bibr" rid="bib7">Bianco et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Friedman et al., 1973</xref>; <xref ref-type="bibr" rid="bib47">Kamp and Donchin, 2015</xref>; <xref ref-type="bibr" rid="bib50">Kloosterman et al., 2015</xref>; <xref ref-type="bibr" rid="bib51">Knapen et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Kuchinke et al., 2007</xref>; <xref ref-type="bibr" rid="bib59">Lavín et al., 2013</xref>; <xref ref-type="bibr" rid="bib61">Liao et al., 2016</xref>; <xref ref-type="bibr" rid="bib89">Qiyuan et al., 1985</xref>; <xref ref-type="bibr" rid="bib90">Raisig et al., 2010</xref>; <xref ref-type="bibr" rid="bib106">Silvestrin et al., 2021</xref>; <xref ref-type="bibr" rid="bib119">Wetzel et al., 2016</xref>; <xref ref-type="bibr" rid="bib126">Zhao et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Ghilardi et al., 2024</xref>). Prediction errors can be operationalized as a function of task conditions related to stimulus expectations. For instance, a main effect of stimulus frequency reflects an unsigned prediction error, since the different frequency conditions correspond to different levels of expectancy (in the simplest form, a contrast of unexpected vs. expected). A main effect of accuracy (categorized post-hoc based on task performance) indicates an error signal about the binary outcome of a decision (correct vs. incorrect). However, an error signal is not the same as a prediction error signal, because an error alone does not necessarily convey information regarding expectation. In other words, errors on accuracy do not contain quantitative information regarding a difference between what was expected and what occurred. Expectations can modulate a main effect of accuracy in the post-feedback pupil response, indicating whether the outcome of the participant’s accuracy (correct or incorrect) is better or worse than expected (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>). A signed prediction error in the context of associative learning would therefore be evidenced by an interaction between stimulus-pair frequency and accuracy.</p><p>In the current data sets, we were interested in comparing the condition when a participant makes an error, and the outcome was expected, with the condition in which they make an error and the outcome was unexpected (and similarly for when they are correct about their decision). If the signed prediction error signal correlates with information gain, then we would expect a larger difference between error and correct trials for the condition with weaker expectations as compared with stronger expectations. In other words, more information is gained from a decision outcome in conditions with more uncertainty as compared with less uncertainty. Finally, we explored whether a definition of prediction error as an interaction between stimulus-pair frequency and accuracy will correlate with information gain.</p></sec><sec id="s4-2"><title>Data set #1: cue-target 2AFC task</title><p>Independent analyses that focused on the relationship between the participants’ pupil responses and Bayesian learning mechanisms have been previously published based on the same data set (<xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>). The data are publicly available and have been re-analyzed (including pre-processing) in the current paper to answer a complementary but conceptually distinct research question compared with the (<xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>) paper. The relevant methods that have been previously published are summarized here.</p><sec id="s4-2-1"><title>Participants and informed consent</title><p>From the thirty participants included in the published data set, six participants missed responses in at least one of the conditions required for the main two-way repeated-measures ANOVA and were therefore excluded from the statistical analysis. The final sample consisted of 24 participants aged 19–42 years (<italic>M</italic> = 23.3, SD = 4.9, 18 women). All participants gave written informed consent before participating and were compensated for participation.</p></sec><sec id="s4-2-2"><title>Task and procedure</title><p>Participants performed a 2AFC decision-making task on the expected orientation direction (left vs. right) of the target stimulus (Gabor patches; spatial frequency = 0.033, opacity = 0.5, 400 x 400 pixels) while pupil dilation was recorded (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). A chin rest was used to keep the distance (50 cm) to the computer screen constant (1920 x 1,080 pixels, 120 Hz). This setup resulted in a Gabor patch with a visual angle of 12.1°. Participants were instructed to use the visual and auditory cues to predict the orientation of the upcoming target stimulus in each trial and to respond (by left or right button press corresponding to a left or right prediction, respectively) as soon as they knew which target orientation would appear. Participants were instructed to wait until cue offset to make their predictions. The orientation of the target was probabilistically determined by the combination of the preceding visual and auditory cues. The cue-target contingencies were not communicated in advance to the participants. The cue-target mappings were counterbalanced between participants in such a way that half of the participants saw the square followed by a right-oriented grating and a diamond followed by a left-oriented grating in 80% of the trials, and for the other half of the participants, this mapping was reversed (i.e. square –&gt; left and diamond –&gt; right). In the remaining 20% of the trials, the participants received the reversed cue-target mapping with respect to their 80% mapping condition. On half of the trials, an auditory tone (“C” octave 4; 300ms) was presented together with the onset of the visual cue. In the first half of the experiment (phase 1), this auditory tone was uninformative of the upcoming target orientation and could essentially be ignored. After phase 1 was completed, participants took a short break and were informed that the cue-target contingency rule would change; for the purposes of the current analysis, we only inspected phase 1 of the original experiment. Phase 1 consisted of 200 trials per participant. The order of the trials was randomly presented to each participant. The entire session took about 1.5 hr to complete (~45 min for phase 1). Stimuli were isoluminant and had a gray background.</p></sec><sec id="s4-2-3"><title>Trial structure</title><p>Each trial of the cue-target task consisted of a fixation period (1.5 s), a cue period (1 s), a decision period during which the participant responded by pressing either the left or right button (RT), a delay period (3 s), and the target period (3 s) which served as feedback for the cue-target contingencies. A vertically oriented Gabor patch was presented on screen except for the target period. Participants were instructed to keep their gaze centered at the fixation cross in the middle of the screen. The fixation cross remained on screen except for the cue period, during which either a square or diamond appeared. During the cue period, a square or diamond would indicate the upcoming orientation direction of the target stimulus with a certain probability (20% vs. 80%). Note that in the cue-target task, the target period served as trial-by-trial feedback on the accuracy of the participants’ cue-target predictions.</p></sec><sec id="s4-2-4"><title>Data acquisition and preprocessing</title><p>Pupil dilation of the right eye was continuously recorded during phase 1 of the cue-target task using an SMI RED500 eye-tracker (SensoMotoric Instruments, Teltow/Berlin, Germany). The sampling rate was 500 Hz. Using custom Python code, the following steps were applied to the entire pupil dilation time series: (i) linear interpolation around missing samples (0.15 s before and after each missing event), (ii) linear interpolation around blinks or saccade events based on spikes in the temporal derivative (0.15 s before and after each nuisance event; note that blinks and saccades were considered as a single nuisance event), (iii) band-pass filtering (third-order Butterworth, 0.01–6 Hz), (iv) responses to nuisance events were removed using linear regression (nuisance responses were estimated using deconvolution; <xref ref-type="bibr" rid="bib51">Knapen et al., 2016</xref>) and (v) the residuals of the nuisance regression were converted to percent signal change with respect to the temporal mean. The size of the interpolation window preceding nuisance events was based on previous literature (<xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">Knapen et al., 2016</xref>; <xref ref-type="bibr" rid="bib120">Winn et al., 2018</xref>). After interpolation based on data markers and/or missing values, remaining blinks and saccades were estimated by testing the first derivative of the pupil dilation time series against a threshold rate of change. The threshold for identifying peaks in the temporal derivative is data-driven, partially based on past work (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib20">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>). The output of each participant’s pre-processing pipeline was checked visually. Once an appropriate threshold was established at the group level, it remained the same for all participants (minimum peak height of 10 units). Trials that were faster or longer than 3 times the standard deviation of the <italic>Z</italic>-transformed RT distribution of each participant were excluded from the analysis, because there was no maximum response window (1.5% of the total number of trials were excluded; <xref ref-type="bibr" rid="bib6">Berger and Kiefer, 2021</xref>).</p></sec><sec id="s4-2-5"><title>Differences with <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref></title><p>The main differences between the current work and <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref> are the following. First, in the current analysis, we are only considering the first 200 trials (referred to as ‘phase 1’) out of the 400 trials in total. After 200 trials (referred to as ‘phase 2’), the cue-target contingencies switched according to a specific rule. The change in rule-based contingencies prevented us from applying the ideal learner model to both phases of the task. Crucially, trials in phase 1 were independent from trials in phase 2 as they took place earlier in time, and therefore, discarding the second half of the experiment would not affect the associative learning processes taking place in the first half of the experiment. Second, we did not include six of the 30 participants that are in the publicly available data set provided by <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref> due to missing cases in the repeated-measures ANOVAs in phase 1 of the experiment. Finally, <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref> only tested for signed prediction errors within an early time window (see their Supplementary Materials) but did not investigate any later time windows as we do in the current experiment.</p></sec></sec><sec id="s4-3"><title>Data set #2: letter-color 2AFC task</title><sec id="s4-3-1"><title>Participants and informed consent</title><p>The final sample consisted of 47 participants aged 17–45 years (<italic>M</italic> = 23.8, SD = 6.16, 34 women and 13 men). Fifty participants completed the experiment. Three participants had to be excluded due to technical error or human error on the part of the researcher. All participants gave written informed consent before participating and were compensated for participation.</p></sec><sec id="s4-3-2"><title>Tasks and procedure</title><p>The experiment consisted of two separate tasks, the odd-ball detection and 2AFC decision tasks, which corresponded to a learning and decision-making phase, respectively (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Participants were not instructed about the decision-making task until the learning task was completed. A chin rest was used to keep the distance (58 cm) to the computer screen constant (1920 x 1080 pixels, 120 Hz). This setup resulted in visual stimuli spanning visual angles between 2.6° and 3.1°. We exposed participants to pairs of stimuli presented together in different frequency conditions during the learning phase of the experiment. We aimed to have low, medium, and high levels of stimulus-pair frequency to correspond to different amounts of exposure to associations between the individual letters and the colors. More exposure to consistent associations between letters and colors was expected to result in stronger expectations of the specific letter-color pairs as compared with less exposure. After this odd-ball task in which participants were exposed to the letter-color pairs in different frequency conditions, participants were asked to make a 2AFC decision based on the presented stimuli pairs in the decision-making phase. Participants completed a questionnaire at the end of the computer tasks (data not reported here). Participants were given self-paced breaks between each task. The entire session took about 2.5 hr to complete.</p></sec><sec id="s4-3-3"><title>Independent learning phase: odd-ball detection task</title><p>We hypothesized that statistical learning would take place within an odd-ball detection paradigm, during which participants had to monitor both the identity of a letter or number and the background color it was presented on (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). The stimuli used for the statistical-learning hypothesis were six letters (‘A’, ‘D’, ‘I’, ‘O’, ‘R’, and ‘T’, 100 pixels, Bookman Old Style font) and six shades of green as the background color in the shape of a square (120 x 120 pixels; see <xref ref-type="fig" rid="fig2">Figure 2A</xref> and <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1</xref> for hexadecimal codes). Shades of a single hue were chosen to help minimize verbal heuristic strategies for naming the six different colors. Three different frequency conditions were used (20%, 40%, and 80% of trials in which a specific letter was presented against a square background with a specific color), meaning that two letter-color pairs were in each frequency condition. For example, if the letter ‘A’ was assigned to the 80% frequency condition, then ‘A’ was shown with its associated shade of green as the background color in eight out of 10 trials in which ‘A’ was presented. On the remaining two out of 10 trials in which an ‘A’ was presented, the background shade of green was randomly drawn from all six shades of green. This sampling with replacement resulted in the letters being shown together with their associated color in actual frequency conditions of 33%, 50%, and 84%. Each letter was shown together with the other five unassociated colors on average in 13%, 10%, and 3% of trials (i.e. the noise around the letter-color pair signal) with respect to the 20%, 40%, and 80% frequency conditions, respectively. The six-letter-color pair combinations as well as their frequency condition were randomly assigned to each participant at the start of the experiment, meaning that participants received individual combinations of stimuli. For clarity, we will only refer to the actual frequency conditions in the letter-color 2AFC task (i.e. 33%, 50%, and 84%) from here on instead of the intended frequency conditions (20%, 40%, and 80%).</p><p>The odd-ball stimuli were numbers 1–9 (randomly drawn) and a non-green hue (one of four colors was chosen by random for each participant at the start of the experiment). Note that odd-balls could consist of (i) a number with a non-green background, (ii) a number with a green background, and (iii) a letter with a non-green background. Participants completed a short round of 10 practice trials of the odd-ball task, which they could repeat until they understood the odd-ball rule. During the practice round, an equal number of odd-ball and regular stimuli were presented. Participants were instructed to indicate whether the stimulus on each trial was an odd-ball or not with either a left or a right button press (button order was counterbalanced between participants). They could respond as soon as the stimulus appeared on screen. Participants were not informed about the frequency conditions of the letter-color pairs. The odd-ball task consisted of 660 trials in total (9% were odd-balls), during which participants had two self-paced breaks. The order of the trials was randomly presented to each participant. The odd-ball task took about 30 min to complete.</p></sec><sec id="s4-3-4"><title>Oddball-task trial structure</title><p>Each trial of the odd-ball task consisted of a stimulus period (0.75 s), a response period (&lt;1.25 s), and an inter-trial interval that included feedback on accuracy (0.5–1 s jittered). A black fixation cross was presented in the center of the screen and changed to green, red, or blue in the inter-trial interval for correct, incorrect, or missed responses, respectively. Errors and missed trials were also accompanied by a short auditory tone (3rd octave ‘D’ for 0.3 s). All stimuli were presented in the center of the screen against a gray background.</p></sec><sec id="s4-3-5"><title>Letter-color 2AFC task</title><p>After the odd-ball task, participants performed a 2AFC decision-making task on the occurrence of letter-color pairs that were shown during the preceding odd-ball task. Specifically, participants were instructed to indicate whether specific letter-color pairs occurred most often together in the preceding odd-ball task. They were instructed to guess if they were unsure. If a letter occurred most often together with a particular color in the preceding oddball task, then this was considered a ‘match’. The 2AFC response options were ‘match’ or ‘no match’. For example, if the letter ‘A’ was most often shown together with a specific shade of green as the background color during the preceding odd-ball task, then ‘A’ would <italic>match</italic> this shade of green. Match and no-match conditions were presented in a 1:1 ratio of the number of trials. Participants could respond as soon as the color was presented on screen. Participants were instructed to indicate whether the letter-color pairs matched or not with either a left or a right button press (button order was counterbalanced between participants). The letter-color visual decision task consisted of 250 trials in total, during which participants had three self-paced breaks. The order of the trials was randomly presented to each participant.</p></sec><sec id="s4-3-6"><title>Letter-color 2AFC task trial structure</title><p>Each trial of the letter-color visual decision task consisted of a new trial cue period (0.2 s), a letter-stimulus period (0.75 s), a short delay period (0.1 s), a response period during which a colored square appeared (&lt;2.5 s), a longer delay period to give sufficient time for the pupil to return to baseline following a colored impulse (3.5–5.5 s, uniform distribution; see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A, B</xref>; <xref ref-type="bibr" rid="bib65">Mathot, 2018</xref>), and an inter-trial interval that included feedback on accuracy (3.5–5.5 s, uniform distribution). A black fixation cross was presented in the center of the screen during the longer delay period preceding feedback as well as in the inter-trial interval. Trial-by-trial feedback was presented to the participants by means of two auditory tones (0.3 s) for errors (3rd octave ‘D’) and correct trials (4th octave ‘B’). We verified that the tone-locked pupil response was not differentially affected by the two feedback tones irrespective of the task context (see <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1C, D</xref>). Participants were familiarized with the feedback tones before the decision task began. All stimuli were presented in the center of the screen against a gray background. The letter-color decision 2AFC task took about one hour to complete.</p></sec><sec id="s4-3-7"><title>Data acquisition and preprocessing</title><p>Pupil dilation of the left or right eye was continuously recorded during the letter-color visual decision task using an EyeLink eye-tracker (SR Research, Ottawa, Ontario, Canada) with a sampling rate of 1000 Hz. The eye-tracker was calibrated once at the start of the decision task. A drift correction was performed after participants took breaks and could move their heads before continuing. Eye blinks and saccades were detected using the standard EyeLink software algorithms (default settings). We aimed to keep the pre-processing pipelines between the two data sets as similar as possible. Using custom Python code, the following steps were applied to the entire pupil dilation time series: (i) linear interpolation around missing samples (0.15 s before and after each missing event), (ii) linear interpolation around blinks or saccade events based on spikes in the temporal derivative (0.15 s before and after each nuisance event), (iii) band-pass filtering (third-order Butterworth, 0.01–6 Hz), (iv) responses to nuisance events were removed using linear regression (nuisance responses were estimated using deconvolution; <xref ref-type="bibr" rid="bib51">Knapen et al., 2016</xref>) and (v) the residuals of the nuisance regression were converted to percent signal change with respect to the temporal mean. The size of the interpolation window preceding nuisance events was based on previous literature (<xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib51">Knapen et al., 2016</xref>; <xref ref-type="bibr" rid="bib120">Winn et al., 2018</xref>). After interpolation based on data markers and/or missing values, remaining blinks and saccades were estimated by testing the first derivative of the pupil dilation time series against a threshold rate of change. The threshold for identifying peaks in the temporal derivative is data-driven, partially based on past work (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib20">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>). The output of each participant’s pre-processing pipeline was checked visually. Once an appropriate threshold was established at the group level, it remained the same for all participants (minimum peak height of 10 units). Missed trials were excluded from all analyses (0.9%).</p></sec></sec><sec id="s4-4"><title>Quantification of the feedback-locked pupil response</title><p>After pre-processing of the pupil data in both tasks, each trial time course was baseline corrected in percent signal change units. The baseline window was defined per trial as the mean pupil size during the 0.5 s before the feedback event (target onset or auditory feedback for the cue-target and letter-color 2AFC tasks, respectively; <xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>). The same time windows were used for both tasks with respect to the feedback event. Feedback-locked pupil responses were defined by the mean pupil response within two time windows of interest: An early time window was defined to be 0.75–1.25 seconds after feedback onset to be centered around the peak of a transient event based on the canonical impulse response function of the pupil (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">de Gee et al., 2021</xref>; <xref ref-type="bibr" rid="bib19">de Gee et al., 2014</xref>; <xref ref-type="bibr" rid="bib41">Hoeks and Levelt, 1993</xref>). A late time window was defined to be 2.5–3 s after feedback onset and was determined by the shortest feedback interval within both decision tasks to make sure that the pupil response was uncontaminated by the subsequent trial: in the cue-target 2AFC task, a new trial started 3 s after the feedback onset. Several sanity checks related to the pre-processing pipeline were carried out on the feedback-locked pupil response (see Appendix 4). The raw and interpolated time courses are shown before the (blink and saccade) nuisance regression (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>, top two rows, respectively). We present a conservative analysis in which only trials with more than half of original (i.e. non-interpolated) data are included in the analyses (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>, third row). Finally, the nuisance predictor time courses (based on blink and saccade events) are shown for the same conditions as the feedback-locked pupil response (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>, bottom row).</p></sec><sec id="s4-5"><title>Ideal learner models</title><p>Following previous literature (<xref ref-type="bibr" rid="bib82">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib64">Mars et al., 2008</xref>; <xref ref-type="bibr" rid="bib84">Poli et al., 2020</xref>), we adapted an ideal learner model to each of the two datasets separately. To model the learning of the task by participants, we assumed that they acted as ideal observers who learn the probability of seeing each of the stimulus pair types as the experiment progressed across trials. For each decision-making task, trial-by-trial quantifications of KL divergence between the posterior and prior belief distributions were estimated using information theory to formally quantify information gain. In addition, surprise and entropy were computed and assumed to reflect the subjective probability and average uncertainty on each trial, respectively.</p><p>The ideal learner model for both data sets follows from the algorithms described by <xref ref-type="bibr" rid="bib64">Mars et al., 2008</xref>; <xref ref-type="bibr" rid="bib84">Poli et al., 2020</xref>. The ideal learner model represents a set of discrete events <inline-formula><alternatives><mml:math id="inf1"><mml:mi>x</mml:mi></mml:math><tex-math id="inft1">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula><italic>,</italic> which can range from one to <inline-formula><alternatives><mml:math id="inf2"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>K</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula>. The events follow each other in a sequence with its length, <inline-formula><alternatives><mml:math id="inf3"><mml:mi>j</mml:mi></mml:math><tex-math id="inft3">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>, equal to the number of trials in the task and denoted by <inline-formula><alternatives><mml:math id="inf4"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}$X^{j}=\left \{x^{1},\ldots ,x^{\,j}\right \}$\end{document}</tex-math></alternatives></inline-formula>. We assume the participants learn the probabilities of <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$X^{\,j}$\end{document}</tex-math></alternatives></inline-formula> occurring, and following each trial, they update their estimate of the probability that each event type will occur based on the previously observed events. The distribution of probabilities can be parametrized by the vector <inline-formula><alternatives><mml:math id="inf6"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="inft6">\begin{document}$P\left (x\right)=\left [p_{1},\ldots ,p_{K}\right ]$\end{document}</tex-math></alternatives></inline-formula>, the elements of which sum to one and will be abbreviated by <inline-formula><alternatives><mml:math id="inf7"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>p</mml:mi></mml:math><tex-math id="inft7">\begin{document}$P\left (x\right)=p$\end{document}</tex-math></alternatives></inline-formula>. Note that the probability of the <inline-formula><alternatives><mml:math id="inf8"><mml:mi>k</mml:mi></mml:math><tex-math id="inft8">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula> th event occurring, <inline-formula><alternatives><mml:math id="inf9"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced></mml:math><tex-math id="inft9">\begin{document}$P\left (x=k\right)$\end{document}</tex-math></alternatives></inline-formula>, is denoted by <inline-formula><alternatives><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft10">\begin{document}$p_{k}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Following previous literature (<xref ref-type="bibr" rid="bib64">Mars et al., 2008</xref>; <xref ref-type="bibr" rid="bib84">Poli et al., 2020</xref>), we assumed a Bayesian paradigm of giving the observer prior knowledge represented by a prior distribution of beliefs. This takes the form of a Dirichlet distribution which indicates the belief in all parameters prior to any observations of events. A Dirichlet prior over <inline-formula><alternatives><mml:math id="inf11"><mml:mi>p</mml:mi></mml:math><tex-math id="inft11">\begin{document}$p$\end{document}</tex-math></alternatives></inline-formula> is parameterized by the vector <inline-formula><alternatives><mml:math id="inf12"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft12">\begin{document}$\alpha =\left [\alpha_{1,}\ldots ,\alpha_{K}\right ]$\end{document}</tex-math></alternatives></inline-formula> and denoted by <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}$P\left (p|\alpha\right)=Dir\left (p;\alpha_{k}\right)$\end{document}</tex-math></alternatives></inline-formula>. All elements of <inline-formula><alternatives><mml:math id="inf14"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft14">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> are positive and the magnitude of each element corresponds to the relative expectation of each element. When the ideal learner has no previous expectations about which event will occur before the first trial of the task begins, all events are considered equally likely to occur and all the elements of <inline-formula><alternatives><mml:math id="inf15"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft15">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> would be set to one (i.e. a uniform prior distribution). For example, if <inline-formula><alternatives><mml:math id="inf16"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft16">\begin{document}$\alpha=\left [100,1,1,1\right ]$\end{document}</tex-math></alternatives></inline-formula>, then the ideal learner model assumes that the event represented by the first element in <inline-formula><alternatives><mml:math id="inf17"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft17">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> is much more likely to occur than any other event.</p><p>After an event is observed, the estimated probabilities <inline-formula><alternatives><mml:math id="inf18"><mml:mi>p</mml:mi></mml:math><tex-math id="inft18">\begin{document}$p$\end{document}</tex-math></alternatives></inline-formula> will be updated. The belief after <inline-formula><alternatives><mml:math id="inf19"><mml:mi>j</mml:mi></mml:math><tex-math id="inft19">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> trials, <inline-formula><alternatives><mml:math id="inf20"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}$X^{\,j}$\end{document}</tex-math></alternatives></inline-formula>, is given by the posterior distribution<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  P\left (p| X^{\,j}, \alpha\right)=Dir\left (p^{\,j};n_{k}^{\,j}+\alpha_{k}\right)={D}^{\,j},$$\end{document}</tex-math></alternatives></disp-formula></p><p>in which <inline-formula><alternatives><mml:math id="inf21"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft21">\begin{document}$n_{k}^{\,j}$\end{document}</tex-math></alternatives></inline-formula> refers to the number of occurrences of event type <inline-formula><alternatives><mml:math id="inf22"><mml:mi>k</mml:mi></mml:math><tex-math id="inft22">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula> until trial <inline-formula><alternatives><mml:math id="inf23"><mml:mi>j</mml:mi></mml:math><tex-math id="inft23">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>, and the parameter, <inline-formula><alternatives><mml:math id="inf24"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft24">\begin{document}$\alpha_{k}$\end{document}</tex-math></alternatives></inline-formula>, determines prior expectations of event type <inline-formula><alternatives><mml:math id="inf25"><mml:mi>k</mml:mi></mml:math><tex-math id="inft25">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula> occurring. The posterior distribution given in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> is updated after each new observation of an event and is abbreviated as <inline-formula><alternatives><mml:math id="inf26"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft26">\begin{document}$D^{\,j}$\end{document}</tex-math></alternatives></inline-formula>. For example, if <inline-formula><alternatives><mml:math id="inf27"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft27">\begin{document}$\alpha =\left [100,1,1,1\right ]$\end{document}</tex-math></alternatives></inline-formula> and the participant observes an event represented by the second element in <inline-formula><alternatives><mml:math id="inf28"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft28">\begin{document}$\alpha$\end{document}</tex-math></alternatives></inline-formula> on the first trial, then the posterior distribution becomes <inline-formula><alternatives><mml:math id="inf29"><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math><tex-math id="inft29">\begin{document}$\left [100,2,1,1\right ]$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf30"><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft30">\begin{document}$j=1$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The probability of a certain event occurring at trial <inline-formula><alternatives><mml:math id="inf31"><mml:mi>j</mml:mi></mml:math><tex-math id="inft31">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> can be computed directly from (1) as<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msubsup><mml:mover><mml:mi>p</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle p\left (x^{\,j}=k| X^{\,j- 1},\alpha \right)=\frac{\left (n_{k}^{\,j- 1}+\alpha _{k}\right)}{\left (j- 1+K\right)}=\overset{\sim}{p}_{k}^{\,j}$$\end{document}</tex-math></alternatives></disp-formula></p><p>In words, <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> states that the probability that a certain event <inline-formula><alternatives><mml:math id="inf32"><mml:mi>k</mml:mi></mml:math><tex-math id="inft32">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula> will occur on trial <inline-formula><alternatives><mml:math id="inf33"><mml:mi>j</mml:mi></mml:math><tex-math id="inft33">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> is denoted by <inline-formula><alternatives><mml:math id="inf34"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft34">\begin{document}$\overset{\sim }{p}_{k}^{j}$\end{document}</tex-math></alternatives></inline-formula> (note the tilde indicates a prediction), which is equal to the total number of times event <italic>k</italic> occurred in previous trials <inline-formula><alternatives><mml:math id="inf35"><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft35">\begin{document}$j- 1$\end{document}</tex-math></alternatives></inline-formula> plus the value of <inline-formula><alternatives><mml:math id="inf36"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft36">\begin{document}$\alpha _{k}$\end{document}</tex-math></alternatives></inline-formula>, which is known to be fixed in the prior distribution, then divided by the total number of observations up to and including <inline-formula><alternatives><mml:math id="inf37"><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft37">\begin{document}$j- 1$\end{document}</tex-math></alternatives></inline-formula> plus the total number of possible event types <inline-formula><alternatives><mml:math id="inf38"><mml:mi>K</mml:mi></mml:math><tex-math id="inft38">\begin{document}$K$\end{document}</tex-math></alternatives></inline-formula>.</p><sec id="s4-5-1"><title>Information-theoretic variables</title><p>Information theory (<xref ref-type="bibr" rid="bib64">Mars et al., 2008</xref>; <xref ref-type="bibr" rid="bib84">Poli et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Attneave, 1959</xref>; <xref ref-type="bibr" rid="bib102">Shannon, 1948</xref>; <xref ref-type="bibr" rid="bib110">Strange et al., 2005</xref>) is used to estimate the information gain, surprise, and entropy at each trial. The subjective probability of each event occurring was quantified as surprise in terms of Shannon information, <italic>I</italic><disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mover><mml:mi>p</mml:mi><mml:mo>∼</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle I\left (x^{\,j}=k\right)=- log_{2}\overset{\sim}{p}_{k}^{\,j}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Note that <inline-formula><alternatives><mml:math id="inf39"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft39">\begin{document}$\overset{\sim }{p}_{k}^{j}$\end{document}</tex-math></alternatives></inline-formula> is given by <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> and represents the prediction of the probability of event <inline-formula><alternatives><mml:math id="inf40"><mml:mi>k</mml:mi></mml:math><tex-math id="inft40">\begin{document}$k$\end{document}</tex-math></alternatives></inline-formula> occurring at trial <inline-formula><alternatives><mml:math id="inf41"><mml:mi>j</mml:mi></mml:math><tex-math id="inft41">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> based on what has been observed up to and including trial <inline-formula><alternatives><mml:math id="inf42"><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft42">\begin{document}$j- 1$\end{document}</tex-math></alternatives></inline-formula>. The negative logarithm ensures that highly probable events are considered as less surprising.</p><p>The average uncertainty of the event at each trial was quantified as the entropy, <inline-formula><alternatives><mml:math id="inf43"><mml:mi>H</mml:mi></mml:math><tex-math id="inft43">\begin{document}$H$\end{document}</tex-math></alternatives></inline-formula>,<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  H\left (p^{\,j}\right)=- \sum _{k=1}^{k}p_{k}^{\,j}log_{2}p_{k}^{\,j}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Note that entropy was calculated including the observation of the event at trial <inline-formula><alternatives><mml:math id="inf44"><mml:mi>j</mml:mi></mml:math><tex-math id="inft44">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>, denoted by <inline-formula><alternatives><mml:math id="inf45"><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft45">\begin{document}$p_{k}^{j}$\end{document}</tex-math></alternatives></inline-formula>, not just up to trial <inline-formula><alternatives><mml:math id="inf46"><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft46">\begin{document}$j- 1$\end{document}</tex-math></alternatives></inline-formula>, because the participants received the information related to trial <inline-formula><alternatives><mml:math id="inf47"><mml:mi>j</mml:mi></mml:math><tex-math id="inft47">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> at the time of feedback presentation.</p><p>Finally, the information gain at each trial was quantified as the KL divergence, <italic>D<sub>KL</sub>,</italic><disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfrac><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  D_{KL}^{\,j}\left (p^{\,j}| p^{\,j- 1}\right)=\sum _{k=1}^{k}p_{k}^{\,j}log_{2}\frac{p_{k}^{\,j}}{p_{k}^{\,j- 1}},$$\end{document}</tex-math></alternatives></disp-formula></p><p>between the posterior and prior distributions at trial <inline-formula><alternatives><mml:math id="inf48"><mml:mi>j</mml:mi></mml:math><tex-math id="inft48">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula>. Note that this KL divergence is sometimes referred to as a ‘Bayesian surprise’ (<xref ref-type="bibr" rid="bib44">Itti and Baldi, 2005</xref>; <xref ref-type="bibr" rid="bib45">Itti and Baldi, 2009</xref>). Here, when referring to ‘surprise’, we are always referring to the Shannon information as given by <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>.</p></sec><sec id="s4-5-2"><title>Ideal learner model assumptions for data set #1: cue-target 2AFC task</title><p>In the cue-target 2AFC task, an event was defined as one of the four possible cue-target pairs determined by the two cues (square and diamond) and two target orientations (left and right). Therefore, in the cue-target 2AFC task, <inline-formula><alternatives><mml:math id="inf49"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math><tex-math id="inft49">\begin{document}$K=4$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf50"><mml:mi>x</mml:mi></mml:math><tex-math id="inft50">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula> could take on values from 1 to 4. We assumed that the participants had no prior knowledge about the probabilities of events occurring at the start of the cue-target 2AFC task, and therefore, all events are assumed to be equally likely in the prior distribution. Since there are four possible events that can occur in the cue-target 2AFC task, then <inline-formula><alternatives><mml:math id="inf51"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="inft51">\begin{document}$P\left (x\right)=\left [p_{1},p_{2},p_{3},p_{4}\right ]$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf52"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft52">\begin{document}$\alpha=\left [1,1,1,1\right ]$\end{document}</tex-math></alternatives></inline-formula>. Note that this resulted in a belief that all four cue-target pairs were likely to occur 25% of the time. We also note that while the ideal learner model for the cue-target 2AFC task used a uniform (flat) prior distribution for all participants, the model parameters were based on the participant-specific cue-target counterbalancing conditions and randomized trial order.</p></sec><sec id="s4-5-3"><title>Ideal learner model assumptions for data set #2: letter-color 2AFC task</title><p>For the letter-color 2AFC task, during which pupil dilation was recorded, there were six letters and six shades of green used as stimuli. An event was defined as one of the 36 possible letter-color pairs; therefore, <inline-formula><alternatives><mml:math id="inf53"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>36</mml:mn></mml:math><tex-math id="inft53">\begin{document}$K=36$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf54"><mml:mi>x</mml:mi></mml:math><tex-math id="inft54">\begin{document}$x$\end{document}</tex-math></alternatives></inline-formula> could take on values from one to 36 and <inline-formula><alternatives><mml:math id="inf55"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>36</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="inft55">\begin{document}$P\left (x\right)=\left [p_{1},\ldots ,p_{36}\right ]$\end{document}</tex-math></alternatives></inline-formula>. We assumed that the participants started the letter-color 2AFC task with prior beliefs about the probabilities of the 36 letter-color pairs based on their observations during the preceding odd-ball task. The prior distribution for the letter-color 2AFC ideal learner model was given by <inline-formula><alternatives><mml:math id="inf56"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mn>36</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft56">\begin{document}$\alpha=P_{o}\left (x\right)=\left [p_{1},\ldots ,p_{36}\right ]$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf57"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft57">\begin{document}$P_{o}$\end{document}</tex-math></alternatives></inline-formula> refers to the final probabilities of all 36 event types occurring at the end of the odd-ball task. Thus, the prior distributions used for the letter-color 2AFC task were estimated from the randomized letter-color pairs and randomized trial order in the preceding odd-ball task; this resulted in participant-specific prior distributions for the ideal learner model of the letter-color 2AFC task. The model parameters were likewise estimated from the (participant-specific) randomized trial order presented in the letter-color 2AFC task. Note that the probabilities of the odd-ball stimuli (i.e., an odd color or number) occurring were not estimated in the model. Unlike in the odd-ball task, the 36 letter-color pairs occurred at equal frequency in the letter-color 2AFC task; the occurrence of response options (match vs. no match) was also balanced. Learning about the letter-color probabilities could still occur, however, through the presentation of trial-by-trial feedback on accuracy.</p></sec></sec><sec id="s4-6"><title>Software and statistical analysis</title><p>All data and code used are publicly available (see link in data availability statement). All tasks were presented with PsychoPy (cue-target 2AFC task, version 1.81; letter-color 2AFC, version 1.82). Custom software in Python (version 3.6) was used for the preprocessing and data analysis with the exception of the repeated-measures ANOVAs, t-tests, and linear mixed modeling analysis (see below). Note that the (<xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>) data set has been re-analyzed here and the above refers to the corresponding code for the current study. Python-specific packages and versions used are listed in the code repository.</p><p>Statistical inference on the evoked pupil responses was conducted with cluster-based permutation test from the MNE-Python package (<xref ref-type="bibr" rid="bib36">Gramfort et al., 2013</xref>) unless otherwise stated. When the cluster-based permutation test could not be applied to a simple difference between two conditions, the evoked pupil responses were corrected with the false discovery rate instead. Repeated-measures ANOVAs and paired-samples t-tests were conducted using JASP version 0.16.3 (<xref ref-type="bibr" rid="bib46">JASP Team, 2022</xref>). Wilcoxon signed-ranked t-tests were used when normality was deviated, and effect size is indicated by the matched rank biserial correlation (r<sub>rb</sub>). For ANOVA results, Greenhouse-Geisser statistics are reported for violations of the assumption of sphericity and generalized eta squared (η<sup>2</sup><sub>G</sub>) is reported as the effect size. In repeated-measures designs, η<sup>2</sup><sub>G</sub> is useful as it can be more easily compared with between-subject designs (<xref ref-type="bibr" rid="bib58">Lakens, 2013</xref>; <xref ref-type="bibr" rid="bib81">Olejnik and Algina, 2003</xref>).</p><sec id="s4-6-1"><title>Comparing the information-theoretic variables to the feedback-locked pupil response</title><p>We sought to examine the overall relationship each of the information-theoretic variables has with the post-feedback pupil response. Furthermore, it was expected that these explanatory variables would be correlated with one another. For this reason, we pursued two complementary approaches to the model fitting (<xref ref-type="bibr" rid="bib73">Morrissey and Ruxton, 2018</xref>): a ‘simple’ correlation analysis and a linear mixed model comparison. Both the correlation analysis and linear mixed model comparison were done for all trials and then separately for error and correct trials.</p><p>First, in the correlation analysis, for each decision task and per participant, we computed the trial-by-trial correlations between the feedback-locked pupil response at each time point in the time course (i.e. in the interval 0–3 s) and the surprise, entropy, and information gain in bits. Correlation coefficients were normalized using the Fisher transform (<xref ref-type="bibr" rid="bib28">Fisher, 1915</xref>) then averaged across participants. Statistical significance of the coefficients at the group level was assessed using non-parametric cluster-based permutation tests (MNE-Python package).</p><p>Second, in a complementary linear mixed model analysis, we compared two linear models to evaluate which combination of predictor variables provided the best fit to the feedback-locked pupil response as the dependent variable. Each model fit included the data for all participants and was done independently for each decision task and time window of interest (early and late). Model 1 consisted of the three model parameters, surprise, entropy, and information gain. Model 2 was identical to Model 1 except that an interaction term between entropy and information gain was additionally included. The pre-feedback baseline pupil dilation and reaction times were included as additional predictor (nuisance) variables in both models for the following reasons: The pre-feedback baseline pupil dilation was expected to improve the overall model fits to the feedback-locked pupil response, as event-related pupil responses are partially determined by the size of the proceeding baseline pupil dilation (<xref ref-type="bibr" rid="bib19">de Gee et al., 2014</xref>). Both simple motor actions as well as statistical confidence/uncertainty about decisions have been shown to scale with the response-locked pupil signal (<xref ref-type="bibr" rid="bib16">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="bib113">Urai et al., 2017</xref>; <xref ref-type="bibr" rid="bib41">Hoeks and Levelt, 1993</xref>; <xref ref-type="bibr" rid="bib42">Hupé et al., 2009</xref>). Therefore, reaction time differences may have contributed to the variation in the feedback-locked pupil response; although we note that both tasks included relatively long inter-stimulus intervals (at least 3 s) following the motor responses on each trial before feedback was presented to allow the pupil response sufficient time to return to baseline. Both models included a constant term and ‘subject’ as a random effect; all other effects were modeled as fixed effects. Data were modeled with Bayesian regression modeling (<italic>brms</italic>) using the <italic>brm</italic> function of the <italic>brms</italic> package in the software package R (R Studio Version 2024.12.1+563) with 10,000 iterations, 5000 warm-ups, and four chains (<xref ref-type="bibr" rid="bib11">Bürkner, 2017</xref>). Other settings used were the default parameters unless otherwise stated. We confirmed that all chains converged to the same posterior distribution (all Rhats = 1). Model comparison was performed using Pareto smoothed importance sampling and leave-one-out cross-validation in the <italic>looic</italic> toolbox in R (<xref ref-type="bibr" rid="bib116">Vehtari et al., 2017</xref>). The <italic>loo</italic> function automatically designates the best-performing model with the highest expected log predictive density (ELPD) as the ‘standard’ model. To assess relative model performance between the models, the ratio between the difference in ELPD and the difference in the corresponding standard error was computed: ratios greater than two were considered to be statistically meaningful (<xref ref-type="bibr" rid="bib49">Kelter, 2021</xref>; <xref ref-type="bibr" rid="bib68">Merkle and Rosseel, 2018</xref>). The linear models that were compared to each other are given below in their equation format, where <italic>I</italic> represents Shannon surprise, <italic>H</italic> represents entropy, and <italic>D<sub>KL</sub></italic> represents information gain:</p><list list-type="simple" id="list1"><list-item><p><underline>Model 1:</underline> pupil ~ <italic>I</italic> + <italic>H</italic> + <italic>D<sub>KL</sub></italic> + pre-feedback baseline pupil + reaction time + (1|subject)</p></list-item><list-item><p><underline>Model 2:</underline> pupil ~ <italic>I</italic> + <italic>H*D<sub>KL</sub></italic> + pre-feedback baseline pupil + reaction time + (1|subject)</p></list-item></list></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experiments were conducted on human participants and were approved by the Ethical Committee of the Faculty of Social Sciences at the Radboud University, the Netherlands (data set #1: ECSW2016-0905-396; data set #2: ECSW-2018-115).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-105287-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All behavioral and physiological data for data set #2, along with the the code for the analyses of both data sets, are openly accessible at the Radboud University Data Repository: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.34973/dt44-x857">https://doi.org/10.34973/dt44-x857</ext-link>. Data set #1 was previously published and the article is available at: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0270619">https://doi.org/10.1371/journal.pone.0270619</ext-link>.</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Rutar</surname><given-names>D</given-names></name><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Spieß</surname><given-names>L</given-names></name><name><surname>Kwisthout</surname><given-names>JHP</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Differentiating between Bayesian parameter learning and structure learning based on behavioural and pupil measures</data-title><source>Radboud University Data Repository</source><pub-id pub-id-type="doi">10.34973/t41p-hx94</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to thank and acknowledge Yibrán Amador Pacheco Sáez, Filip Novický, Francesco Poli, Luke Miller, Lieke van Lieshout, Anna Umurzakova, and the Karl Friston Lab for helpful insight and discussions at various stages of the research presented here. We would also like to thank the reviewers and editors who helped improve the manuscript with their constructive feedback. This research was funded by the Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, The Netherlands.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alamia</surname><given-names>A</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name><name><surname>Pasqualotto</surname><given-names>E</given-names></name><name><surname>Mouraux</surname><given-names>A</given-names></name><name><surname>Zenon</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Pupil-linked arousal responds to unconscious surprisal</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>5369</fpage><lpage>5376</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3010-18.2019</pub-id><pub-id pub-id-type="pmid">31061089</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Statistical learning: a powerful mechanism that operates by mere exposure</article-title><source>Wiley Interdisciplinary Reviews. Cognitive Science</source><volume>8</volume><elocation-id>e1373</elocation-id><pub-id pub-id-type="doi">10.1002/wcs.1373</pub-id><pub-id pub-id-type="pmid">27906526</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine1481 function: adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Attneave</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1959">1959</year><source>Applications of Information Theory to Psychology: A Summary of Basic Concepts, Methods, and Results</source><publisher-loc>Oxford, England</publisher-loc><publisher-name>Henry Holt</publisher-name></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbur</surname><given-names>JL</given-names></name><name><surname>Harlow</surname><given-names>AJ</given-names></name><name><surname>Sahraie</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Pupillary responses to stimulus structure, colour and movement</article-title><source>Ophthalmic &amp; Physiological Optics</source><volume>12</volume><fpage>137</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1111/j.1475-1313.1992.tb00276.x</pub-id><pub-id pub-id-type="pmid">1408159</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname><given-names>A</given-names></name><name><surname>Kiefer</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Comparison of different response time outlier exclusion methods: a simulation study</article-title><source>Frontiers in Psychology</source><volume>12</volume><elocation-id>675558</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2021.675558</pub-id><pub-id pub-id-type="pmid">34194371</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bianco</surname><given-names>R</given-names></name><name><surname>Ptasczynski</surname><given-names>LE</given-names></name><name><surname>Omigie</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil responses to pitch deviants reflect predictability of melodic sequences</article-title><source>Brain and Cognition</source><volume>138</volume><elocation-id>103621</elocation-id><pub-id pub-id-type="doi">10.1016/j.bandc.2019.103621</pub-id><pub-id pub-id-type="pmid">31862512</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braem</surname><given-names>S</given-names></name><name><surname>Coenen</surname><given-names>E</given-names></name><name><surname>Bombeke</surname><given-names>K</given-names></name><name><surname>van Bochove</surname><given-names>ME</given-names></name><name><surname>Notebaert</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Open your eyes for prediction errors</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>15</volume><fpage>374</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.3758/s13415-014-0333-4</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Browning</surname><given-names>M</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Jocham</surname><given-names>G</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Bishop</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Anxious individuals have difficulty learning the causal statistics of aversive environments</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>590</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1038/nn.3961</pub-id><pub-id pub-id-type="pmid">25730669</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckley</surname><given-names>CL</given-names></name><name><surname>Kim</surname><given-names>CS</given-names></name><name><surname>McGregor</surname><given-names>S</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The free energy principle for action and perception: A mathematical review</article-title><source>Journal of Mathematical Psychology</source><volume>81</volume><fpage>55</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2017.09.004</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bürkner</surname><given-names>PC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>brms: an R package for bayesian multilevel models using stan</article-title><source>Journal of Statistical Software</source><volume>80</volume><fpage>1</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.18637/jss.v080.i01</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burlingham</surname><given-names>CS</given-names></name><name><surname>Mirbagheri</surname><given-names>S</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A unified model of the task-evoked pupil response</article-title><source>Science Advances</source><volume>8</volume><elocation-id>eabi9979</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abi9979</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheadle</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Myers</surname><given-names>N</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Herce Castañón</surname><given-names>S</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adaptive gain control during human perceptual choice</article-title><source>Neuron</source><volume>81</volume><fpage>1429</fpage><lpage>1441</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.020</pub-id><pub-id pub-id-type="pmid">24656259</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Predictions, precision, and agentive attention</article-title><source>Consciousness and Cognition</source><volume>56</volume><fpage>115</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.concog.2017.06.013</pub-id><pub-id pub-id-type="pmid">28693812</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colantonio</surname><given-names>J</given-names></name><name><surname>Bascandziev</surname><given-names>I</given-names></name><name><surname>Theobald</surname><given-names>M</given-names></name><name><surname>Brod</surname><given-names>G</given-names></name><name><surname>Bonawitz</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Seeing the error in my “bayes”: a quantified degree of belief change correlates with children’s pupillary surprise responses following explicit predictions</article-title><source>Entropy</source><volume>25</volume><elocation-id>211</elocation-id><pub-id pub-id-type="doi">10.3390/e25020211</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Task-evoked pupil responses reflect internal belief states</article-title><source>Scientific Reports</source><volume>8</volume><elocation-id>13702</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-31985-3</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Critchley</surname><given-names>HD</given-names></name><name><surname>Tang</surname><given-names>J</given-names></name><name><surname>Glaser</surname><given-names>D</given-names></name><name><surname>Butterworth</surname><given-names>B</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Anterior cingulate activity during error and autonomic response</article-title><source>NeuroImage</source><volume>27</volume><fpage>885</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.05.047</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Berker</surname><given-names>AO</given-names></name><name><surname>Rutledge</surname><given-names>RB</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Marshall</surname><given-names>L</given-names></name><name><surname>Cross</surname><given-names>GF</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Bestmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computations of uncertainty mediate acute stress responses in humans</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>10996</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms10996</pub-id><pub-id pub-id-type="pmid">27020312</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decision-related pupil dilation reflects upcoming choice and individual bias</article-title><source>PNAS</source><volume>111</volume><fpage>E618</fpage><lpage>E625</lpage><pub-id pub-id-type="doi">10.1073/pnas.1317557111</pub-id><pub-id pub-id-type="pmid">24449874</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic modulation of decision biases by brainstem arousal systems</article-title><source>eLife</source><volume>6</volume><elocation-id>e23232</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23232</pub-id><pub-id pub-id-type="pmid">28383284</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Correa</surname><given-names>CMC</given-names></name><name><surname>Weaver</surname><given-names>M</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>van Gaal</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Pupil dilation and the slow wave ERP reflect surprise about choice outcome resulting from intrinsic variability in decision confidence</article-title><source>Cerebral Cortex</source><volume>31</volume><fpage>3565</fpage><lpage>3578</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhab032</pub-id><pub-id pub-id-type="pmid">33822917</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Heilbron</surname><given-names>M</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How do expectations shape perception?</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>764</fpage><lpage>779</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.06.002</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>den Ouden</surname><given-names>HEM</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How prediction errors shape perception, attention, and motivation</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>548</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00548</pub-id><pub-id pub-id-type="pmid">23248610</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dijkstra</surname><given-names>N</given-names></name><name><surname>Warrington</surname><given-names>O</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Distinguishing neural correlates of prediction errors on perceptual content and detection of content</article-title><source>Journal of Cognitive Neuroscience</source><volume>37</volume><fpage>1173</fpage><lpage>1188</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_02290</pub-id><pub-id pub-id-type="pmid">39785692</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>H</given-names></name><name><surname>Burke</surname><given-names>T</given-names></name><name><surname>Sambrano</surname><given-names>DC</given-names></name><name><surname>Dial</surname><given-names>E</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Pupil size encodes uncertainty during exploration</article-title><source>Journal of Cognitive Neuroscience</source><volume>35</volume><fpage>1508</fpage><lpage>1520</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_02025</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filipowicz</surname><given-names>AL</given-names></name><name><surname>Glaze</surname><given-names>CM</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil diameter encodes the idiosyncratic, cognitive complexity of belief updating</article-title><source>eLife</source><volume>9</volume><elocation-id>e57872</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57872</pub-id><pub-id pub-id-type="pmid">32420866</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Findling</surname><given-names>C</given-names></name><name><surname>Skvortsova</surname><given-names>V</given-names></name><name><surname>Dromnelle</surname><given-names>R</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational noise in reward-guided learning drives behavioral variability in volatile environments</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>2066</fpage><lpage>2077</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0518-9</pub-id><pub-id pub-id-type="pmid">31659343</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1915">1915</year><article-title>Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population</article-title><source>Biometrika</source><volume>10</volume><elocation-id>507</elocation-id><pub-id pub-id-type="doi">10.2307/2331838</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Fleischmann</surname><given-names>R</given-names></name><name><surname>Meijer</surname><given-names>D</given-names></name><name><surname>Bayram</surname><given-names>B</given-names></name><name><surname>Pellegrini</surname><given-names>V</given-names></name><name><surname>Pomper</surname><given-names>U</given-names></name><name><surname>Spierings</surname><given-names>M</given-names></name><name><surname>Baumgartner</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Arousal-Related Mediation of Perceptual Belief Updating across Auditory Domains</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2025.09.10.675360</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>D</given-names></name><name><surname>Hakerem</surname><given-names>G</given-names></name><name><surname>Sutton</surname><given-names>S</given-names></name><name><surname>Fleiss</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Effect of stimulus uncertainty on the pupillary dilation response and the vertex evoked potential</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>34</volume><fpage>475</fpage><lpage>484</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(73)90065-5</pub-id><pub-id pub-id-type="pmid">4121320</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Hierarchical models in the brain</article-title><source>PLOS Computational Biology</source><volume>4</volume><elocation-id>e1000211</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000211</pub-id><pub-id pub-id-type="pmid">18989391</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gau</surname><given-names>R</given-names></name><name><surname>Noppeney</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How prior expectations shape multisensory perception</article-title><source>NeuroImage</source><volume>124</volume><fpage>876</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.09.045</pub-id><pub-id pub-id-type="pmid">26419391</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geng</surname><given-names>JJ</given-names></name><name><surname>Blumenfeld</surname><given-names>Z</given-names></name><name><surname>Tyson</surname><given-names>TL</given-names></name><name><surname>Minzenberg</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Pupil diameter reflects uncertainty in attentional selection during visual search</article-title><source>Frontiers in Human Neuroscience</source><volume>9</volume><elocation-id>435</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2015.00435</pub-id><pub-id pub-id-type="pmid">26300759</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghilardi</surname><given-names>T</given-names></name><name><surname>Poli</surname><given-names>F</given-names></name><name><surname>Meyer</surname><given-names>M</given-names></name><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>Hunnius</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Early roots of information-seeking: infants predict and generalize the value of information</article-title><source>eLife</source><volume>1</volume><elocation-id>92388.1</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.92388.1</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Understanding dopamine and reinforcement learning: the dopamine reward prediction error hypothesis</article-title><source>PNAS</source><volume>108</volume><fpage>15647</fpage><lpage>15654</lpage><pub-id pub-id-type="doi">10.1073/pnas.1014269108</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Goj</surname><given-names>R</given-names></name><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Brooks</surname><given-names>T</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MEG and EEG data analysis with MNE-Python</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id><pub-id pub-id-type="pmid">24431986</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grujic</surname><given-names>N</given-names></name><name><surname>Polania</surname><given-names>R</given-names></name><name><surname>Burdakov</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Neurobehavioral meaning of pupil size</article-title><source>Neuron</source><volume>112</volume><fpage>3381</fpage><lpage>3395</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2024.05.029</pub-id><pub-id pub-id-type="pmid">38925124</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haarsma</surname><given-names>J</given-names></name><name><surname>Fletcher</surname><given-names>PC</given-names></name><name><surname>Griffin</surname><given-names>JD</given-names></name><name><surname>Taverne</surname><given-names>HJ</given-names></name><name><surname>Ziauddeen</surname><given-names>H</given-names></name><name><surname>Spencer</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>C</given-names></name><name><surname>Katthagen</surname><given-names>T</given-names></name><name><surname>Goodyer</surname><given-names>I</given-names></name><name><surname>Diederen</surname><given-names>KMJ</given-names></name><name><surname>Murray</surname><given-names>GK</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Precision weighting of cortical unsigned prediction error signals benefits learning, is mediated by dopamine, and is impaired in psychosis</article-title><source>Molecular Psychiatry</source><volume>26</volume><fpage>5320</fpage><lpage>5333</lpage><pub-id pub-id-type="doi">10.1038/s41380-020-0803-8</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>DJ</given-names></name><name><surname>Arthur</surname><given-names>T</given-names></name><name><surname>Vine</surname><given-names>SJ</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Abd Rahman</surname><given-names>HR</given-names></name><name><surname>Han</surname><given-names>F</given-names></name><name><surname>Wilson</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Task-evoked pupillary responses track precision-weighted prediction errors and learning rate during interceptive visuomotor actions</article-title><source>Scientific Reports</source><volume>12</volume><elocation-id>22098</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-022-26544-w</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>ZW</given-names></name><name><surname>Hotellier</surname><given-names>L</given-names></name><name><surname>Paunov</surname><given-names>A</given-names></name><name><surname>Guo</surname><given-names>D</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Yu</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Pupil size reflects the relevance of reward prediction error and estimation uncertainty in upcoming choice</article-title><conf-name>Proceedings of the 46th Annual Conference of the CognitiveScience Society</conf-name><fpage>1591</fpage><lpage>1597</lpage></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoeks</surname><given-names>B</given-names></name><name><surname>Levelt</surname><given-names>WJM</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Pupillary dilation as a measure of attention: a quantitative system analysis</article-title><source>Behavior Research Methods, Instruments, &amp; Computers</source><volume>25</volume><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.3758/BF03204445</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupé</surname><given-names>JM</given-names></name><name><surname>Lamirel</surname><given-names>C</given-names></name><name><surname>Lorenceau</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Pupil dynamics during bistable motion perception</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.1167/9.7.10</pub-id><pub-id pub-id-type="pmid">19761325</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iglesias</surname><given-names>S</given-names></name><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Brodersen</surname><given-names>KH</given-names></name><name><surname>Kasper</surname><given-names>L</given-names></name><name><surname>Piccirelli</surname><given-names>M</given-names></name><name><surname>den Ouden</surname><given-names>HEM</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hierarchical prediction errors in midbrain and basal forebrain during sensory learning</article-title><source>Neuron</source><volume>80</volume><fpage>519</fpage><lpage>530</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.009</pub-id><pub-id pub-id-type="pmid">24139048</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Itti</surname><given-names>L</given-names></name><name><surname>Baldi</surname><given-names>PF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Baysian surprise attracts human attention</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Itti</surname><given-names>L</given-names></name><name><surname>Baldi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Bayesian surprise attracts human attention</article-title><source>Vision Research</source><volume>49</volume><fpage>1295</fpage><lpage>1306</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.09.007</pub-id><pub-id pub-id-type="pmid">18834898</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="software"><person-group person-group-type="author"><collab>JASP Team</collab></person-group><year iso-8601-date="2022">2022</year><data-title>JASP</data-title><version designator="Version 0.16.3">Version 0.16.3</version><source>Computer Software</source><ext-link ext-link-type="uri" xlink:href="https://jasp-stats.org/2022/06/16/introducing-jasp-0-16-3-quality-control-glms-bayesian-state-space-models-improvements-to-bayesian-anova-and-more/">https://jasp-stats.org/2022/06/16/introducing-jasp-0-16-3-quality-control-glms-bayesian-state-space-models-improvements-to-bayesian-anova-and-more/</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamp</surname><given-names>SM</given-names></name><name><surname>Donchin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>ERP and pupil responses to deviance in an oddball paradigm</article-title><source>Psychophysiology</source><volume>52</volume><fpage>460</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1111/psyp.12378</pub-id><pub-id pub-id-type="pmid">25369764</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayhan</surname><given-names>E</given-names></name><name><surname>Heil</surname><given-names>L</given-names></name><name><surname>Kwisthout</surname><given-names>J</given-names></name><name><surname>van Rooij</surname><given-names>I</given-names></name><name><surname>Hunnius</surname><given-names>S</given-names></name><name><surname>Bekkering</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Young children integrate current observations, priors and agent information to predict others’ actions</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0200976</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0200976</pub-id><pub-id pub-id-type="pmid">31116742</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelter</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Bayesian model selection in the M-open setting — approximate posterior inference and subsampling for efficient large-scale leave-one-out cross-validation via the difference estimator</article-title><source>Journal of Mathematical Psychology</source><volume>100</volume><elocation-id>102474</elocation-id><pub-id pub-id-type="doi">10.1016/j.jmp.2020.102474</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Meindertsma</surname><given-names>T</given-names></name><name><surname>van Loon</surname><given-names>AM</given-names></name><name><surname>Lamme</surname><given-names>VAF</given-names></name><name><surname>Bonneh</surname><given-names>YS</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Pupil size tracks perceptual content and surprise</article-title><source>The European Journal of Neuroscience</source><volume>41</volume><fpage>1068</fpage><lpage>1078</lpage><pub-id pub-id-type="doi">10.1111/ejn.12859</pub-id><pub-id pub-id-type="pmid">25754528</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Brascamp</surname><given-names>J</given-names></name><name><surname>Nuiten</surname><given-names>S</given-names></name><name><surname>Hoppenbrouwers</surname><given-names>S</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cognitive and ocular factors jointly determine pupil responses under equiluminance</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0155574</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0155574</pub-id><pub-id pub-id-type="pmid">27191166</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koenig</surname><given-names>S</given-names></name><name><surname>Uengoer</surname><given-names>M</given-names></name><name><surname>Lachnit</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupil dilation indicates the coding of past prediction errors: evidence for attentional learning theory</article-title><source>Psychophysiology</source><volume>55</volume><elocation-id>e13020</elocation-id><pub-id pub-id-type="doi">10.1111/psyp.13020</pub-id><pub-id pub-id-type="pmid">29023832</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishnamurthy</surname><given-names>K</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Sarode</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</article-title><source>Nature Human Behaviour</source><volume>1</volume><elocation-id>0107</elocation-id><pub-id pub-id-type="doi">10.1038/s41562-017-0107</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuchinke</surname><given-names>L</given-names></name><name><surname>Võ</surname><given-names>MLH</given-names></name><name><surname>Hofmann</surname><given-names>M</given-names></name><name><surname>Jacobs</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Pupillary responses during lexical decisions vary with word frequency but not emotional valence</article-title><source>International Journal of Psychophysiology</source><volume>65</volume><fpage>132</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2007.04.004</pub-id><pub-id pub-id-type="pmid">17532075</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Kwisthout</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>Prediction error weighting</source><publisher-name>Donders Institute</publisher-name><ext-link ext-link-type="uri" xlink:href="https://www.socsci.ru.nl/johank/Prediction_error.pdf">https://www.socsci.ru.nl/johank/Prediction_error.pdf</ext-link></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwisthout</surname><given-names>J</given-names></name><name><surname>Bekkering</surname><given-names>H</given-names></name><name><surname>van Rooij</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>To be precise, the details don’t matter: on predictive processing, precision, and level of detail of predictions</article-title><source>Brain and Cognition</source><volume>112</volume><fpage>84</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2016.02.008</pub-id><pub-id pub-id-type="pmid">27114040</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lak</surname><given-names>A</given-names></name><name><surname>Nomoto</surname><given-names>K</given-names></name><name><surname>Keramati</surname><given-names>M</given-names></name><name><surname>Sakagami</surname><given-names>M</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Midbrain dopamine neurons signal belief in choice accuracy during a perceptual decision</article-title><source>Current Biology</source><volume>27</volume><fpage>821</fpage><lpage>832</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.02.026</pub-id><pub-id pub-id-type="pmid">28285994</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakens</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs</article-title><source>Frontiers in Psychology</source><volume>4</volume><elocation-id>863</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00863</pub-id><pub-id pub-id-type="pmid">24324449</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lavín</surname><given-names>C</given-names></name><name><surname>San Martín</surname><given-names>R</given-names></name><name><surname>Rosales Jubal</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Pupil dilation signals uncertainty and surprise in a learning gambling task</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>7</volume><elocation-id>218</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2013.00218</pub-id><pub-id pub-id-type="pmid">24427126</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lempert</surname><given-names>KM</given-names></name><name><surname>Chen</surname><given-names>YL</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Relating pupil dilation and metacognitive confidence during auditory decision-making</article-title><source>PLOS ONE</source><volume>10</volume><elocation-id>e0126588</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0126588</pub-id><pub-id pub-id-type="pmid">25950839</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liao</surname><given-names>HI</given-names></name><name><surname>Yoneya</surname><given-names>M</given-names></name><name><surname>Kidani</surname><given-names>S</given-names></name><name><surname>Kashino</surname><given-names>M</given-names></name><name><surname>Furukawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Human pupillary dilation response to deviant auditory stimuli: Effects of stimulus properties and voluntary attention</article-title><source>Frontiers in Neuroscience</source><volume>10</volume><elocation-id>43</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2016.00043</pub-id><pub-id pub-id-type="pmid">26924959</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lloyd</surname><given-names>B</given-names></name><name><surname>de Voogd</surname><given-names>LD</given-names></name><name><surname>Mäki-Marttunen</surname><given-names>V</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Pupil size reflects activation of subcortical ascending arousal system nuclei during rest</article-title><source>eLife</source><volume>12</volume><elocation-id>e84822</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.84822</pub-id><pub-id pub-id-type="pmid">37367220</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maier</surname><given-names>ME</given-names></name><name><surname>Ernst</surname><given-names>B</given-names></name><name><surname>Steinhauser</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Error-related pupil dilation is sensitive to the evaluation of different error types</article-title><source>Biological Psychology</source><volume>141</volume><fpage>25</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2018.12.013</pub-id><pub-id pub-id-type="pmid">30597189</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Debener</surname><given-names>S</given-names></name><name><surname>Gladwin</surname><given-names>TE</given-names></name><name><surname>Harrison</surname><given-names>LM</given-names></name><name><surname>Haggard</surname><given-names>P</given-names></name><name><surname>Rothwell</surname><given-names>JC</given-names></name><name><surname>Bestmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Trial-by-trial fluctuations in the event-related electroencephalogram reflect dynamic changes in the degree of surprise</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>12539</fpage><lpage>12545</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2925-08.2008</pub-id><pub-id pub-id-type="pmid">19020046</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathot</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupillometry: psychology</article-title><source>Physiology, and Function</source><volume>1</volume><elocation-id>18</elocation-id><pub-id pub-id-type="doi">10.5334/joc.18</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathys</surname><given-names>C</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A Bayesian foundation for individual learning under uncertainty</article-title><source>Frontiers in Human Neuroscience</source><volume>5</volume><elocation-id>39</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2011.00039</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>David</surname><given-names>SV</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title><source>Neuron</source><volume>87</volume><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.038</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merkle</surname><given-names>EC</given-names></name><name><surname>Rosseel</surname><given-names>YB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>blavaan: Bayesian structural equation models via parameter expansion</article-title><source>Journal of Statistical Software</source><volume>85</volume><fpage>1</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.18637/jss.v085.i04</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain dynamics for confidence-weighted learning</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007935</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007935</pub-id><pub-id pub-id-type="pmid">32484806</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Modirshanechi</surname><given-names>A</given-names></name><name><surname>Becker</surname><given-names>S</given-names></name><name><surname>Brea</surname><given-names>J</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Surprise and novelty in the brain</article-title><source>Current Opinion in Neurobiology</source><volume>82</volume><elocation-id>102758</elocation-id><pub-id pub-id-type="doi">10.1016/j.conb.2023.102758</pub-id><pub-id pub-id-type="pmid">37619425</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montague</surname><given-names>PR</given-names></name><name><surname>Hyman</surname><given-names>SE</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Computational roles for dopamine in behavioural control</article-title><source>Nature</source><volume>431</volume><fpage>760</fpage><lpage>767</lpage><pub-id pub-id-type="doi">10.1038/nature03015</pub-id><pub-id pub-id-type="pmid">15483596</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moran</surname><given-names>RJ</given-names></name><name><surname>Campo</surname><given-names>P</given-names></name><name><surname>Symmonds</surname><given-names>M</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Free energy, precision and learning: the role of cholinergic neuromodulation</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>8227</fpage><lpage>8236</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4255-12.2013</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrissey</surname><given-names>MB</given-names></name><name><surname>Ruxton</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multiple regression is not multiple regressions: the meaning of multiple regression and the non-problem of collinearity</article-title><source>Philosophy, Theory, and Practice in Biology</source><volume>10</volume><elocation-id>003</elocation-id><pub-id pub-id-type="doi">10.3998/ptpbio.16039257.0010.003</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>O’Connell</surname><given-names>RG</given-names></name><name><surname>O’Sullivan</surname><given-names>M</given-names></name><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Pupil diameter covaries with BOLD activity in human locus coeruleus</article-title><source>Human Brain Mapping</source><volume>35</volume><fpage>4140</fpage><lpage>4154</lpage><pub-id pub-id-type="doi">10.1002/hbm.22466</pub-id><pub-id pub-id-type="pmid">24510607</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Vandekerckhove</surname><given-names>J</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Pupil-linked arousal determines variability in perceptual decision making</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003854</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003854</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>van Moort</surname><given-names>ML</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The pupillary orienting response predicts adaptive behavioral adjustment after errors</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0151763</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0151763</pub-id><pub-id pub-id-type="pmid">27010472</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Wilming</surname><given-names>N</given-names></name><name><surname>Hernandez-Bocanegra</surname><given-names>DC</given-names></name><name><surname>Prat-Ortega</surname><given-names>G</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Adaptive circuit dynamics across human cortex during evidence accumulation in changing environments</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>987</fpage><lpage>997</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00839-z</pub-id><pub-id pub-id-type="pmid">33903770</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Toward a computational role for locus coeruleus/norepinephrine arousal systems</article-title><source>Current Opinion in Behavioral Sciences</source><volume>59</volume><elocation-id>101407</elocation-id><pub-id pub-id-type="doi">10.1016/j.cobeha.2024.101407</pub-id><pub-id pub-id-type="pmid">39070697</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname><given-names>H</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Belief states as a framework to explain extra-retinal influences in visual cortex</article-title><source>Current Opinion in Neurobiology</source><volume>32</volume><fpage>45</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.10.013</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olejnik</surname><given-names>S</given-names></name><name><surname>Algina</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Generalized eta and omega squared statistics: measures of effect size for some common research designs</article-title><source>Psychological Methods</source><volume>8</volume><fpage>434</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1037/1082-989X.8.4.434</pub-id><pub-id pub-id-type="pmid">14664681</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Schüffelgen</surname><given-names>U</given-names></name><name><surname>Cuell</surname><given-names>SF</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dissociable effects of surprise and model update in parietal and anterior cingulate cortex</article-title><source>PNAS</source><volume>110</volume><fpage>E3660</fpage><lpage>E3669</lpage><pub-id pub-id-type="doi">10.1073/pnas.1305373110</pub-id><pub-id pub-id-type="pmid">23986499</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pajkossy</surname><given-names>P</given-names></name><name><surname>Gesztesi</surname><given-names>G</given-names></name><name><surname>Racsmány</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>How uncertain are you? Disentangling expected and unexpected uncertainty in pupil-linked brain arousal during reversal learning</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>23</volume><fpage>578</fpage><lpage>599</lpage><pub-id pub-id-type="doi">10.3758/s13415-023-01072-w</pub-id><pub-id pub-id-type="pmid">36823250</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poli</surname><given-names>F</given-names></name><name><surname>Serino</surname><given-names>G</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Hunnius</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Infants tailor their attention to maximize learning</article-title><source>Science Advances</source><volume>6</volume><elocation-id>eabb5053</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abb5053</pub-id><pub-id pub-id-type="pmid">32967830</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poli</surname><given-names>F</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Hunnius</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Curiosity and the dynamics of optimal exploration</article-title><source>Trends in Cognitive Sciences</source><volume>28</volume><fpage>441</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2024.02.001</pub-id><pub-id pub-id-type="pmid">38413257</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Press</surname><given-names>C</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Yon</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The perceptual prediction paradox</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>13</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.11.003</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname><given-names>K</given-names></name><name><surname>’t Hart</surname><given-names>B</given-names></name><name><surname>Einhauser</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil dilation signals surprise: evidence for noradrenaline’s role in decision making</article-title><source>Frontiers in Neuroscience</source><volume>5</volume><elocation-id>115</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2011.00115</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulcu</surname><given-names>E</given-names></name><name><surname>Browning</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The misestimation of uncertainty in affective disorders</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>865</fpage><lpage>875</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.07.007</pub-id><pub-id pub-id-type="pmid">31431340</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiyuan</surname><given-names>J</given-names></name><name><surname>Richer</surname><given-names>F</given-names></name><name><surname>Wagoner</surname><given-names>BL</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The pupil and stimulus probability</article-title><source>Psychophysiology</source><volume>22</volume><fpage>530</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1985.tb01645.x</pub-id><pub-id pub-id-type="pmid">4048353</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raisig</surname><given-names>S</given-names></name><name><surname>Welke</surname><given-names>T</given-names></name><name><surname>Hagendorf</surname><given-names>H</given-names></name><name><surname>van der Meer</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>I spy with my little eye: detection of temporal violations in event sequences and the pupillary response</article-title><source>International Journal of Psychophysiology</source><volume>76</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2010.01.006</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Smith</surname><given-names>PL</given-names></name><name><surname>Brown</surname><given-names>SD</given-names></name><name><surname>McKoon</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Diffusion decision model: current issues and history</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>260</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.01.007</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Rodenkirch</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13289</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richer</surname><given-names>F</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Contrasting effects of response uncertainty on the task-evoked pupillary response and reaction time</article-title><source>Psychophysiology</source><volume>24</volume><fpage>258</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1987.tb00291.x</pub-id><pub-id pub-id-type="pmid">3602280</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rondeel</surname><given-names>EWM</given-names></name><name><surname>van Steenbergen</surname><given-names>H</given-names></name><name><surname>Holland</surname><given-names>RW</given-names></name><name><surname>van Knippenberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A closer look at cognitive control: differences in resource allocation during updating, inhibition and switching as revealed by pupillometry</article-title><source>Frontiers in Human Neuroscience</source><volume>9</volume><elocation-id>494</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2015.00494</pub-id><pub-id pub-id-type="pmid">26441594</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutar</surname><given-names>D</given-names></name><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>Selen</surname><given-names>L</given-names></name><name><surname>Spieß</surname><given-names>L</given-names></name><name><surname>Kwisthout</surname><given-names>J</given-names></name><name><surname>Hunnius</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Differentiating between bayesian parameter learning and structure learning based on behavioural and pupil measures</article-title><source>PLOS ONE</source><volume>18</volume><elocation-id>e0270619</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0270619</pub-id><pub-id pub-id-type="pmid">36795714</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sales</surname><given-names>AC</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Jones</surname><given-names>MW</given-names></name><name><surname>Pickering</surname><given-names>AE</given-names></name><name><surname>Moran</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Locus coeruleus tracking of prediction errors optimises cognitive flexibility: an active inference model</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006267</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006267</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanders</surname><given-names>JI</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Signatures of a statistical computation in the human sense of confidence</article-title><source>Neuron</source><volume>90</volume><fpage>499</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.025</pub-id><pub-id pub-id-type="pmid">27151640</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sara</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The locus coeruleus and noradrenergic modulation of cognition</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>211</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nrn2573</pub-id><pub-id pub-id-type="pmid">19190638</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satterthwaite</surname><given-names>TD</given-names></name><name><surname>Green</surname><given-names>L</given-names></name><name><surname>Myerson</surname><given-names>J</given-names></name><name><surname>Parker</surname><given-names>J</given-names></name><name><surname>Ramaratnam</surname><given-names>M</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dissociable but inter-related systems of cognitive control and reward during decision making: evidence from pupillometry and event-related fMRI</article-title><source>NeuroImage</source><volume>37</volume><fpage>1017</fpage><lpage>1031</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.066</pub-id><pub-id pub-id-type="pmid">17632014</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Getting formal with dopamine and reward</article-title><source>Neuron</source><volume>36</volume><fpage>241</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)00967-4</pub-id><pub-id pub-id-type="pmid">12383780</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Behavioral theories and the neurophysiology of reward</article-title><source>Annual Review of Psychology</source><volume>57</volume><fpage>87</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.56.091103.070229</pub-id><pub-id pub-id-type="pmid">16318590</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>A mathematical theory of communication</article-title><source>Bell System Technical Journal</source><volume>27</volume><fpage>379</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1002/j.1538-7305.1948.tb01338.x</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheraz</surname><given-names>M</given-names></name><name><surname>Dedu</surname><given-names>S</given-names></name><name><surname>Preda</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Entropy measures for assessing volatile markets</article-title><source>Procedia Economics and Finance</source><volume>22</volume><fpage>655</fpage><lpage>662</lpage><pub-id pub-id-type="doi">10.1016/S2212-5671(15)00279-8</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirama</surname><given-names>A</given-names></name><name><surname>Nobukawa</surname><given-names>S</given-names></name><name><surname>Sumiyoshi</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Eye pupils mirror information divergence in approximate inference</article-title><source>Scientific Reports</source><volume>14</volume><elocation-id>30808</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-024-81111-9</pub-id><pub-id pub-id-type="pmid">39730595</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegelman</surname><given-names>N</given-names></name><name><surname>Bogaerts</surname><given-names>L</given-names></name><name><surname>Armstrong</surname><given-names>BC</given-names></name><name><surname>Frost</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>What exactly is learned in visual statistical learning? Insights from Bayesian modeling</article-title><source>Cognition</source><volume>192</volume><elocation-id>104002</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2019.06.014</pub-id><pub-id pub-id-type="pmid">31228679</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silvestrin</surname><given-names>F</given-names></name><name><surname>Penny</surname><given-names>WD</given-names></name><name><surname>FitzGerald</surname><given-names>THB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Pupil dilation indexes automatic and dynamic inference about the precision of stimulus distributions</article-title><source>Journal of Mathematical Psychology</source><volume>101</volume><elocation-id>102503</elocation-id><pub-id pub-id-type="doi">10.1016/j.jmp.2021.102503</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Whyte</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A step-by-step tutorial on active inference and its application to empirical data</article-title><source>Journal of Mathematical Psychology</source><volume>107</volume><elocation-id>102632</elocation-id><pub-id pub-id-type="doi">10.1016/j.jmp.2021.102632</pub-id><pub-id pub-id-type="pmid">35340847</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sprevak</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>An introduction to predictive processing models of perception and decision-making</article-title><source>Topics in Cognitive Science</source><volume>1</volume><elocation-id>12704</elocation-id><pub-id pub-id-type="doi">10.1111/tops.12704</pub-id><pub-id pub-id-type="pmid">37899002</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stemerding</surname><given-names>LE</given-names></name><name><surname>van Ast</surname><given-names>VA</given-names></name><name><surname>Gerlicher</surname><given-names>AMV</given-names></name><name><surname>Kindt</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Pupil dilation and skin conductance as measures of prediction error in aversive learning</article-title><source>Behaviour Research and Therapy</source><volume>157</volume><elocation-id>104164</elocation-id><pub-id pub-id-type="doi">10.1016/j.brat.2022.104164</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strange</surname><given-names>BA</given-names></name><name><surname>Duggins</surname><given-names>A</given-names></name><name><surname>Penny</surname><given-names>W</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Information theory, novelty and hippocampal responses: unpredicted or unpredictable?</article-title><source>Neural Networks</source><volume>18</volume><fpage>225</fpage><lpage>230</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2004.12.004</pub-id><pub-id pub-id-type="pmid">15896570</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tscshantz</surname><given-names>A</given-names></name><name><surname>Millidge</surname><given-names>B</given-names></name><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Buckley</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Hybrid predictive coding: Inferring, fast and slow</article-title><source>PLOS Computational Biology</source><volume>19</volume><elocation-id>e1011280</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011280</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Jungé</surname><given-names>JA</given-names></name><name><surname>Scholl</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The automaticity of visual statistical learning</article-title><source>Journal of Experimental Psychology. General</source><volume>134</volume><fpage>552</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.134.4.552</pub-id><pub-id pub-id-type="pmid">16316291</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Braun</surname><given-names>A</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>14637</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms14637</pub-id><pub-id pub-id-type="pmid">28256514</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Lieshout</surname><given-names>LLF</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Bekkering</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Predictive processing: shedding light on the computational processes underlying motivated behavior</article-title><source>The Behavioral and Brain Sciences</source><volume>48</volume><elocation-id>e46</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X24000396</pub-id><pub-id pub-id-type="pmid">39886889</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Slooten</surname><given-names>JC</given-names></name><name><surname>Jahfari</surname><given-names>S</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Theeuwes</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How pupil responses track value-based decision-making during and after reinforcement learning</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006632</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006632</pub-id><pub-id pub-id-type="pmid">30500813</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Gabry</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC</article-title><source>Statistics and Computing</source><volume>27</volume><fpage>1413</fpage><lpage>1432</lpage><pub-id pub-id-type="doi">10.1007/s11222-016-9696-4</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vincent</surname><given-names>P</given-names></name><name><surname>Parr</surname><given-names>T</given-names></name><name><surname>Benrimoh</surname><given-names>D</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>With an eye on uncertainty: modelling pupillary responses to environmental volatility</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007126</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007126</pub-id><pub-id pub-id-type="pmid">31276488</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wessel</surname><given-names>JR</given-names></name><name><surname>Danielmeier</surname><given-names>C</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Error awareness revisited: accumulation of multimodal evidence from central and autonomic nervous systems</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>3021</fpage><lpage>3036</lpage><pub-id pub-id-type="doi">10.1162/jocn.2011.21635</pub-id><pub-id pub-id-type="pmid">21268673</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wetzel</surname><given-names>N</given-names></name><name><surname>Buttelmann</surname><given-names>D</given-names></name><name><surname>Schieler</surname><given-names>A</given-names></name><name><surname>Widmann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Infant and adult pupil dilation in response to unexpected sounds</article-title><source>Developmental Psychobiology</source><volume>58</volume><fpage>382</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1002/dev.21377</pub-id><pub-id pub-id-type="pmid">26507492</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winn</surname><given-names>MB</given-names></name><name><surname>Wendt</surname><given-names>D</given-names></name><name><surname>Koelewijn</surname><given-names>T</given-names></name><name><surname>Kuchinsky</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Best practices and advice for using pupillometry to measure listening effort: an introduction for those who want to get started</article-title><source>Trends in Hearing</source><volume>22</volume><elocation-id>2331216518800869</elocation-id><pub-id pub-id-type="doi">10.1177/2331216518800869</pub-id><pub-id pub-id-type="pmid">30261825</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yanagisawa</surname><given-names>H</given-names></name><name><surname>Kawamata</surname><given-names>O</given-names></name><name><surname>Ueda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Modeling emotions associated with novelty at variable uncertainty levels: A bayesian approach</article-title><source>Frontiers in Computational Neuroscience</source><volume>13</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2019.00002</pub-id><pub-id pub-id-type="pmid">30733673</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yon</surname><given-names>D</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Precision and the bayesian brain</article-title><source>Current Biology</source><volume>31</volume><fpage>R1026</fpage><lpage>R1032</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.07.044</pub-id><pub-id pub-id-type="pmid">34520708</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zénon</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Eye pupil signals information gain</article-title><source>Proceedings. Biological Sciences</source><volume>286</volume><elocation-id>20191593</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2019.1593</pub-id><pub-id pub-id-type="pmid">31530143</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zénon</surname><given-names>A</given-names></name><name><surname>Salvaggio</surname><given-names>S</given-names></name><name><surname>Andres</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Pupil Size Variations Reveal Bayesian Inference in Cognitive Arithmetic</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.11.27.625652</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Chait</surname><given-names>M</given-names></name><name><surname>Dick</surname><given-names>F</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Furukawa</surname><given-names>S</given-names></name><name><surname>Liao</surname><given-names>H-I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Pupil-linked phasic arousal evoked by violation but not emergence of regularity within rapid sound sequences</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>4030</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-12048-1</pub-id><pub-id pub-id-type="pmid">31492881</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Individual differences analysis between accuracy and pupil responses</title><sec sec-type="appendix" id="s8-1"><title>Data set #1: cue-target 2AFC task</title><p>In data set #1, it was previously reported that pupil responses decreased for the high-frequency (expected) trials as compared with low-frequency (unexpected) over the course of the experiment as a result of learning the cue-target contingencies (<xref ref-type="bibr" rid="bib95">Rutar et al., 2023</xref>; see their Supplementary Figure 2). In the current analysis, we explored whether a similar relationship between the feedback-locked pupil response and behavioral accuracy was also evident at the level of individual differences across the participant sample. We similarly expected that the feedback-locked pupil response and accuracy would ‘mirror’ one another in such a way that those individuals who showed a larger difference between the 80% and 20% frequency conditions in accuracy would also show the larger (absolute) difference between frequency conditions in the feedback-locked pupil response. Within the early time window, a significant negative Spearman correlation was obtained indicating that individuals who showed larger differences between the 80% as compared with the 20% frequency conditions in accuracy also showed smaller differences between frequency conditions in the feedback-locked pupil response (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, top left). The negative direction of the correlation can be explained because the pupil responses are larger on average for the 20% frequency condition as compared with the 80% frequency condition (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). A trend toward the same negative scaling could be seen in the late time window (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, top right).</p></sec><sec sec-type="appendix" id="s8-2"><title>Data set #2: letter-color 2AFC task</title><p>We explored whether this relationship between the feedback-locked pupil response and behavioral accuracy was also evident at the level of individual differences during the letter-color 2AFC task. However, in contrast to the cue-target 2AFC task, we did not find any evidence that the frequency effect in task accuracy scaled with the frequency effect in the feedback-locked pupil response in either the early or late time window (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, bottom row).</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Individual differences analysis between accuracy and pupil responses.</title><p><italic>Top row</italic>, cue-target 2AFC task. <italic>Bottom row</italic>, letter-color 2AFC task. <italic>Left column</italic>, early time window. Right column, late time window. The average feedback-locked pupil response frequency difference (80–20% and 84–33% frequency conditions for the cue-target and letter-color 2AFC tasks, respectively) is plotted against the frequency difference in accuracy. Data points, individual participants.</p><p><supplementary-material id="app1fig1sdata1"><label>Appendix 1—figure 1—source data 1.</label><caption><title>Processed data for the individual differences analysis between accuracy and pupil responses (both tasks).</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-app1-fig1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-app1-fig1-v1.tif"/></fig></sec></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Linear mixed model comparisons</title><p>The <italic>loo</italic> function (in the <italic>looic</italic> toolbox in R) automatically designates the best-performing model with the highest expected log predictive density (EPLD) as the ‘standard’ model (see the first row of each model comparison). To assess relative model performance between the models, the ratio between the difference in ELPD and the difference in the corresponding standard error was computed: ratios greater than two were considered to be statistically meaningful (<xref ref-type="bibr" rid="bib116">Vehtari et al., 2017</xref>; <xref ref-type="bibr" rid="bib68">Merkle and Rosseel, 2018</xref>). Explanation of abbreviations: <italic>ELPD loo,</italic> expected log predictive density. This is the sum of the pointwise log-likelihoods for each observation, estimated using leave-one-out (LOO) cross-validation. Higher is better, indicating better out-of-sample predictive performance; <italic>p loo</italic>, effective number of parameters (estimated by LOO). This is not the literal number of parameters, but a complexity measure. Higher values suggest more flexible (or more overfit) models; <italic>looic,</italic> LOO information criterion that is on the deviance scale. Lower <italic>looic</italic> values are preferred; <italic>SE</italic>, Standard error.</p><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Linear mixed model comparisons for the cue-target 2AFC task.</title><p><supplementary-material id="app2table1sdata1"><label>Appendix 2—table 1—source data 1.</label><caption><title>Processed data input into the linear mixed modeling analysis for the cue-target 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-app2-table1-data1-v1.xlsx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom" colspan="7">Cue-target 2AFC task</th></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom" colspan="7">Early time window</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><bold>Model</bold></td><td align="left" valign="bottom"><bold>ELPD loo (SE</bold>)</td><td align="left" valign="bottom"><bold>p loo (SE</bold>)</td><td align="left" valign="bottom"><bold>looic (SE</bold>)</td><td align="left" valign="bottom"><bold>△ELPD</bold></td><td align="left" valign="bottom"><bold>△SE</bold></td><td align="left" valign="bottom"><bold>|△ELPD|/△SE</bold></td></tr><tr><td align="left" valign="bottom" rowspan="2">All trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–13596.9 (77)</td><td align="char" char="." valign="bottom">30.3 (1.3)</td><td align="char" char="." valign="bottom">27195.5 (154)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–13598.5 (77)</td><td align="char" char="." valign="bottom">31.0 (1.3)</td><td align="char" char="." valign="bottom">27197.1 (154)</td><td align="char" char="." valign="bottom">–0.8</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">2.0</td></tr><tr><td align="left" valign="bottom" rowspan="2">Correct trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–9499.1 (68.7)</td><td align="char" char="." valign="bottom">29.7 (1.7)</td><td align="char" char="." valign="bottom">18998.3 (137.3)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–9499.0 (68.7)</td><td align="char" char="." valign="bottom">30.0 (1.7)</td><td align="char" char="." valign="bottom">18998.1 (137.3)</td><td align="char" char="." valign="bottom">–0.1</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.1</td></tr><tr><td align="left" valign="bottom" rowspan="2">Error trials</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–4069.5 (35.1)</td><td align="char" char="." valign="bottom">29.8 (1.7)</td><td align="char" char="." valign="bottom">8139.1 (70.3)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–4070.4 (35.2)</td><td align="char" char="." valign="bottom">28.8 (1.7)</td><td align="char" char="." valign="bottom">8140.8 (70.4)</td><td align="char" char="." valign="bottom">–0.9</td><td align="char" char="." valign="bottom">1.9</td><td align="char" char="." valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom" colspan="7">Late time window</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><bold>Model</bold></td><td align="left" valign="bottom"><bold>ELPD loo (SE</bold>)</td><td align="left" valign="bottom"><bold>p loo (SE</bold>)</td><td align="left" valign="bottom"><bold>looic (SE</bold>)</td><td align="left" valign="bottom"><bold>△ELPD</bold></td><td align="left" valign="bottom"><bold>△SE</bold></td><td align="left" valign="bottom"><bold>|△ELPD|/△SE</bold></td></tr><tr><td align="left" valign="bottom" rowspan="2">All trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–14983.7 (67.7)</td><td align="char" char="." valign="bottom">29.7 (1.1)</td><td align="char" char="." valign="bottom">29967.4 (135.5)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–14984.7 (67.7)</td><td align="char" char="." valign="bottom">29.7 (1.1)</td><td align="char" char="." valign="bottom">29969.4 (135.5)</td><td align="char" char="." valign="bottom">–1.0</td><td align="char" char="." valign="bottom">0.3</td><td align="char" char="." valign="bottom">3.3</td></tr><tr><td align="left" valign="bottom" rowspan="2">Correct trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–10575.0 (57.1)</td><td align="char" char="." valign="bottom">27.7 (1.2)</td><td align="char" char="." valign="bottom">21150.1 (114.3)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–10575.8 (57.2)</td><td align="char" char="." valign="bottom">29.0 (1.3)</td><td align="char" char="." valign="bottom">21151.5 (114.3)</td><td align="char" char="." valign="bottom">–0.7</td><td align="char" char="." valign="bottom">1.2</td><td align="char" char="." valign="bottom">0.6</td></tr><tr><td align="left" valign="bottom" rowspan="2">Error trials</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–4363.2 (33.3)</td><td align="char" char="." valign="bottom">27.1 (1.4)</td><td align="char" char="." valign="bottom">8726.3 (66.6)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–4364.0 (33.4)</td><td align="char" char="." valign="bottom">26.7 (1.4)</td><td align="char" char="." valign="bottom">8728.0 (66.7)</td><td align="char" char="." valign="bottom">–0.8</td><td align="char" char="." valign="bottom">1.3</td><td align="char" char="." valign="bottom">0.6</td></tr></tbody></table></table-wrap><table-wrap id="app2table2" position="float"><label>Appendix 2—table 2.</label><caption><title>Linear mixed model comparisons for the letter-color 2AFC task.</title><p><supplementary-material id="app2table2sdata1"><label>Appendix 2—table 2—source data 1.</label><caption><title>Processed data input into the linear mixed modeling analysis for the letter-color 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-app2-table2-data1-v1.xlsx"/></supplementary-material></p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom" colspan="7">Letter-color 2AFC task</th></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom" colspan="7">Early time window</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><bold>Model</bold></td><td align="left" valign="bottom"><bold>ELPD loo (SE</bold>)</td><td align="left" valign="bottom"><bold>p loo (SE</bold>)</td><td align="left" valign="bottom"><bold>looic (SE</bold>)</td><td align="left" valign="bottom"><bold>△ELPD</bold></td><td align="left" valign="bottom"><bold>△SE</bold></td><td align="left" valign="bottom"><bold>|△ELPD|/△SE</bold></td></tr><tr><td align="left" valign="bottom" rowspan="2">All trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–39805.3 (104.8)</td><td align="char" char="." valign="bottom">48.7 (1.1)</td><td align="char" char="." valign="bottom">79610.7 (209.6)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–39805.7 (104.8)</td><td align="char" char="." valign="bottom">49.3 (1.1)</td><td align="char" char="." valign="bottom">79611.4 (209.6)</td><td align="char" char="." valign="bottom">–0.4</td><td align="char" char="." valign="bottom">0.7</td><td align="char" char="." valign="bottom">0.6</td></tr><tr><td align="left" valign="bottom" rowspan="2">Correct trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–32665.1 (95.8)</td><td align="char" char="." valign="bottom">45.1 (1.2)</td><td align="char" char="." valign="bottom">65330.2 (191.5)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–32666.0 (95.8)</td><td align="char" char="." valign="bottom">45.9 (1.2)</td><td align="char" char="." valign="bottom">65331.9 (191.5)</td><td align="char" char="." valign="bottom">–0.9</td><td align="char" char="." valign="bottom">0.2</td><td align="char" char="." valign="bottom">4.5</td></tr><tr><td align="left" valign="bottom" rowspan="2">Error trials</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–7024.7 (41.2)</td><td align="char" char="." valign="bottom">47.4 (2.4)</td><td align="char" char="." valign="bottom">14049.5 (82.4)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–7025.6 (41.3)</td><td align="char" char="." valign="bottom">46.4 (2.4)</td><td align="char" char="." valign="bottom">14051.3 (82.6)</td><td align="char" char="." valign="bottom">–0.9</td><td align="char" char="." valign="bottom">1.8</td><td align="char" char="." valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom" colspan="7">Late time window</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"><bold>Model</bold></td><td align="left" valign="bottom"><bold>ELPD loo (SE</bold>)</td><td align="left" valign="bottom"><bold>p loo (SE</bold>)</td><td align="left" valign="bottom"><bold>looic (SE</bold>)</td><td align="left" valign="bottom"><bold>△ELPD</bold></td><td align="left" valign="bottom"><bold>△SE</bold></td><td align="left" valign="bottom"><bold>|△ELPD|/△SE</bold></td></tr><tr><td align="left" valign="bottom" rowspan="2">All trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–43351.0 (110.0)</td><td align="char" char="." valign="bottom">43.7 (1.0)</td><td align="char" char="." valign="bottom">86701.9 (220.0)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–43351.5 (110.0)</td><td align="char" char="." valign="bottom">44.4 (1.0)</td><td align="char" char="." valign="bottom">86703.0 (220.1)</td><td align="char" char="." valign="bottom">–0.5</td><td align="char" char="." valign="bottom">0.7</td><td align="char" char="." valign="bottom">0.7</td></tr><tr><td align="left" valign="bottom" rowspan="2">Correct trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–35663.4 (97.0)</td><td align="char" char="." valign="bottom">40.9 (1.0)</td><td align="char" char="." valign="bottom">71326.8 (194.0)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–35664.2 (97.0)</td><td align="char" char="." valign="bottom">41.8 (1.0)</td><td align="char" char="." valign="bottom">71328.4 (194.0)</td><td align="char" char="." valign="bottom">–0.8</td><td align="char" char="." valign="bottom">0.5</td><td align="char" char="." valign="bottom">1.6</td></tr><tr><td align="left" valign="bottom" rowspan="2">Error trials</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">–7628.3 (51.2)</td><td align="char" char="." valign="bottom">41.2 (2.8)</td><td align="char" char="." valign="bottom">15256.6 (102.5)</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td><td align="char" char="." valign="bottom">0.0</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">–7628.7 (51.3)</td><td align="char" char="." valign="bottom">41.9 (2.8)</td><td align="char" char="." valign="bottom">15257.4 (102.6)</td><td align="char" char="." valign="bottom">–0.4</td><td align="char" char="." valign="bottom">0.7</td><td align="char" char="." valign="bottom">0.6</td></tr></tbody></table></table-wrap></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Control tasks for data set #2</title><p>Different colors and tones could influence the pupil response due to inherent properties of the stimuli, and thereby confound true feedback-related signals. Therefore, complementary to the main analysis, we administered two control tasks in one independent sample of participants to directly assess whether confounding effects on the pupil’s response to the colors and tones presented in the letter-color 2AFC task should be expected.</p><sec sec-type="appendix" id="s10-1"><title>Participants and informed consent</title><p>An independent sample of fifteen participants (<italic>M</italic> = 24.27 y, SD = 5.79, gender data was not acquired) completed both control tasks in a single session that lasted 30 min in total. All stimuli and equipment were identical to the setup reported for the letter-color 2AFC task. All participants gave written informed consent before participating and were financially compensated for participation with the standard amount.</p></sec></sec><sec sec-type="appendix" id="s11"><title>3.1 The pupil’s response to colored squares returns to baseline before feedback onset</title><sec sec-type="appendix" id="s11-1"><title>Procedure and Methods</title><p>Color was a stimulus dimension in the letter-color 2AFC task, and colors are known to result in impulse responses driven by the light reflex of the pupil (<xref ref-type="bibr" rid="bib5">Barbur et al., 1992</xref>). This light reflex is uninteresting in the context of the current experiment and furthermore could potentially affect the feedback-related pupil response of interest differently for different colors. Participants were presented with the six colored squares used in the letter-color 2AFC tasks and instructed to react with a button press as soon as the color appeared. In the main letter-color 2AFC task, the colored square was replaced with a fixation cross upon the participant’s response, thus stimulus duration varied across trials and participants. To account for part of this variation in stimulus duration, each of the 15 control participants was yoked to one participant in the letter-color 2AFC task. In the control task for colors, the stimulus duration of the colored squares was equal to the mean reaction time (across all trials) of the yoked counterpart of each participant (group average: <italic>M</italic> = 0.70 s, SD = 0.15). On each trial, a fixation cross was presented for 0.5 s, before the colored square was presented for a variable duration (see above), followed by the fixation cross again for the inter-trial interval (3.5–5.5 s; uniform distribution). Each color was presented 20 times for a total of 120 trials while pupil dilation was simultaneously recorded. Behavioral data on the control task were not analyzed.</p></sec><sec sec-type="appendix" id="s11-2"><title>Results</title><p>From the results, on average, the colors resulted in a constriction of the pupil dilation (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1A</xref>). Crucially, when inspecting each of the six colors individually, all responses returned to baseline well before the delay period (3.5–5.5 s; uniform distribution) was terminated and the auditory feedback was presented (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>).</p><fig id="app3fig1" position="float"><label>Appendix 3—figure 1.</label><caption><title>Control tasks for data set #2: letter-color 2AFC task.</title><p>Left column, results from the control task for colors. Right column, results from the control task for feedback tones. (A) Mean tone-locked pupil response across all trials. (B) Feedback-locked pupil response time course plotted as a function of color used in the main letter-color 2AFC task (hexadecimal codes are given in the legend). (C) As A, for the control task for feedback tones. (D) Pupil response time courses plotted as a function of feedback tone used for error and correct trials in the main letter-color 2AFC task. All panels, dark gray boxes indicate the duration of the stimuli; 0.7 s, for the colors (group average); 0.3 s, auditory stimulus for the tones. Light gray boxes indicate time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. Shading represents the standard error of the mean across participants (N = 15). The black and green horizontal bars indicate a significant effect of interest (cluster-corrected, permutation based).</p><p><supplementary-material id="app3fig1sdata1"><label>Appendix 3—figure 1—source data 1.</label><caption><title>Processed pupil data used to generate the figures for the analysis of the control tasks related to the letter-color 2AFC task.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-app3-fig1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-app3-fig1-v1.tif"/></fig><p>In sum, the control task for colors showed that the pupil’s impulse response to the six different colors used in the letter-color 2AFC task would not have affected the upcoming feedback stimulus.</p></sec></sec><sec sec-type="appendix" id="s12"><title>3.2 Mean pupil response is similar for the two ‘feedback’ tones</title><sec sec-type="appendix" id="s12-1"><title>Procedure and methods</title><p>The mapping of feedback tones to indicate accuracy on each trial was as follows: a high tone (4<sup>th</sup> octave “B”) for correct trials and a low tone (3<sup>rd</sup> octave “D”) for error trials. Thus, these tones were not counterbalanced across participants and could potentially confound a main effect of accuracy obtained in the pupil response (although we note that it could not account for any interaction obtained between accuracy and frequency conditions). Participants were presented with the two tones used as trial-wise feedback on accuracy in the letter-color 2AFC task and instructed to maintain their gaze on the fixation cross in the center of the screen for the duration of the task (no responses were required from the participants). On each trial, a fixation cross was presented for 0.5 s, before the tone was presented for 0.3 s, followed by the fixation cross again for the inter-trial interval (3.5 – 5.5 s; uniform distribution). Each tone was presented 50 times for a total of 100 trials while pupil dilation was simultaneously recorded.</p></sec><sec sec-type="appendix" id="s12-2"><title>Results</title><p>Results showed that the auditory tone dilated pupils on average (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1C</xref>). Crucially, however, the two tones did not differ from one another in either of the time windows of interest (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1D</xref>); no significant time points after feedback onset were obtained either before or after correcting for multiple comparisons using cluster-based permutation methods; see Section 2.5.</p><p>In sum, the control task for feedback tones showed that the pupil responded similarly to the two different tones used in the letter-color 2AFC task. Thus, the different tone stimuli used to indicate error or correct trials would not have accounted for any differences obtained in the pupil’s response on error as compared with correct trials.</p></sec></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s13"><title>Sanity checks on pupil preprocessing</title><p>For visual comparison to the main results, the feedback-locked pupil response across the experimental conditions of interest is shown related to different pre-processing stages. These figures can be compared directly to <xref ref-type="fig" rid="fig1">Figures 1D</xref> and <xref ref-type="fig" rid="fig2">2D</xref>, for the two tasks, respectively. The raw and interpolated time courses are shown before the (blink and saccade) nuisance regression. Both the raw and interpolated data have been band-pass filtered as was done in the original pre-processing pipeline and converted to percent signal change. The ratio of interpolated-to-original data (across the entire trial) varied greatly between participants and between trials: cue-target 2AFC task, M = 0.262, SD = 0.242, range = [0,1]; letter-color 2AFC task, M = 0.194, SD = 0.199, range = [0,1]; Here, we present a conservative analysis in which only trials with more than half (threshold = 60%) of original data are included in the analyses. Crucially, we still observe the same pattern of effects as when all data are considered across both tasks (compare the second to last row in <xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref> to <xref ref-type="fig" rid="fig1">Figures 1D</xref> and <xref ref-type="fig" rid="fig2">2D</xref>). Note that for the cue-target 2AFC task, one participant did not have trials remaining in the four conditions of interest defined by the two-way interaction (frequency vs. accuracy) and was therefore removed for this post-hoc supplementary analysis. Finally, the nuisance predictor time courses (based on blink and saccade events) are shown for the same conditions as the feedback-locked pupil response. Model fits (R<sup>2</sup>) for the nuisance regression were generally low: cue-target 2AFC task<italic>,</italic> M = 0.03, SD = 0.02, range = [0.00, 0.07]; letter-color 2AFC task<italic>,</italic> M = 0.08, SD = 0.04, range = [0.02, 0.16].</p><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>Sanity checks on pupil pre-processing for (<bold>A</bold>) the cue-target 2AFC task and (<bold>B</bold>) the letter-color 2AFC task.</title><p>All plots, feedback-locked pupil response time course plotted as a function of cue-target frequency and accuracy for different pre-processing stages. Shading represents the standard error of the mean across participants (cue-target 2AFC task: N = 24; letter-color 2AFC task: N = 47). Light gray boxes, time windows of interest; early time window, [0.75, 1.25]; late time window, [2.5, 3.0]. The black horizontal bar indicates a significant interaction term (cluster-corrected, permutation test). Top row, the raw and band-pass filtered pupil signal before interpolation. Second row, the interpolated and band-pass filtered pupil signal but without the nuisance regression. Third row, the fully pre-processed pupil (as in the main results) for the conservative analysis in which only trials containing at least 60% of original (non-interpolated) data were included. Bottom row, the nuisance predictors based on blink and saccade events estimated by deconvolution.</p><p><supplementary-material id="app4fig1sdata1"><label>Appendix 4—figure 1—source data 1.</label><caption><title>Processed pupil data used to generate the appendix figure showing the sanity checks of pupil pre-processing figure for both tasks.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-105287-app4-fig1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-105287-app4-fig1-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105287.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Press</surname><given-names>Clare</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study investigates the relationship between pupil dilation and information gain during associative learning, using two different tasks. A key strength of this study is its exploration of pupil dilation beyond the immediate response period, extending analysis to later time windows after feedback, and it provides <bold>convincing</bold> evidence that pupillary response to information gain may be context-dependent during associative learning. The interpretation remains limited by task heterogeneity and unresolved contextual factors influencing pupil dynamics, but a range of interesting ideas are discussed.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105287.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This study examines whether changes in pupil size index prediction-error-related updating during associative learning, formalised as information gain via Kullback-Leibler (KL) divergence. Across two independent tasks, pupil responses scaled with KL divergence shortly after feedback, with the timing and direction of the response varying by task. Overall, the work supports the view that pupil size reflects information-theoretic processes in a context-dependent manner.</p><p>Strengths:</p><p>This study provides a novel and convincing contribution by linking pupil dilation to information-theoretic measures, such as KL divergence, supporting Zénon's hypothesis that pupil responses reflect information gain during learning. The robust methodology, including two independent datasets with distinct task structures, enhances the reliability and generalisability of the findings. By carefully analysing early and late time windows, the authors capture the timing and direction of prediction-error-related responses, offering new insights into the temporal dynamics of model updating. The use of an ideal-learner framework to quantify prediction errors, surprise, and uncertainty provides a principled account of the computational processes underlying pupil responses. The work also highlights the critical role of task context in shaping the direction and magnitude of these effects, revealing the adaptability of predictive processing mechanisms. Importantly, the conclusions are supported by rigorous control analyses and preprocessing sanity checks, as well as convergent results from frequentist and Bayesian linear mixed-effects modelling approaches.</p><p>Weaknesses:</p><p>Some aspects of directionality remain context-dependent, and on current evidence cannot be attributed specifically to whether average uncertainty increases or decreases across trials. Differences between the two tasks (e.g., sensory modality and learning regime) limit direct comparisons of effect direction and make mechanistic attribution cautious. In addition, subjective factors such as confidence were not measured and could influence both prediction-error signals and pupil responses. Importantly, the authors explicitly acknowledge these limitations, and the manuscript clearly frames them as areas for future work rather than settled conclusions.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105287.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors investigate whether pupil dilation reflects information gain during associative learning, formalised as Kullback-Leibler divergence within an ideal observer framework. They examine pupil responses in a late time window after feedback and compare these to information-theoretic estimates (information gain, surprise, and entropy) derived from two different tasks with contrasting uncertainty dynamics.</p><p>Strength:</p><p>The exploration of task evoked pupil dynamics beyond the immediate response/feedback period and then associating them with model estimates was interesting and inspiring. This offered a new perspective on the relationship between pupil dilation and information processing.</p><p>Weakness:</p><p>However, the interpretability of the findings remains constrained by the fundamental differences between the two tasks (stimulus modality, feedback type, and learning structure), which confound the claimed context-dependent effects. The later time-window pupil effects, although intriguing, are small in magnitude and may reflect residual noise or task-specific arousal fluctuations rather than distinct information-processing signals. Thus, while the study offers valuable methodological insight and contributes to ongoing debates about the role of the pupil in cognitive inference, its conclusions about the functional significance of late pupil responses should be treated with caution.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105287.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Thank you for inviting me to review this manuscript entitled &quot;Pupil dilation offers a time-window on prediction error&quot; by Colizoli and colleagues. The study examines prediction errors, information gain (Kullback-Leibler [KL] divergence), and uncertainty (entropy) from an information-theory perspective using two experimental tasks and pupillometry. The authors aim to test a theoretical proposal by Zénon (2019) that the pupil response reflects information gain (KL divergence). The conclusion of this work is that (post-feedback) pupil dilation in response to information gain is context dependent.</p><p>Strengths:</p><p>Use of an established Bayesian model to compute KL divergence and entropy.</p><p>Pupillometry data preprocessing and multiple robustness checks.</p><p>Weaknesses:</p><p>Operationalization of prediction errors based on frequency, accuracy, and their interaction:</p><p>The authors rely on a more model-agnostic definition of the prediction error in terms of stimulus frequency (&quot;unsigned prediction error&quot;), accuracy, and their interaction (&quot;signed prediction error&quot;). While I see the point, I would argue that this approach provides a simple approximation of the prediction error, but that a model-based approach would be more appropriate.</p><p>Model validation:</p><p>My impression is that the ideal learner model should work well in this case. However, the authors don't directly compare model behavior to participant behavior (&quot;posterior predictive checks&quot;) to validate the model. Therefore, it is currently unclear if the model-derived terms like KL divergence and entropy provide reasonable estimates for the participant data.</p><p>Lack of a clear conclusion:</p><p>The authors conclude that this study shows for the first time that (post-feedback) pupil dilation in response to information gain is context dependent. However, the study does not offer a unifying explanation for such context dependence. The discussion is quite detailed with respect to task-specific effects, but fails to provide an overarching perspective on the context-dependent nature of pupil signatures of information gain. This seems to be partly due to the strong differences between the experimental tasks.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.105287.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Colizoli</surname><given-names>Olympia</given-names></name><role specific-use="author">Author</role><aff><institution>Radboud University Nijmegen</institution><addr-line><named-content content-type="city">Nijmegen</named-content></addr-line><country>Netherlands</country></aff></contrib><contrib contrib-type="author"><name><surname>van Leeuwen</surname><given-names>Tessa M</given-names></name><role specific-use="author">Author</role><aff><institution>Tilburg University</institution><addr-line><named-content content-type="city">Tilburg</named-content></addr-line><country>Netherlands</country></aff></contrib><contrib contrib-type="author"><name><surname>Rutar</surname><given-names>Danaja</given-names></name><role specific-use="author">Author</role><aff><institution>Sigmund Freud Privatuniversitä - Standort Mailand</institution><addr-line><named-content content-type="city">Ljubljana</named-content></addr-line><country>Slovenia</country></aff></contrib><contrib contrib-type="author"><name><surname>Bekkering</surname><given-names>Harold</given-names></name><role specific-use="author">Author</role><aff><institution>Radboud University Nijmegen</institution><addr-line><named-content content-type="city">Nijmegen</named-content></addr-line><country>Netherlands</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the current reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>This study examines whether changes in pupil size index prediction-error-related updating during associative learning, formalised as information gain via Kullback-Leibler (KL) divergence. Across two independent tasks, pupil responses scaled with KL divergence shortly after feedback, with the timing and direction of the response varying by task. Overall, the work supports the view that pupil size reflects information-theoretic processes in a context-dependent manner.</p><p>Strengths:</p><p>This study provides a novel and convincing contribution by linking pupil dilation to informationtheoretic measures, such as KL divergence, supporting Zénon's hypothesis that pupil responses reflect information gain during learning. The robust methodology, including two independent datasets with distinct task structures, enhances the reliability and generalisability of the findings. By carefully analysing early and late time windows, the authors capture the timing and direction of prediction-error-related responses, oPering new insights into the temporal dynamics of model updating. The use of an ideal-learner framework to quantify prediction errors, surprise, and uncertainty provides a principled account of the computational processes underlying pupil responses. The work also highlights the critical role of task context in shaping the direction and magnitude of these ePects, revealing the adaptability of predictive processing mechanisms. Importantly, the conclusions are supported by rigorous control analyses and preprocessing sanity checks, as well as convergent results from frequentist and Bayesian linear mixed-ePects modelling approaches.</p><p>Weaknesses:</p><p>Some aspects of directionality remain context-dependent, and on current evidence cannot be attributed specifically to whether average uncertainty increases or decreases across trials. DiPerences between the two tasks (e.g., sensory modality and learning regime) limit direct comparisons of ePect direction and make mechanistic attribution cautious. In addition, subjective factors such as confidence were not measured and could influence both predictionerror signals and pupil responses. Importantly, the authors explicitly acknowledge these limitations, and the manuscript clearly frames them as areas for future work rather than settled conclusions.</p><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>The authors investigate whether pupil dilation reflects information gain during associative learning, formalised as Kullback-Leibler divergence within an ideal observer framework. They examine pupil responses in a late time window after feedback and compare these to informationtheoretic estimates (information gain, surprise, and entropy) derived from two diPerent tasks with contrasting uncertainty dynamics.</p><p>Strength:</p><p>The exploration of task evoked pupil dynamics beyond the immediate response/feedback period and then associating them with model estimates was interesting and inspiring. This oPered a new perspective on the relationship between pupil dilation and information processing.</p><p>Weakness:</p><p>However, the interpretability of the findings remains constrained by the fundamental diPerences between the two tasks (stimulus modality, feedback type, and learning structure), which confound the claimed context-dependent ePects. The later time-window pupil ePects, although intriguing, are small in magnitude and may reflect residual noise or task-specific arousal fluctuations rather than distinct information-processing signals. Thus, while the study oPers valuable methodological insight and contributes to ongoing debates about the role of the pupil in cognitive inference, its conclusions about the functional significance of late pupil responses should be treated with caution.</p><p><bold>Reviewer #3 (Public review):</bold></p><p>Summary:</p><p>Thank you for inviting me to review this manuscript entitled &quot;Pupil dilation oPers a time-window on prediction error&quot; by Colizoli and colleagues. The study examines prediction errors, information gain (Kullback-Leibler [KL] divergence), and uncertainty (entropy) from an information-theory perspective using two experimental tasks and pupillometry. The authors aim to test a theoretical proposal by Zénon (2019) that the pupil response reflects information gain (KL divergence). The conclusion of this work is that (post-feedback) pupil dilation in response to information gain is context dependent.</p><p>Strengths:</p><p>Use of an established Bayesian model to compute KL divergence and entropy.</p><p>Pupillometry data preprocessing and multiple robustness checks.</p><p>Weaknesses:</p><p>Operationalization of prediction errors based on frequency, accuracy, and their interaction:</p><p>The authors rely on a more model-agnostic definition of the prediction error in terms of stimulus frequency (&quot;unsigned prediction error&quot;), accuracy, and their interaction (&quot;signed prediction error&quot;). While I see the point, I would argue that this approach provides a simple approximation of the prediction error, but that a model-based approach would be more appropriate.</p><p>Model validation:</p><p>My impression is that the ideal learner model should work well in this case. However, the authors don't directly compare model behavior to participant behavior (&quot;posterior predictive checks&quot;) to validate the model. Therefore, it is currently unclear if the model-derived terms like KL divergence and entropy provide reasonable estimates for the participant data.</p><p>Lack of a clear conclusion:</p><p>The authors conclude that this study shows for the first time that (post-feedback) pupil dilation in response to information gain is context dependent. However, the study does not oPer a unifying explanation for such context dependence. The discussion is quite detailed with respect to taskspecific ePects, but fails to provide an overarching perspective on the context-dependent nature of pupil signatures of information gain. This seems to be partly due to the strong diPerences between the experimental tasks.</p><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>I highly appreciate the care and detail in the authors' response and thank them for the ePort invested in revising the manuscript. They addressed the core concerns to a high standard, and the manuscript has substantially improved in methodological rigour (through additional controls/sanity checks and complementary mixed-ePects analyses) and in clarity of interpretation (by explicitly acknowledging context-dependence and tempering stronger claims). The present version reads clearly and is much strengthened overall. I only have a few minor points below:</p><p>Minor suggestions:</p><p>Abstract:</p><p>In the abstract KL is introduced as abbreviation, but at first occurence it should be written out as &quot;Kullback-Leibler (KL)&quot; for readers not familiar with it.</p></disp-quote><p>We thank the reviewer for catching this error. It has been correct in the version of record.</p><disp-quote content-type="editor-comment"><p>Methods:</p><p>I appreciate the additional bayesian LME analysis. I only had a few things that I thought were missing from knowing the parameters: (1) what was the target acceptance rate (default of .95?), (2) which family was used to model the response distribution: (default) &quot;gaussian&quot; or robust &quot;student-t&quot;? Depending on the data a student-t would be preferred, but since the author's checked the fit &amp; the results corroborate the correlation analysis, using the default would also be fine! Just add the information for completeness.</p></disp-quote><p>Thank you for bringing this to our attention. We have now noted that default parameters were used in all cases unless otherwise mentioned.</p><p>Thank you once again for your time and consideration.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>Thanks to the authors' ePort on revision. I am happy with this new version of manuscript.</p></disp-quote><p>Thank you once again for your time and consideration.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations for the authors):</bold></p><p>(1) Regarding comments #3 and #6 (first round) on model validation and posterior predictive checks, the authors replied that since their model is not a &quot;generative&quot; one, they can't perform posterior predictive checks. Crucially, in eq. 2, the authors present the p{tilde}^j_k variable denoting the learned probability of event k on trial j. I don't see why this can't be exploited for simulations. In my opinion, one could (and should) generate predictions based on this variable. The simplest implementation would translate the probability into a categorical choice (w/o fitting any free parameter). Based on this, they could assess whether the model and data are comparable.</p></disp-quote><p>We thank the reviewer for this clarification. The reviewer suggests using the probability distributions at each trial to predict which event should be chosen on each trial. More specifically, the event(s) with the highest probability on trial j could be used to generate a prediction for the choice of the participant on trial j. We agree that this would indeed be an interesting analysis. However, the response options of each task are limited to two-alternatives. In the cue-target task, four events are modeled (representing all possible cue-target conditions) while the participants’ response options are only “left” and “right”. Similarly, in the letter-color task, 36 events are modeled while the participants’ response options are “match” and “no-match”. In other words, we do not know which event (either four or 36, for the two tasks) the participant would have indicated on each trial. As an approximation to this fine-grained analysis, we investigated the relationship between the information-theoretic variables separately for error and correct trials. Our rationale was that we would have more insight into how the model fits depended on the participants’ actual behavior as compared with the ideal learner model.</p><disp-quote content-type="editor-comment"><p>(2) I recommend providing a plot of the linear mixed model analysis of the pupil data. Currently, results are only presented in the text and tables, but a figure would be much more useful.</p></disp-quote><p>We thank the reviewer for the suggestion to add a plot of the linear mixed model results. We appreciate the value of visualizing model estimates; however, we feel that the current presentation in the text and tables clearly conveys the relevant findings. For this reason, and to avoid further lengthening the manuscript, we prefer to retain the current format.</p><disp-quote content-type="editor-comment"><p>(3) I would consider only presenting the linear mixed ePects for the pupil data in the main results, and the correlation results in the supplement. It is currently quite long.</p></disp-quote><p>We thank the reviewer for this recommendation. We agree that the results section is detailed; however, we consider the correlation analyses to be integral to the interpretation of the pupil data and therefore prefer to keep them in the main text rather than move them to the supplement.</p><p>The following is the authors’ response to the original reviews</p><disp-quote content-type="editor-comment"><p><bold>eLife Assessment</bold></p><p>This important study seeks to examine the relationship between pupil size and information gain, showing opposite effects dependent upon whether the average uncertainty increases or decreases across trials. Given the broad implications for learning and perception, the findings will be of broad interest to researchers in cognitive neuroscience, decision-making, and computational modelling. Nevertheless, the evidence in support of the particular conclusion is at present incomplete - the conclusions would be strengthened if the authors could both clarify the differences between model-updating and prediction error in their account and clarify the patterns in the data.</p><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>This study investigates whether pupil dilation reflects prediction error signals during associative learning, defined formally by Kullback-Leibler (KL) divergence, an information-theoretic measure of information gain. Two independent tasks with different entropy dynamics (decreasing and increasing uncertainty) were analyzed: the cue-target 2AFC task and the lettercolor 2AFC task. Results revealed that pupil responses scaled with KL divergence shortly after feedback onset, but the direction of this relationship depended on whether uncertainty (entropy) increased or decreased across trials. Furthermore, signed prediction errors (interaction between frequency and accuracy) emerged at different time windows across tasks, suggesting taskspecific temporal components of model updating. Overall, the findings highlight that pupil dilation reflects information-theoretic processes in a complex, context-dependent manner.</p><p>Strengths:</p><p>This study provides a novel and convincing contribution by linking pupil dilation to informationtheoretic measures, such as KL divergence, supporting Zénon's hypothesis that pupil responses reflect information gained during learning. The robust methodology, including two independent datasets with distinct entropy dynamics, enhances the reliability and generalisability of the findings. By carefully analysing early and late time windows, the authors capture the temporal dynamics of prediction error signals, offering new insights into the timing of model updates. The use of an ideal learner model to quantify prediction errors, surprise, and entropy provides a principled framework for understanding the computational processes underlying pupil responses. Furthermore, the study highlights the critical role of task context - specifically increasing versus decreasing entropy - in shaping the directionality and magnitude of these effects, revealing the adaptability of predictive processing mechanisms.</p><p>Weaknesses:</p><p>While this study offers important insights, several limitations remain. The two tasks differ significantly in design (e.g., sensory modality and learning type), complicating direct comparisons and limiting the interpretation of differences in pupil dynamics. Importantly, the apparent context-dependent reversal between pupil constriction and dilation in response to feedback raises concerns about how these opposing effects might confound the observed correlations with KL divergence.</p></disp-quote><p>We agree with the reviewer’s concerns and acknowledge that the speculation concerning the directional effect of entropy across trials can not be fully substantiated by the current study. As the reviewer points out, the directional relationship between pupil dilation and information gain must be due to other factors, for instance, the sensory modality, learning type, or the reversal between pupil constriction and dilation across the two tasks. Also, we would like to note that ongoing experiments in our lab already contradict our original speculation. In line with the reviewer’s point, we noted these differences in the section on “Limitations and future research” in the Discussion. To better align the manuscript with the above mentioned points, we have made several changes in the Abstract, Introduction and Discussion summarized below:</p><p>We have removed the following text from the Abstract and Introduction: “…, specifically related to increasing or decreasing average uncertainty (entropy) across trials.”</p><p>We have edited the following text in the Introduction (changes in italics) (p. 5):</p><p>“We analyzed two independent datasets featuring distinct associative learning paradigms, one characterized by increasing entropy and the other by decreasing entropy as the tasks progressed. By examining these different tasks, we aimed to identify commonalities (if any) in the results across varying contexts. Additionally, the contrasting directions of entropy in the two tasks enabled us to disentangle the correlation between stimulus-pair frequency and information gain in the postfeedback pupil response.</p><p>We have removed the following text from the Discussion:</p><p>“…and information gain in fact seems to be driven by increased uncertainty.”</p><p>“We speculate that this difference in the direction of scaling between information gain and the pupil response may depend on whether entropy was increasing or decreasing across trials.”</p><p>“…which could explain the opposite direction of the relationship between pupil dilation and information gain”</p><p>“… and seems to relate to the direction of the entropy as learning progresses (i.e., either increasing or decreasing average uncertainty).”</p><p>We have edited the following texts in the Discussion (changes in italics):</p><p>“For the first time, we show that the direction of the relationship between postfeedback pupil dilation and information gain (defined as KL divergence) was context dependent.” (p. 29):</p><p>Finally, we have added the following correction to the Discussion (p. 30):</p><p>“Although it is tempting to speculate that the direction of the relationship between pupil dilation and information gain may be due to either increasing or decreasing entropy as the task progressed, we must refrain from this conclusion. We note that the two tasks differ substantially in terms of design with other confounding variables and therefore cannot be directly compared to one another. We expand on these limitations in the section below (see Limitations and future research).”</p><disp-quote content-type="editor-comment"><p>Finally, subjective factors such as participants' confidence and internal belief states were not measured, despite their potential influence on prediction errors and pupil responses.</p></disp-quote><p>Thank you for the thoughtful comment. We agree with the reviewer that subjective factors, such as participants' confidence, can be important in understanding prediction errors and pupil responses. As per the reviewer’s point, we have included the following limitation in the Discussion (p. 33):</p><p>“Finally, while we acknowledge the potential relevance of subjective factors, such as the participants’ overt confidence reports, in understanding prediction errors and pupil responses, the current study focused on the more objective, model-driven measure of information-theoretic variables. This approach aligns with our use of the ideal learner model, which estimates information-theoretic variables while being agnostic about the observer's subjective experience itself. Future research is needed to explore the relationship between information-gain signals in pupil dilation and the observer’s reported experience of or awareness about confidence in their decisions.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>The authors proposed that variability in post-feedback pupillary responses during the associative learning tasks can be explained by information gain, which is measured as KL divergence. They analysed pupil responses in a later time window (2.5s-3s after feedback onset) and correlated them with information-theory-based estimates from an ideal learner model (i.e., information gain-KL divergence, surprise-subjective probability, and entropy-average uncertainty) in two different associative decision-making tasks.</p><p>Strength:</p><p>The exploration of task-evoked pupil dynamics beyond the immediate response/feedback period and then associating them with model estimates was interesting and inspiring. This offered a new perspective on the relationship between pupil dilation and information processing.</p><p>Weakness:</p><p>However, disentangling these later effects from noise needs caution. Noise in pupillometry can arise from variations in stimuli and task engagement, as well as artefacts from earlier pupil dynamics. The increasing variance in the time series of pupillary responses (e.g., as shown in Figure 2D) highlights this concern.</p><p>It's also unclear what this complicated association between information gain and pupil dynamics actually means. The complexity of the two different tasks reported made the interpretation more difficult in the present manuscript.</p></disp-quote><p>We share the reviewer’s concerns. To make this point come across more clearly, we have added the following text to the Introduction (p. 5):</p><p>“The current study was motivated by Zenon’s hypothesis concerning the relationship between pupil dilation and information gain, particularly in light of the varying sources of signal and noise introduced by task context and pupil dynamics. By demonstrating how task context can influence which signals are reflected in pupil dilation, and highlighting the importance of considering their temporal dynamics, we aim to promote a more nuanced and model-driven approach to cognitive research using pupillometry.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public review):</bold></p><p>Summary:</p><p>This study examines prediction errors, information gain (Kullback-Leibler [KL] divergence), and uncertainty (entropy) from an information-theory perspective using two experimental tasks and pupillometry. The authors aim to test a theoretical proposal by Zénon (2019) that the pupil response reflects information gain (KL divergence). In particular, the study defines the prediction error in terms of KL divergence and speculates that changes in pupil size associated with KL divergence depend on entropy. Moreover, the authors examine the temporal characteristics of pupil correlates of prediction errors, which differed considerably across previous studies that employed different experimental paradigms. In my opinion, the study does not achieve these aims due to several methodological and theoretical issues.</p><p>Strengths:</p><p>(1) Use of an established Bayesian model to compute KL divergence and entropy.</p><p>(2) Pupillometry data preprocessing, including deconvolution.</p><p>Weaknesses:</p><p>(1) Definition of the prediction error in terms of KL divergence:</p><p>I'm concerned about the authors' theoretical assumption that the prediction error is defined in terms of KL divergence. The authors primarily refer to a review article by Zénon (2019): &quot;Eye pupil signals information gain&quot;. It is my understanding that Zénon argues that KL divergence quantifies the update of a belief, not the prediction error: &quot;In short, updates of the brain's internal model, quantified formally as the Kullback-Leibler (KL) divergence between prior and posterior beliefs, would be the common denominator to all these instances of pupillary dilation to cognition.&quot; (Zénon, 2019).</p><p>From my perspective, the update differs from the prediction error. Prediction error refers to the difference between outcome and expectation, while update refers to the difference between the prior and the posterior. The prediction error can drive the update, but the update is typically smaller, for example, because the prediction error is weighted by the learning rate to compute the update. My interpretation of Zénon (2019) is that they explicitly argue that KL divergence defines the update in terms of the described difference between prior and posterior, not the prediction error.</p><p>The authors also cite a few other papers, including Friston (2010), where I also could not find a definition of the prediction error in terms of KL divergence. For example [KL divergence:] &quot;A non-commutative measure of the non-negative difference between two probability distributions.&quot; Similarly, Friston (2010) states: Bayesian Surprise - &quot;A measure of salience based on the Kullback-Leibler divergence between the recognition density (which encodes posterior beliefs) and the prior density. It measures the information that can be recognized in the data.&quot; Finally, also in O'Reilly (2013), KL divergence is used to define the update of the internal model, not the prediction error.</p><p>The authors seem to mix up this common definition of the model update in terms of KL divergence and their definition of prediction error along the same lines. For example, on page 4: &quot;KL divergence is a measure of the difference between two probability distributions. In the context of predictive processing, KL divergence can be used to quantify the mismatch between the probability distributions corresponding to the brain's expectations about incoming sensory input and the actual sensory input received, in other words, the prediction error (Friston, 2010; Spratling, 2017).&quot;</p><p>Similarly (page 23): &quot;In the current study, we investigated whether the pupil's response to decision outcome (i.e., feedback) in the context of associative learning reflects a prediction error as defined by KL divergence.&quot;</p><p>This is problematic because the results might actually have limited implications for the authors' main perspective (i.e., that the pupil encodes prediction errors) and could be better interpreted in terms of model updating. In my opinion, there are two potential ways to deal with this issue:</p><p>(a) Cite work that unambiguously supports the perspective that it is reasonable to define the prediction error in terms of KL divergence and that this has a link to pupillometry. In this case, it would be necessary to clearly explain the definition of the prediction error in terms of KL divergence and dissociate it from the definition in terms of model updating.</p><p>(b) If there is no prior work supporting the authors' current perspective on the prediction error, it might be necessary to revise the entire paper substantially and focus on the definition in terms of model updating.</p></disp-quote><p>We thank the reviewer for pointy out these inconsistencies in the manuscript and appreciate their suggestions for improvement. We take approach (a) recommended by the reviewer, and provide our reasoning as to why prediction error signals in pupil dilation are expected to correlate with information gain (defined as the KL divergence between posterior and prior belief distributions). This can be found in a new section in the introduction, copied here for convenience (p. 3-4):</p><p>“We reasoned that the link between prediction error signals and information gain in pupil dilation is through precision-weighting. Precision refers to the amount of uncertainty (inverse variance) of both the prior belief and sensory input in the prediction error signals [6,64–67]. More precise prediction errors receive more weighting, and therefore, have greater influence on model updating processes. The precisionweighting of prediction error signals may provide a mechanism for distinguishing between known and unknown sources of uncertainty, related to the inherent stochastic nature of a signal versus insufficient information of the part of the observer, respectively [65,67,68]. In Bayesian frameworks, information gain is fundamentally linked to prediction error, modulated by precision [65,66,69–75]. In non-hierarchical Bayesian models, information gain can be derived as a function of prediction errors and the precision of the prior and likelihood distributions, a relationship that can be approximately linear [70]. In hierarchical Bayesian inference, the update in beliefs (posterior mean changes) at each level is proportional to the precision-weighted prediction error; this update encodes the information gained from new observations [65,66,69,71,72]. Neuromodulatory arousal systems are well-situated to act as precision-weighting mechanisms in line with predictive processing frameworks [76,77]. Empirical evidence suggests that neuromodulatory systems broadcast precisionweighted prediction errors to cortical regions [11,59,66,78]. Therefore, the hypothesis that feedback-locked pupil dilation reflects a prediction error signal is similarly in line with Zenon’s main claim that pupil dilation generally reflects information gain, through precision-weighting of the prediction error. We expected a prediction error signal in pupil dilation to be proportional to the information gain.”</p><p>We have referenced previous work that has linked prediction error and information gain directly (p. 4): “The KL divergence between posterior and prior belief distributions has been previously considered to be a proxy of (precision-weighted) prediction errors [68,72].”</p><p>We have taken the following steps to remedy this error of equating “prediction error” directly with the information gain.</p><p>First, we have replaced “KL divergence” with “information gain” whenever possible throughout the manuscript for greater clarity.</p><p>Second, we have edited the section in the introduction defining information gain substantially (p. 4):</p><p>“Information gain can be operationalized within information theory as the KullbackLeibler (KL) divergence between the posterior and prior belief distributions of a Bayesian observer, representing a formalized quantity that is used to update internal models [29,79,80]. Itti and Baldi (2005)81 termed the KL divergence between posterior and prior belief distributions as “Bayesian surprise” and showed a link to the allocation of attention. The KL divergence between posterior and prior belief distributions has been previously considered to be a proxy of (precision-weighted) prediction errors[68,72]. According to Zénon’s hypothesis, if pupil dilation reflects information gain during the observation of an outcome event, such as feedback on decision accuracy, then pupil size will be expected to increase in proportion to how much novel sensory evidence is used to update current beliefs [29,63]. ”</p><p>Finally, we have made several minor textual edits to the Abstract and main text wherever possible to further clarify the proposed relationship between prediction errors and information gain.</p><disp-quote content-type="editor-comment"><p>(2) Operationalization of prediction errors based on frequency, accuracy, and their interaction:</p><p>The authors also rely on a more model-agnostic definition of the prediction error in terms of stimulus frequency (&quot;unsigned prediction error&quot;), accuracy, and their interaction (&quot;signed prediction error&quot;). While I see the point here, I would argue that this approach offers a simple approximation to the prediction error, but it is possible that factors like difficulty and effort can influence the pupil signal at the same time, which the current approach does not take into account. I recommend computing prediction errors (defined in terms of the difference between outcome and expectation) based on a simple reinforcement-learning model and analyzing the data using a pupillometry regression model in which nuisance regressors are controlled, and results are corrected for multiple comparisons.</p></disp-quote><p>We agree with the reviewer’s suggestion that alternatively modeling the data in a reinforcement learning paradigm would be fruitful. We adopted the ideal learner model as we were primarily focused on Information Theory, stemming from our aim to test Zenon’s hypothesis that information gain drives pupil dilation. However, we agree with the reviewer that it is worthwhile to pursue different modeling approaches in future work. We have now included a complementary linear mixed model analysis in which we controlled for the effects of the information-theoretic variables on one another, while also including the nuisance regressors of pre-feedback baseline pupil dilation and reaction times (explained in more detail below in our response to your point #4). Results including correction for multiple comparisons was reported for all pupil time course data as detailed in Methods section 2.5.</p><disp-quote content-type="editor-comment"><p>(3) The link between model-based (KL divergence) and model-agnostic (frequency- and accuracy-based) prediction errors:</p><p>I was expecting a validation analysis showing that KL divergence and model-agnostic prediction errors are correlated (in the behavioral data). This would be useful to validate the theoretical assumptions empirically.</p></disp-quote><p>The model limitations and the operalization of prediction error in terms of post-feedback processing do not seem to allow for a comparison of information gain and model-agnostic prediction errors in the behavioral data for the following reasons. First, the simple ideal learner model used here is not a generative model, and therefore, cannot replicate or simulate the participants responses (see also our response to your point #6 “model validation” below). Second, the behavioral dependent variables obtained are accuracy and reaction times, which both occur before feedback presentation. While accuracy and reaction times can serve as a marker of the participant’s (statistical) confidence/uncertainty following the decision interval, these behavioral measures cannot provide access to post-feedback information processing. The pupil dilation is of interest to us because the peripheral arousal system is able to provide a marker of post-feedback processing. Through the analysis presented in Figure 3, we indeed aimed to make the comparison of the model-based information gain to the model-agnostic prediction errors via the proxy variable of post-feedback pupil dilation instead of behavioral variables. To bridge the gap between the “behaviorally agnostic” model parameters and the actual performance of the participants, we examined the relationship between the model-based information gain and the post-feedback pupil dilation separately for error and correct trials as shown in Figure 3D-F &amp; Figure 3J-L. We hope this addresses the reviewers concern and apologize in case we did not understand the reviewers suggestion here.</p><disp-quote content-type="editor-comment"><p>(4) Model-based analyses of pupil data:</p><p>I'm concerned about the authors' model-based analyses of the pupil data. The current approach is to simply compute a correlation for each model term separately (i.e., KL divergence, surprise, entropy). While the authors do show low correlations between these terms, single correlational analyses do not allow them to control for additional variables like outcome valence, prediction error (defined in terms of the difference between outcome and expectation), and additional nuisance variables like reaction time, as well as x and y coordinates of gaze.</p><p>Moreover, including entropy and KL divergence in the same regression model could, at least within each task, provide some insights into whether the pupil response to KL divergence depends on entropy. This could be achieved by including an interaction term between KL divergence and entropy in the model.</p></disp-quote><p>In line with the reviewer’s suggestions, we have included a complementary linear mixed model analysis in which we controlled for the effects of the information-theoretic variables on one another, while also including the nuisance regressors of pre-feedback baseline pupil dilation and reaction times. We compared the performance of two models on the post-feedback pupil dilation in each time window of interest: Modle 1 had no interaction between information gain and entropy and Model 2 included an interaction term as suggested. We did not include the x- and y- coordinates of gaze in the mixed linear model analysis, as there are multiple values of these coordinates per trial. Furthermore, regressing out the x and y- coordinates of gaze can potentially remove signal of interest in the pupil dilation data in addition to the gaze-related confounds and we did not measure absolute pupil size (Mathôt, Melmi &amp; Castet, 2015; Hayes &amp; Petrov, 2015). We present more sanity checks on the pre-processing pipeline as recommended by Reviewer 1.</p><p>This new analysis resulted in several additions to the Methods (see Section 2.5) and Results. In sum, we found that including an interaction term for information gain and entropy did not lead to better model fits, but sometimes lead to significantly worse fits. Overall, the results of the linear mixed model corroborated the “simple” correlation analysis across the pupil time course while accounting for the relationship to the pre-feedback baseline pupil and preceeding reaction time differences. There was only one difference to note between the correlation and linear mixed modeling analyses: for the error trials in the cue-target 2AFC task, including entropy in the model accounted for the variance previously explained by surprise.</p><disp-quote content-type="editor-comment"><p>(5) Major differences between experimental tasks:</p><p>More generally, I'm not convinced that the authors' conclusion that the pupil response to KL divergence depends on entropy is sufficiently supported by the current design. The two tasks differ on different levels (stimuli, contingencies, when learning takes place), not just in terms of entropy. In my opinion, it would be necessary to rely on a common task with two conditions that differ primarily in terms of entropy while controlling for other potentially confounding factors. I'm afraid that seemingly minor task details can dramatically change pupil responses. The positive/negative difference in the correlation with KL divergence that the authors interpret to be driven by entropy may depend on another potentially confounding factor currently not controlled.</p></disp-quote><p>We agree with the reviewer’s concerns and acknowledge that the speculation concerning the directional effect of entropy across trials can not be fully substantiated by the currect study. We note that Review #1 had a similar concern. Our response to Reviewer #1 addresses this concern of Reviewer #3 as well. To better align the manuscript with the above mentioned points, we have made several changes that are detailed in our response to Reviewer #1’s public review (above).</p><disp-quote content-type="editor-comment"><p>(6) Model validation:</p><p>My impression is that the ideal learner model should work well in this case. However, the authors don't directly compare model behavior to participant behavior (&quot;posterior predictive checks&quot;) to validate the model. Therefore, it is currently unclear if the model-derived terms like KL divergence and entropy provide reasonable estimates for the participant data.</p></disp-quote><p>Based on our understanding, posterior predictive checks are used to assess the goodness of fit between generated (or simulated) data and observed data. Given that the “simple” ideal learner model employed in the current study is not a generative model, a posterior predictive check would not apply here (Gelman, Carlin, Stern, Dunson, Vehtari, &amp; Rubin 2013). The ideal learner model is unable to simulate or replicate the participants’ responses and behaviors such as accuracy and reaction times; it simply computes the probability of seeing each stimulus type at each trial based on the prior distribution and the exact trial order of the stimuli presented to each participant. The model’s probabilities are computed directly from a Dirichlet distribution of values that represent the number of occurences of each stimulus-pair type for each task. The information-theoretic variables are then directly computed from these probabilities using standard formulas. The exact formulas used in the ideal learner model can be found in section 2.4.</p><p>We have now included a complementary linear mixed model analysis which also provides insight into the amount of explained variance of these information-theoretic predictors on the post-feedback pupil response, while also including the pre-feedback baseline pupil and reaction time differences (see section 3.3, Tables 3 &amp; 4). The R<sup>2</sup> values ranged from 0.16 – 0.50 across all conditions tested.</p><disp-quote content-type="editor-comment"><p>(7) Discussion:</p><p>The authors interpret the directional effect of the pupil response w.r.t. KL divergence in terms of differences in entropy. However, I did not find a normative/computational explanation supporting this interpretation. Why should the pupil (or the central arousal system) respond differently to KL divergence depending on differences in entropy?</p><p>The current suggestion (page 24) that might go in this direction is that pupil responses are driven by uncertainty (entropy) rather than learning (quoting O'Reilly et al. (2013)). However, this might be inconsistent with the authors' overarching perspective based on Zénon (2019) stating that pupil responses reflect updating, which seems to imply learning, in my opinion. To go beyond the suggestion that the relationship between KL divergence and pupil size &quot;needs more context&quot; than previously assumed, I would recommend a deeper discussion of the computational underpinnings of the result.</p></disp-quote><p>Since we have removed the original speculative conclusion from the manuscript, we will refrain from discussing the computational underpinnings of a potential mechanism. To note as mentioned above, we have preliminary data from our own lab that contradicts our original hypothesis about the relationship between entropy and information gain on the post-feedback pupil response.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>Apart from the points raised in the public review above, I'd like to use the opportunity here to provide a more detailed review of potential issues, questions, and queries I have:</p><p>(1) Constriction vs. Dilation Effects:</p><p>The study observes a context-dependent relationship between KL divergence and pupil responses, where pupil dilation and constriction appear to exhibit opposing effects. However, this phenomenon raises a critical concern: Could the initial pupil constriction to visual stimuli (e.g., in the cue-target task) confound correlations with KL divergence? This potential confound warrants further clarification or control analyses to ensure that the observed effects genuinely reflect prediction error signals and are not merely a result of low-level stimulus-driven responses.</p></disp-quote><p>We agree with the reviewers concern and have added the following information to the limitations section in the Discussion (changes in italics below; p. 32-33).</p><p>“First, the two associative learning paradigms differed in many ways and were not directly comparable. For instance, the shape of the mean pupil response function differed across the two tasks in accordance with a visual or auditory feedback stimulus (compare Supplementary Figure 3A with Supplementary Figure 3D), and it is unclear whether these overall response differences contributed to any differences obtained between task conditions within each task. We are unable to rule out whether so-called “low level” effects such as the initial constriction to visual stimuli in the cue-target 2AFC task as compared with the dilation in response auditory stimuli in letter-color 2AFC task could confound correlations with information gain. Future work should strive to disentangle how the specific aspects of the associative learning paradigms relate to prediction errors in pupil dilation by systematically manipulating design elements within each task.”</p><disp-quote content-type="editor-comment"><p>Here, I also was curious about Supplementary Figure 1, showing 'no difference' between the two tones (indicating 'error' or 'correct'). Was this the case for FDR-corrected or uncorrected cluster statistics? Especially since the main results also showed sig. differences only for uncorrected cluster statistics (Figure 2), but were n.s. for FDR corrected. I.e. can we be sure to rule out a confound of the tones here after all?</p></disp-quote><p>As per the reviewer’s suggestion, we verified that there were also no significant clusters after feedback onset before applying the correction for multiple comparisons. We have added this information to Supplemenatary section 1.2 as follows:</p><p>“Results showed that the auditory tone dilated pupils on average (Supplementary Figure 1C). Crucially, however, the two tones did not differ from one another in either of the time windows of interest (Supplementary Figure 1D); no significant time points after feedback onset were obtained either before or after correcting for multiple comparisons using cluster-based permutation methods; see Section 2.5.”</p><p>Supplementary Figure 1 is showing effects cluster-corrected for multiple comparisons using cluster-based permutation tests from the MNE software package in Python (see Methods section 2.5). We have clarified that the cluster-correction was based on permutation testing in the figure legend.</p><disp-quote content-type="editor-comment"><p>(2) Participant-Specific Priors:</p><p>The ideal learner models do not account for individualised priors, assuming homogeneous learning behaviour across participants. Could incorporating participant-specific priors better reflect variability in how individuals update their beliefs during associative learning?</p></disp-quote><p>We have clarified in the Methods (see section 2.4) that the ideal learner models did account for participant-specific stimuli including participant-specific priors in the letter-color 2AFC task. We have added the following texts:</p><p>“We also note that while the ideal learner model for the cue-target 2AFC task used a uniform (flat) prior distribution for all participants, the model parameters were based on the participant-specific cue-target counterbalancing conditions and randomized trial order.” (p. 13)</p><p>“The prior distributions used for the letter-color 2AFC task were estimated from the randomized letter-color pairs and randomized trial order presentation in the preceding odd-ball task; this resulted in participant-specific prior distributions for the ideal learner model of the letter-color 2AFC task. The model parameters were likewise estimated from the (participant-specific) randomized trial order presented in the letter-color 2AFC task.” (p. 13)</p><disp-quote content-type="editor-comment"><p>(3) Trial-by-Trial Variability:</p><p>The analysis does not account for random effects or inter-trial variability using mixed-effects models. Including such models could provide a more robust statistical framework and ensure the observed relationships are not influenced by unaccounted participant- or trial-specific factors.</p></disp-quote><p>We have included a complementary linear mixed model analysis in which “subject” was modeled as a random effect on the post-feedback pupil response in each time window of interest and for each task. Across all trials, the results of the linear mixed model corroborated the “simple” correlation analysis across the pupil time course while accounting for the relationship to the prefeedback baseline pupil and preceeding reaction time differences (see section 3.3, Tables 3 &amp; 4).</p><disp-quote content-type="editor-comment"><p>(4) Preprocessing/Analysis choices:</p><p>Before anything else, I'd like to highlight the authors' effort in providing public code (and data) in a very readable and detailed format!</p></disp-quote><p>We appreciate the compliment - thank you for taking the time to look at the data and code provided.</p><disp-quote content-type="editor-comment"><p>I found the idea of regressing the effect of Blinks/Saccades on the pupil trace intriguing. However, I miss a complete picture here to understand how well this actually worked, especially since it seems to be performed on already interpolated data. My main points here are:</p><p>(4.1) Why is the deconvolution performed on already interpolated data and not on 'raw' data where there are actually peaks of information to fit?</p></disp-quote><p>To our understanding, at least one critical reason for interpolating the data before proceeding with the deconvolution analysis is that the raw data contain many missing values (i.e., NaNs) due to the presence of blinks. Interpolating over the missing data first ensures that there are valid numerical elements in the linear algebra equations. We refer the reviewer to the methods detailed in Knapen et al. (2016) for more details on this pre-processing method.</p><disp-quote content-type="editor-comment"><p>(4.2) What is the model fit (e.g. R-squared)? If this was a poor fit for the regressors in the first place, can we trust the residuals (i.e. clean pupil trace)? Is it possible to plot the same Pupil trace of Figure 1D with (a) the 'raw' pupil time-series, (b) after interpolation only (both of course also mean-centered for comparison), on top of the residuals after deconvolution (already presented), so we can be sure that this is not driving the effects in a 'bad' way? I'd just like to make sure that this approach did not lead to artefacts in the residuals rather than removing them.</p></disp-quote><p>We thank the reviewer for this suggestion. In the Supplementary Materials, we have included a new figure (Supplementary Figure 2, copied below for convience), which illustrates the same conditions as in Figure 1D and Figure 2D, with (1) the raw data, and (2) the interpolated data before the nuisance regression. Both the raw data and interpolated data have been band-pass filtered as was done in the original pre-processing pipeline and converted to percent signal change. These figures can be compared directly to Figure 1D and Figure 2D, for the two tasks, respectively.</p><p>Of note is that the raw data seem to be dominated by responses to blinks (and/or saccades). Crucially, the pattern of results remains overall unchaged between the interpolated-only and fully pre-processed version of the data for both tasks.</p><p>In the Supplementary Materials (see Supplementary section 2), we have added the descriptives of the model fits from the deconvolution method. Model fits (R<sup>2</sup>) for the nuisance regression were generally low: cue-target 2AFC task, M = 0.03, SD = 0.02, range = [0.00, 0.07]; letter-color visual 2AFC, M = 0.08, SD = 0.04, range = [0.02, 0.16].</p><p>Furthermore, a Pearson correlation analysis between the interpolated and fully pre-processed data within the time windows of interest for both task indicated high correspondence:</p><p>Cue-target 2AFC task</p><p>Early time window: M = 0.99, SD = 0.01, range = [0.955, 1.000]</p><p>Late time window: M = 0.99, SD = 0.01, range = [0.971, 1.000]</p><p>Letter-color visual 2AFC</p><p>Early time window: M = 0.95, SD = 0.04, range = [0.803, 0.998]</p><p>Late time window: M = 0.97, SD = 0.02, range = [0.908, 0.999]</p><p>In hindsight, including the deconvolution (nuisance regression) method may not have changed the pattern of results much. However, the decision to include this deconvolution method was not data-driven; instead, it was based on the literature establishing the importance of removing variance (up to 5 s) of these blinks and saccades from cognitive effects of interest in pupil dilation (Knapen et al., 2016).</p><disp-quote content-type="editor-comment"><p>(4.3) Since this should also lead to predicted time series for the nuisance-regressors, can we see a similar effect (of what is reported for the pupil dilation) based on the blink/saccade traces of (a) their predicted time series based on the deconvolution, which could indicate a problem with the interpretation of the pupil dilation effects, and (b) the 'raw' blink/saccade events from the eye-tracker? I understand that this is a very exhaustive analysis so I would actually just be interested here in an averaged time-course / blink&amp;saccade frequency of the same time-window in Figure 1D to complement the PD analysis as a sanity check.</p></disp-quote><p>Also included in the Supplementary Figure 2 is the data averaged as in Figure 1D and Figure 2D for the raw data and nuisance-predictor time courses (please refer to the bottom row of the sub-plots). No pattern was observed in either the raw data or the nuisance predictors as was shown in the residual time courses.</p><disp-quote content-type="editor-comment"><p>(4.4) How many samples were removed from the time series due to blinks/saccades in the first place? 150ms for both events in both directions is quite a long bit of time so I wonder how much 'original' information of the pupil was actually left in the time windows of interest that were used for subsequent interpretations.</p></disp-quote><p>We thank the reviewer for bringing this issue to our attention. The size of the interpolation window was based on previous literature, indicating a range of 100-200 ms as acceptable (Urai et al., 2017; Knapen et al., 2016; Winn et al., 2018). The ratio of interpolated-to-original data (across the entire trial) varied greatly between participants and between trials: cue-target 2AFC task, M = 0.262, SD = 0.242, range = [0,1]; letter-color 2AFC task, M = 0.194, SD = 0.199, range = [0,1].</p><p>We have now included a conservative analysis in which only trials with more than half (threshold = 60%) of original data are included in the analyses. Crucially, we still observe the same pattern of effects as when all data are considered across both tasks (compare the second to last row in the Supplementary Figure 2 to Figure 1D and Figure 2D).</p><disp-quote content-type="editor-comment"><p>(4.5) Was the baseline correction performed on the percentage change unit?</p></disp-quote><p>Yes, the baseline correction was performed on the pupil timeseries after converting to percentsignal change. We have added that information to the Methods (section 2.3).</p><disp-quote content-type="editor-comment"><p>(4.6) What metric was used to define events in the derivative as 'peaks'? I assume some sort of threshold? How was this chosen?</p></disp-quote><p>The threshold was chosen in a data-driven manner and was kept consistent across both tasks. The following details have been added to the Methods:</p><p>“The size of the interpolation window preceding nuisance events was based on previous literature [13,39,99]. After interpolation based on data-markers and/or missing values, remaining blinks and saccades were estimated by testing the first derivative of the pupil dilation time series against a threshold rate of change. The threshold for identifying peaks in the temporal derivative is data-driven, partially based on past work[10,14,33]. The output of each participant’s pre-processing pipeline was checked visually. Once an appropriate threshold was established at the group level, it remained the same for all participants (minimum peak height of 10 units).” (p. 8 &amp; 11).</p><disp-quote content-type="editor-comment"><p>(5) Multicollinearity Between Variables:</p><p>Lastly, the authors state on page 13: &quot;Furthermore, it is expected that these explanatory variables will be correlated with one another. For this reason, we did not adopt a multiple regression approach to test the relationship between the information-theoretic variables and pupil response in a single model&quot;. However, the very purpose of multiple regression is to account for and disentangle the contributions of correlated predictors, no? I might have missed something here.</p></disp-quote><p>We apologize for the ambiguity of our explanation in the Methods section. We originally sought to assess the overall relationship between the post-feedback response and information gain (primarily), but also surprise and entropy. Our reasoning was that these variables are often investigated in isolation across different experiments (i.e., only investigating Shannon surprise), and we would like to know what the pattern of results would look like when comparing a single information-theoretic variable to the pupil response (one-by-one). We assumed that including additional explanatory variables (that we expected to show some degree of collinearity with each other) in a regression model would affect variance attributed to them as compared with the one-on-one relationships observed with the pupil response (Morrissey &amp; Ruxton 2018). We also acknowledge the value of a multiple regression approach on our data. Based on the suggestions by the reviewers we have included a complementary linear mixed model analysis in which we controlled for the effects of the information-theoretic variables on one another, while also including the nuisance regressors of pre-feedback baseline pupil dilation and reaction times.</p><p>This new analysis resulted in several additions to the Methods (see Section 2.5) and Results (see Tables 3 and 4). Overall, the results of the linear mixed model corroborated the “simple” correlation analysis across the pupil time course while accounting for the relationship to the prefeedback baseline pupil and preceeding reaction time differences. There was only one difference to note between the correlation and linear mixed modeling analyses: for the error trials in the cue-target 2AFC task, including entropy in the model accounted for the variance previously explained by surprise.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>(1) Given the inherent temporal dependencies in pupil dynamics, characterising later pupil responses as independent of earlier ones in a three-way repeated measures ANOVA may not be appropriate. A more suitable approach might involve incorporating the earlier pupil response as a covariate in the model.</p></disp-quote><p>We thank the reviewer for bringing this issue to our attention. From our understanding, a repeated-measures ANOVA with factor “time window” would be appropriate in the current context for the following reasons. First, autocorrelation (closely tied to sphericity) is generally not considered a problem when only two timepoints are compared from time series data (Field, 2013; Tabachnick &amp; Fidell, 2019). Second, the repeated-measures component of the ANOVA takes the correlated variance between time points into account in the statistical inference. Finally, as a complementary analysis, we present the results testing the interaction between the frequency and accuracy conditions across the full time courses (see Figures 1D and 2D); in these pupil time courses, any difference between the early and late time windows can be judged by the reader visually and qualitatively.</p><disp-quote content-type="editor-comment"><p>(2) Please clarify the correlations between KL divergence, surprise, entropy, and pupil response time series. Specifically, state whether these correlations account for the interrelationships between these information-theoretic measures. Given their strong correlations, partialing out these effects is crucial for accurate interpretation.</p></disp-quote><p>As mentioned above, based on the suggestions by the reviewers we have included a complementary linear mixed model analysis in which we controlled for the effects of the information-theoretic variables on one another, while also including the nuisance regressors of pre-feedback baseline pupil dilation and reaction times.</p><p>This new analysis resulted in several additions to the Methods (see Section 2.5) and Results (see Tables 3 and 4). Overall, the results of the linear mixed model corroborated the “simple” correlation analysis across the pupil time course while accounting for the relationship to the prefeedback baseline pupil and preceeding reaction time differences. There was only one difference to note between the correlation and linear mixed modeling analyses: for the error trials in the cue-target 2AFC task, including entropy in the model accounted for the variance previously explained by surprise.</p><disp-quote content-type="editor-comment"><p>(3) The effects observed in the late time windows appear weak (e.g., Figure 2E vs. 2F, and the generally low correlation coefficients in Figure 3). Please elaborate on the reliability and potential implications of these findings.</p></disp-quote><p>We have now included a complementary linear mixed model analysis which also provides insight into the amount of explained variance of these information-theoretic predictors on the post-feedback pupil response, while also including the pre-feedback baseline pupil and reaction time differences (see section 3.3, Tables 3 &amp; 4). The R<sup>2</sup> values ranged from 0.16 – 0.50 across all conditions tested. Including the pre-feedback baseline pupil dilation as a predictor in the linear mixed model analysis consistently led to more explained variance in the post-feedback pupil response, as expected.</p><disp-quote content-type="editor-comment"><p>(4) In Figure 3 (C-J), please clarify how the trial-by-trial correlations were computed (averaged across trials or subjects). Also, specify how the standard error of the mean (SEM) was calculated (using the number of participants or trials).</p></disp-quote><p>The trial-by-trial correlations between the pupil signal and model parameters were computed for each participant, then the coefficients were averaged across participants for statistical inference. We have added several clarifications in the text (see section 2.5 and legends of Figure 3 and Supplementary Figure 4).</p><p>We have added “the standard error of the mean across participants” to all figure labels.</p><disp-quote content-type="editor-comment"><p>(5) For all time axes (e.g., Figure 2D), please label the ticks at 0, 0.5, 1, 1.5, 2, 2.5, and 3 seconds. Clearly indicate the duration of the feedback on the time axes. This is particularly important for interpreting the pupil dilation responses evoked by auditory feedback.</p></disp-quote><p>We have labeled the x-ticks every 0.5 seconds in all figures and indicated the duration of the auditory feedback in the letter-color decision task and as well as the stimuli presented in the control tasks in the Supplementary Materials.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations for the authors):</bold></p><p>(1) Introduction page 3: &quot;In information theory, information gain quantifies the reduction of uncertainty about a random variable given the knowledge of another variable. In other words, information gain measures how much knowing about one variable improves the prediction or understanding of another variable.&quot;</p><p>(2) In my opinion, the description of information gain can be clarified. Currently, it is not very concrete and quite abstract. I would recommend explaining it in the context of belief updating.</p></disp-quote><p>We have removed these unclear statements in the Introduction. We now clearly state the following:</p><p>“Information gain can be operationalized within information theory as the KullbackLeibler (KL) divergence between the posterior and prior belief distributions of a Bayesian observer, representing a formalized quantity that is used to update internal models [29,79,80].” (p. 4)</p><disp-quote content-type="editor-comment"><p>(3) Page 4: The inconsistencies across studies are described in extreme detail. I recommend shortening this part and summarizing the inconsistencies instead of listing all of the findings separately.</p></disp-quote><p>As per the reviewer’s recommendation, we have shortened this part of the introduction to summarize the inconsistencies in a more concise manner as follows:</p><p>“Previous studies have shown different temporal response dynamics of prediction error signals in pupil dilation following feedback on decision outcome: While some studies suggest that the prediction error signals arise around the peak (~1 s) of the canonical impulse response function of the pupil [11,30,41,61,62,90], other studies have shown evidence that prediction error signals (also) arise considerably later with respect to feedback on choice outcome [10,25,32,41,62]. A relatively slower prediction error signal following feedback presentation may suggest deeper cognitive processing, increased cognitive load from sustained attention or ongoing uncertainty, or that the brain is integrating multiple sources of information before updating its internal model. Taken together, the literature on prediction error signals in pupil dilation following feedback on decision outcome does not converge to produce a consistent temporal signature.” (p. 5)</p><p>We would like to note some additional minor corrections to the preprint:</p><p>We have clarified the direction of the effect in Supplementary Figure 3 with the following:</p><p>“Participants who showed a larger mean difference between the 80% as compared with the 20% frequency conditions in accuracy also showed smaller differences (a larger mean difference in magnitude in the negative direction) in pupil responses between frequency conditions (see Supplementary Figure 4).”</p><p>The y-axis labels in Supplementary Figure 3 were incorrect and have been corrected as the following: “Pupil responses (80-20%)”.</p><p>We corrected typos, formatting and grammatical mistakes when discovered during the revision process. Some minor changes were made to improve clarity. Of course, we include a version of the manuscript with Tracked Changes as instructed for consideration.</p></body></sub-article></article>