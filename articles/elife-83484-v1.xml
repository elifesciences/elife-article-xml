<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">83484</article-id><article-id pub-id-type="doi">10.7554/eLife.83484</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Medicine</subject></subj-group></article-categories><title-group><article-title>Biomedical supervisors’ role modeling of open science practices</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-292814"><name><surname>Haven</surname><given-names>Tamarinde L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4702-2472</contrib-id><email>tlh@ps.au.dk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-293317"><name><surname>Abunijela</surname><given-names>Susan</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-293318"><name><surname>Hildebrand</surname><given-names>Nicole</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01aj84f44</institution-id><institution>Danish Centre for Studies in Research and Research Policy, Department of Political Science, Aarhus University</institution></institution-wrap><addr-line><named-content content-type="city">Aarhus</named-content></addr-line><country>Denmark</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/001w7jn25</institution-id><institution>QUEST Center for Responsible Research, Berlin Institute of Health at Charité - Universitätsmedizin Berlin</institution></institution-wrap><addr-line><named-content content-type="city">Berlin</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Allison</surname><given-names>David B</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kg8sb98</institution-id><institution>Indiana University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Zaidi</surname><given-names>Mone</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04a9tmd77</institution-id><institution>Icahn School of Medicine at Mount Sinai</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>22</day><month>05</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e83484</elocation-id><history><date date-type="received" iso-8601-date="2022-09-15"><day>15</day><month>09</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-05-04"><day>04</day><month>05</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-09-15"><day>15</day><month>09</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.31222/osf.io/zd5u9"/></event></pub-history><permissions><copyright-statement>© 2023, Haven et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Haven et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-83484-v1.pdf"/><abstract><p>Supervision is one important way to socialize Ph.D. candidates into open and responsible research. We hypothesized that one should be more likely to identify open science practices (here publishing open access and sharing data) in empirical publications that were part of a Ph.D. thesis when the Ph.D. candidates’ supervisors engaged in these practices compared to those whose supervisors did not or less often did. Departing from thesis repositories at four Dutch University Medical centers, we included 211 pairs of supervisors and Ph.D. candidates, resulting in a sample of 2062 publications. We determined open access status using UnpaywallR and Open Data using Oddpub, where we also manually screened publications with potential open data statements. Eighty-three percent of our sample was published openly, and 9% had open data statements. Having a supervisor who published open access more often than the national average was associated with an odds of 1.99 to publish open access. However, this effect became nonsignificant when correcting for institutions. Having a supervisor who shared data was associated with 2.22 (CI:1.19–4.12) times the odds to share data compared to having a supervisor that did not. This odds ratio increased to 4.6 (CI:1.86–11.35) after removing false positives. The prevalence of open data in our sample was comparable to international studies; open access rates were higher. Whilst Ph.D. candidates spearhead initiatives to promote open science, this study adds value by investigating the role of supervisors in promoting open science.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>Open science</kwd><kwd>Supervision</kwd><kwd>responsible conduct of research</kwd><kwd>Open access</kwd><kwd>Open data</kwd><kwd>Research integrity</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>019.212SG.022.</award-id><principal-award-recipient><name><surname>Haven</surname><given-names>Tamarinde L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Supervisors' engagement in open science practices such as data sharing is associated with a greater odds that Ph.D. students engage in these practices and share their data.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>When conducted in a manner that emphasizes rigorous and transparent research, supervision can be an important means to socialize Ph.D. candidates into responsible research practices (<xref ref-type="bibr" rid="bib7">Bird, 2001</xref>; <xref ref-type="bibr" rid="bib2">Anderson et al., 2007</xref>; <xref ref-type="bibr" rid="bib12">Davis et al., 2007</xref>; <xref ref-type="bibr" rid="bib1">All European Academies, 2017</xref>; <xref ref-type="bibr" rid="bib40">Universities of The Netherlands, 2018</xref>). Responsible research practices are practices researchers can engage in to enhance the transparency, validity, and trustworthiness of their work (<xref ref-type="bibr" rid="bib38">Steneck, 2006</xref>; <xref ref-type="bibr" rid="bib8">Bouter, 2020</xref>). Within biomedical science, examples include open science practices such as openly sharing data and publishing open access, as well as making the underlying methodology openly available, and explicitly acknowledging the limitations of the research findings (<xref ref-type="bibr" rid="bib21">Iqbal et al., 2016</xref>; <xref ref-type="bibr" rid="bib25">Moher et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Wallach et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Serghiou et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Gopalakrishna et al., 2022b</xref>; <xref ref-type="bibr" rid="bib39">Susanin et al., 2022</xref>; <xref ref-type="bibr" rid="bib34">Roche et al., 2022a</xref>; <xref ref-type="bibr" rid="bib19">Hughes et al., 2022</xref>).</p><p>To effectively socialize Ph.D. candidates into open and responsible research practices, a pilot study conducted by a research team including the first author distinguished three components (<xref ref-type="bibr" rid="bib17">Haven et al., 2022</xref>). First, the supervisor is supposed to be a role model, i.e., the supervisor engages in open and responsible research practices by for example making their own data and code consistently available. Second, the supervisor encourages the Ph.D. candidate to engage in responsible research practices. After all, it could be that the supervisor has more of a coordinating role or is perhaps versed in another sub-discipline than the Ph.D. candidate’s research. Some have referred to this as the distinction between implicit (role modeling) and explicit (verbal instructions and encouragement) supervision (<xref ref-type="bibr" rid="bib13">Fisher et al., 2009</xref>). Third, the supervisor is able to create a psychologically safe atmosphere where Ph.D. candidates feel the space to discuss dilemmas, admit mistakes, and question the status quo (<xref ref-type="bibr" rid="bib3">Antes and DuBois, 2018</xref>; <xref ref-type="bibr" rid="bib4">Antes et al., 2019a</xref>; <xref ref-type="bibr" rid="bib5">Antes et al., 2019b</xref>). This psychological safety in turn contributes to maintaining quality by creating an environment where colleagues can safely scrutinize each others’ work (<xref ref-type="bibr" rid="bib32">Roberto et al., 2006</xref>; <xref ref-type="bibr" rid="bib16">Halbesleben and Rathert, 2008</xref>).</p><p>Research into responsible supervision is growing, but many knowledge gaps remain. A scoping review (<xref ref-type="bibr" rid="bib28">Pizzolato and Dierickx, 2023</xref>) identified a total of 35 empirical studies on the topic, two-thirds of which used a survey design where they enquired about perceptions from either supervisors or supervisees (except for <xref ref-type="bibr" rid="bib10">Buljan et al., 2018</xref>, who did a qualitative study). More direct evidence (beyond perceptions) on role modeling could not be identified, whereas this role modeling is presumed to be a crucial component of responsible supervision.</p><p>This study adds to the literature by proposing a new way to investigate the role modeling of open science practices in biomedicine. It starts from the assumption that if role modeling is important, then it should be possible to discern an association between the supervisor’s engagement in open science practices and the Ph.D. candidate’s engagement in open science practices. We hypothesized that one should be more likely to identify open science practices (here publishing open access and sharing data) in empirical publications that were part of a Ph.D. thesis when the Ph.D. candidates’ supervisors engaged in these open science practices compared to those whose supervisors did not or less often did.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Open science practices analyses</title><p>We managed to include 211 pairs of Ph.D. candidates and supervisors, 50 from Leiden UMC, 54 pairs from Amsterdam UMC, 52 from UMC Groningen, and 55 from Maastricht UMC. This resulted in 2062 DOIs, six of which did not resolve in Unpaywall (0.3%) and 14 PDFs could not be obtained for Oddpub (0.7%). Prevalence for each practice (expressed as unique DOIs) appear in <xref ref-type="table" rid="table1">Table 1</xref>, as well as correlations between the Ph.D. candidates’ engagement in a practice and the supervisors’ engagement in a practice. GEE logistic regression analyses for both crude and adjusted models appear in <xref ref-type="table" rid="table2">Table 2</xref>.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Prevalence of open access publishing and sharing data openly among unique DOIs.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Practice</th><th align="left" valign="top">Ph.D. candidates</th><th align="left" valign="top">Supervisors</th><th align="left" valign="top">Total<xref ref-type="table-fn" rid="table1fn1"><sup>*</sup></xref></th><th align="left" valign="top">Spearman’s correlation</th></tr></thead><tbody><tr><td align="left" valign="top">Open access</td><td align="char" char="." valign="top">548</td><td align="char" char="." valign="top">1154</td><td align="char" char="." valign="top">1702 (82.8%)</td><td align="char" char="." valign="top">0.24</td></tr><tr><td align="left" valign="top">Open data (automated)</td><td align="char" char="." valign="top">67</td><td align="char" char="." valign="top">112</td><td align="char" char="." valign="top">179 (8.8%)</td><td align="char" char="." valign="top">0.20</td></tr><tr><td align="left" valign="top">Open data (manually verified)</td><td align="char" char="." valign="top">34</td><td align="char" char="." valign="top">66</td><td align="char" char="." valign="top">100 (4.8%)</td><td align="char" char="." valign="top">0.22</td></tr></tbody></table><table-wrap-foot><fn id="table1fn1"><label>*</label><p>Between parentheses indicates proportion out of the total sample.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>GEE logistic analyses for open access, open data (automated detection), and open data (manually verified).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom" colspan="4">Crude analysis</th><th align="left" valign="bottom" colspan="4">Adjusted analysis (institution added)</th></tr></thead><tbody><tr><td align="left" valign="bottom">Practice</td><td align="left" valign="bottom">N</td><td align="left" valign="bottom">OR<xref ref-type="table-fn" rid="table2fn2">*</xref></td><td align="char" char="." valign="bottom">95% CI</td><td align="left" valign="bottom">p-value</td><td align="left" valign="bottom">N</td><td align="left" valign="bottom">OR<xref ref-type="table-fn" rid="table2fn2">*</xref></td><td align="char" char="." valign="bottom">95% CI</td><td align="left" valign="bottom">p-value</td></tr><tr><td align="left" valign="bottom">Open access (binary)</td><td align="char" char="." valign="bottom">651</td><td align="char" char="." valign="bottom">1.99</td><td align="char" char="ndash" valign="bottom">(1.17–3.38)</td><td align="char" char="." valign="bottom">0.011</td><td align="char" char="." valign="bottom">651</td><td align="char" char="." valign="bottom">1.64</td><td align="char" char="ndash" valign="bottom">(0.94–2.85)</td><td align="char" char="." valign="bottom">0.079</td></tr><tr><td align="left" valign="bottom" colspan="9"><italic>Reference category: up to or including the national average (76%) of the supervisor’s publications were open access</italic></td></tr><tr><td align="left" valign="bottom">Open data automated (binary)</td><td align="char" char="." valign="bottom">644</td><td align="char" char="." valign="bottom">2.09</td><td align="char" char="ndash" valign="bottom">(1.13–3.88)</td><td align="char" char="." valign="bottom">0.019</td><td align="char" char="." valign="bottom">644</td><td align="char" char="." valign="bottom">2.21</td><td align="char" char="ndash" valign="bottom">(1.19–4.12)</td><td align="char" char="." valign="bottom">0.012</td></tr><tr><td align="left" valign="bottom" colspan="9"><italic>Reference category: supervisor never shared data</italic></td></tr><tr><td align="left" valign="bottom">Open data manually verified (binary)</td><td align="char" char="." valign="bottom">653</td><td align="char" char="." valign="bottom">3.74</td><td align="char" char="ndash" valign="bottom">(1.53–9.12)</td><td align="char" char="." valign="bottom">0.004</td><td align="char" char="." valign="bottom">653</td><td align="char" char="." valign="bottom">4.60</td><td align="char" char="ndash" valign="bottom">(1.86–11.35)</td><td align="char" char="." valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom" colspan="9"><italic>Reference category: supervisor never shared data</italic></td></tr></tbody></table><table-wrap-foot><fn><p>N=the total number of included publications by Ph.D. candidates.</p></fn><fn id="table2fn2"><label>*</label><p>Odds ratios are EXP transformed.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-2"><title>Retractions analysis</title><p>We were able to link a total of 81,091 publications to the supervisors and Ph.D. candidates. Three Ph.D. candidates could not be identified, all supervisors were identified. Of the 81,091 publications that could be matched to the Ph.D. candidates and supervisors, two were retracted. Both regarded publications where the supervisor appeared as one of the co-authors and were retracted one year after publication. The following reasons were specified, which we interpret as honest errors:</p><p>‘The authors have become aware that some of the results presented in this paper are invalid, not reproducible, and/or misinterpreted. They consider that the main conclusion of the paper is not valid. They, therefore, retract this publication’.</p><p>‘The original version of this article was withdrawn by the authors. An error was discovered in the creation of the protein database file that was used for searching, which led to some incorrect associations between peptides and proteins. A corrected version of the manuscript has been supplied which contains very similar peptide identifications as the original, but the resulting number of proteins in various categories has now changed, and as a result, some of the figures and supplementary files have changed also. The underlying conclusions of this study, however, remain unaltered’.</p><p>None of the publications included in our own dataset were retracted. RetractionWatch, a blog and database tracking and reporting on retractions (<ext-link ext-link-type="uri" xlink:href="https://retractionwatch.com/">https://retractionwatch.com/</ext-link>), indicated that retractions can take from 3 months to many years, hence some papers may be retracted in the future.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We hypothesized that having a supervisor that shares data or publishes open access was associated with a higher likelihood that the Ph.D. candidate will engage in the same practice. Based on the automated detection of data-sharing statements, we found that having a supervisor that shared data is associated with 2.21 (p=0.012) times the odds to share data when compared to having a supervisor that did not share data. This odds ratio increased to 4.6 (p=0.001) after manually checking the open data statements and removing false positives. The unadjusted open access odds ratio was 1.99 (p=0.011) and became 1.64 (p=0.079) when correcting for the role of the institution. By including the institute variable in our adjusted analyses, the effects of open data remain significant. The odds ratio for the manually verified open data increased by 23%, which could be due to the institution initially masking the effect of the supervisor (see also <xref ref-type="bibr" rid="bib22">Kahan et al., 2014</xref>).</p><sec id="s3-1"><title>Contextualisation</title><p>Since our sample consists of Ph.D. candidates and supervisors from Dutch UMCs and focuses only on recent years, it may be useful to compare it to international data and reflect on some assumptions that went into our design. <xref ref-type="bibr" rid="bib37">Serghiou et al., 2021</xref> screened all of PubMed Central using the same text-mining algorithm as the current study and found 8.9% of publications to return Open Data statements. It, therefore, seems likely that our sample (8.8%) is not substantially different from the rest of biomedicine.</p><p>We included publications across various subfields of biomedicine. However, the odds of finding a publication that shares its underlying data may not be the same for all subfields. Subfields working with genetics and OMICS data could be more likely to share data than studies that describe clinical research, because of the ethical and privacy-related complications involved (<xref ref-type="bibr" rid="bib24">Mansmann et al., 2023</xref>).</p><p>It should be noted that open data does not imply the data is gathered in a rigorous, ethical, and reproducible manner. It could even be that the data are FAIR but still not useful, because the methods used were not well-suited to answer the research question, or because the data collection was sloppy, or because the data fail to capture crucial differences in the target population. We manually verified whether we could find the data, and whether data were actually open, stored on a repository and downloadable. Any assessments about the quality of the data or the quality of archiving (see e.g. <xref ref-type="bibr" rid="bib35">Roche et al., 2022b</xref>) are beyond the scope of this paper.</p><p>For open access (82.8% current study), we find our Dutch sample to be in line with national data, but above average when compared to international studies. The Rathenau Institute calculated that 76% of all Dutch publications were available to open access in 2021. Using the Unpaywall, <xref ref-type="bibr" rid="bib33">Robinson-Garcia et al., 2020</xref> found the Dutch uptake of open access to be around 60%. Looking internationally, <xref ref-type="bibr" rid="bib26">Piwowar et al., 2018</xref> assessed the prevalence of open access in different databases. When they looked specifically at biomedicine, using data from the Web of Science, and using the same open/closed distinction as the current study, they found a little over 30% to be open. This difference could be due to various recent Dutch policies for open access. Dutch universities and UMC federations have sealed various deals with publishers (<ext-link ext-link-type="uri" xlink:href="https://www.openaccess.nl/en/in-the-netherlands/publisher-deals">https://www.openaccess.nl/en/in-the-netherlands/publisher-deals</ext-link>), plus the Dutch Research Council requires all their funded research to be published open access (<ext-link ext-link-type="uri" xlink:href="https://www.nwo.nl/en/open-access-publishing">https://www.nwo.nl/en/open-access-publishing</ext-link>).</p><p>Open access comes in different forms and publishing in open-access journals is often not for free (<xref ref-type="bibr" rid="bib36">Ross-Hellauer, 2022</xref>). Some publishers make exceptions for scientists from low and middle-income countries, but the Netherlands would not classify. It could thus be that the amount of funding that a supervisor or Ph.D. candidate had available affected the relationship we studied. In other words: funding availability may determine whether Ph.D. candidates (or supervisors) chose to publish in an open access journal. However, it should be noted that green open access, archiving a paper in an appropriate format in an (institutional) repository, can be done free of financial charge.</p></sec><sec id="s3-2"><title>The role of early career researchers (ECRs)</title><p>A variety of grassroots initiatives that aim to promote open science practices are spearheaded by ECRs (many of them in the process of obtaining a Ph.D.). Popular examples in the Netherlands include ReproducbiliTea (<ext-link ext-link-type="uri" xlink:href="https://reproducibilitea.org">https://reproducibilitea.org</ext-link>) as well as the Open Science Communities (<ext-link ext-link-type="uri" xlink:href="https://www.osc-nl.com">https://www.osc-nl.com</ext-link>).</p><p>In addition, many education and training activities to promote open science and responsible research practices target master and Ph.D. candidates. Assuming this group then has more opportunities to learn about open and responsible research, it begs the question of who teaches who. On this note, Pizzolato and Dierickx propose it might be useful to have Ph.D. candidates mentor their supervisors when it comes to matters of research integrity (<xref ref-type="bibr" rid="bib27">Pizzolato and Dierickx, 2022</xref>).</p><p>Our findings do not allow for causal inferences, yet we believe they don’t need to conflict with ECRs and Ph.D. candidates’ knowledge about and engagement in open science practices. Even when one has knowledge about open science practices when starting a Ph.D. trajectory or engages in a ReproducibiliTea reading group during a Ph.D., it may still help to have a supervisor who role models these practices. Considering the associations that we identified, we speculate that working under supervisors who engage in open science themselves could empower Ph.D. candidates to engage in open science more readily. Or at the very least, the supervisor is then less likely to hamper the Ph.D. candidate’s engagement in these practices. The other side of the coin, supervisors’ lack of engagement in open science practices, still seems more normal, although a recent Dutch survey found Ph.D. candidates to score lower compared to senior researchers on sharing data (<xref ref-type="bibr" rid="bib14">Gopalakrishna et al., 2022a</xref>). Finally, it could be that the relationship investigated here is bidirectional.</p></sec><sec id="s3-3"><title>Limitations</title><p>This study included many publications by the supervisors, but not all. The number of included first or last author publications for the open science practices varies between 3 and 11; we always included more publications by the supervisor than by the Ph.D. candidate. This meant that at times, we had to exclude pairs because the supervisor did not have a sufficient number of publications, meaning we may have a small bias towards productive supervisors. In addition, we only included publications up until the year that the Ph.D. candidate defended their thesis, meaning that we at times had to exclude the most recent works.</p><p>We only sampled from four out of eight Dutch UMCs; hence our findings may not generalize to all Dutch UMCs, let alone to other countries. That said, we see no prima facie reason to believe that Leiden, Amsterdam - AMC, Groningen, and Maastricht differ substantially from Nijmegen, Utrecht, Rotterdam, and Amsterdam – Vumc, especially given the national data from the Rathenau Institute and the fact that a similar proportion of Open Data statements was returned in a much larger study of biomedical research (<xref ref-type="bibr" rid="bib37">Serghiou et al., 2021</xref>).</p><p>Finally, our study does not allow for drawing causal inferences on who educated who regarding open science practices. This is due to its design, but also because we only extracted publications by Ph.D. candidates that were part of their Ph.D. thesis. Hence, we might have missed publications outside the Ph.D. or prior to the Ph.D. candidate that would have indicated a greater engagement in open science practices. That said, this was beyond the scope of our study that aimed at looking at the effect of a supervisor engaging in open science practices.</p></sec><sec id="s3-4"><title>Conclusion</title><p>We investigated whether having a supervisor that shared data openly and published open access, resulted in a greater odds of the Ph.D. candidate sharing their data and publishing open access. Based on our sample of 211 pairs of biomedical Ph.D. candidates and supervisors, we find the odds of a Ph.D. candidate sharing data to be greater when working under a supervisor who shared data themselves. The effect of open access was smaller and vanished when correcting for institutions, which might be explained by a greater uptake of open access across the Dutch ecosystem. Our design highlights a new way of investigating role modeling in the context of Open Science and other responsible research practices.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Materials availability statement</title><p>Data were collected using a pilot-tested protocol that is freely accessible on <ext-link ext-link-type="uri" xlink:href="https://osf.io/4fzx8">OSF</ext-link>, we provide a brief overview of our data collection procedures and materials below.</p></sec><sec id="s4-2"><title>Ethical aspects</title><p>This study used publicly available information (publications) as its data and hence no ethical approval was required. The study was preregistered on the OSF, see: 10.17605/OSF.IO/2PBNS.</p></sec><sec id="s4-3"><title>Population</title><p>Our population consisted of pairs of Ph.D. candidates and their main supervisors (in the Netherlands, the primary supervisor has to be a full professor, although recently associate professors can get these rights, too). They had to be affiliated with a Dutch University Medical Center (henceforth: UMC) and had to work in biomedicine (understood as their publications being indexed in PubMed).</p><p>The Netherlands has eight UMCs, four of those maintained Ph.D. thesis repositories that allowed for the reliable extraction of data (based on a pilot study, see <ext-link ext-link-type="uri" xlink:href="https://osf.io/4fzx8">here</ext-link>). These were Leiden UMC, Amsterdam UMC (location AMC), Maastricht UMC, and UMC Groningen, respectively.</p></sec><sec id="s4-4"><title>Sample size</title><p>In the absence of, to our knowledge, previous studies using a similar method to examine supervisor’s role modeling in this or a comparable manner, we conducted a pilot study (n=30). We used the correlations found in the pilot for open access (0.2) as input for the sample size calculation. With an alpha of 0.05 and a power of 0.80, we would need 194 pairs. However, we oversampled as some publications might not meet eligibility criteria after screening the full publication.</p></sec><sec id="s4-5"><title>Sampling time</title><p>We identified pairs and extracted data between April 17<sup>th</sup> and June 30<sup>th</sup>, 2022. We stopped sampling when we passed the required sample size, and wanted to include an equal share of pairs from each of the four university medical centers. This meant we focused on Ph.D. theses that were defended in 2022 or late 2021.</p></sec><sec id="s4-6"><title>Eligibility criteria</title><p>Ph.D. candidates’ publications had to be in English, part of their Ph.D. thesis (other works published during the same time were excluded), regard empirical work (excluding reviews, commentaries, and narratives), published no earlier than 2018 (to make it reasonable they worked with the supervisor we identified), where the Ph.D. candidate was the sole first author. We only included Ph.D. candidates if they had at least two publications that met these criteria.</p><p>Supervisors’ publications had to be in English, had to regard empirical work, and be published no earlier than 2017 where the supervisor was the sole first or last author. We only included supervisors if they had at least three publications that met these criteria. Each supervisor only appears once in our dataset to prevent additional clustering and the Ph.D. candidates could not be co-authors on included publications.</p></sec><sec id="s4-7"><title>Data extracted</title><p>If both the Ph.D. candidate and the supervisor met the eligibility criteria, we extracted the DOIs of the relevant publications, the names of the pairs, the institute they worked at the time of the Ph.D. defense, and the year of the thesis defense. For the supervisor, we also extracted the authorship position.</p></sec><sec id="s4-8"><title>Data preparation</title><p>To assess the open access status, we used the Unpaywall API through the <ext-link ext-link-type="uri" xlink:href="https://github.com/NicoRiedel/unpaywallR">UnpaywallR</ext-link> package (<xref ref-type="bibr" rid="bib30">Ridel and Franzen, 2022</xref>). The UnpaywallR package takes the DOI and returns the different forms in which a publication is available. We applied the following hierarchy: Gold, Green, Hybrid, Bronze, and Paywalled, following the interpretations of the different forms as described by <xref ref-type="bibr" rid="bib29">Priem, 2021</xref>. We recoded this into a binary variable where Gold, Green, and Hybrid were considered open, and Bronze and paywalled were considered closed.</p><p>To identify papers with open data, we used Oddpub followed by a manual review of extracted statements. First, we downloaded the PDFs from the extracted DOIs, we could not access 11 publications – this did not result in excluding pairs. Next, we transformed the PDFs into raw text and applied Oddpub (<xref ref-type="bibr" rid="bib31">Riedel et al., 2020</xref>). Oddpub is a text-mining algorithm that is designed to pick up data-sharing statements in biomedical research papers (<xref ref-type="bibr" rid="bib31">Riedel et al., 2020</xref>) RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_018385">SCR_018385</ext-link>; Version 6. Publications where Oddpub returned a statement were assigned a one and publications where Oddpub did not return a statement were assigned a zero. We refer to this as open data automated.</p><p>To assure that the publications where Oddpub returned a statement genuinely had open data, two extractors manually reviewed all statements using a piloted protocol (<xref ref-type="bibr" rid="bib20">Iarkaeva, 2022</xref>). If there were any discrepancies between extractions, a third extractor or a research data management expert was consulted, and discrepancies were solved through discussion. This resulted in another binary variable where all publications from the list that Oddpub picked up on that had open data were assigned a one and all other publications (i.e. publications where Oddpub initially returned a statement but that were on closer inspection no instances of open data plus all publications where Oddpub returned no statement) were assigned a zero. We refer to this as manually verified open data.</p></sec><sec id="s4-9"><title>Data analysis</title><p>First, we calculated the prevalence and correlations between a supervisors’ engagement in a practice and Ph.D. candidates’ engagement in a practice. Next, we used Generalized Equations Estimations (GEE) logistic regression to analyze the data, because our dataset is clustered. We transformed the dataset to the level of the Ph.D. candidate where publications (by the candidate) cluster within the candidate. We recoded supervisors’ engagement in open access publishing and data sharing into dichotomous covariates so they could be added to the GEE logistic regression model.</p><p>When the percentage of publications from the supervisor that was openly available was above the national average (76%, see <xref ref-type="bibr" rid="bib23">Koens and Vennekens, 2022</xref>), we gave them a 1. If the percentage was 76% or lower, we assigned this supervisor a 0.</p><p>We recoded the supervisors’ sharing of data into never (no included publications with open data) and ever (one or more included publications with open data) and applied the same categorization to automated statements and manually checked statements. We then exponentially transformed the model’s ß coefficients and present Odds ratios. We conducted a crude and adjusted analysis of our odds ratios, where the adjusted models include a dummy coded institute variable to control for a potential confounding bias. In order to determine if the institute was a confounding factor, we compared the measure of association (odds ratios) before and after adjustment. The 10% rule for confounding was applied (<xref ref-type="bibr" rid="bib6">Beukelman and Brunner, 2016</xref>; <xref ref-type="bibr" rid="bib9">Budtz-Jørgensen et al., 2007</xref>).</p></sec><sec id="s4-10"><title>Additional retraction analyses</title><p>A potential concern with our way of studying supervisors’ role modeling regards missing potential irresponsible behaviors. To accommodate this concern, we used the author-disambiguation algorithm developed by <xref ref-type="bibr" rid="bib11">Caron and van Eck, 2014</xref> to obtain meta-data on all publications from supervisors and Ph.D. candidates that were available in the in-house version of Web of Science database at CWTS, Leiden University, the Netherlands, and screened these for retractions. Note that a retraction need not indicate actual irresponsible behavior, it may regard honest mistakes. Where possible, we provide the reason for the retraction as specified by the respective journal.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Supervision, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Investigation, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-83484-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data are available alongside the code to produce it on the associated <ext-link ext-link-type="uri" xlink:href="https://github.com/tamarinde/ResponsibleSupervision">GitHub repository</ext-link> (copy archived at <xref ref-type="bibr" rid="bib18">Haven et al., 2023</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to acknowledge Martin Holst for his support during the pilot study to assess the feasibility of the approach. Benjamin Gregory Carlisle’s support of data science-related issues was crucial. Delwen Franzen helpfully adapted the UnpaywallR script for our project, and Nico Riedel revised the Oddpub script to work on our dataset. Evgeny Bobrov and Anastasiia Iarkaeva instructed us on how to use their protocol and provided the much-needed guidance when assessing challenging cases. Thanks also to Evgeny for pointing out that data sharing may not be equal across all biomedical fields. We also extend our gratitude to Jesper Wiborg Schneider who kindly helped with the retraction analyses and obtaining relevant author publications using the in-house version of the Web of Science database at CWTS, Leiden University, the Netherlands.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="web"><person-group person-group-type="author"><collab>All European Academies</collab></person-group><year iso-8601-date="2017">2017</year><article-title>The European Code of Conduct for Research Integrity</article-title><ext-link ext-link-type="uri" xlink:href="https://www.allea.org/wp-content/uploads/2017/05/ALLEA-European-Code-of-Conduct-for-Research-353">https://www.allea.org/wp-content/uploads/2017/05/ALLEA-European-Code-of-Conduct-for-Research-353</ext-link><date-in-citation iso-8601-date="2022-05-10">May 10, 2022</date-in-citation></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>MS</given-names></name><name><surname>Horn</surname><given-names>AS</given-names></name><name><surname>Risbey</surname><given-names>KR</given-names></name><name><surname>Ronning</surname><given-names>EA</given-names></name><name><surname>De Vries</surname><given-names>R</given-names></name><name><surname>Martinson</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>What do mentoring and training in the responsible conduct of research have to do with scientists’ misbehavior? findings from a national survey of NIH-funded scientists</article-title><source>Academic Medicine</source><volume>82</volume><fpage>853</fpage><lpage>860</lpage><pub-id pub-id-type="doi">10.1097/ACM.0b013e31812f764c</pub-id><pub-id pub-id-type="pmid">17726390</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antes</surname><given-names>AL</given-names></name><name><surname>DuBois</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cultivating the human dimension in research</article-title><source>Molecular Cell</source><volume>72</volume><fpage>207</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.molcel.2018.09.015</pub-id><pub-id pub-id-type="pmid">30340021</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antes</surname><given-names>AL</given-names></name><name><surname>Kuykendall</surname><given-names>A</given-names></name><name><surname>DuBois</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>Leading for research excellence and integrity: a qualitative investigation of the relationship-building practices of exemplary principal Investigators</article-title><source>Accountability in Research</source><volume>26</volume><fpage>198</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1080/08989621.2019.1611429</pub-id><pub-id pub-id-type="pmid">31033345</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antes</surname><given-names>AL</given-names></name><name><surname>Kuykendall</surname><given-names>A</given-names></name><name><surname>DuBois</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>The lab management practices of `` research exemplars’’ that foster research rigor and regulatory compliance: a qualitative study of successful principal Investigators</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0214595</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0214595</pub-id><pub-id pub-id-type="pmid">31017929</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Beukelman</surname><given-names>T</given-names></name><name><surname>Brunner</surname><given-names>HI</given-names></name></person-group><year iso-8601-date="2016">2016</year><chapter-title>Chapter 6-trial design, measurement, and analysis of clinical investigations</chapter-title><person-group person-group-type="editor"><name><surname>Beukelman</surname><given-names>T</given-names></name></person-group><source>Textbook of Pediatric Rheumatology</source><publisher-name>Elsevier</publisher-name><fpage>54</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/B978-0-323-24145-8.00006-5</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bird</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Mentors, advisors and supervisors: their role in teaching responsible research conduct</article-title><source>Science and Engineering Ethics</source><volume>7</volume><fpage>455</fpage><lpage>468</lpage><pub-id pub-id-type="doi">10.1007/s11948-001-0002-1</pub-id><pub-id pub-id-type="pmid">11697001</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouter</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>What research institutions can do to foster research integrity</article-title><source>Science and Engineering Ethics</source><volume>26</volume><fpage>2363</fpage><lpage>2369</lpage><pub-id pub-id-type="doi">10.1007/s11948-020-00178-5</pub-id><pub-id pub-id-type="pmid">31965429</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Budtz-Jørgensen</surname><given-names>E</given-names></name><name><surname>Keiding</surname><given-names>N</given-names></name><name><surname>Grandjean</surname><given-names>P</given-names></name><name><surname>Weihe</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Confounder selection in environmental epidemiology: assessment of health effects of prenatal mercury exposure</article-title><source>Annals of Epidemiology</source><volume>17</volume><fpage>27</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/j.annepidem.2006.05.007</pub-id><pub-id pub-id-type="pmid">17027287</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buljan</surname><given-names>I</given-names></name><name><surname>Barać</surname><given-names>L</given-names></name><name><surname>Marušić</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How researchers perceive research misconduct in biomedicine and how they would prevent it: a qualitative study in a small scientific community</article-title><source>Accountability in Research</source><volume>25</volume><fpage>220</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1080/08989621.2018.1463162</pub-id><pub-id pub-id-type="pmid">29637796</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Caron</surname><given-names>E</given-names></name><name><surname>van Eck</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Large scale author name disambiguation using rule-based scoring and clustering</article-title><conf-name>Proceedings of the Science and Technology Indicators Conference 2014</conf-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>MS</given-names></name><name><surname>Riske-Morris</surname><given-names>M</given-names></name><name><surname>Diaz</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Causal factors implicated in research misconduct: evidence from ori case files</article-title><source>Science and Engineering Ethics</source><volume>13</volume><fpage>395</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1007/s11948-007-9045-2</pub-id><pub-id pub-id-type="pmid">18038194</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>CB</given-names></name><name><surname>Fried</surname><given-names>AL</given-names></name><name><surname>Feldman</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Graduate socialization in the responsible conduct of research: a national survey on the research ethics training experiences of psychology doctoral students</article-title><source>Ethics &amp; Behavior</source><volume>19</volume><fpage>496</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1080/10508420903275283</pub-id><pub-id pub-id-type="pmid">23641128</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gopalakrishna</surname><given-names>G</given-names></name><name><surname>Ter Riet</surname><given-names>G</given-names></name><name><surname>Vink</surname><given-names>G</given-names></name><name><surname>Stoop</surname><given-names>I</given-names></name><name><surname>Wicherts</surname><given-names>JM</given-names></name><name><surname>Bouter</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2022">2022a</year><article-title>Prevalence of questionable research practices, research misconduct and their potential explanatory factors: a survey among academic researchers in the Netherlands</article-title><source>PLOS ONE</source><volume>17</volume><elocation-id>e0263023</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0263023</pub-id><pub-id pub-id-type="pmid">35171921</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gopalakrishna</surname><given-names>G</given-names></name><name><surname>Wicherts</surname><given-names>JM</given-names></name><name><surname>Vink</surname><given-names>G</given-names></name><name><surname>Stoop</surname><given-names>I</given-names></name><name><surname>van den Akker</surname><given-names>OR</given-names></name><name><surname>Ter Riet</surname><given-names>G</given-names></name><name><surname>Bouter</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2022">2022b</year><article-title>Prevalence of responsible research practices among academics in the Netherlands</article-title><source>F1000Research</source><volume>11</volume><elocation-id>471</elocation-id><pub-id pub-id-type="doi">10.12688/f1000research.110664.2</pub-id><pub-id pub-id-type="pmid">36128558</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halbesleben</surname><given-names>JRB</given-names></name><name><surname>Rathert</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The role of continuous quality improvement and psychological safety in predicting work-arounds</article-title><source>Health Care Management Review</source><volume>33</volume><fpage>134</fpage><lpage>144</lpage><pub-id pub-id-type="doi">10.1097/01.HMR.0000304505.04932.62</pub-id><pub-id pub-id-type="pmid">18360164</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haven</surname><given-names>T</given-names></name><name><surname>Bouter</surname><given-names>L</given-names></name><name><surname>Mennen</surname><given-names>L</given-names></name><name><surname>Tijdink</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Superb supervision: a pilot study on training supervisors to convey responsible research practices onto their PHD candidates</article-title><source>Accountability in Research</source><volume>1</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1080/08989621.2022.2071153</pub-id><pub-id pub-id-type="pmid">35475492</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Haven</surname><given-names>TL</given-names></name><name><surname>Hildebrand</surname><given-names>N</given-names></name><name><surname>Franzen</surname><given-names>D</given-names></name><name><surname>Abunijela</surname><given-names>S</given-names></name><name><surname>Carlisle</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>ResponsibleSupervision</data-title><version designator="swh:1:rev:04eac91557e5babad4839d912235c5b64e45ba5c">swh:1:rev:04eac91557e5babad4839d912235c5b64e45ba5c</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:c56a1d9a1d37ace6f177ac0dbfb775c84cec670a;origin=https://github.com/tamarinde/ResponsibleSupervision;visit=swh:1:snp:b8391149515c34f07ec687fa323e8aec593d8c66;anchor=swh:1:rev:04eac91557e5babad4839d912235c5b64e45ba5c">https://archive.softwareheritage.org/swh:1:dir:c56a1d9a1d37ace6f177ac0dbfb775c84cec670a;origin=https://github.com/tamarinde/ResponsibleSupervision;visit=swh:1:snp:b8391149515c34f07ec687fa323e8aec593d8c66;anchor=swh:1:rev:04eac91557e5babad4839d912235c5b64e45ba5c</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname><given-names>BT</given-names></name><name><surname>Niemann</surname><given-names>A</given-names></name><name><surname>Tritz</surname><given-names>D</given-names></name><name><surname>Boyer</surname><given-names>K</given-names></name><name><surname>Robbins</surname><given-names>H</given-names></name><name><surname>Vassar</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Transparent and reproducible research practices in the surgical literature</article-title><source>The Journal of Surgical Research</source><volume>274</volume><fpage>116</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.jss.2021.09.024</pub-id><pub-id pub-id-type="pmid">35150944</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Iarkaeva</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Semi-Automated extraction of information on open datasets mentioned in articles V1</data-title><version designator="V1">V1</version><source>Protocols.Io</source><ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.17504/protocols.io.q26g74p39gwz/v1">https://dx.doi.org/10.17504/protocols.io.q26g74p39gwz/v1</ext-link></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iqbal</surname><given-names>SA</given-names></name><name><surname>Wallach</surname><given-names>JD</given-names></name><name><surname>Khoury</surname><given-names>MJ</given-names></name><name><surname>Schully</surname><given-names>SD</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reproducible research practices and transparency across the biomedical literature</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002333</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002333</pub-id><pub-id pub-id-type="pmid">26726926</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahan</surname><given-names>BC</given-names></name><name><surname>Jairath</surname><given-names>V</given-names></name><name><surname>Doré</surname><given-names>CJ</given-names></name><name><surname>Morris</surname><given-names>TP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The risks and rewards of covariate adjustment in randomized trials: an assessment of 12 outcomes from 8 studies</article-title><source>Trials</source><volume>15</volume><elocation-id>139</elocation-id><pub-id pub-id-type="doi">10.1186/1745-6215-15-139</pub-id><pub-id pub-id-type="pmid">24755011</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Koens</surname><given-names>L</given-names></name><name><surname>Vennekens</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Fact sheet: open access of research publications</article-title><ext-link ext-link-type="uri" xlink:href="https://www.rathenau.nl/en/science-figures/output/publications/open-access-research-publications">https://www.rathenau.nl/en/science-figures/output/publications/open-access-research-publications</ext-link><date-in-citation iso-8601-date="2022-12-23">December 23, 2022</date-in-citation></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mansmann</surname><given-names>U</given-names></name><name><surname>Locher</surname><given-names>C</given-names></name><name><surname>Prasser</surname><given-names>F</given-names></name><name><surname>Weissgerber</surname><given-names>T</given-names></name><name><surname>Sax</surname><given-names>U</given-names></name><name><surname>Posch</surname><given-names>M</given-names></name><name><surname>Decullier</surname><given-names>E</given-names></name><name><surname>Cristea</surname><given-names>IA</given-names></name><name><surname>Debray</surname><given-names>TPA</given-names></name><name><surname>Held</surname><given-names>L</given-names></name><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name><name><surname>Ross</surname><given-names>JS</given-names></name><name><surname>Ohmann</surname><given-names>C</given-names></name><name><surname>Naudet</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Implementing clinical trial data sharing requires training a new generation of biomedical researchers</article-title><source>Nature Medicine</source><volume>29</volume><fpage>298</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.1038/s41591-022-02080-y</pub-id><pub-id pub-id-type="pmid">36732626</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moher</surname><given-names>D</given-names></name><name><surname>Naudet</surname><given-names>F</given-names></name><name><surname>Cristea</surname><given-names>IA</given-names></name><name><surname>Miedema</surname><given-names>F</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name><name><surname>Goodman</surname><given-names>SN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Assessing scientists for hiring, promotion, and tenure</article-title><source>PLOS Biology</source><volume>16</volume><elocation-id>e2004089</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2004089</pub-id><pub-id pub-id-type="pmid">29596415</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piwowar</surname><given-names>H</given-names></name><name><surname>Priem</surname><given-names>J</given-names></name><name><surname>Larivière</surname><given-names>V</given-names></name><name><surname>Alperin</surname><given-names>JP</given-names></name><name><surname>Matthias</surname><given-names>L</given-names></name><name><surname>Norlander</surname><given-names>B</given-names></name><name><surname>Farley</surname><given-names>A</given-names></name><name><surname>West</surname><given-names>J</given-names></name><name><surname>Haustein</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The state of oa: a large-scale analysis of the prevalence and impact of open access articles</article-title><source>PeerJ</source><volume>6</volume><elocation-id>e4375</elocation-id><pub-id pub-id-type="doi">10.7717/peerj.4375</pub-id><pub-id pub-id-type="pmid">29456894</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pizzolato</surname><given-names>D</given-names></name><name><surname>Dierickx</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Reverse mentoring to enhance research integrity climate</article-title><source>BMC Research Notes</source><volume>15</volume><elocation-id>209</elocation-id><pub-id pub-id-type="doi">10.1186/s13104-022-06098-w</pub-id><pub-id pub-id-type="pmid">35715865</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pizzolato</surname><given-names>D</given-names></name><name><surname>Dierickx</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The mentor's role in fostering research integrity standards among new generations of researchers: A review of empirical studies</article-title><source>Science and Engineering Ethics</source><volume>29</volume><elocation-id>19</elocation-id><pub-id pub-id-type="doi">10.1007/s11948-023-00439-z</pub-id><pub-id pub-id-type="pmid">37160826</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Priem</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>What do the types of oa_status (green, gold, hybrid, and bronze) mean?</article-title><ext-link ext-link-type="uri" xlink:href="https://support.unpaywall.org/support/solutions/articles/44001777288-what-do-the-types-of-oa-status-green-gold-hybrid-and-bronze-mean">https://support.unpaywall.org/support/solutions/articles/44001777288-what-do-the-types-of-oa-status-green-gold-hybrid-and-bronze-mean</ext-link><date-in-citation iso-8601-date="2022-11-10">November 10, 2022</date-in-citation></element-citation></ref><ref id="bib30"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Ridel</surname><given-names>N</given-names></name><name><surname>Franzen</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>UnpaywallR (R)</data-title><version designator="0.1.0">0.1.0</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/NicoRiedel/unpaywallR">https://github.com/NicoRiedel/unpaywallR</ext-link></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riedel</surname><given-names>N</given-names></name><name><surname>Kip</surname><given-names>M</given-names></name><name><surname>Bobrov</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>ODDPub – a text-mining algorithm to detect data sharing in biomedical publications</article-title><source>Data Science Journal</source><volume>19</volume><elocation-id>42</elocation-id><pub-id pub-id-type="doi">10.5334/dsj-2020-042</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberto</surname><given-names>MA</given-names></name><name><surname>Bohmer</surname><given-names>RMJ</given-names></name><name><surname>Edmondson</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Facing ambiguous threats</article-title><source>Harvard Business Review</source><volume>84</volume><fpage>106</fpage><lpage>113</lpage><pub-id pub-id-type="pmid">17131567</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson-Garcia</surname><given-names>N</given-names></name><name><surname>Costas</surname><given-names>R</given-names></name><name><surname>van Leeuwen</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Open access uptake by universities worldwide</article-title><source>PeerJ</source><volume>8</volume><elocation-id>e9410</elocation-id><pub-id pub-id-type="doi">10.7717/peerj.9410</pub-id><pub-id pub-id-type="pmid">32714658</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roche</surname><given-names>DG</given-names></name><name><surname>Berberi</surname><given-names>I</given-names></name><name><surname>Dhane</surname><given-names>F</given-names></name><name><surname>Lauzon</surname><given-names>F</given-names></name><name><surname>Soeharjono</surname><given-names>S</given-names></name><name><surname>Dakin</surname><given-names>R</given-names></name><name><surname>Binning</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2022">2022a</year><article-title>Slow improvement to the archiving quality of open datasets shared by researchers in ecology and evolution</article-title><source>Proceedings of the Royal Society B</source><volume>289</volume><elocation-id>20212780</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2021.2780</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roche</surname><given-names>DG</given-names></name><name><surname>Raby</surname><given-names>GD</given-names></name><name><surname>Norin</surname><given-names>T</given-names></name><name><surname>Ern</surname><given-names>R</given-names></name><name><surname>Scheuffele</surname><given-names>H</given-names></name><name><surname>Skeeles</surname><given-names>M</given-names></name><name><surname>Morgan</surname><given-names>R</given-names></name><name><surname>Andreassen</surname><given-names>AH</given-names></name><name><surname>Clements</surname><given-names>JC</given-names></name><name><surname>Louissaint</surname><given-names>S</given-names></name><name><surname>Jutfelt</surname><given-names>F</given-names></name><name><surname>Clark</surname><given-names>TD</given-names></name><name><surname>Binning</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2022">2022b</year><article-title>Paths towards greater consensus building in experimental biology</article-title><source>The Journal of Experimental Biology</source><volume>225</volume><elocation-id>jeb243559</elocation-id><pub-id pub-id-type="doi">10.1242/jeb.243559</pub-id><pub-id pub-id-type="pmid">35258604</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross-Hellauer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Open science, done wrong, will compound inequities</article-title><source>Nature</source><volume>603</volume><elocation-id>363</elocation-id><pub-id pub-id-type="doi">10.1038/d41586-022-00724-0</pub-id><pub-id pub-id-type="pmid">35288691</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Serghiou</surname><given-names>S</given-names></name><name><surname>Contopoulos-Ioannidis</surname><given-names>DG</given-names></name><name><surname>Boyack</surname><given-names>KW</given-names></name><name><surname>Riedel</surname><given-names>N</given-names></name><name><surname>Wallach</surname><given-names>JD</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Assessment of transparency indicators across the biomedical literature: how open is open?</article-title><source>PLOS Biology</source><volume>19</volume><elocation-id>e3001107</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3001107</pub-id><pub-id pub-id-type="pmid">33647013</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steneck</surname><given-names>NH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Fostering integrity in research: definitions, current knowledge, and future directions</article-title><source>Science and Engineering Ethics</source><volume>12</volume><fpage>53</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1007/pl00022268</pub-id><pub-id pub-id-type="pmid">16501647</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Susanin</surname><given-names>A</given-names></name><name><surname>Boyar</surname><given-names>A</given-names></name><name><surname>Costello</surname><given-names>K</given-names></name><name><surname>Fraiman</surname><given-names>A</given-names></name><name><surname>Misrok</surname><given-names>A</given-names></name><name><surname>Sears</surname><given-names>M</given-names></name><name><surname>Hildebrandt</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Rigor and reproducibility for data analysis and design in the study of eating disorders</article-title><source>The International Journal of Eating Disorders</source><volume>55</volume><fpage>1267</fpage><lpage>1278</lpage><pub-id pub-id-type="doi">10.1002/eat.23774</pub-id><pub-id pub-id-type="pmid">35852964</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="web"><person-group person-group-type="author"><collab>Universities of The Netherlands</collab></person-group><year iso-8601-date="2018">2018</year><article-title>Netherlands Code of Conduct for Research Integrity</article-title><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17026/dans-2cj-nvwu">https://doi.org/10.17026/dans-2cj-nvwu</ext-link><date-in-citation iso-8601-date="2022-06-10">June 10, 2022</date-in-citation></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallach</surname><given-names>JD</given-names></name><name><surname>Boyack</surname><given-names>KW</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Reproducible research practices, transparency, and open access data in the biomedical literature, 2015-2017</article-title><source>PLOS Biology</source><volume>16</volume><elocation-id>e2006930</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2006930</pub-id><pub-id pub-id-type="pmid">30457984</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.83484.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Allison</surname><given-names>David B</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kg8sb98</institution-id><institution>Indiana University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>This paper will be of interest to scientists who are interested in open-access publishing and open data-sharing procedures. The authors examine associations between PhD candidates' use of open access and open data procedures and use by their supervisors. At present, the study provides solid, useful information suggesting that candidates whose supervisors engage in open-access publishing and open data sharing are more likely to do so, but it does not establish causality or directionality.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.83484.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Allison</surname><given-names>David B</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kg8sb98</institution-id><institution>Indiana University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Schwiebert</surname><given-names>Lisa</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/008s83205</institution-id><institution>University of Alabama at Birmingham</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Agley</surname><given-names>Jon</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02k40bc56</institution-id><institution>Indiana University Bloomington</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Meta-Research: Biomedical supervisors' role modeling of responsible research practices&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Mone Zaidi as the Senior Editor. The following individuals involved in the review of your submission have agreed to reveal their identity: Lisa Schwiebert (Reviewer #1); Jon Agley (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>The investigators are encouraged to widen the years of their analyses so as to include the number and incidence of retracted papers by respective supervisor and PhD supervisee pairs.</p><p>Please also address Reviewer 2's recommendations for the authors.</p><p><italic>Reviewer #1:</italic></p><p>The purpose of the current study is to address a gap in knowledge regarding the assessment of responsible supervision of PhD supervisees in the field of biomedical research. Specifically, the investigators theorize that a supervisor's role modeling of responsible research practices in the context of data sharing will likely result in the PhD supervisees engaging in the same responsible practice as compared with supervisors who did not data share. Through careful analyses of Open Access publishing and Open Data sharing platforms, the investigators found that the odds of a PhD supervisee sharing data were greater working with a supervisor who shared data themselves versus those who did not.</p><p>The strengths of this study are several and they include an innovative approach toward a complex concern; strong statistical analyses; well-described limitations of the study. Overall, this is an interesting report, while not wholly surprising, it does add value with its evidenced-based approach toward the assessment of responsible research practices.</p><p>Of note, the conclusion assumes that shared data themselves are accurate, rigorous, and reproducible, which may not be wholly representative of the desired responsible practices.</p><p>The investigators are encouraged to widen the years of their analyses so as to include the number and incidence of retracted papers by respective supervisor and PhD supervisee pairs.</p><p><italic>Reviewer #2:</italic></p><p>The authors sought to undertake an examination of open-access publishing and open data sharing among PhD students and their supervisors as part of an expressed interest in responsible research practices (RRPs). The study was preregistered (including hypotheses, procedures, and outcomes), contained a step-by-step guide with screenshots for replicating their protocol, and shared all data and code.</p><p>The study results are fairly clearly explained, though I have some specific comments and questions that I provide to the authors privately. The research question itself is interesting and the procedures used to identify and match open access publication and data availability both use and advance novel procedures for doing so. I do have some questions about possible mediating and moderating factors that may be important to discuss, as well as the possible importance of separating open publication and data accessibility from the highly related, but not identical, concept of RRP. In most cases, the resolution of these questions would not change the core findings of the manuscript but would simply serve to advance clarity and discussion. As with all papers using associative analyses, readers are cautioned to avoid causal interpretations – a caveat that is also addressed by the paper itself.</p><p>Abstract</p><p>Although I have a few questions about some of the analyses, if indeed it is the case that the open access odds were lower, since your manuscript has 4 primary findings, consider sharing all 4 in the abstract.</p><p>Introduction</p><p>Paragraph 1: The first sentence appears to imply that supervision generally results in socialization into responsible research practices. This may benefit from being expanded somewhat for clarity. For example, the first paper (Bird, 2001) discusses how role modeling and mentorship differ in key ways, and the second paper (Anderson et al., 2007) explicitly notes that certain kinds of mentorship/supervision were associated with higher rates of problematic practices for early career researchers. Would it be more apt to state something like, &quot;When conducted in a manner that clearly emphasizes rigorous, reproducible, and transparent research practices, it is plausible that supervision…&quot;</p><p>Paragraph 1: The sentence focused on examples of RRPs cites articles that address RRPs to a degree, but some (e.g., Gopalakrishna et al., 2022) primarily focus on questionable research practices, not necessarily why RRPs might mitigate some of those concerns. I encourage the identification of additional references on RRP to be included here.</p><p>Paragraph 2: Although scientific writing conventions vary, my own preference would be for your description to be in the personal possessive here (e.g., &quot;…a pilot study conducted by the first author identified three components.&quot;). I think it is important for the reader to understand the origin of these ideas and that you are building on your own prior work.</p><p>Paragraph 2: In the final sentence, consider also adding a point raised by the cited work around the importance of being able to safely scrutinize each others' work.</p><p>Materials and methods</p><p>Materials Availability: I appreciated the excellent use of screenshots to guide readers through the procedures used (as documented on OSF).</p><p>Population: I encourage including some of the population information from your preregistration here as well. For example, readers may not intuit that full professorship is the normative rank for candidate supervision in Dutch universities and might mistakenly assume some sort of selection bias (e.g., if associate professors were more commonly supervisors but you identified mostly full professors…).</p><p>Sampling Time: It is unclear why the data extraction timeframe resulted in the specific range of PhD thesis defense times. You explore some of this in your preregistration, but additional details would be useful here (even if it's just to indicate that normative delays reflected X – this also addresses why you planned to but did not include German universities, in part).</p><p>Eligibility Criteria: Can you clarify whether &quot;latest 2018&quot; means &quot;no earlier than 2018&quot;? I suspect this is a linguistic difference but I want to be sure. In addition, can you explain why you included PhD candidates if they only had at least 2 publications? Is it possible that this inclusion criterion systematically excluded candidates or supervisors with specific characteristics?</p><p>Data Preparation: I recommend referencing the Unpaywall FAQ here for data definitions (can be cited as a resource since the FAQ was prepared by Jason Priem; https://support.unpaywall.org/support/solutions/articles/44001777288-what-do-the-types-of-oa-status-green-gold-hybrid-and-bronze-mean-). The advantage is that, as the FAQ notes, there is no formal classification schema that exists. I would not have known that &quot;Green&quot; OA includes institutional repositories because some journals use that term similarly to how this FAQ uses &quot;Hybrid.&quot;</p><p>Data Analysis: I am not a statistician, but I wonder (perhaps naively) whether 'university' should have been included in the model as a clustering term, especially since some of the earlier literature cited indicates that the environment (beyond the mentor and lab) can contribute to RRP.</p><p>Discussion</p><p>The first paragraph of the Discussion contains information that I would ordinarily associate with Results. That aside, can you clarify the interpretation of the open-access information? If these are presented as exp(b) values, then would a.18 would indicate that PhD candidates published open access less often when their supervisors did than when they did not?</p><p>Contextualization: Since there is a substantial cost associated with publishing in many open-access venues, might an important contributor to variance (that might affect this model but is not included in the model) be the funding amount of the supervisor? For example, some supervisors may have limited ability to publish open access where a cost is incurred, some may be able to publish their own work (or at least some of their own work) open access, but fewer likely can afford to support their candidates in publishing at cost. If there is indeed a weaker relationship between supervisor publishing and candidate publishing than between data availability, then could this be a mediating or moderating factor?</p><p>The role of ECRs: I'm not sure that we should assume that ECRs have more opportunities to learn about responsible research, in general, though they may have more exposure to open research principles. This paper primarily focuses on open data and open publication. While these are important components of reproducibility and transparency, and while they may aid in the identification of problematic findings and work, they do not subsume the entirety of RRPs. Some components of RRP are longstanding or axiomatic ethical determinations or orientations, whereas the rise of open access has been relatively recent. So even highly ethical, responsible, and transparent senior researchers may be slow to uptake new publishing approaches.</p><p>The role of ECRs: Since your findings are nondirectional (e.g., correlations), it seems plausible (given the citations you provide) that you may be capturing a bidirectional relationship.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Biomedical supervisors' role modeling of open science practices&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Mone Zaidi (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues to consider and respond to from Reviewer #2:</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>The authors have well responded to the initial review – no further comments or concerns.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I would like to thank the authors for the work put into this revision and the clarifications offered in the response to reviewers. I restate my perception that this work is interesting and provides a solid and useful contribution to the overall scientific enterprise in this area. I have a few questions and comments around the revised work that I hope you find useful.</p><p>Abstract</p><p>Here and elsewhere, you might want to use or provide the specific meaning of &quot;actively published open access&quot; since it's very specific to this article (e.g., published open access more often than the average Dutch professor did in 2021). There are also comments in the Discussion about the odds ratio that apply to the abstract (depending on whether you decide to make those revisions).</p><p>Introduction</p><p>I think that the modifications made to the Introduction section are helpful and address my comments in full.</p><p>Materials and methods</p><p>I am glad that my questions prompted further investigation into the analyses and variable structure. My only remaining comment relates to the new statement, &quot;The 10% rule for confounding was applied.&quot; I think the application here is fine (again – I am not a professional statistician, so caveat emptor) but a citation may be useful. Some readers may be unfamiliar with that rule, and others may have questions about it (see, eg., Lee, 2014 – https://doi.org/10.2188%2Fjea.JE20130062).</p><p>Results</p><p>In the title for Table 1, you might want to specify the unit of analysis (e.g., a unique DOI). While it is clear to me what is meant by the table, a reader who is skimming might assume that there are, for example 548 PhD candidates publishing open access, rather than 548 DOIs from PhD candidates that were published open access.</p><p>If I understand your methods for identifying open data correctly, it may be worth removing the &quot;Open data (automated)&quot; information from the Results entirely. Here is my reasoning: Oddpub was used to extract possible instances of open data statements, but through manual verification, you triaged around half of those instances. Specifically, it seems that those that were excluded by manual verification did not have open data statements as affirmed by two to three human reviewers. Thus, I am not sure what value is added by analyzing the &quot;Open data (automated)&quot; variable, which seems to only describe a subset of papers for which a specific algorithm thought it found open data. We are not concerned with whether things are associated with whether a machine thinks there might be an open data statement, but rather whether things are associated with actual open data access.</p><p>Can you please consider verifying the total number of linked publications (81,091)? Given that the supervisor+candidate total n was around 2,000, that number would imply that the supervisors in this study published an additional 79,000 or so papers before 2017. While that is certainly possible, even if we assume that the 211 recent PhD candidates published an aggregate 10,000 papers (a very generous assumption), it would mean that the 211 supervisors published an average of 327 papers each, which is fairly remarkable. In some ways, this number is less relevant than the 2 retractions, but it does make me wonder.</p><p>Discussion</p><p>If you agree with my point about automated open data statement identification, you can also remove this sentence from the Discussion (&quot;Based on the automated detection of data sharing statements, we found that having a supervisor that shared data is associated with 2.21 times the odds to share data when compared to having a supervisor that did not share data.&quot;)</p><p>I would suggest revising this sentence: &quot;Effects for Open Access were smaller (1.99) and became nonsignificant when correcting for the role of the institution.&quot; Instead, you could indicate that the unadjusted odds ratio was 1.99 (p=.011) and the adjusted odds ratio was 1.64 (p=.079). I think that the shift in odds is interesting even though it falls above the conventional significance threshold.</p><p>You currently write, &quot;This may indicate there being greater acceptance of and support for a particular practice in a research group. In other words: a responsible supervisory climate may empower PhD candidates to engage in open science more readily.&quot; You might want to contextualize this with something like, &quot;In considering the associations that we identified, we speculate that…&quot;</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.83484.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>The investigators are encouraged to widen the years of their analyses so as to include the number and incidence of retracted papers by respective supervisor and PhD supervisee pairs.</p><p>Please also address Reviewer 2's recommendations for the authors.</p></disp-quote><p>Thank you for these valuable suggestions. We have widened the years of analyses to assess retractions (described in more detail below) and incorporated the recommendations by Reviewer 2 to the best of our ability.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>The purpose of the current study is to address a gap in knowledge regarding the assessment of responsible supervision of PhD supervisees in the field of biomedical research. Specifically, the investigators theorize that a supervisor's role modeling of responsible research practices in the context of data sharing will likely result in the PhD supervisees engaging in the same responsible practice as compared with supervisors who did not data share. Through careful analyses of Open Access publishing and Open Data sharing platforms, the investigators found that the odds of a PhD supervisee sharing data were greater working with a supervisor who shared data themselves versus those who did not.</p><p>The strengths of this study are several and they include an innovative approach toward a complex concern; strong statistical analyses; well-described limitations of the study. Overall, this is an interesting report, while not wholly surprising, it does add value with its evidenced-based approach toward the assessment of responsible research practices.</p><p>Of note, the conclusion assumes that shared data themselves are accurate, rigorous, and reproducible, which may not be wholly representative of the desired responsible practices.</p></disp-quote><p>We agree and added this point to the Contextualisation section (part of Discussion) noting open data does not imply ethically, sound and rigorously collected data, see below. We also adapted our terminology and now use Open Science Practices throughout the paper.</p><p>“It should be noted that open data does not imply the data is gathered in a rigorous, ethical, and reproducible manner. It could even be that the data are FAIR but still not useful, because the methods used were not well-suited to answer the research question, or because the data collection was sloppy, or because the data fail to capture crucial differences in the target population. We manually verified whether we could find the data, whether data were actually open, stored on a repository and downloadable.Any assessments about the quality of the data or the quality of archiving (see e.g., Roche et al., 2022) are beyond the scope of this paper.”</p><disp-quote content-type="editor-comment"><p>The investigators are encouraged to widen the years of their analyses so as to include the number and incidence of retracted papers by respective supervisor and PhD supervisee pairs.</p></disp-quote><p>Thank you for this interesting suggestion. We used a modified approach to answer this request. First we collected additional data on the supervisor and supervisee pairs, namely their email addresses and their Open Researcher and Contributor IDs (ORCIDs).</p><p>Second we used our existing data plus the newly acquired information to identify the authors and their papers using the author-disambiguation algorithm developed by Caron &amp; van Eck (2014) in the in-house version of Web of Science database at CWTS, Leiden University, the Netherlands.</p><p>Web of Science data includes a binary variable on retractions. Note that the time window for retractions tends to be rather long (see e.g., https://retractionwatch.com/2017/07/07/retraction-countdown-quickly-journals-pull-papers/). Hence it remains possible that papers we included may be retracted in the future.</p><p>Using this approach, we identified a total of 81091 publications where the researchers in our sample were identified as (co-)authors. We found 2 retracted papers. Both regarded publications where the supervisor appeared as co-author and both regarded honest mistakes where the retraction was issued one year after the initial publication. We include the specifications provided by the journal below:</p><p>Original paper: British Journal of Pharmacology (2002) 136, 1107–1116. Doi:10.1038/sj.bjp.0704814</p><p>Retraction: British Journal of Pharmacology (2003) 138, 531. Doi:10.1038/sj.bjp.0705183</p><p>Retraction notice: The authors have become aware that some of the results presented in this paper are invalid, not reproducible and/or misinterpreted. They consider that the main conclusion of the paper is not valid. They therefore retract this publication.</p><p>Original paper: Molecular &amp; Cellular Proteomics (2018) 17, 2132-2145. Doi: 10.1074/mcp.RA118.000792</p><p>Retraction: Molecular &amp; Cellular Proteomics (2019) 16, 1270. Doi:10.1074/mcp.W119.001571</p><p>Retraction notice: The original version of this article was withdrawn by the authors. An error was discovered in the creation of the protein database file that was used for searching, which led to some incorrect associations between peptides and proteins. A corrected version of the manuscript has been supplied which contains the very similar peptide identifications as the original, but the resulting number of proteins in various categories has now changed, and as a result some of the figures and supplementary files have changed also. The underlying conclusions of this study, however, remain unaltered.</p><p>Corrected version: Shraibman, B., Barnea, E., Kadosh, D. M., Haimovich, Y., Slobodin, G., Rosner, I., López-Larrea, C., Hilf, N., Kuttruff, S., Song, C., Britten, C., Castle, J., Kreiter, S., Frenzel, K., Tatagiba, M., Tabatabai, G., Dietrich, P.-Y., Dutoit, V., Wick, W., Platten, M., Winkler, F., von Deimling, A., Kroep, J., Sahuquillo, J., Martinez-Ricarte, F., Rodon, J., Lassen, U., Ottensmeier, C., van der Burg, S. H., Thor Straten, P., Poulsen, H. S., Ponsati, B., Okada, H., Rammensee, H. G., Sahin, U., Singh, H., and Admon, A. (2019) Identification of tumor antigens among the HLA peptidomes of glioblastoma tumors and plasma. Mol. Cell. Proteomics 18, 1255–1268.</p><p>In case the reviewer would like to see these findings in the paper, we have prepared the following text. That said, we feel that given the small number of retractions (#2) and the provided reasons (honest mistakes), it may not add much to the paper. We leave it up to the reviewer and the editor to decide on the matter and have attached the data underlying in anonymised form to this re-submission.</p><p>“Additional analyses</p><p>A potential concern with our way of studying supervisors’ role modeling regards missing potential irresponsible behaviors. To accommodate this concern, we used the author-disambiguation algorithm developed by Caron &amp; van Eck (2014) to obtain meta-data on all publications from supervisors and PhD candidates that were available in the in-house version of Web of Science database at CWTS, Leiden University, the Netherlands, and screened these for retractions. Note that a retraction need not indicate actual irresponsible behavior, it may regard honest mistakes. Where possible, we provide the reason for the retraction as specified by the respective journal.</p><p>…</p><p>Retractions analysis</p><p>We were able to link a total of 81091 publications to the supervisors and PhD candidates. Three PhD candidates could not be identified, all supervisors were identified. Of the 81091 publications that could be matched to the PhD candidates and supervisors, 2 were retracted. Both regarded publications where the supervisor appeared as one of the co-authors and were retracted one year after publication. The following reasons were specified, which we interpret as honest errors:</p><p>“The authors have become aware that some of the results presented in this paper are invalid, not reproducible and/or misinterpreted. They consider that the main conclusion of the paper is not valid. They therefore retract this publication.”</p><p>“The original version of this article was withdrawn by the authors. An error was discovered in the creation of the protein database file that was used for searching, which led to some incorrect associations between peptides and proteins. A corrected version of the manuscript has been supplied which contains the very similar peptide identifications as the original, but the resulting number of proteins in various categories has now changed, and as a result some of the figures and supplementary files have changed also. The underlying conclusions of this study, however, remain unaltered.”</p><p>None of the publications included in our own dataset were retracted. RetractionWatch, a blog and database tracking and reporting on retractions (https://retractionwatch.com/), indicated that retractions can take from 3 months to many years, hence some papers may</p><p>be retracted in the future.”</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>The authors sought to undertake an examination of open-access publishing and open data sharing among PhD students and their supervisors as part of an expressed interest in responsible research practices (RRPs). The study was preregistered (including hypotheses, procedures, and outcomes), contained a step-by-step guide with screenshots for replicating their protocol, and shared all data and code.</p><p>The study results are fairly clearly explained, though I have some specific comments and questions that I provide to the authors privately. The research question itself is interesting and the procedures used to identify and match open access publication and data availability both use and advance novel procedures for doing so. I do have some questions about possible mediating and moderating factors that may be important to discuss, as well as the possible importance of separating open publication and data accessibility from the highly related, but not identical, concept of RRP. In most cases, the resolution of these questions would not change the core findings of the manuscript but would simply serve to advance clarity and discussion. As with all papers using associative analyses, readers are cautioned to avoid causal interpretations – a caveat that is also addressed by the paper itself.</p></disp-quote><p>Thank you for the kind words and helpful comments. We re-ran our analyses with institution as a potential confounding variable and present the crude and adjusted results side-by-side in Table 2 now. We have also adjusted the formulation of our concept, and the paper now consistently refers to open science practices. The remainder of the comments is answered in-depth below.</p><disp-quote content-type="editor-comment"><p>Abstract</p><p>Although I have a few questions about some of the analyses, if indeed it is the case that the open access odds were lower, since your manuscript has 4 primary findings, consider sharing all 4 in the abstract.</p></disp-quote><p>Thanks for flagging this, we added the open access odds to the abstract. We added the following sentence:</p><p>“Having a supervisor who actively published open access was associated with an odds of 1.99 to publish open access, but this effect became nonsignificant when correcting for institutions.”</p><disp-quote content-type="editor-comment"><p>Introduction</p><p>Paragraph 1: The first sentence appears to imply that supervision generally results in socialization into responsible research practices. This may benefit from being expanded somewhat for clarity. For example, the first paper (Bird, 2001) discusses how role modeling and mentorship differ in key ways, and the second paper (Anderson et al., 2007) explicitly notes that certain kinds of mentorship/supervision were associated with higher rates of problematic practices for early career researchers. Would it be more apt to state something like, &quot;When conducted in a manner that clearly emphasizes rigorous, reproducible, and transparent research practices, it is plausible that supervision…&quot;</p></disp-quote><p>That would indeed be more apt – we revised the sentence to emphasize that a particular style of supervision is necessary, namely responsible supervision. We now write:</p><p>“When conducted in a manner that emphasizes rigorous and transparent research, supervision can be an important manner to socialize PhD candidates into responsible research practices.”</p><disp-quote content-type="editor-comment"><p>Paragraph 1: The sentence focused on examples of RRPs cites articles that address RRPs to a degree, but some (e.g., Gopalakrishna et al., 2022) primarily focus on questionable research practices, not necessarily why RRPs might mitigate some of those concerns. I encourage the identification of additional references on RRP to be included here.</p></disp-quote><p>Thank you for flagging this, we added an additional 6 references that investigate outcome variables similar to ours, i.e., Iqbal et al. (2016); Wallach et al. (2018); Susanin et al. (2022); Roche et al. (2022), and Hughes et al. (2022).</p><disp-quote content-type="editor-comment"><p>Paragraph 2: Although scientific writing conventions vary, my own preference would be for your description to be in the personal possessive here (e.g., &quot;…a pilot study conducted by the first author identified three components.&quot;). I think it is important for the reader to understand the origin of these ideas and that you are building on your own prior work.</p></disp-quote><p>It was indeed out of different conventions that we choose this description. We now rephrased it to: “… a pilot study conducted by a research team including the first author identified three components.” to denote the connection with previous research.</p><disp-quote content-type="editor-comment"><p>Paragraph 2: In the final sentence, consider also adding a point raised by the cited work around the importance of being able to safely scrutinize each others' work.</p></disp-quote><p>Thank you for this suggestion, we added the following point with references:</p><p>“This psychological safety in turn contributes to maintaining quality by creating an environment where colleagues can safely scrutinize each others’ work (Roberto, Bohmer, and Edmondson, 2006; Halbesleben &amp; Rathert, 2008).”</p><disp-quote content-type="editor-comment"><p>Materials and methods</p><p>Materials Availability: I appreciated the excellent use of screenshots to guide readers through the procedures used (as documented on OSF).</p></disp-quote><p>We are pleased to read you found it useful.</p><disp-quote content-type="editor-comment"><p>Population: I encourage including some of the population information from your preregistration here as well. For example, readers may not intuit that full professorship is the normative rank for candidate supervision in Dutch universities and might mistakenly assume some sort of selection bias (e.g., if associate professors were more commonly supervisors but you identified mostly full professors…).</p></disp-quote><p>This is very helpful, especially given the international readership. We added the following clarifier:</p><p>“(in The Netherlands, the primary supervisor has to be a full professor, although recently associate professors can get these rights, too).”</p><disp-quote content-type="editor-comment"><p>Sampling Time: It is unclear why the data extraction timeframe resulted in the specific range of PhD thesis defense times. You explore some of this in your preregistration, but additional details would be useful here (even if it's just to indicate that normative delays reflected X – this also addresses why you planned to but did not include German universities, in part).</p></disp-quote><p>The sampling time frame of 2022-2021 was a result of the required sample size. We set out to include about 200 pairs and wanted to assure equal representation among the four institutions. For some institutions, this meant that we had to go back until theses defended late 2021. We now added the following clarification:</p><p>“We stopped sampling when we passed the required sample size, and wanted to include an equal share of pairs from each of the four university medical centers.”</p><disp-quote content-type="editor-comment"><p>Eligibility Criteria: Can you clarify whether &quot;latest 2018&quot; means &quot;no earlier than 2018&quot;? I suspect this is a linguistic difference but I want to be sure. In addition, can you explain why you included PhD candidates if they only had at least 2 publications? Is it possible that this inclusion criterion systematically excluded candidates or supervisors with specific characteristics?</p></disp-quote><p>Indeed, no earlier than 2018. This has been adjusted in the main text now. Initially, the criterion of at least 2 publications was intended to filter our German thesis that were Dr Med instead of PhD degrees – Dr Med theses can be built around one journal publication. In addition, Dutch university medical centers often apply the criterion of at least 2 journal publications the regulations of Maastricht University and Amsterdam University Medical center even denote this more explicitly. Hence, we see no reason to believe this systematically excluded PhD candidates. That said, we encountered cases where we could not include a pair because the supervisor did not have enough works, either as primary or last author, or works without the PhD candidate as a co-author. We reflect on this on the Limitations’ section as follows:</p><p>“This meant that at times, we had to exclude some pairs because the supervisor did not have a sufficient number of publications, meaning we may have a small bias towards productive supervisors.”</p><disp-quote content-type="editor-comment"><p>Data Preparation: I recommend referencing the Unpaywall FAQ here for data definitions (can be cited as a resource since the FAQ was prepared by Jason Priem; https://support.unpaywall.org/support/solutions/articles/44001777288-what-do-the-types-of-oa-status-green-gold-hybrid-and-bronze-mean-). The advantage is that, as the FAQ notes, there is no formal classification schema that exists. I would not have known that &quot;Green&quot; OA includes institutional repositories because some journals use that term similarly to how this FAQ uses &quot;Hybrid.&quot;</p></disp-quote><p>Excellent suggestion, we added the following sentence:</p><p>“We applied the following hierarchy: Gold, Green, Hybrid, Bronze, and Paywalled, following the interpretations of the different forms as described by Priem (2021).”</p><disp-quote content-type="editor-comment"><p>Data Analysis: I am not a statistician, but I wonder (perhaps naively) whether 'university' should have been included in the model as a clustering term, especially since some of the earlier literature cited indicates that the environment (beyond the mentor and lab) can contribute to RRP.</p></disp-quote><p>Thanks for flagging this, we agree and reran our models to see if university functioned as a potential confounding variable. This would mean that part of the association between behavior of the supervisor and the PhD candidate was actually due to the university environment. We now present crude and adjusted models side-by-side in Table 2. The upshot is that the institutional environment is of greater relevance for open access, but the associations identified for open data stand and are even strengthened by adding the environment.</p><disp-quote content-type="editor-comment"><p>Discussion</p><p>The first paragraph of the Discussion contains information that I would ordinarily associate with Results. That aside, can you clarify the interpretation of the open-access information? If these are presented as exp(b) values, then would a.18 would indicate that PhD candidates published open access less often when their supervisors did than when they did not?</p></disp-quote><p>Apologies for the confusion, the reviewer is right. When looking into this, we found that the recoding of our variable (never open access/sometimes open access/often open access) was flawed, as recent data showed that 76% of publications from Dutch researchers are open access (<ext-link ext-link-type="uri" xlink:href="https://www.rathenau.nl/en/science-figures/output/publications/open-access-research-publications">https://www.rathenau.nl/en/science-figures/output/publications/open-access-research-publications</ext-link>). Hence the groups we created when recoding were heavily skewed. We updated the preregistration, detailing the rationale for choosing a different coding scheme and recoded Open Access into up to the national average (0) and beyond the national average now (1). This created a binary variable. We reasoned that supervisors who publish Open Access more often than the national average could be seen as actively practicing open access, and thus as role models. We now write:</p><p>“Effects for Open Access were smaller (1.99) and became nonsignificant when correcting for the role of the institution.”</p><disp-quote content-type="editor-comment"><p>Contextualization: Since there is a substantial cost associated with publishing in many open-access venues, might an important contributor to variance (that might affect this model but is not included in the model) be the funding amount of the supervisor? For example, some supervisors may have limited ability to publish open access where a cost is incurred, some may be able to publish their own work (or at least some of their own work) open access, but fewer likely can afford to support their candidates in publishing at cost. If there is indeed a weaker relationship between supervisor publishing and candidate publishing than between data availability, then could this be a mediating or moderating factor?</p></disp-quote><p>This could indeed be true, and we added this to the Contextualisation section (Discussion), while noting that green OA is still open, but free of (financial) cost:</p><p>“Open access comes in different forms and publishing in open access journals is often not for free. Some publishers make exceptions for scientists from low and middle income countries, but The Netherlands would rightly not classify. It could thus be that the amount of funding that a supervisor or PhD candidate had available affected the relationship we studied. In other words: funding availability may determine whether PhD candidates (or supervisors) chose to publish in an open access journal. However, it should be noted that green open access, archiving a paper in an appropriate format in an (institutional) repository, can be done free of financial charge.”</p><disp-quote content-type="editor-comment"><p>The role of ECRs: I'm not sure that we should assume that ECRs have more opportunities to learn about responsible research, in general, though they may have more exposure to open research principles. This paper primarily focuses on open data and open publication. While these are important components of reproducibility and transparency, and while they may aid in the identification of problematic findings and work, they do not subsume the entirety of RRPs. Some components of RRP are longstanding or axiomatic ethical determinations or orientations, whereas the rise of open access has been relatively recent. So even highly ethical, responsible, and transparent senior researchers may be slow to uptake new publishing approaches.</p></disp-quote><p>We now refer to open science practices, and tried to make it clear from the outset that these are, as you rightly indicate, only a subset of RRPs. It seems true that many activities to educate researchers about open science practices do focus on ECRs, hence we trust the paragraph to be in order, given the greater current emphasis on open science.</p><disp-quote content-type="editor-comment"><p>The role of ECRs: Since your findings are nondirectional (e.g., correlations), it seems plausible (given the citations you provide) that you may be capturing a bidirectional relationship.</p></disp-quote><p>True, we incorporated this so that the paragraph now describes the possibility of PhD candidates influencing supervisors, supervisors influencing PhD candidates, or a bidirectional relationship. We end the paragraph with the following sentence:</p><p>“Finally, it could be that the relationship investigated here is bidirectional.”</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>I would like to thank the authors for the work put into this revision and the clarifications offered in the response to reviewers. I restate my perception that this work is interesting and provides a solid and useful contribution to the overall scientific enterprise in this area. I have a few questions and comments around the revised work that I hope you find useful.</p><p>Abstract</p><p>Here and elsewhere, you might want to use or provide the specific meaning of &quot;actively published open access&quot; since it's very specific to this article (e.g., published open access more often than the average Dutch professor did in 2021). There are also comments in the Discussion about the odds ratio that apply to the abstract (depending on whether you decide to make those revisions).</p></disp-quote><p>Thank you for flagging this, we now use the more descriptive “more often than the national average” to prevent confusion.</p><disp-quote content-type="editor-comment"><p>Introduction</p><p>I think that the modifications made to the Introduction section are helpful and address my comments in full.</p></disp-quote><p>Thank you.</p><disp-quote content-type="editor-comment"><p>Materials and methods</p><p>I am glad that my questions prompted further investigation into the analyses and variable structure. My only remaining comment relates to the new statement, &quot;The 10% rule for confounding was applied.&quot; I think the application here is fine (again – I am not a professional statistician, so caveat emptor) but a citation may be useful. Some readers may be unfamiliar with that rule, and others may have questions about it (see, eg., Lee, 2014 – https://doi.org/10.2188%2Fjea.JE20130062).</p></disp-quote><p>Many thanks for suggesting this, we have added some references to sources (Budtz-Jørgensen et al., 2007; Beukelman &amp; Brunner, 2016) that provide an accessible introduction to the confounder rule applied.</p><disp-quote content-type="editor-comment"><p>Results</p><p>In the title for Table 1, you might want to specify the unit of analysis (e.g., a unique DOI). While it is clear to me what is meant by the table, a reader who is skimming might assume that there are, for example 548 PhD candidates publishing open access, rather than 548 DOIs from PhD candidates that were published open access.</p></disp-quote><p>We have adjusted the description of the table accordingly, thanks for the close reading. It now reads:</p><p>“Prevalence for each practice (expressed as unique DOIs) appears in Table 1, as well as correlations between the PhD candidates’ engagement in a practice and the supervisors’ engagement in a practice.”</p><p>The new title for Table 1 is:</p><p>“Prevalence of Open Access publishing and sharing data openly among unique DOIs.”</p><disp-quote content-type="editor-comment"><p>If I understand your methods for identifying open data correctly, it may be worth removing the &quot;Open data (automated)&quot; information from the Results entirely. Here is my reasoning: Oddpub was used to extract possible instances of open data statements, but through manual verification, you triaged around half of those instances. Specifically, it seems that those that were excluded by manual verification did not have open data statements as affirmed by two to three human reviewers. Thus, I am not sure what value is added by analyzing the &quot;Open data (automated)&quot; variable, which seems to only describe a subset of papers for which a specific algorithm thought it found open data. We are not concerned with whether things are associated with whether a machine thinks there might be an open data statement, but rather whether things are associated with actual open data access.</p></disp-quote><p>We understand your reasoning but respectfully disagree for a number of reasons. First, The Oddpub tool by Riedel and colleagues (2020) has fairly good sensitivity (0.73) and excellent specificity (0.97) and has been used around the world. Hence, we would prefer to keep the passages in as it allows for international comparison. In addition, keeping it in allows others to re-do our analyses for integrity purposes. Also, the automated screening is arguably a less resource intensive manner (as compared to human deliberation) to assess data sharing. Finally, the sample size and power was calculated based on automated Open Access screening, not on human deliberation, and hence we would prefer to present both results side-by-side as we believe that they provide the most accurate description together.</p><disp-quote content-type="editor-comment"><p>Can you please consider verifying the total number of linked publications (81,091)? Given that the supervisor+candidate total n was around 2,000, that number would imply that the supervisors in this study published an additional 79,000 or so papers before 2017. While that is certainly possible, even if we assume that the 211 recent PhD candidates published an aggregate 10,000 papers (a very generous assumption), it would mean that the 211 supervisors published an average of 327 papers each, which is fairly remarkable. In some ways, this number is less relevant than the 2 retractions, but it does make me wonder.</p></disp-quote><p>We verified this. A few contextual remarks may be helpful. Firstly, researchers may have published since we stopped sampling last year. Secondly, the number of unique papers is smaller, as many publications are multi-authored. Thirdly, it is not entirely helpful to speak of averages here as we found 20% of the authors to account for 64% of the publications (see excel sheet attached to this revision and added to the GitHub repository). Note that for the first researcher who started publishing in 1982, over 2000 publications were identified.</p><disp-quote content-type="editor-comment"><p>Discussion</p><p>If you agree with my point about automated open data statement identification, you can also remove this sentence from the Discussion (&quot;Based on the automated detection of data sharing statements, we found that having a supervisor that shared data is associated with 2.21 times the odds to share data when compared to having a supervisor that did not share data.&quot;)</p></disp-quote><p>As above, we would prefer to keep the passage in as the two ways of assessing data sharing together provide the most accurate description.</p><disp-quote content-type="editor-comment"><p>I would suggest revising this sentence: &quot;Effects for Open Access were smaller (1.99) and became nonsignificant when correcting for the role of the institution.&quot; Instead, you could indicate that the unadjusted odds ratio was 1.99 (p=.011) and the adjusted odds ratio was 1.64 (p=.079). I think that the shift in odds is interesting even though it falls above the conventional significance threshold.</p></disp-quote><p>We agree this is a cleaner presentation of the main findings and now write:</p><p>“ The unadjusted open access odds ratio was 1.99 (p=.011) and became 1.64 (p=.079) when correcting for the role of the institution.”</p><disp-quote content-type="editor-comment"><p>You currently write, &quot;This may indicate there being greater acceptance of and support for a particular practice in a research group. In other words: a responsible supervisory climate may empower PhD candidates to engage in open science more readily.&quot; You might want to contextualize this with something like, &quot;In considering the associations that we identified, we speculate that…&quot;</p></disp-quote><p>Thank you for suggesting this, we have largely taken over your formulation and now write:</p><p>“Considering the associations that we identified, we speculate that working under supervisors who engage in open science themselves could empower PhD candidates to engage in open science more readily.”</p><p>References</p><p>Riedel, N., Kip, M. and Bobrov, E., (2020). ODDPub – a Text-Mining Algorithm to Detect Data Sharing in Biomedical Publications. <italic>Data Science Journal</italic>, 19(1), 1-14. <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5334/dsj-2020-042">http://doi.org/10.5334/dsj-2020-042</ext-link></p><p>Beukelman, T., &amp; Brunner, H. I. (2016). Chapter 6 – Trial Design, Measurement, and Analysis of Clinical Investigations. In <italic>Textbook of Pediatric Rheumatology</italic> (7th ed., pp. 54–77). W.B. Saunders. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/b978-0-323-24145-8.00006-5">https://doi.org/10.1016/b978-0-323-24145-8.00006-5</ext-link></p><p>Budtz-Jørgensen, E., Keiding, N., Grandjean, P., &amp; Weihe, P. (2007). Confounder selection in environmental epidemiology: assessment of health effects of prenatal mercury exposure. <italic>Annals of epidemiology</italic>, <italic>17</italic>(1), 27–35. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.annepidem.2006.05.007">https://doi.org/10.1016/j.annepidem.2006.05.007</ext-link></p></body></sub-article></article>