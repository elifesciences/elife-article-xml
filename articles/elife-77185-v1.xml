<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">77185</article-id><article-id pub-id-type="doi">10.7554/eLife.77185</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A neural network model of hippocampal contributions to category learning</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-267427"><name><surname>Sučević</surname><given-names>Jelena</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5091-5434</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-94513"><name><surname>Schapiro</surname><given-names>Anna C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8086-0331</contrib-id><email>aschapir@sas.upenn.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Experimental Psychology, University of Oxford</institution></institution-wrap><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>Department of Psychology, University of Pennsylvania</institution></institution-wrap><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Zeithamova</surname><given-names>Dasa</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0293rh119</institution-id><institution>University of Oregon</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>11</day><month>12</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e77185</elocation-id><history><date date-type="received" iso-8601-date="2022-01-18"><day>18</day><month>01</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-11-06"><day>06</day><month>11</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-01-13"><day>13</day><month>01</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.01.12.476051"/></event></pub-history><permissions><copyright-statement>© 2023, Sučević and Schapiro</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Sučević and Schapiro</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-77185-v1.pdf"/><abstract><p>In addition to its critical role in encoding individual episodes, the hippocampus is capable of extracting regularities across experiences. This ability is central to category learning, and a growing literature indicates that the hippocampus indeed makes important contributions to this form of learning. Using a neural network model that mirrors the anatomy of the hippocampus, we investigated the mechanisms by which the hippocampus may support novel category learning. We simulated three category learning paradigms and evaluated the network’s ability to categorize and recognize specific exemplars in each. We found that the trisynaptic pathway within the hippocampus—connecting entorhinal cortex to dentate gyrus, CA3, and CA1—was critical for remembering exemplar-specific information, reflecting the rapid binding and pattern separation capabilities of this circuit. The monosynaptic pathway from entorhinal cortex to CA1, in contrast, specialized in detecting the regularities that define category structure across exemplars, supported by the use of distributed representations and a relatively slower learning rate. Together, the simulations provide an account of how the hippocampus and its constituent pathways support novel category learning.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>hippocampus</kwd><kwd>neural network model</kwd><kwd>category learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000769</institution-id><institution>University of Oxford</institution></institution-wrap></funding-source><award-id>St Hugh's College Travel Grant</award-id><principal-award-recipient><name><surname>Sučević</surname><given-names>Jelena</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100014147</institution-id><institution>Charles E. Kaufman Foundation</institution></institution-wrap></funding-source><award-id>KA2020-114800</award-id><principal-award-recipient><name><surname>Schapiro</surname><given-names>Anna C</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A neural network model of the hippocampus exhibits a division of labor across its two main pathways during category learning, with one pathway specializing in extracting systematic category information and another in encoding arbitrary details.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Learning how the entities in our environment cluster into groups with overlapping properties, names, and consequences allows us to communicate and act adaptively. This category learning often unfolds over long periods of time, for example, when learning about the many species of dogs across development, but can also occur within a few minutes or hours, as when learning about different kinds of penguins on a first visit to the zoo. Much is known about how neocortical areas represent categories of information learned over long timescales (<xref ref-type="bibr" rid="bib44">Martin, 2007</xref>; <xref ref-type="bibr" rid="bib48">Miller et al., 2003</xref>), but less is understood about the mechanisms by which the brain learns quickly in initial encounters. Given the ability of the hippocampus to learn rapidly (<xref ref-type="bibr" rid="bib46">McClelland et al., 1995</xref>) combined with its ability to learn regularities across experiences (<xref ref-type="bibr" rid="bib72">Schapiro et al., 2012</xref>), this brain area seems well suited to make a contribution to rapid category learning (<xref ref-type="bibr" rid="bib41">Mack et al., 2018</xref>; <xref ref-type="bibr" rid="bib90">Zeithamova and Bowman, 2020</xref>). Indeed, neuroimaging studies provide strong evidence that the hippocampus is engaged in novel category learning (<xref ref-type="bibr" rid="bib5">Bowman and Zeithamova, 2018</xref>; <xref ref-type="bibr" rid="bib40">Mack et al., 2016</xref>; <xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>). Studies with hippocampal amnesics tend to find partial but not complete deficits in category learning (<xref ref-type="bibr" rid="bib88">Zaki, 2004</xref>), indicating that the hippocampus—though not the sole region involved—makes an important causal contribution.</p><p>In the present work, we ask what computational properties of the hippocampus might allow it to contribute to category learning. Using a neural network model of the hippocampus named C-HORSE (Complementary Hippocampal Operations for Representing Statistics and Episodes), we previously demonstrated how the hippocampus might contribute to learning temporal regularities embedded in continuous sequences of stimuli (temporal statistical learning) and to inference over pairwise associations (<xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>; <xref ref-type="bibr" rid="bib91">Zhou et al., 2023</xref>). We showed that the heterogeneous properties of the two main pathways within the hippocampus may support complementary learning systems, with one pathway specializing in the rapid encoding of individual episodes and another in extracting statistics over time. This division of labor is analogous to the roles of the hippocampus and neocortex in the classic Complementary Learning Systems framework (<xref ref-type="bibr" rid="bib46">McClelland et al., 1995</xref>), and our proposal was thus that a microcosm of this memory systems dynamic plays out within the hippocampus itself.</p><p>Category learning is related to temporal statistical learning in requiring information to be integrated across experiences, with the structure of a category discovered across exposure to individual exemplars, but it is also different in important ways. Category learning involves tracking exemplars composed of separate features that can vary in different ways across exemplars. The regularities in these features often manifest in co-occurrence in space at one moment (e.g., different parts of an object), as opposed to co-occurrence nearby in time. There is also often demand in category learning tasks for more explicit grouping and labeling of exemplars. The present work evaluates to what extent the principles of structure learning that allow the hippocampus to support statistical learning may also apply to this different learning domain. If the principles generalize, it would suggest the possibility of broad, domain-general learning mechanisms at work in the hippocampus that allow integration of varied forms of information across experiences.</p><p>C-HORSE comes from a lineage of models developed to explain how the subfields of the hippocampus support episodic memory (<xref ref-type="bibr" rid="bib24">Ketz et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib58">O’Reilly and Rudy, 2001</xref>). It instantiates the broad anatomical structure of the hippocampus: hippocampal subfields dentate gyrus (DG), cornu ammonis (CA3), and CA1 are represented as three hidden layers; they receive input and process output through entorhinal cortex (EC; <xref ref-type="fig" rid="fig1">Figure 1</xref>). The subfields are connected via two main pathways: the trisynaptic pathway (TSP) and the monosynaptic pathway (MSP). The TSP runs through DG and CA3 to reach CA1. The projections within the TSP are sparse, enabling the formation of orthogonalized representations even with highly similar input patterns (i.e., pattern separation). This corresponds to the observed physiology; for example, distinct sets of place cells in rodents are responsive to particular locations in CA3 even in very similar enclosures (<xref ref-type="bibr" rid="bib38">Leutgeb et al., 2004</xref>). The TSP is highly plastic in the brain and in the model, which supports rapid, even one-shot learning (<xref ref-type="bibr" rid="bib51">Nakashiba et al., 2008</xref>). The TSP also contributes to the process of retrieving previously encoded patterns from partial cues (i.e., pattern completion) via recurrent connections in CA3. The TSP is thus critical for carrying out the episodic memory function of the hippocampus.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>C-HORSE architecture.</title><p>The model consists of dentate gyrus (DG), CA3, and CA1 subfields which map inputs from superficial (EC<sub>in</sub>) to deep layers (EC<sub>out</sub>) of the entorhinal cortex. The height and color of each box represents the activity level of a unit. The trisynaptic pathway (TSP) connects EC to CA1 via DG and CA3 (blue arrows), and the monosynaptic pathway (MSP) connects EC directly with CA1 (green arrows). The TSP specializes in pattern separation (depicted as separated blue pools of neurons), whereas the MSP contains more overlapping representations (overlapping green pools).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77185-fig1-v1.tif"/></fig><p>The MSP connects EC directly to CA1. These projections do not have the specialized sparsity of those in the TSP, allowing for more overlapping representations to emerge. Place cell responses in CA1 tend to overlap as a function of the similarity of the enclosure (<xref ref-type="bibr" rid="bib38">Leutgeb et al., 2004</xref>). In addition, the MSP seems to learn more slowly (<xref ref-type="bibr" rid="bib37">Lee et al., 2004</xref>; <xref ref-type="bibr" rid="bib51">Nakashiba et al., 2008</xref>). These properties of relatively more overlapping representations and more incremental learning mirror those of neocortex (<xref ref-type="bibr" rid="bib46">McClelland et al., 1995</xref>). In earlier versions of this model (<xref ref-type="bibr" rid="bib52">Norman and O’Reilly, 2003</xref>), the MSP was seen as merely a translator between the TSP representations and neocortex, but we have argued that its properties may make the MSP well suited to learning structured information across episodes (<xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>). Despite its analogous properties, the MSP is not redundant with neocortex in this framework: the MSP allows <italic>rapid</italic> structure learning, on the timescale of minutes to hours, whereas the neocortex learns more slowly, across days, months, and years. The learning rate in the MSP is intermediate between the TSP (which operates as rapidly as one shot) and neocortex. The proposal is thus that the MSP is crucial to the extent that structure must be learned rapidly.</p><p>To investigate the role of the hippocampus in category learning, we tested how the MSP and TSP of C-HORSE contribute to category learning behavior across three different types of categories. First, we evaluated the network’s ability to learn simple nonoverlapping categories of exemplars consisting of multiple discrete features, with some features shared among the members of a category and others unique to each exemplar (<xref ref-type="bibr" rid="bib74">Schapiro et al., 2017a</xref>; <xref ref-type="bibr" rid="bib76">Schapiro et al., 2018</xref>). We assessed the model’s memory for these different kinds of features as well as its ability to generalize to novel exemplars. Second, we simulated the probabilistic Weather Prediction Task (<xref ref-type="bibr" rid="bib29">Knowlton et al., 1996</xref>; <xref ref-type="bibr" rid="bib28">Knowlton et al., 1994</xref>). In this task, four different cards with shapes are each probabilistically associated with one of two categories: on each trial, a prediction about the weather (sun or rain) is made based on a combination of one, two, or three presented cards. We assessed the model’s categorization ability as well as recognition of particular card combinations. Third, we tested the network’s ability to learn categories with varying typicality defined along a continuum of overlapping features (<xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>; <xref ref-type="bibr" rid="bib6">Bowman et al., 2020</xref>). Prototypes of two categories have no features in common, and category exemplars then fall on a continuum between the two prototypes. Exemplars that share more features with the prototype are more typical category members. We assessed the model’s categorization and recognition as a function of typicality.</p><p>Across the three category learning tasks, C-HORSE was able to both determine the category membership of exemplars and recognize specifics of individual studied exemplars, demonstrating similar learning trajectories to humans in these tasks. There was a division of labor across the two pathways of the hippocampus in these functions: the MSP played a central role in learning the regularities underlying category structure and excelled in generalizing knowledge to novel exemplars. The TSP also contributed to behavior across the tasks but with the opposite expertise, specializing in memory for the unique properties of exemplars. The rapid binding and pattern separation abilities of the TSP that make the pathway well suited to episodic memory are also advantageous for encoding arbitrary relationships in category learning. The findings together motivate a theory of hippocampal contributions to category learning, with the MSP responsible for true understanding of category structure and the TSP for encoding the arbitrary specifics of individual exemplars.</p></sec><sec id="s2" sec-type="methods"><title>Methods</title><p>We adopted a neural network model of the hippocampus developed after a lineage of models used to explain how the DG, CA3, and CA1 subfields of the hippocampus contribute to episodic memory (<xref ref-type="bibr" rid="bib24">Ketz et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Norman and O’Reilly, 2003</xref>; <xref ref-type="bibr" rid="bib58">O’Reilly and Rudy, 2001</xref>). This variant, C-HORSE, was developed recently to account for the role of the hippocampus in statistical learning (<xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>; <xref ref-type="bibr" rid="bib91">Zhou et al., 2023</xref>). Simulations were performed in the Emergent simulation environment (version 7.0.1, <xref ref-type="bibr" rid="bib1">Aisa et al., 2008</xref>, <xref ref-type="bibr" rid="bib59">O’Reilly et al., 2014a</xref>). Files for running the model can be found on <ext-link ext-link-type="uri" xlink:href="https://github.com/schapirolab/hip-cat">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib77">Schapiro Lab, 2022</xref>).</p><sec id="s2-1"><title>Model architecture</title><p>The model has three hidden layers, representing DG, CA3, and CA1 hippocampal subfields, which learn to map input from superficial to deep layers of entorhinal cortex (EC<sub>in</sub> and EC<sub>out</sub>; <xref ref-type="fig" rid="fig1">Figure 1</xref>). There is also a separate Input layer (not shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>) with the same dimensionality as EC<sub>in</sub>, where external input was clamped (i.e., forced to take on particular values), allowing activity in EC<sub>in</sub> to vary as a function of external input as well as EC<sub>out</sub> activity. There are one-to-one non-learning connections between Input and EC<sub>in</sub> and between EC<sub>in</sub> and EC<sub>out</sub>.</p><p>Each layer is composed of a pool of units. There were 400 units in DG, 80 units in CA3, and 100 units in CA1, while input and output layer size (Input, EC<sub>in</sub>, and EC<sub>out</sub>) varied as a function of the task. The hidden layer size ratios reflect the approximate ratios in the human hippocampus (<xref ref-type="bibr" rid="bib24">Ketz et al., 2013</xref>). Units have activity levels ranging from 0 to 1, implementing a rate code. A unit’s activity is proportional to the activity of all units connected to it, weighted by connection weights between them. Unit activity is also modulated by inhibition between units within a layer. The inhibition simulates the action of inhibitory interneurons and is implemented using a set-point inhibitory current with k-winner-take-all dynamics (<xref ref-type="bibr" rid="bib60">O’Reilly et al., 2014b</xref>). All simulations involved tasks with discrete-valued dimensions as these are more easily amenable to implementation across input/output units whose activity tends to become binarized as a result of these inhibition dynamics. It will be important for future work to extend to implementations of category learning tasks with continuous-valued dimensions.</p><p>The TSP connects EC to CA1 via DG and CA3. Connections are sparse, reflecting known physiological properties of the hippocampus: DG and CA3 units receive input from 25% of units in the EC<sub>in</sub> layer, and CA3 receives directly from 5% of DG. Both DG and CA3 have high levels of within-layer inhibition. CA3 also has a full recurrent projection (every unit connected to every other). Finally, CA3 is fully connected to CA1.</p><p>The MSP is formed by a full direct connection from EC<sub>in</sub> to CA1, and bidirectional connections between CA1 and EC<sub>out</sub>. CA1 has lower inhibition than CA3 and DG, allowing a higher proportion of units in the layer to be simultaneously active. See <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1g and h</xref> for parameter values.</p></sec><sec id="s2-2"><title>Learning</title><p>The model was trained as an autoencoder, adjusting connection weights to reproduce patterns presented to EC<sub>in</sub> on EC<sub>out</sub>. Weights were updated via Contrastive Hebbian Learning (<xref ref-type="bibr" rid="bib24">Ketz et al., 2013</xref>). Following <xref ref-type="bibr" rid="bib24">Ketz et al., 2013</xref> and in line with known changes in projection strength across the theta phase, each learning trial has two minus phases each contrasted against one plus phase, with the minus phases corresponding to the peak and trough of the theta phase. At the simulated trough, EC has a strong influence on CA1, while the connection from CA3 to CA1 is inhibited. At the simulated peak, CA3 has a strong influence on CA1, while connections from EC<sub>in</sub> to CA1 are inhibited. This learning scheme allows the two pathways to learn more independently. During the plus phase, the target output is directly clamped on EC<sub>out</sub>. Weights are adjusted after each trial to reduce the local differences in unit coactivities between each of the two minus phases and the plus phase. As in previous work, the learning rate on the TSP was set to be 10 times higher than the MSP (<xref ref-type="bibr" rid="bib24">Ketz et al., 2013</xref>; <xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>), at 0.02 versus 0.002, except in the third simulation, where the MSP learning rate was smaller to accommodate stimuli with high degrees of overlap (which can lead to degenerate learning at relatively higher learning rates). The differential learning rates support the different functions of the TSP and MSP in one shot versus more incremental learning across experiences.</p><p>Simulations had a fixed number of training trials except in the Weather Prediction Task, where we used a stopping rule: after a minimum of 25 training trials, the model had to achieve five consecutive trials with sum squared error below 1.2. The stopping rule was introduced because of the probabilistic nature of the categories, where it is not possible to eliminate all error.</p></sec><sec id="s2-3"><title>Testing</title><p>Connection weights were not changed during test. Networks were tested before any training (trial 0) and intermittently after fixed sets of training trials. For each set of simulations, we assessed the model’s categorization ability and its ability to remember item-specific information.</p></sec><sec id="s2-4"><title>Lesions</title><p>We simulated lesions of the MSP and TSP in order to assess the contributions of each pathway to performance. The MSP lesion was performed by setting the strength of the projection from EC<sub>in</sub> to CA1 to 0. We did not lesion connections between CA1 and EC<sub>out</sub> because they are necessary for producing output. The TSP lesion was performed by setting weights from CA3 to CA1 to 0. The lesions were implemented in a version of the model that did not use the theta-inspired learning scheme described above as only one minus phase is appropriate with only one pathway intact. Lesions were implemented during both learning and testing.</p></sec><sec id="s2-5"><title>Statistical analysis</title><p>For each simulation, we analyzed 100 networks with randomly initialized weights (randomizing both the topography of weight connections where projections were sparse as well as the values of individual weights). To characterize variability across initializations, we conducted statistical analyses treating network initialization as the random effects factor. To compare performance in the intact and lesioned networks, the mean accuracy was submitted to an ANOVA with a between-network factor <italic>Condition</italic> (intact, MSP-only, and TSP-only network), a within-network factor <italic>Trial</italic> (number of training trials prior to test), and <italic>Network initialization</italic> as a random effects factor. Following the omnibus ANOVA, to determine which conditions may differ, we ran three separate ANOVAs with a between-network factor <italic>Condition</italic> which included two out of three conditions (intact vs. MSP-only, intact vs. TSP-only, and MSP-only vs. TSP-only). Data visualization and statistical analyses were performed in R, version 3.6.1 (<xref ref-type="bibr" rid="bib65">R Development Core Team, 2019</xref>).</p></sec><sec id="s2-6"><title>Representational similarity analyses</title><p>To assess the nature of learned representations in the networks, we performed representational similarity analyses for each of the simulations during a test phase at the end of training. We used Pearson correlation to relate the patterns of activity evoked by presentation of different items. We analyzed representations separately in the ‘initial’ and ‘settled’ response to each item in the intact network. The initial response captures the activation pattern once activity has spread throughout the network but before output activity in EC<sub>out</sub> recirculates back to the input in EC<sub>in</sub>—before there is an impact of ‘big-loop’ recurrence (<xref ref-type="bibr" rid="bib34">Kumaran and McClelland, 2012</xref>; <xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>). The settled response captures the fully settled pattern of activity including the influence of big-loop recurrence. Big-loop recurrence permits the representations in CA1 to influence those in DG and CA3, so separate analysis of the initial response allows cleaner assessment of the unique representational contributions of the different subfields.</p></sec></sec><sec id="s3" sec-type="results"><title>Results</title><sec id="s3-1"><title>Simulation 1: Learning distinct categories of items with unique and shared features</title><p>First, we examined C-HORSE’s ability to learn categories of items that consist of multiple discrete features, with some features unique to individual items and others shared amongst members of the same category, and no features overlapping across categories. To test the network’s ability to learn these categories, we presented a set of novel objects representing three categories of ‘satellites,’ with five satellites in each category, following empirical work with this paradigm (<xref ref-type="bibr" rid="bib74">Schapiro et al., 2017a</xref>; <xref ref-type="bibr" rid="bib76">Schapiro et al., 2018</xref>). The model and humans were given a comparable number of training trials: 140 for the model and on average 122 for humans (<xref ref-type="bibr" rid="bib76">Schapiro et al., 2018</xref>).</p><p>Each category had a prototype, defining the shared features for that category. Four other exemplars of the category had one out of five features swapped away from the prototype, such that they had one unique feature and four shared features (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). This structure means that one of the shared features is present across all exemplars in a category, which effectively serves as a category name/indicator and was used to assess categorization ability. Each feature was assigned to one unit in the input layer. If the feature was present, the input unit representing the feature took on a value of 1, and otherwise 0. Thus, there were 27 input units in total, 9 per category. Within each category, there were five units representing shared features and four units for unique features (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1a</xref>; see <xref ref-type="fig" rid="fig2">Figure 2a</xref> for an illustration of the inputs corresponding to one category).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Overview of simulated category learning paradigms.</title><p>(<bold>a</bold>) Satellite categories: distinct categories of novel ‘satellites’ consisting of unique and shared features (reproduced from Figure 1A of <xref ref-type="bibr" rid="bib74">Schapiro et al., 2017a</xref>). Grids depict model input structure for the five members of the Alpha category, with the prototype consisting of only shared features and all other exemplars containing one unique feature. One feature (the satellite head) is category prototypical, appearing in all exemplars of its category. (<bold>b</bold>) Weather Prediction Task: each abstract card is probabilistically related to a category (sun or rain), and on a given trial, category must be guessed from a simultaneously presented set of 1–3 cards (<xref ref-type="bibr" rid="bib28">Knowlton et al., 1994</xref>). The illustration shows the first two cards related to the ‘sun’ category on 90% of the trials (and to ‘rain’ on 10% of the trials), while a combination of the first three cards related to sun 79% of the time, and a fourth card viewed by itself associated with sun 15% of the time. (<bold>c</bold>) Intermixed categories with varying typicality: categories where each item consists of 10 binary features. The two prototypes on opposite sides of the feature space have no features in common (depicted by all green versus all yellow features in the piecharts), and the rest of the exemplars have a varying number of features in common with the prototypes (adapted from Figure 1 of <xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77185-fig2-v1.tif"/></fig><p>To characterize the network’s behavior, we investigated its ability to recognize unique features of individual trained satellites (unique feature recognition), recognize the prototypical feature shared across all trained members of a category (categorization), and fill in the prototypical feature for novel satellites not presented during training (generalization). For unique feature recognition, we presented the network with the unique feature of a trained satellite as input and evaluated the network’s ability to activate that feature on the output, compared to unique features of other members of the same category (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref>). Accuracy was determined by dividing the activation of the correct unit by the total activation in the four units representing unique features for that category (chance accuracy 0.25).</p><p><xref ref-type="fig" rid="fig3">Figure 3a and b</xref> show human performance across training for unique features (ability to fill in missing ‘code names’) and categorization (ability to fill in the category-prototypical visual feature, analogous to model assessment), re-analyzed from first session data from <xref ref-type="bibr" rid="bib74">Schapiro et al., 2017a</xref>. The intact network learned to recognize unique features of individual satellites with a similar trajectory to humans (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). A version of the network with access only to the MSP was completely unable to output the correct unique features, whereas a version with only the TSP could do this well above a chance, and even slightly better than the intact model. This reveals that the TSP is fully responsible for the network’s ability to remember unique features. Differences between model types across time were all highly reliable (all p<italic><sub>s</sub></italic>&lt;0.001).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Simulation 1: satellite task.</title><p>Human performance on (<bold>a</bold>) unique features and (<bold>b</bold>) categorization across training in <xref ref-type="bibr" rid="bib74">Schapiro et al., 2017a</xref>. Unique feature trajectory plotted with a linear learning curve fit and categorization with a quadratic fit. (Humans were not tested on generalization over the course of training.) Performance of the network across training trials for (<bold>c</bold>) unique feature recognition, (<bold>d</bold>) categorization of trained items, and (<bold>e</bold>) generalization (categorization of novel items). Performance is shown for the intact network (green), a version of the network with only the monosynaptic pathway (MSP) (orange), and a version with only the trisynaptic pathway (TSP) (purple). Plots show mean performance averaged across random network initializations. Error bars denote ±1 s.e.m. across people / 100 network initializations (some are too small to be visible). Dashed lines indicate chance level performance. Source data can be found in <xref ref-type="supplementary-material" rid="fig3sdata1">Figure 3—source data 1</xref>. (<bold>f</bold>) Representational similarity for the initial and settled response of the intact network. Each item appears in the rows and columns of the heatmaps. The diagonals are always 1 as this reflects items correlated to themselves, and the off-diagonals are symmetric. Black boxes delineate categories. Source data can be found in <xref ref-type="supplementary-material" rid="fig3sdata2">Figure 3—source data 2</xref>.</p><p><supplementary-material id="fig3scode1"><label>Figure 3—source code 1.</label><caption><title>R code used to generate <xref ref-type="fig" rid="fig3">Figure 3</xref> panels.</title></caption><media mimetype="application" mime-subtype="zip" xlink:href="elife-77185-fig3-code1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Data corresponding to all line plots in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title></caption><media mimetype="application" mime-subtype="octet-stream" xlink:href="elife-77185-fig3-data1-v1.csv"/></supplementary-material></p><p><supplementary-material id="fig3sdata2"><label>Figure 3—source data 2.</label><caption><title>Correlation values for representational similarity analysis heatmaps in <xref ref-type="fig" rid="fig3">Figure 3f</xref>.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-77185-fig3-data2-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77185-fig3-v1.tif"/></fig><p>To test categorization ability, we examined the network’s ability to indicate the correct category of a satellite, operationalized as activating the category-prototypical feature shared across all members of the satellite’s category. We presented the network with the unique feature of a satellite and divided output activity for the correct prototypical feature by the sum of activation of the three prototypical features for the three categories. The model’s trajectory and level of performance (<xref ref-type="fig" rid="fig3">Figure 3d</xref>) were comparable to humans (<xref ref-type="fig" rid="fig3">Figure 3b</xref>), although humans were able to perform this task well very early on in training. The MSP-only network exhibited much better performance than the intact network. The TSP-only network had poorer performance (0.71 vs. 1 by the end of training), but still well above chance. Because this test involved trained satellites, categorization could be solved using a memorization strategy, likely enabling good performance for the TSP-only network. Because the MSP was unable to remember unique features (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), it expressed knowledge only of the shared features, leading to excellent categorization performance. The intact network combined information from both sources, resulting in intermediate performance (see below for discussion of the idea that a control mechanism might allow selective enhancement of pathways depending on task). All differences between model types were again highly reliable (all p<italic><sub>s</sub></italic>&lt;0.001).</p><p>The strongest test of category understanding is the ability to generalize to novel instances. To test generalization, we presented the network with a set of 18 satellites (6 per category) that were not presented during training (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1c</xref>). Each input satellite consisted of two shared features (not including the category-prototypical feature) and two unique features, and we tested the network’s ability to output the category-prototypical feature. A similar pattern was observed as with the categorization of familiar items, but the TSP-only network showed poorer (though still above-chance) performance (0.53) in comparison to the intact network (0.94), while the MSP-only network was even better (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). The MSP was able to ignore the unique features of these novel satellites, resulting in perfect generalization behavior relatively early in training. All differences were reliable (p<italic><sub>s</sub></italic>&lt;0.001).</p><p>To assess network representations, we performed representational similarity analysis for each hidden layer of the intact network at the end of training (140 trials). We captured the patterns of unit activities evoked by presentation of each satellite’s unique feature (for the 12 satellites with unique features). There was no structure in the representations prior to training (not depicted), and the representations that emerged with training revealed sensitivity to the category structure (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). This was particularly evident in CA1, with items from the same category represented much more similarly than items from different categories. We separately analyzed the initial pattern of activity evoked by each feature (before there was time for activity to spread from EC<sub>out</sub> to EC<sub>in</sub>), and the fully settled response. The initial response allows us to understand the separate representational contributions of the subfields, before CA1 activity has the potential to influence DG and CA3. In the initial response, there was no sensitivity to category structure in DG and CA3—items were represented with distinct sets of units. This is a demonstration of the classic pattern separation function of the TSP, applied to this domain of category learning, where it is able to take overlapping inputs and project them to separate populations of units in DG and CA3. CA1 representations, on the other hand, mirrored the category structure, with overlapping sets of units evoked by items in the same category. This result is consistent with our neuroimaging findings using this paradigm, where CA1 was the only subfield of the hippocampus to show significant within versus between category multivoxel pattern similarity (<xref ref-type="bibr" rid="bib76">Schapiro et al., 2018</xref>). The settled response revealed sensitivity to category structure in all three hidden layers, reflecting the influence of CA1 on the rest of the network after ‘big-loop’ recurrence (<xref ref-type="bibr" rid="bib31">Koster et al., 2018</xref>; <xref ref-type="bibr" rid="bib34">Kumaran and McClelland, 2012</xref>; <xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>), though CA1 still showed the strongest response.</p><p>In sum, these results suggest that the network is capable of learning categories and generalizing to novel instances. To achieve this, the MSP and TSP take on complementary roles: the MSP extracts regularities and learns information that defines category structure, while the TSP encodes individual exemplars and handles unique feature recognition. These properties are analogous to our prior simulations with C-HORSE, where we found that the MSP detects statistical structure while the TSP encodes episode-unique information (<xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>). There are two key properties that differ between the pathways that underlie these results: (1) slower learning in the MSP than TSP, which allows integration of information over longer periods of time in the MSP and rapid learning in the TSP, and (2) more overlapping (distributed) representations in the MSP than TSP, which helps the MSP see commonalities across experiences and helps the TSP separate experiences to avoid interference.</p></sec><sec id="s3-2"><title>Simulation 2: Learning probabilistic categories</title><p>While the previous set of simulations focused on deterministic categories, that is, categories in which each item could belong to only one category, in this section we test the network’s ability to learn probabilistic categories using the canonical Weather Prediction Task (<xref ref-type="bibr" rid="bib29">Knowlton et al., 1996</xref>; <xref ref-type="bibr" rid="bib28">Knowlton et al., 1994</xref>; <xref ref-type="bibr" rid="bib66">Reber et al., 1996</xref>). In this task, there are a total of four cards with abstract shapes, and a combination of one, two, or three cards is simultaneously presented on each trial to predict a weather outcome, sunshine or rain (<xref ref-type="fig" rid="fig2">Figure 2b</xref>).</p><p>The number of times a particular combination of cards was presented to the network and the frequency of its association to each category were identical to the experimental procedure used in <xref ref-type="bibr" rid="bib28">Knowlton et al., 1994</xref> (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1d</xref>). Two combinations of cards that had an equal probability of being associated with each category were removed from analysis. Each card was represented by one unit in the input and output, and each weather outcome (category) was represented by two units (increasing the relative salience of category information). As in prior simulations, the model was trained as an autoencoder, meaning that both the cards and category information were presented as input and the model was asked to reconstruct all of these features on the output layer. This training regimen is more akin to an ‘observational’ than ‘feedback’ mode of the task, which is appropriate given evidence that the medial temporal lobe (MTL) is more engaged by observational variants (<xref ref-type="bibr" rid="bib62">Poldrack et al., 2001</xref>; <xref ref-type="bibr" rid="bib82">Shohamy et al., 2004</xref>). We trained the network for 50 trials, simulating the first part of Task 2 in <xref ref-type="bibr" rid="bib28">Knowlton et al., 1994</xref>, where patients also saw 50 trials (<xref ref-type="fig" rid="fig4">Figure 4a</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Simulation 2: Weather Prediction Task.</title><p>(<bold>a</bold>) Human control and amnesic performance from Task 2 of <xref ref-type="bibr" rid="bib28">Knowlton et al., 1994</xref> (adapted from Figure 2). (<bold>b</bold>) Intact and lesioned model categorization performance across trials, simulating the initial phase of human learning. (<bold>c</bold>) Model recognition performance for the intact network, a version of the network with only the monosynaptic pathway (MSP), and a version with only the trisynaptic pathway (TSP). (<bold>d</bold>) Model categorization performance across the three network variants. Source data can be found in <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>. (<bold>e</bold>) Representational similarity for the initial and settled response of the intact network. Each combination of cards appears in the rows and columns of the heatmap, organized by most likely to predict sun to most likely to predict rain. Source data can be found in <xref ref-type="supplementary-material" rid="fig4sdata2">Figure 4—source data 2</xref>.</p><p><supplementary-material id="fig4scode1"><label>Figure 4—source code 1.</label><caption><title>R code used to generate <xref ref-type="fig" rid="fig4">Figure 4</xref> panels.</title></caption><media mimetype="application" mime-subtype="zip" xlink:href="elife-77185-fig4-code1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Data corresponding to all line plots in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title></caption><media mimetype="application" mime-subtype="octet-stream" xlink:href="elife-77185-fig4-data1-v1.csv"/></supplementary-material></p><p><supplementary-material id="fig4sdata2"><label>Figure 4—source data 2.</label><caption><title>Correlation values for representational similarity analysis heatmaps in <xref ref-type="fig" rid="fig4">Figure 4e</xref>.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-77185-fig4-data2-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77185-fig4-v1.tif"/></fig><p>To examine the network’s performance, we tested its ability to reconstruct individual combinations of cards (recognition) and predict category based on the presented cards (categorization). For recognition performance, we evaluated reconstruction of the correct card output units given a set of input cards. Since all possible card combinations are presented during training, this does not involve discriminating old from new combinations, but is rather a simple measure of the network’s ability to process each distinct card configuration. Recognition score was calculated by dividing the mean activation of correct card units by the mean activation across all card units.</p><p>A stopping criterion was used during training, resulting in networks being trained for different numbers of trials, with better performing networks stopping earlier (which sometimes produces a slight dip in performance towards the end of training, as seen in <xref ref-type="fig" rid="fig4">Figure 4</xref>). We ran as many networks as needed to obtain data from 100 networks in each of the three lesion conditions at trial 50. As a result, there were 722 networks at trial 10, 715 networks at trial 20, 625 networks at trial 30, 443 networks at trial 40, and 300 networks in the final test trial (100 per condition).</p><p>The results indicated that the network was able to recognize individual combinations of cards (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). An ANOVA revealed significant main effects of trial, lesion type, and their interaction (all p<italic><sub>s</sub></italic>&lt;0.001). While the intact and TSP-only network showed equivalent performance (p=0.138), both showed significantly higher recognition accuracy than the MSP-only network (p<italic><sub>s</sub></italic>&lt;0.001). Consistent with the prior simulations, the TSP-only network demonstrated better recognition than the MSP-only network, and performed in this case virtually identically to the intact network. For this simple form of recognition, the MSP-only network was able to perform above chance.</p><p>Categorization performance was assessed by presenting sets of cards without any category input and testing the network’s ability to output the correct category. The intact and the MSP-only networks were able to categorize the sets of cards more effectively than the TSP-only network (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). The trajectory and accuracy levels for the intact and MSP-only network were similar to the performance levels observed in healthy participants (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). The TSP-only network performed close to chance on this task (though still exhibiting some degree of reliable categorization ability). An ANOVA revealed significant main effects of trial, lesion type, and their interaction (all p<italic><sub>s</sub></italic>&lt;0.001). Further analyses revealed significant differences between all three lesion conditions (intact vs. MSP-only network: p=0.005, other p<italic><sub>s</sub></italic>&lt;0.001). As in categorization and generalization in Simulation 1, the network performed better in categorization without the presence of the TSP, though this advantage was more subtle in this simulation. <xref ref-type="fig" rid="fig4">Figure 4b</xref> shows categorization for the intact network replotted as well as an average of the behavior of the MSP and TSP lesioned networks as a simulation of the behavior of amnesic patients shown in <xref ref-type="fig" rid="fig4">Figure 4a</xref> (who had a range of types and degrees of hippocampal damage).</p><p><xref ref-type="fig" rid="fig4">Figure 4e</xref> shows the similarity structure of the activity patterns evoked by different card combinations at the end of learning. As in Simulation 1, DG and CA3 represented the card combinations relatively distinctly, whereas the patterns of activity in CA1 reflected the category structure (mean similarity within category: 0.38, across: 0.25; p&lt;0.001). Similarity levels increased somewhat throughout the network after there was opportunity for big-loop recurrence (the ‘settled’ response), but patterns remained quite distinct in the TSP. The probabilistic nature of the categories in this simulation resulted in much noisier representations as well as middling behavioral performance in the model, but the qualitative match to human behavior (<xref ref-type="fig" rid="fig4">Figure 4a</xref> vs. <xref ref-type="fig" rid="fig4">Figure 4b</xref>) suggests that these underlying representations may be related to those supporting human behavior.</p><p>In sum, the network learned probabilistic categories similarly to humans. Mirroring the Simulation 1 results, the MSP contributed relatively more to this categorization ability, whereas the TSP was better able to process individual combinations of cards.</p></sec><sec id="s3-3"><title>Simulation 3: Learning intermixed categories with varying typicality</title><p>The third set of simulations tested the network’s ability to acquire categories with intermixed features and varying typicality. The network was exposed to a set of novel creatures belonging to two categories (<xref ref-type="fig" rid="fig2">Figure 2c</xref>; <xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>). Each creature had 10 binary features, and prototypes of the two categories had no features in common. The rest of the items spanned a continuum between the two prototypes: some items had nine features in common with one prototype and one feature in common with the other prototype; other items had eight features shared with one prototype and two features shared with the other prototype, and so on. If an item had more than five features in common with one prototype, it was considered to belong to the prototype’s category (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). Each feature was represented by two units (one unit for each of the two possible feature values), and each category label was represented by five units (increasing the salience of category information relative to the many creature features).</p><p>During training, the network learned 20 items, 10 from each category. The model saw each item five times for a total of 100 trials. The stimulus structure and training were based on <xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>, where participants were presented with 4 runs of 20 items, 10 from each category. Within each category, there were two items that shared nine features with the prototype, three items with eight shared features, three items with seven shared features, and two items with six shared features (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1e</xref>). At test, the network was presented with the training set and a test set consisting of 42 novel items (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1f</xref>): the two untrained prototypes and five items at each distance from the prototype (<xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>). We tested the network’s ability to remember the atypical features of the training items (atypical feature recognition) and its ability to predict the correct category for the novel items (generalization).</p><p>Human generalization performance in this paradigm across learning and in a subsequent test from <xref ref-type="bibr" rid="bib6">Bowman et al., 2020</xref> is shown in <xref ref-type="fig" rid="fig5">Figure 5a and b</xref>. Participants improved for all item types across learning, with better performance for more prototypical items. Generalization was assessed in the model by testing the network’s ability to predict the correct category for a set of novel category exemplars based on their features only (no category information was inputted). The mean activation in units representing the correct category was divided by the mean activation across units representing both the correct and incorrect categories. Like human participants, the intact network improved in its categorization of novel items across training, with better performance for more prototypical items (<xref ref-type="fig" rid="fig5">Figure 5c</xref>). <xref ref-type="fig" rid="fig5">Figure 5c</xref> plots the initial training period, with 10 trials prior to each interim test, <xref ref-type="fig" rid="fig5">Figure 5d</xref> shows the typicality gradient at the end of this training, and <xref ref-type="fig" rid="fig5">Figure 5e</xref> shows generalization behavior over a longer training period, broken down by pathway. As in the prior simulations, the MSP-only network excelled in generalization, outperforming the intact network by the end of training across all typicality levels. The TSP-only network performed much worse, but still above chance, and was able to generalize quite well for highly prototypical items. All main effects and interactions were significant (p<italic><sub>s</sub></italic>&lt;0.001).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Simulation 3: intermixed categories with varying typicality.</title><p>Human generalization across (<bold>a</bold>) learning and (<bold>b</bold>) test, for varying levels of typicality, from Figure 3 in <xref ref-type="bibr" rid="bib6">Bowman et al., 2020</xref>. Intact model generalization across (<bold>c</bold>) learning, with 10 trials prior to each interim test, and (<bold>d</bold>) at the end of learning. Source data can be found in <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>. (<bold>e</bold>) Model generalization broken down by typicality and model type. (<bold>f</bold>) Model atypical feature recognition broken down by typicality and model type. Source data can be found in <xref ref-type="supplementary-material" rid="fig5sdata2">Figure 5—source data 2</xref>. (<bold>g</bold>) Representational similarity for the initial and settled response of the intact network. Each item appears in the rows and columns of the heatmap, organized by most prototypical members of one category to most prototypical members of the other. Source data can be found in <xref ref-type="supplementary-material" rid="fig5sdata3">Figure 5—source data 3</xref>.</p><p><supplementary-material id="fig5scode1"><label>Figure 5—source code 1.</label><caption><title>R code used to generate <xref ref-type="fig" rid="fig5">Figure 5</xref> panels.</title></caption><media mimetype="application" mime-subtype="zip" xlink:href="elife-77185-fig5-code1-v1.zip"/></supplementary-material></p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Data corresponding to <xref ref-type="fig" rid="fig5">Figure 5c, d</xref>.</title></caption><media mimetype="application" mime-subtype="octet-stream" xlink:href="elife-77185-fig5-data1-v1.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata2"><label>Figure 5—source data 2.</label><caption><title>Data corresponding to <xref ref-type="fig" rid="fig5">Figure 5e, f</xref>.</title></caption><media mimetype="application" mime-subtype="octet-stream" xlink:href="elife-77185-fig5-data2-v1.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata3"><label>Figure 5—source data 3.</label><caption><title>Correlation values for representational similarity analysis heatmaps in <xref ref-type="fig" rid="fig5">Figure 5g</xref>.</title></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-77185-fig5-data3-v1.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77185-fig5-v1.tif"/></fig><p>Atypical feature recognition was assessed by testing the ability to activate the correct atypical features in the output layer when presented with trained category exemplars. For each item, we compared the activation of features that did not match the prototypical item (atypical features) to the total activation in the atypical units. The proportion of activation in the correct atypical features was compared against chance (0.1 for items that had only one atypical feature, 0.2 for items that had two atypical features, etc.). As shown in <xref ref-type="fig" rid="fig5">Figure 5f</xref>, the intact network generally showed good atypical feature recognition performance. The level of recognition accuracy depended on the level of similarity of the item to its prototype. Atypical features of less typical category members were recognized more easily than atypical features for items very similar to the prototype. Unlike prior simulations, in this case the intact network exhibited better performance than the lesioned networks, suggesting that this task benefits from having both pathways intact. The TSP-only network performed better than the MSP-only network, which was virtually unable to recognize atypical category members (three or four atypical features), but showed somewhat better performance on items more similar to the prototype (one or two atypical features). The MSP can thus contribute to atypical feature memory to some extent, when the item is overall very similar to the prototype. The more arbitrary the item, the more the TSP is needed. Even for arbitrary items, though, the TSP benefited from the presence of the MSP (as indicated by higher performance for the intact network), suggesting that this may be a situation where the MSP plays an important supportive function. Initial below-chance performance for the exemplars with only one atypical feature reflects the tendency to pattern-complete these items to the highly similar prototype. Effects of lesion, time, number of shared features, and their interactions were all significant (p<italic><sub>s</sub></italic>&lt;0.001).</p><p>Visualization of the internal representations of the model after training provides insight into the behaviors of the two pathways. <xref ref-type="fig" rid="fig5">Figure 5g</xref> shows the similarity of the evoked activity of the items in this domain, with items arranged from most prototypical members of one category to most prototypical members of the other. As in the prior simulations, DG and CA3 represented the items more distinctly than CA1, and settled activity after big-loop recurrence increased similarity, especially in CA1. This simulation was unique, however, in that DG and CA3 showed clear similarity structure for the prototype and highly prototypical items. There is a limit to the pattern separation abilities of the TSP, and these highly similar items exceeded that limit. This explains why, at high typicality levels, the TSP could be quite successful on its own in generalization (<xref ref-type="fig" rid="fig5">Figure 5e</xref>), and why it struggled with atypical feature recognition for these items (<xref ref-type="fig" rid="fig5">Figure 5f</xref>).</p><p>Overall, the results from Simulation 3 are convergent with those from Simulations 1 and 2, with the TSP contributing more to recognition than categorization and the MSP contributing more to categorization than recognition. As in the satellite simulation, there was a clear trade-off across pathways in categorization behavior, with the MSP-only network performing better without the influence of the TSP. The recognition results showed an interesting new dimension of behavior as a function of exemplar typicality: the TSP is better than the MSP at remembering the unique features of more atypical exemplars. The more features an exemplar has that depart from the category prototype, the more important the arbitrary binding ability of the TSP.</p></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>We found that a neural network model of the hippocampus was readily able to learn three different types of categories, providing an account of how the hippocampus may contribute to category learning. Across paradigms, the MSP specialized in detecting the regularities that define category structure. Lower sparsity in this pathway enables overlapping, distributed representations (<xref ref-type="bibr" rid="bib20">Hinton, 1984</xref>), which facilitate the detection of commonalities across exemplars, and a relatively lower learning rate helps to integrate this information over time. After learning, representations of items from the same category were more similar than items from different categories. This was driven by and especially true in subfield CA1, consistent with our prior fMRI finding that CA1 shows stronger within-category representational similarity (<xref ref-type="bibr" rid="bib76">Schapiro et al., 2018</xref>). The work thus demonstrates that the principles that allowed C-HORSE to detect regularities in structured temporal input (<xref ref-type="bibr" rid="bib75">Schapiro et al., 2017b</xref>) apply more broadly to detecting regularities in multidimensional category spaces. The fact that one model accounts for findings across these paradigms points to domain-general principles in the operations the hippocampus is engaged in to extract related information across experiences.</p><p>In contrast to the MSP’s capacity for detecting shared structure and generalizing, the main contribution of the TSP to category learning was encoding the distinguishing information about individual category exemplars. Higher sparsity in this pathway allowed the TSP to orthogonalize similar inputs and encode the details of individual exemplars. The ability to quickly bind together arbitrary information that is so useful for episodic memory (e.g., <xref ref-type="bibr" rid="bib52">Norman and O’Reilly, 2003</xref>) translates into a specialization for remembering the arbitrary details of individual exemplars in the domain of category learning. This ability proved especially useful for atypical exemplars. Lesioning the TSP resulted in poor recognition with preserved categorization ability. Consistent with these behaviors, a recent study found that TSP white matter integrity predicts the ability to learn category exceptions (<xref ref-type="bibr" rid="bib78">Schlichting et al., 2021</xref>). We thus propose that the properties of the TSP should make it useful beyond its traditional domain of episodic memory—it should contribute to any rapid new learning that requires memory for arbitrary, as opposed to systematic, information.</p><sec id="s4-1"><title>Relationship to other models of categorization</title><p>Our goal was to take a model with an architecture inspired by the anatomy and properties of the hippocampus and explore how it might accomplish category learning. While we did not endeavor to build in any particular strategies, the emergent behaviors of the model bear resemblance to existing psychological models of categorization. The model thus provides a bridge across levels of analysis, showing how neurobiological mechanisms may give rise to some of the more abstract operations of existing models.</p><p>The classic exemplar model proposes that people store memory representations of individual category instances and perform similarity judgments on these separate representations at test in order to come to a categorization decision (<xref ref-type="bibr" rid="bib47">Medin and Schaffer, 1978</xref>; <xref ref-type="bibr" rid="bib57">Nosofsky, 2011</xref>; <xref ref-type="bibr" rid="bib56">Nosofsky and Johansen, 2000</xref>). This model has been successful in accounting for many findings across categorization and recognition paradigms (<xref ref-type="bibr" rid="bib53">Nosofsky, 1988</xref>; <xref ref-type="bibr" rid="bib54">Nosofsky, 1991</xref>; <xref ref-type="bibr" rid="bib55">Nosofsky and Zaki, 1998</xref>; <xref ref-type="bibr" rid="bib61">Palmeri, 1997</xref>). The TSP of our model is similar to the exemplar model in that it stores separate traces of individual exemplars. In fact, our model provides an account of how a neural circuit might implement exemplar-style representations: the sparsity-inducing machinery that leads to pattern separation of individual episodic memories in the TSP similarly leads to pattern separation across exemplars. The consequence in our model is high fidelity memory for the details of particular exemplars. Unlike the exemplar model, however, our model’s TSP exhibited relatively poor categorization. There may be modifications to the model that would allow the TSP to behave more like an exemplar model. For example, the present version of the model does not modulate the influence of the DG during encoding and retrieval, but it is possible that reducing the influence of DG during retrieval would bias the TSP toward pattern completion at test (<xref ref-type="bibr" rid="bib36">Lee and Kesner, 2004</xref>; <xref ref-type="bibr" rid="bib68">Rolls, 1995</xref>; <xref ref-type="bibr" rid="bib69">Rolls, 2018</xref>), which might enhance certain kinds of categorization. REMERGE (<xref ref-type="bibr" rid="bib34">Kumaran and McClelland, 2012</xref>) is a model of how the hippocampus might support inference and generalization that relies on pattern separated, conjunctive representations, as in our TSP. The model can accomplish categorization in a manner closely analogous to exemplar models (<xref ref-type="bibr" rid="bib34">Kumaran and McClelland, 2012</xref>, Appendix), suggesting that there may indeed be ways to increase the categorization ability of a TSP-style representation. Regardless, and across these models, the unique expertise of the TSP-style representation is in its ability to retain the details of individual exemplars.</p><p>The classic prototype model postulates that categories are represented by the central tendency across exemplars in a category, without retaining traces of the individual observed exemplars (<xref ref-type="bibr" rid="bib50">Minda and Smith, 2011</xref>). The prototype model explains categorization behavior well in the context of well-defined, high-coherence categories (<xref ref-type="bibr" rid="bib7">Bowman and Zeithamova, 2020</xref>; <xref ref-type="bibr" rid="bib49">Minda and Smith, 2001</xref>). The MSP of our model behaves similarly to a prototype model in that it tends to abstract across the details of individual exemplars and represent the central tendency. However, this is not true in an absolute sense—the representation in the MSP is sensitive to individual exemplars to some extent.</p><p><xref ref-type="bibr" rid="bib45">McClelland and Rumelhart, 1985</xref> showed how specifics and generalities can coexist in a neural network model with distributed representations. Our MSP uses distributed representations and shows some degree of this dual sensitivity. However, there is a tension between the representation of specifics and generalities in the way that the hidden layers in our model behave. In a hidden layer with very large capacity and a very slow learning rate, distributed internal representations can be carefully and gradually shaped to faithfully reflect the statistics of the environment, which can include representation of both arbitrary and systematic information, to the extent that each is present in the input. Neocortical areas of the brain likely have this property of representing arbitrary and general information in harmonious superposition, as in the representations described by <xref ref-type="bibr" rid="bib45">McClelland and Rumelhart, 1985</xref>. But in the case of our hippocampal system, capacity is somewhat more limited and, critically, learning rates are necessarily fast, in order to support behavior on the timescale of a few minutes to hours. The fast learning rate appears to force trade-offs: representations can either tend to emphasize the specifics or the generalities.</p><p>Our model assumes that every item is encoded in two different ways, with one representation focusing on its details, separating it from other similar items, and the other glossing over the details, emphasizing its similarity to other items. This idea is consistent with neuroimaging data showing coexisting neural representations that are more prototype- and exemplar-like (<xref ref-type="bibr" rid="bib6">Bowman et al., 2020</xref>). This perspective avoids the kind of discrete category decision-making that occurs in a category learning model like SUSTAIN, where a new exemplar either merges with an existing category or separates into a new one (<xref ref-type="bibr" rid="bib39">Love et al., 2004</xref>). We propose that the brain may have it both ways, solving the tension between representing details and generalities by maintaining both representations in parallel. The solution is closely analogous to that proposed by the Complementary Learning Systems theory, which argued that the hippocampus and neocortex take on complementary roles in memory for encoding the specifics of new items and generalizing across them over time (<xref ref-type="bibr" rid="bib46">McClelland et al., 1995</xref>). The MSP in our model has properties similar to the neocortex in that framework, with relatively more overlapping representations and a relatively slower learning rate, allowing it to behave as a miniature semantic memory system. The TSP and MSP in our model are thus a microcosm of the broader Complementary Learning Systems dynamic, with the MSP playing the role of a <italic>rapid</italic> learner of novel semantics, relative to the slower learning of neocortex.</p><p>There are many models of category learning in the literature, including neural network models, that would likely exhibit behavior closely analogous to our model’s MSP. Our goal here is not to claim that our model better fits empirical data than existing models, but rather to provide a proof-of-concept demonstration of how the computations of hippocampal subregions may give rise to different components of category learning. Detailed comparison of the model’s behavior to other models in the literature will be valuable in evaluating and refining the model, however, and will be an important goal for future work.</p></sec><sec id="s4-2"><title>Coordinating the contributions of the MSP and TSP</title><p>Having two different representations of the same item leads to a problem at retrieval: which representation should be used? In our current work, we have assumed that both representations contribute, and the retrieved information reflects some blending of the two. But in many cases, there is a trade-off in the relevance and utility of the representations, depending on the task. Such trade-offs between representing specifics and regularities have been documented in the literature (e.g., <xref ref-type="bibr" rid="bib80">Sherman and Turk-Browne, 2020</xref>). We found several cases of trade-offs playing out in our simulations; for example, generalization in the satellite categories is strong in the intact model, which uses both pathways, but much stronger in the version of the model that only uses the MSP. This suggests that a control mechanism that enhances one pathway over another depending on the task would be beneficial for behavior. In a recent paper, we adopted a version of C-HORSE that invoked such a control function in order to explain behavior across tasks with different demands in an associative inference paradigm (<xref ref-type="bibr" rid="bib91">Zhou et al., 2023</xref>). Medial prefrontal cortex could potentially carry out a control function of this kind (<xref ref-type="bibr" rid="bib81">Sherman et al., 2023</xref>), as it participates in category learning (<xref ref-type="bibr" rid="bib42">Mack et al., 2020</xref>) and is known to modulate CA1 representations as a function of task (<xref ref-type="bibr" rid="bib10">Eichenbaum, 2017</xref>; <xref ref-type="bibr" rid="bib17">Guise and Shapiro, 2017</xref>). As the TSP and MSP are both routed through CA1, medial prefrontal control over CA1 could conceivably help coordinate information flow there for optimal behavior. This will be an interesting hypothesis to explore in future modeling and empirical work.</p></sec><sec id="s4-3"><title>Hippocampal maturation and development of categorization abilities</title><p>In humans, the hippocampus has a protracted development, with hippocampal subfields exhibiting different maturation rates (<xref ref-type="bibr" rid="bib35">Lavenex and Banta Lavenex, 2013</xref>). While the CA1 subfield develops during the first two years of life and reaches adult-like volume around two years, the DG and CA3 subfields develop at a slower pace (<xref ref-type="bibr" rid="bib4">Bachevalier, 2013</xref>; <xref ref-type="bibr" rid="bib15">Gómez and Edgin, 2016</xref>; <xref ref-type="bibr" rid="bib35">Lavenex and Banta Lavenex, 2013</xref>). The projection from EC to CA1 (the MSP), develops prior to the projection from EC to DG in the TSP (<xref ref-type="bibr" rid="bib19">Hevner and Kinney, 1996</xref>; <xref ref-type="bibr" rid="bib21">Jabès et al., 2011</xref>). Given the MSP’s role in detecting regularities, early maturation of CA1 suggests that the ability to detect regularities should emerge early in development. Indeed, even before their first birthday infants show evidence of categorization (<xref ref-type="bibr" rid="bib11">Eimas and Quinn, 1994</xref>; <xref ref-type="bibr" rid="bib43">Mareschal and Quinn, 2001</xref>; <xref ref-type="bibr" rid="bib84">Younger and Cohen, 1983</xref>) and statistical learning abilities (<xref ref-type="bibr" rid="bib13">Fiser and Aslin, 2002</xref>; <xref ref-type="bibr" rid="bib26">Kirkham et al., 2002</xref>; <xref ref-type="bibr" rid="bib70">Saffran et al., 1996</xref>). There is evidence for involvement of the anterior hippocampus in statistical learning as young as three months (<xref ref-type="bibr" rid="bib12">Ellis et al., 2021</xref>). Our model predicts that children with immature TSPs should struggle with learning categories with more atypical exemplars or arbitrary features and should have poor memory for category exceptions. In line with these predictions, infants struggle to learn low coherence categories (<xref ref-type="bibr" rid="bib14">Gómez and Lakusta, 2004</xref>; <xref ref-type="bibr" rid="bib86">Younger, 1990</xref>; <xref ref-type="bibr" rid="bib85">Younger and Gotlieb, 1988</xref>), and young children demonstrate poorer memory for exceptions than typical category members (<xref ref-type="bibr" rid="bib71">Savic and Sloutsky, 2019</xref>). Our model may resolve the puzzle in the developmental literature about the discrepancy between infants’ precocious performance on categorization tasks, on the one hand, and poor episodic memory abilities, on the other hand (<xref ref-type="bibr" rid="bib22">Keresztes et al., 2018</xref>). To the extent that infants have access only to the MSP, our model predicts poor recognition performance (especially for atypical category instances) but intact categorization and even enhanced generalization. A fully operating basic hippocampal circuitry is eventually needed for learning low-coherence categories and for mature episodic memory functions which emerge later in development (<xref ref-type="bibr" rid="bib15">Gómez and Edgin, 2016</xref>).</p></sec><sec id="s4-4"><title>Neuropsychological accounts of hippocampal contributions to category learning</title><p>Initial accounts of the role of the hippocampus in category learning came from studies of patients with MTL damage. Patients have been tested on a range of category learning tasks, including random dot patterns, probabilistic categories, faces, scenes, and painting categorization (<xref ref-type="bibr" rid="bib23">Kéri et al., 2001</xref>; <xref ref-type="bibr" rid="bib27">Knowlton and Squire, 1993</xref>; <xref ref-type="bibr" rid="bib30">Kolodny, 1994</xref>; <xref ref-type="bibr" rid="bib66">Reber et al., 1996</xref>; <xref ref-type="bibr" rid="bib67">Reed et al., 1999</xref>; <xref ref-type="bibr" rid="bib87">Zaki et al., 2003</xref>). <xref ref-type="bibr" rid="bib27">Knowlton and Squire, 1993</xref> tested amnesics’ ability to learn abstract novel categories of random dot patterns and observed similar categorization performance as in healthy controls, but impaired recognition, leading to the proposal that the MTL is not involved in category learning. However, amnesics do show impairment on a more difficult version of this task (learning categories A vs. B, as opposed to simply A vs. not-A; <xref ref-type="bibr" rid="bib87">Zaki et al., 2003</xref>). Amnesics are also impaired on categorizing paintings by artist (<xref ref-type="bibr" rid="bib30">Kolodny, 1994</xref>), and while they succeed in a categorization task with faces, they fail with scenes (<xref ref-type="bibr" rid="bib16">Graham et al., 2006</xref>). Alzheimer’s patients also show intact performance on the A/not-A task (<xref ref-type="bibr" rid="bib23">Kéri et al., 2001</xref>; <xref ref-type="bibr" rid="bib87">Zaki et al., 2003</xref>) but poor performance on the A/B task (<xref ref-type="bibr" rid="bib87">Zaki et al., 2003</xref>), and categorization performance deteriorates as the disease progresses (<xref ref-type="bibr" rid="bib23">Kéri et al., 2001</xref>). Rats with hippocampal damage also show impaired visual categorization (<xref ref-type="bibr" rid="bib25">Kim et al., 2018</xref>). Overall, MTL damage leaves some ability to learn novel categories, indicating that the hippocampus is not the only region involved in category learning, but also creates clear deficits, especially when aggregating evidence across studies (<xref ref-type="bibr" rid="bib88">Zaki, 2004</xref>), indicating that the hippocampus makes a causal contribution. Our proposal is that the MSP is responsible for that hippocampal contribution. This predicts that patients with specific TSP damage should be unimpaired in category learning, consistent with recent evidence of preserved statistical learning performance in a patient with specific DG damage (<xref ref-type="bibr" rid="bib83">Wang et al., 2023</xref>).</p></sec><sec id="s4-5"><title>Neural evidence of hippocampal involvement in category learning</title><p>Neuroimaging studies provide strong additional evidence for hippocampal involvement in category learning and generalization (<xref ref-type="bibr" rid="bib5">Bowman and Zeithamova, 2018</xref>; <xref ref-type="bibr" rid="bib33">Kumaran et al., 2009</xref>; <xref ref-type="bibr" rid="bib40">Mack et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Mack et al., 2018</xref>; <xref ref-type="bibr" rid="bib42">Mack et al., 2020</xref>; <xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>). There is also a neurophysiological literature on concept / category representation in the human hippocampus, with demonstrations of cells that respond similarly to distinct instantiations of a particular concept (e.g., Jennifer Aniston; <xref ref-type="bibr" rid="bib64">Quiroga et al., 2005</xref>) and cells that respond invariantly across exemplars of higher level categories (e.g., faces; <xref ref-type="bibr" rid="bib32">Kreiman et al., 2000</xref>). These findings are consistent with our proposal that the hippocampus contains representations that exhibit invariance across exemplars. Hippocampal subfields have not generally been investigated directly in neural studies of category learning, with one exception being our finding that CA1 but not CA3/DG represented category structure in the satellite stimuli (<xref ref-type="bibr" rid="bib76">Schapiro et al., 2018</xref>). However, anterior hippocampus has a much larger proportion of the CA1 subfield than posterior hippocampus in humans (<xref ref-type="bibr" rid="bib63">Poppenk et al., 2013</xref>; <xref ref-type="bibr" rid="bib8">Dalton et al., 2019</xref>), so our account predicts that anterior hippocampus should preferentially reflect the learning of category structure. Indeed, several studies have found that activation in the anterior hippocampus is related to category learning (<xref ref-type="bibr" rid="bib40">Mack et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Mack et al., 2018</xref>; <xref ref-type="bibr" rid="bib89">Zeithamova et al., 2008</xref>) and to prototype-style learning specifically (<xref ref-type="bibr" rid="bib5">Bowman and Zeithamova, 2018</xref>). Further, activation in the hippocampal body and tail is associated with learning categories that involve exceptions (<xref ref-type="bibr" rid="bib9">Davis et al., 2012</xref>), which is also consistent with the finding that TSP white matter integrity predicts exception learning (<xref ref-type="bibr" rid="bib78">Schlichting et al., 2021</xref>). There are many differences, however, between anterior and posterior hippocampus apart from subfield ratios (e.g., differential connectivity and tuning to spatial scale), so future work will be needed to more directly test these connections between subfield properties and the properties of anterior and posterior hippocampus.</p></sec><sec id="s4-6"><title>Recruitment of multiple neural systems during rapid category learning</title><p>As described above, we know that the hippocampus is not the only region contributing to category learning, with the basal ganglia and various regions of the neocortex known to be critically involved (<xref ref-type="bibr" rid="bib2">Ashby and Maddox, 2005</xref>; <xref ref-type="bibr" rid="bib79">Seger and Miller, 2010</xref>). While the hippocampus and basal ganglia seem especially important for rapid category learning, on the timescale of minutes to hours, most cortical regions likely support slower learning, across days, weeks, and months (<xref ref-type="bibr" rid="bib79">Seger and Miller, 2010</xref>). An important exception is the prefrontal cortex, which is critical for certain kinds of rapid category learning, especially when working memory is required (<xref ref-type="bibr" rid="bib3">Ashby and O’Brien, 2005</xref>). The involvement of the hippocampus relative to basal ganglia seems to hinge in part on the presence of feedback. The feedback version of the Weather Prediction Task preferentially engages the basal ganglia, whereas the observational version engages the MTL (<xref ref-type="bibr" rid="bib62">Poldrack et al., 2001</xref>), and patients with Parkinson’s disease (affecting basal ganglia function) show deficits in the feedback version but preserved performance in the observational version (<xref ref-type="bibr" rid="bib82">Shohamy et al., 2004</xref>). Our view, based on these findings as well as literatures outside the domain of category learning, is that the hippocampus (and the MSP in particular) should be especially important in situations that involve more neutral, observational learning, with less motor response, feedback, or reward. Our current model has provided an account of the potential isolated contributions of the hippocampus to category learning, and future extensions should explore interactions with the basal ganglia, prefrontal cortex, and other cortical areas.</p></sec><sec id="s4-7"><title>Conclusions</title><p>We have put forward an account of the possible contributions of the hippocampus to rapid, novel category learning. We propose that the TSP, known for its rapid binding and pattern separation computations, contributes to remembering the arbitrary aspects of categories—the specifics or atypical aspects of individual exemplars or observations. The MSP, with a relatively slower learning rate and more distributed representations, contributes to learning the systematic aspects of categories—the structure shared across category exemplars. This proposal for two systems within the hippocampus with complementary expertise makes specific predictions. First, the neural responses to exemplars from the same category should tend to be more similar in CA1 than in CA3 and DG. This should be especially true immediately after presentation of a stimulus, as the circuit is recurrent, so information in CA1 can spread through EC back to DG and CA3 with more processing time (e.g., as in <xref ref-type="fig" rid="fig3">Figure 3f</xref>). Second, variation in the integrity of the two pathways—through individual differences, development, aging, psychiatric disorders, or neurological disease—should have differential behavioral consequences. Disruptions to TSP function should result in poor memory for specific, arbitrary features of exemplars but preserved memory for structure shared across exemplars, whereas disruptions to MSP function should result in poor memory for shared structure and relatively preserved memory for specifics. We predict behavioral consequences to be stronger in paradigms that involve more passive, observational learning, as the basal ganglia is more likely to be able to pick up the slack in tasks involving motor responses and feedback. There are several empirical datapoints that already fit these predictions, including category-related similarity structure in CA1 (<xref ref-type="bibr" rid="bib73">Schapiro et al., 2016</xref>), TSP white matter integrity predicting exception learning (<xref ref-type="bibr" rid="bib78">Schlichting et al., 2021</xref>), and behavioral exception learning that unfolds in accordance with MSP and TSP properties (<xref ref-type="bibr" rid="bib18">Heffernan et al., 2021</xref>). But more work is needed to establish the extent to which this account correctly characterizes the contribution of the hippocampus to category learning. We hope this work inspires new theoretically diagnostic empirical studies as well as further model development.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Supplementary material includes input pattern and parameter details.</title></caption><media xlink:href="elife-77185-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-77185-transrepform1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no empirical data have been generated for this manuscript. The model is available on <ext-link ext-link-type="uri" xlink:href="https://github.com/schapirolab/hip-cat">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib77">Schapiro Lab, 2022</xref>). Source data and source code for Figures 3, 4 and 5 are provided.</p></sec><ack id="ack"><title>Acknowledgements</title><p>We are grateful to Siri Krishnamurthy, Brynn Sherman, and Dhairyya Singh for helpful discussions and assistance. This work was supported by a St Hugh’s College Travel Grant, University of Oxford to JS, and Charles E Kaufman Foundation KA2020-114800 to ACS.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aisa</surname><given-names>B</given-names></name><name><surname>Mingus</surname><given-names>B</given-names></name><name><surname>O’Reilly</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The emergent neural modeling system</article-title><source>Neural Networks</source><volume>21</volume><fpage>1146</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2008.06.016</pub-id><pub-id pub-id-type="pmid">18684591</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>Maddox</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Human category learning</article-title><source>Annual Review of Psychology</source><volume>56</volume><fpage>149</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.56.091103.070217</pub-id><pub-id pub-id-type="pmid">15709932</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>O’Brien</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Category learning and multiple memory systems</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>83</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.12.003</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bachevalier</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><chapter-title>The development of memory from a Neurocognitive and comparative perspective</chapter-title><person-group person-group-type="editor"><name><surname>Bauer</surname><given-names>PJ</given-names></name><name><surname>Fivush</surname><given-names>R</given-names></name></person-group><source>The Wiley Handbook on the Development of Children’s Memory</source><publisher-name>Wiley-Blackwell</publisher-name><fpage>109</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1002/9781118597705</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>CR</given-names></name><name><surname>Zeithamova</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Abstract memory representations in the ventromedial prefrontal cortex and hippocampus support concept generalization</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>2605</fpage><lpage>2614</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2811-17.2018</pub-id><pub-id pub-id-type="pmid">29437891</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>CR</given-names></name><name><surname>Iwashita</surname><given-names>T</given-names></name><name><surname>Zeithamova</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Tracking prototype and exemplar representations in the brain across learning</article-title><source>eLife</source><volume>9</volume><elocation-id>e59360</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.59360</pub-id><pub-id pub-id-type="pmid">33241999</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bowman</surname><given-names>CR</given-names></name><name><surname>Zeithamova</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Training set coherence and set size effects on concept generalization and recognition</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>46</volume><fpage>1442</fpage><lpage>1464</lpage><pub-id pub-id-type="doi">10.1037/xlm0000824</pub-id><pub-id pub-id-type="pmid">32105147</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalton</surname><given-names>MA</given-names></name><name><surname>McCormick</surname><given-names>C</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Differences in functional connectivity along the anterior-posterior axis of human hippocampal subfields</article-title><source>NeuroImage</source><volume>192</volume><fpage>38</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.02.066</pub-id><pub-id pub-id-type="pmid">30840906</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>T</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Learning the exception to the rule: model-based FMRI reveals specialized representations for surprising category members</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>260</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr036</pub-id><pub-id pub-id-type="pmid">21666132</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>On the integration of space, time, and memory</article-title><source>Neuron</source><volume>95</volume><fpage>1007</fpage><lpage>1018</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.036</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eimas</surname><given-names>PD</given-names></name><name><surname>Quinn</surname><given-names>PC</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Studies on the formation of perceptually based basic-level categories in young infants</article-title><source>Child Development</source><volume>65</volume><fpage>903</fpage><lpage>917</lpage><pub-id pub-id-type="doi">10.2307/1131427</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ellis</surname><given-names>CT</given-names></name><name><surname>Skalaban</surname><given-names>LJ</given-names></name><name><surname>Yates</surname><given-names>TS</given-names></name><name><surname>Bejjanki</surname><given-names>VR</given-names></name><name><surname>Córdova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Evidence of hippocampal learning in human infants</article-title><source>Current Biology</source><volume>31</volume><fpage>3358</fpage><lpage>3364</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.04.072</pub-id><pub-id pub-id-type="pmid">34022155</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname><given-names>J</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Statistical learning of new visual feature combinations by infants</article-title><source>PNAS</source><volume>99</volume><fpage>15822</fpage><lpage>15826</lpage><pub-id pub-id-type="doi">10.1073/pnas.232472899</pub-id><pub-id pub-id-type="pmid">12429858</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gómez</surname><given-names>RL</given-names></name><name><surname>Lakusta</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A first step in form-based category abstraction by 12-month-old infants</article-title><source>Developmental Science</source><volume>7</volume><fpage>567</fpage><lpage>580</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2004.00381.x</pub-id><pub-id pub-id-type="pmid">15603290</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gómez</surname><given-names>RL</given-names></name><name><surname>Edgin</surname><given-names>JO</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The extended trajectory of hippocampal development: Implications for early memory development and disorder</article-title><source>Developmental Cognitive Neuroscience</source><volume>18</volume><fpage>57</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2015.08.009</pub-id><pub-id pub-id-type="pmid">26437910</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graham</surname><given-names>KS</given-names></name><name><surname>Scahill</surname><given-names>VL</given-names></name><name><surname>Hornberger</surname><given-names>M</given-names></name><name><surname>Barense</surname><given-names>MD</given-names></name><name><surname>Lee</surname><given-names>ACH</given-names></name><name><surname>Bussey</surname><given-names>TJ</given-names></name><name><surname>Saksida</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Abnormal categorization and perceptual learning in patients with hippocampal damage</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>7547</fpage><lpage>7554</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1535-06.2006</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guise</surname><given-names>KG</given-names></name><name><surname>Shapiro</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Medial prefrontal cortex reduces memory interference by modifying hippocampal encoding</article-title><source>Neuron</source><volume>94</volume><fpage>183</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.011</pub-id><pub-id pub-id-type="pmid">28343868</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heffernan</surname><given-names>EM</given-names></name><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Mack</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning exceptions to the rule in human and model via hippocampal encoding</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>21429</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-00864-9</pub-id><pub-id pub-id-type="pmid">34728698</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hevner</surname><given-names>RF</given-names></name><name><surname>Kinney</surname><given-names>HC</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Reciprocal entorhinal-hippocampal connections established by human fetal midgestation</article-title><source>The Journal of Comparative Neurology</source><volume>372</volume><fpage>384</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19960826)372:3&lt;384::AID-CNE4&gt;3.0.CO;2-Z</pub-id><pub-id pub-id-type="pmid">8873867</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1984">1984</year><source>Distributed Representations</source><publisher-name>Carnegie-Mellon University</publisher-name></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jabès</surname><given-names>A</given-names></name><name><surname>Lavenex</surname><given-names>PB</given-names></name><name><surname>Amaral</surname><given-names>DG</given-names></name><name><surname>Lavenex</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Postnatal development of the hippocampal formation: a stereological study in macaque monkeys</article-title><source>The Journal of Comparative Neurology</source><volume>519</volume><fpage>1051</fpage><lpage>1070</lpage><pub-id pub-id-type="doi">10.1002/cne.22549</pub-id><pub-id pub-id-type="pmid">21344402</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keresztes</surname><given-names>A</given-names></name><name><surname>Ngo</surname><given-names>CT</given-names></name><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>Werkle-Bergner</surname><given-names>M</given-names></name><name><surname>Newcombe</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hippocampal maturation drives memory from generalization to specificity</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>676</fpage><lpage>686</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.05.004</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kéri</surname><given-names>S</given-names></name><name><surname>Kálmán</surname><given-names>J</given-names></name><name><surname>Kelemen</surname><given-names>O</given-names></name><name><surname>Benedek</surname><given-names>G</given-names></name><name><surname>Janka</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Are Alzheimer’s disease patients able to learn visual prototypes?</article-title><source>Neuropsychologia</source><volume>39</volume><fpage>1218</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1016/s0028-3932(01)00046-x</pub-id><pub-id pub-id-type="pmid">11527559</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ketz</surname><given-names>N</given-names></name><name><surname>Morkonda</surname><given-names>SG</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Theta coordinated error-driven learning in the hippocampus</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003067</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003067</pub-id><pub-id pub-id-type="pmid">23762019</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Castro</surname><given-names>L</given-names></name><name><surname>Wasserman</surname><given-names>EA</given-names></name><name><surname>Freeman</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dorsal hippocampus is necessary for visual categorization in rats</article-title><source>Hippocampus</source><volume>28</volume><fpage>392</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1002/hipo.22839</pub-id><pub-id pub-id-type="pmid">29473984</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kirkham</surname><given-names>NZ</given-names></name><name><surname>Slemmer</surname><given-names>JA</given-names></name><name><surname>Johnson</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Visual statistical learning in infancy: evidence for a domain general learning mechanism</article-title><source>Cognition</source><volume>83</volume><fpage>B35</fpage><lpage>B42</lpage><pub-id pub-id-type="doi">10.1016/s0010-0277(02)00004-5</pub-id><pub-id pub-id-type="pmid">11869728</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The learning of categories: parallel brain systems for item memory and category knowledge</article-title><source>Science</source><volume>262</volume><fpage>1747</fpage><lpage>1749</lpage><pub-id pub-id-type="doi">10.1126/science.8259522</pub-id><pub-id pub-id-type="pmid">8259522</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Probabilistic classification learning in amnesia</article-title><source>Learning &amp; Memory</source><volume>1</volume><fpage>106</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1101/lm.1.2.106</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Mangels</surname><given-names>JA</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A neostriatal habit learning system in humans</article-title><source>Science</source><volume>273</volume><fpage>1399</fpage><lpage>1402</lpage><pub-id pub-id-type="doi">10.1126/science.273.5280.1399</pub-id><pub-id pub-id-type="pmid">8703077</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolodny</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Memory processes in classification learning: an investigation of amnesic performance in categorization of dot patterns and artistic styles</article-title><source>Psychological Science</source><volume>5</volume><fpage>164</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.1994.tb00654.x</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koster</surname><given-names>R</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Berron</surname><given-names>D</given-names></name><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Big-loop recurrence within the hippocampal system supports integration of information across episodes</article-title><source>Neuron</source><volume>99</volume><fpage>1342</fpage><lpage>1354</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.08.009</pub-id><pub-id pub-id-type="pmid">30236285</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Category-specific visual responses of single neurons in the human medial temporal lobe</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>946</fpage><lpage>953</lpage><pub-id pub-id-type="doi">10.1038/78868</pub-id><pub-id pub-id-type="pmid">10966627</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Summerfield</surname><given-names>JJ</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Tracking the emergence of conceptual knowledge during human decision making</article-title><source>Neuron</source><volume>63</volume><fpage>889</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.030</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Generalization through the recurrent interaction of episodic memories: a model of the hippocampal system</article-title><source>Psychological Review</source><volume>119</volume><fpage>573</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1037/a0028681</pub-id><pub-id pub-id-type="pmid">22775499</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lavenex</surname><given-names>P</given-names></name><name><surname>Banta Lavenex</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Building hippocampal circuits to learn and remember: insights into the development of human memory</article-title><source>Behavioural Brain Research</source><volume>254</volume><fpage>8</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2013.02.007</pub-id><pub-id pub-id-type="pmid">23428745</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>I</given-names></name><name><surname>Kesner</surname><given-names>RP</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Encoding versus retrieval of spatial memory: double dissociation between the dentate gyrus and the perforant path inputs into CA3 in the dorsal hippocampus</article-title><source>Hippocampus</source><volume>14</volume><fpage>66</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1002/hipo.10167</pub-id><pub-id pub-id-type="pmid">15058484</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>I</given-names></name><name><surname>Rao</surname><given-names>G</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A double dissociation between hippocampal subfields: differential time course of CA3 and CA1 place cells for processing changed environments</article-title><source>Neuron</source><volume>42</volume><fpage>803</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.05.010</pub-id><pub-id pub-id-type="pmid">15182719</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Leutgeb</surname><given-names>JK</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Distinct ensemble codes in hippocampal areas CA3 and CA1</article-title><source>Science</source><volume>305</volume><fpage>1295</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1126/science.1100265</pub-id><pub-id pub-id-type="pmid">15272123</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Love</surname><given-names>BC</given-names></name><name><surname>Medin</surname><given-names>DL</given-names></name><name><surname>Gureckis</surname><given-names>TM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>SUSTAIN: A network model of category learning</article-title><source>Psychological Review</source><volume>111</volume><fpage>309</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.111.2.309</pub-id><pub-id pub-id-type="pmid">15065912</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mack</surname><given-names>ML</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dynamic updating of hippocampal object representations reflects new conceptual knowledge</article-title><source>PNAS</source><volume>113</volume><fpage>13203</fpage><lpage>13208</lpage><pub-id pub-id-type="doi">10.1073/pnas.1614048113</pub-id><pub-id pub-id-type="pmid">27803320</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mack</surname><given-names>ML</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Building concepts one episode at a time: The hippocampus and concept formation</article-title><source>Neuroscience Letters</source><volume>680</volume><fpage>31</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1016/j.neulet.2017.07.061</pub-id><pub-id pub-id-type="pmid">28801273</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mack</surname><given-names>ML</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Ventromedial prefrontal cortex compression during concept learning</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>46</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-13930-8</pub-id><pub-id pub-id-type="pmid">31911628</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mareschal</surname><given-names>D</given-names></name><name><surname>Quinn</surname><given-names>PC</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Categorization in infancy</article-title><source>Trends in Cognitive Sciences</source><volume>5</volume><fpage>443</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01752-6</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The representation of object concepts in the brain</article-title><source>Annual Review of Psychology</source><volume>58</volume><fpage>25</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.57.102904.190143</pub-id><pub-id pub-id-type="pmid">16968210</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Rumelhart</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Distributed memory and the representation of general and specific information</article-title><source>Journal of Experimental Psychology. General</source><volume>114</volume><fpage>159</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1037//0096-3445.114.2.159</pub-id><pub-id pub-id-type="pmid">3159828</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id><pub-id pub-id-type="pmid">7624455</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medin</surname><given-names>DL</given-names></name><name><surname>Schaffer</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Context theory of classification learning</article-title><source>Psychological Review</source><volume>85</volume><fpage>207</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.85.3.207</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Nieder</surname><given-names>A</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Wallis</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Neural correlates of categories and concepts</article-title><source>Current Opinion in Neurobiology</source><volume>13</volume><fpage>198</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1016/s0959-4388(03)00037-0</pub-id><pub-id pub-id-type="pmid">12744974</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Minda</surname><given-names>JP</given-names></name><name><surname>Smith</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Prototypes in category learning: The effects of category size, category structure, and stimulus complexity</article-title><source>Journal of Experimental Psychology</source><volume>27</volume><fpage>775</fpage><lpage>799</lpage><pub-id pub-id-type="doi">10.1037//0278-7393.27.3.775</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Minda</surname><given-names>JP</given-names></name><name><surname>Smith</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2011">2011</year><chapter-title>Prototype models of Categorization: basic formulation, predictions, and limitations</chapter-title><person-group person-group-type="editor"><name><surname>Pothos</surname><given-names>EM</given-names></name><name><surname>Wills</surname><given-names>AJ</given-names></name></person-group><source>Formal Approaches in Categorization</source><publisher-name>Cambridge University Press</publisher-name><fpage>40</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1017/CBO9780511921322.003</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakashiba</surname><given-names>T</given-names></name><name><surname>Young</surname><given-names>JZ</given-names></name><name><surname>McHugh</surname><given-names>TJ</given-names></name><name><surname>Buhl</surname><given-names>DL</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Transgenic inhibition of synaptic transmission reveals role of CA3 output in hippocampal learning</article-title><source>Science</source><volume>319</volume><fpage>1260</fpage><lpage>1264</lpage><pub-id pub-id-type="doi">10.1126/science.1151120</pub-id><pub-id pub-id-type="pmid">18218862</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Modeling hippocampal and neocortical contributions to recognition memory: A complementary-learning-systems approach</article-title><source>Psychological Review</source><volume>110</volume><fpage>611</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.110.4.611</pub-id><pub-id pub-id-type="pmid">14599236</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nosofsky</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Exemplar-based accounts of relations between classification, recognition, and typicality</article-title><source>Journal of Experimental Psychology</source><volume>14</volume><fpage>700</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.14.4.700</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nosofsky</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Tests of an exemplar model for relating perceptual classification and recognition memory</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>17</volume><fpage>3</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1037//0096-1523.17.1.3</pub-id><pub-id pub-id-type="pmid">1826320</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nosofsky</surname><given-names>RM</given-names></name><name><surname>Zaki</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Dissociations between categorization and recognition in amnesic and normal individuals: an exemplar-based interpretation</article-title><source>Psychological Science</source><volume>9</volume><fpage>247</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00051</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nosofsky</surname><given-names>RM</given-names></name><name><surname>Johansen</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Exemplar-based accounts of “multiple-system” phenomena in perceptual categorization</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>7</volume><fpage>375</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1007/BF03543066</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nosofsky</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2011">2011</year><chapter-title>The generalized context model: an exemplar model of classification</chapter-title><person-group person-group-type="editor"><name><surname>Pothos</surname><given-names>EM</given-names></name><name><surname>Wills</surname><given-names>AJ</given-names></name></person-group><source>Formal Approaches in Categorization</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>18</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1017/CBO9780511921322.002</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>RC</given-names></name><name><surname>Rudy</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Conjunctive representations in learning and memory: principles of cortical and hippocampal function</article-title><source>Psychological Review</source><volume>108</volume><fpage>311</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.108.2.311</pub-id><pub-id pub-id-type="pmid">11381832</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>R</given-names></name><name><surname>Rohrlich</surname><given-names>J</given-names></name><collab>androticus</collab><collab>apmon</collab><collab>thazy</collab></person-group><year iso-8601-date="2014">2014a</year><data-title>Emergent</data-title><version designator="7.0.1">7.0.1</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/emer/cemer">https://github.com/emer/cemer</ext-link></element-citation></ref><ref id="bib60"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>R</given-names></name><name><surname>Munakata</surname><given-names>Y</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014b</year><source>Computational Cognitive Neuroscience</source><publisher-name>CCNBook</publisher-name></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmeri</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Exemplar similarity and the development of automaticity</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>23</volume><fpage>324</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1037//0278-7393.23.2.324</pub-id><pub-id pub-id-type="pmid">9080007</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Clark</surname><given-names>J</given-names></name><name><surname>Paré-Blagoev</surname><given-names>EJ</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Creso Moyano</surname><given-names>J</given-names></name><name><surname>Myers</surname><given-names>C</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Interactive memory systems in the human brain</article-title><source>Nature</source><volume>414</volume><fpage>546</fpage><lpage>550</lpage><pub-id pub-id-type="doi">10.1038/35107080</pub-id><pub-id pub-id-type="pmid">11734855</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poppenk</surname><given-names>J</given-names></name><name><surname>Evensmoen</surname><given-names>HR</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-axis specialization of the human hippocampus</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>230</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.03.005</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Reddy</surname><given-names>L</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Invariant visual representation by single neurons in the human brain</article-title><source>Nature</source><volume>435</volume><fpage>1102</fpage><lpage>1107</lpage><pub-id pub-id-type="doi">10.1038/nature03687</pub-id><pub-id pub-id-type="pmid">15973409</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="software"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group><year iso-8601-date="2019">2019</year><data-title>R: A language and environment for statistical computing</data-title><publisher-loc>Vienna, Austria</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name><ext-link ext-link-type="uri" xlink:href="http://www.r-project.org">http://www.r-project.org</ext-link></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reber</surname><given-names>PJ</given-names></name><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Dissociable properties of memory systems: differences in the flexibility of declarative and nondeclarative knowledge</article-title><source>Behavioral Neuroscience</source><volume>110</volume><fpage>861</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.110.5.861</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reed</surname><given-names>JM</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name><name><surname>Patalano</surname><given-names>AL</given-names></name><name><surname>Smith</surname><given-names>EE</given-names></name><name><surname>Jonides</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Learning about categories that are defined by object-like stimuli despite impaired declarative memory</article-title><source>Behavioral Neuroscience</source><volume>113</volume><fpage>411</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.113.3.411</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>A model of the operation of the hippocampus and entorhinal cortex in memory</article-title><source>International Journal of Neural Systems</source><volume>6</volume><fpage>51</fpage><lpage>70</lpage></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The storage and recall of memories in the hippocampo-cortical system</article-title><source>Cell and Tissue Research</source><volume>373</volume><fpage>577</fpage><lpage>604</lpage><pub-id pub-id-type="doi">10.1007/s00441-017-2744-3</pub-id><pub-id pub-id-type="pmid">29218403</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saffran</surname><given-names>JR</given-names></name><name><surname>Aslin</surname><given-names>RN</given-names></name><name><surname>Newport</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Statistical learning by 8-month-old infants</article-title><source>Science</source><volume>274</volume><fpage>1926</fpage><lpage>1928</lpage><pub-id pub-id-type="doi">10.1126/science.274.5294.1926</pub-id><pub-id pub-id-type="pmid">8943209</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savic</surname><given-names>O</given-names></name><name><surname>Sloutsky</surname><given-names>VM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Assimilation of exceptions? examining representations of regular and exceptional category members across development</article-title><source>Journal of Experimental Psychology. General</source><volume>148</volume><fpage>1071</fpage><lpage>1090</lpage><pub-id pub-id-type="doi">10.1037/xge0000611</pub-id><pub-id pub-id-type="pmid">31180718</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Kustner</surname><given-names>LV</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Shaping of object representations in the human medial temporal lobe based on temporal regularities</article-title><source>Current Biology</source><volume>22</volume><fpage>1622</fpage><lpage>1627</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.06.056</pub-id><pub-id pub-id-type="pmid">22885059</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistical learning of temporal community structure in the hippocampus</article-title><source>Hippocampus</source><volume>26</volume><fpage>3</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1002/hipo.22523</pub-id><pub-id pub-id-type="pmid">26332666</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>McDevitt</surname><given-names>EA</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Mednick</surname><given-names>SC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Sleep benefits memory for semantic category structure while preserving exemplar-specific information</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>14869</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-12884-5</pub-id><pub-id pub-id-type="pmid">29093451</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Complementary learning systems within the hippocampus: A neural network modelling approach to reconciling episodic memory with statistical learning</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>372</volume><elocation-id>20160049</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0049</pub-id><pub-id pub-id-type="pmid">27872368</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>McDevitt</surname><given-names>EA</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Mednick</surname><given-names>SC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human hippocampal replay during rest prioritizes weakly learned information and predicts memory performance</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3920</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06213-1</pub-id><pub-id pub-id-type="pmid">30254219</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Schapiro Lab</collab></person-group><year iso-8601-date="2022">2022</year><data-title>Hip-cat</data-title><version designator="swh:1:rev:77f01c4f473e985364990d5c07fb7166aa4f993d">swh:1:rev:77f01c4f473e985364990d5c07fb7166aa4f993d</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:e50358bb9437917d64afd0d46a9246cb240c3c45;origin=https://github.com/schapirolab/hip-cat;visit=swh:1:snp:564923b61e43e323c57105482c656eeee3a29829;anchor=swh:1:rev:77f01c4f473e985364990d5c07fb7166aa4f993d">https://archive.softwareheritage.org/swh:1:dir:e50358bb9437917d64afd0d46a9246cb240c3c45;origin=https://github.com/schapirolab/hip-cat;visit=swh:1:snp:564923b61e43e323c57105482c656eeee3a29829;anchor=swh:1:rev:77f01c4f473e985364990d5c07fb7166aa4f993d</ext-link></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Gumus</surname><given-names>M</given-names></name><name><surname>Zhu</surname><given-names>T</given-names></name><name><surname>Mack</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The structure of hippocampal circuitry relates to rapid category learning in humans</article-title><source>Hippocampus</source><volume>31</volume><fpage>1179</fpage><lpage>1190</lpage><pub-id pub-id-type="doi">10.1002/hipo.23382</pub-id><pub-id pub-id-type="pmid">34379847</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seger</surname><given-names>CA</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Category learning in the brain</article-title><source>Annual Review of Neuroscience</source><volume>33</volume><fpage>203</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.051508.135546</pub-id><pub-id pub-id-type="pmid">20572771</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>BE</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Statistical prediction of the future impairs episodic encoding of the present</article-title><source>PNAS</source><volume>117</volume><fpage>22760</fpage><lpage>22770</lpage><pub-id pub-id-type="doi">10.1073/pnas.2013291117</pub-id><pub-id pub-id-type="pmid">32859755</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>BE</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Goldfarb</surname><given-names>EV</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Multiple memory subsystems: reconsidering memory in the mind and brain</article-title><source>Perspectives on Psychological Science</source><volume>1</volume><elocation-id>17456916231179146</elocation-id><pub-id pub-id-type="doi">10.1177/17456916231179146</pub-id><pub-id pub-id-type="pmid">37390333</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name><name><surname>Grossman</surname><given-names>S</given-names></name><name><surname>Sage</surname><given-names>J</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Cortico-striatal contributions to feedback-based learning: converging data from neuroimaging and neuropsychology</article-title><source>Brain</source><volume>127</volume><fpage>851</fpage><lpage>859</lpage><pub-id pub-id-type="doi">10.1093/brain/awh100</pub-id><pub-id pub-id-type="pmid">15013954</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>HS</given-names></name><name><surname>Rosenbaum</surname><given-names>RS</given-names></name><name><surname>Baker</surname><given-names>S</given-names></name><name><surname>Lauzon</surname><given-names>C</given-names></name><name><surname>Batterink</surname><given-names>LJ</given-names></name><name><surname>Köhler</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Dentate gyrus integrity is necessary for behavioral pattern separation but not statistical learning</article-title><source>Journal of Cognitive Neuroscience</source><volume>35</volume><fpage>900</fpage><lpage>917</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01981</pub-id><pub-id pub-id-type="pmid">36877071</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Younger</surname><given-names>BA</given-names></name><name><surname>Cohen</surname><given-names>LB</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Infant perception of correlations among attributes</article-title><source>Child Development</source><volume>54</volume><fpage>858</fpage><lpage>867</lpage><pub-id pub-id-type="doi">10.2307/1129890</pub-id><pub-id pub-id-type="pmid">6617307</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Younger</surname><given-names>BA</given-names></name><name><surname>Gotlieb</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Development of categorization skills: Changes in the nature or structure of infant form categories?</article-title><source>Developmental Psychology</source><volume>24</volume><fpage>611</fpage><lpage>619</lpage><pub-id pub-id-type="doi">10.1037/0012-1649.24.5.611</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Younger</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Infants’ detection of correlations among feature categories</article-title><source>Child Development</source><volume>61</volume><elocation-id>614</elocation-id><pub-id pub-id-type="doi">10.2307/1130948</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaki</surname><given-names>SR</given-names></name><name><surname>Nosofsky</surname><given-names>RM</given-names></name><name><surname>Jessup</surname><given-names>NM</given-names></name><name><surname>Unverzagt</surname><given-names>FW</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Categorization and recognition performance of a memory-impaired group: evidence for single-system models</article-title><source>Journal of the International Neuropsychological Society</source><volume>9</volume><fpage>394</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1017/S1355617703930050</pub-id><pub-id pub-id-type="pmid">12666764</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaki</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Is categorization performance really intact in amnesia? A meta-analysis</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>11</volume><fpage>1048</fpage><lpage>1054</lpage><pub-id pub-id-type="doi">10.3758/bf03196735</pub-id><pub-id pub-id-type="pmid">15875974</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeithamova</surname><given-names>D</given-names></name><name><surname>Maddox</surname><given-names>WT</given-names></name><name><surname>Schnyer</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dissociable prototype learning systems: evidence from brain imaging and behavior</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>13194</fpage><lpage>13201</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2915-08.2008</pub-id><pub-id pub-id-type="pmid">19052210</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeithamova</surname><given-names>D</given-names></name><name><surname>Bowman</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Generalization and the hippocampus: more than one story?</article-title><source>Neurobiology of Learning and Memory</source><volume>175</volume><elocation-id>107317</elocation-id><pub-id pub-id-type="doi">10.1016/j.nlm.2020.107317</pub-id><pub-id pub-id-type="pmid">33007461</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Singh</surname><given-names>D</given-names></name><name><surname>Tandoc</surname><given-names>MC</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Building integrated representations through interleaved learning</article-title><source>Journal of Experimental Psychology. General</source><volume>152</volume><fpage>2666</fpage><lpage>2684</lpage><pub-id pub-id-type="doi">10.1037/xge0001415</pub-id><pub-id pub-id-type="pmid">37227843</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77185.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zeithamova</surname><given-names>Dasa</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0293rh119</institution-id><institution>University of Oregon</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.01.12.476051" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.01.12.476051"/></front-stub><body><p>This article will be of interest to a broad audience of cognitive neuroscientists interested in learning and memory, especially those who study the computations of the hippocampus in human and animal models. This work offers compelling evidence in support of a role for the computations theorized to occur within the hippocampus in category learning more generally. The well-conducted and rigorous computational simulations support the key conclusions and offer a novel theoretical entry into characterizing human learning.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77185.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Zeithamova</surname><given-names>Dasa</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0293rh119</institution-id><institution>University of Oregon</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.01.12.476051">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.01.12.476051v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;A neural network model of hippocampal contributions to category learning&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Michael Frank as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. Distinction from Schapiro et al., 2017: It is key to distinguish the current work from the simulations and findings in Schapiro et al. (2017). Although Reviewers were convinced that demonstrating that C-HORSE naturally accounts for category learning across a broad range of categorization tasks is novel and a worthy contribution, but how this is different from the senior author's prior work is not well argued in the current manuscript. In particular, the authors should address the conceptual differences between statistical/inferential learning (as is the focus in the 2017 paper) and category learning to highlight the novelty of the current work.</p><p>2. Apparent disconnect with established findings from unit recordings in CA1 and CA3: One concern, best described by Reviewer 2, is that in accounting for both statistical and category learning effects, C-HORSE may be unable to account for the more well-established body of empirical findings from unit recordings of hippocampal subfields. For example, it is not clear if the type of place and concept coding in hippocampal cells from rodents and humans are amenable to the predictions of C-HORSE. The Reviewers thought that this should be directly addressed by reviewing the literature which describes the response of single cells in CA1 and CA3 and considering how this corresponds to the predictions of the model, noting limitations where appropriate. Relatedly, Reviewer 3 noted that although the discussion of the CA1 vs. CA3 as it relates to functional differences in anterior vs. posterior hippocampus is an interesting point, the authors should soften their language here. Certainly, the C-HORSE findings coupled with anterior-posterior differences in subfields offers a compelling avenue for reconciling these viewpoints, but the matter is not as resolved as the discussion currently implies.</p><p>3. Situating C-HORSE in the literature: As a neurobiologically inspired model that provides insight into higher-level cognition, C-HORSE is broadly relevant to several research domains and existing theoretical frameworks (e.g., CLS, formal models of category learning, etc.). However, the Reviewers felt that it was not clear how to best place the proposed model in the literature. A formal comparison of C-HORSE to extant models seems beyond the scope of the current work. But, as a proof-of-concept alternative framework, the current work demonstrates how a single brain structure (i.e., hippocampus) can support both memory generalization and specificity. As such, the Reviewers suggest that making this proof-of-concept aspect explicit will help resolve confusion as to how C-HORSE in its current state should be considered alongside related theories/models.</p><p>4. Clarifying claims: In discussing the implications of their findings, the authors make several claims that over generalize their findings. For example, it is noted multiple times that MSP is &quot;critical&quot; and &quot;responsible&quot; for detecting regularities that support category generalization. It is true that MSP is clearly supporting this sort of generalization and more so than TSP, yet the simulation results also clearly show that the TSP-only model is still capable of above-chance categorization. The Reviewers suggest that the authors revise these statements to better align with the findings.</p><p>5. Directly characterizing the nature of representations in simulated tasks: The RSA approach is leveraged only in simulation 1, but would be helpful to consider for the other two simulations as well. In particular, many of the general versus specific claims made are based on indirect inferences from learning measures, when a direct characterization of the representations and how they change over learning could be made with RSA. The authors should consider adding these analyses for all simulations to better support their conclusions or provide a rationale for why they are not necessary.</p><p>6. Logic of initial vs. settled representations: In the RSA results of simulation 1, initial and settled representations are presented and compared, yet there is no logic provided as to why this is an important comparison to make (or even what initial vs. settled representations are, see point 7 below). The authors should provide a rationale for this analysis in terms of the learning mechanisms and information flow in the model.</p><p>7. Relationship to human learning findings: For each simulation, the qualitative fit between C-HORSE and end-of-learning behaviour from the prior work is mentioned in the main text to demonstrate a qualitatively &quot;good fit&quot; between model and human. Reviewer 1 suggested that these comparisons are expanded to (1) include behavioural measures across learning where appropriate and (2) include depictions of these behavioural effects in the figures. To be clear, quantitative fits of the model to empirical data are not expected, but that learning trajectories and end of learning performance in both model and human participants are more thoroughly considered in the text and figures.</p><p>8. Details of model and modelling approach: Although C-HORSE has been described in more detail in a prior paper (Schapiro et al., 2017), the Reviewers felt that more of these details should be included in the current work, especially since this will potentially reach an audience unfamiliar with the originating paper. In particular, important model mechanisms like learning rates, unit numbers across the layers, rationales for differences in TSP and MSP weights, cycles, and clamping should be further described and motivated.</p><p>9. More focused discussion: Although the discussion offers a comprehensive view on the role of hippocampus in category learning more broadly, it is not always connected back to the main conclusions of the paper. Reviewers suggested streamlining the discussion to include only those sections most relevant (see Reviewers 1 and 2 for specifics).</p><p>10. Clarity suggestions: The Reviewers also had several other suggestions that might increase the clarity of the methods, results, and discussion. The authors should please consider these suggestions and implement if they see fit.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>I think this work is very exciting and compelling. However, I am certainly an insider in this field and am familiar with category learning research in general and relating hippocampal-based memory functions to learning behaviour. As such, it took a few reads to realize that the manuscript as is perhaps assumes to much knowledge of the reader. I think the contribution could be greatly strengthened if:</p><p>– More model details were provided. A citation is provided to the Schapiro et al., 2017 study, but important elements of the model that speak to key learning constructs are omitted (e.g., what is a cycle? what are initial and settled representations?)</p><p>– The authors should consider either directly evaluating the predictive power of C-HORSE relative to other models or recognizing the need for such an evaluation in future work as an important point for the discussion.</p><p>– Overall, the discussion could be refocused (and likely shortened) to put greater emphasis on the implications of the current findings to the broader themes in the literature.</p><p>– The RSA approach utilized in simulation 1 to characterize subfield representations should be used for all simulations potentially for both intact and lesion-variants of the model. Although the authors' main conclusions (MSP=detecting regularities, TSP=encoding items) can be inferred from the generalization and recognition performance of the lesion simulations, adding a more detailed and direct exploration of the model would strengthen the contribution significantly.</p><p>– The behaviour signatures of the original studies were described and depicted. Although there is some effort to describe how each of the three tasks capture distinct components of category learning, more description of these original studies in terms of their key behavioural patterns and what they reveal about category learning would be helpful. End of learning behavioural performance is sometimes provided in the main text, but it would help clarify the degree of fit from C-HORSE if these average accuracy measures from the prior work were plotted alongside the model results.</p><p>– In systematically varying the typicality of exemplars, the third simulation offers an interesting testbed for characterizing the contribution of MSP and TSP. And, in the analyses provided, there are hints at this. Recognition is better for TSP than MSP with increasing atypical exemplars. And, it is compelling that MSP matches TSP recognition with 1-2 atypical features. What I found most intriguing about this simulation is that the intact model offers the best performance. How is the information from both pathways combined in the model to drive good recognition? Characterizing this aspect of the model dynamics would potentially provide some insight into how the so-called complementary hippocampal functions are actually complementary.</p><p>– Relatedly, although the simulation results are interesting in this third study, I was left wondering how well they matched human performance. As suggested above, demonstrating the degree that C-HORSE actually matches human performance is key to understanding how well this new model truly accounts for human learning. As is, it is difficult to evaluate with this explicit comparison.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>This model does come from a long 'lineage of models developed to account for episodic memory phenomena', and those should be more extensively cited (rather than only including papers authored or co-authored by Randy O'Reilly). I would suggest Marr (1971) Phil Trans B at the very least, and I think Gluck and Myers (1993) Hippocampus is also particularly relevant</p><p>The Discussion is far too long (thirteen and a half pages, about half of the total length of the manuscript). Please try and reduce the word count by sticking to the most pertinent issues</p><p>The authors state that the &quot;monosynaptic pathway … was responsible for detecting the regularities that define category structure&quot; and, later, that &quot;the MSP was critical for learning the regularities underlying category structure and was responsible for generalization of knowledge to novel exemplars&quot;, but their results show that simulations with the TSP alone consistently perform better than chance on tests of either function (e.g. Figure 3A-C, 4B, 5B). As such, these statements appear to misrepresent the results. Please clarify</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>1. The one analysis that seems missing is analysis of generalization in Task 3 based on typicality. It would be informative, especially given that the training data showed interesting dissociations based on typicality.</p><p>2. I did not understand the relationship between time and performance during test in Task 1 and Task 3, where there are distinct training and test phases. I thought there are no labels and no weight adjustments at this stage. Why is the already trained network starting at chance at generalization test and then improve? How can we reconcile it with human performance that does not show such test accuracy pattern?</p><p>3. The clarity and flow of writing was exceptional, further enhancing interesting content, making this one of my favorite reviews this year. I did find a few challenging sentences, which perhaps could use rewording for clarity. I also found a couple of details that I would like clarified.</p><p>– Lines 66-69 could be split into two sentences, one defining complementary learning systems, another noting it may exist within hippocampus itself in distinct pathways. As written, it was confusing.</p><p>– Consider whether TSP and MSP abbreviations are necessary or if the words trisynaptic and monosynaptic could be spelt out each time instead (I am aware of the frequency, so this is just for consideration).</p><p>Methods details:</p><p>– Line 149 could add rationale for the distinct number of units in the different hidden layers</p><p>– Line 151 could mention the weight constraints</p><p>– Line 173 could explain &quot;clamped&quot; in non-technical terms</p><p>– Line 333/388 could explain why each category was represented by 2 units/5 units</p><p>– The additional task visualizations for task 2 and task 3 in Figure 2 were very helpful (the outcomes and %chance for cards combinations, the feature value visualization using the circles in task 3). Perhaps they could be explained more in the legend.</p><p>4. Connection to other work:</p><p>Line 53 puts up the idea that hippocampus may be well suited for category learning after all. It may be worth referencing a couple recent review papers that made the same point (e.g., Mack et al. 2018; Zeithamova and Bowman, 2020).</p><p>Line 293-296 Big Loop Recurrence could reference Koster et al., 2018.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;A neural network model of hippocampal contributions to category learning&quot; for further consideration by <italic>eLife</italic>. Your revised article has been re-reviewed by one of the original reviewers and evaluated by Michael Frank (Senior Editor) and a Reviewing Editor.</p><p>We found that you were highly responsive to the previous comments and the manuscript has been significantly improved. There are only a couple of remaining issues that should be addressed, as outlined below:</p><p>1. The representation of exemplars and common features in your network could be made more intuitively understandable with the help of an illustration. For example, you could add another row to Figure 2A (or possibly 2B) that shows activity in the input layer to EC_in (which is clamped throughout learning), illustrating the activity pattern for each exemplar in one category. This is currently given in Supplementary Table 1A, but it would be useful to have it in the main text. Illustration of just one category would be sufficient to illustrate the pattern of activity across exemplars and perhaps also get a better idea of how the &quot;classification&quot; performance is evaluated in the network. This would complement the symbolic illustration of the exemplars, unique features and shared features from the three categories this is already a helpful part of Figure 2A. Alternatively, more information can be provided in the text.</p><p>2. The category structure effects are relatively subtle in Figure 4e and would benefit from a summary representation that more explicitly highlights their presence or absence in the different subfields. Adding a visual or numerical summary report of within-category vs. between-category similarity would be beneficial.</p><p>3. The Koster et al., 2018 citation was only added in the response letter but not the revised manuscript.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77185.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. Distinction from Schapiro et al., 2017: It is key to distinguish the current work from the simulations and findings in Schapiro et al. (2017). Although Reviewers were convinced that demonstrating that C-HORSE naturally accounts for category learning across a broad range of categorization tasks is novel and a worthy contribution, but how this is different from the senior author's prior work is not well argued in the current manuscript. In particular, the authors should address the conceptual differences between statistical/inferential learning (as is the focus in the 2017 paper) and category learning to highlight the novelty of the current work.</p></disp-quote><p>We agree that the novelty of the category learning simulations needed better articulation. We have added the following:</p><p>Introduction: “In the present work, we ask what computational properties of the hippocampus might allow it to contribute to category learning. Using a neural network model of the hippocampus named C-HORSE (Complementary Hippocampal Operations for Representing Statistics and Episodes), we previously demonstrated how the hippocampus might contribute to learning temporal regularities embedded in continuous sequences of stimuli (temporal statistical learning) and to inference over pairwise associations (Schapiro, Turk-Browne, et al., 2017; Zhou, Singh, Tandoc, and Schapiro, 2021). We showed that the heterogeneous properties of the two main pathways within the hippocampus may support complementary learning systems, with one pathway specializing in the rapid encoding of individual episodes and another in extracting statistics over time. This division of labor is analogous to the roles of the hippocampus and neocortex in the classic Complementary Learning Systems framework (McClelland, McNaughton, and O’Reilly, 1995), and our proposal was thus that a microcosm of this memory systems dynamic plays out within the hippocampus itself.</p><p>Category learning is related to temporal statistical learning in requiring information to be integrated across experiences, with the structure of a category discovered across exposure to individual exemplars. However, category learning is also different from temporal statistical learning in fundamental ways. Category learning involves tracking exemplars composed of separate features that can vary in different ways across exemplars. The regularities in these features often manifest in co-occurrence in space at one moment (e.g., different parts of an object), as opposed to co-occurrence nearby in time. There is also often demand in category learning tasks for more explicit grouping and labeling of exemplars. The present work evaluates to what extent the principles of structure learning that allow the hippocampus to support statistical learning may also apply to this different learning domain. If the principles generalize, it would suggest the possibility of broad, domain-general learning mechanisms at work in the hippocampus that allow integration of varied forms of information across experiences.”</p><p>While we see the demonstration of convergence across domains as novel, significant, and nontrivial, our expanded analyses and results in this version of the manuscript also unpack various findings from the model that are specific to category learning, which add important new insight into hippocampal contributions to category learning <italic>in particular</italic>.</p><disp-quote content-type="editor-comment"><p>2. Apparent disconnect with established findings from unit recordings in CA1 and CA3: One concern, best described by Reviewer 2, is that in accounting for both statistical and category learning effects, C-HORSE may be unable to account for the more well-established body of empirical findings from unit recordings of hippocampal subfields. For example, it is not clear if the type of place and concept coding in hippocampal cells from rodents and humans are amenable to the predictions of C-HORSE. The Reviewers thought that this should be directly addressed by reviewing the literature which describes the response of single cells in CA1 and CA3 and considering how this corresponds to the predictions of the model, noting limitations where appropriate.</p></disp-quote><p>We appreciate the encouragement to unpack the relationships between our model and the electrophysiology literature on properties of CA1 and CA3 cells. We view the model as strongly consistent with this literature, so it is useful for us to highlight these connections. First, in the place cell literature, CA1 spatial representations exhibit overlap across environments that reflects the similarity of those environments, whereas CA3 representations orthogonalize responses even for very similar environments, which is exactly the behavior of our model.</p><p>Introduction: “The projections within the TSP are sparse, enabling the formation of orthogonalized representations even with highly similar input patterns (i.e., pattern separation). This corresponds to the observed physiology; for example, distinct sets of place cells in rodents are responsive to particular locations in CA3 even in very similar enclosures (Leutgeb et al., 2004). The TSP is highly plastic in the brain and in the model, which supports rapid, even one-shot learning (Nakashiba et al., 2008). The MSP connects EC directly to CA1. These projections do not have the specialized sparsity of those in the TSP, allowing for more overlapping representations to emerge. Place cell responses in CA1 tend to overlap as a function of the similarity of the enclosure (Leutgeb et al., 2004). In addition, the MSP seems to learn more slowly (Lee, Rao, and Knierim, 2004; Nakashiba, et al., 2008).”</p><p>Our work can be viewed as studying how the hippocampus learns new concepts, which also connects it to the literature on concept cells in the human hippocampus. These cells respond to a particular concept, like Jennifer Aniston, and can be activated by her name or by different views of her face. Reviewer 2 points out that these neurons do not fire in response to other actors from Friends, which seems at odds with the units in our model that respond to all members of a category.</p><p>The understanding of concept cells is probably at too early a stage to say with confidence how they correspond to our proposal. One possibility is that concept cells actually reflect episodic memory. The experimenters in the concept cell studies conduct interviews with the patients prior to recording to determine their knowledge of celebrities, and the cells may thus correspond to memories of that prior conversation, which can be evoked by various different cues to the celebrity. This is related to an idea we put forward in a commentary in Trends in Cognitive Sciences (Solomon and Schapiro, 2022) that concept cells may reflect pattern completion of a concept, and would be consistent with the functions of our model’s TSP.</p><p>In the scenario where concept cells reflect semantic knowledge more than episodic memory, though, they still correspond to a kind of category. A cell could in theory be selective to a particular exemplar of Jennifer Aniston (e.g. her role in one movie) or it could correspond to <italic>all</italic> instances of Jennifer Aniston — defining a Jennifer Aniston <italic>category</italic>. Concept cells are thus categorical in this sense. There are also cells in the hippocampus that respond generally to faces and other higher-level categories (Kreiman et al., <italic>Nature Neuroscience</italic>, 2000), reflecting a superordinate category representation. Our MSP tends to cluster related experiences into overlapping neural ensembles, and would have similar representations in CA1 for different instances of Jennifer Aniston, as well as similar representations for different faces.</p><p>So while it is true that the studied Jennifer Aniston neurons do not fire in response to other actors from friends, given the presence of general face-selective cells, there are certainly <italic>other</italic> cells that would respond to multiple actors from friends. In sum, there are cells that reflect different levels of category structure in the hippocampus (reflecting our hierarchical understanding of categories).</p><p>Exploring these points seems out of the scope of the current paper, as there are multiple paths and they are all speculative at this point (and we need to cut down as opposed to expand our Discussion), but we do think it is important to acknowledge the potential connection to this literature. We have added the following to the Discussion:</p><p>“In addition to the neuroimaging literature on category learning, there is also neurophysiological literature on concept / category representation in the human hippocampus, with demonstrations of cells that respond similarly to distinct instantiations a particular concept (e.g., Jennifer Aniston; Quiroga et al., 2005) and cells that respond invariantly across exemplars of higher level categories (e.g. faces; Kreiman et al., 2000). These findings are consistent with our proposal that the hippocampus contains representations that exhibit invariance across exemplars.”</p><disp-quote content-type="editor-comment"><p>Relatedly, Reviewer 3 noted that although the discussion of the CA1 vs. CA3 as it relates to functional differences in anterior vs. posterior hippocampus is an interesting point, the authors should soften their language here. Certainly, the C-HORSE findings coupled with anterior-posterior differences in subfields offers a compelling avenue for reconciling these viewpoints, but the matter is not as resolved as the discussion currently implies.</p></disp-quote><p>We agree that the anterior vs. posterior hippocampus discussion needed qualification. We deleted a sentence in the Discussion that suggested that anterior/posterior differences provide an indirect test of the theory, and added the following to that paragraph:</p><p>“There are many differences, however, between anterior and posterior hippocampus apart from subfield ratios (e.g., differential connectivity and tuning to spatial scale), so future work will be needed to more directly test these connections between subfield properties and the properties of anterior and posterior hippocampus.”</p><disp-quote content-type="editor-comment"><p>3. Situating C-HORSE in the literature: As a neurobiologically inspired model that provides insight into higher-level cognition, C-HORSE is broadly relevant to several research domains and existing theoretical frameworks (e.g., CLS, formal models of category learning, etc.). However, the Reviewers felt that it was not clear how to best place the proposed model in the literature. A formal comparison of C-HORSE to extant models seems beyond the scope of the current work. But, as a proof-of-concept alternative framework, the current work demonstrates how a single brain structure (i.e., hippocampus) can support both memory generalization and specificity. As such, the Reviewers suggest that making this proof-of-concept aspect explicit will help resolve confusion as to how C-HORSE in its current state should be considered alongside related theories/models.</p></disp-quote><p>We agree that it is important for us to be clear that this model is a proof-of-concept for how the hippocampus may contribute to category learning and that formal comparison with other models is very valuable but out of scope of the present work. We have added the following sections to the Discussion:</p><p>“Our goal was to take a model with an architecture inspired by the anatomy and properties of the hippocampus and explore how it might accomplish category learning. While we did not endeavor to build in any particular strategies, the emergent behaviors of the model bear resemblance to existing psychological models of categorization. The model thus provides a bridge across levels of analysis, showing how neurobiological mechanisms may give rise to some of the more abstract operations of existing models.”</p><p>“There are many models of category learning in the literature, including neural network models that would likely exhibit behavior closely analogous to our model’s MSP. Our goal here is not to claim that our model better fits empirical data than existing models, but rather to provide a proof-of-concept demonstration of how the computations of hippocampal subregions may give rise to different components of category learning. Detailed comparison of the model’s behavior to other models in the literature will be valuable in evaluating and refining the model, however, and will be an important goal for future work.”</p><disp-quote content-type="editor-comment"><p>4. Clarifying claims: In discussing the implications of their findings, the authors make several claims that over generalize their findings. For example, it is noted multiple times that MSP is &quot;critical&quot; and &quot;responsible&quot; for detecting regularities that support category generalization. It is true that MSP is clearly supporting this sort of generalization and more so than TSP, yet the simulation results also clearly show that the TSP-only model is still capable of above-chance categorization. The Reviewers suggest that the authors revise these statements to better align with the findings.</p></disp-quote><p>This is an excellent point, and we have revised our language to be more accurate about the differences in expertise across the pathways without making strong claims about necessity:</p><p>Abstract: “The monosynaptic pathway from entorhinal cortex to CA1, in contrast, specialized in detecting the regularities that define category structure”</p><p>Introduction: “The MSP played a central role in learning the regularities underlying category structure and excelled in generalizing knowledge to novel exemplars. The TSP also contributed to behavior across the tasks but with the opposite expertise, specializing in memory for the unique properties of exemplars.”</p><p>Results: “the MSP contributed relatively more to this categorization ability, whereas the TSP was better able to process individual combinations of cards”</p><p>Discussion: “Across paradigms, the MSP specialized in detecting the regularities that define category structure.”</p><disp-quote content-type="editor-comment"><p>5. Directly characterizing the nature of representations in simulated tasks: The RSA approach is leveraged only in simulation 1, but would be helpful to consider for the other two simulations as well. In particular, many of the general versus specific claims made are based on indirect inferences from learning measures, when a direct characterization of the representations and how they change over learning could be made with RSA. The authors should consider adding these analyses for all simulations to better support their conclusions or provide a rationale for why they are not necessary.</p></disp-quote><p>We completely agree that RSA visualizations would be useful for all simulations. We have run these analyses for Simulations 2 and 3, and Figures 4 and 5 have been updated to include these. The new RSAs are convergent with those for Simulation 1, showing more similarity for items in the same category in CA1 relative to DG and CA3. The RSA for Simulation 3 provides some new insight into the model’s behavior, showing the limits of pattern separation in the TSP, as described below.</p><disp-quote content-type="editor-comment"><p>6. Logic of initial vs. settled representations: In the RSA results of simulation 1, initial and settled representations are presented and compared, yet there is no logic provided as to why this is an important comparison to make (or even what initial vs. settled representations are, see point 7 below). The authors should provide a rationale for this analysis in terms of the learning mechanisms and information flow in the model.</p></disp-quote><p>We agree that this needed to be much clearer. We have added the following section to the Methods:</p><p>“Representational similarity analyses. To assess the nature of learned representations in the networks, we performed representational similarity analyses for each of the simulations during a test phase at the end of training. We used Pearson correlation to relate the patterns of activity evoked by presentation of different items. We analyzed representations separately in the ‘initial’ and ‘settled’ response in the intact network. The initial response captures the activation pattern once activity has spread throughout the network but before output activity in EC<sub>out</sub> recirculates back to the input in EC<sub>in</sub> — before there is an impact of “big-loop” recurrence (Kumaran and McClelland, 2012; Schapiro, Turk-Browne, et al., 2017). The settled response captures the fully settled pattern of activity including the influence of big-loop recurrence. Big-loop recurrence permits the representations in CA1 to influence those in DG and CA3, so separate analysis of the initial response allows cleaner assessment of the unique representational contributions of the different subfields.”</p><p>We also reiterate these points now in the first presentation of representational similarity results:</p><p>“To assess network representations, we performed representational similarity analysis for each hidden layer of the intact network at the end of training (140 trials). We captured the patterns of unit activities evoked by presentation of each satellite’s unique feature (for the 12 satellites with unique features). There was no structure in the representations prior to training (not depicted), and the representations that emerged with training revealed sensitivity to the category structure. This was particularly evident in CA1 (Error! Reference source not found.f), with items from the same category represented much more similarly than items from different categories. We separately analyzed the initial pattern of activity evoked by each feature (before there was time for activity to spread from EC<sub>out</sub> to EC<sub>in</sub>), and the fully settled response. The initial response allows us to understand the separate representational contributions of the subfields, before CA1 activity has the potential to influence DG and CA3. In the initial response, there was no sensitivity at all to category structure in DG and CA3 — items were represented with distinct sets of units. This is a demonstration of the classic pattern separation function of the TSP, applied to this domain of category learning, where it is able to take overlapping inputs and project them to separate populations of units in DG and CA3. CA1 representations, on the other hand, mirrored the category structure, with overlapping sets of units evoked by items in the same category. This result is consistent with our neuroimaging findings using this paradigm, where CA1 was the only subfield of the hippocampus to show significant within versus between category multivoxel pattern similarity (Schapiro et al., 2018). The settled response revealed sensitivity to category structure in all three hidden layers, reflecting the influence of CA1 on the rest of the network after “big-loop” recurrence (Koster et al., 2018; Kumaran and McClelland, 2012; Schapiro, Turk-Browne, et al., 2017), though CA1 still showed the strongest response. All sensitivity to the category structure in this network was thus driven by the learned representations in CA1.”</p><disp-quote content-type="editor-comment"><p>7. Relationship to human learning findings: For each simulation, the qualitative fit between C-HORSE and end-of-learning behaviour from the prior work is mentioned in the main text to demonstrate a qualitatively &quot;good fit&quot; between model and human. Reviewer 1 suggested that these comparisons are expanded to (1) include behavioural measures across learning where appropriate and (2) include depictions of these behavioural effects in the figures. To be clear, quantitative fits of the model to empirical data are not expected, but that learning trajectories and end of learning performance in both model and human participants are more thoroughly considered in the text and figures.</p></disp-quote><p>We very much appreciate this suggestion, as we agree that including comparisons to behavior would significantly strengthen the paper. For Simulation 1, we re-analyzed our own prior data in order to generate timecourses showing performance for unique and shared features over the course of learning (we did not have intermittent tests of generalization). Figure 3a and b show the human behavior with learning curve fits, which are a nice qualitative match to the intact model performance (Figure 3c and 3d).</p><p>For Figure 4, we now include a timecourse of categorization performance for amnesics and controls for the weather prediction task (Figure 4a). We also added a plot in the same format showing intact performance in our model alongside an average of the MSP/TSP lesion, as a rough analogy to the amnesic condition. The results are again highly consistent.</p><p>For Figure 5, we have included two panels of behavioral results from Bowman, Iwashita, and Zeithamova (2020) showing typicality effects on behavior, across learning, and at the final test (Figure 5a and 5b). We have added our model results in a comparable format in Figure 5c and 5d, again showing a nice correspondence.</p><disp-quote content-type="editor-comment"><p>8. Details of model and modelling approach: Although C-HORSE has been described in more detail in a prior paper (Schapiro et al., 2017), the Reviewers felt that more of these details should be included in the current work, especially since this will potentially reach an audience unfamiliar with the originating paper. In particular, important model mechanisms like learning rates, unit numbers across the layers, rationales for differences in TSP and MSP weights, cycles, and clamping should be further described and motivated.</p></disp-quote><p>We agree that it is useful to have more motivation and details in this paper. We have added more details and explanations throughout the Methods section.</p><disp-quote content-type="editor-comment"><p>9. More focused discussion: Although the discussion offers a comprehensive view on the role of hippocampus in category learning more broadly, it is not always connected back to the main conclusions of the paper. Reviewers suggested streamlining the discussion to include only those sections most relevant (see Reviewers 1 and 2 for specifics).</p></disp-quote><p>We have very substantially revised the Discussion to streamline and connect the sections better to the main points of the paper. We provide more information on the changes in response to Reviewers 1 and 2 below.</p><disp-quote content-type="editor-comment"><p>10. Clarity suggestions: The Reviewers also had several other suggestions that might increase the clarity of the methods, results, and discussion. The authors should please consider these suggestions and implement if they see fit.</p></disp-quote><p>We appreciate all the suggestions and have implemented almost all of them, as detailed below.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>I think this work is very exciting and compelling. However, I am certainly an insider in this field and am familiar with category learning research in general and relating hippocampal-based memory functions to learning behaviour. As such, it took a few reads to realize that the manuscript as is perhaps assumes to much knowledge of the reader. I think the contribution could be greatly strengthened if:</p><p>– More model details were provided. A citation is provided to the Schapiro et al., 2017 study, but important elements of the model that speak to key learning constructs are omitted (e.g., what is a cycle? what are initial and settled representations?)</p></disp-quote><p>We agree. See response to Editor points #6 and #8 above.</p><disp-quote content-type="editor-comment"><p>– The authors should consider either directly evaluating the predictive power of C-HORSE relative to other models or recognizing the need for such an evaluation in future work as an important point for the discussion.</p></disp-quote><p>We agree that this is an important point to make, and have added the following to the Discussion:</p><p>“There are many models of category learning in the literature, including neural network models that would likely exhibit behavior closely analogous to our model’s MSP. Our goal here is not to claim that our model better fits empirical data than existing models, but rather to provide a proof-of-concept demonstration of how the computations of hippocampal subregions may give rise to different components of category learning. Detailed comparison of the model’s behavior to other models in the literature will be valuable in evaluating and refining the model, however, and will be an important goal for future work.”</p><disp-quote content-type="editor-comment"><p>– Overall, the discussion could be refocused (and likely shortened) to put greater emphasis on the implications of the current findings to the broader themes in the literature.</p></disp-quote><p>We agree and have implemented significant refocusing and shortening of the Discussion.</p><disp-quote content-type="editor-comment"><p>– The RSA approach utilized in simulation 1 to characterize subfield representations should be used for all simulations potentially for both intact and lesion-variants of the model. Although the authors' main conclusions (MSP=detecting regularities, TSP=encoding items) can be inferred from the generalization and recognition performance of the lesion simulations, adding a more detailed and direct exploration of the model would strengthen the contribution significantly.</p></disp-quote><p>We agree and have added representational similarity analyses for all simulations in this version of the paper.</p><disp-quote content-type="editor-comment"><p>– The behaviour signatures of the original studies were described and depicted. Although there is some effort to describe how each of the three tasks capture distinct components of category learning, more description of these original studies in terms of their key behavioural patterns and what they reveal about category learning would be helpful. End of learning behavioural performance is sometimes provided in the main text, but it would help clarify the degree of fit from C-HORSE if these average accuracy measures from the prior work were plotted alongside the model results.</p></disp-quote><p>We really appreciate this suggestion and have added empirical behavioral trajectories as comparisons for all of our simulations. (See Editor point #7 above.)</p><disp-quote content-type="editor-comment"><p>– In systematically varying the typicality of exemplars, the third simulation offers an interesting testbed for characterizing the contribution of MSP and TSP. And, in the analyses provided, there are hints at this. Recognition is better for TSP than MSP with increasing atypical exemplars. And, it is compelling that MSP matches TSP recognition with 1-2 atypical features. What I found most intriguing about this simulation is that the intact model offers the best performance. How is the information from both pathways combined in the model to drive good recognition? Characterizing this aspect of the model dynamics would potentially provide some insight into how the so-called complementary hippocampal functions are actually complementary.</p></disp-quote><p>This is a very interesting point. This is indeed the only case where we found that the intact model performed better than an individual pathway on a particular task. We think that this suggests that the MSP is playing a “supportive” role for the episodic machinery of the TSP, a role that has been characterized in the prior work with this lineage of models. It is not clear to us, though, why this role is important in this simulation and not in others. While exploring this issue is very important, we think it will be a significant undertaking and out of the scope of the current work. We have added some additional comment on this issue when discussing this result:</p><p>“Unlike prior simulations, in this case the intact network exhibited better performance than the lesioned networks, suggesting that this task benefits from having both pathways intact. The TSP-only network performed better than the MSP only network, which was virtually unable to recognize atypical category members (3 or 4 atypical features), but showed somewhat better performance on items more similar to the prototype (1 or 2 atypical features). The MSP can thus contribute to atypical feature memory to some extent, when the item is overall very similar to the prototype. The more arbitrary the item, the more the TSP is needed. Even for arbitrary items, though, the TSP benefitted from the presence of the MSP (as indicated by higher performance for the intact network), suggesting that this may be a situation where the MSP plays an important supportive function.”</p><disp-quote content-type="editor-comment"><p>– Relatedly, although the simulation results are interesting in this third study, I was left wondering how well they matched human performance. As suggested above, demonstrating the degree that C-HORSE actually matches human performance is key to understanding how well this new model truly accounts for human learning. As is, it is difficult to evaluate with this explicit comparison.</p></disp-quote><p>We agree. We have now included figures depicting human performance in a study by Bowman, Iwastiha and Zeithamova, (2020) that used this category learning task and presented these results alongside model performance.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>This model does come from a long 'lineage of models developed to account for episodic memory phenomena', and those should be more extensively cited (rather than only including papers authored or co-authored by Randy O'Reilly). I would suggest Marr (1971) Phil Trans B at the very least, and I think Gluck and Myers (1993) Hippocampus is also particularly relevant</p></disp-quote><p>We had a more specific intention here to describe how we are building on a particular neural network architecture implementing properties of the subfields and pathways of the hippocampus. The Marr and Gluck and Myers papers are of course central to the history of hippocampal modeling of episodic memory, but we want to make a narrower point about the architecture used here. We have updated to these narrower statements:</p><p>Methods: “We adopted a neural network model of the hippocampus developed after a lineage of models used to explain how the DG, CA3, and CA1 subfields of the hippocampus contribute to episodic memory (Ketz et al., 2013; Norman and O’Reilly, 2003; O’Reilly and Rudy, 2001).”</p><p>Introduction: “C-HORSE comes from a lineage of models developed to explain how the subfields of the hippocampus support episodic memory (Ketz, Morkonda, and O’Reilly, 2013; Norman and O’Reilly, 2003; O’Reilly and Rudy, 2001).”</p><disp-quote content-type="editor-comment"><p>The Discussion is far too long (thirteen and a half pages, about half of the total length of the manuscript). Please try and reduce the word count by sticking to the most pertinent issues</p></disp-quote><p>We agree, and have now made significant cuts to the Discussion to streamline this section.</p><disp-quote content-type="editor-comment"><p>The authors state that the &quot;monosynaptic pathway … was responsible for detecting the regularities that define category structure&quot; and, later, that &quot;the MSP was critical for learning the regularities underlying category structure and was responsible for generalization of knowledge to novel exemplars&quot;, but their results show that simulations with the TSP alone consistently perform better than chance on tests of either function (e.g. Figure 3A-C, 4B, 5B). As such, these statements appear to misrepresent the results. Please clarify</p></disp-quote><p>We completely agree that the language we had was too binary — both pathways show evidence of supporting both kinds of functions to some extent, but with different relative specializations. See response to Editor point #4 above.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>1. The one analysis that seems missing is analysis of generalization in Task 3 based on typicality. It would be informative, especially given that the training data showed interesting dissociations based on typicality.</p></disp-quote><p>This is a great suggestion. We now include results in Figure 5 that show generalization as a function of typicality. Generalization gets easier with increasing typically, for both the MSP and TSP. This relates to our new RSA results now also shown in Figure 5, where DG/CA3 does show some category structure for highly typical exemplars.</p><p>New text describing these results:</p><p>“Like human participants, the intact network improved in its categorization of novel items across training, with better performance for more prototypical items (Figure 5c). Figure 5c plots the initial training period, with 10 trials prior to each interim test, Figure 5d shows the typicality gradient at the end of this training, and Figure 5e shows generalization behavior over a longer training period, broken down by pathway. As in the prior simulations, the MSP-only network excelled in generalization, outperforming the intact network by the end of training across all typicality levels. The TSP-only network performed much worse, but still above chance, and was able to generalize quite well for highly prototypical items.”</p><p>“Visualization of the internal representations of the model after training provides insight into the behaviors of the two pathways. Figure 5g shows the similarity of the evoked activity of the items in this domain, with items arranged from most prototypical members of one category to most prototypical members of the other. As in the prior simulations, DG and CA3 represented the items more distinctly than CA1, and settling activity after big-loop recurrence increased similarity, especially in CA1. This simulation was unique, however, in that DG and CA3 showed clear similarity structure for the prototype and highly prototypical items. There is a limit to the pattern separation abilities of the TSP, and these highly similar items exceed that limit. This explains why, at high typicality levels, the TSP could be quite successful on its own in generalization (Figure 5e), and why it struggled with atypical feature recognition for these items (Figure 5f).”</p><disp-quote content-type="editor-comment"><p>2. I did not understand the relationship between time and performance during test in Task 1 and Task 3, where there are distinct training and test phases. I thought there are no labels and no weight adjustments at this stage. Why is the already trained network starting at chance at generalization test and then improve? How can we reconcile it with human performance that does not show such test accuracy pattern?</p></disp-quote><p>The “Trials” shown in these plots refer to trials of training, not trials of test. We stop the network after a certain number of training trials and run a test with no learning. So Trial 0 corresponds to no training, and thus chance performance. We have added clarification that trials correspond to training to all of the relevant figure legends.</p><disp-quote content-type="editor-comment"><p>3. The clarity and flow of writing was exceptional, further enhancing interesting content, making this one of my favorite reviews this year. I did find a few challenging sentences, which perhaps could use rewording for clarity. I also found a couple of details that I would like clarified.</p></disp-quote><p>We truly appreciate the Reviewer’s positive view overall on the writing.</p><disp-quote content-type="editor-comment"><p>– Lines 66-69 could be split into two sentences, one defining complementary learning systems, another noting it may exist within hippocampus itself in distinct pathways. As written, it was confusing.</p></disp-quote><p>We have split this up into two sentences:</p><p>“We showed that the heterogeneous properties of the two main pathways within the hippocampus may support complementary learning systems, with one pathway specializing in the rapid encoding of individual episodes and another in extracting statistics over time. This division of labor is analogous to the roles of the hippocampus and neocortex in the classic Complementary Learning Systems framework (McClelland, McNaughton, and O’Reilly, 1995), and our proposal was thus that a microcosm of this memory systems dynamic plays out within the hippocampus itself.”</p><disp-quote content-type="editor-comment"><p>– Consider whether TSP and MSP abbreviations are necessary or if the words trisynaptic and monosynaptic could be spelt out each time instead (I am aware of the frequency, so this is just for consideration).</p></disp-quote><p>We appreciate the suggested but have decided to retain the abbreviations given the frequency of their use.</p><disp-quote content-type="editor-comment"><p>Methods details:</p><p>– Line 149 could add rationale for the distinct number of units in the different hidden layers</p></disp-quote><p>We have added the following:</p><p>“There are 400 units in DG, 80 units in CA3, and 100 units in CA1, while input and output layer size (Input, EC<sub>in</sub> and EC<sub>out</sub>) varied as a function of the task. The hidden layer size ratios reflect the approximate ratios in the human hippocampus (Ketz et al., 2013).”</p><disp-quote content-type="editor-comment"><p>– Line 151 could mention the weight constraints</p></disp-quote><p>We are unsure exactly what the Reviewer has in mind but have clarified the learning schemes controlling the weights.</p><disp-quote content-type="editor-comment"><p>– Line 173 could explain &quot;clamped&quot; in non-technical terms</p></disp-quote><p>We have updated this paragraph to read:</p><p>“There is also a separate Input layer (not shown in Figure 1) with the same dimensionality as EC<sub>in</sub>, where external input was clamped (i.e., forced to take on particular values), allowing activity in EC<sub>in</sub> to vary as a function of external input as well as EC<sub>out</sub> activity. There are one-to-one non-learning connections between Input and EC<sub>in</sub> and between EC<sub>in</sub> and EC<sub>out</sub>.”</p><disp-quote content-type="editor-comment"><p>– Line 333/388 could explain why each category was represented by 2 units/5 units</p></disp-quote><p>Here are the edited versions:</p><p>“Each card was represented by one unit in the input and output, and each weather outcome (category) was represented by two units (increasing the relative salience of category information).”</p><p>“Each feature was represented by 2 units (one unit for each of the two possible feature values), and each category label was represented by 5 units (increasing the salience of category information relative to the many creature features).”</p><disp-quote content-type="editor-comment"><p>– The additional task visualizations for task 2 and task 3 in Figure 2 were very helpful (the outcomes and %chance for cards combinations, the feature value visualization using the circles in task 3). Perhaps they could be explained more in the legend.</p></disp-quote><p>The legend now reads:</p><p>“Figure 1. Overview of simulated category learning paradigms. (a) Satellite categories: Distinct categories of novel “satellites” consisting of unique and shared features (Schapiro, McDevitt, et al., 2017). (b) Weather Prediction Task: each abstract card is probabilistically related to a category (sun or rain), and on a given trial, category must be guessed from a simultaneously-presented set of one to three cards (Knowlton et al., 1994). The illustration shows the first two cards related to the “sun” category on 90% of the trials (and to “rain” on 10% of the trials), while a combination of the first three cards related to sun 79% of the time, and a fourth card viewed by itself associated with sun 15% of the time. (c) Intermixed categories with varying typicality: Categories where each item consists of 10 binary features. The two prototypes on opposite sides of the feature space have no features in common (depicted by all green versus all yellow features in the piecharts), and the rest of the exemplars have a varying number of features in common with the prototypes (Zeithamova et al., 2008, material adapted from Figure 1, Figure Copyright [2008] Society for Neuroscience).”</p><disp-quote content-type="editor-comment"><p>4. Connection to other work:</p><p>Line 53 puts up the idea that hippocampus may be well suited for category learning after all. It may be worth referencing a couple recent review papers that made the same point (e.g., Mack et al. 2018; Zeithamova and Bowman, 2020).</p></disp-quote><p>Agreed, and added.</p><disp-quote content-type="editor-comment"><p>Line 293-296 Big Loop Recurrence could reference Koster et al., 2018.</p></disp-quote><p>We have added this indeed very relevant reference.</p><p>[Editors’ note: what follows is the authors’ response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>We found that you were highly responsive to the previous comments and the manuscript has been significantly improved. There are only a couple of remaining issues that should be addressed, as outlined below:</p><p>1. The representation of exemplars and common features in your network could be made more intuitively understandable with the help of an illustration. For example, you could add another row to Figure 2A (or possibly 2B) that shows activity in the input layer to EC_in (which is clamped throughout learning), illustrating the activity pattern for each exemplar in one category. This is currently given in Supplementary Table 1A, but it would be useful to have it in the main text. Illustration of just one category would be sufficient to illustrate the pattern of activity across exemplars and perhaps also get a better idea of how the &quot;classification&quot; performance is evaluated in the network. This would complement the symbolic illustration of the exemplars, unique features and shared features from the three categories this is already a helpful part of Figure 2A. Alternatively, more information can be provided in the text.</p></disp-quote><p>These are very helpful suggestions for clarifying the format of the model input. Figure 2A now has grids that illustrate the input for one of the satellite categories:</p><disp-quote content-type="editor-comment"><p>2. The category structure effects are relatively subtle in Figure 4e and would benefit from a summary representation that more explicitly highlights their presence or absence in the different subfields. Adding a visual or numerical summary report of within-category vs. between-category similarity would be beneficial.</p></disp-quote><p>While it is true that the Weather Prediction Task resulted in much noisier category representations than the other simulations (because of the probabilistic nature of the task), we would argue that the category effects are still readily visible by eye. In the CA1 initial response — the key representational similarity analysis for this simulation — it is clear that there are more dark blue squares outside than inside the black boxes. While we are wary of crowding the Results with too many new stats, we completely agree that it is important to reassure readers about the reliably of the category effects given the noisiness of the CA1 category structure relative to the other simulations. We have added the following means / stats:</p><p>“As in Simulation 1, DG and CA3 represented the card combinations relatively distinctly, whereas the patterns of activity in CA1 reflected the category structure (mean similarity within category: 0.38, across: 0.25; <italic>p</italic> &lt;.001).”</p><disp-quote content-type="editor-comment"><p>3. The Koster et al., 2018 citation was only added in the response letter but not the revised manuscript.</p></disp-quote><p>Thank you so much for catching this error. The Koster citation is now in the text.</p></body></sub-article></article>