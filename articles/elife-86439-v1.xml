<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">86439</article-id><article-id pub-id-type="doi">10.7554/eLife.86439</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Variability of visual field maps in human early extrastriate cortex challenges the canonical model of organization of V2 and V3</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-192474"><name><surname>Ribeiro</surname><given-names>Fernanda Lenita</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1620-4193</contrib-id><email>fernanda.ribeiro@uq.edu.au</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-262393"><name><surname>York</surname><given-names>Ashley</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5151-6160</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-79107"><name><surname>Zavitz</surname><given-names>Elizabeth</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6501-2358</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-304767"><name><surname>Bollmann</surname><given-names>Steffen</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2909-0906</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-42293"><name><surname>Rosa</surname><given-names>Marcello GP</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6620-6285</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="fn1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-192473"><name><surname>Puckett</surname><given-names>Alexander</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5983-397X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="fn1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00rqy9422</institution-id><institution>School of Psychology, The University of Queensland</institution></institution-wrap><addr-line><named-content content-type="city">Brisbane</named-content></addr-line><country>Australia</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00rqy9422</institution-id><institution>Queensland Brain Institute, The University of Queensland</institution></institution-wrap><addr-line><named-content content-type="city">Brisbane</named-content></addr-line><country>Australia</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00rqy9422</institution-id><institution>School of Electrical Engineering and Computer Science, The University of Queensland</institution></institution-wrap><addr-line><named-content content-type="city">Brisbane</named-content></addr-line><country>Australia</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02bfwt286</institution-id><institution>Department of Physiology, Monash University</institution></institution-wrap><addr-line><named-content content-type="city">Melbourne</named-content></addr-line><country>Australia</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02bfwt286</institution-id><institution>Neuroscience Program, Biomedicine Discovery Institute; Monash University</institution></institution-wrap><addr-line><named-content content-type="city">Melbourne</named-content></addr-line><country>Australia</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02bfwt286</institution-id><institution>Department of Electrical and Computer Systems Engineering, Monash University</institution></institution-wrap><addr-line><named-content content-type="city">Clayton</named-content></addr-line><country>Australia</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00rqy9422</institution-id><institution>Queensland Digital Health Centre, The University of Queensland</institution></institution-wrap><addr-line><named-content content-type="city">Brisbane</named-content></addr-line><country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Merriam</surname><given-names>Elisha</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>National Institutes of Health</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Baker</surname><given-names>Chris I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="other" id="fn1"><label>†</label><p>Joint senior authors</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>15</day><month>08</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e86439</elocation-id><history><date date-type="received" iso-8601-date="2023-01-26"><day>26</day><month>01</month><year>2023</year></date><date date-type="accepted" iso-8601-date="2023-08-02"><day>02</day><month>08</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-10-18"><day>18</day><month>10</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.10.16.511648"/></event></pub-history><permissions><copyright-statement>© 2023, Ribeiro et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Ribeiro et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-86439-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-86439-figures-v1.pdf"/><abstract><p>Visual field maps in human early extrastriate areas (V2 and V3) are traditionally thought to form mirror-image representations which surround the primary visual cortex (V1). According to this scheme, V2 and V3 form nearly symmetrical halves with respect to the calcarine sulcus, with the dorsal halves representing lower contralateral quadrants, and the ventral halves representing upper contralateral quadrants. This arrangement is considered to be consistent across individuals, and thus predictable with reasonable accuracy using templates. However, data that deviate from this expected pattern have been observed, but mainly treated as artifactual. Here, we systematically investigate individual variability in the visual field maps of human early visual cortex using the 7T Human Connectome Project (HCP) retinotopy dataset. Our results demonstrate substantial and principled inter-individual variability. Visual field representation in the dorsal portions of V2 and V3 was more variable than in their ventral counterparts, including substantial departures from the expected mirror-symmetrical patterns. In addition, left hemisphere retinotopic maps were more variable than those in the right hemisphere. Surprisingly, only one-third of individuals had maps that conformed to the expected pattern in the left hemisphere. Visual field sign analysis further revealed that in many individuals the area conventionally identified as dorsal V3 shows a discontinuity in the mirror-image representation of the retina, associated with a Y-shaped lower vertical representation. Our findings challenge the current view that inter-individual variability in early extrastriate cortex is negligible, and that the dorsal portions of V2 and V3 are roughly mirror images of their ventral counterparts.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>retinotopy</kwd><kwd>high-resolution fMRI</kwd><kwd>vision</kwd><kwd>hemispheric differences</kwd><kwd>V3</kwd><kwd>Human Connectome Project</kwd><kwd>interindividual variability</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DE180100433</award-id><principal-award-recipient><name><surname>Puckett</surname><given-names>Alexander</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DP210101042</award-id><principal-award-recipient><name><surname>Zavitz</surname><given-names>Elizabeth</given-names></name><name><surname>Rosa</surname><given-names>Marcello GP</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000925</institution-id><institution>National Health and Medical Research Council</institution></institution-wrap></funding-source><award-id>APP1194206</award-id><principal-award-recipient><name><surname>Rosa</surname><given-names>Marcello GP</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The representation of the retina in early visual cortex shows that human brains have diverse functional organizations, raising questions about developmental mechanisms for visual map formation and how reliably these can be described by average templates.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Non-invasive imaging has been instrumental in mapping the topographic organization of human visual cortex (<xref ref-type="bibr" rid="bib66">Wandell and Winawer, 2011</xref>). The visual field maps in early visual areas (V1, V2, and V3) have been reported to be remarkably consistent across people, and predictable with reasonable accuracy using a template (<xref ref-type="bibr" rid="bib6">Benson et al., 2014</xref>; <xref ref-type="bibr" rid="bib5">Benson et al., 2012</xref>; <xref ref-type="bibr" rid="bib52">Schira et al., 2010</xref>). While V1 contains a complete, first-order (continuous) representation of the contralateral visual hemifield, areas V2 and V3 form second-order (discontinuous) representations (<xref ref-type="bibr" rid="bib48">Rosa, 2002</xref>). In these areas, a field discontinuity near the horizontal meridian splits the maps into upper and lower field representations that are only connected at the foveal confluence (<xref ref-type="fig" rid="fig1">Figure 1a, b</xref>). Accordingly, in parcellation schemes (<xref ref-type="bibr" rid="bib18">Glasser et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Wang et al., 2015</xref>), early visual areas form concentric bands, arranged in nearly symmetrical halves with respect to the calcarine sulcus. These bands, each containing the representation of a contralateral visual field quadrant, are referred to as the dorsal and ventral portions of V2 and V3 (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). However, observations originating in several laboratories have indicated departures from this pattern, particularly in the dorsal region (<xref ref-type="bibr" rid="bib2">Allen et al., 2022</xref>; <xref ref-type="bibr" rid="bib4">Arcaro and Kastner, 2015</xref>; <xref ref-type="bibr" rid="bib8">Benson and Winawer, 2018</xref>; <xref ref-type="bibr" rid="bib63">Van Essen and Glasser, 2018</xref>). Even so, small-sized datasets, variability in acquisition sites and protocols, and methodological constraints have limited the investigation of this variability. As a result, no consensus exists about deviations from the canonical mirror-symmetrical organization of V2 and V3.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Visual field mapping in the human early visual cortex.</title><p>(<bold>a</bold>) Coarse scale visual field mapping in the early visual cortex. The left (L) hemisphere maps the right visual field, and the right (R) hemisphere maps the left visual field. The dorsal portion of early visual areas maps the lower hemifield, and the ventral portion the upper field. (<bold>b</bold>) Fine scale visual field mapping with visual field maps represented in polar angles (0–360°). In this model, the vertical (90° or 270°) and horizontal meridians (0° for the left and 180° for the right hemispheres) delineate boundaries between visual areas. (<bold>c</bold>) Three ‘classical’ polar angle maps, obtained from the left hemispheres of three individuals in the Human Connectome Project (HCP) retinotopy dataset, which conform to the traditional model. (<bold>d</bold>) Three polar angle maps that deviate from this pattern, obtained from left hemispheres of three other individuals in the HCP retinotopy dataset. In the latter, the isopolar bands representing the anterior borders of dorsal V3 (V3d) and dorsal V2 (V2d) do not follow the proposed borders of V2 and V3 (dashed lines).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Average retinotopic maps across all 181 individuals from the Human Connectome Project (HCP) retinotopy dataset for both left (LH) and right (RH) hemispheres.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig1-figsupp1-v1.tif"/></fig></fig-group><p>In humans, empirical visual field mapping using functional MRI (fMRI) is the primary means of delineating precise visual area boundaries in individuals. Visual field maps are typically defined in polar coordinates, resulting in two maps: one representing polar angle (or clock position) and the other eccentricity (or distance away from the fixation point) (<xref ref-type="bibr" rid="bib66">Wandell and Winawer, 2011</xref>). In primates, isoangle bands representing the vertical and the horizontal meridians are thought to delineate boundaries between V1 and V2, V2 and V3, and V3 and higher-order visual areas (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Particularly, in human probabilistic maps, boundaries between the dorsal portions of early visual areas are roughly mirror images of their ventral counterparts (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). Nevertheless, boundaries that deviate from the expected ones exist, but these have been mainly treated as artifactual, with researchers often overlooking the irregularities by simply drawing the boundaries to resemble that of a canonical map as best as possible (e.g., <xref ref-type="fig" rid="fig1">Figure 1d</xref>). Here, it may be important to remark that the border between the dorsal parts of V2 and V3 is well known to be variable in other mammals, and that it typically does not coincide with the representation of the horizontal meridian (see <xref ref-type="bibr" rid="bib49">Rosa and Manger, 2005</xref> for review).</p><p>Although previous reports of individual variability in the dorsal portion of human early visual cortex were primarily anecdotal (<xref ref-type="bibr" rid="bib2">Allen et al., 2022</xref>; <xref ref-type="bibr" rid="bib4">Arcaro and Kastner, 2015</xref>; <xref ref-type="bibr" rid="bib8">Benson and Winawer, 2018</xref>; <xref ref-type="bibr" rid="bib63">Van Essen and Glasser, 2018</xref>), a recently developed deep learning model predicts that individual variability in retinotopy exists, and that this is correlated with variations in gross anatomy (e.g., the pattern of sulci and gyri) (<xref ref-type="bibr" rid="bib40">Ribeiro et al., 2021</xref>). Moreover, studies modeling the formation of retinotopic maps in non-human primates also indicate that different variants could develop based on the application of similar developmental rules (<xref ref-type="bibr" rid="bib70">Yu et al., 2020</xref>).</p><p>Motivated by these findings, here we systematically investigate individual variability in visual field maps of human early visual cortex using a recently released, large-scale dataset: the 181 participants, 7T Human Connectome Project (HCP) retinotopy dataset (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>). Our aims were to quantify the level of individual variability throughout early visual cortex (V1–V3) and to determine whether there are common modes of retinotopic organization that differ from the established view (i.e., whether individual retinotopic maps differ from a template in similar ways). Our results demonstrate that the dorsal portions of human early visual areas are more heterogeneous than previously acknowledged and challenge the current view that individual differences in retinotopic organization reflect experimental artifacts that may be dismissed for practical purposes.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Individual variability in retinotopy</title><p>We defined an individual variability metric to quantify how variable visual field maps are across visual areas (V1, V2, and V3), portions (dorsal and ventral), and hemispheres (left and right) in human early visual cortex. First, we computed the average visual field maps across all 181 individuals from the HCP retinotopy dataset for both left and right hemispheres. Then, we iteratively calculated the difference between an individual’s visual field map and the average map. Finally, these differences were averaged over all vertices within the dorsal and ventral portions of early visual areas, resulting in one scalar value per individual per visual area, which is our individual variability metric. Therefore, this metric is a proxy for large-scale deviations in visual field mapping. <xref ref-type="fig" rid="fig2">Figure 2</xref> shows the distribution of individual variability scores across all participants.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Individual variability in visual field maps of early visual areas.</title><p>(<bold>a</bold>) Hypothetical diagram of symmetrical distributions of individual variability across visual areas. The center and right columns illustrate empirical distributions of individual variability of polar angle (<bold>b, c</bold>) and eccentricity (<bold>d, e</bold>) maps for both dorsal (dark shades) and ventral (lighter shades) portions of early visual areas in left (purple) and right (green) hemispheres.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig2-v1.tif"/></fig><p>We built a linear mixed-effect (LME) model (<xref ref-type="bibr" rid="bib71">Yu et al., 2022</xref>) to test the fixed effects of hemispheres, visual areas, and portions on large-scale individual variability of polar angle (<xref ref-type="table" rid="table1">Table 1</xref>) and eccentricity (<xref ref-type="table" rid="table2">Table 2</xref>) maps. <xref ref-type="table" rid="table1">Table 1</xref> shows statistically significant main effects of all factors on individual variability of polar angle maps. Specifically, polar angle maps of the left hemisphere show higher individual variability than those found in the right hemisphere (mean difference = 3.35, p &lt; 0.001). The dorsal portions of early visual areas are also more variable than the ventral portions (mean difference = 3.30, p &lt; 0.001). Finally, post hoc comparisons of visual areas indicated that V3 has higher individual variability than V2 (mean difference = 1.60, p &lt; 0.001) and V1 (mean difference = 3.99, p &lt; 0.001); V2 also has higher individual variability than V1 (mean difference = 2.38, p &lt; 0.001). For brevity, we only show the main effects in <xref ref-type="table" rid="table1">Table 1</xref>, although we also found statistically significant interactions. Briefly, each visual area in the left hemisphere has significantly higher individual variability than its analogous area in the right hemisphere. In addition, the dorsal portion of each visual area of the left hemisphere is significantly more variable than its dorsal analog in the right hemisphere and the ventral analog of both the left and right hemispheres (for more, see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). These findings suggest that individual variability in polar angle representations varies across hemispheres, visual areas, and according to dorsal/ventral locations.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Fixed effects parameter estimates for the linear mixed-effect model of individual variability of polar angle maps.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" colspan="9">Polar angle</th></tr><tr><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="char" char="." valign="bottom" colspan="2">95% CI</th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr><tr><th align="left" valign="bottom">Names</th><th align="left" valign="bottom">Effect</th><th align="left" valign="bottom">Estimate</th><th align="left" valign="bottom">SE</th><th align="left" valign="bottom">Lower</th><th align="left" valign="bottom">Upper</th><th align="left" valign="bottom">df</th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom">p</th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">18.58</td><td align="char" char="." valign="bottom">0.30</td><td align="char" char="." valign="bottom">17.99</td><td align="char" char="." valign="bottom">19.17</td><td align="char" char="." valign="bottom">180</td><td align="char" char="." valign="bottom">61.86</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Hemisphere</td><td align="left" valign="bottom">RH–LH</td><td align="char" char="." valign="bottom">−3.35</td><td align="char" char="." valign="bottom">0.32</td><td align="char" char="." valign="bottom">−3.97</td><td align="char" char="." valign="bottom">−2.72</td><td align="char" char="." valign="bottom">181</td><td align="char" char="." valign="bottom">−10.47</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Visual area (1)</td><td align="left" valign="bottom">V2–V1</td><td align="char" char="." valign="bottom">2.38</td><td align="char" char="." valign="bottom">0.29</td><td align="char" char="." valign="bottom">1.81</td><td align="char" char="." valign="bottom">2.95</td><td align="char" char="." valign="bottom">210</td><td align="char" char="." valign="bottom">8.21</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Visual area (2)</td><td align="left" valign="bottom">V3–V1</td><td align="char" char="." valign="bottom">3.99</td><td align="char" char="." valign="bottom">0.32</td><td align="char" char="." valign="bottom">3.36</td><td align="char" char="." valign="bottom">4.61</td><td align="char" char="." valign="bottom">187</td><td align="char" char="." valign="bottom">12.54</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Portion</td><td align="left" valign="bottom">Ventral–dorsal</td><td align="char" char="." valign="bottom">−3.30</td><td align="char" char="." valign="bottom">0.29</td><td align="char" char="." valign="bottom">−3.86</td><td align="char" char="." valign="bottom">−2.74</td><td align="char" char="." valign="bottom">181</td><td align="char" char="." valign="bottom">−11.50</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr></tbody></table><table-wrap-foot><fn><p>SE – standard error; CI – confidence interval.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Fixed effects parameter estimates for the linear mixed-effect model of individual variability of eccentricity maps.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" colspan="9">Eccentricity</th></tr><tr><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="char" char="." valign="bottom" colspan="2">95% CI</th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr><tr><th align="left" valign="bottom">Names</th><th align="left" valign="bottom">Effect</th><th align="left" valign="bottom">Estimate</th><th align="left" valign="bottom">SE</th><th align="left" valign="bottom">Lower</th><th align="left" valign="bottom">Upper</th><th align="left" valign="bottom">df</th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom">p</th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.81</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.77</td><td align="char" char="." valign="bottom">0.85</td><td align="char" char="." valign="bottom">180</td><td align="char" char="." valign="bottom">41.86</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Hemisphere</td><td align="left" valign="bottom">RH–LH</td><td align="char" char="." valign="bottom">−0.14</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">−0.16</td><td align="char" char="." valign="bottom">−0.11</td><td align="char" char="." valign="bottom">181</td><td align="char" char="." valign="bottom">−10.91</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Visual area (1)</td><td align="left" valign="bottom">V2–V1</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">−0.01</td><td align="char" char="." valign="bottom">0.04</td><td align="char" char="." valign="bottom">402</td><td align="char" char="." valign="bottom">0.98</td><td align="char" char="." valign="bottom">0.326</td></tr><tr><td align="left" valign="bottom">Visual area (2)</td><td align="left" valign="bottom">V3–V1</td><td align="char" char="." valign="bottom">0.05</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.08</td><td align="char" char="." valign="bottom">182</td><td align="char" char="." valign="bottom">3.24</td><td align="char" char="." valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom">Portion</td><td align="left" valign="bottom">Ventral–dorsal</td><td align="char" char="." valign="bottom">−0.13</td><td align="char" char="." valign="bottom">0.03</td><td align="char" char="." valign="bottom">−0.18</td><td align="char" char="." valign="bottom">−0.07</td><td align="char" char="." valign="bottom">180</td><td align="char" char="." valign="bottom">−4.64</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr></tbody></table><table-wrap-foot><fn><p>SE – standard error; CI – confidence interval.</p></fn></table-wrap-foot></table-wrap><p>Moreover, <xref ref-type="table" rid="table2">Table 2</xref> shows statistically significant main effects of the hemisphere, visual area, and the visual area portion on individual variability of eccentricity maps. Like polar angle maps, eccentricity maps of the left hemisphere show higher individual variability than those in the right hemisphere (mean difference = 0.14, p &lt; 0.001). The dorsal portion of early visual areas is also more variable than the ventral portion (mean difference = 0.13, p &lt; 0.001). For visual areas, post hoc comparisons indicated that the only statistically significant difference was that of V3 versus V1, with V3 having higher individual variability than V1 (mean difference = 0.05, p &lt; 0.004). In addition, statistically significant interactions were also found (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). Each visual area in the left hemisphere has significantly higher individual variability than analogous areas in the right hemisphere, except for V3. Eccentricity maps of each visual area’s dorsal portion in the left hemisphere are significantly more variable than the dorsal counterpart in the right hemisphere, and the ventral analogs in both the left and the right hemispheres.</p></sec><sec id="s2-2"><title>Influence of covariates on individual variability of retinotopic maps</title><p>Other potential sources of individual variability in retinotopic maps include covariates, such as cortical curvature and mean blood oxygenation level dependent (BOLD) signal. As mentioned in the Materials and methods, these factors are known to be correlated with retinotopy and could explain part of the variability found across visual areas. In <xref ref-type="fig" rid="fig3">Figure 3</xref>, we show pair-wise correlations among polar angle, eccentricity, curvature, and normalized mean BOLD signal for both V1–3 (main plots) and each visual area separately (inset plots). Across V1–3 (<xref ref-type="fig" rid="fig3">Figure 3</xref>, main plots), polar angle was significantly correlated with curvature and the mean BOLD signal in both the right and left hemispheres; eccentricity was correlated with the mean BOLD signal in both hemispheres and curvature in the right hemisphere. Moreover, the correlation between these maps varied across visual areas. Specifically, correlations between polar angle and curvature, polar angle and mean BOLD signal, and curvature and mean BOLD signal decreased from V1 to V2 to V3.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Retinotopic maps correlation with covariates.</title><p>Pair-wise correlations among polar angle, eccentricity, curvature, and normalized mean BOLD signal for early visual areas (V1–3; main plot) and each visual area separately (inset plots), for both left (<bold>a</bold>) and right (<bold>b</bold>) hemispheres. Polar angle maps were converted such that 0° corresponds to the horizontal meridian and 90° corresponds to the upper and lower vertical meridians (<xref ref-type="bibr" rid="bib29">Kurzawski et al., 2022</xref>). Finally, data were concatenated across all participants (<italic>n</italic> = 181). *p &lt; 0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Intra-individual variability in visual field maps of early visual areas.</title><p>Empirical distributions of intra-individual variability of polar angle (top) and eccentricity (bottom) maps for both dorsal (dark shades) and ventral (lighter shades) portions of early visual areas in the left (purple) and right (green) hemispheres. The intra-individual variability is the difference in pRF estimates from two pRF model fits; each used half of the retinotopic mapping data (see <xref ref-type="supplementary-material" rid="supp7">Supplementary file 7</xref> for more information).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig3-figsupp1-v1.tif"/></fig></fig-group><p>Given the meaningful correlation between some of these variables and their varying degree of association across visual areas, we further include individual variability in curvature and mean BOLD signal maps and the intra-individual variability in pRF estimates (a proxy for the reliability of the retinotopic maps; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) as covariates in the LME model (<xref ref-type="table" rid="table3 table4">Tables 3 and 4</xref>; <xref ref-type="supplementary-material" rid="supp3 supp4">Supplementary files 3 and 4</xref>). Our findings indicate that the main effects found here were not a mere reflection of variation in the reliability of the individual maps and other covariates, at least at large scale. For example, we found that the main effects of all factors (hemispheres, visual areas, and portions) on individual variability of polar angle maps persisted, but the estimated effects were slightly reduced (<xref ref-type="table" rid="table3">Table 3</xref>). To determine whether other properties would predict individual variability in polar angle maps, we included age, gender (as cofactor), and gray matter volume as additional covariates, but did not find significant effects of any of these variables (not shown here, but available as <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>). For eccentricity, we found the main effects of hemisphere and portion but not visual area after accounting for these covariates (<xref ref-type="table" rid="table4">Table 4</xref>). Crucially, these findings suggest that individual variability in polar angle representations varies as a function of hemispheres, visual areas, and dorsal/ventral locations. These effects are not only due to trivial intra-individual variability in pRF estimates or individual variability in curvature and the mean BOLD signal.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Fixed effects parameter estimates for the linear mixed-effects model of individual variability of polar angle maps using covariates.</title><p>The covariates included in the model were intra-individual variability in pRF estimates, and individual variability in curvature and the mean BOLD signal.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" colspan="9">Polar angle</th></tr><tr><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="char" char="." valign="bottom" colspan="2">95% CI</th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr><tr><th align="left" valign="bottom">Names</th><th align="left" valign="bottom">Effect</th><th align="left" valign="bottom">Estimate</th><th align="left" valign="bottom">SE</th><th align="left" valign="bottom">Lower</th><th align="left" valign="bottom">Upper</th><th align="left" valign="bottom">df</th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom">p</th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">18.58</td><td align="char" char="." valign="bottom">0.27</td><td align="char" char="." valign="bottom">18.06</td><td align="char" char="." valign="bottom">19.11</td><td align="char" char="." valign="bottom">179</td><td align="char" char="." valign="bottom">69.58</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Hemisphere</td><td align="left" valign="bottom">RH–LH</td><td align="char" char="." valign="bottom">−2.44</td><td align="char" char="." valign="bottom">0.28</td><td align="char" char="." valign="bottom">−2.99</td><td align="char" char="." valign="bottom">−1.89</td><td align="char" char="." valign="bottom">189</td><td align="char" char="." valign="bottom">−8.71</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Visual area (1)</td><td align="left" valign="bottom">V2–V1</td><td align="char" char="." valign="bottom">1.93</td><td align="char" char="." valign="bottom">0.33</td><td align="char" char="." valign="bottom">1.29</td><td align="char" char="." valign="bottom">2.57</td><td align="char" char="." valign="bottom">323</td><td align="char" char="." valign="bottom">5.90</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Visual area (2)</td><td align="left" valign="bottom">V3–V1</td><td align="char" char="." valign="bottom">3.54</td><td align="char" char="." valign="bottom">0.32</td><td align="char" char="." valign="bottom">2.92</td><td align="char" char="." valign="bottom">4.16</td><td align="char" char="." valign="bottom">288</td><td align="char" char="." valign="bottom">11.22</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Portion</td><td align="left" valign="bottom">Ventral–dorsal</td><td align="char" char="." valign="bottom">−2.12</td><td align="char" char="." valign="bottom">0.29</td><td align="char" char="." valign="bottom">−2.69</td><td align="char" char="." valign="bottom">−1.54</td><td align="char" char="." valign="bottom">207</td><td align="char" char="." valign="bottom">−7.20</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Intra-individual variability</td><td align="left" valign="bottom">Intra-individual variability</td><td align="char" char="." valign="bottom">2.90</td><td align="char" char="." valign="bottom">0.16</td><td align="char" char="." valign="bottom">2.58</td><td align="char" char="." valign="bottom">3.22</td><td align="char" char="." valign="bottom">1364</td><td align="char" char="." valign="bottom">17.81</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Individual variability in curvature</td><td align="left" valign="bottom">Individual variability in curvature</td><td align="char" char="." valign="bottom">0.40</td><td align="char" char="." valign="bottom">0.14</td><td align="char" char="." valign="bottom">0.12</td><td align="char" char="." valign="bottom">0.68</td><td align="char" char="." valign="bottom">1812</td><td align="char" char="." valign="bottom">2.82</td><td align="char" char="." valign="bottom">0.005</td></tr><tr><td align="left" valign="bottom">Individual variability in mean BOLD signal</td><td align="left" valign="bottom">Individual variability in mean BOLD signal</td><td align="char" char="." valign="bottom">0.21</td><td align="char" char="." valign="bottom">0.19</td><td align="char" char="." valign="bottom">−0.16</td><td align="char" char="." valign="bottom">0.57</td><td align="char" char="." valign="bottom">597</td><td align="char" char="." valign="bottom">1.11</td><td align="char" char="." valign="bottom">0.268</td></tr></tbody></table><table-wrap-foot><fn><p>SE – standard error; CI – confidence interval.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Fixed effects parameter estimates for the linear mixed-effects model of individual variability of eccentricity maps using covariates.</title><p>The covariates included in the model were intra-individual variability in pRF estimates, and individual variability in curvature and the mean BOLD signal.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" colspan="9">Polar angle</th></tr><tr><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="char" char="." valign="bottom" colspan="2">95% CI</th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr><tr><th align="left" valign="bottom">Names</th><th align="left" valign="bottom">Effect</th><th align="left" valign="bottom">Estimate</th><th align="left" valign="bottom">SE</th><th align="left" valign="bottom">Lower</th><th align="left" valign="bottom">Upper</th><th align="left" valign="bottom">df</th><th align="left" valign="bottom"><italic>t</italic></th><th align="left" valign="bottom">p</th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.81</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.78</td><td align="char" char="." valign="bottom">0.84</td><td align="char" char="." valign="bottom">179</td><td align="char" char="." valign="bottom">54.64</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Hemisphere</td><td align="left" valign="bottom">RH–LH</td><td align="char" char="." valign="bottom">−0.07</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">−0.09</td><td align="char" char="." valign="bottom">−0.05</td><td align="char" char="." valign="bottom">201</td><td align="char" char="." valign="bottom">−6.40</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Visual area (1)</td><td align="left" valign="bottom">V2–V1</td><td align="char" char="." valign="bottom">−0.02</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">−0.05</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">506</td><td align="char" char="." valign="bottom">−1.52</td><td align="char" char="." valign="bottom">0.128</td></tr><tr><td align="left" valign="bottom">Visual area (2)</td><td align="left" valign="bottom">V3–V1</td><td align="char" char="." valign="bottom">−0.02</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">−0.05</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">262</td><td align="char" char="." valign="bottom">−1.20</td><td align="char" char="." valign="bottom">0.231</td></tr><tr><td align="left" valign="bottom">Portion</td><td align="left" valign="bottom">Ventral–dorsal</td><td align="char" char="." valign="bottom">−0.07</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">−0.11</td><td align="char" char="." valign="bottom">−0.03</td><td align="char" char="." valign="bottom">186</td><td align="char" char="." valign="bottom">−3.24</td><td align="char" char="." valign="bottom">0.001</td></tr><tr><td align="left" valign="bottom">Intra-individual variability</td><td align="left" valign="bottom">Intra-individual variability</td><td align="char" char="." valign="bottom">0.21</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.20</td><td align="char" char="." valign="bottom">0.23</td><td align="char" char="." valign="bottom">1982</td><td align="char" char="." valign="bottom">26.51</td><td align="char" char="." valign="bottom">&lt;0.001</td></tr><tr><td align="left" valign="bottom">Individual variability in curvature</td><td align="left" valign="bottom">Individual variability in curvature</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">−0.00</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">1829</td><td align="char" char="." valign="bottom">1.52</td><td align="char" char="." valign="bottom">0.128</td></tr><tr><td align="left" valign="bottom">Individual variability in mean BOLD signal</td><td align="left" valign="bottom">Individual variability in mean BOLD signal</td><td align="char" char="." valign="bottom">0.02</td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.00</td><td align="char" char="." valign="bottom">0.03</td><td align="char" char="." valign="bottom">489</td><td align="char" char="." valign="bottom">2.34</td><td align="char" char="." valign="bottom">0.020</td></tr></tbody></table><table-wrap-foot><fn><p>SE – standard error; CI – confidence interval.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-3"><title>Common modes of variability</title><p>Next, we performed an exploratory analysis to determine whether polar angle maps differ from the average map in similar ways, particularly in the dorsal portion of early visual cortex of the left hemisphere (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Note that an analogous analysis was performed for eccentricity maps, but in agreement with our statistical models we did not find meaningful differences across eccentricity map clusters (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We computed the extent of overlap between discrete polar angle maps from all possible pairs of individuals using the Jaccard index, resulting in a similarity matrix (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). Next, we applied a spectral clustering algorithm with a fixed number of clusters equal to 6 (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). Finally, we averaged the continuous polar angle maps across individuals within each cluster to visualize common patterns of retinotopic organization in the dorsal portion of early visual cortex (<xref ref-type="fig" rid="fig4">Figure 4c</xref>; see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> for the complete set of average maps based on <xref ref-type="fig" rid="fig4">Figure 4c</xref> clustering assignment).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Clusters of retinotopic organization in the dorsal portion of early visual cortex.</title><p>(<bold>a</bold>) Continuous polar angle maps were converted into discrete maps, such that each vertex would be categorized into one out of four possible labels. Spatial overlap between discrete maps was estimated using the Jaccard similarity coefficient from all possible pairs of individuals, resulting in a 181 × 181 similarity matrix. (<bold>b</bold>) Then, we applied a spectral clustering algorithm – setting the number of clusters to 6. (<bold>c</bold>) An average map (discrete and continuous) was calculated for each cluster by averaging the continuous polar angle maps across all individuals within each cluster.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Clusters of eccentricity maps of the dorsal portion of early visual cortex.</title><p>An average continuous map was calculated for each cluster by averaging the continuous eccentricity maps across all individuals within each cluster.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Average polar angle, eccentricity, and normalized mean BOLD signal maps from each cluster and hemisphere.</title><p>Average continuous polar angle, eccentricity, and normalized mean BOLD signal maps were calculated for each cluster by averaging the continuous maps across all individuals within each cluster. As in the manuscript, the cluster assignment was based on the clustering analysis with polar angle maps from the dorsal portion of the early visual cortex and left hemisphere.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig4-figsupp2-v1.tif"/></fig></fig-group><p>Our findings clearly indicate shared patterns of retinotopic organization that deviate from the canonical polar angle representation in the dorsal portion of early visual cortex (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). Specifically, average maps from clusters 1 and 5 capture nearly a third of individuals and show canonical polar angle representations, with clear boundaries between V1/V2 and V2/V3 (<xref ref-type="fig" rid="fig1">Figure 1c</xref> and <xref ref-type="fig" rid="fig4">Figure 4c</xref>). However, clusters 2, 3, and 4 capture nearly two-thirds of individuals and deviate from this canonical polar angle representation (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). The average map from cluster 2 shows that the boundaries between V1 and V2, and the most anterior portion of V3 and higher-order visual areas, merge to form a Y-shaped (or forked) lower vertical representation. Clusters 3 and 4 show a truncated V3 boundary, indicating that dorsal V3 does not cover the entire quarter visual field (i.e., from 360° to 270°) either throughout its length or only in its most anterior portion. Finally, cluster 6 reflects unclear retinotopic organization, with a handful of individuals’ retinotopic maps showing overall low correspondence with the canonical retinotopic organization.</p><p>Qualitatively, individual maps seem to agree with their corresponding average cluster map, but there are some exceptions (<xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1</xref>–<xref ref-type="fig" rid="fig5s6">6</xref>). <xref ref-type="fig" rid="fig5">Figure 5</xref> shows the average cluster maps from each cluster and examples of individuals’ maps that are qualitatively similar and dissimilar to their corresponding average cluster map. While most polar angle maps correspond well with their average cluster maps (as seen in the middle row of <xref ref-type="fig" rid="fig5">Figure 5</xref>), there is also an apparent mismatch between a few maps and their corresponding cluster average (bottom row in <xref ref-type="fig" rid="fig5">Figure 5</xref>). For example, individual #132118 was assigned to cluster 4, but their polar angle map is qualitatively more similar to cluster 5. These mismatches are likely due to the extensive overlap between within- and between-cluster distributions of pair-wise Jaccard scores (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Note in <xref ref-type="fig" rid="fig6">Figure 6</xref> that the within-cluster distributions highlighted in gray are generally shifted to the right compared to the between-cluster distributions, indicating their higher Jaccard scores. However, the overlap between these distributions is substantial. For example, the between cluster 1 and 5 distribution overlaps with within-cluster 1 distribution throughout its entirety, which is justified by the significant similarity between their average maps. Despite this, we found that the average within-cluster Jaccard score is 0.54 (standard deviation (SD) = 0.07), while the average between-cluster score is 0.46 (SD = 0.08), showing that pairs of maps within a cluster are, on average, more similar than between clusters.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Qualitative evaluation of clusters.</title><p>Average cluster maps are shown in the top row. The middle row shows examples of maps from each cluster with a similar retinotopic organization to the corresponding average map. Finally, in the bottom row, examples of those with dissimilar organizations are shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Nine randomly selected polar angle maps within cluster 1.</title><p>The average discrete map of cluster 1 is shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Individual polar angle maps within cluster 2.</title><p>The average discrete map of cluster 2 is shown. All individuals’ polar angle maps within cluster 2 (total of 26 individuals) are shown for qualitative examination.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Nine randomly selected polar angle maps within cluster 3.</title><p>The average discrete map of cluster 3 is shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig5-figsupp3-v1.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>Nine randomly selected polar angle maps within cluster 4.</title><p>The average discrete map of cluster 4 is shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig5-figsupp4-v1.tif"/></fig><fig id="fig5s5" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 5.</label><caption><title>Nine randomly selected polar angle maps within cluster 5.</title><p>The average discrete map of cluster 5 is shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig5-figsupp5-v1.tif"/></fig><fig id="fig5s6" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 6.</label><caption><title>Nine randomly selected polar angle maps within cluster 6.</title><p>The average discrete map of cluster 6 is shown.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig5-figsupp6-v1.tif"/></fig></fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Distributions of pair-wise Jaccard scores.</title><p>Within- and between-cluster distribution of Jaccard scores across all pairs of individuals. Within-cluster distributions are highlighted in gray. Between-cluster distributions are the same regardless of the order of the clusters, that is, the Jaccard score distribution between clusters 1 and 2 (between 1 and 2) is the same as the one between clusters 2 and 1. Black vertical lines indicate distributions’ means.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig6-v1.tif"/></fig></sec><sec id="s2-4"><title>Visual field sign analysis for delineating visual area boundaries</title><p>Finally, we further examined retinotopic maps with a Y-shaped lower vertical representation, that is, those primarily assigned to cluster 2, to elucidate the kind of deviation from the canonical maps they represent (<xref ref-type="fig" rid="fig7">Figure 7</xref> and <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). To do so, we performed a visual field sign analysis (<xref ref-type="bibr" rid="bib55">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib54">Sereno et al., 1994</xref>), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image or a mirror-image representation of the retina (<xref ref-type="fig" rid="fig7">Figure 7a</xref>; see Materials and methods). With such representation, we can directly infer visual area parcellation.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Visual field sign analysis for delineating visual areas.</title><p>(<bold>a</bold>) The visual field sign analysis (<xref ref-type="bibr" rid="bib55">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib54">Sereno et al., 1994</xref>) combines polar angle and eccentricity maps (not shown) into a unique representation of the visual field as either a non-mirror-image (like V2) or a mirror-image (like V1) representation of the retina. This analysis consists of determining the angle between the polar angle and eccentricity maps’ gradient vectors, respectively, the green and purple vectors, at each cortical coordinate. If the angle between the gradient vectors is between 0 and <italic>π</italic>, by convention, the cortical patch is a mirror-image representation of the retina; otherwise, it is a non-mirror-image. (<bold>b</bold>) Six examples of left hemisphere polar angle maps with canonical (on the left) and non-canonical (on the right) representations in the dorsal portion of early visual cortex are shown (top row). Polar angle gradients are shown in a ‘streamline’ representation to highlight reversals in the progression of the polar angle values. Their respective visual field sign representation (bottom row) is also shown. While it was unclear how to delineate boundaries in the dorsal portion of polar angle maps in those participants with non-canonical maps, the visual field sign representation reveals that the area identified as dorsal V3 shows a discontinuity in the canonical mirror-image representation (solid white circles).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Visual field sign analysis for delineating visual areas.</title><p>Five more examples of left hemisphere polar angle maps with unusual Y-shaped lower vertical representations are shown in the top half. Polar angle gradients are shown in a ‘streamline’ representation (first row) with their respective visual field sign representation (second row). In the bottom half are five other examples of polar angle maps with a truncated V3 boundary, indicating that dorsal V3 does not cover the entire quarter visual field (i.e., from 360° to 270°). Despite that, the visual field sign representation does not show discontinuity in the typical mirror-image representation of dorsal V3.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86439-fig7-figsupp1-v1.tif"/></fig></fig-group><p><xref ref-type="fig" rid="fig7">Figure 7b</xref> shows polar angle gradients in a ‘streamline’ representation and their respective visual field sign representation for two participants with canonical and four with Y-shaped lower vertical representations. While visual area boundaries in early visual cortex are conventionally identified by reversals in the progression of the polar angle values – or changes in the direction of polar angle gradients, it is unclear how to delineate boundaries in the dorsal portion of polar angle maps in those participants with non-canonical maps (note that their respective ventral portion followed the classical representation), but not on those with canonical maps. However, with the visual field sign representation, the boundaries delineating dorsal V2 in those participants with non-canonical maps are more explicit, and it reveals that the area identified as dorsal V3 shows a discontinuity in the expected mirror-image representation. Such representation has been proposed as the ‘incomplete-V3’ model of the third-tier cortex for the macaque (<xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>) and other similar models for the owl monkey (<xref ref-type="bibr" rid="bib56">Sereno et al., 2015</xref>) and the marmoset monkey (<xref ref-type="bibr" rid="bib47">Rosa and Tweedale, 2000</xref>). <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref> shows five more examples of polar angle maps with unusual Y-shaped lower vertical representations and five other examples with a truncated V3 boundary. While individuals with unusual Y-shaped lower vertical representations have a discontinuity in the canonical mirror-image representation of the retina in dorsal V3, individuals with a truncated V3 do not show such a discontinuity. Altogether, our findings may suggest that, at least in humans, the canonical model does not oppose other models established for non-human primates; these models coexist and reflect common modes of variability in the retinotopic mapping of early visual areas.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we systematically investigated individual variability in visual field representation of human early visual cortex using the HCP 7T retinotopy dataset. We found that retinotopic maps in the left hemisphere were more variable than those in the right hemisphere. Moreover, in the left hemisphere the dorsal portions of early visual areas were more variable than their ventral counterparts, and these effects were not merely due to trivial large-scale intra-individual variability in pRF estimates or individual variability in curvature and the mean BOLD signal. Thus, we investigated whether there were common motifs in the observed individual variability in retinotopic maps of left hemispheres. This analysis showed that deviations from the canonical model of continuous, alternating bands of vertical and horizontal meridian representation in V2 and V3 exist in the majority of individuals. Specifically, the visual field sign analysis revealed that the area identified as dorsal V3 shows a discontinuity in the expected mirror-image representation of the retina in individuals with a Y-shaped lower vertical representation in the dorsal portion of early visual cortex. Overall, our findings challenge the current view that the dorsal portions of early visual areas form retinotopic maps which are consistent between individuals and are roughly mirror images of their ventral counterparts.</p><sec id="s3-1"><title>Individual variability in retinotopy</title><p>Although previous evidence for the variability seen across dorsal early visual cortex in humans has been mostly anecdotal, a number of studies have indicated a complex, retinotopic organization of dorsal early visual areas in non-human primates, using both electrophysiological recordings and high-resolution fMRI (<xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>; <xref ref-type="bibr" rid="bib15">Gattass et al., 1988</xref>; <xref ref-type="bibr" rid="bib56">Sereno et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">Zhu and Vanduffel, 2019</xref>). Accordingly, there is a long-standing debate about the number of visual areas – and their boundaries – in the third-tier visual cortex of New and Old-World monkeys (<xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>; <xref ref-type="bibr" rid="bib20">Hadjidimitrakis et al., 2019</xref>). However, the question of whether the areal boundaries in this region show significant individual variability has not been studied systematically in non-human primates. Only (<xref ref-type="bibr" rid="bib15">Gattass et al., 1988</xref>) reported, in the macaque monkey, that the representation of the lower vertical meridian in dorsal V3 varied across individuals, but firm conclusions could not be drawn due to the small sample. These authors indicated that some animals showed a continuous representation of this meridian along the rostral border of this area, whereas in others additional field discontinuities created a discontinuous representation. Notably, the same discontinuities in the anterior border of dorsal V3 were also found in our systematic investigation of individual variability in human polar angle maps. It is also significant that the same pattern of variation (relatively simple and reproducible representations of the upper contralateral quadrant, and complex and variable representations of the lower quadrant) characterize V2 and V3 in at least one non-primate, the cat (<xref ref-type="bibr" rid="bib49">Rosa and Manger, 2005</xref>; <xref ref-type="bibr" rid="bib61">Tusa et al., 1979</xref>). Overall, our findings in humans demonstrate that the organization of dorsal early visual areas is more heterogeneous than previously acknowledged and suggest that this may be a common feature of mammals with developed vision.</p><p>Our results also indicate that the variability in retinotopic organization increases between V1 and V2, and between V2 and V3. These findings are compatible with a model whereby retinotopic maps develop sequentially from ‘core’ areas like V1, where maps are determined by genetically encoded molecular gradients, toward late-maturing areas, where their formation occurs interactively through a wire-length minimization rule, allowing progressively greater degrees of freedom (<xref ref-type="bibr" rid="bib70">Yu et al., 2020</xref>). The fact that the organization of ventral maps tends to be more reproducible than that of dorsal maps may be related to the presence of the middle temporal area (MT, or V5) as a second ‘anchor’ node for the formation of dorsal maps in the proximity of the dorsal cortex, resulting in merging maturational gradients in the region of dorsal V3 and V4 (<xref ref-type="bibr" rid="bib50">Rosa and Tweedale, 2005</xref>).</p><p>Although different models of third-tier visual cortex organization in non-human primates (<xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>) also suggest unusual eccentricity mapping, we did not find meaningful differences in clusters of eccentricity maps (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) nor in the average eccentricity maps based on clusters from <xref ref-type="fig" rid="fig4">Figure 4c</xref> (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). This may be associated with the limited extent of the visual stimulus (up to 8° of eccentricity) (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>) and remains to be further investigated. Indeed, much of the controversy regarding the organization of dorsal areas in non-human primates refers to regions anterior to the peripheral representations in V2 (<xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>). Another alternative is having a complex pattern of polar angle representation coexisting with a preserved eccentricity gradient, as demonstrated by previous work in areas V2 and V3 of cats (<xref ref-type="bibr" rid="bib61">Tusa et al., 1979</xref>), flying foxes (<xref ref-type="bibr" rid="bib46">Rosa, 1999</xref>), ferrets (<xref ref-type="bibr" rid="bib33">Manger et al., 2002</xref>), and tree shrews (<xref ref-type="bibr" rid="bib53">Sedigh-Sarvestani et al., 2021</xref>).</p><p>Our investigation provides firm evidence for individual variability in the retinotopic organization across parts of early visual areas in the human visual cortex. Moreover, the exploratory analysis indicates the presence of shared patterns of retinotopic organization that deviate from the canonical polar angle representation in the dorsal portion of early visual cortex. Future work could extend these insights through additional analyses – for example, by employing different similarity metrics, using different features, or changing the number of clusters. Here, we limited our analysis to the spatial overlap of discrete polar angle maps, which means that a pair of qualitatively similar but spatially misaligned polar angle maps, for example, might have a low Jaccard score. If another more suitable metric can consider the topographic organization of polar angle maps regardless of the spatial location, it would be possible to increase the consistency between an individual’s map and their cluster average map. It would also be possible to estimate the similarity between two individuals’ retinotopic maps from specific features extracted from the maps, such as linear magnification along isoeccentricity lines, to provide insights into changes in these properties as a function of cortical location (<xref ref-type="bibr" rid="bib52">Schira et al., 2010</xref>). Another option would be to use the visual field sign representation directly for clustering individuals based on the non-mirror-image and mirror-image representation of the retina across early visual cortex. Finally, it is important to note that selecting the ideal number of clusters depends on the similarity metric employed, prior knowledge, and the clustering algorithm. Therefore, future work could be performed to explore the effect of the number of clusters on clustering quality (perhaps as indicated by within- vs. between-cluster similarity measures).</p></sec><sec id="s3-2"><title>Potential sources of individual variability in retinotopy</title><p>Given the presence of individual variability across early visual cortex in humans, another potential line of investigation involves the origin of this variability. Pertinently, we recently developed a deep learning model of retinotopy able to predict this individual variability from anatomical information (including curvature) (<xref ref-type="bibr" rid="bib40">Ribeiro et al., 2021</xref>), suggesting that it is, to some extent, a structure-related variation. Accordingly, here we modeled individual variability in curvature as an anatomy-related covariate, which significantly affected the individual variability of polar angle maps. Additionally, to determine if our findings were not merely due to other covariates, we included the normalized mean BOLD signal and intra-individual variability in pRF estimates as additional covariates. The former is an important proxy for the location of large veins (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Kurzawski et al., 2022</xref>), which are known to affect pRF estimates (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>; <xref ref-type="bibr" rid="bib68">Winawer et al., 2010</xref>). The latter is a proxy for the reliability of individuals’ retinotopic maps, which could vary across visual areas. While we found a significant effect of intra-individual variability, the main effects of all factors (hemispheres, visual areas, and portions) on individual variability of polar angle maps persisted. This finding indicates that these large-scale effects were not merely due to the covariates included in the model. Note, however, that as we only consider the effect of large-scale deviations (averaged over a region of interest) of each of these covariates on large-scale variability of the retinotopic maps, it could be the case they still have a crucial role in local variability, which we further discuss in the Limitations.</p><p>Retinotopic maps could also vary as a function of data resolution and cortical depth. For example, signal-to-noise ratio (SNR) and partial volume artifacts are directly affected by data resolution (or voxel size); that is, both reduce with voxel size (<xref ref-type="bibr" rid="bib23">Hoffmann et al., 2009</xref>). While lower SNR might lead to noisier (or less smooth) retinotopic maps (<xref ref-type="bibr" rid="bib23">Hoffmann et al., 2009</xref>), the gain from the reduced susceptibility to partial volume artifacts will likely result in increased validity of the observed maps. Partial volume artifacts may arise from patches of opposite walls of a sulcus running across a single voxel or even small vessels, leading to inaccurate signals from the combination of different brain regions and tissues. With increasing magnetic field strength, it should be easier to strike the right balance between high SNR and low partial volume artifacts, which is crucial for determining the impact of registration errors due to partial volume artifacts on the variability of retinotopic maps. Moreover, previous studies have also shown that the hemodynamic response function (<xref ref-type="bibr" rid="bib37">Puckett et al., 2016</xref>) and a spatial pattern of activation (<xref ref-type="bibr" rid="bib36">Polimeni et al., 2010</xref>) varied across depths in V1. Specifically, Polimeni et al. found that a spatial pattern of activation (an ‘M’) becomes clearer from the white matter surface to the mid-thickness surfaces and then deteriorates once again near the pial surface. Altogether, these studies motivate a more thorough investigation of how retinotopy, as measured by fMRI, varies as a function of data resolution and cortical depth and its implication on individual variability in retinotopy. However, it is also important to note that studies of the columnar organization of non-human primates using single-cell recordings have not found any evidence that the receptive field location varies with cortical depth, although the receptive field size changes, being smallest in the middle layers (<xref ref-type="bibr" rid="bib26">Hubel and Wiesel, 1974</xref>; <xref ref-type="bibr" rid="bib45">Rosa et al., 1997</xref>).</p><p>Another potential research direction is determining the extent to which eye movement underlies some of the variability found in retinotopic maps of early visual areas. For example, one could systematically evaluate pRF modeling accuracy as a function of gaze position change (and other eye-tracking signal derivatives). We performed a preliminary analysis of the deviation in gaze position at each time point and averaged across runs of retinotopic mapping stimuli and individuals assigned to each cluster. <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref> summarizes the average deviation of gaze position from the fixation point along the <italic>X</italic> and <italic>Y</italic> axes for each cluster. In brief, we did not find consistent results across clusters. However, we do not rule out the effect of eye movement on the variability of the retinotopic maps because the eye-tracking data quality is variable and unavailable for some individuals in the HCP retinotopy dataset (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>), and the clustering quality could be improved (e.g., through manual clustering or the other approaches previously discussed). Another possibility is determining the reliability of these retinotopic maps through connective field modeling (<xref ref-type="bibr" rid="bib19">Haak et al., 2013</xref>) with unconstrained eye movement data (<xref ref-type="bibr" rid="bib59">Tangtartharakul et al., 2023</xref>). Yet, we observe that unusual maps in the dorsal portion of the early visual cortex coincide with canonical representations in the ventral portion (<xref ref-type="fig" rid="fig7">Figure 7</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>), which is unlikely to be the case for noisy data driven by massive eye movements.</p></sec><sec id="s3-3"><title>Limitations</title><p>Although we demonstrate that common modes of deviation from the canonical dorsal V2 and V3 organization exist in the left hemisphere, further analyses are necessary to fully ascertain if such variability is indeed neurogenic or if it could be a result of measurement errors. Among potential sources of measurement error are the presence of large veins running adjacent to regions of interest. Accordingly, by using the normalized mean BOLD signal as a proxy for the location of large veins (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Kurzawski et al., 2022</xref>), studies have shown that voxels near these veins show lower mean BOLD signal, a phenomenon known as the venous eclipse, which affects pRF estimates, for example, in area hV4 (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>; <xref ref-type="bibr" rid="bib68">Winawer et al., 2010</xref>). As such, deviations in the expected mean BOLD signal could result in deviations from the expected retinotopic organization. Thus, to better understand the potential effects of the presence of large veins on the different levels of variability in visual field representation across early visual areas, we considered both the pair-wise correlations between retinotopic maps and the normalized mean BOLD signal (<xref ref-type="fig" rid="fig3">Figure 3</xref>) and the large-scale deviation in the normalized mean BOLD signal as covariates in the LME model (<xref ref-type="table" rid="table3 table4">Tables 3 and 4</xref>).</p><p>In the pair-wise correlation analysis, we found that the polar angle representation is indeed correlated with the normalized mean BOLD signal, and the magnitude of such association varies across visual areas. Specifically, we found a higher correlation (in magnitude) between the polar angle and normalized BOLD signal in ventral visual areas than in dorsal areas. This difference could be explained by ventral areas’ proximity to the dural venous sinuses (<xref ref-type="bibr" rid="bib68">Winawer et al., 2010</xref>), that is, the transverse sinus, the superior sagittal sinus, and the straight sinus. These venous sinuses are known to introduce artifacts to the BOLD signal, which might lead to changes in retinotopic maps. Importantly, none of these sinuses run near the dorsal V2 and V3 (see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, in which it is possible to observe the likely confluence of sinuses), and both of which show the lowest correlation between polar angle and normalized BOLD signal maps.</p><p>Moreover, we modeled large-scale deviation in visual field maps using the large-scale deviation of the normalized mean BOLD signal as a covariate. We did find a significant effect of the normalized mean BOLD signal on the individual variability of eccentricity (<xref ref-type="table" rid="table4">Table 4</xref>) but not of polar angle maps (<xref ref-type="table" rid="table3">Table 3</xref>). Thus, to determine the effectiveness of the LME model for uncovering the effects of covariates, we similarly modeled the large-scale variability in polar angle maps of hV4 (not shown in the manuscript). We did not find an effect of the normalized mean BOLD signal on large-scale deviation in polar angle maps in hV4. However, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: <italic>r</italic> = −0.06; RH: <italic>r</italic> = −0.07). This finding does not reconcile with previous reports, that is, that venous artifact impacts retinotopy. However, a fine-grained analysis of polar angle maps in hV4 indicated the inconsistent effect of the venous artifact on polar angle mapping (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>). In our analysis, though, these results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation; while early visual areas are more consistently found at specific spatial locations, this is not the case for other visual areas of which spatial location and extent seem to vary across participants. Therefore, although we did not find a significant effect of the normalized mean BOLD signal in our LME model, it does not mean that the macro- and microvasculature do not affect retinotopy. For the former, future research might consider a fine-grained analysis of topographic deviations, such as the one reported by (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>). For the latter, given that the mean BOLD signal is only used as a proxy for the location of large veins, a more detailed analysis of the microvasculature might require other imaging data, such as high-resolution time-of-flight magnetic resonance angiography data (<xref ref-type="bibr" rid="bib9">Bollmann et al., 2022</xref>).</p></sec><sec id="s3-4"><title>Future directions</title><p>Our findings raise questions about if and how cortical atlases should be revisited to accommodate deviations from the canonical model of retinotopic organization, especially for dorsal V3. Here, by using the visual field sign representation, we could better understand what kind of deviation from the canonical model atypical maps represent. Therefore, using such data representation could be helpful for the manual segmentation of atypical maps. Alternatively, combining deep learning models (<xref ref-type="bibr" rid="bib40">Ribeiro et al., 2021</xref>) for generating a retinotopic prior that accommodates more variability with a Bayesian framework (<xref ref-type="bibr" rid="bib8">Benson and Winawer, 2018</xref>) for boundary delineation might prove fruitful to support the need for automated individual-level parcellation methods. It would also be desirable to use functional characteristics of areas, such as the responses to specific types of visual stimulation, to increase the confidence in assignment of boundaries. Whereas this may be possible in some situations (e.g., using motion selectivity as a localizer for area MT; <xref ref-type="bibr" rid="bib35">Pitzalis et al., 2010</xref>), attempts to segregate V3 from adjacent areas on this basis may be more challenging, due to the physiological similarity between this area and the adjacent V2 and V3a (<xref ref-type="bibr" rid="bib16">Gegenfurtner et al., 1997</xref>; <xref ref-type="bibr" rid="bib31">Levitt et al., 1994</xref>; <xref ref-type="bibr" rid="bib72">Zeki, 1978</xref>). Differences in pRF size (<xref ref-type="bibr" rid="bib73">Zhu and Vanduffel, 2019</xref>) could offer some insight, although the wide overlap in the distributions of single-unit receptive field sizes in adjacent areas (<xref ref-type="bibr" rid="bib44">Rosa, 1997</xref>) suggests that obtaining clear-cut boundaries on this basis remains unlikely.</p><p>Importantly, accommodating individual variability for the automatic parcellation of visual areas is also crucial for understanding the functional properties of the human visual cortex. These analyses require the precise delineation of boundaries between visual areas, either by manually tracing transitions in visual field maps or by using an automatic segmentation method (<xref ref-type="bibr" rid="bib6">Benson et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Benson and Winawer, 2018</xref>; <xref ref-type="bibr" rid="bib11">Dougherty et al., 2003</xref>). In both cases, a spatially consistent mapping (i.e., a canonical representation) of continuous, alternating bands of vertical and horizontal meridian representation in V2 and V3 is often assumed. However, we demonstrate that deviations from the canonical model exist, especially in the left hemisphere and dorsal V3. This finding could have several implications for post hoc analyses requiring visual area delineation, suggesting that previous studies may have mischaracterized differences between these visual areas due to misidentification. Therefore, an important future direction of this work is determining how functional selectivity varies across visual areas parcellated according to the canonical model compared to using new parcels estimated with the visual field sign analysis.</p><p>In addition, the present findings highlight the need for a more comprehensive assessment of the degree of variability in visuotopic maps in non-human primates, where a higher degree of precision can be achieved with invasive methods including single neuron recordings and optical imaging of intrinsic signals. To date, variability has only been reported in macaque monkeys (<xref ref-type="bibr" rid="bib15">Gattass et al., 1988</xref>), but the available data in marmoset and owl monkeys indicate a reproducible organization that does not fully agree with the canonical model of dorsal V3 (<xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>; <xref ref-type="bibr" rid="bib43">Rosa and Schmid, 1995</xref>; <xref ref-type="bibr" rid="bib47">Rosa and Tweedale, 2000</xref>; <xref ref-type="bibr" rid="bib56">Sereno et al., 2015</xref>). Whether this simply reflects the small number of individuals explored, or a truly more stable configuration (perhaps associated with the larger brain size in humans; <xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>; <xref ref-type="bibr" rid="bib50">Rosa and Tweedale, 2005</xref>) remains to be determined.</p><p>Another finding that requires consideration is the interhemispheric difference revealed in our data: retinotopic maps in the left hemisphere showed more variation than those in the right hemisphere. To date, there has been no report of interhemispheric differences in early visual cortex of other mammals, including non-human primates. In part, this may be traced to the relatively small samples in these studies compared to those possible using human fMRI. However, another possibility is that such differences may arise more frequently in human brains due to the scaling of callosal connections with brain size (<xref ref-type="bibr" rid="bib42">Rilling and Insel, 1999</xref>), which may promote a higher degree of connectional independence during development.</p><p>Finally, these results raise many questions regarding how retinotopic maps develop. For example, studies modeling the formation of retinotopic maps in development have suggested that multistable solutions may occur depending on factors such as the degree of elongation of the area (<xref ref-type="bibr" rid="bib53">Sedigh-Sarvestani et al., 2021</xref>; <xref ref-type="bibr" rid="bib69">Wolf et al., 1994</xref>) and adjacency with other areas (<xref ref-type="bibr" rid="bib70">Yu et al., 2020</xref>), which do not violate the need to minimize the length of connections (<xref ref-type="bibr" rid="bib13">Durbin and Mitchison, 1990</xref>; <xref ref-type="bibr" rid="bib57">Swindale, 1996</xref>). Therefore, future work could evaluate whether there is an overlap between function- and anatomy-based clusters to help elucidate the developmental mechanisms underlying the variability of human dorsal extrastriate cortex.</p><p>In conclusion, using a large-scale brain imaging dataset, we provide new insights into the variability in the topographical organization of human visual cortex. These insights may prove crucial in guiding further experimental investigations and theories about retinotopic organization differentiation across species, development, and individuals.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Dataset</title><p>We used the HCP 7T Retinotopy dataset (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>) to investigate individual variability in retinotopic maps of human early visual cortex. This dataset consists of high-resolution functional retinotopic mapping and structural data from 181 participants (109 females, age 22–35) with normal or corrected-to-normal visual acuity. Participant recruitment and data collection were led by Washington University and the University of Minnesota. The Institutional Review Board (IRB) at Washington University approved all experimental procedures (IRB number 201204036; ‘Mapping the Human Connectome: Structure, Function, and Heritability’), and all participants provided written informed consent before data collection (<xref ref-type="bibr" rid="bib62">Van Essen et al., 2013</xref>). Additionally, the acquisition protocol has been described in previous work (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Van Essen et al., 2013</xref>).</p><p>Structural data were acquired at 0.7-mm isotropic resolution in a customized Siemens 3T Connectome scanner (<xref ref-type="bibr" rid="bib62">Van Essen et al., 2013</xref>). Briefly, cortical surfaces were reconstructed from T1w structural images using FreeSurfer and aligned to the 32k fs_LR standard surface space. This standard 32k fs_LR cortical surface consists of 32,492 vertices sparsely connected, forming triangular faces. Functional data were later aligned with this standard surface space.</p><p>Functional retinotopic mapping data were acquired using a Siemens 7T Magnetom scanner at 1.6-mm isotropic resolution and 1-s TR. Data were preprocessed following the HCP pipeline (<xref ref-type="bibr" rid="bib17">Glasser et al., 2013</xref>), which included correction for head motion and EPI spatial distortion, alignment of the fMRI data with the HCP standard surface space, and denoising for spatially specific structured noise. Retinotopic mapping stimuli comprised rotating wedges, expanding and contracting rings, and bars of different orientations moving across different directions in the visual field. A population receptive field (pRF) modeling procedure was then used to reconstruct visual field maps (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>; <xref ref-type="bibr" rid="bib12">Dumoulin and Wandell, 2008</xref>; <xref ref-type="bibr" rid="bib28">Kay et al., 2013</xref>), which encompasses estimating the spatial preference of cortical surface vertices to different locations of the visual field (i.e., its receptive field) defined in polar coordinates – for more, see <xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>. Hence, polar angle maps are retinotopic maps reflecting the polar angle (angle relative to the horizontal vertical meridian) in the visual field to which a vertex is most responsive, while eccentricity maps reflect the distance from the center of the visual field (i.e., the fixation point). The combination of a polar angle map and an eccentricity map completely specifies a map of the visual field, from the center of the visual field to at least 8° of eccentricity (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>).</p></sec><sec id="s4-2"><title>Region of interest</title><p>Early visual areas were defined by a surface-based probabilistic atlas (<xref ref-type="bibr" rid="bib67">Wang et al., 2015</xref>). This probabilistic atlas includes the dorsal and ventral portions of V1, V2, and V3, not including the foveal confluence. For the clustering analysis, we slightly modified the atlas by extending the dorsal border of V3 and including V1/V2/V3 foveal confluence (<xref ref-type="bibr" rid="bib51">Schira et al., 2009</xref>), in line with our previous work (<xref ref-type="bibr" rid="bib40">Ribeiro et al., 2021</xref>).</p></sec><sec id="s4-3"><title>Individual variability</title><p>We determined individual variability in visual field maps to quantify how variable these maps were across visual areas (V1, V2, and V3), portions (dorsal and ventral), and hemispheres (left and right) in human early visual cortex. First, we computed the average retinotopic maps across all 181 individuals from the HCP retinotopy dataset for both left and right hemispheres (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Then, we iteratively calculated the vertex-wise difference between an individual’s retinotopic map and the average map. The difference between two angles is given by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>for 0 &lt; <inline-formula><mml:math id="inf1"><mml:mi>θ</mml:mi></mml:math></inline-formula> &lt; 2<italic>π</italic>.</p><p>Finally, vertex-wise difference scores were averaged over vertices in the range of 1–8° of eccentricity within the dorsal and ventral portions of early visual areas, resulting in one scalar value per individual per visual area, which we refer to as the individual variability. The eccentricity mask was defined using the group-average eccentricity map. This range of eccentricity values was chosen because, in the original population receptive field mapping experiment of the HCP, the visual stimulus extended to 8° of eccentricity (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>). Additionally, due to the inherent difficulty in mapping the foveal confluence (<xref ref-type="bibr" rid="bib51">Schira et al., 2009</xref>), we constrained our comparison to eccentricity values above 1°. According to studies in non-human primates, this corresponds approximately to half of the expected extent of V1, V2, and V3 (<xref ref-type="bibr" rid="bib15">Gattass et al., 1988</xref>; <xref ref-type="bibr" rid="bib14">Gattass et al., 1981</xref>).</p></sec><sec id="s4-4"><title>LME model</title><p>We determined whether there were main effects and interactions of hemispheres (left and right), visual areas (V1, V2, and V3), and portions (dorsal and ventral) on individual variability of retinotopic maps using LME models. Standard analyses of variance and <italic>t</italic>-tests assume statistical independence of individuals’ data (<xref ref-type="bibr" rid="bib71">Yu et al., 2022</xref>), which is often not the case. For example, the 7T HCP retinotopy dataset includes data from 50 monozygotic and 34 dizygotic twins, totaling 168 individuals out of 181. Therefore, to meet the statistical independence criterion, many data points would have to be disregarded for standard statistical inference. However, LME models allow us to take full advantage of the dataset by explicitly modeling cluster-specific means (random intercepts). Indeed, individual variability from different visual areas is naturally clustered by individuals (<xref ref-type="bibr" rid="bib32">Magezi, 2015</xref>). Therefore, using this statistical model, we can appropriately model individual-specific effects (<xref ref-type="bibr" rid="bib32">Magezi, 2015</xref>; <xref ref-type="bibr" rid="bib71">Yu et al., 2022</xref>).</p><p>In our LME model, the dependent variable is the individual variability (<italic>Y</italic>), which is modeled as a function of the fixed effects (<italic>β</italic>) of three factors (<italic>x</italic>) and their interactions. These three factors are: hemisphere, visual area, and portion. Additionally, we also consider the random effects (<italic>γ</italic><sub><italic>i</italic></sub>) associated with the individual (<italic>i</italic> = 1, …, 181), and the random effects of each factor nested within the individual (<italic>γ</italic><sub><italic>ij</italic></sub>, with <italic>j</italic> = 1, 2, and 3). This model is expressed as:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>13</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>23</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>123</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>where <italic>β</italic><sub>0</sub> is the intercept and <italic>ε</italic> is the residual random error. We built two separate models for individual variability associated with polar angle and eccentricity maps using Jamovi (<xref ref-type="bibr" rid="bib60">The Jamovi project, 2021</xref>, n.d.).</p></sec><sec id="s4-5"><title>Individual variability in retinotopic maps and potential confounds</title><p>Other potential sources of individual variability in retinotopic maps can be readily included as covariates in LME models after their appropriate standardization by computing <italic>z</italic>-scores. Effectively, adding a covariate to an LME model adds a <inline-formula><mml:math id="inf2"><mml:mi>β</mml:mi><mml:mi>x</mml:mi></mml:math></inline-formula> term to <xref ref-type="disp-formula" rid="equ2">equation 2</xref>, where <italic>β</italic> is the estimated effect and <italic>x</italic> is the covariate. Here, we consider the effect of potential confounders, including curvature, normalized mean BOLD signal, and intra-individual variability in pRF estimates. These factors are known to be correlated with retinotopy and could explain part of the variability found across visual areas. Accordingly, we calculated pair-wise correlations among polar angle, eccentricity, curvature, and normalized mean BOLD signal for both V1–3 and each visual area separately. Given a region of interest, each topographic map was vectorized, and data were concatenated across all participants (<italic>n</italic> = 181) for each modality. Polar angle maps were converted such that 0° corresponds to the horizontal meridian and 90° corresponds to the upper and lower vertical meridians (<xref ref-type="bibr" rid="bib29">Kurzawski et al., 2022</xref>). Finally, pair-wise correlations were determined using these concatenated sets of vectorized maps. Below we provide further motivation for considering each of these covariates.</p><p>Curvature maps highlight the geometry of folding patterns of individuals’ cortical surfaces, with negative values representing sulci and positive gyri (as per the HCP dataset). In V1, the horizontal and vertical meridian representations of the visual field correlate with underlying sulcal patterns (<xref ref-type="bibr" rid="bib22">Hinds et al., 2008</xref>; <xref ref-type="bibr" rid="bib24">Holmes and Lister, 1916</xref>; <xref ref-type="bibr" rid="bib25">Horton and Hoyt, 1991</xref>; <xref ref-type="bibr" rid="bib27">Inouye, 1909</xref>; <xref ref-type="bibr" rid="bib38">Rajimehr and Tootell, 2009</xref>). This tight structure–function relationship was further leveraged for individual-level predictions of retinotopy from underlying anatomy, using atlas-fitting algorithms (<xref ref-type="bibr" rid="bib6">Benson et al., 2014</xref>; <xref ref-type="bibr" rid="bib5">Benson et al., 2012</xref>), a Bayesian model (<xref ref-type="bibr" rid="bib8">Benson and Winawer, 2018</xref>), and deep learning (<xref ref-type="bibr" rid="bib40">Ribeiro et al., 2021</xref>). Therefore, although curvature is a good predictor of retinotopy, it is unclear if it is sufficient to explain the systematic differences in individual variability across visual areas. Here, we consider the individual variability in curvature maps as a covariate. Individual variability in curvature was operationalized as the mean absolute difference between an individual’s curvature map and the corresponding average map over vertices in the range of 1–8° of eccentricity within the dorsal and ventral portions of early visual areas, resulting in one scalar value per individual per visual area.</p><p>The mean preprocessed BOLD signal was used as a proxy for the location of large veins (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Kurzawski et al., 2022</xref>), which are known to affect pRF estimates. Voxels near large veins show lower mean BOLD signal, a phenomenon known as the venous eclipse, which affects pRF estimates, for example, in area hV4 (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>; <xref ref-type="bibr" rid="bib68">Winawer et al., 2010</xref>). As such, deviations in the expected mean BOLD signal could lead to deviations from the expected retinotopic organization. Therefore, we considered individual variability in the mean BOLD signal as another covariate. To do so, we first normalized the mean BOLD signal (over the time course) by dividing the value of each vertex by the maximum intensity (<xref ref-type="bibr" rid="bib10">Boyd Taylor et al., 2019</xref>). Then, we computed the individual variability as previously described for curvature maps.</p><p>Finally, different levels of individual variability in retinotopic maps could also reflect variations in their reliability across visual areas. For example, in the HCP dataset, despite pRF estimates being highly consistent between two model fits (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>), there was still some intra-individual (between-fit) variability. Thus, we considered intra-individual variability in pRF estimates as a covariate. Intra-individual variability was operationalized as the difference in pRF estimates from two pRF model fits of half splits of the retinotopic mapping data (fit 2 and 3; <xref ref-type="supplementary-material" rid="supp7">Supplementary file 7</xref>), which were provided and determined using the first and second half of the temporal data from each run (<xref ref-type="bibr" rid="bib7">Benson et al., 2018</xref>). By using these two other fits, it is possible to assess the reliability of the pRF parameter estimates; hence, the difference in pRF estimates is a proxy for the reliability of individuals’ retinotopic maps and can be included as a covariate in the LME model.</p></sec><sec id="s4-6"><title>Clusters of spatial organization</title><p>We performed an exploratory clustering analysis to determine whether retinotopic maps differ from the average map in similar ways, particularly in the dorsal portion of early visual cortex. Specifically, we investigated the spatial overlap between retinotopic maps as an unambiguous indicator of the similarity between two maps. First, to obtain such a measure of the spatial overlap, the continuous polar angle maps were converted into discrete maps, such that each vertex was categorized into one out of four possible labels:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:msup><mml:mn>0</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>0</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msup><mml:mn>45</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mn>90</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>45</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msup><mml:mn>180</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mn>270</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>180</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>315</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mn>360</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>315</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>360</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>these categories were chosen because they highlight the location of visual area boundaries. Discrete eccentricity maps were determined by:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:msup><mml:mn>0</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>0</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msup><mml:mn>2</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mn>2</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>2</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msup><mml:mn>4</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mn>4</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>4</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msup><mml:mn>6</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mn>6</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:msup><mml:mn>6</mml:mn><mml:mo>∘</mml:mo></mml:msup><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Next, the spatial overlap between discrete maps from all possible pairs of individuals was estimated using the Jaccard similarity coefficient (<xref ref-type="bibr" rid="bib30">Levandowsky and Winter, 1971</xref>; <xref ref-type="bibr" rid="bib58">Taha and Hanbury, 2015</xref>). The Jaccard index estimates similarity between two maps by taking the size of the intersection (in number of vertices) divided by the size of the union of two label sets. Hence, the Jaccard score ranges from 0 to 1; the closer to 1 the score is, the more similar the two maps are. For our data and each pair of individuals, the Jaccard index is determined from the two possible individuals’ combinations (i.e., individual 1 vs. individual 2 and individual 2 vs. individual 1) since the order of the maps determines which map is the reference. For each combination, we estimated the Jaccard index for each label, and their weighted average was determined using the number of labels’ instances in the reference map to account for label imbalance. Then, these two estimates were averaged, resulting in one estimate of the spatial overlap between two individuals’ discrete retinotopic maps.</p><p>To assess whether inter-individual differences fell into stereotyped patterns, we applied a spectral clustering algorithm from Scikit-learn (<xref ref-type="bibr" rid="bib1">Abraham et al., 2014</xref>; <xref ref-type="bibr" rid="bib34">Pedregosa et al., 2011</xref>). This algorithm operates on the low-dimensional embedding of the affinity matrix (our Jaccard index-based similarity matrix), followed by <italic>K</italic>-means clustering of the components of the eigenvectors in the low-dimensional space. This low-dimensional space is determined by selecting the most relevant eigenvectors of the graph Laplacian of the affinity matrix, of which corresponding eigenvalues reflect important properties of the affinity matrix that can be used to partition it (<xref ref-type="bibr" rid="bib65">von Luxburg, 2007</xref>). In implementing the spectral clustering algorithm, we set the number of clusters to 6 and fixed the random state for replication purposes. We selected this number of clusters as there are at least five different models of third-tier visual cortex organization in non-human primates (<xref ref-type="bibr" rid="bib3">Angelucci and Rosa, 2015</xref>), with a sixth cluster intended to capture noisy or unclear retinotopic organization. Note, however, that this selection is simply a speculation of the possibility space and do not reflect known inter-individual differences in non-human primates. After clustering, we computed each cluster’s mean map by averaging the continuous retinotopic maps across individuals within each cluster.</p></sec><sec id="s4-7"><title>Visual field sign analysis</title><p>Lastly, we further examined unusual retinotopic maps to elucidate the kind of deviation from the canonical maps they represent. We performed a visual field sign analysis (<xref ref-type="bibr" rid="bib55">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib54">Sereno et al., 1994</xref>), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image (like V2) or a mirror-image representation of the retina (like V1). Since the left hemisphere represents the right visual field, which in polar angle includes 0–90° (upper right visual field) and 270–360° (lower right visual field), we shifted the polar angle values so the point of wrap-around (from 360° to 0°) was positioned at the horizontal meridian in the contralateral hemifield, avoiding the discontinuous representation between 360° and 0°. Then, we interpolated the sparse and flattened polar angle and eccentricity maps onto a regular <italic>x</italic>–<italic>y</italic> grid using SciPy (<xref ref-type="bibr" rid="bib64">Virtanen et al., 2020</xref>). Next, we determined the gradient of polar angle and eccentricity maps, mathematically expressed as:<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>θ</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>θ</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the polar angle map and <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the eccentricity, using the NumPy gradient numerical method (<xref ref-type="bibr" rid="bib21">Harris et al., 2020</xref>). Finally, the angle between the polar angle and eccentricity maps’ gradient vectors was determined at each <italic>x</italic>–<italic>y</italic> coordinate. If the angle between the gradient vectors is between 0 and <italic>π</italic>, by convention, the cortical patch is a mirror-image representation of the retina; otherwise, it is a non-mirror-image. After binarizing the angle projection, we can conveniently infer borders between visual areas because adjacent areas often have the opposite visual field sign (<xref ref-type="bibr" rid="bib55">Sereno et al., 1995</xref>; but see <xref ref-type="bibr" rid="bib70">Yu et al., 2020</xref> for caveat).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Funding acquisition, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>We used the Human Connectome Project (HCP) 7T Retinotopy dataset (Benson et al., 2018) to investigate individual variability in retinotopic maps of human early visual cortex. This dataset consists of high-resolution functional retinotopic mapping and structural data from 181 participants (109 females, age 22–35) with normal or corrected-to-normal visual acuity. Participant recruitment and data collection were led by Washington University and the University of Minnesota. The Institutional Review Board (IRB) at Washington University approved all experimental procedures (IRB number 201204036; 'Mapping the Human Connectome: Structure, Function, and Heritability'), and all participants provided written informed consent before data collection (Van Essen et al., 2013).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Linear mixed-effect model of individual variability of polar angle maps.</title><p>This file was exported from Jamovi.</p></caption><media xlink:href="elife-86439-supp1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Linear mixed-effect model of individual variability of eccentricity maps.</title><p>This file was exported from Jamovi.</p></caption><media xlink:href="elife-86439-supp2-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>Fixed effects parameter estimates for the linear mixed-effects model of individual variability of polar angle maps using covariates.</title><p>This file was exported from Jamovi.</p></caption><media xlink:href="elife-86439-supp3-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp4"><label>Supplementary file 4.</label><caption><title>Fixed effects parameter estimates for the linear mixed-effects model of individual variability of eccentricity maps using covariates.</title><p>This file was exported from Jamovi.</p></caption><media xlink:href="elife-86439-supp4-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp5"><label>Supplementary file 5.</label><caption><title>Fixed effects parameter estimates for the linear mixed-effects model of individual variability of polar angle maps using covariates, including age, gender, and gray matter volume as additional covariates.</title><p>This file was exported from Jamovi.</p></caption><media xlink:href="elife-86439-supp5-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp6"><label>Supplementary file 6.</label><caption><title>Gaze position change as a function of cluster assignment.</title><p>The mean deviation in gaze position along the <italic>X</italic> and <italic>Y</italic> axes across runs of retinotopic mapping stimuli presentation and individuals is shown for each cluster. We also show the number of individuals with eye-tracking data per cluster, given that eye-tracking data are not available for all individuals.</p></caption><media xlink:href="elife-86439-supp6-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp7"><label>Supplementary file 7.</label><caption><title>Summary of the data used for the analyses described in the main manuscript.</title></caption><media xlink:href="elife-86439-supp7-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-86439-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data used in this study are publicly available at <ext-link ext-link-type="uri" xlink:href="https://balsa.wustl.edu/study/show/9Zkk">BALSA</ext-link>. In addition, all accompanying Python and MATLAB source codes are available on <ext-link ext-link-type="uri" xlink:href="https://github.com/felenitaribeiro/VariabilityEarlyVisualCortex">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib41">Ribeiro and York, 2023</xref>). On our GitHub repository, executable code is available on interactive computational notebooks (Jupyter notebooks) that allow anyone to execute interactive plotting functions with dropdown menus to visualize an individual's polar angle and visual field sign maps, given their cluster assignment. Note that our documentation provides instructions for running them on Neurodesk (<xref ref-type="bibr" rid="bib39">Renton et al., 2022</xref>). Finally, the intermediate files for fitting the linear mixed-effect models using Jamovi are available on the <ext-link ext-link-type="uri" xlink:href="https://osf.io/tdkuj/">Open Science Framework</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Ribeiro</surname><given-names>FL</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Variability of visual field maps in human early extrastriate cortex challenges the canonical model of organization of V2 and V3</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/tdkuj/">tdkuj</pub-id></element-citation></p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Jamison</surname><given-names>KW</given-names></name><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Essen</surname><given-names>DCV</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name><name><surname>Vu</surname><given-names>AT</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>The HCP 7T Retinotopy Dataset</data-title><source>The Brain Analysis Library of Spatial Maps and Atlases</source><pub-id pub-id-type="accession" xlink:href="https://balsa.wustl.edu/study/show/9Zkk">9Zkk</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the Australian Research Council (DE180100433 and DP210101042) and National Health and Medical Research Council (APP1194206). Data were provided by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University. In addition, FLR acknowledges support through the Australian Government Research Training Program Scholarship. We thank the reviewers (Elisha Merriam, Tomas Knapen, and Noah C Benson) for helpful comments on early versions of our manuscript and Mark Schira for helpful discussions.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Eickenberg</surname><given-names>M</given-names></name><name><surname>Gervais</surname><given-names>P</given-names></name><name><surname>Mueller</surname><given-names>A</given-names></name><name><surname>Kossaifi</surname><given-names>J</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Machine learning for neuroimaging with scikit-learn</article-title><source>Frontiers in Neuroinformatics</source><volume>8</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id><pub-id pub-id-type="pmid">24600388</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>EJ</given-names></name><name><surname>St-Yves</surname><given-names>G</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Breedlove</surname><given-names>JL</given-names></name><name><surname>Prince</surname><given-names>JS</given-names></name><name><surname>Dowdle</surname><given-names>LT</given-names></name><name><surname>Nau</surname><given-names>M</given-names></name><name><surname>Caron</surname><given-names>B</given-names></name><name><surname>Pestilli</surname><given-names>F</given-names></name><name><surname>Charest</surname><given-names>I</given-names></name><name><surname>Hutchinson</surname><given-names>JB</given-names></name><name><surname>Naselaris</surname><given-names>T</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence</article-title><source>Nature Neuroscience</source><volume>25</volume><fpage>116</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00962-x</pub-id><pub-id pub-id-type="pmid">34916659</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Angelucci</surname><given-names>A</given-names></name><name><surname>Rosa</surname><given-names>MGP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Resolving the organization of the third tier visual cortex in primates: A hypothesis-based approach</article-title><source>Visual Neuroscience</source><volume>32</volume><elocation-id>E010</elocation-id><pub-id pub-id-type="doi">10.1017/S0952523815000073</pub-id><pub-id pub-id-type="pmid">26241792</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Topographic organization of areas V3 and V4 and its relation to supra-areal organization of the primate visual system</article-title><source>Visual Neuroscience</source><volume>32</volume><elocation-id>E014</elocation-id><pub-id pub-id-type="doi">10.1017/S0952523815000115</pub-id><pub-id pub-id-type="pmid">26241035</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Butt</surname><given-names>OH</given-names></name><name><surname>Datta</surname><given-names>R</given-names></name><name><surname>Radoeva</surname><given-names>PD</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Aguirre</surname><given-names>GK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The retinotopic organization of striate cortex is well predicted by surface topology</article-title><source>Current Biology</source><volume>22</volume><fpage>2081</fpage><lpage>2085</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.09.014</pub-id><pub-id pub-id-type="pmid">23041195</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Butt</surname><given-names>OH</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Aguirre</surname><given-names>GK</given-names></name><name><surname>Einhäuser</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Correction of distortion in flattened representations of the cortical surface allows prediction of V1-V3 functional organization from anatomy</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003538</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003538</pub-id><pub-id pub-id-type="pmid">24676149</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Jamison</surname><given-names>KW</given-names></name><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Vu</surname><given-names>AT</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Human Connectome Project 7 Tesla retinotopy dataset: Description and population receptive field analysis</article-title><source>Journal of Vision</source><volume>18</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.1167/18.13.23</pub-id><pub-id pub-id-type="pmid">30593068</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benson</surname><given-names>NC</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Bayesian analysis of retinotopic maps</article-title><source>eLife</source><volume>7</volume><elocation-id>e40224</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.40224</pub-id><pub-id pub-id-type="pmid">30520736</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bollmann</surname><given-names>S</given-names></name><name><surname>Mattern</surname><given-names>H</given-names></name><name><surname>Bernier</surname><given-names>M</given-names></name><name><surname>Robinson</surname><given-names>SD</given-names></name><name><surname>Park</surname><given-names>D</given-names></name><name><surname>Speck</surname><given-names>O</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Imaging of the pial arterial vasculature of the human brain in vivo using high-resolution 7T time-of-flight angiography</article-title><source>eLife</source><volume>11</volume><elocation-id>e71186</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.71186</pub-id><pub-id pub-id-type="pmid">35486089</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyd Taylor</surname><given-names>HG</given-names></name><name><surname>Puckett</surname><given-names>AM</given-names></name><name><surname>Isherwood</surname><given-names>ZJ</given-names></name><name><surname>Schira</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Vascular effects on the BOLD response and the retinotopic mapping of hV4</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0204388</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0204388</pub-id><pub-id pub-id-type="pmid">31194745</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dougherty</surname><given-names>RF</given-names></name><name><surname>Koch</surname><given-names>VM</given-names></name><name><surname>Brewer</surname><given-names>AA</given-names></name><name><surname>Fischer</surname><given-names>B</given-names></name><name><surname>Modersitzki</surname><given-names>J</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Visual field representations and locations of visual areas V1/2/3 in human visual cortex</article-title><source>Journal of Vision</source><volume>3</volume><fpage>586</fpage><lpage>598</lpage><pub-id pub-id-type="doi">10.1167/3.10.1</pub-id><pub-id pub-id-type="pmid">14640882</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Population receptive field estimates in human visual cortex</article-title><source>NeuroImage</source><volume>39</volume><fpage>647</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.034</pub-id><pub-id pub-id-type="pmid">17977024</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durbin</surname><given-names>R</given-names></name><name><surname>Mitchison</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A dimension reduction framework</article-title><source>Nature</source><volume>343</volume><fpage>644</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1038/343644a0</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name><name><surname>Sandell</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Visual topography of V2 in the macaque</article-title><source>The Journal of Comparative Neurology</source><volume>201</volume><fpage>519</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1002/cne.902010405</pub-id><pub-id pub-id-type="pmid">7287933</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Sousa</surname><given-names>AP</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Visuotopic organization and extent of V3 and V4 of the macaque</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>1831</fpage><lpage>1845</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-06-01831.1988</pub-id><pub-id pub-id-type="pmid">3385477</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gegenfurtner</surname><given-names>KR</given-names></name><name><surname>Kiper</surname><given-names>DC</given-names></name><name><surname>Levitt</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Functional properties of neurons in macaque area V3</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>1906</fpage><lpage>1923</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.4.1906</pub-id><pub-id pub-id-type="pmid">9114244</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Sotiropoulos</surname><given-names>SN</given-names></name><name><surname>Wilson</surname><given-names>JA</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Andersson</surname><given-names>JL</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name><name><surname>Jbabdi</surname><given-names>S</given-names></name><name><surname>Webster</surname><given-names>M</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>The minimal preprocessing pipelines for the Human Connectome Project</article-title><source>NeuroImage</source><volume>80</volume><fpage>105</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id><pub-id pub-id-type="pmid">23668970</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Coalson</surname><given-names>TS</given-names></name><name><surname>Robinson</surname><given-names>EC</given-names></name><name><surname>Hacker</surname><given-names>CD</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A multi-modal parcellation of human cerebral cortex</article-title><source>Nature</source><volume>536</volume><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1038/nature18933</pub-id><pub-id pub-id-type="pmid">27437579</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haak</surname><given-names>KV</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Renken</surname><given-names>R</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Cornelissen</surname><given-names>FW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Connective field modeling</article-title><source>NeuroImage</source><volume>66</volume><fpage>376</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.10.037</pub-id><pub-id pub-id-type="pmid">23110879</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hadjidimitrakis</surname><given-names>K</given-names></name><name><surname>Bakola</surname><given-names>S</given-names></name><name><surname>Chaplin</surname><given-names>TA</given-names></name><name><surname>Yu</surname><given-names>HH</given-names></name><name><surname>Alanazi</surname><given-names>O</given-names></name><name><surname>Chan</surname><given-names>JM</given-names></name><name><surname>Worthy</surname><given-names>KH</given-names></name><name><surname>Rosa</surname><given-names>MGP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Topographic organization of the “third-tier” dorsomedial visual cortex in the macaque</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>5311</fpage><lpage>5325</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0085-19.2019</pub-id><pub-id pub-id-type="pmid">31036760</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Wieser</surname><given-names>E</given-names></name><name><surname>Taylor</surname><given-names>J</given-names></name><name><surname>Berg</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>NJ</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Picus</surname><given-names>M</given-names></name><name><surname>Hoyer</surname><given-names>S</given-names></name><name><surname>van Kerkwijk</surname><given-names>MH</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Haldane</surname><given-names>A</given-names></name><name><surname>Del Río</surname><given-names>JF</given-names></name><name><surname>Wiebe</surname><given-names>M</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Gérard-Marchant</surname><given-names>P</given-names></name><name><surname>Sheppard</surname><given-names>K</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Abbasi</surname><given-names>H</given-names></name><name><surname>Gohlke</surname><given-names>C</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Array programming with NumPy</article-title><source>Nature</source><volume>585</volume><fpage>357</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id><pub-id pub-id-type="pmid">32939066</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinds</surname><given-names>OP</given-names></name><name><surname>Rajendran</surname><given-names>N</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Augustinack</surname><given-names>JC</given-names></name><name><surname>Wiggins</surname><given-names>G</given-names></name><name><surname>Wald</surname><given-names>LL</given-names></name><name><surname>Diana Rosas</surname><given-names>H</given-names></name><name><surname>Potthast</surname><given-names>A</given-names></name><name><surname>Schwartz</surname><given-names>EL</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Accurate prediction of V1 location from cortical folds in a surface coordinate system</article-title><source>NeuroImage</source><volume>39</volume><fpage>1585</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.10.033</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffmann</surname><given-names>MB</given-names></name><name><surname>Stadler</surname><given-names>J</given-names></name><name><surname>Kanowski</surname><given-names>M</given-names></name><name><surname>Speck</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Retinotopic mapping of the human visual cortex at a magnetic field strength of 7T</article-title><source>Clinical Neurophysiology</source><volume>120</volume><fpage>108</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1016/j.clinph.2008.10.153</pub-id><pub-id pub-id-type="pmid">19071059</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmes</surname><given-names>G</given-names></name><name><surname>Lister</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1916">1916</year><article-title>Disturbances of vision from cerebral lesions, with special reference to the cortical representation of the macula</article-title><source>Brain</source><volume>39</volume><fpage>34</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1093/brain/39.1-2.34</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horton</surname><given-names>JC</given-names></name><name><surname>Hoyt</surname><given-names>WF</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>The representation of the visual field in human striate cortex. A revision of the classic Holmes map</article-title><source>Archives of Ophthalmology</source><volume>109</volume><fpage>816</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1001/archopht.1991.01080060080030</pub-id><pub-id pub-id-type="pmid">2043069</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Uniformity of monkey striate cortex: a parallel relationship between field size, scatter, and magnification factor</article-title><source>The Journal of Comparative Neurology</source><volume>158</volume><fpage>295</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1002/cne.901580305</pub-id><pub-id pub-id-type="pmid">4436457</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Inouye</surname><given-names>T.</given-names></name></person-group><year iso-8601-date="1909">1909</year><source>Die Sehstörungen bei Schussverletzungen der kortikalen Sehsphäre: nach Beobachtungen an Verwundeten der letzten japanischen Kriege</source><publisher-name>W. Engelmann</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname><given-names>KN</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Mezer</surname><given-names>A</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Compressive spatial summation in human visual cortex</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>481</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1152/jn.00105.2013</pub-id><pub-id pub-id-type="pmid">23615546</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurzawski</surname><given-names>JW</given-names></name><name><surname>Gulban</surname><given-names>OF</given-names></name><name><surname>Jamison</surname><given-names>K</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Kay</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Non-neural factors influencing BOLD response magnitudes within individual subjects</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>7256</fpage><lpage>7266</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2532-21.2022</pub-id><pub-id pub-id-type="pmid">35970558</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levandowsky</surname><given-names>M</given-names></name><name><surname>Winter</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Distance between Sets</article-title><source>Nature</source><volume>234</volume><fpage>34</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1038/234034a0</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname><given-names>JB</given-names></name><name><surname>Kiper</surname><given-names>DC</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Receptive fields and functional architecture of macaque V2</article-title><source>Journal of Neurophysiology</source><volume>71</volume><fpage>2517</fpage><lpage>2542</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.71.6.2517</pub-id><pub-id pub-id-type="pmid">7931532</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magezi</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Linear mixed-effects models for within-participant psychology experiments: an introductory tutorial and free, graphical user interface (LMMgui)</article-title><source>Frontiers in Psychology</source><volume>6</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2015.00002</pub-id><pub-id pub-id-type="pmid">25657634</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manger</surname><given-names>PR</given-names></name><name><surname>Kiper</surname><given-names>D</given-names></name><name><surname>Masiello</surname><given-names>I</given-names></name><name><surname>Murillo</surname><given-names>L</given-names></name><name><surname>Tettoni</surname><given-names>L</given-names></name><name><surname>Hunyadi</surname><given-names>Z</given-names></name><name><surname>Innocenti</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The representation of the visual field in three extrastriate areas of the ferret (Mustela putorius) and the relationship of retinotopy and field boundaries to callosal connectivity</article-title><source>Cerebral Cortex</source><volume>12</volume><fpage>423</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1093/cercor/12.4.423</pub-id><pub-id pub-id-type="pmid">11884357</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Passos</surname><given-names>A</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Brucher</surname><given-names>M</given-names></name><name><surname>Perrot</surname><given-names>M</given-names></name><name><surname>Duchesnay</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in Python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitzalis</surname><given-names>S</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Committeri</surname><given-names>G</given-names></name><name><surname>Fattori</surname><given-names>P</given-names></name><name><surname>Galati</surname><given-names>G</given-names></name><name><surname>Patria</surname><given-names>F</given-names></name><name><surname>Galletti</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Human v6: the medial motion area</article-title><source>Cerebral Cortex</source><volume>20</volume><fpage>411</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp112</pub-id><pub-id pub-id-type="pmid">19502476</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Greve</surname><given-names>DN</given-names></name><name><surname>Wald</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Laminar analysis of 7T BOLD using an imposed spatial activation pattern in human V1</article-title><source>NeuroImage</source><volume>52</volume><fpage>1334</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.05.005</pub-id><pub-id pub-id-type="pmid">20460157</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puckett</surname><given-names>AM</given-names></name><name><surname>Aquino</surname><given-names>KM</given-names></name><name><surname>Robinson</surname><given-names>PA</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Schira</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The spatiotemporal hemodynamic response function for depth-dependent functional imaging of human cortex</article-title><source>NeuroImage</source><volume>139</volume><fpage>240</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.06.019</pub-id><pub-id pub-id-type="pmid">27321045</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajimehr</surname><given-names>R</given-names></name><name><surname>Tootell</surname><given-names>RBH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Does retinotopy influence cortical folding in primate visual cortex?</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>11149</fpage><lpage>11152</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1835-09.2009</pub-id><pub-id pub-id-type="pmid">19741121</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Renton</surname><given-names>AI</given-names></name><name><surname>Dao</surname><given-names>TT</given-names></name><name><surname>Abbott</surname><given-names>DF</given-names></name><name><surname>Amos</surname><given-names>TJ</given-names></name><name><surname>Bollmann</surname><given-names>S</given-names></name><name><surname>Botting</surname><given-names>A</given-names></name><name><surname>Campbell</surname><given-names>MEJ</given-names></name><name><surname>Chang</surname><given-names>J</given-names></name><name><surname>Civier</surname><given-names>O</given-names></name><name><surname>Close</surname><given-names>TG</given-names></name><name><surname>Eckstein</surname><given-names>K</given-names></name><name><surname>Egan</surname><given-names>GF</given-names></name><name><surname>Evas</surname><given-names>S</given-names></name><name><surname>Flandin</surname><given-names>G</given-names></name><name><surname>Garner</surname><given-names>KG</given-names></name><name><surname>Garrido</surname><given-names>MI</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Grignard</surname><given-names>M</given-names></name><name><surname>Hannan</surname><given-names>AJ</given-names></name><name><surname>Huber</surname><given-names>R</given-names></name><name><surname>Hughes</surname><given-names>ME</given-names></name><name><surname>Johnstone</surname><given-names>T</given-names></name><name><surname>Kaczmarzyk</surname><given-names>JR</given-names></name><name><surname>Kasper</surname><given-names>L</given-names></name><name><surname>Kuhlmann</surname><given-names>L</given-names></name><name><surname>Lou</surname><given-names>K</given-names></name><name><surname>Lyons</surname><given-names>P</given-names></name><name><surname>Mantilla-Ramos</surname><given-names>YJ</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name><name><surname>Morris</surname><given-names>J</given-names></name><name><surname>Narayanan</surname><given-names>A</given-names></name><name><surname>Pestilli</surname><given-names>F</given-names></name><name><surname>Puce</surname><given-names>A</given-names></name><name><surname>Ribeiro</surname><given-names>FL</given-names></name><name><surname>Rogasch</surname><given-names>NC</given-names></name><name><surname>Rorden</surname><given-names>C</given-names></name><name><surname>Schira</surname><given-names>M</given-names></name><name><surname>Shaw</surname><given-names>TB</given-names></name><name><surname>Slade</surname><given-names>BM</given-names></name><name><surname>Spitz</surname><given-names>G</given-names></name><name><surname>Stewart</surname><given-names>A</given-names></name><name><surname>Sullivan</surname><given-names>RP</given-names></name><name><surname>White</surname><given-names>DJ</given-names></name><name><surname>Ye</surname><given-names>X</given-names></name><name><surname>Zhu</surname><given-names>JD</given-names></name><name><surname>Narayanan</surname><given-names>A</given-names></name><name><surname>Bollmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neurodesk: An Accessible, Flexible, and Portable Data Analysis Environment for Reproducible Neuroimaging</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.12.23.521691</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ribeiro</surname><given-names>FL</given-names></name><name><surname>Bollmann</surname><given-names>S</given-names></name><name><surname>Puckett</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Predicting the retinotopic organization of human visual cortex from anatomy using geometric deep learning</article-title><source>NeuroImage</source><volume>244</volume><elocation-id>118624</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118624</pub-id><pub-id pub-id-type="pmid">34607019</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Ribeiro</surname><given-names>F</given-names></name><name><surname>York</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>VariabilityEarlyVisualCortex</data-title><version designator="swh:1:rev:01c85e211dd76c2519e0ec03de9378d8b857e951">swh:1:rev:01c85e211dd76c2519e0ec03de9378d8b857e951</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:fd3f6776298b8f1e63623dfb95fe2107d9d8a573;origin=https://github.com/felenitaribeiro/VariabilityEarlyVisualCortex;visit=swh:1:snp:e0332826ab7ce6d28cacd222400e18570fc4fd0e;anchor=swh:1:rev:01c85e211dd76c2519e0ec03de9378d8b857e951">https://archive.softwareheritage.org/swh:1:dir:fd3f6776298b8f1e63623dfb95fe2107d9d8a573;origin=https://github.com/felenitaribeiro/VariabilityEarlyVisualCortex;visit=swh:1:snp:e0332826ab7ce6d28cacd222400e18570fc4fd0e;anchor=swh:1:rev:01c85e211dd76c2519e0ec03de9378d8b857e951</ext-link></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rilling</surname><given-names>JK</given-names></name><name><surname>Insel</surname><given-names>TR</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Differential expansion of neural projection systems in primate brain evolution</article-title><source>Neuroreport</source><volume>10</volume><fpage>1453</fpage><lpage>1459</lpage><pub-id pub-id-type="doi">10.1097/00001756-199905140-00012</pub-id><pub-id pub-id-type="pmid">10380962</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MG</given-names></name><name><surname>Schmid</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Visual areas in the dorsal and medial extrastriate cortices of the marmoset</article-title><source>The Journal of Comparative Neurology</source><volume>359</volume><fpage>272</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1002/cne.903590207</pub-id><pub-id pub-id-type="pmid">7499529</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name></person-group><year iso-8601-date="1997">1997</year><chapter-title>Visuotopic organization of Primate Extrastriate cortex</chapter-title><person-group person-group-type="editor"><name><surname>Rockland</surname><given-names>KS</given-names></name><name><surname>Kaas</surname><given-names>JH</given-names></name><name><surname>Peters</surname><given-names>A</given-names></name></person-group><source>Extrastriate Cortex in Primates</source><publisher-loc>Boston, MA</publisher-loc><publisher-name>Springer US</publisher-name><fpage>127</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1007/978-1-4757-9625-4</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MG</given-names></name><name><surname>Fritsches</surname><given-names>KA</given-names></name><name><surname>Elston</surname><given-names>GN</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The second visual area in the marmoset monkey: visuotopic organisation, magnification factors, architectonical boundaries, and modularity</article-title><source>The Journal of Comparative Neurology</source><volume>387</volume><fpage>547</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1002/(sici)1096-9861(19971103)387:4&lt;547::aid-cne6&gt;3.0.co;2-2</pub-id><pub-id pub-id-type="pmid">9373013</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Topographic organisation of extrastriate areas in the flying fox: Implications for the evolution of mammalian visual cortex</article-title><source>The Journal of Comparative Neurology</source><volume>411</volume><fpage>503</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19990830)411:3&lt;503::AID-CNE12&gt;3.0.CO;2-6</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Tweedale</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Visual areas in lateral and ventral extrastriate cortices of the marmoset monkey</article-title><source>The Journal of Comparative Neurology</source><volume>422</volume><fpage>621</fpage><lpage>651</lpage><pub-id pub-id-type="doi">10.1002/1096-9861(20000710)422:4&lt;621::AID-CNE10&gt;3.0.CO;2-E</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Visual maps in the adult primate cerebral cortex: some implications for brain development and evolution</article-title><source>Brazilian Journal of Medical and Biological Research = Revista Brasileira de Pesquisas Medicas e Biologicas</source><volume>35</volume><fpage>1485</fpage><lpage>1498</lpage><pub-id pub-id-type="doi">10.1590/s0100-879x2002001200008</pub-id><pub-id pub-id-type="pmid">12436190</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Manger</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Clarifying homologies in the mammalian cerebral cortex: the case of the third visual area (V3)</article-title><source>Clinical and Experimental Pharmacology &amp; Physiology</source><volume>32</volume><fpage>327</fpage><lpage>339</lpage><pub-id pub-id-type="doi">10.1111/j.1440-1681.2005.04192.x</pub-id><pub-id pub-id-type="pmid">15854138</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Tweedale</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Brain maps, great and small: lessons from comparative studies of primate visual cortical organization</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>360</volume><fpage>665</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1626</pub-id><pub-id pub-id-type="pmid">15937007</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schira</surname><given-names>MM</given-names></name><name><surname>Tyler</surname><given-names>CW</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Spehar</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The foveal confluence in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>9050</fpage><lpage>9058</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1760-09.2009</pub-id><pub-id pub-id-type="pmid">19605642</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schira</surname><given-names>MM</given-names></name><name><surname>Tyler</surname><given-names>CW</given-names></name><name><surname>Spehar</surname><given-names>B</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modeling magnification and anisotropy in the primate foveal confluence</article-title><source>PLOS Computational Biology</source><volume>6</volume><elocation-id>e1000651</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000651</pub-id><pub-id pub-id-type="pmid">20126528</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sedigh-Sarvestani</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>KS</given-names></name><name><surname>Jaepel</surname><given-names>J</given-names></name><name><surname>Satterfield</surname><given-names>R</given-names></name><name><surname>Shultz</surname><given-names>N</given-names></name><name><surname>Fitzpatrick</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A sinusoidal transformation of the visual field is the basis for periodic maps in area V2</article-title><source>Neuron</source><volume>109</volume><fpage>4068</fpage><lpage>4079</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.053</pub-id><pub-id pub-id-type="pmid">34687665</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>McDonald</surname><given-names>CT</given-names></name><name><surname>Allman</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Analysis of retinotopic maps in extrastriate cortex</article-title><source>Cerebral Cortex</source><volume>4</volume><fpage>601</fpage><lpage>620</lpage><pub-id pub-id-type="doi">10.1093/cercor/4.6.601</pub-id><pub-id pub-id-type="pmid">7703687</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Brady</surname><given-names>TJ</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging</article-title><source>Science</source><volume>268</volume><fpage>889</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1126/science.7754376</pub-id><pub-id pub-id-type="pmid">7754376</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>McDonald</surname><given-names>CT</given-names></name><name><surname>Allman</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Retinotopic organization of extrastriate cortex in the owl monkey--dorsal and lateral areas</article-title><source>Visual Neuroscience</source><volume>32</volume><elocation-id>E021</elocation-id><pub-id pub-id-type="doi">10.1017/S0952523815000206</pub-id><pub-id pub-id-type="pmid">26423343</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swindale</surname><given-names>NV</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The development of topography in the visual cortex: a review of models</article-title><source>Network</source><volume>7</volume><fpage>161</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1088/0954-898X/7/2/002</pub-id><pub-id pub-id-type="pmid">16754382</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taha</surname><given-names>AA</given-names></name><name><surname>Hanbury</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool</article-title><source>BMC Medical Imaging</source><volume>15</volume><elocation-id>29</elocation-id><pub-id pub-id-type="doi">10.1186/s12880-015-0068-x</pub-id><pub-id pub-id-type="pmid">26263899</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Tangtartharakul</surname><given-names>GT</given-names></name><name><surname>Morgan</surname><given-names>CA</given-names></name><name><surname>Rushton</surname><given-names>SK</given-names></name><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Retinotopic Connectivity Maps of Human Visual Cortex with Unconstrained Eye Movements</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.03.16.533037</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="software"><person-group person-group-type="author"><collab>The Jamovi project</collab></person-group><year iso-8601-date="2021">2021</year><data-title>Jamovi</data-title><version designator="Version 1.6.15">Version 1.6.15</version><publisher-name>Jamovi</publisher-name><ext-link ext-link-type="uri" xlink:href="https://www.jamovi.org">https://www.jamovi.org</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tusa</surname><given-names>RJ</given-names></name><name><surname>Rosenquist</surname><given-names>AC</given-names></name><name><surname>Palmer</surname><given-names>LA</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Retinotopic organization of areas 18 and 19 in the cat</article-title><source>The Journal of Comparative Neurology</source><volume>185</volume><fpage>657</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1002/cne.901850405</pub-id><pub-id pub-id-type="pmid">447876</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>The WU-Minn Human connectome project: an overview</article-title><source>NeuroImage</source><volume>80</volume><fpage>62</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.041</pub-id><pub-id pub-id-type="pmid">23684880</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Parcellating cerebral cortex: how invasive animal studies inform noninvasive mapmaking in humans</article-title><source>Neuron</source><volume>99</volume><fpage>640</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.002</pub-id><pub-id pub-id-type="pmid">30138588</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Carey</surname><given-names>CJ</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Henriksen</surname><given-names>I</given-names></name><name><surname>Quintero</surname><given-names>EA</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>van Mulbregt</surname><given-names>P</given-names></name><name><surname>Vijaykumar</surname><given-names>A</given-names></name><name><surname>Bardelli</surname><given-names>AP</given-names></name><name><surname>Rothberg</surname><given-names>A</given-names></name><name><surname>Hilboll</surname><given-names>A</given-names></name><name><surname>Kloeckner</surname><given-names>A</given-names></name><name><surname>Scopatz</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>A</given-names></name><name><surname>Rokem</surname><given-names>A</given-names></name><name><surname>Woods</surname><given-names>CN</given-names></name><name><surname>Fulton</surname><given-names>C</given-names></name><name><surname>Masson</surname><given-names>C</given-names></name><name><surname>Häggström</surname><given-names>C</given-names></name><name><surname>Fitzgerald</surname><given-names>C</given-names></name><name><surname>Nicholson</surname><given-names>DA</given-names></name><name><surname>Hagen</surname><given-names>DR</given-names></name><name><surname>Pasechnik</surname><given-names>DV</given-names></name><name><surname>Olivetti</surname><given-names>E</given-names></name><name><surname>Martin</surname><given-names>E</given-names></name><name><surname>Wieser</surname><given-names>E</given-names></name><name><surname>Silva</surname><given-names>F</given-names></name><name><surname>Lenders</surname><given-names>F</given-names></name><name><surname>Wilhelm</surname><given-names>F</given-names></name><name><surname>Young</surname><given-names>G</given-names></name><name><surname>Price</surname><given-names>GA</given-names></name><name><surname>Ingold</surname><given-names>GL</given-names></name><name><surname>Allen</surname><given-names>GE</given-names></name><name><surname>Lee</surname><given-names>GR</given-names></name><name><surname>Audren</surname><given-names>H</given-names></name><name><surname>Probst</surname><given-names>I</given-names></name><name><surname>Dietrich</surname><given-names>JP</given-names></name><name><surname>Silterra</surname><given-names>J</given-names></name><name><surname>Webber</surname><given-names>JT</given-names></name><name><surname>Slavič</surname><given-names>J</given-names></name><name><surname>Nothman</surname><given-names>J</given-names></name><name><surname>Buchner</surname><given-names>J</given-names></name><name><surname>Kulick</surname><given-names>J</given-names></name><name><surname>Schönberger</surname><given-names>JL</given-names></name><name><surname>de Miranda Cardoso</surname><given-names>JV</given-names></name><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Harrington</surname><given-names>J</given-names></name><name><surname>Rodríguez</surname><given-names>JLC</given-names></name><name><surname>Nunez-Iglesias</surname><given-names>J</given-names></name><name><surname>Kuczynski</surname><given-names>J</given-names></name><name><surname>Tritz</surname><given-names>K</given-names></name><name><surname>Thoma</surname><given-names>M</given-names></name><name><surname>Newville</surname><given-names>M</given-names></name><name><surname>Kümmerer</surname><given-names>M</given-names></name><name><surname>Bolingbroke</surname><given-names>M</given-names></name><name><surname>Tartre</surname><given-names>M</given-names></name><name><surname>Pak</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>NJ</given-names></name><name><surname>Nowaczyk</surname><given-names>N</given-names></name><name><surname>Shebanov</surname><given-names>N</given-names></name><name><surname>Pavlyk</surname><given-names>O</given-names></name><name><surname>Brodtkorb</surname><given-names>PA</given-names></name><name><surname>Lee</surname><given-names>P</given-names></name><name><surname>McGibbon</surname><given-names>RT</given-names></name><name><surname>Feldbauer</surname><given-names>R</given-names></name><name><surname>Lewis</surname><given-names>S</given-names></name><name><surname>Tygier</surname><given-names>S</given-names></name><name><surname>Sievert</surname><given-names>S</given-names></name><name><surname>Vigna</surname><given-names>S</given-names></name><name><surname>Peterson</surname><given-names>S</given-names></name><name><surname>More</surname><given-names>S</given-names></name><name><surname>Pudlik</surname><given-names>T</given-names></name><name><surname>Oshima</surname><given-names>T</given-names></name><name><surname>Pingel</surname><given-names>TJ</given-names></name><name><surname>Robitaille</surname><given-names>TP</given-names></name><name><surname>Spura</surname><given-names>T</given-names></name><name><surname>Jones</surname><given-names>TR</given-names></name><name><surname>Cera</surname><given-names>T</given-names></name><name><surname>Leslie</surname><given-names>T</given-names></name><name><surname>Zito</surname><given-names>T</given-names></name><name><surname>Krauss</surname><given-names>T</given-names></name><name><surname>Upadhyay</surname><given-names>U</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Vázquez-Baeza</surname><given-names>Y</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Luxburg</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A tutorial on spectral clustering</article-title><source>Statistics and Computing</source><volume>17</volume><fpage>395</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1007/s11222-007-9033-z</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Imaging retinotopic maps in the human brain</article-title><source>Vision Research</source><volume>51</volume><fpage>718</fpage><lpage>737</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2010.08.004</pub-id><pub-id pub-id-type="pmid">20692278</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Mruczek</surname><given-names>REB</given-names></name><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Probabilistic maps of visual topography in human cortex</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3911</fpage><lpage>3931</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu277</pub-id><pub-id pub-id-type="pmid">25452571</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Horiguchi</surname><given-names>H</given-names></name><name><surname>Sayres</surname><given-names>RA</given-names></name><name><surname>Amano</surname><given-names>K</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Mapping hV4 and ventral occipital cortex: the venous eclipse</article-title><source>Journal of Vision</source><volume>10</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.1167/10.5.1</pub-id><pub-id pub-id-type="pmid">20616143</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>F</given-names></name><name><surname>Bauer</surname><given-names>HU</given-names></name><name><surname>Geisel</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Formation of field discontinuities and islands in visual cortical maps</article-title><source>Biological Cybernetics</source><volume>70</volume><fpage>525</fpage><lpage>531</lpage><pub-id pub-id-type="doi">10.1007/BF00198805</pub-id><pub-id pub-id-type="pmid">8068768</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>HH</given-names></name><name><surname>Rowley</surname><given-names>DP</given-names></name><name><surname>Price</surname><given-names>NSC</given-names></name><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Zavitz</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A twisted visual field map in the primate dorsomedial cortex predicted by topographic continuity</article-title><source>Science Advances</source><volume>6</volume><elocation-id>eaaz8673</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aaz8673</pub-id><pub-id pub-id-type="pmid">33115750</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Guindani</surname><given-names>M</given-names></name><name><surname>Grieco</surname><given-names>SF</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Holmes</surname><given-names>TC</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Beyond t test and ANOVA: applications of mixed-effects models for more rigorous statistical analysis in neuroscience research</article-title><source>Neuron</source><volume>110</volume><fpage>21</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.10.030</pub-id><pub-id pub-id-type="pmid">34784504</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeki</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Uniformity and diversity of structure and function in rhesus monkey prestriate visual cortex</article-title><source>The Journal of Physiology</source><volume>277</volume><fpage>273</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1978.sp012272</pub-id><pub-id pub-id-type="pmid">418176</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Q</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Submillimeter fMRI reveals a layout of dorsal visual cortex in macaques, remarkably similar to New World monkeys</article-title><source>PNAS</source><volume>116</volume><fpage>2306</fpage><lpage>2311</lpage><pub-id pub-id-type="doi">10.1073/pnas.1805561116</pub-id><pub-id pub-id-type="pmid">30674668</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86439.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Merriam</surname><given-names>Elisha</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>National Institutes of Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>This fundamental work advances our understanding of the retinotopic organization of early visual cortex in humans, and in particular, patterns of variability in the organization of V2 and V3 in normal populations. The evidence supporting the conclusions is compelling, with rigorous retinotopic analysis across a large publicly-available dataset. The work will be of broad interest to vision scientists, as well as those interested in inter-individual variability and neural fingerprinting using fMRI.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86439.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Merriam</surname><given-names>Elisha</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>National Institutes of Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Merriam</surname><given-names>Elisha</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>National Institutes of Health</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Knapen</surname><given-names>Tomas</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05kgbsy64</institution-id><institution>Spinoza Centre for Neuroimaging</institution></institution-wrap><country>Netherlands</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Benson</surname><given-names>Noah C</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>University of Washington</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Variability of visual field maps in human early extrastriate cortex challenges the canonical model of organization of V2 and V3&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Elisha Merriam as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Chris Baker as the Senior Editor. The following individuals involved in the review of your submission have agreed to reveal their identity: Tomas Knapen (Reviewer #2); Noah C Benson (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Each of the reviewers raised questions about potential explanations for the alternate organization that the authors report. While it is likely not possible to completely address each of the reviewers' concerns with additional analysis, the authors should consider the reviewers' recommendations, and at the very least provide a serious discussion of the points that are not possible to address with further data analysis.</p><p>2) Both Reviewers 1 and 2 recommended providing a more systematic and complete visualization of the alternate organization that the authors report. There are a number of ways in which this could be accomplished. The authors should pursue an approach that most effectively documents the alternative pattern that they have discovered and the range of variability in the HCP data.</p><p>3) Reviewer 3 asked the authors to perform an examination of the field sign, which may shed light on the data in Figure 4., or perhaps a further analysis of the patch of cortex bounded by the arms of the &quot;dorsal Y&quot; in Cluster 2 would help elucidate the kind of deviation from the traditional maps this cluster represents.</p><p>4) There was a general consensus amongst the reviewers that the LME approach that the authors have employed may not be the most appropriate or the most sensitive analysis. For example, it would be good to demonstrate convincingly that including the normalized mean BOLD signal in the LME is in fact capable of detecting the venous eclipse around V4 (See Reviewer 1, point #2). Without such a positive result showing that the analysis can detect vascular artefacts, it is difficult to fully trust the lack of an effect in the early visual cortex.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>This manuscript concerns the organization of the first three cortical visual areas (V1/V2/V3). For decades, the field has assumed an organization in which V2 and V3 are conceived as alternating, mirror-symmetric quarterfield representations emanating from a full hemifield field representation in V1. Here, the authors have described an innovative and (mostly) compelling analysis demonstrating a striking degree of intersubject variability in this organization. Deviations from the canonical organization are not random. Instead, the authors have uncovered a subset of subjects that follow an alternative organization, most prevalent in the dorsal portion of the left hemisphere.</p><p>This study comes as a breath of fresh air, a huge relief to somebody who has personally spent many hundreds of hours over the years hand-drawing visual area boundaries on inflated brains. As anybody who has attempted this task can readily attest, there is indeed a large degree of inter-subject variability, and forcing the canonical organization on some hemispheres can involve more than a bit of guesswork. The present study suggests that the glove simply doesn't fit for these subjects.</p><p>I have always assumed that the canonical organization is correct and that the frequent deviations that I've observed were due to measurement errors. My biggest criticism of the present study is that the authors have not gone far enough in demonstrating that this isn't the case. In other words, I am not completely convinced that this alternative organization derives from variability in the neural map, rather than from a systematic artifact, either in the MRI measurements (functional or structural) or in one of the many processing stages to intervene between data acquisition and the final map.</p><p>Regardless of whether the results shown here are indeed neurogenic, or are somehow the result of measurement error, the implications are far-reaching. Over the years, countless fMRI studies have shown bar graphs quantifying some effect in areas V1/V2/V3, with areas boundaries that were either drawn by hand or estimated with an atlas, conforming to the standard, canonical organization. A major implication of the current results is that these previous studies may have mischaracterized differences between these visual areas. And if that is the case in the early visual cortex, I am sure this is a much larger problem in higher-order cortical areas. So in sum, I think this is a really important set of observations and I am confident that it will have an impact on the field.</p><p>1. The manuscript is very clear and well-written and I am inclined to believe the results. But this inclination is really based on simple visual inspection of the maps shown, and not the statistical analyses per se. Given that the I find visual inspection to be the most compelling presentation of the result, the manuscript could be greatly improved by showing more data visually demonstrating the range of maps in the HCP data. This could be a supplement, or a pointer to an online resource showing the retinotopic maps for all subjects and all hemispheres, perhaps categorized into meaningful groups.</p><p>2. The authors have not done an especially convincing job of discounting various artifacts that may have contributed to the variability in map structure. The authors included covariates in the LME for curvature, normalized mean BOLD signal, and intra-individual variability in pRF estimates, and then argue that these covariates do not account for the pattern of variability in map organization. But doesn't this logic ask us to accept the null hypothesis that these factors aren't playing a role? &quot;line 367: Our findings indicate that the main effects found here were not a mere reflection of variation in the reliability of the individual maps and other covariates.&quot; But in fact, the analysis simply suggests that an effect could not be detected. It would be more convincing if the authors could demonstrate that such effects do occur and do impact retinotopic maps (such as the venous eclipse in V4), but that they aren't playing a role here. Specifically, I am concerned that including the normalized mean BOLD signal in an LME isn't a very sensitive way of testing for the effects of the vasculature. Demonstrating a positive effect in V4 with this approach (where we know all about the impact of a large draining vein) would be a more convincing demonstration of the method, and enable us to interpret the lack of an effect in V2/V3.</p><p>3. In addition to the three covariates that the authors considered, I wonder about additional issues, such as segmentation reliability, cortical thickness, partial voluming, and bleed over from the wall of the adjacent sulcal surface (i.e., multiple surfaces passing through a single voxel). Obviously, the authors can't test for all of these possibilities, but a more complete discussion of additional factors would strengthen the manuscript.</p><p>4. Did the pattern of V2/V3 topography depend at all on cortical surface depth? Even though the voxel size was relatively large, it should be possible to sample the voxel matrix using surfaces defined at different cortical depths relative to the gray matter. If the aberrant maps are somehow due to a distortion artifact associated with the cortical sampling and/or inflation procedure, the pattern may be less pronounced at deeper cortical depths.</p><p>5. Functional selectivity. In addition to pRF mapping, the HCP dataset included task runs, as well as resting state data. Did the pattern of activity in either task or resting state data follow the alternate boundaries for V2 and V3 defined here?</p><p>6. I wonder about morphometric/anatomical properties that may correlate or predict the alternative organization of V2/V3. Was there anything different in global brain structure (e.g., hemispheric asymmetry, brain size, etc) that might be predictive?</p><p>7. Did any demographic information predict the alternative pattern in V2/V3 (gender, age?)</p><p>8. Lastly, the results presented here suggest that the most widely used cortical atlases need to be revised to accommodate this known variability. It would be wonderful if the authors provided software to do this, or at least discuss the need for approaches that accommodate the range of variability described here.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The authors take aim at the retinotopic organization of V2 and V3, which in the field is generally assumed to follow a standard pattern: mirrored quarter-field representations abutting V1 on both the dorsal and ventral side. The deviations from the assumed canonical shape which the authors point to are intriguing, as this finding would change the way we think of the organization of low levels of the visual system. If we don't understand the lower levels of visual-cortical organization, what can we say about the higher levels? This finding could have quite a significant impact on how vision scientists approach their work.</p><p>Indeed, visually their point is well taken: the few visualisations in Figure 1 are quite compelling in their depiction of deviations of the locations and orientations of apparent visual field map boundaries.</p><p>I think the main point of the paper could be strengthened a lot, and that's because of the choices made in terms of the quantifications and analyses. In order for the field to incorporate the main finding into our way of thinking about low-level visual cortical organization, the findings need to be presented more convincingly. The manuscript fully depends on linear mixed effects modelling and clustering analysis based on summary results. The authors will want to dive more deeply into the phenomenology of what they're showing and be less concerned with statistical analyses.</p><p>One question that remains after reading the manuscript is what possible sources underpin the idiosyncratic polar angle patterns in so many participants.</p><p>For instance, I wonder whether the linear mixed effects modelling can adequately account for (i.e. correct for) the correlations of the polar angle deviations with mean EPI values and curvature. These effects, in my experience, definitely don't look like 'linear' effects in that they are quite all-or-none. Does a single 'omnibus' analysis suffice to prove that this pattern we see is a true signature of neural organization? I think many in the field, where drawing visual field map boundaries is a skill that's mastered over the course of many participants, would answer no. Similarly, the binarization of the patterns leading up to the clustering analysis could have a lot of unintended consequences. A more thorough visual exploration of these patterns would make the findings much more convincing. An open presentation of the data, so that the public can browse through the results, would be very valuable here.</p><p>Going back to the data:</p><p>1. To what extent do the patterns reported in the ms depend on their use of the 2mm HCP data? As the data were originally acquired at 1.6mm and these data can be readily downloaded, I wonder whether the idiosyncratic patterns in polar angle distribution on the surface depend on the pooling across voxels that is inherent in the data format that's being used here. If the authors re-fit those subjects with idiosyncratic polar angle patterns at higher resolution, does this change the pattern? It's likely that influences of venous signals are changed when subsampling the voxels.</p><p>2. In my experience, this sort of polar angle discontinuity can also be the result of anatomical segmentation errors, however small. I think the authors want to ensure that this is not a driving influence here.</p><p>3. To what extent could this sort of pattern of results be driven by eye movements? There are eye-tracking signals in the HCP dataset, so can the authors check this?</p><p>To get a bit of a better view of the authors' claims I quickly went through the surface maps provided by the NSD paper, since the authors cite this paper as an example study that also showcases the idiosyncrasies reported here. I'm uploading outlines of the most compelling deviations from the canonical V2/V3 organization in this dataset (See https://www.dropbox.com/s/auqjmiz1nghsxv3/Screenshot-Reviewer2.png?dl=0) To summarise; I see clear examples of the patterns outlined by the authors in 4 out of 16 hemispheres (admittedly, slightly conservative an estimate, perhaps). This is below what the authors report. For 2 or 3 of these instances, there is a clear venous eclipse-like effect that could have caused the polar angle patterns to deviate -- we know that this sort of thing is more likely to occur at 7T than at 3T, where retinotopic maps usually look smoother. I don't know what this means in relation to the reported findings, of course, but it could indicate that the more detailed preprocessing and higher single-subject quality of the NSD data decrease the occurrence of the reported patterns.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>The work presented here by Ribeiro et al. attempts to quantify the observation that the &quot;standard model&quot; of V1, V2, and V3 matches the average human retinotopic maps but does not consistently match the retinotopic maps of individuals. (In this case, the &quot;standard model&quot; I'm referring to is just the assumption that the boundaries of V1, V2, and V3 topologically resemble those of the wedge-dipole model of Balasubramanian et al., 2002, or the banded double-sech model of Schira et al., 2010). Such non-standard retinotopic organizations in individual subjects are (as the authors note) well documented in other primates, and informal speculation about such non-standard human subjects has historically been common, if inconclusive, among those of us who study human V1-V3. Further, because the visual cortex is one of the few macroscopic brain systems for which neural computations, macroscopic organization, and connectivity are well-modeled, any novel observations about its individual variability are likely to lead to novel hypotheses about brain development and to serve as a template for future analyses. For these reasons, this manuscript is of clear value both to visual neuroscience researchers interested in the details of V1-V3 as well as to neuroscientists in adjacent domains.</p><p>While the findings of this paper are convincing and leave little doubt that non-standard organizations of V1-V3 not only exist but are common, it falls short of eliminating all possible explanations of such variability. To be clear, this is not primarily a critique of the paper but an observation that the authors' analyses point the field toward many additional questions. While the authors have done an excellent job demonstrating that large-scale deviations in the average curvature and BOLD signal do not explain large-scale variability of the maps, their analyses do not eliminate microscopic features of curvature or vasculature as potential causes. For example, a skeptic might claim that Cluster 2 (Figure 4) can be explained by partial voluming arising from tight curvature in a small patch of the dorsal V2-V3 region or by a blood vessel in the same region. If tight curvature or a vessel were critical to explaining these maps but were confined to a small patch of cortex, the analysis of curvature and BOLD intensity here may have been insufficiently precise to find it. (Of course, given the results of the analysis here, one might be justified in speculating that more detailed examinations of V1-V3 could reveal the &quot;standard&quot; model to be the model that most depend on typical sources of BOLD noise.) It would benefit the paper to include additional discussion of the extent to which the clear differences found in the clustered maps might or might not depend on microscopic features that are beyond the paper's current scope. However, the authors should be lauded for demonstrating conclusively that these differences cannot be easily dismissed.</p><p>I am particularly intrigued by the clustering analysis performed by the authors, summarized in Figure 4. This figure, along with Supplemental Figure 3, provides compelling evidence that the &quot;Dorsal Y,&quot; as the branching lower vertical meridian representation of V1 and V2 is sometimes called, is common and reasonably consistent across individuals. However, I am not entirely convinced that clusters 1, 3, and 5 are capturing substantial deviations in the &quot;standard&quot; model of human retinotopy. It is possible that density-based or hierarchical clustering methods that do not employ any dimension reduction would yield different results (though I am skeptical that the differences would be especially large). Regardless, the fundamental issue with these three clusters is that the topology of the V1-V2-V3 boundaries does not appear terribly different, even when, for example, the intensity of the lower vertical meridian differs. Of course, the intensity of the representation of the meridian may be a feature of the maps worth examining in and of itself, but I suspect that most researchers will be more interested in the clear violation of the topology of visual area boundaries implicit in the &quot;standard&quot; model that one can easily see in Cluster 2. With respect to the differences between Cluster 2 and the other clusters, it seems likely to me that the authors could have captured these differences more easily and accurately by examining the distribution and cortical location of the visual field sign (see for example Tootell et al., 1998, DOI:10.1073/pnas.95.3.811). The most interesting feature of this cluster is arguably that it suggests either (1) that, in these subjects, V2 and V3 are split, with each having a &quot;standard&quot; portion as well as a dorsal-anterior representation; or alternately (2) that at least one (or more likely 2) additional visual areas exist just anterior to dorsal V2 and dorsal to anterior V1. My speculation here – that the patch of cortex bounded by the two branches of the Y (i.e., dorsal to anterior V1 and anterior to dorsal V2) must consist of 2 separate representations – arises from the fact that it contains two separate patches of cortex in which the field signs do not match.</p><p>Another possibility that I would have liked to see discussed is the likelihood that the &quot;Dorsal Y&quot; organization of Cluster 2 appears in many (more) subjects but does not appear at a consistent location with respect to eccentricity. To this end, I believe that Supplemental Figure 2 would have been more interesting had it been calculated not as a new set of clusters based on eccentricity but instead as the average eccentricity map of each of the clusters from Figure 4 that were based on the polar angle. My own observation (which I would like to emphasize is purely anecdotal) is that the eccentricity maps of subjects whose polar angle maps resemble those of Cluster 2 tend to bend sharply near the junction of the &quot;y&quot;. I find myself wondering if the subjects in Cluster 2 have a similar feature in their eccentricity maps, whether the junction of the &quot;y&quot; of Cluster 2 tends to occur near the same eccentricity across subjects, and whether the cortical magnification functions of such subjects differ substantially from those who do not have this feature. The size of the PRFs in these regions might also be illuminating---do they scale with eccentricity in a manner that matches the rest of dorsal V2 and V3?</p><p>Overall, despite (and arguably because of) the many questions that this paper exposes, it is of substantial value to the community. Its results are straightforward and well-supported, and it provides a valuable starting point from which further refinements of the organization of the visual cortex can be studied.</p><p>Overall this paper is compelling and does not require substantial revision or refinement in order to be of great value to the field. To be frank, I have been hoping for several years that someone would publish a clear analysis of the dorsal retinotopic maps in V1-V3, and am pleased to see a conclusive demonstration of their variability finally appear. In my public review, I have pointed out many questions and implications that arise from these findings, and I believe that mentioning some of these implications would improve the paper. However, I do not believe that answering them is necessary for the paper – merely that discussion may be helpful for researchers who do not work on these maps closely on a regular basis.</p><p>One concrete suggestion I do have for the authors is that a cursory examination of the field sign may lead to clearer clusters and thus a clearer narrative of the data in Figure 4. That said, the field sign can be tricky – such an analysis would likely rest at least somewhat on light smoothing of the PRF parameters and may become difficult in ways I have not anticipated. Similarly, a brief analysis of the patch of cortex bounded by the arms of the &quot;dorsal Y&quot; in Cluster 2 would be of substantial interest and may help determine what kind of deviation from the traditional maps this cluster represents.</p><p>I would also suggest that the authors include some discussion of how the human clusters found in this analysis compare to the 6 clusters found in non-human primates. I don't think that much ink needs to be spent on this, but it struck me as odd that the non-human primate clusters would be cited as motivation for the clustering parameters in humans and then never discussed more carefully.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86439.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Each of the reviewers raised questions about potential explanations for the alternate organization that the authors report. While it is likely not possible to completely address each of the reviewers' concerns with additional analysis, the authors should consider the reviewers' recommendations, and at the very least provide a serious discussion of the points that are not possible to address with further data analysis.</p></disp-quote><p>Here we briefly summarize our changes to the manuscript as suggested by the reviewers (each of these changes will be detailed throughout this letter):</p><p>Visualization ⁠–⁠ For seamless visualization of retinotopic maps as a function of the participant’s assignment to the reported clusters, we provide an executable code notebook with instructions for running them on Neurodesk (a data analysis environment for reproducible neuroimaging). In this code notebook, it is possible to interactively visualize maps and perform additional analyses of the retinotopic maps. Note that this code notebook and all source code are now available on GitHub (https://github.com/felenitaribeiro/VariabilityEarlyVisualCortex). In addition, we provide a tutorial for visualizing the 7T HCP Retinotopy dataset using Connectome Workbench on Neurodesk (https://www.neurodesk.org/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/).</p><p>Detailed analyses for assessing the patch of cortex bounded by the arms of the &quot;dorsal Y&quot; ⁠–⁠ We provide extra analyses of the &quot;dorsal Y&quot; maps in the manuscript and make an interactive visualization of such analyses available in the same code notebook.</p><p>‘Limitations’ section ⁠–⁠ We now include a ‘Limitations’ subsection to expand our discussion about the limitations of our study, including the fact that the LME model does not eliminate microscopic features of the vasculature as a potential cause of individual variability in retinotopic maps.</p><p>‘Future directions’ section ⁠–⁠ Finally, we also included a ‘Future directions’ subsection to expand our discussion about many of the reviewers' suggestions that we could not address here or were beyond the scope of our study.</p><disp-quote content-type="editor-comment"><p>2) Both Reviewers 1 and 2 recommended providing a more systematic and complete visualization of the alternate organization that the authors report. There are a number of ways in which this could be accomplished. The authors should pursue an approach that most effectively documents the alternative pattern that they have discovered and the range of variability in the HCP data.</p></disp-quote><p>To address this concern, we have made available a Jupyter Notebook with interactive plotting functions and dropdown menus for visualizing an individual’s polar angle map (given their cluster assignment). In addition, we include five additional figure supplements (Figure 5—figure supplement 1-6) with nine randomly selected exemplary maps from the remaining clusters. Besides that, we provide a tutorial for visualizing the 7T HCP Retinotopy dataset using Connectome Workbench on Neurodesk (https://www.neurodesk.org/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/).</p><p>Lines 822-833: “Data and code availability</p><p>The data used in this study is publicly available at BALSA (https://balsa.wustl.edu/study/show/9Zkk). In addition, all accompanying Python and MATLAB source codes are available on GitHub (https://github.com/felenitaribeiro/VariabilityEarlyVisualCortex). On our GitHub repository, executable code is available on interactive computational notebooks (Jupyter notebooks) that allow anyone to execute interactive plotting functions with dropdown menus to visualize an individual’s polar angle and visual field sign maps, given their cluster assignment. Note that our documentation provides instructions for running them on Neurodesk (Renton et al., 2022). Finally, the intermediate files for fitting the linear mixed effect models using Jamovi are available on the Open Science Framework (https://osf.io/tdkuj/).”</p><disp-quote content-type="editor-comment"><p>3) Reviewer 3 asked the authors to perform an examination of the field sign, which may shed light on the data in Figure 4., or perhaps a further analysis of the patch of cortex bounded by the arms of the &quot;dorsal Y&quot; in Cluster 2 would help elucidate the kind of deviation from the traditional maps this cluster represents.</p></disp-quote><p>As advised, we expanded our analysis of the “dorsal Y” in our manuscript by including polar angle gradient representation and the visual field sign analysis. Interestingly, the visual field sign analysis suggests that the area identified as dorsal V3 shows a discontinuity in the canonical mirror-image representation. This is now illustrated in Figure 7 (white circles added for emphasis). In addition, as previously mentioned, we made an interactive visualization of these analyses available in a code notebook. We hope to provide other visual neuroscientists a good starting point for exploring alternate models for early visual area parcellation.</p><p>Lines 800-821: “Visual field sign analysis</p><p>Lastly, we further examined unusual retinotopic maps to elucidate the kind of deviation from the canonical maps they represent. We performed a visual field sign analysis (Sereno et al., 1995, 1994), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image (like V2) or a mirror-image representation of the retina (like V1). Since the left hemisphere represents the right visual field, which in polar angle includes 0⁰-90⁰ (upper right visual field) and 270⁰- 360⁰ (lower right visual field), we shifted the polar angle values so the point of wrap-around (from 360⁰ to 0⁰) was positioned at the horizontal meridian in the contralateral hemifield, avoiding the discontinuous representation between 360⁰ and 0⁰. Then, we interpolated the sparse and flattened polar angle and eccentricity maps onto a regular x-y grid using SciPy (Virtanen et al., 2020). Next, we determined the gradient of polar angle and eccentricity maps, mathematically expressed as:</p><p><inline-formula><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p>where <inline-formula><mml:math id="sa2m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the polar angle map and <inline-formula><mml:math id="sa2m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> the eccentricity, using the NumPy gradient numerical method (Harris et al., 2020). Finally, the angle between the polar angle and eccentricity maps’ gradient vectors was determined at each x-y coordinate. If the angle between the gradient vectors is between 0 and π, by convention, the cortical patch is a mirror-image representation of the retina; otherwise, it is a non-mirror-image. After binarizing the angle projection, we can conveniently infer borders between visual areas because adjacent areas often have the opposite visual field sign (Sereno et al., 1995; but see Yu et al. 2020 for caveat).”</p><p>Lines 291-340: “Visual field sign analysis for delineating visual area boundaries</p><p>Finally, we further examined retinotopic maps with a Y-shaped lower vertical representation, i.e., those primarily assigned to cluster 2, to elucidate the kind of deviation from the canonical maps they represent (Figure 7 and Figure 7—figure supplement 1). To do so, we performed a visual field sign analysis (Sereno et al., 1995, 1994), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image or a mirror-image representation of the retina (Figure 7a; see Materials and methods). With such representation, we can directly infer visual area parcellation.</p><p>Figure 7b shows polar angle gradients in a ‘streamline’ representation and their respective visual field sign representation for two participants with canonical and four with Y-shaped lower vertical representations. While visual area boundaries in early visual cortex are conventionally identified by reversals in the progression of the polar angle values – or changes in the direction of polar angle gradients, it is unclear how to delineate boundaries in the dorsal portion of polar angle maps in those participants with non-canonical maps (note that their respective ventral portion followed the classical representation), but not on those with canonical maps. However, with the visual field sign representation, the boundaries delineating dorsal V2 in those participants with non-canonical maps are more explicit, and it reveals that the area identified as dorsal V3 shows a discontinuity in the expected mirror-image representation. Such representation has been proposed as the ‘incomplete-V3’ model of the third-tier cortex for the macaque (Angelucci and Rosa, 2015) and other similar models for the owl monkey (Sereno et al., 2015) and the marmoset monkey (Rosa and Tweedale, 2000). Figure 7—figure supplement 1 shows five more examples of polar angle maps with unusual Y-shaped lower vertical representations and five other examples with a truncated V3 boundary. While individuals with unusual Y-shaped lower vertical representations have a discontinuity in the canonical mirror-image representation of the retina in dorsal V3, individuals with a truncated V3 do not show such a discontinuity. Altogether, our findings may suggest that, at least in humans, the canonical model does not oppose other models established for non-human primates; these models coexist and reflect common modes of variability in the retinotopic mapping of early visual areas.”</p><disp-quote content-type="editor-comment"><p>4) There was a general consensus amongst the reviewers that the LME approach that the authors have employed may not be the most appropriate or the most sensitive analysis. For example, it would be good to demonstrate convincingly that including the normalized mean BOLD signal in the LME is in fact capable of detecting the venous eclipse around V4 (See Reviewer 1, point #2). Without such a positive result showing that the analysis can detect vascular artefacts, it is difficult to fully trust the lack of an effect in the early visual cortex.</p></disp-quote><p>We agree with the reviewers and would like to echo what Reviewer 3 mentioned, i.e., that the purpose of the LME model was to demonstrate that large-scale deviations in the average curvature and BOLD signal do not explain all the large-scale variability of the retinotopic maps. But, of course, this does not mean this method can eliminate microscopic (or local) features of curvature or vasculature as potential causes. As such, we reformulated our manuscript to make it more explicit. First, we provide more detail on how we computed pair-wise correlations among polar angle, eccentricity, curvature, and normalized mean BOLD signal for both V1-3 and each visual area separately (Figure 3; lines 206-214). Our findings reconcile with those in previous work. For example, we found that the polar angle representation is indeed correlated with the normalized mean BOLD signal, and the magnitude of such association varies across visual areas. Specifically, we found a higher correlation between polar angle and normalized BOLD signal maps in ventral visual areas than in dorsal areas. This difference could be explained by ventral areas' proximity to the dural venous sinuses (Winawer et al., 2010), i.e., the transverse sinus, the superior sagittal sinus, and the straight sinus. These venous sinuses are known to introduce artifacts to the BOLD signal, which might lead to changes in retinotopic maps. Importantly, none of these sinuses run near the dorsal V2/V3 (see Figure 4—figure supplement 2), and both of these dorsal areas show the lowest correlation (in magnitude) between the polar angle and normalized BOLD signal maps. But, again, it does not mean that vasculature does not affect retinotopy.</p><p>As for hV4, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: r = -0.06; RH: r = -0.07) and did not find an effect on <italic>large-scale deviations</italic> in an LME model. This finding does not reconcile with previous reports, i.e., that venous artifact impacts retinotopy. However, in Boyd Taylor et al. (2019), a fine-grained analysis of polar angle maps in hV4 indicated that “<italic>[…] incomplete hV4 maps did not correspond with venous artefact in every instance, with incomplete maps being present in the absence of a venous eclipse and complete maps coexisting with a proximate venous eclipse.</italic>” In our analysis, though, these results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation; while early visual areas are more consistently found at specific spatial locations, this is not the case for other visual areas of which spatial location and extent seem to vary across participants. Unfortunately, we do not have manual segmentations of hV4 for the HCP dataset that would allow for a better understanding of the vasculature effect in retinotopic mapping. Accordingly, we extend our discussion about the limitations of our study in the manuscript.</p><p>Lines 711-719: “Accordingly, we calculated pair-wise correlations among polar angle, eccentricity, curvature, and normalized mean BOLD signal for both V1-3 and each visual area separately. Given a region of interest, each topographic map was vectorized, and data were concatenated across all participants (n=181) for each modality. Polar angle maps were converted such that 0⁰ corresponds to the horizontal meridian and 90⁰ corresponds to the upper and lower vertical meridians (Kurzawski et al., 2022). Finally, pair-wise correlations were determined using these concatenated sets of vectorized maps. Below we provide further motivation for considering each of these covariates.”</p><p>Lines 496-548: “Limitations</p><p>Although we demonstrate that common modes of deviation from the canonical dorsal V2 and V3 organization exist in the left hemisphere, further analyses are necessary to fully ascertain if such variability is indeed neurogenic or if it could be a result of measurement errors. Amongst potential sources of measurement error is the presence of large veins running adjacent to regions of interest. Accordingly, by using the normalized mean BOLD signal as a proxy for the location of large veins (Boyd Taylor et al., 2019; Kurzawski et al., 2022), studies have shown that voxels near these veins show lower mean BOLD signal, a phenomenon known as the venous eclipse, which affects pRF estimates, for example, in area hV4 (Boyd Taylor et al., 2019; Winawer et al., 2010). As such, deviations in the expected mean BOLD signal could result in deviations from the expected retinotopic organization. Thus, to better understand the potential effects of the presence of large veins on the different levels of variability in visual field representation across early visual areas, we considered both the pair-wise correlations between retinotopic maps and the normalized mean BOLD signal (Figure 3) and the large-scale deviation in the normalized mean BOLD signal as covariates in the LME model (Tables 3 and 4).</p><p>In the pair-wise correlation analysis, we found that the polar angle representation is indeed correlated with the normalized mean BOLD signal, and the magnitude of such association varies across visual areas. Specifically, we found a higher correlation (in magnitude) between the polar angle and normalized BOLD signal in ventral visual areas than in dorsal areas. This difference could be explained by ventral areas' proximity to the dural venous sinuses (Winawer et al., 2010), i.e., the transverse sinus, the superior sagittal sinus, and the straight sinus. These venous sinuses are known to introduce artifacts to the BOLD signal, which might lead to changes in retinotopic maps. Importantly, none of these sinuses run near the dorsal V2 and V3 (see Figure 4—figure supplement 2, in which it is possible to observe the likely confluence of sinuses), and both of which show the lowest correlation between polar angle and normalized BOLD signal maps.</p><p>Moreover, we modeled large-scale deviation in visual field maps using the large-scale deviation of the normalized mean BOLD signal as a covariate. We did find a significant effect of the normalized mean BOLD signal on the individual variability of eccentricity (Table 4) but not of polar angle maps (Table 3). Thus, to determine the effectiveness of the LME model for uncovering the effects of covariates, we similarly modeled the large-scale variability in polar angle maps of hV4 (not shown in the manuscript). We did not find an effect of the normalized mean BOLD signal on large-scale deviation in polar angle maps in hV4. However, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: r = -0.06; RH: r = -0.07). This finding does not reconcile with previous reports, i.e., that venous artifact impacts retinotopy. However, a fine-grained analysis of polar angle maps in hV4 indicated the inconsistent effect of the venous artifact on polar angle mapping (Boyd Taylor et al., 2019). In our analysis, though, these results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation; while early visual areas are more consistently found at specific spatial locations, this is not the case for other visual areas of which spatial location and extent seem to vary across participants. Therefore, although we did not find a significant effect of the normalized mean BOLD signal in our LME model, it does not mean that the macro- and microvasculature do not affect retinotopy. For the former, future research might consider a fine-grained analysis of topographic deviations, such as the one reported by Boyd Taylor et al. (2019). For the latter, given that the mean BOLD signal is only used as a proxy for the location of large veins, a more detailed analysis of the microvasculature might require other imaging data, such as high-resolution time-of-flight magnetic resonance angiography data (Bollmann et al., 2022).”</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>This manuscript concerns the organization of the first three cortical visual areas (V1/V2/V3). For decades, the field has assumed an organization in which V2 and V3 are conceived as alternating, mirror-symmetric quarterfield representations emanating from a full hemifield field representation in V1. Here, the authors have described an innovative and (mostly) compelling analysis demonstrating a striking degree of intersubject variability in this organization. Deviations from the canonical organization are not random. Instead, the authors have uncovered a subset of subjects that follow an alternative organization, most prevalent in the dorsal portion of the left hemisphere.</p><p>This study comes as a breath of fresh air, a huge relief to somebody who has personally spent many hundreds of hours over the years hand-drawing visual area boundaries on inflated brains. As anybody who has attempted this task can readily attest, there is indeed a large degree of inter-subject variability, and forcing the canonical organization on some hemispheres can involve more than a bit of guesswork. The present study suggests that the glove simply doesn't fit for these subjects.</p><p>I have always assumed that the canonical organization is correct and that the frequent deviations that I've observed were due to measurement errors. My biggest criticism of the present study is that the authors have not gone far enough in demonstrating that this isn't the case. In other words, I am not completely convinced that this alternative organization derives from variability in the neural map, rather than from a systematic artifact, either in the MRI measurements (functional or structural) or in one of the many processing stages to intervene between data acquisition and the final map.</p><p>Regardless of whether the results shown here are indeed neurogenic, or are somehow the result of measurement error, the implications are far-reaching. Over the years, countless fMRI studies have shown bar graphs quantifying some effect in areas V1/V2/V3, with areas boundaries that were either drawn by hand or estimated with an atlas, conforming to the standard, canonical organization. A major implication of the current results is that these previous studies may have mischaracterized differences between these visual areas. And if that is the case in the early visual cortex, I am sure this is a much larger problem in higher-order cortical areas. So in sum, I think this is a really important set of observations and I am confident that it will have an impact on the field.</p><p>1. The manuscript is very clear and well-written and I am inclined to believe the results. But this inclination is really based on simple visual inspection of the maps shown, and not the statistical analyses per se. Given that the I find visual inspection to be the most compelling presentation of the result, the manuscript could be greatly improved by showing more data visually demonstrating the range of maps in the HCP data. This could be a supplement, or a pointer to an online resource showing the retinotopic maps for all subjects and all hemispheres, perhaps categorized into meaningful groups.</p></disp-quote><p>To address this concern, we have made available a Jupyter Notebook with interactive plotting functions and dropdown menus for visualizing an individual’s polar angle map (given their cluster assignment) on GitHub (https://github.com/felenitaribeiro/VariabilityEarlyVisualCortex). In addition, we include five additional figure supplements (Figure 5—figure supplement 1-6) with nine randomly selected exemplary maps from the remaining clusters.</p><p>Lines 822-833: “Data and code availability</p><p>The data used in this study is publicly available at BALSA (https://balsa.wustl.edu/study/show/9Zkk). In addition, all accompanying Python and MATLAB source codes are available on GitHub (https://github.com/felenitaribeiro/VariabilityEarlyVisualCortex). On our GitHub repository, executable code is available on interactive computational notebooks (Jupyter notebooks) that allow anyone to execute interactive plotting functions with dropdown menus to visualize an individual’s polar angle and visual field sign maps, given their cluster assignment. Note that our documentation provides instructions for running them on Neurodesk (Renton et al., 2022). Finally, the intermediate files for fitting the linear mixed effect models using Jamovi are available on the Open Science Framework (https://osf.io/tdkuj/).”</p><disp-quote content-type="editor-comment"><p>2. The authors have not done an especially convincing job of discounting various artifacts that may have contributed to the variability in map structure. The authors included covariates in the LME for curvature, normalized mean BOLD signal, and intra-individual variability in pRF estimates, and then argue that these covariates do not account for the pattern of variability in map organization. But doesn't this logic ask us to accept the null hypothesis that these factors aren't playing a role? &quot;line 367: Our findings indicate that the main effects found here were not a mere reflection of variation in the reliability of the individual maps and other covariates.&quot; But in fact, the analysis simply suggests that an effect could not be detected. It would be more convincing if the authors could demonstrate that such effects do occur and do impact retinotopic maps (such as the venous eclipse in V4), but that they aren't playing a role here. Specifically, I am concerned that including the normalized mean BOLD signal in an LME isn't a very sensitive way of testing for the effects of the vasculature. Demonstrating a positive effect in V4 with this approach (where we know all about the impact of a large draining vein) would be a more convincing demonstration of the method, and enable us to interpret the lack of an effect in V2/V3.</p></disp-quote><p>We have considered this suggestion carefully. As a result, to determine the effectiveness of the LME model for uncovering the effects of covariates, we similarly modeled the large-scale variability in polar angle maps of hV4 as a function of hemispheres and included the individual variability in normalized mean BOLD signal as a covariate. We did not find an effect of normalized mean BOLD signal on large-scale deviation in polar angle maps. However, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: r = -0.06; RH: r = -0.07). This finding does not entirely reconcile with previous reports that venous artifact impacts on the assessment of retinotopy in hV4. However, our results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation. We now discuss this important limitation in our manuscript and have also emphasized throughout the manuscript that such an analysis cannot rule out the effect of vasculature in retinotopy, as the reviewer has mentioned.</p><p>Lines 496-548: “Limitations</p><p>Although we demonstrate that common modes of deviation from the canonical dorsal V2 and V3 organization exist in the left hemisphere, further analyses are necessary to fully ascertain if such variability is indeed neurogenic or if it could be a result of measurement errors. Amongst potential sources of measurement error is the presence of large veins running adjacent to regions of interest. Accordingly, by using the normalized mean BOLD signal as a proxy for the location of large veins (Boyd Taylor et al., 2019; Kurzawski et al., 2022), studies have shown that voxels near these veins show lower mean BOLD signal, a phenomenon known as the venous eclipse, which affects pRF estimates, for example, in area hV4 (Boyd Taylor et al., 2019; Winawer et al., 2010). As such, deviations in the expected mean BOLD signal could result in deviations from the expected retinotopic organization. Thus, to better understand the potential effects of the presence of large veins on the different levels of variability in visual field representation across early visual areas, we considered both the pair-wise correlations between retinotopic maps and the normalized mean BOLD signal (Figure 3) and the large-scale deviation in the normalized mean BOLD signal as covariates in the LME model (Tables 3 and 4). In the pair-wise correlation analysis, we found that the polar angle representation is indeed correlated with the normalized mean BOLD signal, and the magnitude of such association varies across visual areas. Specifically, we found a higher correlation (in magnitude) between the polar angle and normalized BOLD signal in ventral visual areas than in dorsal areas. This difference could be explained by ventral areas' proximity to the dural venous sinuses (Winawer et al., 2010), i.e., the transverse sinus, the superior sagittal sinus, and the straight sinus. These venous sinuses are known to introduce artifacts to the BOLD signal, which might lead to changes in retinotopic maps. Importantly, none of these sinuses run near the dorsal V2 and V3 (see Figure 4—figure supplement 2, in which it is possible to observe the likely confluence of sinuses), and both of which show the lowest correlation between polar angle and normalized BOLD signal maps. Moreover, we modeled large-scale deviation in visual field maps using the large-scale deviation of the normalized mean BOLD signal as a covariate. We did find a significant effect of the normalized mean BOLD signal on the individual variability of eccentricity (Table 4) but not of polar angle maps (Table 3). Thus, to determine the effectiveness of the LME model for uncovering the effects of covariates, we similarly modeled the large-scale variability in polar angle maps of hV4 (not shown in the manuscript). We did not find an effect of the normalized mean BOLD signal on large-scale deviation in polar angle maps in hV4. However, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: r = -0.06; RH: r = -0.07). This finding does not reconcile with previous reports, i.e., that venous artifact impacts retinotopy. However, a fine-grained analysis of polar angle maps in hV4 indicated the inconsistent effect of the venous artifact on polar angle mapping (Boyd Taylor et al., 2019).</p><p>In our analysis, though, these results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation; while early visual areas are more consistently found at specific spatial locations, this is not the case for other visual areas of which spatial location and extent seem to vary across participants. Therefore, although we did not find a significant effect of the normalized mean BOLD signal in our LME model, it does not mean that the macro- and microvasculature do not affect retinotopy. For the former, future research might consider a fine-grained analysis of topographic deviations, such as the one reported by Boyd Taylor et al. (2019). For the latter, given that the mean BOLD signal is only used as a proxy for the location of large veins, a more detailed analysis of the microvasculature might require other imaging data, such as high-resolution time-of-flight magnetic resonance angiography data (Bollmann et al., 2022).”</p><disp-quote content-type="editor-comment"><p>3. In addition to the three covariates that the authors considered, I wonder about additional issues, such as segmentation reliability, cortical thickness, partial voluming, and bleed over from the wall of the adjacent sulcal surface (i.e., multiple surfaces passing through a single voxel). Obviously, the authors can't test for all of these possibilities, but a more complete discussion of additional factors would strengthen the manuscript.</p></disp-quote><p>As suggested, we have expanded our discussion regarding the abovementioned confounders.</p><p>Lines 453-476: “Retinotopic maps could also vary as a function of data resolution and cortical depth. For example, signal-to-noise ratio (SNR) and partial volume artifacts are directly affected by data resolution (or voxel size); that is, both reduce with voxel size (Hoffmann et al., 2009). While lower SNR might lead to noisier (or less smooth) retinotopic maps (Hoffmann et al., 2009), the gain from the reduced susceptibility to partial volume artifacts will likely result in increased validity of the observed maps. Partial volume artifacts may arise from patches of opposite walls of a sulcus running across a single voxel or even small vessels, leading to inaccurate signals from the combination of different brain regions and tissues. With increasing magnetic field strength, it should be easier to strike the right balance between high SNR and low partial volume artifacts, which is crucial for determining the impact of registration errors due to partial volume artifacts on the variability of retinotopic maps. Moreover, previous studies have also shown that the hemodynamic response function (Puckett et al., 2016) and a spatial pattern of activation (Polimeni et al., 2010) varied across depths in V1. Specifically, Polimeni and colleagues found that a spatial pattern of activation (an ‘M’) becomes clearer from the white matter surface to the mid-thickness surfaces and then deteriorates once again near the pial surface. Altogether, these studies motivate a more thorough investigation of how retinotopy, as measured by fMRI, varies as a function of data resolution and cortical depth and its implication on individual variability in retinotopy. However, it is also important to note that studies of the columnar organization of non-human primates using single-cell recordings have not found any evidence that the receptive field location varies with cortical depth, although the receptive field size changes, being smallest in the middle layers (Hubel and Wiesel, 1974; Rosa et al., 1997).”</p><disp-quote content-type="editor-comment"><p>4. Did the pattern of V2/V3 topography depend at all on cortical surface depth? Even though the voxel size was relatively large, it should be possible to sample the voxel matrix using surfaces defined at different cortical depths relative to the gray matter. If the aberrant maps are somehow due to a distortion artifact associated with the cortical sampling and/or inflation procedure, the pattern may be less pronounced at deeper cortical depths.</p></disp-quote><p>We have yet to investigate whether V2/V3 topography varies according to cortical depth. With the current data (voxel size is equal to 1.6 mm isotropic), it might be difficult to reliably tell whether these patterns vary according to layers, given that these cortical areas are thin (2-2.5mm). However, with higher resolution data, previous studies have shown that the hemodynamic response function (0.8 mm isotropic; Puckett et al., 2016) and a spatial pattern of activation (1 mm isotropic; Polimeni et al., 2010) varied across depths in V1. Specifically, Polimeni and colleagues found that the spatial pattern of activation (an ‘M’) becomes clearer from the white matter surface to the mid-thickness surfaces and then deteriorates once again near the pial surface. Here, we limited our analysis to pRF fits promptly available at BALSA (https://balsa.wustl.edu/study/show/9Zkk). These data have gone through the HCP pre-processing pipelines (Glasser et al., 2013; Benson et al., 2018), of which only data sampled to the mid-thickness surface was completely pre-processed and used for pRF mapping (Benson et al., 2018).</p><p>Lines 453-476: “Retinotopic maps could also vary as a function of data resolution and cortical depth. For example, signal-to-noise ratio (SNR) and partial volume artifacts are directly affected by data resolution (or voxel size); that is, both reduce with voxel size (Hoffmann et al., 2009). While lower SNR might lead to noisier (or less smooth) retinotopic maps (Hoffmann et al., 2009), the gain from the reduced susceptibility to partial volume artifacts will likely result in increased validity of the observed maps. Partial volume artifacts may arise from patches of opposite walls of a sulcus running across a single voxel or even small vessels, leading to inaccurate signals from the combination of different brain regions and tissues. With increasing magnetic field strength, it should be easier to strike the right balance between high SNR and low partial volume artifacts, which is crucial for determining the impact of registration errors due to partial volume artifacts on the variability of retinotopic maps. Moreover, previous studies have also shown that the hemodynamic response function (Puckett et al., 2016) and a spatial pattern of activation (Polimeni et al., 2010) varied across depths in V1. Specifically, Polimeni and colleagues found that a spatial pattern of activation (an ‘M’) becomes clearer from the white matter surface to the mid-thickness surfaces and then deteriorates once again near the pial surface. Altogether, these studies motivate a more thorough investigation of how retinotopy, as measured by fMRI, varies as a function of data resolution and cortical depth and its implication on individual variability in retinotopy. However, it is also important to note that studies of the columnar organization of non-human primates using single-cell recordings have not found any evidence that the receptive field location varies with cortical depth, although the receptive field size changes, being smallest in the middle layers (Hubel and Wiesel, 1974; Rosa et al., 1997).”</p><disp-quote content-type="editor-comment"><p>5. Functional selectivity. In addition to pRF mapping, the HCP dataset included task runs, as well as resting state data. Did the pattern of activity in either task or resting state data follow the alternate boundaries for V2 and V3 defined here?</p></disp-quote><p>We did not investigate differences in functional selectivity in V1-V3. The battery of tasks in the HCP dataset includes working memory, gambling, motor, language, social cognition, and relational and emotional processing. These tasks evaluate cognitive processes and might not be the most appropriate for investigating functional selectivity in early visual areas. However, such an analysis would be valuable since misidentifying individual visual areas can lead to the misinterpretation of functional selectivity findings. Hence, we have expanded this discussion in Future Directions.</p><p>Lines 550-568: “Our findings raise questions about if and how cortical atlases should be revisited to accommodate deviations from the canonical model of retinotopic organization, especially for dorsal V3. Here, by using the visual field sign representation, we could better understand what kind of deviation from the canonical model atypical maps represent. Therefore, using such data representation could be helpful for the manual segmentation of atypical maps. Alternatively, combining deep learning models (Ribeiro et al., 2021) for generating a retinotopic prior that accommodates more variability with a Bayesian framework (Benson and Winawer, 2018) for boundary delineation might prove fruitful to support the need for automated individual-level parcellation methods. It would also be desirable to use functional characteristics of areas, such as the responses to specific types of visual stimulation, to increase the confidence in assignment of boundaries. Whereas this may be possible in some situations (e.g. using motion selectivity as a localizer for area MT; Pitzalis et al., 2010), attempts to segregate V3 from adjacent areas on this basis may be more challenging, due to the physiological similarity between this area and the adjacent V2 and V3a (Gegenfurtner et al., 1997; Levitt et al., 1994; Zeki, 1978). Differences in pRF size (Zhu and Vanduffel, 2019) could offer some insight, although the wide overlap in the distributions of single-unit receptive field sizes in adjacent areas (Rosa, 1997) suggests that obtaining clear-cut boundaries on this basis remains unlikely.”</p><disp-quote content-type="editor-comment"><p>6. I wonder about morphometric/anatomical properties that may correlate or predict the alternative organization of V2/V3. Was there anything different in global brain structure (e.g., hemispheric asymmetry, brain size, etc) that might be predictive?</p><p>7. Did any demographic information predict the alternative pattern in V2/V3 (gender, age?)</p></disp-quote><p>To determine whether other properties would predict individual variability in polar angle maps, we included additional covariates in our LME model. Specifically, this model is similar to the one reported in Table 3, but it also has age, gender (as cofactor), and gray matter volume as additional covariates. In brief, we did not find significant effects of any of these variables (https://osf.io/c2pjm).</p><p>Lines 202-206: “To determine whether other properties would predict individual variability in polar angle maps, we included age, gender (as cofactor), and gray matter volume as additional covariates, but did not find significant effects of any of these variables (not shown here, but available as Supplementary File 5).”</p><disp-quote content-type="editor-comment"><p>8. Lastly, the results presented here suggest that the most widely used cortical atlases need to be revised to accommodate this known variability. It would be wonderful if the authors provided software to do this, or at least discuss the need for approaches that accommodate the range of variability described here.</p></disp-quote><p>As suggested, we have expanded our discussion about this need in our manuscript.</p><p>Lines 550-594: “Our findings raise questions about if and how cortical atlases should be revisited to accommodate deviations from the canonical model of retinotopic organization, especially for dorsal V3. Here, by using the visual field sign representation, we could better understand what kind of deviation from the canonical model atypical maps represent. Therefore, using such data representation could be helpful for the manual segmentation of atypical maps. Alternatively, combining deep learning models (Ribeiro et al., 2021) for generating a retinotopic prior that accommodates more variability with a Bayesian framework (Benson and Winawer, 2018) for boundary delineation might prove fruitful to support the need for automated individual-level parcellation methods. It would also be desirable to use functional characteristics of areas, such as the responses to specific types of visual stimulation, to increase the confidence in assignment of boundaries. Whereas this may be possible in some situations (e.g. using motion selectivity as a localizer for area MT; Pitzalis et al., 2010), attempts to segregate V3 from adjacent areas on this basis may be more challenging, due to the physiological similarity between this area and the adjacent V2 and V3a (Gegenfurtner et al., 1997; Levitt et al., 1994; Zeki, 1978). Differences in pRF size (Zhu and Vanduffel, 2019) could offer some insight, although the wide overlap in the distributions of single-unit receptive field sizes in adjacent areas (Rosa, 1997) suggests that obtaining clear-cut boundaries on this basis remains unlikely.</p><p>Importantly, accommodating individual variability for the automatic parcellation of visual areas is also crucial for understanding the functional properties of the human visual cortex. These analyses require the precise delineation of boundaries between visual areas, either by manually tracing transitions in visual field maps or by using an automatic segmentation method (Benson et al., 2014; Benson and Winawer, 2018; Dougherty et al., 2003). In both cases, a spatially consistent mapping (i.e., a canonical representation) of continuous, alternating bands of vertical and horizontal meridian representation in V2 and V3 is often assumed. However, we demonstrate that deviations from the canonical model exist, especially in the left hemisphere and dorsal V3. This finding could have several implications for post hoc analyses requiring visual area delineation, suggesting that previous studies may have mischaracterized differences between these visual areas due to misidentification. Therefore, an important future direction of this work is determining how functional selectivity varies across visual areas parcellated according to the canonical model compared to using new parcels estimated with the visual field sign analysis.</p><p>In addition, the present findings highlight the need for a more comprehensive assessment of the degree of variability in visuotopic maps in non-human primates, where a higher degree of precision can be achieved with invasive methods including single neuron recordings and optical imaging of intrinsic signals. To date, variability has only been reported in macaque monkeys (Gattass et al. 1988), but the available data in marmoset and owl monkeys indicate a reproducible organization that does not fully agree with the canonical model of dorsal V3 (Angelucci and Rosa, 2015; Rosa and Schmid, 1995; Rosa and Tweedale, 2000; Sereno et al., 2015). Whether this simply reflects the small number of individuals explored, or a truly more stable configuration (perhaps associated with the larger brain size in humans; Angelucci and Rosa, 2015; Rosa and Tweedale, 2005) remains to be determined.”</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>The authors take aim at the retinotopic organization of V2 and V3, which in the field is generally assumed to follow a standard pattern: mirrored quarter-field representations abutting V1 on both the dorsal and ventral side. The deviations from the assumed canonical shape which the authors point to are intriguing, as this finding would change the way we think of the organization of low levels of the visual system. If we don't understand the lower levels of visual-cortical organization, what can we say about the higher levels? This finding could have quite a significant impact on how vision scientists approach their work.</p><p>Indeed, visually their point is well taken: the few visualisations in Figure 1 are quite compelling in their depiction of deviations of the locations and orientations of apparent visual field map boundaries.</p><p>I think the main point of the paper could be strengthened a lot, and that's because of the choices made in terms of the quantifications and analyses. In order for the field to incorporate the main finding into our way of thinking about low-level visual cortical organization, the findings need to be presented more convincingly. The manuscript fully depends on linear mixed effects modelling and clustering analysis based on summary results. The authors will want to dive more deeply into the phenomenology of what they're showing and be less concerned with statistical analyses.</p></disp-quote><p>Aiming to elucidate the deviation from traditional maps that some of the atypical retinotopic maps represent, we now provide additional analyses of the &quot;dorsal Y&quot; maps in the manuscript. We include the representation of polar angle maps’ gradients and their corresponding visual field sign representations. In brief, the visual field sign analysis suggests that the region of cortex usually identified as dorsal V3 shows a discontinuity in the canonical mirror-image representation of the retina in many individuals.</p><p>Lines 800-821: “Visual field sign analysis</p><p>Lastly, we further examined unusual retinotopic maps to elucidate the kind of deviation from the canonical maps they represent. We performed a visual field sign analysis (Sereno et al., 1995, 1994), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image (like V2) or a mirror-image representation of the retina (like V1). Since the left hemisphere represents the right visual field, which in polar angle includes 0⁰-90⁰ (upper right visual field) and 270⁰- 360⁰ (lower right visual field), we shifted the polar angle values so the point of wrap-around (from 360⁰ to 0⁰) was positioned at the horizontal meridian in the contralateral hemifield, avoiding the discontinuous representation between 360⁰ and 0⁰. Then, we interpolated the sparse and flattened polar angle and eccentricity maps onto a regular x-y grid using SciPy (Virtanen et al., 2020). Next, we determined the gradient of polar angle and eccentricity maps, mathematically expressed as:</p><p><inline-formula><mml:math id="sa2m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p>where <inline-formula><mml:math id="sa2m7"><mml:msub id="ce909523-a4ef-414f-b2b6-49b0ce7cdc87"><mml:mi id="c4c4b132-391e-4519-9435-7616ea0b05c3">f</mml:mi><mml:mi id="c591d473-7e8e-40bc-afa1-a870038951dd">θ</mml:mi></mml:msub></mml:math></inline-formula> is the polar angle map and <inline-formula><mml:math id="sa2m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> the eccentricity, using the NumPy gradient numerical method (Harris et al., 2020). Finally, the angle between the polar angle and eccentricity maps’ gradient vectors was determined at each x-y coordinate. If the angle between the gradient vectors is between 0 and π, by convention, the cortical patch is a mirror-image representation of the retina; otherwise, it is a non-mirror-image. After binarizing the angle projection, we can conveniently infer borders between visual areas because adjacent areas often have the opposite visual field sign (Sereno et al., 1995; but see Yu et al. 2020 for caveat).”</p><p>Lines 291-340: “Visual field sign analysis for delineating visual area boundaries</p><p>Finally, we further examined retinotopic maps with a Y-shaped lower vertical representation, i.e., those primarily assigned to cluster 2, to elucidate the kind of deviation from the canonical maps they represent (Figure 7 and Figure 7-figurse supplement 2). To do so, we performed a visual field sign analysis (Sereno et al., 1995, 1994), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image or a mirror-image representation of the retina (Figure 7a; see Materials and methods). With such representation, we can directly infer visual area parcellation.</p><p>Figure 7b shows polar angle gradients in a ‘streamline’ representation and their respective visual field sign representation for two participants with canonical and four with Y-shaped lower vertical representations. While visual area boundaries in early visual cortex are conventionally identified by reversals in the progression of the polar angle values – or changes in the direction of polar angle gradients, it is unclear how to delineate boundaries in the dorsal portion of polar angle maps in those participants with non-canonical maps (note that their respective ventral portion followed the classical representation), but not on those with canonical maps. However, with the visual field sign representation, the boundaries delineating dorsal V2 in those participants with non-canonical maps are more explicit, and it reveals that the area identified as dorsal V3 shows a discontinuity in the expected mirror-image representation. Such representation has been proposed as the ‘incomplete-V3’ model of the third-tier cortex for the macaque (Angelucci and Rosa, 2015) and other similar models for the owl monkey (Sereno et al., 2015) and the marmoset monkey (Rosa and Tweedale, 2000). Figure 7—figure supplement 1 shows five more examples of polar angle maps with unusual Y-shaped lower vertical representations and five other examples with a truncated V3 boundary. While individuals with unusual Y-shaped lower vertical representations have a discontinuity in the canonical mirror-image representation of the retina in dorsal V3, individuals with a truncated V3 do not show such a discontinuity. Altogether, our findings may suggest that, at least in humans, the canonical model does not oppose other models established for non-human primates; these models coexist and reflect common modes of variability in the retinotopic mapping of early visual areas.”</p><disp-quote content-type="editor-comment"><p>One question that remains after reading the manuscript is what possible sources underpin the idiosyncratic polar angle patterns in so many participants.</p><p>For instance, I wonder whether the linear mixed effects modelling can adequately account for (i.e. correct for) the correlations of the polar angle deviations with mean EPI values and curvature. These effects, in my experience, definitely don't look like 'linear' effects in that they are quite all-or-none. Does a single 'omnibus' analysis suffice to prove that this pattern we see is a true signature of neural organization? I think many in the field, where drawing visual field map boundaries is a skill that's mastered over the course of many participants, would answer no. Similarly, the binarization of the patterns leading up to the clustering analysis could have a lot of unintended consequences. A more thorough visual exploration of these patterns would make the findings much more convincing. An open presentation of the data, so that the public can browse through the results, would be very valuable here.</p></disp-quote><p>For a more thorough visual exploration of the retinotopic maps and clusters, we have made a Jupyter Notebook available with interactive plotting functions and dropdown menus for visualizing an individual’s polar angle map (given their cluster assignment). In addition, we include five additional figure supplements (Figure 5—figure supplement 1-6) with nine randomly selected exemplary maps from the remaining clusters. Besides that, we provide a tutorial for visualizing the 7T HCP Retinotopy dataset using Connectome Workbench on Neurodesk (https://www.neurodesk.org/tutorials-examples/tutorials/functional_imaging/connectomeworkbench/).</p><p>As for the concern about the appropriateness of the linear mixed effects model to account for the covariates discussed in the manuscript, we similarly modeled the large-scale variability in polar angle maps of hV4 as a function of hemispheres and included the individual variability in normalized mean BOLD signal as a covariate. We did not find an effect of normalized mean BOLD signal on large-scale deviation in polar angle maps. However, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: r = -0.06; RH: r = -0.07). This finding does not reconcile with previous reports, i.e., that venous artifact impacts retinotopy. Our results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation. We now discuss this important limitation in our manuscript and have also emphasized throughout the manuscript that such an analysis cannot rule out the effect of vasculature in retinotopy.</p><p>Lines 496-548: “Limitations</p><p>Although we demonstrate that common modes of deviation from the canonical dorsal V2 and V3 organization exist in the left hemisphere, further analyses are necessary to fully ascertain if such variability is indeed neurogenic or if it could be a result of measurement errors. Amongst potential sources of measurement error is the presence of large veins running adjacent to regions of interest. Accordingly, by using the normalized mean BOLD signal as a proxy for the location of large veins (Boyd Taylor et al., 2019; Kurzawski et al., 2022), studies have shown that voxels near these veins show lower mean BOLD signal, a phenomenon known as the venous eclipse, which affects pRF estimates, for example, in area hV4 (Boyd Taylor et al., 2019; Winawer et al., 2010). As such, deviations in the expected mean BOLD signal could result in deviations from the expected retinotopic organization. Thus, to better understand the potential effects of the presence of large veins on the different levels of variability in visual field representation across early visual areas, we considered both the pair-wise correlations between retinotopic maps and the normalized mean BOLD signal (Figure 3) and the large-scale deviation in the normalized mean BOLD signal as covariates in the LME model (Tables 3 and 4).</p><p>In the pair-wise correlation analysis, we found that the polar angle representation is indeed correlated with the normalized mean BOLD signal, and the magnitude of such association varies across visual areas. Specifically, we found a higher correlation (in magnitude) between the polar angle and normalized BOLD signal in ventral visual areas than in dorsal areas. This difference could be explained by ventral areas' proximity to the dural venous sinuses (Winawer et al., 2010), i.e., the transverse sinus, the superior sagittal sinus, and the straight sinus. These venous sinuses are known to introduce artifacts to the BOLD signal, which might lead to changes in retinotopic maps. Importantly, none of these sinuses run near the dorsal V2 and V3 (see Figure 4—figure supplement 2, in which it is possible to observe the likely confluence of sinuses), and both of which show the lowest correlation between polar angle and normalized BOLD signal maps.</p><p>Moreover, we modeled large-scale deviation in visual field maps using the large-scale deviation of the normalized mean BOLD signal as a covariate. We did find a significant effect of the normalized mean BOLD signal on the individual variability of eccentricity (Table 4) but not of polar angle maps (Table 3). Thus, to determine the effectiveness of the LME model for uncovering the effects of covariates, we similarly modeled the large-scale variability in polar angle maps of hV4 (not shown in the manuscript). We did not find an effect of the normalized mean BOLD signal on large-scale deviation in polar angle maps in hV4. However, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: r = -0.06; RH: r = -0.07). This finding does not reconcile with previous reports, i.e., that venous artifact impacts retinotopy. However, a fine-grained analysis of polar angle maps in hV4 indicated the inconsistent effect of the venous artifact on polar angle mapping (Boyd Taylor et al., 2019). In our analysis, though, these results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation; while early visual areas are more consistently found at specific spatial locations, this is not the case for other visual areas of which spatial location and extent seem to vary across participants. Therefore, although we did not find a significant effect of the normalized mean BOLD signal in our LME model, it does not mean that the macro- and microvasculature do not affect retinotopy. For the former, future research might consider a fine-grained analysis of topographic deviations, such as the one reported by Boyd Taylor et al. (2019). For the latter, given that the mean BOLD signal is only used as a proxy for the location of large veins, a more detailed analysis of the microvasculature might require other imaging data, such as high-resolution time-of-flight magnetic resonance angiography data (Bollmann et al., 2022).”</p><disp-quote content-type="editor-comment"><p>Going back to the data:</p><p>1. To what extent do the patterns reported in the ms depend on their use of the 2mm HCP data? As the data were originally acquired at 1.6mm and these data can be readily downloaded, I wonder whether the idiosyncratic patterns in polar angle distribution on the surface depend on the pooling across voxels that is inherent in the data format that's being used here. If the authors re-fit those subjects with idiosyncratic polar angle patterns at higher resolution, does this change the pattern? It's likely that influences of venous signals are changed when subsampling the voxels.</p></disp-quote><p>Here, we limited our analysis to pRF fits promptly available at BALSA (https://balsa.wustl.edu/study/show/9Zkk), which have gone through the HCP pre-processing pipelines (Glasser et al., 2013) and only include three pRF fits for the mid-thickness surface at 2 mm spatial resolution (Benson et al., 2018). However, given that the signal-to-noise ratio (SNR) decreases with voxel size (Hoffman et al., 2009), we would expect that, for a fixed variance explained threshold, the functional data sampled at a higher resolution would result in noisier (or less smooth) retinotopic maps. We expanded our discussion about these concerns in the manuscript.</p><p>Lines 453-476: “Retinotopic maps could also vary as a function of data resolution and cortical depth. For example, signal-to-noise ratio (SNR) and partial volume artifacts are directly affected by data resolution (or voxel size); that is, both reduce with voxel size (Hoffmann et al., 2009). While lower SNR might lead to noisier (or less smooth) retinotopic maps (Hoffmann et al., 2009), the gain from the reduced susceptibility to partial volume artifacts will likely result in increased validity of the observed maps. Partial volume artifacts may arise from patches of opposite walls of a sulcus running across a single voxel or even small vessels, leading to inaccurate signals from the combination of different brain regions and tissues. With increasing magnetic field strength, it should be easier to strike the right balance between high SNR and low partial volume artifacts, which is crucial for determining the impact of registration errors due to partial volume artifacts on the variability of retinotopic maps. Moreover, previous studies have also shown that the hemodynamic response function (Puckett et al., 2016) and a spatial pattern of activation (Polimeni et al., 2010) varied across depths in V1. Specifically, Polimeni and colleagues found that a spatial pattern of activation (an ‘M’) becomes clearer from the white matter surface to the mid-thickness surfaces and then deteriorates once again near the pial surface. Altogether, these studies motivate a more thorough investigation of how retinotopy, as measured by fMRI, varies as a function of data resolution and cortical depth and its implication on individual variability in retinotopy. However, it is also important to note that studies of the columnar organization of non-human primates using single-cell recordings have not found any evidence that the receptive field location varies with cortical depth, although the receptive field size changes, being smallest in the middle layers (Hubel and Wiesel, 1974; Rosa et al., 1997).”</p><disp-quote content-type="editor-comment"><p>2. In my experience, this sort of polar angle discontinuity can also be the result of anatomical segmentation errors, however small. I think the authors want to ensure that this is not a driving influence here.</p></disp-quote><p>The three pRF model fits and other pre-processed data analyzed and reported in the manuscript (Supplementary File 7) have gone through the HCP pre-processing pipeline, which includes PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines (Benson et al., 2018; Glasser et al., 2013). Although it could be the case that ‘one pre-processing pipeline does not fit all,’ we believe that given the complexity of the HCP pipeline, such an investigation is beyond the scope of our manuscript.</p><disp-quote content-type="editor-comment"><p>3. To what extent could this sort of pattern of results be driven by eye movements? There are eye-tracking signals in the HCP dataset, so can the authors check this?</p></disp-quote><p>We checked the eye-tracking signal as suggested by the reviewer and did not find a consistent change in gaze position in individuals across clusters. Note that, as reported by Benson et al. (2018), “[…] eye tracking data are available on ConnectomeDB for most subjects, but we caution that the quality of the data is variable due to obstructions within the head coil.” Thus, although we found that individuals with noisy retinotopic maps did show a consistent change in gaze position throughout each retinotopic mapping stimuli presentation, we have not found a clear pattern in those with ‘dorsal Y’ maps. That said, as far as we are aware, there is no work suggesting that specific eye movements could lead to localized deviation in retinotopy, i.e., while we find unusual maps in the dorsal portion of the early visual cortex, their respective ventral portion follows the canonical representation (Figure 7, Figure 7—figure supplement 1, and Figure 4—figure supplement 2). All in all, it could be of interest to systematically evaluate gaze position change (and other eye-tracking signal derivatives) and how they relate to pRF modeling accuracy in more detail, which we discuss in our manuscript. Finally, for transparency purposes, we also made an interactive plot of the gaze position data available, as described here https://mne.tools/dev/auto_tutorials/io/70_reading_eyetracking_data.html, in our Jupyter Notebook.</p><p>Lines 477-495: “Another potential research direction is determining the extent to which eye movement underlies some of the variability found in retinotopic maps of early visual areas. For example, one could systematically evaluate pRF modeling accuracy as a function of gaze position change (and other eye-tracking signal derivatives). We performed a preliminary analysis of the deviation in gaze position at each time point and averaged across runs of retinotopic mapping stimuli and individuals assigned to each cluster. Supplementary File 6 summarizes the average deviation of gaze position from the fixation point along the X and Y axes for each cluster. In brief, we did not find consistent results across clusters. However, we do not rule out the effect of eye movement on the variability of the retinotopic maps because the eye-tracking data quality is variable and unavailable for some individuals in the HCP retinotopy dataset (Benson et al., 2018), and the clustering quality could be improved (e.g., through manual clustering or the other approaches previously discussed). Another possibility is determining the reliability of these retinotopic maps through connective field modeling (Haak et al., 2013) with unconstrained eye movement data (Tangtartharakul et al., 2023). Yet, we observe that unusual maps in the dorsal portion of the early visual cortex coincide with canonical representations in the ventral portion (Figure 7, Figure 7—figure supplement 1, and Figure 4—figure supplement 2), which is unlikely to be the case for noisy data driven by massive eye movements.”</p><disp-quote content-type="editor-comment"><p>To get a bit of a better view of the authors' claims I quickly went through the surface maps provided by the NSD paper, since the authors cite this paper as an example study that also showcases the idiosyncrasies reported here. I'm uploading outlines of the most compelling deviations from the canonical V2/V3 organization in this dataset (See https://www.dropbox.com/s/auqjmiz1nghsxv3/Screenshot-Reviewer2.png?dl=0) To summarise; I see clear examples of the patterns outlined by the authors in 4 out of 16 hemispheres (admittedly, slightly conservative an estimate, perhaps). This is below what the authors report. For 2 or 3 of these instances, there is a clear venous eclipse-like effect that could have caused the polar angle patterns to deviate -- we know that this sort of thing is more likely to occur at 7T than at 3T, where retinotopic maps usually look smoother. I don't know what this means in relation to the reported findings, of course, but it could indicate that the more detailed preprocessing and higher single-subject quality of the NSD data decrease the occurrence of the reported patterns.</p></disp-quote><p>We thank the reviewer for bringing this to our attention. As per the clustering analysis, we report that 2/3 of the left hemispheres show these unusual maps. However, we did notice it was unclear that we were referring to the left hemispheres in the ‘Abstract,’ so we appropriately addressed that by changing the Abstract. In addition, as highlighted by the reviewer in the uploaded figure, at least 4 out of 8 left hemispheres show unusual maps, which is not at odds with our estimates for the HCP dataset.</p><p>Lines 32-36: “Surprisingly, only one-third of individuals had maps that conformed to the expected pattern in the left hemisphere. Visual field sign analysis further revealed that in many individuals the area conventionally identified as dorsal V3 shows a discontinuity in the mirror-image representation of the retina, associated with a Y-shaped lower vertical representation.”</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>The work presented here by Ribeiro et al. attempts to quantify the observation that the &quot;standard model&quot; of V1, V2, and V3 matches the average human retinotopic maps but does not consistently match the retinotopic maps of individuals. (In this case, the &quot;standard model&quot; I'm referring to is just the assumption that the boundaries of V1, V2, and V3 topologically resemble those of the wedge-dipole model of Balasubramanian et al., 2002, or the banded double-sech model of Schira et al., 2010). Such non-standard retinotopic organizations in individual subjects are (as the authors note) well documented in other primates, and informal speculation about such non-standard human subjects has historically been common, if inconclusive, among those of us who study human V1-V3. Further, because the visual cortex is one of the few macroscopic brain systems for which neural computations, macroscopic organization, and connectivity are well-modeled, any novel observations about its individual variability are likely to lead to novel hypotheses about brain development and to serve as a template for future analyses. For these reasons, this manuscript is of clear value both to visual neuroscience researchers interested in the details of V1-V3 as well as to neuroscientists in adjacent domains.</p><p>While the findings of this paper are convincing and leave little doubt that non-standard organizations of V1-V3 not only exist but are common, it falls short of eliminating all possible explanations of such variability. To be clear, this is not primarily a critique of the paper but an observation that the authors' analyses point the field toward many additional questions. While the authors have done an excellent job demonstrating that large-scale deviations in the average curvature and BOLD signal do not explain large-scale variability of the maps, their analyses do not eliminate microscopic features of curvature or vasculature as potential causes. For example, a skeptic might claim that Cluster 2 (Figure 4) can be explained by partial voluming arising from tight curvature in a small patch of the dorsal V2-V3 region or by a blood vessel in the same region. If tight curvature or a vessel were critical to explaining these maps but were confined to a small patch of cortex, the analysis of curvature and BOLD intensity here may have been insufficiently precise to find it. (Of course, given the results of the analysis here, one might be justified in speculating that more detailed examinations of V1-V3 could reveal the &quot;standard&quot; model to be the model that most depend on typical sources of BOLD noise.) It would benefit the paper to include additional discussion of the extent to which the clear differences found in the clustered maps might or might not depend on microscopic features that are beyond the paper's current scope. However, the authors should be lauded for demonstrating conclusively that these differences cannot be easily dismissed.</p><p>I am particularly intrigued by the clustering analysis performed by the authors, summarized in Figure 4. This figure, along with Supplemental Figure 3, provides compelling evidence that the &quot;Dorsal Y,&quot; as the branching lower vertical meridian representation of V1 and V2 is sometimes called, is common and reasonably consistent across individuals. However, I am not entirely convinced that clusters 1, 3, and 5 are capturing substantial deviations in the &quot;standard&quot; model of human retinotopy. It is possible that density-based or hierarchical clustering methods that do not employ any dimension reduction would yield different results (though I am skeptical that the differences would be especially large). Regardless, the fundamental issue with these three clusters is that the topology of the V1-V2-V3 boundaries does not appear terribly different, even when, for example, the intensity of the lower vertical meridian differs. Of course, the intensity of the representation of the meridian may be a feature of the maps worth examining in and of itself, but I suspect that most researchers will be more interested in the clear violation of the topology of visual area boundaries implicit in the &quot;standard&quot; model that one can easily see in Cluster 2. With respect to the differences between Cluster 2 and the other clusters, it seems likely to me that the authors could have captured these differences more easily and accurately by examining the distribution and cortical location of the visual field sign (see for example Tootell et al., 1998, DOI:10.1073/pnas.95.3.811). The most interesting feature of this cluster is arguably that it suggests either (1) that, in these subjects, V2 and V3 are split, with each having a &quot;standard&quot; portion as well as a dorsal-anterior representation; or alternately (2) that at least one (or more likely 2) additional visual areas exist just anterior to dorsal V2 and dorsal to anterior V1. My speculation here – that the patch of cortex bounded by the two branches of the Y (i.e., dorsal to anterior V1 and anterior to dorsal V2) must consist of 2 separate representations – arises from the fact that it contains two separate patches of cortex in which the field signs do not match.</p></disp-quote><p>To address some of these concerns, we expanded the discussion about the vasculature effect on retinotopy and the limitations of the LME model to detect the effect of localized (microscopic) features that were not further investigated in our current work.</p><p>Lines 453-476: “Retinotopic maps could also vary as a function of data resolution and cortical depth. For example, signal-to-noise ratio (SNR) and partial volume artifacts are directly affected by data resolution (or voxel size); that is, both reduce with voxel size (Hoffmann et al., 2009). While lower SNR might lead to noisier (or less smooth) retinotopic maps (Hoffmann et al., 2009), the gain from the reduced susceptibility to partial volume artifacts will likely result in increased validity of the observed maps. Partial volume artifacts may arise from patches of opposite walls of a sulcus running across a single voxel or even small vessels, leading to inaccurate signals from the combination of different brain regions and tissues. With increasing magnetic field strength, it should be easier to strike the right balance between high SNR and low partial volume artifacts, which is crucial for determining the impact of registration errors due to partial volume artifacts on the variability of retinotopic maps. Moreover, previous studies have also shown that the hemodynamic response function (Puckett et al., 2016) and a spatial pattern of activation (Polimeni et al., 2010) varied across depths in V1. Specifically, Polimeni and colleagues found that a spatial pattern of activation (an ‘M’) becomes clearer from the white matter surface to the mid-thickness surfaces and then deteriorates once again near the pial surface. Altogether, these studies motivate a more thorough investigation of how retinotopy, as measured by fMRI, varies as a function of data resolution and cortical depth and its implication on individual variability in retinotopy. However, it is also important to note that studies of the columnar organization of non-human primates using single-cell recordings have not found any evidence that the receptive field location varies with cortical depth, although the receptive field size changes, being smallest in the middle layers (Hubel and Wiesel, 1974; Rosa et al., 1997).”</p><p>Lines 496-548: “Limitations</p><p>Although we demonstrate that common modes of deviation from the canonical dorsal V2 and V3 organization exist in the left hemisphere, further analyses are necessary to fully ascertain if such variability is indeed neurogenic or if it could be a result of measurement errors. Amongst potential sources of measurement error is the presence of large veins running adjacent to regions of interest. Accordingly, by using the normalized mean BOLD signal as a proxy for the location of large veins (Boyd Taylor et al., 2019; Kurzawski et al., 2022), studies have shown that voxels near these veins show lower mean BOLD signal, a phenomenon known as the venous eclipse, which affects pRF estimates, for example, in area hV4 (Boyd Taylor et al., 2019; Winawer et al., 2010). As such, deviations in the expected mean BOLD signal could result in deviations from the expected retinotopic organization. Thus, to better understand the potential effects of the presence of large veins on the different levels of variability in visual field representation across early visual areas, we considered both the pair-wise correlations between retinotopic maps and the normalized mean BOLD signal (Figure 3) and the large-scale deviation in the normalized mean BOLD signal as covariates in the LME model (Tables 3 and 4).</p><p>In the pair-wise correlation analysis, we found that the polar angle representation is indeed correlated with the normalized mean BOLD signal, and the magnitude of such association varies across visual areas. Specifically, we found a higher correlation (in magnitude) between the polar angle and normalized BOLD signal in ventral visual areas than in dorsal areas. This difference could be explained by ventral areas' proximity to the dural venous sinuses (Winawer et al., 2010), i.e., the transverse sinus, the superior sagittal sinus, and the straight sinus. These venous sinuses are known to introduce artifacts to the BOLD signal, which might lead to changes in retinotopic maps. Importantly, none of these sinuses run near the dorsal V2 and V3 (see Figure 4—figure supplement 2, in which it is possible to observe the likely confluence of sinuses), and both of which show the lowest correlation between polar angle and normalized BOLD signal maps.</p><p>Moreover, we modeled large-scale deviation in visual field maps using the large-scale deviation of the normalized mean BOLD signal as a covariate. We did find a significant effect of the normalized mean BOLD signal on the individual variability of eccentricity (Table 4) but not of polar angle maps (Table 3). Thus, to determine the effectiveness of the LME model for uncovering the effects of covariates, we similarly modeled the large-scale variability in polar angle maps of hV4 (not shown in the manuscript). We did not find an effect of the normalized mean BOLD signal on large-scale deviation in polar angle maps in hV4. However, we found a weak correlation between the polar angle and normalized mean BOLD signal (LH: r = -0.06; RH: r = -0.07). This finding does not reconcile with previous reports, i.e., that venous artifact impacts retinotopy. However, a fine-grained analysis of polar angle maps in hV4 indicated the inconsistent effect of the venous artifact on polar angle mapping (Boyd Taylor et al., 2019). In our analysis, though, these results might reflect an inability to appropriately parcellate hV4 at the individual level when using an atlas-based parcellation; while early visual areas are more consistently found at specific spatial locations, this is not the case for other visual areas of which spatial location and extent seem to vary across participants. Therefore, although we did not find a significant effect of the normalized mean BOLD signal in our LME model, it does not mean that the macro- and microvasculature do not affect retinotopy. For the former, future research might consider a fine-grained analysis of topographic deviations, such as the one reported by Boyd Taylor et al. (2019). For the latter, given that the mean BOLD signal is only used as a proxy for the location of large veins, a more detailed analysis of the microvasculature might require other imaging data, such as high-resolution time-of-flight magnetic resonance angiography data (Bollmann et al., 2022).”</p><disp-quote content-type="editor-comment"><p>Another possibility that I would have liked to see discussed is the likelihood that the &quot;Dorsal Y&quot; organization of Cluster 2 appears in many (more) subjects but does not appear at a consistent location with respect to eccentricity. To this end, I believe that Supplemental Figure 2 would have been more interesting had it been calculated not as a new set of clusters based on eccentricity but instead as the average eccentricity map of each of the clusters from Figure 4 that were based on the polar angle. My own observation (which I would like to emphasize is purely anecdotal) is that the eccentricity maps of subjects whose polar angle maps resemble those of Cluster 2 tend to bend sharply near the junction of the &quot;y&quot;. I find myself wondering if the subjects in Cluster 2 have a similar feature in their eccentricity maps, whether the junction of the &quot;y&quot; of Cluster 2 tends to occur near the same eccentricity across subjects, and whether the cortical magnification functions of such subjects differ substantially from those who do not have this feature. The size of the PRFs in these regions might also be illuminating---do they scale with eccentricity in a manner that matches the rest of dorsal V2 and V3?</p></disp-quote><p>We included a figure supplement (Figure 4—figure supplement 2) with a set of average maps of each cluster from Figure 4c, i.e., the cluster assignment was based on the clustering analysis with polar angle maps from the dorsal portion of the early visual cortex and left hemisphere. Based on the new figure, we could not find evidence that the polar angle mapping variability coincides with variability in eccentricity.</p><disp-quote content-type="editor-comment"><p>Overall, despite (and arguably because of) the many questions that this paper exposes, it is of substantial value to the community. Its results are straightforward and well-supported, and it provides a valuable starting point from which further refinements of the organization of the visual cortex can be studied.</p><p>Overall this paper is compelling and does not require substantial revision or refinement in order to be of great value to the field. To be frank, I have been hoping for several years that someone would publish a clear analysis of the dorsal retinotopic maps in V1-V3, and am pleased to see a conclusive demonstration of their variability finally appear. In my public review, I have pointed out many questions and implications that arise from these findings, and I believe that mentioning some of these implications would improve the paper. However, I do not believe that answering them is necessary for the paper – merely that discussion may be helpful for researchers who do not work on these maps closely on a regular basis.</p></disp-quote><p>We thank the reviewer for the interesting remarks made in the public review, and we have included responses to some of those above.</p><disp-quote content-type="editor-comment"><p>One concrete suggestion I do have for the authors is that a cursory examination of the field sign may lead to clearer clusters and thus a clearer narrative of the data in Figure 4. That said, the field sign can be tricky – such an analysis would likely rest at least somewhat on light smoothing of the PRF parameters and may become difficult in ways I have not anticipated. Similarly, a brief analysis of the patch of cortex bounded by the arms of the &quot;dorsal Y&quot; in Cluster 2 would be of substantial interest and may help determine what kind of deviation from the traditional maps this cluster represents.</p></disp-quote><p>We thank the reviewer for these suggestions. In the manuscript, we expanded our analysis of the “dorsal Y” by including the representation of polar angle maps’ gradients and their corresponding visual field sign representations, aiming to elucidate the kind of deviation from the traditional maps this cluster represents. In brief, the visual field sign analysis suggests that the area identified as dorsal V3 shows a discontinuity in the canonical mirror-image representation in individuals where the canonical type of representation is not evident.</p><p>Lines 800-821: “Visual field sign analysis</p><p>Lastly, we further examined unusual retinotopic maps to elucidate the kind of deviation from the canonical maps they represent. We performed a visual field sign analysis (Sereno et al., 1995, 1994), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image (like V2) or a mirror-image representation of the retina (like V1). Since the left hemisphere represents the right visual field, which in polar angle includes 0⁰-90⁰ (upper right visual field) and 270⁰- 360⁰ (lower right visual field), we shifted the polar angle values so the point of wrap-around (from 360⁰ to 0⁰) was positioned at the horizontal meridian in the contralateral hemifield, avoiding the discontinuous representation between 360⁰ and 0⁰. Then, we interpolated the sparse and flattened polar angle and eccentricity maps onto a regular x-y grid using SciPy (Virtanen et al., 2020). Next, we determined the gradient of polar angle and eccentricity maps, mathematically expressed as:</p><p><inline-formula><mml:math id="sa2m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>i</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mover><mml:mi>j</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></p><p>where <inline-formula><mml:math id="sa2m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the polar angle map and <inline-formula><mml:math id="sa2m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> the eccentricity, using the NumPy gradient numerical method (Harris et al., 2020). Finally, the angle between the polar angle and eccentricity maps’ gradient vectors was determined at each x-y coordinate. If the angle between the gradient vectors is between 0 and π, by convention, the cortical patch is a mirror-image representation of the retina; otherwise, it is a non-mirror-image. After binarizing the angle projection, we can conveniently infer borders between visual areas because adjacent areas often have the opposite visual field sign (Sereno et al., 1995; but see Yu et al. 2020 for caveat).”</p><p>Lines 291-340: Visual field sign analysis for delineating visual area boundaries</p><p>“Finally, we further examined retinotopic maps with a Y-shaped lower vertical representation, i.e., those primarily assigned to cluster 2, to elucidate the kind of deviation from the canonical maps they represent (Figure 7 and Figure 7—figure supplement 1). To do so, we performed a visual field sign analysis (Sereno et al., 1995, 1994), which combines both polar angle and eccentricity maps into a unique representation of the visual field as either a non-mirror-image or a mirror-image representation of the retina (Figure 7a; see Materials and methods). With such representation, we can directly infer visual area parcellation.</p><p>Figure 7b shows polar angle gradients in a ‘streamline’ representation and their respective visual field sign representation for two participants with canonical and four with Y-shaped lower vertical representations. While visual area boundaries in early visual cortex are conventionally identified by reversals in the progression of the polar angle values – or changes in the direction of polar angle gradients, it is unclear how to delineate boundaries in the dorsal portion of polar angle maps in those participants with non-canonical maps (note that their respective ventral portion followed the classical representation), but not on those with canonical maps. However, with the visual field sign representation, the boundaries delineating dorsal V2 in those participants with non-canonical maps are more explicit, and it reveals that the area identified as dorsal V3 shows a discontinuity in the expected mirror-image representation. Such representation has been proposed as the ‘incomplete-V3’ model of the third-tier cortex for the macaque (Angelucci and Rosa, 2015) and other similar models for the owl monkey (Sereno et al., 2015) and the marmoset monkey (Rosa and Tweedale, 2000). Figure 7—figure supplement 1 shows five more examples of polar angle maps with unusual Y-shaped lower vertical representations and five other examples with a truncated V3 boundary. While individuals with unusual Y-shaped lower vertical representations have a discontinuity in the canonical mirror-image representation of the retina in dorsal V3, individuals with a truncated V3 do not show such a discontinuity. Altogether, our findings may suggest that, at least in humans, the canonical model does not oppose other models established for non-human primates; these models coexist and reflect common modes of variability in the retinotopic mapping of early visual areas.”</p><disp-quote content-type="editor-comment"><p>I would also suggest that the authors include some discussion of how the human clusters found in this analysis compare to the 6 clusters found in non-human primates. I don't think that much ink needs to be spent on this, but it struck me as odd that the non-human primate clusters would be cited as motivation for the clustering parameters in humans and then never discussed more carefully.</p></disp-quote><p>As indicated by the reviewer, we selected this number of clusters as there are at least five different models of third-tier visual cortex organization in non-human primates. However, note that these models of the third-tier cortex are a guess at the size of the possibility space and do not reflect known inter-individual differences in non-human primates. Specifically, the non-human primate data is described by competing theories for how the third-tier visual cortex is organized, and each explains different aspects of parts of data sets that are far less complete than the HCP data. Besides, whether the areal boundaries in this region show significant individual variability has yet to be studied systematically in non-human primates (lines 583-588). We clarified this aspect in our methods.</p><p>Lines 795-797: <italic><bold>“</bold></italic>Note, however, that this selection is simply a speculation of the possibility space and do not reflect known inter-individual differences in non-human primates.”</p></body></sub-article></article>