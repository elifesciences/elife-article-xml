<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">95243</article-id><article-id pub-id-type="doi">10.7554/eLife.95243</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95243.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Embedding stochastic dynamics of the environment in spontaneous activity by prediction-based plasticity</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Asabuki</surname><given-names>Toshitake</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0951-5791</contrib-id><email>toshitake.asabuki@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Clopath</surname><given-names>Claudia</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4507-8648</contrib-id><email>c.clopath@imperial.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Department of Bioengineering, Imperial College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04j1n1c04</institution-id><institution>RIKEN Center for Brain Science, RIKEN ECL Research Unit</institution></institution-wrap><addr-line><named-content content-type="city">Wako</named-content></addr-line><country>Japan</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01sjwvz98</institution-id><institution>RIKEN Pioneering Research Institute</institution></institution-wrap><addr-line><named-content content-type="city">Wako</named-content></addr-line><country>Japan</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gjorgjieva</surname><given-names>Julijana</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02kkvpp62</institution-id><institution>Technical University of Munich</institution></institution-wrap><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>11</day><month>06</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP95243</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-01-17"><day>17</day><month>01</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-05-01"><day>01</day><month>05</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.05.01.538909"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-04-12"><day>12</day><month>04</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95243.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-12-03"><day>03</day><month>12</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95243.2"/></event></pub-history><permissions><copyright-statement>© 2024, Asabuki and Clopath</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Asabuki and Clopath</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-95243-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-95243-figures-v1.pdf"/><abstract><p>The brain learns an internal model of the environment through sensory experiences, which is essential for high-level cognitive processes. Recent studies show that spontaneous activity reflects such a learned internal model. Although computational studies have proposed that Hebbian plasticity can learn the switching dynamics of replayed activities, it is still challenging to learn dynamic spontaneous activity that obeys the statistical properties of sensory experience. Here, we propose a pair of biologically plausible plasticity rules for excitatory and inhibitory synapses in a recurrent spiking neural network model to embed stochastic dynamics in spontaneous activity. The proposed synaptic plasticity rule for excitatory synapses seeks to minimize the discrepancy between stimulus-evoked and internally predicted activity, while inhibitory plasticity maintains the excitatory-inhibitory balance. We show that the spontaneous reactivation of cell assemblies follows the transition statistics of the model’s evoked dynamics. We also demonstrate that simulations of our model can replicate recent experimental results of spontaneous activity in songbirds, suggesting that the proposed plasticity rule might underlie the mechanism by which animals learn internal models of the environment.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>synaptic plasticity</kwd><kwd>spontaneous activity</kwd><kwd>internal model</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/N013956/1</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010269</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.35802/200790</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>564408</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000266</institution-id><institution>Engineering and Physical Sciences Research Council</institution></institution-wrap></funding-source><award-id>EP/R035806/1</award-id><principal-award-recipient><name><surname>Clopath</surname><given-names>Claudia</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A computational model shows how synaptic plasticity shapes spontaneous activity to encode the transition statistics of sensory experience.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The brain is thought to use its sensory experience to learn an appropriate internal model of the environment, which can improve perception and behavioral performance. (<xref ref-type="bibr" rid="bib42">Merfeld et al., 1999</xref>; <xref ref-type="bibr" rid="bib38">Lewald and Ehrenstein, 1998</xref>; <xref ref-type="bibr" rid="bib10">Bell et al., 1997</xref>; <xref ref-type="bibr" rid="bib59">Yasui and Young, 1975</xref>; <xref ref-type="bibr" rid="bib57">Wolpert et al., 1995</xref>). Such learning is thought to be fundamental to higher-order cognitive processes such as perception, decision making, and prediction of sensory stimuli. Recent computational and experimental evidence suggests that the brain’s learned internal model may be reflected in spontaneous activity. For example, in the visual cortex of awake ferrets, spontaneous activity shows spatial similarity to activity elicited by natural scenes (<xref ref-type="bibr" rid="bib11">Berkes et al., 2011</xref>). Furthermore, hippocampus generates sequential replay of place fields during rest and sleep (<xref ref-type="bibr" rid="bib56">Wilson and McNaughton, 1994</xref>; <xref ref-type="bibr" rid="bib50">Skaggs and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="bib36">Lee and Wilson, 2002</xref>). Such hippocampal replay occurs in a highly stereotyped temporal order, with the same sequence of replayed activities often observed across multiple events (<xref ref-type="bibr" rid="bib17">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib18">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib27">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib58">Wu and Foster, 2014</xref>).</p><p>Several computational studies have proposed variants of Hebbian plasticity rules for learning deterministic or even stochastic switching dynamics of replayed activities (<xref ref-type="bibr" rid="bib37">Levy et al., 2001</xref>; <xref ref-type="bibr" rid="bib39">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="bib53">Triplett et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ocker and Doiron, 2019</xref>; <xref ref-type="bibr" rid="bib5">Asabuki and Fukai, 2024</xref>). However, it has been challenging to extend these results to generate dynamic spontaneous activity obeying appropriate transition probabilities learned through sensory experience. Finding a plasticity rule which is capable of learning structured transitions in spontaneous activity could be instrumental for understanding the mechanism underlying cognitive processes in the brain.</p><p>In this paper, we propose a local biologically plausible plasticity rule for learning the statistical transitions between assemblies in spontaneous activity. We use a recurrent spiking neural network model consisting of distinct excitatory and inhibitory populations. The proposed synaptic plasticity rule for excitatory synapses seeks to minimize the discrepancy between stimulus-evoked and internally predicted activity, while inhibitory plasticity maintains the excitatory-inhibitory balance. We explore the potential performance of our model by learning the Markovian transition statistics of evoked network states. Our results show that the trained model exhibits spontaneous stochastic transitions of cell assemblies, even after structured external inputs are removed. We show that the transition statistics of spontaneous activity show a striking similarity to those of the evoked dynamics.</p><p>To further validate our model, we compare the model behavior with recent experimental results in songbirds (<xref ref-type="bibr" rid="bib13">Bouchard and Brainard, 2016</xref>), which show that the uncertainty of upcoming states in a bird song modulates the degree of neural predictability. Our model replicates this experimental result, suggesting that the connectivity structure learned via the proposed plasticity mechanism could plausibly underlie the songbird’s learned internal model.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Spontaneous replay of learned stochastic sequences</title><p>While most studies have investigated plasticity mechanisms for learning random switching (<xref ref-type="bibr" rid="bib39">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="bib53">Triplett et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ocker and Doiron, 2019</xref>; <xref ref-type="bibr" rid="bib5">Asabuki and Fukai, 2024</xref>) or deterministic transitions (<xref ref-type="bibr" rid="bib15">Chadwick et al., 2015</xref>) between cell assemblies, our objective is to create a network model that spontaneously replays stochastic sequences of assemblies following synaptic plasticity. To that end, we first design a simple task whereby stimuli undergo stochastic transitions over time, and presentation of each stimulus increases excitatory drive to neurons targeted by that pattern (<xref ref-type="fig" rid="fig1">Figure 1a,top</xref>). We assume that a non-overlapping subset of excitatory network neurons receive its preferred stimulus (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). After learning, the network should replay stochastic sequences of assemblies with transitions that are statistically consistent with evoked dynamics, without relying on external stimuli (<xref ref-type="fig" rid="fig1">Figure 1a, bottom</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Task to be learned.</title><p>(<bold>a</bold>, top) An example of a task used to test the model. Stimulus patterns evolve in time according to structured transition probabilities. The presentation of each stimulus pattern activates the corresponding group of neurons. Recurrent connections are learned by synaptic plasticity (<bold>a</bold>, bottom). The learned network should replay assemblies spontaneously, where the transition statistics are consistent with the evoked stimuli. (<bold>b</bold>) A network model with distinct excitatory and inhibitory populations. Only excitatory populations are driven by external inputs. Only synapses that project to excitatory neurons are assumed to be plastic. (<bold>c</bold>) A schematic of the proposed plasticity rules. Excitatory (blue) and inhibitory (orange) synapses projecting to an excitatory neuron (triangle) obey different plasticity rules. For excitatory synapses, errors between internally driven excitation (blue sigmoid) and the output of the cell provide feedback to the synapses (dashed arrow) and modulate plasticity (blue square; exc. error). All excitatory connections seek to minimize these errors. For inhibitory synapses, the error between internally driven excitation (blue sigmoid) and inhibition (orange sigmoid) must be minimized to maintain excitation-inhibition balance (orange square; inh. error).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig1-v1.tif"/></fig><p>We examined the possible learning mechanisms of stochastic neural sequences with a recurrent spiking network. Our network model consists of excitatory (E) and inhibitory (I) model neurons (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Only excitatory neurons are driven by external stochastic sequences. Initially, neurons in the network have random recurrent connections.</p><p>To learn a network model to obtain transition statistics of evoked dynamics, we proposed different local plasticity mechanisms for excitatory and inhibitory synapses. We assumed that only connections onto excitatory neurons were plastic (<xref ref-type="fig" rid="fig1">Figure 1b</xref>), while all others (i.e. connections onto inhibitory neurons) were fixed. In the excitatory recurrent connectivity, all synaptic weights were modified to reduce the error between internally generated and stimulus-evoked activities (<xref ref-type="fig" rid="fig1">Figure 1c, blue square</xref>). This plasticity rule is mathematically similar to that proposed in <xref ref-type="bibr" rid="bib46">Pfister et al., 2006</xref>; <xref ref-type="bibr" rid="bib54">Urbanczik and Senn, 2014</xref>, which minimizes the discrepancy between the somatic and dendritic activities (<xref ref-type="bibr" rid="bib2">Asabuki and Fukai, 2020</xref>; <xref ref-type="bibr" rid="bib5">Asabuki and Fukai, 2024</xref>). Through this process, excitatory synapses that contribute to predicting neural activity will be strengthened, thereby increasing the similarity between spontaneous and evoked activity. Instead of predicting the firing rate of neurons, the inhibitory synapses were modified to predict the recurrent excitatory potential (<xref ref-type="fig" rid="fig1">Figure 1c, orange square</xref>). This inhibitory plasticity is crucial for the network to maintain excitatory-inhibitory balance (<xref ref-type="bibr" rid="bib55">Vogels et al., 2011</xref>) and generate spontaneous replay of stochastic assembly sequences, as we will see later. All feedforward connections were fixed and receptive fields were preconfigured. Finally, as in the previous study (<xref ref-type="bibr" rid="bib5">Asabuki and Fukai, 2024</xref>), parameters of the response function are regulated according to the activity history of individual neurons (Methods). This regulation maintains the appropriate dynamic range of activities irrespective of the strength of external stimuli.</p><p>To examine how external stochastic sequences can influence network wiring, we trained a network model driven by stochastic external inputs. These inputs were generated by first-order Markovian chains with three 200ms long states, governed by fixed transition probabilities (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). During training, excitatory synapses were modified much quicker than inhibitory synapses (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). This difference in plasticity timescales follows from the nature of our learning rules: the wiring of excitatory synapses is reorganized by external stimuli, while inhibitory synapses only change to rebalance excitation. As such, excitatory plasticity in our model occurs before inhibitory plasticity, consistent with the experimental results (<xref ref-type="bibr" rid="bib16">D’amour and Froemke, 2015</xref>). Indeed, even when the learning rate of inhibitory plasticity was twice that of excitatory plasticity, inhibitory plasticity still occurred on a slower timescale than excitatory plasticity (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Spontaneous replay of stochastic transition of assemblies.</title><p>(<bold>a</bold>) First, we considered a simple stochastic transition between three stimulus patterns. (<bold>b</bold>) Dynamics of weight change via plasticity. Excitatory synapses (blue) converged quicker than inhibitory synapses (orange). (<bold>c</bold>) Example spontaneous assembly reactivations (top) and raster plot (bottom) of the learned network are shown. Colors indicate the corresponding stimulus patterns shown in a. (<bold>d</bold>) Distribution of assembly reactivations. (<bold>e</bold>, left) The network currents to assembly 1 (green) and assembly 2 (orange) immediately after the reactivation of assembly 3 ceased. Both currents were similar in magnitude. (<bold>e</bold>, right) Currents to assembly 2 (orange) and assembly 3 (blue) immediately after the reactivation of assembly 1 ceased. The current to assembly 3 was stronger than that to assembly 2. (f) Relationship between the transition statistics of stimulus patterns and that of replayed assemblies. The spontaneous activity reproduced transition statistics of external stimulus patterns.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Inhibitory plasticity lags behind excitatory plasticity.</title><p>(<bold>a</bold>) The learning rate of inhibitory plasticity was made twice that of excitatory plasticity. The inhibitory plasticity still occurred on a slower timescale than excitatory plasticity (<xref ref-type="bibr" rid="bib22">Froemke et al., 2007</xref>). (<bold>b</bold>) Example raster plot of spontaneous assembly reactivations of the learned network are shown. (<bold>c</bold>) Even if the learning rate of inhibitory plasticity was larger, the spontaneous activity reproduced transition statistics of external stimulus patterns.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Unstructured spontaneous activity before learning.</title><p>Example spontaneous assembly reactivations (top) and raster plot (bottom) of the network are shown. Colors indicate the corresponding stimulus patterns shown in <xref ref-type="fig" rid="fig2">Figure 2a</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>The network performance is less sensitive to the duration of evoked assembly activations during learning.</title><p>(<bold>a</bold>) The distributions of the durations of the assembly reactivations after training with input states of half the duration of the initial setting are shown. (<bold>b</bold>) The spontaneous activity of the trained network still showed appropriate transition dynamics.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>The network performance dependence on cell assembly size.</title><p>(<bold>a</bold>) The network was trained with the assembly size ratio of 1:1.5:2. (<bold>b</bold>) In the case of a, the spontaneous activity after training reproduced an appropriate transition statistics. (<bold>c</bold>) The network was trained with the assembly size ratio of 1:2:3. (<bold>d</bold>) In the case of c, the network showed less performance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-figsupp4-v1.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>The learning rate controls the duration of cell assembly reactivations.</title><p>(<bold>a</bold>) The learning rate of all plasticity was made half that of the original settings in <xref ref-type="fig" rid="fig2">Figure 2</xref>. (<bold>b</bold>) In the case of a, the spontaneous activity reproduced the transition statistics of the external stimulus patterns. (<bold>c</bold>) The learning rate of all plasticity was made twice that of the original settings in <xref ref-type="fig" rid="fig2">Figure 2</xref>. The duration of assembly reactivations was shorter than in a. (<bold>d</bold>) Spontaneous activity reproduced transition statistics of external stimulus patterns.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-figsupp5-v1.tif"/></fig><fig id="fig2s6" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 6.</label><caption><title>The network performance dependence on the strength of background input.</title><p>(<bold>a</bold>) The network was trained and tested with half the strength of the background input compared to the case in <xref ref-type="fig" rid="fig2">Figure 2</xref>. (<bold>b</bold>) The network showed worse performance than the case shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. (<bold>c</bold>) The network was trained and tested with double the strength of the background input compared to the case in <xref ref-type="fig" rid="fig2">Figure 2</xref>. (<bold>d</bold>) The network exhibited more uniform transitions compared to the case in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-figsupp6-v1.tif"/></fig><fig id="fig2s7" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 7.</label><caption><title>The networks with more biologically plausible architectures.</title><p>(<bold>a</bold>) The network consists of 80% of excitatory neurons and 20% of inhibitory neurons was trained. Same as in <xref ref-type="fig" rid="fig1">Figure 1</xref>, synapses projecting on excitatory neurons only were trained (left). The network after training showed spontaneous activity with appropriate transition statistics (middle, bottom). (<bold>b</bold>) Same with a, but all synapses were assumed to be plastic. The network spontaneous activity did not show appropriate transitions. (<bold>c</bold>) Same with b, but all network neurons receive the external input. The network spontaneous activity did not show appropriate transitions. (<bold>d</bold>) Same with c, but all inhibitory neurons had mixed selectivity. Here, we assumed that when each state is presented, all inhibitory neurons are driven with a randomly assigned intensity between 0 and 2. The spontaneous activity showed appropriate transitions in this case.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig2-figsupp7-v1.tif"/></fig></fig-group><p>We then asked how plasticity affects the neural dynamics by comparing the spontaneous activities of the network before and after learning. Here, we simulated spontaneous activity by replacing the temporally structured stimulation (i.e. the Markovian chain in <xref ref-type="fig" rid="fig2">Figure 2a</xref>) with constant background input. Furthermore, all synapses were kept fixed during spontaneous activity. Before learning, due to uniform initial connectivity, all excitatory neurons showed synchronous and spatially unstructured spontaneous activity (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). However, after learning, three cell assemblies emerged in the network, each of which encoded one external stimulus. Sequences of these cell assemblies were replayed stochastically in spontaneous activity (<xref ref-type="fig" rid="fig2">Figure 2c</xref>), and durations of given assembly reactivations were biased toward shorter durations but distributed broadly (<xref ref-type="fig" rid="fig2">Figure 2d</xref>).</p><p>We next asked whether or not the statistics of assembly switching were influenced by the temporal structure of the external sequence received by the network while it was learning. Since each assembly reactivation was contingent upon the previous assembly, statistics of external sequence may influence the strength of synaptic currents via recurrent connectivity. To test this prediction, we first investigated how spontaneous reactivation of assembly 3 drives the subsequent assemblies (i.e. assemblies 1 and 2). Immediately after the reactivation of assembly 3 ceased, currents onto both subsequent assemblies increased gradually, without showing a significant difference (<xref ref-type="fig" rid="fig2">Figure 2e, left</xref>). This is due to the fact that state 1 and state 2 are structurally symmetrical in our setting (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). We then asked how reactivation of assembly 1 drives the subsequent assemblies (i.e. assemblies 2 and 3). We note that the transition probabilities in the stimulus patterns were biased towards state 3 in this case (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). Consistent with this bias between transition probabilities, we found that assembly 3 was driven much strongly than assembly 2 (<xref ref-type="fig" rid="fig2">Figure 2e, right</xref>). These results suggest that the temporal statistics of the trained external sequence influence the strength of synaptic currents that drive each assembly. We then quantified the similarity between the transition statistics of stimulus patterns and that of the replayed assemblies. We defined the transition probabilities between assemblies by simply counting the occurrence of switching events over all possible pairs of assemblies (Methods). Comparison between transition probabilities of stimulus patterns and that of the reactivated assemblies revealed a clear alignment of temporal statistics (<xref ref-type="fig" rid="fig2">Figure 2f</xref>). Interestingly, even when the network was trained with input states of half the duration, the distributions of the durations of assembly reactivations remain almost identical to those in the original case (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3a</xref>). Furthermore, the transition probabilities in the replay were still consistent with the true transition probabilities (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3b</xref>).</p><p>We then asked how robust our model is to different stimulus settings and parameters. To this end, we first asked whether varying the size of the cell assemblies would affect learning. We ran simulations with two different configurations (in the task shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>). The first configuration used three assemblies with a size ratio of 1:1.5:2. After training, these assemblies exhibited transition statistics that closely matched those of the evoked activity (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4a</xref>). In contrast, the second configuration, which used a size ratio of 1:2:3, showed worse performance compared to the 1:1.5:2 case (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4b</xref>). These results suggest that the model can learn appropriate transition statistics as long as the size ratio of the assemblies is not drastically varied. We next asked whether the speed of plasticity, controlled by the learning rate, would affect model performance. To see this, we trained the network model in two cases, one with a fast plasticity and one with a slow plasticity. We found that the two models still showed spontaneous assembly replay whose statistics clearly matched those of the evoked dynamics (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5b, d</xref>). Interestingly, however, we found that the duration of assembly became longer in the slow learning case than in the fast case (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5a, c</xref>). Finally, we found that the weaker background input causes spontaneous activity with a lower replay rate, which in turn leads to a high variance of the encoded transition (<xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6a, b</xref>), while stronger inputs make the assembly replay transitions more uniform (<xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6c, d</xref>).</p><p>We then tested whether learning performance would be affected by setting the ratio of excitatory to inhibitory neurons to 80% and 20% (<xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7a, left</xref>). Even in such a scenario, the network still showed structured spontaneous activity (<xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7a, center</xref>), with transition statistics of replayed events matching the true transition probabilities (<xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7a, right</xref>). We then asked whether the model with our plasticity rule applied to all synapses would reproduce the corresponding stochastic transitions. We found the network could replay the appropriate transition only under some conditions (<xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7b</xref>). The replay failed when the inhibitory neurons were no longer driven by the synaptic currents reflecting the stimulus, due to a tight balance of excitatory and inhibitory currents on the inhibitory neurons. We found similarly that when each stimulus pattern activates a non-overlapping subset of neurons, the network does not exhibit the correct stochastic transition of assembly reactivation (<xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7c</xref>). Interestingly, when the activity of each neuron is triggered by multiple stimuli and has mixed selectivity, the reactivation reproduced the appropriate stochastic transitions (<xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7d</xref>).</p><p>In summary, the plasticity rules in our model learn the transition statistics of evoked patterns while maintaining excitation-inhibition balance. Our results show that the prediction-based plasticity rule allows the model to learn and spontaneously replays the transition statistics of evoked patterns.</p></sec><sec id="s2-2"><title>Learned excitatory synapses encode transition statistics</title><p>To further understand the mechanism underlying the statistical similarity between the evoked patterns and spontaneous activity, we next asked how the transition statistics of stimulus patterns can influence network wiring. Over the course of training, the average weights of connections in each of the three cell assemblies increased gradually and converged to a strong value (<xref ref-type="fig" rid="fig3">Figure 3a, middle and b, top</xref>), indicating the formation of assemblies. On the other hand, we found that the average weights between each pair of assemblies decreased and settled at different stationary values (<xref ref-type="fig" rid="fig3">Figure 3a, right and b, bottom</xref>). After training, we reasoned that the transition probabilities between states should be encoded exclusively via between-assembly connections, as none of the states in the Markovian chain have self-transitions. To test this prediction, we first compared the average between-assembly connection matrix (<xref ref-type="fig" rid="fig3">Figure 3a, right</xref>) and the ground truth transition aligned well to the ground truth probabilities (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). These results indicate that the network learns the temporal statistics of sequences by modifying the structure of inter-assembly excitatory connections.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Learned excitatory synapses encode transition statistics.</title><p>(<bold>a</bold>) A 3 by 3 matrix of excitatory connections, learned with the task in Fig.2a (left). The matrix can be decomposed to within- (middle) and between-assembly connections (right). (<bold>b</bold>) Strength of within- (top) and that of between-assembly excitatory synapses (bottom) during learning are shown. (<bold>c</bold>) True transition matrix of stimulus patterns. (<bold>d</bold>) Relationship between the strength of excitatory synapses between assemblies and true transition probabilities between patterns.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>The role of inhibitory plasticity in transition probability learning.</title><p>(<bold>a</bold>) Example spontaneous assembly of a model without inhibitory plasticity is shown. (<bold>b</bold>) Relationship between the transition statistics of stimulus patterns and that of replayed assemblies. (<bold>c</bold>) Learned excitatory weights. (<bold>d</bold>) Relationship between the strength of excitatory synapses between assemblies and true transition probabilities between patterns.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Network adaptation to task switching.</title><p>(<bold>a</bold>) Two types of tasks were considered. (<bold>b</bold>) Strength of within- (top) and that of between-assembly excitatory synapses (bottom) during learning are shown. Switching from task1 to task2 was occured at the middle of learning phase (inverted triangles). Between-assembly connectivity reorganized once the task switching occurred. (<bold>c</bold>) Dynamics of prediction error for excitatory (blue) and inhibitory (orange) plasticity are shown. (<bold>d</bold>) Magnified versions of c are shown. Both errors show an abrupt increase immediately after task switching, followed by a gradual decay. In c and d, errors were calculated as averages over five independent simulations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig3-figsupp2-v1.tif"/></fig></fig-group><p>The above analysis of excitatory weights revealed its crucial role in learning transition probabilities. Next, we examined the role of inhibitory plasticity in our model’s function. To do so, we first simulated the network with fixed inhibitory weights performing the same task shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>. We found that such a model exhibited spontaneous activity with blurred assembly structures compared to the original model (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a</xref>). Furthermore, the transition probabilities between replayed assemblies in this case did not show clear alignment with true transition (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref>), though the excitatory weights reached values which did encode transitions (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c, d</xref>). These results suggest that maintenance of EI balance through inhibitory plasticity is necessary for generating structured spontaneous activity, even if excitatory connections learn transition probabilities.</p></sec><sec id="s2-3"><title>Network can adapt fast to task switching</title><p>In the above results, transitions between stimulus patterns obeyed fixed transition probabilities. We then wondered how the network learning would be affected if transition structures of stimulus patterns changed over time. To test such a scenario, we considered a case where the transition matrix in a Markovian chain switch between the first half and the second half of the learning phase (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a</xref>). We will refer these matrices as task1- and task2-matrix, respectively, and examine whether switching of transition matrixes influences the connectivity. During the first half of learning phase, between-assembly connections converged to certain values to encode task1-matrix (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b, bottom</xref>, 0–500 s). However, such stable connectivity reorganized quickly once the imposed task was switched to task2-matrix (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b, bottom</xref>, 500–1000 s). Note that in contrast to between-assemblies connections, within-assembly connections did not show such reorganization (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b, top</xref>). These results indicate that our model adapted to the second task even if distinct assembly structures were already formed during the first task.</p><p>To further understand how the model adapts to the new task, we next asked how error terms in excitatory and inhibitory plasticity (<xref ref-type="disp-formula" rid="equ11 equ15">Equations 11 and 13</xref>) change through learning. As expected, the low-pass filtered errors <inline-formula><mml:math id="inf1"><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> decreased as the network trained on task1 (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c</xref>, 0-500 s). However, once the task was switched, errors showed an abrupt increase followed by a gradual decrease as the network learned the second task (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c</xref> 500-1000 s; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2d</xref>). Consistent with the previous result (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), the peak of inhibitory error occurred delayed after that of excitatory one in each task (<xref ref-type="bibr" rid="bib16">D’amour and Froemke, 2015</xref>; <xref ref-type="bibr" rid="bib55">Vogels et al., 2011</xref>; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2d</xref>). In summary, our model is also capable of task switching, via the reorganization of its weight structures through continuing plasticity.</p></sec><sec id="s2-4"><title>The network can learn complex stochastic sequences</title><p>So far, we have considered the capabilities of our model in regard to the relatively simple class of stochastic dynamics. In particular, the task we considered above contains only three states, and the transition structure was symmetric. In a realistic sequence, like the song of a bird, transition statistics are typically heterogeneous and more structured. To evaluate the model performance over a wide variety of structures, we now consider a transition diagram with more complex structure (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). Despite its complex structure, the learned network showed spontaneous reactivations of all assemblies evoked during learning (<xref ref-type="fig" rid="fig4">Figure 4b</xref>), and the transition dynamics between these assemblies were governed by learned transition probabilities (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). Indeed, the learned weight structures were consistent with the transition probabilities between states as we have seen in simpler task (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Learning complex structures.</title><p>(<bold>a</bold>) Transition diagram of complex task. (<bold>b</bold>) Spontaneous activity of learned network. (<bold>c</bold>) Transition statistics of assemblies reproduce true statistics. (<bold>d</bold>) Transition diagram of temporal community structure. (<bold>e</bold>) Raster plot of spontaneous activity of the network trained over structure shown in (<bold>d</bold>). (<bold>f</bold>) Structure of learned excitatory synapses encode the community structure. (<bold>g</bold>) Spontaneous transition between assemblies connected in the diagram shown in d occurs much frequent than disconnected case. (<bold>h</bold>) Low dimensional representation of evoked activity patterns shows high similarity with community structure. (<bold>i</bold>) Time courses of replayed activities transitioning within (red) and between (blue) communities. (<bold>j</bold>) Comparison of mean durations in (<bold>i</bold>). P-value was calculated by two-sided Welch’s t-test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>The excitatory synapses learned transition structures of complex task shown in <xref ref-type="fig" rid="fig4">Figure 4a</xref>.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Low-dimensional community structure reflects learned weights, not input order.</title><p>(<bold>a</bold>) Scrambled structure in which presentation rule of patterns violates temporal community structure. Scrambled sequence consists of both learned (black arrows) and untrained (red arrows) transitions, which viorates the community structure. The network underwent scrambled task only after it learned community structure shown in <xref ref-type="fig" rid="fig4">Figure 4d</xref>. (<bold>b</bold>) Low-dimensional representation of activity patterns evoked by scrambled sequence.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig4-figsupp2-v1.tif"/></fig></fig-group><p>Recent experimental studies which examined temporal community structure (i.e. highly structured graph structure consisting of clusters of densely interconnected nodes; <xref ref-type="fig" rid="fig4">Figure 4d</xref>) found that human subjects tend to associate a given visual stimulus with other stimuli within the same ‘community’ (<xref ref-type="bibr" rid="bib48">Schapiro et al., 2013</xref>; <xref ref-type="bibr" rid="bib47">Pudhiyidath et al., 2022</xref>). To investigate whether the model can learn to associate states within a stimulated community, we first trained the network with a stochastic sequence of inputs, generated by a random walk over a graph with temporal community structure (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). The learned model showed stochastic assembly transition during spontaneous activity (<xref ref-type="fig" rid="fig4">Figure 4e</xref>) relying on the appropriate weight structure (<xref ref-type="fig" rid="fig4">Figure 4f</xref>). Although transitions occurred between all pairs of assemblies, transitions between connected states in the diagram occurred much frequently than transitions between disconnected states (<xref ref-type="fig" rid="fig4">Figure 4g</xref>). This is because plasticity formed strong excitatory connections between assemblies with nonzero transition probabilities, as shown in <xref ref-type="fig" rid="fig4">Figure 4f</xref>.</p><p>In human participants, low-dimensional representations of evoked activities in different cortical regions have been reported to show clusters consistent with the structure of communities (<xref ref-type="bibr" rid="bib48">Schapiro et al., 2013</xref>). To test whether our model could reproduce such representation of communities, we analyzed the low-dimensional representation of evoked activities in our model by applying principal component analysis (PCA) (see Methods). Such analysis revealed that the representations of stimulus patterns were grouped together into clusters or communities of mutually predictive stimuli, consistent with the experimental results (<xref ref-type="fig" rid="fig4">Figure 4h</xref>). We found that the clustered representations still exist even if the input sequences were scrambled after learning (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>), indicating that this result does not rely on the stimulus protocol, but instead on the learned weights.</p><p>We further asked whether within- and between-community reactivations showed any differences in terms of their behavior. To this end, we perturbed an assembly corresponding to non-boundary states in the first community (states 2–4 in the transition diagram shown in <xref ref-type="fig" rid="fig4">Figure 4d</xref>) and monitored the behavior of subsequent autonomous network activities. According to the above results, we expect that within-community reactivations should occur quicker than between-community assemblies, due to strong within-community coupling. To test this hypothesis, we calculated the duration from the end of the perturbation until subsequent activity reached a certain threshold (<xref ref-type="fig" rid="fig4">Figure 4i</xref>). As expected, the transition to within-community states showed much shorter durations than to between-community case (<xref ref-type="fig" rid="fig4">Figure 4j</xref>), indicating that between-community transition occurred with much slower time scale compared to within-community case. Together, these results indicate that our network can learn complex temporal structures in spontaneous activity and reproduce the neural representation of the temporal community structure observed in the experiment.</p></sec><sec id="s2-5"><title>Network dynamics consistent with recorded neural data of songbirds</title><p>Finally, we tested whether the spontaneous activity in our model resembles recorded neural activity of HVC in Bengalese finch (Bf). Bf learns songs composed of multiple stereotyped short sequences, or syllables. The transitions between these syllables can be described via Markovian process with varying levels of certainty. Intuitively, given one syllable in a bird song, precise prediction about the neural response to the next syllable can be made if the transition from that syllable is highly certain, while imprecise transitions will lead to imprecise predictions about the neural response. Indeed, recent experimental study reported that uncertainty of upcoming syllables in a Bf song modulates the degree of predictability of subsequent neural activation (poststimulus activity; PSA) in HVC (<xref ref-type="bibr" rid="bib13">Bouchard and Brainard, 2016</xref>). We sought to test whether our model would exhibit a similar property. To this end, we analyzed the behavior of a network model that had already learned the task (shown in <xref ref-type="fig" rid="fig4">Figure 4a</xref>). The transition structure we chose is relatively simple compared to the real song of a Bf, yet captures measured features of bird songs (i.e. both structures consist of highly certain and less-certain transitions). In the experiment, similarities were calculated between the trial-averaged PSA following a short sequence of stimuli, and the response to an isolated stimulus. To mimic this experimental design, we measured stimulus-triggered averages of our autonomous network activity as a proxy for PSA (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). To examine how uncertainty of state transitions in a sequence influences predictive strength in network activity, we first calculated the Pearson correlation coefficient between PSA and responses to next states in a sequence. We will refer to such correlations as ‘next-state correlations.’ Note that if there were multiple next-states from a given state, all correlations corresponding to that state were averaged. We further calculated the correlation between PSA and responses to other states that did not follow the given state (‘other-state correlations’). Similar to the next-state correlations, other-state correlations were averaged over all disconnected states from each state. We then compared next-state correlations and other-state correlations between highly certain (<xref ref-type="fig" rid="fig5">Figure 5b, left</xref>) and less-certain (<xref ref-type="fig" rid="fig5">Figure 5b, right</xref>) transitions. Here, highly certain transitions refer to those which have a transition probability greater than 1/2. Other transitions were classified as less-certain transitions. Consistent with experimental results, next-state correlations were significantly greater than other-state correlations in the highly certain case (<xref ref-type="fig" rid="fig5">Figure 5b, left</xref>). This correlation difference was less significant in less-certain case (<xref ref-type="fig" rid="fig5">Figure 5b, right</xref>). These results indicate that transition uncertainty modulated the degree to which PSA is predictive of upcoming states.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Network dynamics consistent with recorded neural data of songbird.</title><p>(<bold>a</bold>) Example poststimulus activity (PSA) for low- (left) and high-entropy (right) transition cases. (<bold>b</bold>) Comparison of correlation coefficients between PSA and evoked single-syllable responses for next syllables and other syllables. For low entropy transition case, the next-syllables correlations were significantly higher than other-syllables correlations (p &lt; 0.01, Wilcoxon signed-rank test) (left). In contrast, such correlation coefficients showed no significant difference for high entropy transition case (p &gt; 0.3, Wilcoxon signed-rank test) (right). Red crosses are mean. (<bold>c</bold>) The difference in correlation coefficients between next and other syllables (ΔR) was significantly greater for low entropy transitions than for high entropy transitions (p &lt; 0.01, two-sided Welch’ s t-test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95243-fig5-v1.tif"/></fig><p>We performed a more direct comparison of predictive strength by measuring the difference between two types of correlations (i.e. next- and other-state correlations) over multiple levels of transition uncertainty. Here, for each state, next-state correlation was subtracted by other-state correlation. Transition uncertainties were quantified by calculating the conditional entropy of transition probabilities of stimulus patterns. Note that a higher value of entropy indicates less-certain transition, and vice versa. As expected, correlation differences increased as entropy decreased (<xref ref-type="fig" rid="fig5">Figure 5c</xref>), indicating that the predictive strength of network PSA was larger for low-entropy transitions (i.e. highly certain transitions) than for high-entropy transitions (i.e. less-certain transitions). What is the underlying mechanism of such predictability differences? Although each trial of assembly perturbation lead to subsequent reactivation of one of the assemblies, trial-averaged activities (i.e. PSAs) marginalized all possible transitions in the transition diagram (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). Due to this averaging process, similarities between PSA and stimulus-evoked activities increase if conditional entropy is low (i.e. certain transition), and vice versa. Overall, our results suggest that our model learns transition statistics of stimulus patterns, with transition uncertainty influencing predictive strength in the network activity.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Understanding how the brain learns internal models of the environment is a challenging problem in neuroscience. In this study, we proposed synaptic plasticity rules for learning assembly transitions via sensory experiences. Our excitatory plasticity aims at minimizing the error between sensory-evoked and internally generated predictions of upcoming activity. We showed that the network learns the appropriate wiring patterns to encode the transition structure of states, and thus exhibits stochastic transitions between assemblies in spontaneous activity. We further showed that appropriate replay of stochastic transitions requires both excitatory and inhibitory plasticity. These plasticity rules showed a clear division of labor. For excitatory synapses, the connectivity learns transition probabilities during the evoked phase, and inhibitory plasticity seeks to maintain the excitatory-inhibitory balance. We showed that network excitatory plasticity alone cannot account for stochastic replay of learned activity, even if excitatory synapses learn an appropriate structure. Future experimental studies could examine our model’s predictions by testing how blocking synaptic plasticity specifically in excitatory or inhibitory neuron populations distinctly impacts the transition statistics in spontaneous replay events.</p><p>Variants of the Hebbian plasticity rule have been widely used to learn the precise order of sequential reactivations. For example, a rate-based Hebbian rule has been proposed to generate trajectories along a chain of metastable attractors, each corresponding to a reactivation of a single network state (<xref ref-type="bibr" rid="bib20">Fonollosa et al., 2015</xref>). Another proposed mechanism is that the transitions are governed by theta oscillations, which form a temporal backbone of the sequential reactivation of assemblies (<xref ref-type="bibr" rid="bib15">Chadwick et al., 2015</xref>). Despite the successes of these Hebbian rules in learning precise order in sequences, plasticity rules that learn structured transition probabilities and replay them in spontaneous activity were still unknown.</p><p>How does our plasticity mechanism differ from the Hebbian rule? In the Hebbian rule, synaptic strength is potentiated as long as pre- and postsynaptic neurons show correlated activities. Due to the nature of the Hebbian rule, after sufficient potentiation, synapses reach a predefined upper limit, making the strength uniform among strong synapses (<xref ref-type="bibr" rid="bib34">Kempter et al., 1999</xref>; <xref ref-type="bibr" rid="bib51">Song et al., 2000</xref>; <xref ref-type="bibr" rid="bib41">Masquelier et al., 2008</xref>). Such connectivity is useful when the network learns deterministic sequences, but it alone is insufficient to learn transition probabilities. In contrast, our proposed model aims at predicting the evoked activities by internally generated dynamics, so that learning ceases when the prediction error is sufficiently minimized. A similar plasticity rule has been proposed to minimize the discrepancy between stimulus-evoked and internally predicted activity, generating a stable synaptic distribution that allows pattern completion and unsupervised feature detection from noisy sensory input. (<xref ref-type="bibr" rid="bib52">Tavazoie, 2013</xref>). These mechanisms result in learned synaptic distributions that are not uniform as observed in STDP, but rather converge to values proportional to the transition probabilities between assemblies (as shown in <xref ref-type="fig" rid="fig3">Figure 3b</xref>).</p><p>Our proposed plasticity mechanism could be implemented through somatodendritic interactions. Analogous to previous computational works (<xref ref-type="bibr" rid="bib54">Urbanczik and Senn, 2014</xref>; <xref ref-type="bibr" rid="bib2">Asabuki and Fukai, 2020</xref>; <xref ref-type="bibr" rid="bib3">Asabuki et al., 2022</xref>), our model suggests that somatic responses may encode the stimulus-evoked neural activity states, while dendrites encode predictions based on recurrent dynamics that aim to minimize the discrepancy between somatic and dendritic activity. To directly test this hypothesis, future experimental studies could simultaneously record from both somatic and dendritic compartments to investigate how they encode evoked responses and predictive signals during learning (<xref ref-type="bibr" rid="bib21">Francioni et al., 2023</xref>).</p><p>The proposed mechanism of learning stochastic transitions between cell assemblies may offer several advantages over deterministic transitions, as suggested by previous studies. One possibility is that the internal dynamics of stochastic transitions can be used as prior knowledge about the structure of the world. In particular, the learned information about the transition statistics can be used to make probabilistic predictions about upcoming sensory events. It may also provide a flexible representation of the environment. In a deterministic case, assemblies are replayed in a fixed temporal order, which may make the network susceptible to noise or unexpected changes in the environment. In contrast, stochastic transitions may allow the network to generate rich repertoires of representations that could provide flexible computation against an uncertain environment.</p><p>In reinforcement learning (RL), balancing the tradeoff between exploration and exploitation to maximize a long-term reward signal is one of the most challenging problems. While both exploration and exploitation phases are crucial in RL, exploration is often much more difficult. This difficulty arises from the fact that exploration is especially important when the agent does not have an optimal policy. One way in which the agent might bypass or speed up this exploration phase is through prior knowledge of the environment’s transition statistics. Furthermore, learning transition statistics as an internal model may be beneficial when an agent solves a task in an environment where the reward distribution is sparse. Having an internal model of the transition statistics may allow an agent to predict the expected value of the future reward for taking a particular action in a given state. However, the relationship between the reward-based plasticity rule and our proposed rule still needs further study.</p><p>Several computational models have demonstrated that Hebbian-like plasticity rule can learn appropriate Markovian statistics (<xref ref-type="bibr" rid="bib31">Kappel et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Barber, 2002</xref>; <xref ref-type="bibr" rid="bib9">Barber and Agakov, 2002</xref>). However, our model differs conceptually from these previous models in some respects. While Kappel et al. demonstrated that STDP in winner-take-all circuits can approximate online learning of hidden Markov models (HMMs), a key distinction from our model is that their neural representations acquire deterministic sequential activations, rather than exhibiting stochastic transitions governing Markovian dynamics. Specifically, in their model, the neural representation of state B would be different in the sequences ABC and CBA, resulting in distinct deterministic representations like ABC and C'B'A', where ‘A’ and ‘A’ are represented by different neural states (e.g. activations of different cell assemblies). In contrast, our network learns to generate stochastically transitioning cell assemblies that replay Markovian trajectories of spontaneous activity obeying the learned transition probabilities between neural representations of states. For example, starting from reactivation from assembly ‘A,’ there may be an 80% probability to transition to assembly ‘B’ and 20% to ‘C.’ Although Kappel et al.’s model successfully solves HMMs, their neural representations do not themselves stochastically transition between states according to the learned model. Similar to Kappel et al.’s model, while the models proposed in <xref ref-type="bibr" rid="bib8">Barber, 2002</xref> and <xref ref-type="bibr" rid="bib9">Barber and Agakov, 2002</xref> learn the Markovian statistics, these models learned a static spatiotemporal input patterns only and how assemblies of neurons show stochastic transition in spontaneous activity has been still unclear. In contrast with these models, our model captures the probabilistic neural state trajectories, allowing spontaneous replay of experienced sequences with stochastic dynamics matching the learned environmental statistics.</p><p>Our model results were also compared to experimental results of sequence predictability in a songbird. Recent experiments have shown that the predictive uncertainty of the upcoming stimulus modulates the degree of similarity between stimulus-evoked and post-stimulus autonomous activity in the HVC of the Bengal finch (<xref ref-type="bibr" rid="bib13">Bouchard and Brainard, 2016</xref>). However, the underlying mechanism is still unknown. Here, we have shown that a stochastic state transition in spontaneous activity can explain such a dependence of activity similarity on stimulus uncertainty. Our model predicts that the PSA reflects a trial average of stochastic transitions of evoked activity from a given stimulus. Trial-averaged neural activity washes out the variability of all possible realizations of the stochastic transition. Thus, PSA of an uncertain stimulus results in a combination of multiple transitions, leading to activity less similar than that evoked by a single stimulus. Several studies have shown that Hidden Markov Models or other statistical methods could account for the transition statistics in bird song (<xref ref-type="bibr" rid="bib35">Kogan and Margoliash, 1998</xref>; <xref ref-type="bibr" rid="bib32">Katahira et al., 2011</xref>). However, our study suggests that trial averaging operations can influence the degree of similarity between stimulus-evoked and post-stimulus activity.</p><p>Although we have shown that the proposed model can learn Markovian transitions, several studies suggest that animals often exhibit behaviors with non-Markovian or hierarchical statistics (<xref ref-type="bibr" rid="bib49">Seeds et al., 2014</xref>; <xref ref-type="bibr" rid="bib12">Berman et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Jovanic et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Jin and Costa, 2015</xref>; <xref ref-type="bibr" rid="bib25">Geddes et al., 2018</xref>; <xref ref-type="bibr" rid="bib40">Markowitz et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Kato et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Kaplan et al., 2020</xref>). In principle, our learning rule cannot be applied to learning non-Markovian transitions, since it only learns local transitions between states (<xref ref-type="bibr" rid="bib14">Brea et al., 2013</xref>). Therefore, to learn higher-order stochastic transitions, recurrent neural networks like ours may need to integrate higher-order inputs with longer time scales. Another limitation of our model is that it cannot learn transition statistics if the states are separated in time. Both of these problems could be solved by considering working memory (WM) (<xref ref-type="bibr" rid="bib6">Baddeley, 1992</xref>; <xref ref-type="bibr" rid="bib43">Miller and Cohen, 2001</xref>) in an activity-dependent (<xref ref-type="bibr" rid="bib23">Funahashi et al., 1989</xref>; <xref ref-type="bibr" rid="bib26">Goldman-Rakic, 1995</xref>; <xref ref-type="bibr" rid="bib24">Fuster and Alexander, 1971</xref>; <xref ref-type="bibr" rid="bib1">Amit and Brunel, 1997</xref>) or activity-silent manner (<xref ref-type="bibr" rid="bib44">Mongillo et al., 2008</xref>; <xref ref-type="bibr" rid="bib7">Barak and Tsodyks, 2014</xref>; <xref ref-type="bibr" rid="bib60">Zucker and Regehr, 2002</xref>; <xref ref-type="bibr" rid="bib19">Erickson et al., 2010</xref>). Clarifying the relationship between the proposed prediction-based plasticity rule and plasticity rules that support memory traces, such as short-term plasticity, will warrant future computational studies.</p><p>Our work sheds light on the learning mechanism of the brain’s internal model, which is a crucial step towards a better understanding of the role of spontaneous activity as an internal generative model of stochastic processes in complex environments.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Neural network model</title><p>Our recurrent neural networks consist of <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> excitatory and <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> inhibitory neurons. During learning, the membrane potentials of neurons at time <inline-formula><mml:math id="inf5"><mml:mi>t</mml:mi></mml:math></inline-formula> with external current <inline-formula><mml:math id="inf6"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> were calculated as follows:<disp-formula id="equ1"> <label> (1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf7"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf8"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> are the membrane potential of <inline-formula><mml:math id="inf9"><mml:mi>i</mml:mi></mml:math></inline-formula>-th excitatory and inhibitory neuron, respectively (see<xref ref-type="table" rid="table1">Table 1</xref> for the list of variables and functions). The strength of external input <inline-formula><mml:math id="inf10"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> takes the value 1 if stimulus pattern targets neuron <inline-formula><mml:math id="inf11"><mml:mi>i</mml:mi></mml:math></inline-formula> was presented and 0 otherwise. This structured external input was replaced to constant inputs <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> of value 0.3 during spontaneous activity. We will describe the details of stimulus patterns later. <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo>;</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is a recurrent connection weight from <inline-formula><mml:math id="inf14"><mml:mi>j</mml:mi></mml:math></inline-formula>-th neuron in population <inline-formula><mml:math id="inf15"><mml:mi>b</mml:mi></mml:math></inline-formula> to <inline-formula><mml:math id="inf16"><mml:mi>i</mml:mi></mml:math></inline-formula>-th neuron in population <inline-formula><mml:math id="inf17"><mml:mi>a</mml:mi></mml:math></inline-formula>. All neurons were connected with a coupling probability of p=0.5. Initial value of synaptic weights <inline-formula><mml:math id="inf18"><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> were uniformly set to 0.1/<inline-formula><mml:math id="inf19"><mml:msqrt><mml:mi>p</mml:mi><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:math></inline-formula> if <inline-formula><mml:math id="inf20"><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi></mml:math></inline-formula> and 1/<inline-formula><mml:math id="inf21"><mml:msqrt><mml:mi>p</mml:mi><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:math></inline-formula> if <inline-formula><mml:math id="inf22"><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi></mml:math></inline-formula>. <inline-formula><mml:math id="inf23"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is a postsynaptic potential evoked by <inline-formula><mml:math id="inf24"><mml:mi>i</mml:mi></mml:math></inline-formula>-th neuron in population <inline-formula><mml:math id="inf25"><mml:mi>a</mml:mi></mml:math></inline-formula>, which will be described later.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Definition of variables and functions.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"><inline-formula><mml:math id="inf26"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf27"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></th><th align="left" valign="bottom">Membrane potentials</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf28"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf29"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td><td align="left" valign="bottom">Postsynaptic potentials</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf30"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td><td align="left" valign="bottom">Poisson spike train generated by network neurons</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Recurrent connections</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf35"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td><td align="left" valign="bottom">External current elicited by stimulus presentation</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Synaptic currents generated by network neurons</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf37"><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf38"><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td><td align="left" valign="bottom">Instantaneous firing rates</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf39"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf40"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td><td align="left" valign="bottom">Recurrent predictions</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Memory trace</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf42"><mml:mi>φ</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">Dynamic sigmoidal function</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf43"><mml:mover accent="true"><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula></td><td align="left" valign="bottom">Static sigmoidal function</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Filtered prediction errors</td></tr></tbody></table></table-wrap><p>Spiking of each neuron model in population <inline-formula><mml:math id="inf46"><mml:mi>E</mml:mi></mml:math></inline-formula> was modeled as an inhomogeneous Poisson process with instantaneous firing rate <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> with a dynamic sigmoidal response function φ with parameters of slope β and threshold θ as:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the maximum instantaneous firing rate of 50 Hz and <inline-formula><mml:math id="inf49"><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula>. The slope β and threshold θ of sigmoidal function of population <inline-formula><mml:math id="inf50"><mml:mi>E</mml:mi></mml:math></inline-formula> was regulated by the memory trace <inline-formula><mml:math id="inf51"><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> as:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where the values of constant parameters are <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The memory trace tracks the maximum value of the short history of membrane potential <inline-formula><mml:math id="inf54"><mml:msubsup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mover><mml:mi>h</mml:mi><mml:mrow><mml:mo>˙</mml:mo></mml:mrow></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf55"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula> s is a time scale of memory trace. In the previous study (<xref ref-type="bibr" rid="bib5">Asabuki and Fukai, 2024</xref>), such dynamic response function was introduced to prevent trivial solutions during the learning of recurrent and feedforward connections. In the current model, we assumed that each stimulus presentation drives a specific subset of network neurons with a fixed input strength, which avoids convergence to trivial solutions. Nevertheless, the dynamic sigmoid function could facilitate stable replay by regulating neuron activity to prevent saturation.</p><p>Inhibitory neurons’ firing rate were assumed to be calculated with static sigmoidal function as:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>φ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>≡</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>u</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Where the maximum instantaneous firing rate <inline-formula><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> was assumed to be same with that of excitatory neurons (i.e. 50 Hz). The parameters <inline-formula><mml:math id="inf57"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are the constant values already appeared in <xref ref-type="disp-formula" rid="equ4 equ5">Equations 4 and 5</xref>.</p><p>Neuron <inline-formula><mml:math id="inf59"><mml:mi>i</mml:mi></mml:math></inline-formula> in population <inline-formula><mml:math id="inf60"><mml:mi>a</mml:mi></mml:math></inline-formula> generates a Poisson spike train at the instantaneous firing rate of <inline-formula><mml:math id="inf61"><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>. Let us describe the generated Poisson spike trains as:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf62"><mml:mi>δ</mml:mi></mml:math></inline-formula> is the Dirac’s delta function and <inline-formula><mml:math id="inf63"><mml:msubsup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is the set of time of the spikes of the neuron. The postsynaptic potential evoked by the neuron (i.e. <inline-formula><mml:math id="inf64"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>) was then calculated as:<disp-formula id="equ9"><label> (9)</label><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mover><mml:mi>I</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi>a</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi></mml:msubsup></mml:mrow></mml:math></disp-formula><disp-formula id="equ10"> <label> (10)</label><mml:math id="m10"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mi>a</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi></mml:msubsup><mml:mi>τ</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msubsup><mml:mi>I</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf65"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math></inline-formula> ms, <inline-formula><mml:math id="inf66"><mml:mi mathvariant="normal">τ</mml:mi></mml:math></inline-formula> = 15 ms, and <inline-formula><mml:math id="inf67"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>25</mml:mn></mml:math></inline-formula>.</p></sec><sec id="s4-2"><title>The learning rules</title><p>All excitatory synaptic connections onto excitatory neurons were modified to minimize the following cost function:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="fraktur">L</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf68"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> is a recurrent prediction of a firing rate, defined as:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>E</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where the function  φ (.) is the static sigmoid function defined in <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>. The above cost function evaluates to what extent the recurrent potential predicts the activity of postsynaptic neurons. Taking the gradient of the cost function in <xref ref-type="disp-formula" rid="equ11">Equation 11</xref>, we derived the plasticity rule for the excitatory plasticity as:<disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>∝</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ14"><mml:math id="m14"><mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ15"> <label>(13)</label><mml:math id="m15"><mml:mrow><mml:mo>∝</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>While the term the term <inline-formula><mml:math id="inf69"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></inline-formula>, which arose from the derivative of <inline-formula><mml:math id="inf70"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula>, avoids saturation of neural activity, we show numerically this can be ruled out in the learning rule. Hence, the resultant plasticity rule for the excitatory synapses can be written as:<disp-formula id="equ16"><label>(14)</label><mml:math id="m16"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf71"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> is a learning rate and was set to <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, unless otherwise specified.</p><p>We note that for Poisson spiking neurons, the derived learning rule is equivalent to the one that minimizes the Kullback-Leibler divergence between the distributions of output firing and the dendritic prediction, in our case, the recurrent prediction (<xref ref-type="bibr" rid="bib2">Asabuki and Fukai, 2020</xref>). Thus, the rule suggests that the recurrent prediction learns the statistical model of the evoked activity, which in turn allows the network to reproduce the learned transition statistics.</p><p>Similarly, we defined the cost function for the inhibitory plasticity as:<disp-formula id="equ17"><label>(15)</label><mml:math id="m17"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="fraktur">L</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> was the total inhibitory input onto postsynaptic neuron:<disp-formula id="equ18"><label>(16)</label><mml:math id="m18"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>I</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Again, by taking the gradient with respect to <inline-formula><mml:math id="inf74"><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> derive the following inhibitory plasticity rule to maintain excitatory-inhibitory balance in all excitatory neurons:<disp-formula id="equ19"><mml:math id="m19"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>∝</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ20"><mml:math id="m20"><mml:mrow><mml:mo>∝</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ21"> <label> (17)</label><mml:math id="m21"><mml:mrow><mml:mo>∝</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In all simulations in this paper, we dropped the term <inline-formula><mml:math id="inf75"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math></inline-formula> and modified the inhibitory synapses according to the following rule:<disp-formula id="equ22"><label>(18)</label><mml:math id="m22"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-3"><title>Simulation details</title><p>The parameters used in the simulations are summarized in <xref ref-type="table" rid="table2">Table 2</xref>. All simulations were performed in customized Python3 code written by TA with numpy 1.17.3 and scipy 0.18. Differential equations were numerically integrated using an Euler method with integration time steps of 1 ms.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Parameter settings.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"><inline-formula><mml:math id="inf76"><mml:mi>p</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom">Connection probability</th><th align="left" valign="bottom">0.5</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf77"><mml:mi>g</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">Gain parameter in sigmoid function</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Network size</td><td align="left" valign="bottom">500, 500 (1500,1500<break/>in <xref ref-type="fig" rid="fig5">Figure 5e-j</xref>; 800, 200 in <xref ref-type="fig" rid="fig2s7">Figure 2—figure supplement 7</xref>)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Learning rate</td><td align="left" valign="bottom">10<sup>-4</sup></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Synaptic time constant</td><td align="left" valign="bottom">5 ms</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf82"><mml:mi mathvariant="normal">τ</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">Membrane time constant</td><td align="left" valign="bottom">15 ms</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf84"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Parameters for sigmoid</td><td align="left" valign="bottom">5, 1</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Time constant of memory trace</td><td align="left" valign="bottom">10 s</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf86"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Maximal firing rate</td><td align="left" valign="bottom">50 Hz</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Scaling factor of synaptic current</td><td align="left" valign="bottom">25</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf88"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Time constant for low-pass filtering the error</td><td align="left" valign="bottom">30 s</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf89"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula></td><td align="left" valign="bottom">Constant external current during spontaneous activity</td><td align="left" valign="bottom">0.3</td></tr></tbody></table></table-wrap></sec><sec id="s4-4"><title>Stimulation protocols</title><p>In all simulations, each stimulus patterns had a duration of 200 ms and were presented without inter-pattern interval. We assumed each neuron in a network was stimulated by one of stimulus patterns and targeted assemblies were not overlapped. Presentation of each pattern triggers excitatory current to its targeted neurons of strength 1 and zero otherwise. During spontaneous activity, stimulus patterns were replaced with constant background input <inline-formula><mml:math id="inf90"><mml:msubsup><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> for all excitatory neurons. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we assumed all excitatory neurons receive both structured and constant background inputs over whole period.</p></sec><sec id="s4-5"><title>Calculation of transition probabilities in spontaneous activity</title><p>In <xref ref-type="fig" rid="fig2">Figures 2f</xref>, <xref ref-type="fig" rid="fig4">4c and g</xref>, we first calculated the population average of the instantaneous firing rates of all neurons in each assembly, during spontaneous activity. We will term such activities as assembly activities. We then defined the assembly reactivations by events that the assembly activities exceeded the threshold of which the value 50% of maximum value of each assembly activity. Transition probabilities between assemblies across all possible pairs were then calculated by counting the occurrences of reactivation of the subsequent assembly within 100ms of the end time of reactivation of the preceding assembly. In <xref ref-type="fig" rid="fig2">Figure 2d</xref>, durations of each assembly reactivation event were defined as a period during each assembly activation exceeded threshold.</p></sec><sec id="s4-6"><title>Calculation of weight changes</title><p>In <xref ref-type="fig" rid="fig2">Figure 2b</xref>, the weight changes were calculated every 2 s for excitatory and inhibitory synapses as:<disp-formula id="equ23"><label>(19)</label><mml:math id="m23"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mfrac><mml:msqrt><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:msqrt><mml:msubsup><mml:mi>N</mml:mi><mml:mi>E</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ24"><label>(20)</label><mml:math id="m24"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>:=</mml:mo><mml:mfrac><mml:msqrt><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:msqrt><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>I</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mo>;</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is a synapse at time <inline-formula><mml:math id="inf92"><mml:mi>t</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf93"><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:math></inline-formula> is a simulation time step of 1ms.</p></sec><sec id="s4-7"><title>Calculation of error dynamics in task switching</title><p>In <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2c and 2d</xref>, two types of prediction errors for excitatory and inhibitory plasticity were calculated as follows. First, we obtained the low-pass filtered errors <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi class="mathcal" mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mi class="mathcal" mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> calculated by instantaneous error values in the plasticity rules (i.e. <xref ref-type="disp-formula" rid="equ16 equ22">Equations 14 and 18</xref>) as:<disp-formula id="equ25"><label>(21)</label><mml:math id="m25"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>avg</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi class="mathcal" mathvariant="script">E</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi class="mathcal" mathvariant="script">E</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mtext>exc</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ26"><label>(22)</label><mml:math id="m26"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>avg</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mover><mml:mrow><mml:mi class="mathcal" mathvariant="script">E</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi class="mathcal" mathvariant="script">E</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mtext>inh</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>E</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:math></inline-formula> s is a time constant for low-pass filter and <inline-formula><mml:math id="inf97"><mml:mi>i</mml:mi></mml:math></inline-formula> is a neuron index. We then calculated the averaged errors <inline-formula><mml:math id="inf98"><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf99"><mml:msup><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> as:<disp-formula id="equ27"><label>(23)</label><mml:math id="m27"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ28"><label>(24)</label><mml:math id="m28"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi>ε</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf100"><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mo>∙</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is an absolute value.</p></sec><sec id="s4-8"><title>Analysis of the low-dimensional representation in network</title><p>In <xref ref-type="fig" rid="fig4">Figure 4h</xref>, we first obtained matrix of network responses <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mn>15</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>15</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is a trial-averaged response of a whole network to one of 15 stimulus patterns shown in <xref ref-type="fig" rid="fig4">Figure 4d</xref>. Trial averaging was performed over multiple presentations of each stimulus. We then applied the PCA to matrix <inline-formula><mml:math id="inf103"><mml:mi>U</mml:mi></mml:math></inline-formula> and visualized the low-dimensional representation of multiple stimulus in the learned network.</p></sec><sec id="s4-9"><title>Correlation measure for comparison with a songbird</title><p>In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we calculated stimulus-triggered averages of autonomous network activity to obtain poststimulus activity (PSA) of a network model. In <xref ref-type="fig" rid="fig5">Figure 5b and c</xref>, the correlation between PSA and evoked activity triggered by one stimulus pattern was calculated neuron-wise and then averaged over all neurons.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Funding acquisition, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-95243-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. Code is provided on the GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/TAsabuki/stochastic_transition">https://github.com/TAsabuki/stochastic_transition</ext-link>; copy archived at <xref ref-type="bibr" rid="bib4">Asabuki, 2024</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by BBSRC (BB/N013956/1), Wellcome Trust (200790/Z/16/Z), the Simons Foundation (564408), and EPSRC (EP/R035806/1). The authors also thank Ian Cone for his comments on the manuscript and technical assistance.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amit</surname><given-names>DJ</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title><source>Cerebral Cortex</source><volume>7</volume><fpage>237</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1093/cercor/7.3.237</pub-id><pub-id pub-id-type="pmid">9143444</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asabuki</surname><given-names>T</given-names></name><name><surname>Fukai</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Somatodendritic consistency check for temporal feature segmentation</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>1554</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15367-w</pub-id><pub-id pub-id-type="pmid">32214100</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asabuki</surname><given-names>T</given-names></name><name><surname>Kokate</surname><given-names>P</given-names></name><name><surname>Fukai</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neural circuit mechanisms of hierarchical sequence learning tested on large-scale recording data</article-title><source>PLOS Computational Biology</source><volume>18</volume><elocation-id>e1010214</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010214</pub-id><pub-id pub-id-type="pmid">35727828</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Asabuki</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Stochastic transition</data-title><version designator="swh:1:rev:cfc52ba9074fcb684998bc2c593315b1a6b6b83f">swh:1:rev:cfc52ba9074fcb684998bc2c593315b1a6b6b83f</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:8e8c60033cf1c42d437d5957a92711fda936ac55;origin=https://github.com/TAsabuki/stochastic_transition;visit=swh:1:snp:03afb1f293b69ed8569fb80c45c0a147a2d4a2c4;anchor=swh:1:rev:cfc52ba9074fcb684998bc2c593315b1a6b6b83f">https://archive.softwareheritage.org/swh:1:dir:8e8c60033cf1c42d437d5957a92711fda936ac55;origin=https://github.com/TAsabuki/stochastic_transition;visit=swh:1:snp:03afb1f293b69ed8569fb80c45c0a147a2d4a2c4;anchor=swh:1:rev:cfc52ba9074fcb684998bc2c593315b1a6b6b83f</ext-link></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asabuki</surname><given-names>T</given-names></name><name><surname>Fukai</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Predictive Learning rules generate a cortical-like replay of probabilistic sensory experiences</article-title><source>eLife</source><volume>13</volume><elocation-id>RP92712</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.92712</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Working memory</article-title><source>Science</source><volume>255</volume><fpage>556</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1126/science.1736359</pub-id><pub-id pub-id-type="pmid">1736359</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Working models of working memory</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>20</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.10.008</pub-id><pub-id pub-id-type="pmid">24709596</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barber</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>Learning in Spiking Neural Assemblies</source><publisher-name>Advances in Neural Information Processing Systems</publisher-name></element-citation></ref><ref id="bib9"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barber</surname><given-names>D</given-names></name><name><surname>Agakov</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>Correlated Sequence Learning in a Network of Spiking Neurons Using Maximum Likelihood</source><publisher-name>Institute for Adaptive and Neural Computation</publisher-name></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>C</given-names></name><name><surname>Bodznick</surname><given-names>D</given-names></name><name><surname>Montgomery</surname><given-names>J</given-names></name><name><surname>Bastian</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The generation and subtraction of sensory expectations within cerebellum-like structures</article-title><source>Brain, Behavior and Evolution</source><volume>50</volume><fpage>17</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1159/000113352</pub-id><pub-id pub-id-type="pmid">9217991</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Orbán</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name><name><surname>Fiser</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment</article-title><source>Science</source><volume>331</volume><fpage>83</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1126/science.1195870</pub-id><pub-id pub-id-type="pmid">21212356</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname><given-names>GJ</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>Shaevitz</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Predictability and hierarchy in <italic>Drosophila</italic> behavior</article-title><source>PNAS</source><volume>113</volume><fpage>11943</fpage><lpage>11948</lpage><pub-id pub-id-type="doi">10.1073/pnas.1607601113</pub-id><pub-id pub-id-type="pmid">27702892</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouchard</surname><given-names>KE</given-names></name><name><surname>Brainard</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Auditory-induced neural dynamics in sensory-motor circuitry predict learned temporal and sequential statistics of birdsong</article-title><source>PNAS</source><volume>113</volume><fpage>9641</fpage><lpage>9646</lpage><pub-id pub-id-type="doi">10.1073/pnas.1606725113</pub-id><pub-id pub-id-type="pmid">27506786</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brea</surname><given-names>J</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Pfister</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Matching recall and storage in sequence learning with spiking neural networks</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>9565</fpage><lpage>9575</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4098-12.2013</pub-id><pub-id pub-id-type="pmid">23739954</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chadwick</surname><given-names>A</given-names></name><name><surname>van Rossum</surname><given-names>MCW</given-names></name><name><surname>Nolan</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Independent theta phase coding accounts for CA1 population sequences and enables flexible remapping</article-title><source>eLife</source><volume>4</volume><elocation-id>e03542</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.03542</pub-id><pub-id pub-id-type="pmid">25643396</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’amour</surname><given-names>JA</given-names></name><name><surname>Froemke</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Inhibitory and excitatory spike-timing-dependent plasticity in the auditory cortex</article-title><source>Neuron</source><volume>86</volume><fpage>514</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.014</pub-id><pub-id pub-id-type="pmid">25843405</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>TJ</given-names></name><name><surname>Kloosterman</surname><given-names>F</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hippocampal replay of extended experience</article-title><source>Neuron</source><volume>63</volume><fpage>497</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id><pub-id pub-id-type="pmid">19709631</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diba</surname><given-names>K</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1241</fpage><lpage>1242</lpage><pub-id pub-id-type="doi">10.1038/nn1961</pub-id><pub-id pub-id-type="pmid">17828259</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erickson</surname><given-names>MA</given-names></name><name><surname>Maramara</surname><given-names>LA</given-names></name><name><surname>Lisman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A single brief burst induces GluR1-dependent associative short-term potentiation: a potential mechanism for short-term memory</article-title><source>Journal of Cognitive Neuroscience</source><volume>22</volume><fpage>2530</fpage><lpage>2540</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21375</pub-id><pub-id pub-id-type="pmid">19925206</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonollosa</surname><given-names>J</given-names></name><name><surname>Neftci</surname><given-names>E</given-names></name><name><surname>Rabinovich</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning of chunking sequences in cognition and behavior</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004592</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004592</pub-id><pub-id pub-id-type="pmid">26584306</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Francioni</surname><given-names>V</given-names></name><name><surname>Tang</surname><given-names>VD</given-names></name><name><surname>Toloza</surname><given-names>EHS</given-names></name><name><surname>Brown</surname><given-names>NJ</given-names></name><name><surname>Harnett</surname><given-names>MT</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Vectorized instructive signals in cortical dendrites during a brain-computer interface task</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.11.03.565534</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Froemke</surname><given-names>RC</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A synaptic memory trace for cortical receptive field plasticity</article-title><source>Nature</source><volume>450</volume><fpage>425</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1038/nature06289</pub-id><pub-id pub-id-type="pmid">18004384</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Bruce</surname><given-names>CJ</given-names></name><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Mnemonic coding of visual space in the monkey’s dorsolateral prefrontal cortex</article-title><source>Journal of Neurophysiology</source><volume>61</volume><fpage>331</fpage><lpage>349</lpage><pub-id pub-id-type="doi">10.1152/jn.1989.61.2.331</pub-id><pub-id pub-id-type="pmid">2918358</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name><name><surname>Alexander</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Neuron activity related to short-term memory</article-title><source>Science</source><volume>173</volume><fpage>652</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1126/science.173.3997.652</pub-id><pub-id pub-id-type="pmid">4998337</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geddes</surname><given-names>CE</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Jin</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Optogenetic editing reveals the hierarchical organization of learned action sequences</article-title><source>Cell</source><volume>174</volume><fpage>32</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.012</pub-id><pub-id pub-id-type="pmid">29958111</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Cellular basis of working memory</article-title><source>Neuron</source><volume>14</volume><fpage>477</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1016/0896-6273(95)90304-6</pub-id><pub-id pub-id-type="pmid">7695894</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>AS</given-names></name><name><surname>van der Meer</surname><given-names>MAA</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Hippocampal replay is not a simple function of experience</article-title><source>Neuron</source><volume>65</volume><fpage>695</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.034</pub-id><pub-id pub-id-type="pmid">20223204</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>X</given-names></name><name><surname>Costa</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Shaping action sequences in basal ganglia circuits</article-title><source>Current Opinion in Neurobiology</source><volume>33</volume><fpage>188</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2015.06.011</pub-id><pub-id pub-id-type="pmid">26189204</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jovanic</surname><given-names>T</given-names></name><name><surname>Schneider-Mizell</surname><given-names>CM</given-names></name><name><surname>Shao</surname><given-names>M</given-names></name><name><surname>Masson</surname><given-names>JB</given-names></name><name><surname>Denisov</surname><given-names>G</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Mensh</surname><given-names>BD</given-names></name><name><surname>Truman</surname><given-names>JW</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Zlatic</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Competitive disinhibition mediates behavioral choice and sequences in <italic>Drosophila</italic></article-title><source>Cell</source><volume>167</volume><fpage>858</fpage><lpage>870</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2016.09.009</pub-id><pub-id pub-id-type="pmid">27720450</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname><given-names>HS</given-names></name><name><surname>Salazar Thula</surname><given-names>O</given-names></name><name><surname>Khoss</surname><given-names>N</given-names></name><name><surname>Zimmer</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Nested neuronal dynamics orchestrate a behavioral hierarchy across timescales</article-title><source>Neuron</source><volume>105</volume><fpage>562</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.10.037</pub-id><pub-id pub-id-type="pmid">31786012</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappel</surname><given-names>D</given-names></name><name><surname>Nessler</surname><given-names>B</given-names></name><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>STDP installs in Winner-Take-All circuits an online approximation to hidden Markov model learning</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003511</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003511</pub-id><pub-id pub-id-type="pmid">24675787</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katahira</surname><given-names>K</given-names></name><name><surname>Suzuki</surname><given-names>K</given-names></name><name><surname>Okanoya</surname><given-names>K</given-names></name><name><surname>Okada</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Complex sequencing rules of birdsong can be explained by simple hidden Markov processes</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e24516</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0024516</pub-id><pub-id pub-id-type="pmid">21915345</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname><given-names>S</given-names></name><name><surname>Kaplan</surname><given-names>HS</given-names></name><name><surname>Schrödel</surname><given-names>T</given-names></name><name><surname>Skora</surname><given-names>S</given-names></name><name><surname>Lindsay</surname><given-names>TH</given-names></name><name><surname>Yemini</surname><given-names>E</given-names></name><name><surname>Lockery</surname><given-names>S</given-names></name><name><surname>Zimmer</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Global brain dynamics embed the motor command sequence of <italic>Caenorhabditis elegans</italic></article-title><source>Cell</source><volume>163</volume><fpage>656</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.09.034</pub-id><pub-id pub-id-type="pmid">26478179</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kempter</surname><given-names>R</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>van Hemmen</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Hebbian learning and spiking neurons</article-title><source>Physical Review E</source><volume>59</volume><fpage>4498</fpage><lpage>4514</lpage><pub-id pub-id-type="doi">10.1103/PhysRevE.59.4498</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kogan</surname><given-names>JA</given-names></name><name><surname>Margoliash</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Automated recognition of bird song elements from continuous recordings using dynamic time warping and hidden Markov models: a comparative study</article-title><source>The Journal of the Acoustical Society of America</source><volume>103</volume><fpage>2185</fpage><lpage>2196</lpage><pub-id pub-id-type="doi">10.1121/1.421364</pub-id><pub-id pub-id-type="pmid">9566338</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title><source>Neuron</source><volume>36</volume><fpage>1183</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01096-6</pub-id><pub-id pub-id-type="pmid">12495631</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>N</given-names></name><name><surname>Horn</surname><given-names>D</given-names></name><name><surname>Meilijson</surname><given-names>I</given-names></name><name><surname>Ruppin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Distributed synchrony in a cell assembly of spiking neurons</article-title><source>Neural Networks</source><volume>14</volume><fpage>815</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1016/s0893-6080(01)00044-2</pub-id><pub-id pub-id-type="pmid">11665773</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewald</surname><given-names>J</given-names></name><name><surname>Ehrenstein</surname><given-names>WH</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Influence of head-to-trunk position on sound lateralization</article-title><source>Experimental Brain Research</source><volume>121</volume><fpage>230</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.1007/s002210050456</pub-id><pub-id pub-id-type="pmid">9746129</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litwin-Kumar</surname><given-names>A</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5319</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6319</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markowitz</surname><given-names>JE</given-names></name><name><surname>Gillis</surname><given-names>WF</given-names></name><name><surname>Beron</surname><given-names>CC</given-names></name><name><surname>Neufeld</surname><given-names>SQ</given-names></name><name><surname>Robertson</surname><given-names>K</given-names></name><name><surname>Bhagat</surname><given-names>ND</given-names></name><name><surname>Peterson</surname><given-names>RE</given-names></name><name><surname>Peterson</surname><given-names>E</given-names></name><name><surname>Hyun</surname><given-names>M</given-names></name><name><surname>Linderman</surname><given-names>SW</given-names></name><name><surname>Sabatini</surname><given-names>BL</given-names></name><name><surname>Datta</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The striatum organizes 3D behavior via moment-to-moment action selection</article-title><source>Cell</source><volume>174</volume><fpage>44</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.04.019</pub-id><pub-id pub-id-type="pmid">29779950</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masquelier</surname><given-names>T</given-names></name><name><surname>Guyonneau</surname><given-names>R</given-names></name><name><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spike timing dependent plasticity finds the start of repeating patterns in continuous spike trains</article-title><source>PLOS ONE</source><volume>3</volume><elocation-id>e1377</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0001377</pub-id><pub-id pub-id-type="pmid">18167538</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merfeld</surname><given-names>DM</given-names></name><name><surname>Zupan</surname><given-names>L</given-names></name><name><surname>Peterka</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Humans use internal models to estimate gravity and linear acceleration</article-title><source>Nature</source><volume>398</volume><fpage>615</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.1038/19303</pub-id><pub-id pub-id-type="pmid">10217143</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>An integrative theory of prefrontal cortex function</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>167</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id><pub-id pub-id-type="pmid">11283309</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mongillo</surname><given-names>G</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Synaptic theory of working memory</article-title><source>Science</source><volume>319</volume><fpage>1543</fpage><lpage>1546</lpage><pub-id pub-id-type="doi">10.1126/science.1150769</pub-id><pub-id pub-id-type="pmid">18339943</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ocker</surname><given-names>GK</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Training and spontaneous reinforcement of neuronal assemblies by spike timing plasticity</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>937</fpage><lpage>951</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy001</pub-id><pub-id pub-id-type="pmid">29415191</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfister</surname><given-names>JP</given-names></name><name><surname>Toyoizumi</surname><given-names>T</given-names></name><name><surname>Barber</surname><given-names>D</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal spike-timing-dependent plasticity for precise action potential firing in supervised learning</article-title><source>Neural Computation</source><volume>18</volume><fpage>1318</fpage><lpage>1348</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.6.1318</pub-id><pub-id pub-id-type="pmid">16764506</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pudhiyidath</surname><given-names>A</given-names></name><name><surname>Morton</surname><given-names>NW</given-names></name><name><surname>Viveros Duran</surname><given-names>R</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Momennejad</surname><given-names>I</given-names></name><name><surname>Hinojosa-Rowland</surname><given-names>DM</given-names></name><name><surname>Molitor</surname><given-names>RJ</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Representations of temporal community structure in hippocampus and precuneus predict inductive reasoning decisions</article-title><source>Journal of Cognitive Neuroscience</source><volume>34</volume><fpage>1736</fpage><lpage>1760</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01864</pub-id><pub-id pub-id-type="pmid">35579986</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeds</surname><given-names>AM</given-names></name><name><surname>Ravbar</surname><given-names>P</given-names></name><name><surname>Chung</surname><given-names>P</given-names></name><name><surname>Hampel</surname><given-names>S</given-names></name><name><surname>Midgley</surname><given-names>FM</given-names><suffix>Jr</suffix></name><name><surname>Mensh</surname><given-names>BD</given-names></name><name><surname>Simpson</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A suppression hierarchy among competing motor programs drives sequential grooming in <italic>Drosophila</italic></article-title><source>eLife</source><volume>3</volume><elocation-id>e02951</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.02951</pub-id><pub-id pub-id-type="pmid">25139955</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience</article-title><source>Science</source><volume>271</volume><fpage>1870</fpage><lpage>1873</lpage><pub-id pub-id-type="doi">10.1126/science.271.5257.1870</pub-id><pub-id pub-id-type="pmid">8596957</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Competitive Hebbian learning through spike-timing-dependent synaptic plasticity</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>919</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1038/78829</pub-id><pub-id pub-id-type="pmid">10966623</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavazoie</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Synaptic state matching: a dynamical architecture for predictive internal representation and feature detection</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e72865</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0072865</pub-id><pub-id pub-id-type="pmid">23991161</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Triplett</surname><given-names>MA</given-names></name><name><surname>Avitan</surname><given-names>L</given-names></name><name><surname>Goodhill</surname><given-names>GJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergence of spontaneous assembly activity in developing neural networks without afferent input</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006421</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006421</pub-id><pub-id pub-id-type="pmid">30265665</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urbanczik</surname><given-names>R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning by the dendritic prediction of somatic spiking</article-title><source>Neuron</source><volume>81</volume><fpage>521</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.030</pub-id><pub-id pub-id-type="pmid">24507189</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Gerstner</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title><source>Science</source><volume>334</volume><fpage>1569</fpage><lpage>1573</lpage><pub-id pub-id-type="doi">10.1126/science.1211095</pub-id><pub-id pub-id-type="pmid">22075724</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Reactivation of hippocampal ensemble memories during sleep</article-title><source>Science</source><volume>265</volume><fpage>676</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1126/science.8036517</pub-id><pub-id pub-id-type="pmid">8036517</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Ghahramani</surname><given-names>Z</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>An internal model for sensorimotor integration</article-title><source>Science</source><volume>269</volume><fpage>1880</fpage><lpage>1882</lpage><pub-id pub-id-type="doi">10.1126/science.7569931</pub-id><pub-id pub-id-type="pmid">7569931</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hippocampal replay captures the unique topological structure of a novel environment</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>6459</fpage><lpage>6469</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3414-13.2014</pub-id><pub-id pub-id-type="pmid">24806672</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yasui</surname><given-names>S</given-names></name><name><surname>Young</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Perceived visual motion as effective stimulus to pursuit eye movement system</article-title><source>Science</source><volume>190</volume><fpage>906</fpage><lpage>908</lpage><pub-id pub-id-type="doi">10.1126/science.1188373</pub-id><pub-id pub-id-type="pmid">1188373</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zucker</surname><given-names>RS</given-names></name><name><surname>Regehr</surname><given-names>WG</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Short-term synaptic plasticity</article-title><source>Annual Review of Physiology</source><volume>64</volume><fpage>355</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1146/annurev.physiol.64.092501.114547</pub-id><pub-id pub-id-type="pmid">11826273</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95243.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gjorgjieva</surname><given-names>Julijana</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02kkvpp62</institution-id><institution>Technical University of Munich</institution></institution-wrap><addr-line><named-content content-type="city">Munich</named-content></addr-line><country>Germany</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>This is an <bold>important</bold> study that investigates how neural networks can learn to stochastically replay presented sequences of activity according to learned transition probabilities. The authors use error-based excitatory plasticity to minimize the difference between internally predicted activity and stimulus-driven activity, and inhibitory plasticity to maintain E-I balance. The approach is <bold>solid</bold> but the choice of learning rules and parameters is not always always justified, with some unclear aspects to the formal derivation.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95243.3.sa1</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This work proposes a synaptic plasticity rule which explains the generation of learned stochastic dynamics during spontaneous activity. The proposed plasticity rule assumes that excitatory synapses seek to minimize the difference between the internal predicted activity and stimulus-evoked activity, and inhibitory synapses try to maintain the E-I balance by matching the excitatory activity. By implementing this plasticity rule in a spiking recurrent neural network, the authors show that the state-transition statistics of spontaneous excitatory activity agrees with that of the learned stimulus patterns, which is reflected in the learned excitatory synaptic weights. The authors further demonstrate that inhibitory connections contribute to well-defined state-transitions matching the transition patterns evoked by the stimulus. Finally, they show that this mechanism can be expanded to more complex state-transition structures including songbird neural data.</p><p>Strengths:</p><p>This study makes an important contribution to computational neuroscience, by proposing a possible synaptic plasticity mechanism underlying spontaneous generations of learned stochastic state-switching dynamics that are experimentally observed in the visual cortex and hippocampus. This work is also very clearly presented and well-written, and the authors conducted comprehensive simulations testing multiple hypotheses. Overall, I believe this is a well-conducted study providing interesting and novel aspects on the capacity of recurrent spiking neural networks with local synaptic plasticity.</p><p>Weaknesses:</p><p>This study is very well-thought out and theoretically valuable to the neuroscience community, and I think the main weaknesses are in regard to how much biological realism is taken into account. For example, the proposed model assumes that only synapses targeting excitatory neurons are plastic, and uses an equal number of excitatory and inhibitory neurons.</p><p>The model also assumes Markovian state dynamics while biological systems can depend more on history. This limitation, however, is acknowledged in the Discussion.</p><p>Finally, to simulate spontaneous activity, the authors use a constant input of 0.3 throughout the study. Different amplitudes of constant input may correspond to different internal states, so it will be more convincing if the authors test the model with varying amplitudes of constant inputs.</p><p>Comments on revisions:</p><p>The authors have addressed all of the previously raised concerns satisfactorily, by running extra simulations with a biologically plausible composition of excitatory and inhibitory neurons, plasticity assumed for all synapses, and varied amounts of constant inputs representing internal states or background activities. While in some of these cases the stochastic dynamics during spontaneous activity change or do not replicate those of the learned stimulus patterns as well as before, these extended studies provide thorough evaluations of the strengths and limitations of the proposed plasticity rule as the underlying mechanism of stochastic dynamics during spontaneous activity. Overall, the revision has strengthened the paper significantly.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95243.3.sa2</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Asabuki and Clopath study stochastic sequence learning in recurrent networks of Poisson spiking neurons that obey Dale's law. Inspired by previous modeling studies, they introduce two distinct learning rules, to adapt excitatory-to-excitatory and inhibitory-to-excitatory synaptic connections. Through a series of computer experiments, the authors demonstrate that their networks can learn to generate stochastic sequential patterns, where states correspond to non-overlapping sets of neurons (cell assemblies) and the state-transition conditional probabilities are first-order Markov, i.e., the transition to a given next state only depends on the current state. Finally, the authors use their model to reproduce certain experimental songbird data involving highly-predictable and highly-uncertain transitions between song syllables. While the findings are only moderately surprising, this is a well-written and welcome detailed study that may be of interest to experts of plasticity and learning in recurrent neural networks that respect Dale's law.</p><p>Strengths:</p><p>This is an easy-to-follow, well-written paper, whose results are likely easy to reproduce. The experiments are clear and well-explained. In particular, the study of the interplay between excitation and inhibition (and their different plasticity rules) is a highlight of the study. The study of songbird experimental data is another good feature of this paper; finches are classical model animals for understanding sequence learning in the brain. I also liked the study of rapid task-switching, it's a good-to-know type of result that is not very common in sequence learning papers.</p><p>Weaknesses:</p><p>One weakness I see in this paper is the derivation of the learning rules, which is semi-heuristic. The paper studies Poisson spiking neurons, for which learning rules can be derived from a statistical objective, typically maximum likelihood, as previously done in the cited literature. The authors provide a brief section connecting the learning rules to gradient descent on objective functions, but the link is only heuristic or at least not entirely presented. The reason is that the neural network state is not fully determined by (or &quot;clamped to&quot;) the target during learning (for instance, inhibitory neurons do not even have a target assigned). So, the (total) gradient should take into account the recurrent contributions from other neurons, and equation 13 does not appear to be complete/correct to me. Moreover, the target firing rate is a mixture of external currents with currents arising from other neurons in the recurrent network. The authors ideally should start from an actual distribution matching objective (e.g., KL divergence, and not such a squared error), so that their main claims immediately follow from the mathematical derivations. Along the same line, it would be excellent to get some additional insights on the interaction of the two distinct plasticity rules, one of the highlights of the study. This could be naturally achieved by relating their distinct rules to a common principled objective.</p><p>The other major weakness (albeit one that is clearly discussed by the authors) is that the study assumes that every excitatory neuron is directly given its target state when learning. In machine learning language, there are no 'hidden' excitatory neurons. While this assumption greatly simplifies the derivation of efficient and biologically-plausible learning rules that can be mapped to synaptic plasticity, it also limits considerably the distributions that can be learned by the network, more precisely to those that satisfy the Markov property.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95243.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Asabuki</surname><given-names>Toshitake</given-names></name><role specific-use="author">Author</role><aff><institution>RIKEN</institution><addr-line><named-content content-type="city">Saitama</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Clopath</surname><given-names>Claudia</given-names></name><role specific-use="author">Author</role><aff><institution>Imperial College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>In the presented manuscript, the authors investigate how neural networks can learn to replay presented sequences of activity. Their focus lies on the stochastic replay according to learned transition probabilities. They show that based on error-based excitatory and balance-based inhibitory plasticity networks can selforganize towards this goal. Finally, they demonstrate that these learning rules can recover experimental observations from song-bird song learning experiments.</p><p>Overall, the study appears well-executed and coherent, and the presentation is very clear and helpful. However, it remains somewhat vague regarding the novelty. The authors could elaborate on the experimental and theoretical impact of the study, and also discuss how their results relate to those of Kappel et al, and others (e.g., Kappel et al (<ext-link ext-link-type="uri" xlink:href="http://doi.org/10.1371/journal.pcbi.1003511)">doi.org/10.1371/journal.pcbi.1003511))</ext-link>.</p></disp-quote><p>We agree with the reviewer that our previous manuscript lacked comparison with previously published similar works. While Kappel et al. demonstrated that STDP in winner-take-all circuits can approximate online learning of hidden Markov models (HMMs), a key distinction from our model is that their neural representations acquire deterministic sequential activations, rather than exhibiting stochastic transitions governing Markovian dynamics. Specifically, in their model, the neural representation of state B would be different in the sequences ABC and CBA, resulting in distinct deterministic representations like ABC and C'B'A', where ‘A’ and ‘A'’ are represented by different neural states (e.g., activations of different cell assemblies). In contrast, our network learns to generate stochastically transitioning cell assemblies which replay Markovian trajectories of spontaneous activity obeying the learned transition probabilities between neural representations of states. For example, starting from reactivation from assembly ‘A’, there may be an 80% probability to transition to assembly ‘B’ and 20% to ‘C’. Although Kappel et al.'s model successfully solves HMMs, their neural representations do not themselves stochastically transition between states according to the learned model. Similar to the Kappel et al.'s model, while the models proposed in Barber (2002) and Barber and Agakov (2002) learn the Markovian statistics, these models learned a static spatiotemporal input patterns only and how assemblies of neurons show stochastic transition in spontaneous activity has been still unclear. In contrast with these models, our model captures the probabilistic neural state trajectories, allowing spontaneous replay of experienced sequences with stochastic dynamics matching the learned environmental statistics.</p><p>We have included new sentences for explain these in ll. 509-533 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Overall, the work could benefit if there was either (A) a formal analysis or derivation of the plasticity rules involved and a formal justification of the usefulness of the resulting (learned) neural dynamics;</p></disp-quote><p>We have included a derivation of our plasticity rules in ll. 630-670 in the revised manuscript. Consistent with our claim that excitatory plasticity updates the excitatory synapse to predict output firing rates, we have shown that the corresponding cost function measures the discrepancy between the recurrent prediction and the output firing rate. Similarly, for inhibitory plasticity, we defined the cost function that evaluates the difference between the excitatory and inhibitory potential within each neuron. We showed that the resulting inhibitory plasticity rule updates the inhibitory synapses to maintain the excitation-inhibition balance.</p><disp-quote content-type="editor-comment"><p>and/or (B) a clear connection of the employed plasticity rules to biological plasticity and clear testable experimental predictions. Thus, overall, this is a good work with some room for improvement.</p></disp-quote><p>Our proposed plasticity mechanism could be implemented through somatodendritic interactions. Analogous to previous computational works (Urbanczik and Senn, 2014; Asabuki and Fukai, 2020; Asabuki et al., 2022), our model suggests that somatic responses may encode the stimulus-evoked neural activity states, while dendrites encode predictions based on recurrent dynamics that aim to minimize the discrepancy between somatic and dendritic activity. To directly test this hypothesis, future experimental studies could simultaneously record from both somatic and dendritic compartments to investigate how they encode evoked responses and predictive signals during learning (Francioni et al., 2025).</p><p>We have included new sentences for explain these in ll. 476-484 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>This work proposes a synaptic plasticity rule that explains the generation of learned stochastic dynamics during spontaneous activity. The proposed plasticity rule assumes that excitatory synapses seek to minimize the difference between the internal predicted activity and stimulus-evoked activity, and inhibitory synapses try to maintain the E-I balance by matching the excitatory activity. By implementing this plasticity rule in a spiking recurrent neural network, the authors show that the state-transition statistics of spontaneous excitatory activity agree with that of the learned stimulus patterns, which are reflected in the learned excitatory synaptic weights. The authors further demonstrate that inhibitory connections contribute to well-defined state transitions matching the transition patterns evoked by the stimulus. Finally, they show that this mechanism can be expanded to more complex state-transition structures including songbird neural data.</p><p>Strengths:</p><p>This study makes an important contribution to computational neuroscience, by proposing a possible synaptic plasticity mechanism underlying spontaneous generations of learned stochastic state-switching dynamics that are experimentally observed in the visual cortex and hippocampus. This work is also very clearly presented and well-written, and the authors conducted comprehensive simulations testing multiple hypotheses. Overall, I believe this is a well-conducted study providing interesting and novel aspects of the capacity of recurrent spiking neural networks with local synaptic plasticity.</p><p>Weaknesses:</p><p>This study is very well-thought-out and theoretically valuable to the neuroscience community, and I think the main weaknesses are in regard to how much biological realism is taken into account. For example, the proposed model assumes that only synapses targeting excitatory neurons are plastic, and uses an equal number of excitatory and inhibitory neurons.</p></disp-quote><p>We agree with the reviewer. The network shown in the previous manuscript consists of an equal number of excitatory and inhibitory neurons, which seems to lack biological plausibility. Therefore, we first tested whether a biologically plausible scenario would affect learning performance by setting the ratio of excitatory to inhibitory neurons to 80% and 20% (Supplementary Figure 7a; left). Even in such a scenario, the network still showed structured spontaneous activity (Supplementary Figure 7a; center), with transition statistics of replayed events matching the true transition probabilities (Supplementary Figure 7a; right). We then asked whether the model with our plasticity rule applied to all synapses would reproduce the corresponding stochastic transitions. We found that the network can learn transition statistics but only under certain conditions. The network showed only weak replay and failed to reproduce the appropriate transition (Supplementary Fig. 7b) if the inhibitory neurons were no longer driven by the synaptic currents reflecting the stimulus, due to a tight balance of excitatory and inhibitory currents on the inhibitory neurons. We then tested whether the network with all synapses plastic can learn transition statistics if the external inputs project to the inhibitory neurons as well. We found that, when each stimulus pattern activates a non-overlapping subset of neurons, the network does not exhibit the correct stochastic transition of assembly reactivation (Supplementary Fig. 7c). Interestingly, when each neuron's activity is triggered by multiple stimuli and has mixed selectivity, the reactivation reproduced the appropriate stochastic transitions (Supplementary Fig. 7d).</p><p>We have included these new results as new Supplementary Figure 7 and they are explained in ll.215-230 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>The model also assumes Markovian state dynamics while biological systems can depend more on history. This limitation, however, is acknowledged in the Discussion.</p></disp-quote><p>We have included the following sentence to provide a possible solution to this limitation: “Therefore, to learn higher-order stochastic transitions, recurrent neural networks like ours may need to integrate higher-order inputs with longer time scales.” in ll.557-559 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Finally, to simulate spontaneous activity, the authors use a constant input of 0.3 throughout the study. Different amplitudes of constant input may correspond to different internal states, so it will be more convincing if the authors test the model with varying amplitudes of constant inputs.</p></disp-quote><p>We thank the reviewer for pointing this out. In the revised manuscript, we have tested constant input with three different strengths. If the strength is moderate, the network showed accurate encoding of transition statistics in the spontaneous activity as we have seen in Fig.2. We have additionally shown that the weaker background input causes spontaneous activity with lower replay rate, which in turn leads to high variance of encoded transition, while stronger inputs make assembly replay transitions more uniform. We have included these new results as new Supplementary Figure 6 and they are explained in ll.211214 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Summary:</p><p>Asabuki and Clopath study stochastic sequence learning in recurrent networks of Poisson spiking neurons that obey Dale's law. Inspired by previous modeling studies, they introduce two distinct learning rules, to adapt excitatory-to-excitatory and inhibitory-to-excitatory synaptic connections. Through a series of computer experiments, the authors demonstrate that their networks can learn to generate stochastic sequential patterns, where states correspond to non-overlapping sets of neurons (cell assemblies) and the state-transition conditional probabilities are first-order Markov, i.e., the transition to a given next state only depends on the current state. Finally, the authors use their model to reproduce certain experimental songbird data involving highly-predictable and highly-uncertain transitions between song syllables.</p><p>Strengths:</p><p>This is an easy-to-follow, well-written paper, whose results are likely easy to reproduce. The experiments are clear and well-explained. The study of songbird experimental data is a good feature of this paper; finches are classical model animals for understanding sequence learning in the brain. I also liked the study of rapid task-switching, it's a good-to-know type of result that is not very common in sequence learning papers.</p><p>Weaknesses:</p><p>While the general subject of this paper is very interesting, I missed a clear main result. The paper focuses on a simple family of sequence learning problems that are well-understood, namely first-order Markov sequences and fully visible (nohidden-neuron) networks, studied extensively in prior work, including with spiking neurons. Thus, because the main results can be roughly summarized as examples of success, it is not entirely clear what the main point of the authors is.</p></disp-quote><p>We apologize the reviewer that our main claim was not clear. While various computational studies have suggested possible plasticity mechanisms for embedding evoked activity patterns or their probability structures into spontaneous activity (Litwin-Kumar et al., Nat. Commun. 2014, Asabuki and Fukai., Biorxiv 2023), how transition statistics of the environment are learned in spontaneous activity is still elusive and poorly understood. Furthermore, while several network models have been proposed to learn Markovian dynamics via synaptic plasticity (Brea, et al. (2013); Pfister et al. (2004); Kappel et al. (2014)), they have been limited in a sense that the learned network does not show stochastic transition in a neural state space. For instance, while Kappel et al. demonstrated that STDP in winner-take-all circuits can approximate online learning of hidden Markov models (HMMs), a key distinction from our model is that their neural representations acquire deterministic sequential activations, rather than exhibiting stochastic transitions governing Markovian dynamics. Specifically, in their model, the neural representation of state B would be different in the sequences ABC and CBA, resulting in distinct deterministic representations like ABC and C'B'A', where ‘A’ and ‘A'’ are represented by different neural states (e.g., activations of different cell assemblies). In contrast, our network learns to generate stochastically transitioning cell assemblies that replay Markovian trajectories of spontaneous activity obeying the learned transition probabilities between neural representations of states. For example, starting from reactivation from assembly ‘A’, there may be an 80% probability to transition to assembly ‘B’ and 20% to ‘C’. Although Kappel et al.'s model successfully solves HMMs, their neural representations do not themselves stochastically transition between states according to the learned model. Similar to the Kappel et al.'s model, while the models proposed in Barber (2002) and Barber and Agakov (2002) learn the Markovian statistics, these models learned a static spatiotemporal input patterns only and how assemblies of neurons show stochastic transition in spontaneous activity has been still unclear. In contrast with these models, our model captures the probabilistic neural state trajectories, allowing spontaneous replay of experienced sequences with stochastic dynamics matching the learned environmental statistics.</p><p>We have explained this point in ll.509-533 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Going into more detail, the first major weakness I see in this paper is the heuristic choice of learning rules. The paper studies Poisson spiking neurons (I return to this point below), for which learning rules can be derived from a statistical objective, typically maximum likelihood. For fully-visible networks, these rules take a simple form, similar in many ways to the E-to-E rule introduced by the authors. This more principled route provides quite a lot of additional understanding on what is to be expected from the learning process.</p></disp-quote><p>We thank the reviewer for pointing this out. To better demonstrate the function of our plasticity rules, we have included the derivation of the rules of synaptic plasticity in ll. 630-670 in the revised manuscript. Consistent with our claim that excitatory plasticity updates the excitatory synapse to predict output firing rates, we have shown that the corresponding cost function measures the discrepancy between the recurrent prediction and the output firing rate. Similarly, for inhibitory plasticity, we defined the cost function that evaluates the difference between the excitatory and inhibitory potential within each neuron. We showed that the resulting inhibitory plasticity rule updates the inhibitory synapses to maintain the excitation-inhibition balance.</p><disp-quote content-type="editor-comment"><p>For instance, should maximum likelihood learning succeed, it is not surprising that the statistics of the training sequence distribution are reproduced. Moreover, given that the networks are fully visible, I think that the maximum likelihood objective is a convex function of the weights, which then gives hope that the learning rule does succeed. And so on. This sort of learning rule has been studied in a series of papers by David Barber and colleagues [refs. 1, 2 below], who applied them to essentially the same problem of reproducing sequence statistics in recurrent fully-visible nets. It seems to me that one key difference is that the authors consider separate E and I populations, and find the need to introduce a balancing I-to-E learning rule.</p></disp-quote><p>The reviewer’s understanding that inhibitory plasticity to maintain EI balance is one of a critical difference from previous works is correct. However, we believe that the most striking point of our study is that we have shown numerically that predictive plasticity rules enable recurrent networks to learn and replay the assembly activations whose transition statistics match those of the evoked activity. Please see our reply above.</p><disp-quote content-type="editor-comment"><p>Because the rules here are heuristic, a number of questions come to mind. Why these rules and not others - especially, as the authors do not discuss in detail how they could be implemented through biophysical mechanisms? When does learning succeed or fail? What is the main point being conveyed, and what is the contribution on top of the work of e.g. Barber, Brea, et al. (2013), or Pfister et al. (2004)?</p></disp-quote><p>Our proposed plasticity mechanism could be implemented through somatodendritic interactions. Analogous to previous computational works (Senn, Asabuki), our model suggests that somatic responses may encode the stimulusevoked neural activity states, while dendrites encode predictions based on recurrent dynamics that aim to minimize the discrepancy between somatic and dendritic activity. To directly test this hypothesis, future experimental studies could simultaneously record from both somatic and dendritic compartments to investigate how they encode evoked responses and predictive signals during learning.</p><p>To address the point of the reviewer, we conducted addionnal simulations to test where the model fails. We found that the model with our plasticity rule applied to all synapses only showed faint replays and failed to replay the appropriate transition (Supplementary Fig. 7b). This result is reasonable because the inhibitory neurons were no longer driven by the synaptic currents reflecting the stimulus, due to a tight balance of excitatory and inhibitory currents on the inhibitory neurons. Our model predicts that mixed selectivity in the inhibitory population is crucial to learn an appropriate transition statistics (Supplementary Fig. 7d). Future work should clarify the role of synaptic plasticity on inhibitory neurons, especially plasticity at I to I synapses. We have explained this result as new supplementary Figure7 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>The use of a Poisson spiking neuron model is the second major weakness of the study. A chief challenge in much of the cited work is to generate stochastic transitions from recurrent networks of deterministic neurons. The task the authors set out to do is much easier with stochastic neurons; it is reasonable that the network succeeds in reproducing Markovian sequences, given an appropriate learning rule. I believe that the main point comes from mapping abstract Markov states to assemblies of neurons. If I am right, I missed more analyses on this point, for instance on the impact that varying cell assembly size would have on the findings reported by the authors.</p></disp-quote><p>The reviewer’s understanding is correct. Our main point comes from mapping Markov statistics to replays of cell assemblies. In the revised manuscript, we performed additional simulations to ask whether varying the size of the cell assemblies would affect learning. We ran simulations with two different configurations in the task shown in Figure 2. The first configuration used three assemblies with a size ratio of 1:1.5:2. After training, these assemblies exhibited transition statistics that closely matched those of the evoked activity (Supplementary Fig.4a,b). In contrast, the second configuration, which used a size ratio of 1:2:3, showed worse performance compared to the 1:1.5:2 case (Supplementary Fig.4c,d). These results suggest that the model can learn appropriate transition statistics as long as the size ratio of the assemblies is not drastically varied.</p><disp-quote content-type="editor-comment"><p>Finally, it was not entirely clear to me what the main fundamental point in the HVC data section was. Can the findings be roughly explained as follows: if we map syllables to cell assemblies, for high-uncertainty syllable-to-syllable transitions, it becomes harder to predict future neural activity? In other words, is the main point that the HVC encodes syllables by cell assemblies?</p></disp-quote><p>The reviewer's understanding is correct. We wanted to show that if the HVC learns transition statistics as a replay of cell assemblies, a high-uncertainty syllable-to-syllable transition would make predicting future reactivations more difficult, since trial-averaged activities (i.e., poststimulus activities; PSAs) marginalized all possible transitions in the transition diagram.</p><p>(1) Learning in Spiking Neural Assemblies, David Barber, 2002. URL: <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2002/file/619205da514e83f869515c782a328d3c-Paper.pdf">https://proceedings.neurips.cc/paper/2002/file/619205da514e83f869515c782a328d3c-Paper.pdf</ext-link></p><p>(2) Correlated sequence learning in a network of spiking neurons usingmaximum likelihood, David Barber, Felix Agakov, 2002. URL: <ext-link ext-link-type="uri" xlink:href="http://web4.cs.ucl.ac.uk/staff/D.Barber/publications/barber-agakovTR0149.pdf">http://web4.cs.ucl.ac.uk/staff/D.Barber/publications/barber-agakovTR0149.pdf</ext-link></p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>In more detail:</p><p>A) Theoretical analysis</p><p>The plasticity rules in the study are introduced with a vague reference to previous theoretical studies of others. Doing this, one does not provide any formal insight as to why these plasticity rules should enable one to learn to solve the intended task, and whether they are optimal in some respect. This becomes noticeable, especially in the discussion of the importance of inhibitory balance, which does not go into any detail, but rather only states that its required, both in the results and discussion sections. Another unclarity appears when error-based learning is discussed and compared to Hebbian plasticity, which, as you state, &quot;alone is insufficient to learn transition probabilities&quot;. It is not evident how this claim is warranted, nor why error-based plasticity in comparison should be able to perform this (other than referring to the simulation results). Please either clarify formally (or at least intuitively) how plasticity rules result in the mentioned behavior, or alternatively acknowledge explicitly the (current) lack of intuition.</p><p>The lack of formal discussion is a relevant shortcoming compared to previous research that showed very similar results with formally more rigorous and principled approaches. In particular, Kappel et al derived explicitly how neural networks can learn to sample from HMMs using STDP and winner-take-all dynamics. Even though this study has limitations, the relation with respect to that work should be made very clear; potentially the claims of novelty of some results (sampling) should be adjusted accordingly. See also Yanping Huang, Rajesh PN Rao (NIPS 2014), and possibly other publications. While it might be difficult to formally justify the learning rules post-hoc, it would be very helpful to the field if you very clearly related your work to that of others, where learning rules have been formally justified, and elaborate on the intuition of how the employed rules operate and interact (especially for inhibition).</p><p>Lastly, while the importance of sampling learned transition probabilities is discussed, the discussion again remains on a vague level, characterized by the lack of references in the relevant paragraphs. Ideally, there should be a proof of concept or a formal understanding of how the learned behaviour enables to solve a problem that is not solved by deterministic networks. Please incorporate also the relation to the literature on neural sampling/planning/RL etc. and substantiate the claims with citations.</p></disp-quote><p>We have included sentences in ll. 691-696 in the revised manuscript to explain that for Poisson spiking neurons, the derived learning rule is equivalent to the one that minimizes the Kullback-Leibler divergence between the distributions of output firing and the dendritic prediction, in our case, the recurrent prediction (Asabuki and Fukai; 2020). Thus, the rule suggests that the recurrent prediction learns the statistical model of the evoked activity, which in turn allows the network to reproduce the learned transition statistics.</p><p>We have also added a paragraph to discuss the differences between previously published similar models (e.g., Kappel et al.). Please see our response above.</p><disp-quote content-type="editor-comment"><p>B) Connection to biology</p><p>The plasticity rules in the study are introduced with a vague reference to previous theoretical studies of others. Please discuss in more detail if these rules (especially the error-based learning rule) could be implemented biologically and how this could be achieved. Are there connections to biologically observed plasticity? E.g. for error-based plasticity has been discussed in the original publication by Urbanzcik and Senn, or more recently by Mikulasch et al (TINS 2023). The biological plausibility of inhibitory balance has been discussed many times before, e.g. by Vogels and others, and a citation would acknowledge that earlier work. This also leaves the question of how neurons in the songbird experiment could adapt and if the model does capture this well (i.e., do they exhibit E-I balance? etc), which might be discussed as well.</p><p>Last, please provide some testable experimental predictions. By proposing an interesting experimental prediction, the model could become considerably more relevant to experimentalists. Also, are there potentially alternative models of stochastic sequence learning (e.g., Kappel et al)? How could they be distinguished? (especially, again, why not Hebbian/STDP learning?)</p></disp-quote><p>We have cited the Vogels paper to acknowledge the earlier work. We have also included additional paragraphs to discuss a possible biologically plausible implementation of our model and how our model differs from similar models proposed previously (e.g., Kappel et al.). Please see our response above.</p><disp-quote content-type="editor-comment"><p>Other comments</p><p>As mentioned, a derivation of recurrent plasticity rules is missing, and parameters are chosen ad-hoc. This leaves the question of how much the results rely on the specific choice of parameters, and how robust they are to perturbations. As a robustness check, please clarify how the duration of the Markov states influences performance. It can be expected that this interacts with the timescale of recurrent connections, so having longer or shorter Markov states, as it would be in reality, should make a difference in learning that should be tested and discussed.</p></disp-quote><p>We thank the reviewer for pointing this out. To address this point, we performed new simulations and asked to what extent the duration of Markov states affect performance. Interestingly, even when the network was trained with input states of half the duration, the distributions of the durations of assembly reactivations remain almost identical to those in the original case (Supplementary Figure 3a). Furthermore, the transition probabilities in the replay were still consistent with the true transition probabilities (Supplementary Figure 3b). We have also included the derivation of our plasticity rule in ll. 630-670 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Similarly, inhibitory plasticity operates with the same plasticity timescale parameter as excitatory plasticity, but, as the authors discuss, lags behind excitatory plasticity in simulation as in experiment. Is this required or was the parameter chosen such that this behaviour emerges? Please clarify this in the methods section; moreover, it would be good to test if the same results appear with fast inhibitory plasticity.</p></disp-quote><p>We have performed a new simulation and showed that even when the learning rate of inhibitory plasticity was larger than that of excitatory plasticity, inhibitory plasticity still occurred on a slower timescale than excitatory plasticity. We have included this result in a new Supplementary Figure 2 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>What is the justification (biologically and theoretically) for the memory trace h and its impact on neural spiking? Is it required for the results or can it be left away? Since this seems to be an important and unconventional component of the model, please discuss it in more detail.</p></disp-quote><p>In the model, it is assumed that each stimulus presentation drives a specific subset of network neurons with a fixed input strength, which avoids convergence to trivial solutions. Nevertheless, we choose to add this dynamic sigmoid function to facilitate stable replay by regulating neuron activity to prevent saturation. We have explained this point in ll.605-611 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>I noticed a couple of minor typos:</p><p>Page 3 &quot;underly&quot;-&gt;&quot;underlie&quot;</p><p>Page 7 &quot;assemblies decreased settled&quot;-&gt;&quot;assemblies decreased and settled&quot;</p></disp-quote><p>We have modified the text. We thank the reviewer for their careful review.</p><disp-quote content-type="editor-comment"><p>I think Figure 1C is rather confusing and not intuitive.</p></disp-quote><p>We apologize that the Figure 1C was confusing. In the revised figure, we have emphasized the flow of excitatory and inhibitory error for updating synapses.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>One possible path to improve the paper would be to establish a relationship between the proposed learning rules and e.g. the ones derived by Barber.</p><p>When reading the paper, I was left with a number of more detailed questions I omitted from the public review:</p><p>(1) The authors introduce a dynamic sigmoidal function for excitatory neurons, Eq. 3. This point requires more discussion and analysis. How does this impact the results?</p></disp-quote><p>In the model, it is assumed that each stimulus presentation drives a specific subset of network neurons with a fixed input strength, which avoids convergence to trivial solutions. Nevertheless, we choose to add this dynamic sigmoid function to facilitate stable replay by regulating neuron activity to prevent saturation. We have explained this point in ll.605-611 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>(2) For Poisson spiking neurons, it would be great to understand what cell assemblies bring (apart from biological realism, i.e., reproducing data where assemblies can be found), compared to self-connected single neurons. For example, how do the results shown in Figure 2 depend on assembly size?</p></disp-quote><p>We have changed the cell assembly size ratio and how it affects learning performance in a new Supplementary Figure 4. Please see our reply above.</p><disp-quote content-type="editor-comment"><p>(3) The authors focus on modeling spontaneous transitions, corresponding to a highly stochastic generative model (with most transition probabilities far from 1). A complementary question is that of learning to produce a set of stereotypical sequences, with probabilities close to 1. I wondered whether the learning rules and architecture of the model (in particular under the I-to-E rule) would also work in such a scenario.</p></disp-quote><p>We thank the reviewer for pointing this out. In fact, we had the same question, so we considered a situation in which the setting in Figure 2 includes both cases where the transition matrix is very stochastic (prob=0.5) and near deterministic (prob=0.9).</p><disp-quote content-type="editor-comment"><p>(4) An analysis of what controls the time so that the network stays in a certain state would be welcome.</p></disp-quote><p>We trained the network model in two cases, one with a fast speed of plasticity and one with a slow speed of plasticity. As a result, we found that the duration of assembly becomes longer in the slow learning case than in the fast case. We have included these results as Supplementary Figure 5 in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Regarding the presentation, given that this is a computational modeling paper, I wonder whether *all* the formulas belong in the Methods section. I found myself skipping back and forth to understand what the main text meant, mainly because I missed a few key equations. I understand that this is a style issue that is very much community-dependent, but I think readability would improve drastically if the main model and learning rule equations could be introduced in the main text, as they start being discussed.</p></disp-quote><p>We thank the reviewer for the suggestion. To cater to a wider audience, we try to explain the principle of the paper without using mathematical formulas as much as possible in the main text.</p></body></sub-article></article>