<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">80680</article-id><article-id pub-id-type="doi">10.7554/eLife.80680</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural learning rules for generating flexible predictions and computing the successor representation</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-283316"><name><surname>Fang</surname><given-names>Ching</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3653-0057</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-85606"><name><surname>Aronov</surname><given-names>Dmitriy</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8277-5074</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-176755"><name><surname>Abbott</surname><given-names>LF</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-281603"><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6593-4398</contrib-id><email>em3406@columbia.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj8s172</institution-id><institution>Zuckerman Institute, Department of Neuroscience, Columbia University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Basis Research Institute</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx6zz33</institution-id><institution>École Normale Supérieure Paris</institution></institution-wrap><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>16</day><month>03</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e80680</elocation-id><history><date date-type="received" iso-8601-date="2022-05-30"><day>30</day><month>05</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-10-26"><day>26</day><month>10</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2022-05-19"><day>19</day><month>05</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.05.18.492543"/></event></pub-history><permissions><copyright-statement>© 2023, Fang et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Fang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-80680-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-80680-figures-v1.pdf"/><related-article related-article-type="article-reference" ext-link-type="doi" xlink:href="10.7554/eLife.80663" id="ra1"/><related-article related-article-type="article-reference" ext-link-type="doi" xlink:href="10.7554/eLife.80671" id="ra2"/><abstract><p>The predictive nature of the hippocampus is thought to be useful for memory-guided cognitive behaviors. Inspired by the reinforcement learning literature, this notion has been formalized as a predictive map called the successor representation (SR). The SR captures a number of observations about hippocampal activity. However, the algorithm does not provide a neural mechanism for how such representations arise. Here, we show the dynamics of a recurrent neural network naturally calculate the SR when the synaptic weights match the transition probability matrix. Interestingly, the predictive horizon can be flexibly modulated simply by changing the network gain. We derive simple, biologically plausible learning rules to learn the SR in a recurrent network. We test our model with realistic inputs and match hippocampal data recorded during random foraging. Taken together, our results suggest that the SR is more accessible in neural circuits than previously thought and can support a broad range of cognitive functions.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>Memories are an important part of how we think, understand the world around us, and plan out future actions. In the brain, memories are thought to be stored in a region called the hippocampus. When memories are formed, neurons store events that occur around the same time together. This might explain why often, in the brains of animals, the activity associated with retrieving memories is not just a snapshot of what happened at a specific moment-- it can also include information about what the animal might experience next. This can have a clear utility if animals use memories to predict what they might experience next and plan out future actions.</p><p>Mathematically, this notion of predictiveness can be summarized by an algorithm known as the successor representation. This algorithm describes what the activity of neurons in the hippocampus looks like when retrieving memories and making predictions based on them. However, even though the successor representation can computationally reproduce the activity seen in the hippocampus when it is making predictions, it is unclear what biological mechanisms underpin this computation in the brain.</p><p>Fang et al. approached this problem by trying to build a model that could generate the same activity patterns computed by the successor representation using only biological mechanisms known to exist in the hippocampus. First, they used computational methods to design a network of neurons that had the biological properties of neural networks in the hippocampus. They then used the network to simulate neural activity. The results show that the activity of the network they designed was able to exactly match the successor representation. Additionally, the data resulting from the simulated activity in the network fitted experimental observations of hippocampal activity in Tufted Titmice.</p><p>One advantage of the network designed by Fang et al. is that it can generate predictions in flexible ways,. That is, it canmake both short and long-term predictions from what an individual is experiencing at the moment. This flexibility means that the network can be used to simulate how the hippocampus learns in a variety of cognitive tasks. Additionally, the network is robust to different conditions. Given that the brain has to be able to store memories in many different situations, this is a promising indication that this network may be a reasonable model of how the brain learns.</p><p>The results of Fang et al. lay the groundwork for connecting biological mechanisms in the hippocampus at the cellular level to cognitive effects, an essential step to understanding the hippocampus, as well as its role in health and disease. For instance, their network may provide a concrete approach to studying how disruptions to the ways neurons make and break connections can impair memory formation. More generally, better models of the biological mechanisms involved in making computations in the hippocampus can help scientists better understand and test out theories about how memories are formed and stored in the brain.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>tufted titmouse</kwd><kwd>hippocampus</kwd><kwd>state-space model</kwd><kwd>recurrent neural network</kwd><kwd>plasticity</kwd><kwd>predictive coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>NeuroNex Award DBI-1707398</award-id><principal-award-recipient><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Fang</surname><given-names>Ching</given-names></name><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000324</institution-id><institution>Gatsby Charitable Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Fang</surname><given-names>Ching</given-names></name><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100003194</institution-id><institution>New York Stem Cell Foundation</institution></institution-wrap></funding-source><award-id>Robertson Neuroscience Investigator Award</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Ching</given-names></name><name><surname>Aronov</surname><given-names>Dmitriy</given-names></name><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>NIH Director's New Innovator Award (DP2-AG071918)</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Ching</given-names></name><name><surname>Aronov</surname><given-names>Dmitriy</given-names></name><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000997</institution-id><institution>Arnold and Mabel Beckman Foundation</institution></institution-wrap></funding-source><award-id>Beckman Young Investigator Award</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Ching</given-names></name><name><surname>Aronov</surname><given-names>Dmitriy</given-names></name><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>Graduate Research Fellowship Program</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Ching</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>Society of Fellows</award-id><principal-award-recipient><name><surname>Mackevicius</surname><given-names>Emily L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A recurrent network using a simple, biologically plausible learning rule can learn the successor representation, suggesting that long-horizon predictions are computations that are easily accessible in neural circuits.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>To learn from the past, plan for the future, and form an understanding of our world, we require memories of personal experiences. These memories depend on the hippocampus for formation and recall (<xref ref-type="bibr" rid="bib109">Scoville and Milner, 1957</xref>; <xref ref-type="bibr" rid="bib98">Penfield and Milner, 1958</xref>; <xref ref-type="bibr" rid="bib20">Corkin, 2002</xref>), but an algorithmic and mechanistic understanding of memory formation and retrieval in this region remains elusive. From a computational perspective, a key function of memory is to use past experiences to inform predictions of possible futures (<xref ref-type="bibr" rid="bib18">Bubic et al., 2010</xref>; <xref ref-type="bibr" rid="bib122">Wayne et al., 2018</xref>; <xref ref-type="bibr" rid="bib123">Whittington et al., 2020</xref>; <xref ref-type="bibr" rid="bib85">Momennejad, 2020</xref>). This suggests that hippocampal memory is stored in a way that is particularly suitable for forming predictions. Consistent with this hypothesis, experimental work has shown that, across species and tasks, hippocampal activity is predictive of the future experience of an animal (<xref ref-type="bibr" rid="bib112">Skaggs and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="bib65">Lisman and Redish, 2009</xref>; <xref ref-type="bibr" rid="bib80">Mehta et al., 1997</xref>; <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>; <xref ref-type="bibr" rid="bib87">Muller and Kubie, 1989</xref>; <xref ref-type="bibr" rid="bib99">Pfeiffer and Foster, 2013</xref>; <xref ref-type="bibr" rid="bib108">Schapiro et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Garvert et al., 2017</xref>). Furthermore, theoretical work has found that models endowed with predictive objectives tend to resemble hippocampal activity (<xref ref-type="bibr" rid="bib11">Blum and Abbott, 1996</xref>; <xref ref-type="bibr" rid="bib81">Mehta et al., 2000</xref>; <xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref>; <xref ref-type="bibr" rid="bib83">Momennejad et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Geerts et al., 2020</xref>; <xref ref-type="bibr" rid="bib103">Recanatesi et al., 2021</xref>; <xref ref-type="bibr" rid="bib123">Whittington et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">George et al., 2021</xref>). Thus, it is clear that predictive representations are an important aspect of hippocampal memory.</p><p>Inspired by work in the reinforcement learning (RL) field, these observations have been formalized by describing hippocampal activity as a predictive map under the successor representation (SR) algorithm (<xref ref-type="bibr" rid="bib22">Dayan, 1993</xref>; <xref ref-type="bibr" rid="bib40">Gershman et al., 2012</xref>; <xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref>). Under this framework, an animal’s experience in the world is represented as a trajectory through some defined state space, and hippocampal activity predicts the future experience of an animal by integrating over the likely states that an animal will visit given its current state. This algorithm further explains how, in addition to episodic memory, the hippocampus may support relational reasoning and decision making (<xref ref-type="bibr" rid="bib103">Recanatesi et al., 2021</xref>; <xref ref-type="bibr" rid="bib76">Mattar and Daw, 2018</xref>), consistent with differences in hippocampal representations in different tasks (<xref ref-type="bibr" rid="bib73">Markus et al., 1995</xref>; <xref ref-type="bibr" rid="bib52">Jeffery, 2021</xref>). The SR framework captures many experimental observations of neural activity, leading to a proposed computational function for the hippocampus (<xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref>).</p><p>While the SR algorithm convincingly argues for a computational function of the hippocampus, it is unclear what biological mechanisms might compute the SR in a neural circuit. Thus, several relevant questions remain that are difficult to probe with the current algorithm. What kind of neural architecture should one expect in a region that can support this computation? Are there distinct forms of plasticity and neuromodulation needed in this system? What is the structure of hippocampal inputs to be expected? A biologically plausible model can explore these questions and provide insight into both mechanism and function (<xref ref-type="bibr" rid="bib74">Marr and Poggio, 1976</xref>; <xref ref-type="bibr" rid="bib33">Frank, 2015</xref>; <xref ref-type="bibr" rid="bib69">Love, 2021</xref>).</p><p>In other systems, it has been possible to derive biological mechanisms with the goal of achieving a particular network function or property (<xref ref-type="bibr" rid="bib125">Zeldenrust et al., 2021</xref>; <xref ref-type="bibr" rid="bib55">Karimi et al., 2022</xref>; <xref ref-type="bibr" rid="bib96">Pehlevan et al., 2017</xref>; <xref ref-type="bibr" rid="bib92">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib19">Burbank, 2015</xref>; <xref ref-type="bibr" rid="bib4">Aitchison et al., 2021</xref>; <xref ref-type="bibr" rid="bib31">Földiák, 1990</xref>; <xref ref-type="bibr" rid="bib120">Tyulmankov et al., 2022</xref>). Key to many of these models is the constraint that learning rules at any given neuron can only use information local to that neuron. A promising direction towards such a neural model of the SR is to use the dynamics of a recurrent neural network (RNN) to perform SR computations (<xref ref-type="bibr" rid="bib121">Vértes and Sahani, 2019</xref>; <xref ref-type="bibr" rid="bib105">Russek et al., 2017</xref>). An RNN model is particularly attractive as the hippocampus is highly recurrent, and its connectivity patterns are thought to support associative learning and recall (<xref ref-type="bibr" rid="bib35">Gardner-Medwin, 1976</xref>; <xref ref-type="bibr" rid="bib79">McNaughton and Morris, 1987</xref>; <xref ref-type="bibr" rid="bib75">Marr et al., 1991</xref>; <xref ref-type="bibr" rid="bib67">Liu et al., 2012</xref>). However, an RNN model of the SR has not been tied to neural learning rules that support its operation and allow for testing of specific hypotheses.</p><p>Here, we show that an RNN with local learning rules and an adaptive learning rate exactly calculates the SR at steady state. We test our model with realistic inputs and make comparisons to neural data. In addition, we compare our results to the standard SR algorithm with respect to the speed of learning and the learned representations in cases where multiple solutions exist. Our work provides a mechanistic account for an algorithm that has been frequently connected to the hippocampus, but could only be interpreted at an algorithmic level. This network-level perspective allows us to make specific predictions about hippocampal mechanisms and activity.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The successor representation</title><p>The SR algorithm described in <xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref> first discretizes the environment explored by an animal (whether a physical or abstract space) into a set of <inline-formula><mml:math id="inf1"><mml:mi>n</mml:mi></mml:math></inline-formula> states that the animal transitions through over time (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The animal’s behavior can then be thought of as a Markov chain with a corresponding transition probability matrix <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). <inline-formula><mml:math id="inf3"><mml:mi>T</mml:mi></mml:math></inline-formula> gives the probability that the animal transitions to a state <inline-formula><mml:math id="inf4"><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> from the state <inline-formula><mml:math id="inf5"><mml:mi>s</mml:mi></mml:math></inline-formula> in one time step: <inline-formula><mml:math id="inf6"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The SR matrix is defined as<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>T</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a temporal discount factor. <inline-formula><mml:math id="inf8"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> can be seen as a measure of the occcupancy of state <inline-formula><mml:math id="inf9"><mml:mi>i</mml:mi></mml:math></inline-formula> over time if the animal starts at state <inline-formula><mml:math id="inf10"><mml:mi>j</mml:mi></mml:math></inline-formula>, with <inline-formula><mml:math id="inf11"><mml:mi>γ</mml:mi></mml:math></inline-formula> controlling how much to discount time steps in the future (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The SR of state <inline-formula><mml:math id="inf12"><mml:mi>j</mml:mi></mml:math></inline-formula> is the <inline-formula><mml:math id="inf13"><mml:mi>j</mml:mi></mml:math></inline-formula>th row of <inline-formula><mml:math id="inf14"><mml:mi>M</mml:mi></mml:math></inline-formula> and represents the states that an animal is likely to transition to from state <inline-formula><mml:math id="inf15"><mml:mi>j</mml:mi></mml:math></inline-formula>. <xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref> demonstrate that, if one assumes each state drives a single neuron, the SR of <inline-formula><mml:math id="inf16"><mml:mi>j</mml:mi></mml:math></inline-formula> resembles the population activity of hippocampal neurons when the animal is at state <inline-formula><mml:math id="inf17"><mml:mi>j</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). They also show that the <inline-formula><mml:math id="inf18"><mml:mi>i</mml:mi></mml:math></inline-formula>th column of <inline-formula><mml:math id="inf19"><mml:mi>M</mml:mi></mml:math></inline-formula> resembles the place field (activity as a function of state) of a hippocampal neuron representing state <inline-formula><mml:math id="inf20"><mml:mi>i</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). In addition, the <inline-formula><mml:math id="inf21"><mml:mi>i</mml:mi></mml:math></inline-formula>th column of <inline-formula><mml:math id="inf22"><mml:mi>M</mml:mi></mml:math></inline-formula> shows which states are likely to lead to state <inline-formula><mml:math id="inf23"><mml:mi>i</mml:mi></mml:math></inline-formula>.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The successor representation and an analogous recurrent network model.</title><p>(<bold>A</bold>) The behavior of an animal running down a linear track can be described as a transition between discrete states where the states encode spatial location. (<bold>B</bold>) By counting the transitions between different states, the behavior of an animal can be summarized in a transition probability matrix <inline-formula><mml:math id="inf24"><mml:mi>T</mml:mi></mml:math></inline-formula>. (<bold>C</bold>) The successor representation matrix is defined as <inline-formula><mml:math id="inf25"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, <inline-formula><mml:math id="inf26"><mml:mi>M</mml:mi></mml:math></inline-formula> is shown for <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math></inline-formula>. Dashed boxes indicate the slices of <inline-formula><mml:math id="inf28"><mml:mi>M</mml:mi></mml:math></inline-formula> shown in (<bold>D</bold>) and (<bold>E</bold>). (<bold>D</bold>) The fourth row of the <inline-formula><mml:math id="inf29"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix describes the activity of each state-encoding neuron when the animal is at the fourth state. (<bold>E</bold>) The fourth column of the <inline-formula><mml:math id="inf30"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix describes the place field of the neuron encoding the fourth state. (<bold>F</bold>) Recurrent network model of the SR (RNN-S). The current state of the animal is one-hot encoded by a layer of input neurons. Inputs connect one-to-one onto RNN neurons with synaptic connectivity matrix <inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. The activity of the RNN neurons are represented by <inline-formula><mml:math id="inf32"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula>. SR activity is read out from one-to-one connections from the RNN neurons to the output neurons. The example here shows inputs and outputs when the animal is at state 4. (<bold>G</bold>) Feedforward neural network model of the SR (FF-TD). The <inline-formula><mml:math id="inf33"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix is encoded in the weights from the input neurons to the output layer neurons, where the SR activity is read out. (<bold>H</bold>) Diagram of the terms used for the RNN-S learning rule. Terms in red are used for potentiation while terms in blue are used for normalization (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). (<bold>I</bold>) As in (<bold>H</bold>) but for the feedforward-TD model (<xref ref-type="disp-formula" rid="equ11">Equation 11</xref>). To reduce the notation indicating time steps, we use <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in place of <inline-formula><mml:math id="inf35"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and no added notation for <inline-formula><mml:math id="inf36"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig1-v1.tif"/></fig></sec><sec id="s2-2"><title>Recurrent neural network computes SR at steady state</title><p>We begin by drawing connections between the SR algorithm (<xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref>) and an analogous neural network architecture. The input to the network encodes the current state of the animal and is represented by a layer of input neurons (<xref ref-type="fig" rid="fig1">Figure 1FG</xref>). These neurons feed into the rest of the network that computes the SR (<xref ref-type="fig" rid="fig1">Figure 1FG</xref>). The SR is then read out by a layer of output neurons so that downstream systems receive a prediction of the upcoming states (<xref ref-type="fig" rid="fig1">Figure 1FG</xref>). We will first model the inputs <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as one-hot encodings of the current state of the animal (<xref ref-type="fig" rid="fig1">Figure 1FG</xref>). That is, each input neuron represents a unique state, and input neurons are one-to-one connected to the hidden neurons.</p><p>We first consider an architecture in which a recurrent neural network (RNN) is used to compute the SR (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). Let us assume that the <inline-formula><mml:math id="inf38"><mml:mi>T</mml:mi></mml:math></inline-formula> matrix is encoded in the synaptic weights of the RNN. In this case, the steady state activity of the network in response to input <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> retrieves a row of the SR matrix, <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1F</xref>, subsection 4.14). Intuitively, this is because each recurrent iteration of the RNN progresses the prediction by one transition. In other words, the <inline-formula><mml:math id="inf41"><mml:mi>t</mml:mi></mml:math></inline-formula>th recurrent iteration raises <inline-formula><mml:math id="inf42"><mml:mi>T</mml:mi></mml:math></inline-formula> to the <inline-formula><mml:math id="inf43"><mml:mi>t</mml:mi></mml:math></inline-formula>th power as in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. To formally derive this result, we first start by defining the dynamics of our RNN with classical rate network equations (<xref ref-type="bibr" rid="bib5">Amarimber, 1972</xref>). At time <inline-formula><mml:math id="inf44"><mml:mi>t</mml:mi></mml:math></inline-formula>, the firing rate <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> of <inline-formula><mml:math id="inf46"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons given each neurons’ input <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> follows the discrete-time dynamics (assuming a step size <inline-formula><mml:math id="inf48"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>)<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf49"><mml:mi>γ</mml:mi></mml:math></inline-formula> scales the recurrent activity and is a constant factor for all neurons. The synaptic weight matrix <inline-formula><mml:math id="inf50"><mml:mrow><mml:mi>J</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi class="ltx_font_mathcaligraphic">ℛ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is defined such that <inline-formula><mml:math id="inf51"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the synaptic weight from neuron <inline-formula><mml:math id="inf52"><mml:mi>j</mml:mi></mml:math></inline-formula> to neuron <inline-formula><mml:math id="inf53"><mml:mi>i</mml:mi></mml:math></inline-formula>. Notably, this notation is transposed from what is used in RL literature, where conventions have the first index as the starting state. Generally, <inline-formula><mml:math id="inf54"><mml:mi>f</mml:mi></mml:math></inline-formula> is some nonlinear function in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. For now, we will consider <inline-formula><mml:math id="inf55"><mml:mi>f</mml:mi></mml:math></inline-formula> to be the identity function, rendering this equation linear. Under this assumption, we can solve for the steady state activity <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> as<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Equivalence between <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> and <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> is clearly reached when <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib105">Russek et al., 2017</xref>; <xref ref-type="bibr" rid="bib121">Vértes and Sahani, 2019</xref>). Thus, if the network can learn <inline-formula><mml:math id="inf58"><mml:mi>T</mml:mi></mml:math></inline-formula> in its synaptic weight matrix, it will exactly compute the SR.</p><p>Here, the factor <inline-formula><mml:math id="inf59"><mml:mi>γ</mml:mi></mml:math></inline-formula> represents the gain of the neurons in the network, which is factored out of the synaptic strengths characterized by  <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Thus, <inline-formula><mml:math id="inf61"><mml:mi>γ</mml:mi></mml:math></inline-formula> is an independently adjustable factor that can flexibly control the strength of the recurrent dynamics (see <xref ref-type="bibr" rid="bib113">Sompolinsky et al., 1988</xref>). A benefit of this flexibility is that the system can retrieve successor representations of varying predictive strengths by modulating the gain factor <inline-formula><mml:math id="inf62"><mml:mi>γ</mml:mi></mml:math></inline-formula>. In this way, the predictive horizon can be dynamically controlled without any additional learning required. We will refer to the <inline-formula><mml:math id="inf63"><mml:mi>γ</mml:mi></mml:math></inline-formula> used during learning of the SR as the baseline <inline-formula><mml:math id="inf64"><mml:mi>γ</mml:mi></mml:math></inline-formula>, or <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula>.</p><p>We next consider what is needed in a learning rule such that <inline-formula><mml:math id="inf66"><mml:mi>J</mml:mi></mml:math></inline-formula> approximates <inline-formula><mml:math id="inf67"><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:math></inline-formula>. In order to learn a transition probability matrix, a learning rule must associate states that occur sequentially and normalize the synaptic weights into a valid probability distribution. We derive a learning rule that addresses both requirements (<xref ref-type="fig" rid="fig1">Figure 1H</xref>, Appendix 2),<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf68"><mml:mi>η</mml:mi></mml:math></inline-formula> is the learning rate. The first term in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> is a temporally asymmetric potentiation term that counts states that occur in sequence. This is similar to spike-timing dependent plasticity, or STDP (<xref ref-type="bibr" rid="bib8">Bi and Poo, 1998</xref>; <xref ref-type="bibr" rid="bib112">Skaggs and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="bib1">Abbott and Blum, 1996</xref>).</p><p>The second term in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> is a form of synaptic depotentiation. Depotentiation has been hypothesized to be broadly useful for stabilizing patterns and sequence learning (<xref ref-type="bibr" rid="bib31">Földiák, 1990</xref>; <xref ref-type="bibr" rid="bib30">Fiete et al., 2010</xref>), and similar inhibitory effects are known to be elements of hippocampal learning (<xref ref-type="bibr" rid="bib60">Kullmann and Lamsa, 2007</xref>; <xref ref-type="bibr" rid="bib62">Lamsa et al., 2007</xref>). In our model, the depotentiation term in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> imposes local anti-Hebbian learning at each neuron– that is, each column of <inline-formula><mml:math id="inf69"><mml:mi>J</mml:mi></mml:math></inline-formula> is normalized independently. This normalizes the observed transitions from each state by the number of visits to that state, such that transition statistics are correctly captured. We note, however, that other ways of column-normalizing the synaptic weight matrix may give similar representations (Appendix 7).</p><p>Crucially, the update rule (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>) uses information local to each neuron (<xref ref-type="fig" rid="fig1">Figure 1H</xref>), an important aspect of biologically plausible learning rules. We show that, in the asymptotic limit, the update rule extracts information about the inputs <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and learns <inline-formula><mml:math id="inf71"><mml:mi>T</mml:mi></mml:math></inline-formula> exactly despite having access only to neural activity <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (Appendix 3). We will refer to an RNN using <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> as the RNN-Successor, or RNN-S. Combined with recurrent dynamics (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>), RNN-S computes the SR exactly (<xref ref-type="fig" rid="fig1">Figure 1H</xref>).</p><p>As an alternative to the RNN-S model, we consider the conditions necessary for a feedforward neural network to compute the SR. Under this architecture, the <inline-formula><mml:math id="inf73"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix must be encoded in the weights from the input neurons to the hidden layer neurons (<xref ref-type="fig" rid="fig1">Figure 1G</xref>). This can be achieved by updating the synaptic weights with a temporal difference (TD) learning rule, the standard update used to learn the SR in the usual algorithm. Although the TD update learns the SR, it requires information about multiple input layer neurons to make updates for the synapse from input neuron <inline-formula><mml:math id="inf74"><mml:mi>j</mml:mi></mml:math></inline-formula> to output neuron <inline-formula><mml:math id="inf75"><mml:mi>i</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1I</xref>). Thus, it is useful to explore other possible mechanisms that are simpler to compute locally. We refer to the model described in <xref ref-type="fig" rid="fig1">Figure 1I</xref> as the feedforward-TD (FF-TD) model. The FF-TD model implements the canonical SR algorithm.</p></sec><sec id="s2-3"><title>Evaluating SR learning by biologically plausible learning rules</title><p>To evaluate the effectiveness of the RNN-S learning rule, we tested its accuracy in learning the SR matrix for random walks. Specifically, we simulated random walks with different transition biases in a 1D circular track environment (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The RNN-S can learn the SR for these random walks (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Comparing the effects of an adaptive learning rate and plasticity kernels in RNN-S.</title><p>(<bold>A</bold>) Sample one-minute segments from random walks on a 1 meter circular track. Possible actions in this 1D walk are to move forward, stay in one place, or move backward. Action probabilities are uniform (top), biased to move forward (middle), or biased to stay in one place (bottom). (<bold>B</bold>) <inline-formula><mml:math id="inf76"><mml:mi>M</mml:mi></mml:math></inline-formula> matrices estimated by the RNN-S model in the full random walks from (<bold>A</bold>).(<bold>C</bold>) The proposed learning rate normalization. The learning rate <inline-formula><mml:math id="inf77"><mml:msub><mml:mi>η</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> for synapses out of neuron <inline-formula><mml:math id="inf78"><mml:mi>j</mml:mi></mml:math></inline-formula> changes as a function of its activity <inline-formula><mml:math id="inf79"><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> and recency bias <inline-formula><mml:math id="inf80"><mml:mi>λ</mml:mi></mml:math></inline-formula>. Dotted lines are at <inline-formula><mml:math id="inf81"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0.0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>1.0</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. (<bold>D</bold>) The mean row sum of <inline-formula><mml:math id="inf82"><mml:mi>T</mml:mi></mml:math></inline-formula> over time computed by the RNN-S with an adaptive learning rate (blue) or the RNN-S with static learning rates (orange). Darker lines indicate larger static learning rates. Lines show the average over 5 simulations from walks with a forward bias, and shading shows 95% confidence interval. A correctly normalized <inline-formula><mml:math id="inf83"><mml:mi>T</mml:mi></mml:math></inline-formula> matrix should have a row sum of 1.0. (<bold>E</bold>) As in (<bold>D</bold>), but for the mean absolute error in estimating <inline-formula><mml:math id="inf84"><mml:mi>T</mml:mi></mml:math></inline-formula>. (<bold>F</bold>) As in (<bold>E</bold>), but for mean absolute error in estimating the real <inline-formula><mml:math id="inf85"><mml:mi>M</mml:mi></mml:math></inline-formula>, and with performance of FF-TD included, with darker lines indicating slower learning rates for FF-TD. (<bold>G</bold>) Lap-based activity map of a neuron from RNN-S with static learning rate <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The neuron encodes the state at 45cm on a circular track. The simulated agent is moving according to forward-biased transition statistics. (<bold>H</bold>) As in (<bold>G</bold>), but for RNN-S with adaptive learning rate. (<bold>I</bold>) The learning rate over time for the neuron in (<bold>G</bold>) (orange) and the neuron in (<bold>H</bold>) (blue). (<bold>J</bold>) Mean-squared error (MSE) at the end of meta-learning for different plasticity kernels. The pre→post (K+) and post→pre (K-) sides of each kernel were modeled by <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Heatmap indices indicate the values <inline-formula><mml:math id="inf88"><mml:mi>τ</mml:mi></mml:math></inline-formula> s were fixed to. Here, K+ is always a positive function (i.e., <inline-formula><mml:math id="inf89"><mml:mi>A</mml:mi></mml:math></inline-formula> was positive), because performance was uniformly poor when K+ was negative. K- could be either positive (left, “Post → Pre Potentiation&quot;) or negative (right, “Post → Pre Depression&quot;). Regions where the learned value for <inline-formula><mml:math id="inf90"><mml:mi>A</mml:mi></mml:math></inline-formula> was negligibly small were set to high errors. Errors are max-clipped at 0.03 for visualization purposes. 40 initializations were used for each K+ and K- pairing, and the heatmap shows the minimum error acheived over all intializations. (<bold>K</bold>) Plasticity kernels chosen from the areas of lowest error in the grid search from (<bold>J</bold>). Left is post → pre potentiation. Right is post → pre depression. Kernels are normalized by the maximum, and dotted lines are at one second intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Comparing model performance in different random walks.</title><p>(<bold>a</bold>-<bold>c</bold>) As in <xref ref-type="fig" rid="fig2">Figure 2D–F</xref> of the main document, but for a walk with uniform action probabilities.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Because equivalence is only reached in the asymptotic limit of learning (i.e. <inline-formula><mml:math id="inf91"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), our RNN-S model learns the SR slowly. In contrast, animals are thought to be able to learn the structure of an environment quickly (<xref ref-type="bibr" rid="bib126">Zhang et al., 2021</xref>), and neural representations in an environment can also develop quickly (<xref ref-type="bibr" rid="bib86">Monaco et al., 2014</xref>; <xref ref-type="bibr" rid="bib110">Sheffield and Dombeck, 2015</xref>; <xref ref-type="bibr" rid="bib9">Bittner et al., 2015</xref>). To remedy this, we introduce a dynamic learning rate that allows for faster normalization of the synaptic weight matrix, similar to the formula for calculating a moving average (Appendix 4). For each neuron, suppose that a trace <inline-formula><mml:math id="inf92"><mml:mi>n</mml:mi></mml:math></inline-formula> of its recent activity is maintained with some time constant <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ5">, <label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>If the learning rate of the outgoing synapses from each neuron <inline-formula><mml:math id="inf94"><mml:mi>j</mml:mi></mml:math></inline-formula> is inversely proportional to <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, the update equation quickly normalizes the synapses to maintain a valid transition probability matrix (Appendix 4). Modulating synaptic learning rates as a function of neural activity is consistent with experimental observations of metaplasticity (<xref ref-type="bibr" rid="bib2">Abraham and Bear, 1996</xref>; <xref ref-type="bibr" rid="bib3">Abraham, 2008</xref>; <xref ref-type="bibr" rid="bib51">Hulme et al., 2014</xref>). We refer to this as an adaptive learning rate and contrast it with the previous static learning rate. We consider the setting where <inline-formula><mml:math id="inf96"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, so the learning rate monotonically decreases over time (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). In general, however, the learning rate could increase or decrease over time if <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), and <inline-formula><mml:math id="inf98"><mml:mi>n</mml:mi></mml:math></inline-formula> could be reset, allowing for rapid learning. Our learning rule with the adaptive learning rate is the same as in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>, with the exception that <inline-formula><mml:math id="inf99"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>min</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mn>1.0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for synapses <inline-formula><mml:math id="inf100"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. This learning rule still relies only on information local to the neuron as in <xref ref-type="fig" rid="fig1">Figure 1H</xref>.</p><p>The RNN-S with an adaptive learning rate normalizes the synapses more quickly than a network with a static learning rate (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) and learns <inline-formula><mml:math id="inf101"><mml:mi>T</mml:mi></mml:math></inline-formula> faster (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). The RNN-S with a static learning rate exhibits more of a tradeoff between normalizing synapses quickly (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>) and learning <inline-formula><mml:math id="inf102"><mml:mi>M</mml:mi></mml:math></inline-formula> accurately (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). However, both versions of the RNN-S estimate <inline-formula><mml:math id="inf103"><mml:mi>M</mml:mi></mml:math></inline-formula> more quickly than the FF-TD model (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>Place fields can form quickly, but over time the place fields may skew if transition statistics are consistently biased (<xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref>; <xref ref-type="bibr" rid="bib86">Monaco et al., 2014</xref>; <xref ref-type="bibr" rid="bib110">Sheffield and Dombeck, 2015</xref>; <xref ref-type="bibr" rid="bib9">Bittner et al., 2015</xref>). The adaptive learning rate recapitulates both of these effects, which are thought to be caused by slow and fast learning processes, respectively. A low learning rate can capture the biasing of place fields, which develops over many repeated experiences. This is seen in the RNN-S with a static learning rate (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). However, a high learning rate is needed for hippocampal place cells to develop sizeable place fields in one-shot. Both these effects of slow and fast learning can be seen in the neural activity of an example RNN-S neuron with an adaptive learning rate (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). After the first lap, a sizeable field is induced in a one-shot manner, centered at the cell’s preferred location. In subsequent laps, the place field slowly distorts to reflect the bias of the transition statistics (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). The model is able to capture these learning effects because the adaptive learning rate transitions between high and low learning rates, unlike the static version (<xref ref-type="fig" rid="fig2">Figure 2I</xref>).</p><p>Thus far, we have assumed that the RNN-S learning rule uses pre→post activity over two neighboring time steps (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). A more realistic framing is that a convolution with a plasticity kernel determines the weight change at any synapse. We tested how this affects our model and what range of plasticity kernels best supports the estimation of the SR. We do this by replacing the pre→post potentiation term in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> with a convolution:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>In the above equation, the full kernel <inline-formula><mml:math id="inf104"><mml:mi>K</mml:mi></mml:math></inline-formula> is split into a pre→post kernel (<inline-formula><mml:math id="inf105"><mml:msub><mml:mi>K</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>) and a post→pre kernel (<inline-formula><mml:math id="inf106"><mml:msub><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>). <inline-formula><mml:math id="inf107"><mml:msub><mml:mi>K</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf108"><mml:msub><mml:mi>K</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> are parameterized as independent exponential functions, <inline-formula><mml:math id="inf109"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p><p>To systematically explore the space of plasticity kernels that can be used to learn the SR, we performed a grid search over the sign and the time constants of the pre→post and post→pre sides of the plasticity kernels. For each fixed sign and time constant, we used an evolutionary algorithm to learn the remaining parameters that determine the plasticity kernel. We find that plasticity kernels that are STDP-like are more effective than others, although plasticity kernels with slight post→pre potentiation work as well (<xref ref-type="fig" rid="fig2">Figure 2J</xref>). The network is sensitive to the time constant and tends to find solutions for time constants around a few hundred milliseconds (<xref ref-type="fig" rid="fig2">Figure 2JK</xref>). Our robustness analysis indicates the timescale of a plasticity rule in such a circuit may be longer than expected by standard STDP, but within the timescale of changes in behavioral states. We note that this also contrasts with behavioral timescale plasticity (<xref ref-type="bibr" rid="bib9">Bittner et al., 2015</xref>), which integrates over a window that is several seconds long. Finally, we see that even plasticity kernels with slightly different time constants may give results with minimal error from the SR matrix, even if they do not estimate the SR exactly (<xref ref-type="fig" rid="fig2">Figure 2J</xref>). This suggests that, although other plasticity rules could be used to model long-horizon predictions, the SR is a reasonable –although not strictly unique– model to describe this class of predictive representations.</p></sec><sec id="s2-4"><title>RNN-S can compute the SR with arbitrary <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> under a stable regime of <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></title><p>We next investigate how robust the RNN-S model is to the value of <inline-formula><mml:math id="inf112"><mml:mi>γ</mml:mi></mml:math></inline-formula>. Typically, for purposes of fitting neural data or for RL simulations, <inline-formula><mml:math id="inf113"><mml:mi>γ</mml:mi></mml:math></inline-formula> will take on values as high as 0.9 (<xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Barreto et al., 2017</xref>). However, previous work that used RNN models reported that recurrent dynamics become unstable if the gain <inline-formula><mml:math id="inf114"><mml:mi>γ</mml:mi></mml:math></inline-formula> exceeds a critical value (<xref ref-type="bibr" rid="bib113">Sompolinsky et al., 1988</xref>; <xref ref-type="bibr" rid="bib126">Zhang et al., 2021</xref>). This could be problematic as we show analytically that the RNN-S update rule is effective only when the network dynamics are stable and do not have non-normal amplification (Appendix 2). If these conditions are not satisfied during learning, the update rule no longer optimizes for fitting the SR and the learned weight matrix will be incorrect.</p><p>We first test how the value of <inline-formula><mml:math id="inf115"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula>, the gain of the network during learning, affects the RNN-S dynamics. The dynamics become unstable when <inline-formula><mml:math id="inf116"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> exceeds 0.6 (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Specifically, the eigenvalues of the synaptic weight matrix exceed the critical threshold for learning when <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, ‘Linear’). As expected from our analytical results, the stability of the network is tied to the network’s ability to estimate <inline-formula><mml:math id="inf118"><mml:mi>M</mml:mi></mml:math></inline-formula>. RNN-S cannot estimate <inline-formula><mml:math id="inf119"><mml:mi>M</mml:mi></mml:math></inline-formula> well when <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, ‘Linear’). We explored two strategies to enable RNN-S to learn at high <inline-formula><mml:math id="inf121"><mml:mi>γ</mml:mi></mml:math></inline-formula>.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>RNN-S requires a stable choice of <inline-formula><mml:math id="inf122"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> during learning, and can compute SR with any <inline-formula><mml:math id="inf123"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> (<bold>A</bold>) Maximum real eigenvalue of the <inline-formula><mml:math id="inf124"><mml:mi>J</mml:mi></mml:math></inline-formula> matrix at the end of random walks under different <inline-formula><mml:math id="inf125"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula>.</title><p>The network dynamics were either fully linear (solid) or had a tanh nonlinearity (dashed). Red line indicates the transition into an unstable regime. 45 simulations were run for each <inline-formula><mml:math id="inf126"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula>, line indicates mean, and shading shows 95% confidence interval. (<bold>B</bold>) MAE of <inline-formula><mml:math id="inf127"><mml:mi>M</mml:mi></mml:math></inline-formula> matrices learned by RNN-S with different <inline-formula><mml:math id="inf128"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula>. RNN-S was simulated with linear dynamics (solid line) or with a tanh nonlinearity added to the recurrent dynamics (dashed line). Test datasets used various biases in action probability selection. (<bold>C</bold>) <inline-formula><mml:math id="inf129"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix learned by RNN-S with tanh nonlinearity added in the recurrent dynamics. A forward-biased walk on a circular track was simulated, and <inline-formula><mml:math id="inf130"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>D</bold>) The true <inline-formula><mml:math id="inf131"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix of the walk used to generate (<bold>C</bold>). (<bold>E</bold>) Simulated population activity over the first ten laps in a circular track with <inline-formula><mml:math id="inf132"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>. Dashed box indicates the retrieval phase, where learning is turned off and <inline-formula><mml:math id="inf133"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>. Boxes are zoomed in on three minute windows.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Understanding the effects of recurrency on stability.</title><p>(<bold>A</bold>) Mean absolute error (MAE) of <inline-formula><mml:math id="inf134"><mml:mi>M</mml:mi></mml:math></inline-formula> matrices learned by RNN-S with different baseline <inline-formula><mml:math id="inf135"><mml:mi>γ</mml:mi></mml:math></inline-formula> and different numbers of recurrent steps in dynamics. Test datasets used various biases in action probability selection. Errors are max-clipped at 10<sup>1</sup> for visualization purposes. (<bold>B</bold>) <inline-formula><mml:math id="inf136"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix learned by RNN-S with two recurrent steps in dynamics and baseline <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>. A forward-biased walk on a circular track was simulated. (<bold>C</bold>) As in (<bold>B</bold>), but for four recurrent steps. (<bold>D</bold>) As in (<bold>B</bold>), but for five recurrent steps. Three examples are shown from different sampled walks to highlight the runaway activity of the network. (<bold>E</bold>) As in (<bold>B</bold>) but for the RNN-S activity calculated as <inline-formula><mml:math id="inf138"><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>. Note that this calculation amounts to an unstable fixed point in the dynamics that cannot be reached when the network is in an unstable regime. (<bold>F</bold>) Mean absolute error (MAE) in <inline-formula><mml:math id="inf139"><mml:mi>T</mml:mi></mml:math></inline-formula> made by RNN-S with linear dynamics using <inline-formula><mml:math id="inf140"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> during learning. (<bold>G</bold>) MAE in <inline-formula><mml:math id="inf141"><mml:mi>M</mml:mi></mml:math></inline-formula> for <inline-formula><mml:math id="inf142"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> made by RNN-S with linear dynamics using <inline-formula><mml:math id="inf143"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> during learning. (<bold>H</bold>) As in (<bold>G</bold>), but the dynamics now have a tanh nonlinearity.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig3-figsupp1-v1.tif"/></fig></fig-group><p>One way to tame this instability is to add a saturating nonlinearity into the dynamics of the network. This is a feature of biological neurons that is often incorporated in models to prevent unbounded activity (<xref ref-type="bibr" rid="bib23">Dayan and Abbott, 2001</xref>) Specifically, instead of assuming the network dynamics are linear (<inline-formula><mml:math id="inf144"><mml:mi>f</mml:mi></mml:math></inline-formula> is the identity function in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>), we add a hyperbolic tangent into the dynamics equation. This extends the stable regime of the network– the eigenvalues do not exceed the critical threshold until <inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Similar to the linear case, the network with nonlinear dynamics fits <inline-formula><mml:math id="inf146"><mml:mi>M</mml:mi></mml:math></inline-formula> well until the critical threshold for stability (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). These differences are clear visually as well. While the linear network does not estimate <inline-formula><mml:math id="inf147"><mml:mi>M</mml:mi></mml:math></inline-formula> well for <inline-formula><mml:math id="inf148"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), the estimate of the nonlinear network (<xref ref-type="fig" rid="fig3">Figure 3c</xref>) is a closer match to the true <inline-formula><mml:math id="inf149"><mml:mi>M</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). However, there is a tradeoff between the stabilizing effect of the nonlinearity and the potential loss of accuracy in calculating <inline-formula><mml:math id="inf150"><mml:mi>M</mml:mi></mml:math></inline-formula> with a nonlinearity (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>We explore an alternative strategy for computing <inline-formula><mml:math id="inf151"><mml:mi>M</mml:mi></mml:math></inline-formula> with arbitrarily high <inline-formula><mml:math id="inf152"><mml:mi>γ</mml:mi></mml:math></inline-formula> in the range <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>γ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. We have thus far pushed the limits of the model in learning the SR for different <inline-formula><mml:math id="inf154"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula>. However, an advantage of our recurrent architecture is that <inline-formula><mml:math id="inf155"><mml:mi>γ</mml:mi></mml:math></inline-formula> is a global gain modulated independently of the synaptic weights. Thus, an alternative strategy for computing <inline-formula><mml:math id="inf156"><mml:mi>M</mml:mi></mml:math></inline-formula> with high <inline-formula><mml:math id="inf157"><mml:mi>γ</mml:mi></mml:math></inline-formula> is to consider two distinct modes that the network can operate under. First, there is a learning phase in which the plasticity mechanism actively learns the structure of the environment and the model is in a stable regime (i.e. <inline-formula><mml:math id="inf158"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> is small). Separately, there is a retrieval phase during which the gain <inline-formula><mml:math id="inf159"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> of the network can be flexibly modulated. By changing the gain, the network can compute the SR with arbitrary prediction horizons, without any changes to the synaptic weights. We show the effectiveness of separate network phases by simulating a 1D walk where the learning phase uses a small <inline-formula><mml:math id="inf160"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Halfway through the walk, the animal enters a retrieval mode and accurately computes the SR with higher <inline-formula><mml:math id="inf161"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p><p>Under this scheme, the model can compute the SR for any <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The separation of learning and retrieval phases stabilizes neural dynamics and allows flexible tuning of predictive power depending on task context.</p></sec><sec id="s2-5"><title>RNN-S can be generalized to more complex inputs with successor features</title><p>We wondered how RNN-S performs given more biologically realistic inputs. We have so far assumed that an external process has discretized the environment into uncorrelated states so that each possible state is represented by a unique input neuron. In other words, the inputs <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are one-hot vectors. However, inputs into the hippocampus are expected to be continuous and heterogeneous, with states encoded by overlapping sets of neurons (<xref ref-type="bibr" rid="bib44">Hardcastle et al., 2017</xref>). When inputs are not one-hot, there is not always a canonical ground-truth <inline-formula><mml:math id="inf164"><mml:mi>T</mml:mi></mml:math></inline-formula> matrix to fit and the predictive representations are referred to as successor features (<xref ref-type="bibr" rid="bib6">Barreto et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Kulkarni et al., 2016</xref>). In this setting, the performance of a model estimating successor features is evaluated by the temporal difference (TD) loss function.</p><p>Using the RNN-S model and update rule (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), we explore more realistic inputs <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and refer to <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as ‘input features’ for consistency with the successor feature literature. We vary the sparsity and spatial correlation of the input features (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). As before (<xref ref-type="fig" rid="fig3">Figure 3H</xref>), the network will operate in separate learning and retrieval modes, where <inline-formula><mml:math id="inf167"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> is below the critical value for stability. Under these conditions, the update rule will learn<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>at steady state, where <inline-formula><mml:math id="inf168"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the correlation matrix of <inline-formula><mml:math id="inf169"><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:math></inline-formula> with time lag <inline-formula><mml:math id="inf170"><mml:mi>τ</mml:mi></mml:math></inline-formula> (Appendix 3). Thus, the RNN-S update rule has the effect of normalizing the input feature via a decorrelative factor (<inline-formula><mml:math id="inf171"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) and mapping the normalized input to the feature expected at the next time step in a STDP-like manner (<inline-formula><mml:math id="inf172"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). This interpretation generalizes the result that <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> in the one-hot encoding case (Appendix 3).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Generalizing the model to more realistic inputs.</title><p>(<bold>A</bold>) Illustration of possible feature encodings <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for two spatially adjacent states in green and red. Feature encodings may vary in sparsity level and spatial correlation. (<bold>B</bold>) Average value of the STDP component (red) and the decorrelative normalization (solid blue) component of the gradient update over the course of a random walk. In dashed blue is a simpler Oja-like independent normalization update for comparison. Twenty-five simulations of forward-biased walks on a circular track were run, and shading shows 95% confidence interval. Input features are 3% sparse, with 10 cm spatial correlation. (<bold>C</bold>) Top: Example population activity of neurons in the RNN-S using the full decorrelative normalization rule over a 2min window of a forward-biased random walk. Population activity is normalized by the maximum firing rate. Bottom: As above, but for RNN-S using the simplified normalization update. (<bold>D</bold>) Shifts in place field peaks after a half hour simulation from the first two minutes of a 1D walk. Proportion of shifts in RNN-S with one-hot inputs shown in gray. Proportion of shifts in RNN-S with feature encodings (10% sparsity, 7.5 cm spatial correlation, <inline-formula><mml:math id="inf175"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>) shown in blue. Each data point is the average shift observed in one simulated walk, and each histogram is over 40 simulated walks. Solid line indicates the reported measure from <xref ref-type="bibr" rid="bib81">Mehta et al., 2000</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Comparing place field shift and skew effects for different feature encodings.</title><p>(<bold>A–D</bold>) Average firing rate as a function of position on a circular track for four example neurons. The walk and feature encodings were generated as in <xref ref-type="fig" rid="fig4">Figure 4D</xref> of the main text. Each neuron is sampled from a different walk. ‘Before Learning’ refers to firing fields made from the first 2-minute window of the walk. ‘After Learning’ refers to firing fields made from the entire walk. (<bold>E–F</bold>) As in (<bold>A–D</bold>), but for two neurons from a walk where the features were one-hot encoded.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig4-figsupp1-v1.tif"/></fig></fig-group><p>We wanted to further explore the function of the normalization term. In the one-hot case, it operates over each synapse independently and makes a probability distribution. With more realistic inputs, it operates over a set of synapses and has a decorrelative effect. We first ask how the decorrelative term changes over learning of realistic inputs. We compare the mean value of the STDP term of the update (<inline-formula><mml:math id="inf176"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) to the normalization term of the update (<inline-formula><mml:math id="inf177"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>) during a sample walk (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). The RNN-S learning rule has stronger potentiating effects in the beginning of the walk. As the model learns more of the environment and converges on the correct transition structure, the strength of the normalization term balances out the potentiation term. It may be that the normalization term is particularly important in maintaining this balance as inputs become more densely encoded. We test this hypothesis by using a normalization term that operates on each synapse independently (similar to Oja’s Rule, <xref ref-type="bibr" rid="bib91">Oja, 1982</xref>, Appendix 5). We see that the equilibrium between potentiating and depressing effects is not achieved by this type of independent normalization (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, Appendix 6).</p><p>We wondered whether the decorrelative normalization term is necessary for the RNN-S to develop accurate representations. By replacing the decorrelative term with an independent normalization, features from non-adjacent states begin to be associated together and the model activity becomes spatially non-specific over time (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, top). In contrast, using the decorrelative term, the RNN-S population activity is more localized (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, bottom).</p><p>Interestingly, we noticed an additional feature of place maps as we transitioned from one-hot feature encodings to more complex feature encodings. We compared the representations learned by the RNN-S in a circular track walk with one-hot features versus more densely encoded features. For both input distributions, the RNN-S displayed the same skewing in place fields seen in <xref ref-type="fig" rid="fig2">Figure 2</xref> (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). However, the place field peaks of the RNN-S model additionally shifted backwards in space for the more complex feature encodings (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). This was not seen for the one-hot encodings (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). The shifting in the RNN-S model is consistent with the observations made in <xref ref-type="bibr" rid="bib81">Mehta et al., 2000</xref> and demonstrates the utility of considering more complex input conditions. A similar observation was made in <xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref> with noisy state inputs. In both cases, field shifts could be caused by neurons receiving external inputs at more than one state, particularly at states leading up to its original field location.</p></sec><sec id="s2-6"><title>RNN-S estimates successor features even with naturalistic trajectories</title><p>We ask whether RNN-S can accurately estimate successor features, particularly under conditions of natural behavior. Specifically, we used the dataset from <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>, gathered from foraging Tufted Titmice in a 2D arena (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). We discretize the arena into a set of states and encode each state as in Section 2.5. Using position-tracking data from <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>, we simulate the behavioral trajectory of the animal as transitions through the discrete state space. The inputs into the successor feature model are the features associated with the states in the behavioral trajectory.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Fitting successor features to data with RNN-S over a variety of feature encodings.</title><p>(<bold>A</bold>) We use behavioral data from Payne et al, where a Tufted Titmouse randomly forages in a 2D environment while electrophysiological data is collected (replicated with permission from authors). Two example trajectories are shown on the right. (<bold>B</bold>) Temporal difference (TD) loss versus the spatial correlation of the input dataset, aggregated over all sparsity levels. Here, <inline-formula><mml:math id="inf178"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula>. Line shows mean, and shading shows 95% confidence interval. (<bold>C</bold>) As in (<bold>B</bold>), but measuring TD loss versus the sparsity level of the input dataset, aggregated over all spatial correlation levels. (<bold>D</bold>) TD loss for RNN-S with datasets with different spatial correlations and sparsities. Gray areas were not represented in the input dataset due to the feature generation process. Here, <inline-formula><mml:math id="inf179"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula>, and three simulations were run for each spatial correlation and sparsity pairing under each chosen <inline-formula><mml:math id="inf180"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula>. (<bold>E</bold>) As in (<bold>G</bold>), but for FF-TD. (<bold>F</bold>) TD loss of each model as a function of <inline-formula><mml:math id="inf181"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula>, aggregated over all input encodings. Line shows mean, and shading shows 95% confidence interval.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Parameter sweep details and extended TD error plots.</title><p>(<bold>A</bold>) The values of P (initial sparsity of random vectors before spatial smoothing) and σ sampled in our parameter sweep for <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref> in the main text. See methods 4.10 for more details of how feature encodings were generated. (<bold>B</bold>) The values of S (final sparsity of features, measured after spatial smoothing) and σ sampled in our parameter sweep for <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref> in the main text. (<bold>C</bold>) A sample state encoded by the firing rate of 200 input neurons. Here, <inline-formula><mml:math id="inf182"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>0.11</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>D</bold>) As in <xref ref-type="fig" rid="fig5">Figure 5F</xref> of the main text, with the results from a random feedforward network included (“Shuffle”). The random network was constructed by randomly drawing weights from the distribution of weights learned by the FF-TD network. The random network is representative of a model without learned structure but with a similar magnitude of weights as the FF-TD model. (<bold>E</bold>) Spatial correlation of the feature encoding for an example state with the features of all other states. The <inline-formula><mml:math id="inf184"><mml:mrow><mml:mn>14</mml:mn><mml:mo>×</mml:mo><mml:mn>14</mml:mn></mml:mrow></mml:math></inline-formula> states are laid out in their position in the 2D arena. Here, the sample state is the state in the center of the 2D arena and <inline-formula><mml:math id="inf185"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>F</bold>) As in (<bold>E</bold>), but for <inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>G</bold>) As in <xref ref-type="fig" rid="fig5">Figure 5D</xref> of the main text, but for RNN-S (first row) and FF-TD (second row) with <inline-formula><mml:math id="inf187"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula> (left column), <inline-formula><mml:math id="inf188"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math></inline-formula> (middle column), and <inline-formula><mml:math id="inf189"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula> (right column).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig5-figsupp1-v1.tif"/></fig></fig-group><p>We first wanted to test whether the RNN-S model was robust across a range of different types of input features. We calculate the TD loss of the model as a function of the spatial correlation across inputs <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). We find that the model performs well across a range of inputs but loss is higher when inputs are spatially uncorrelated. This is consistent with the observation that behavioral transitions are spatially local, such that correlations across spatially adjacent features aid in the predictive power of the model. We next examine the model performance as a function of the sparsity of inputs <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). We find the model also performs well across a range of feature sparsity, with lowest loss when features are sparse.</p><p>To understand the interacting effects of spatial correlation and feature sparsity in more detail, we performed a parameter sweep over both of these parameters (<xref ref-type="fig" rid="fig5">Figure 5D</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A-F</xref>). We generated random patterns according to the desired sparsity and smoothness with a spatial filter to generate correlations. This means that the entire parameter space is not covered in our sweep (e.g. the top-left area with high correlation and high sparsity is not explored). Note that since we generate <inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> by randomly drawing patterns, the special case of one-hot encoding is also not included in the parameter sweep (one-hot encoding is already explored in <xref ref-type="fig" rid="fig2">Figure 2</xref>). The RNN-S seems to perform well across a wide range, with highest loss in regions of low spatial correlation and low sparsity.</p><p>We want to compare the TD loss of RNN-S to that of a non-biological model designed to minimize TD loss. We repeat the same parameter sweep over input features with the FF-TD model (<xref ref-type="fig" rid="fig5">Figure 5E</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1G</xref>). The FF-TD model performs similarly to the RNN-S model, with lower TD loss in regions with low sparsity or higher correlation. We also tested how the performance of both models is affected by the strength of <inline-formula><mml:math id="inf193"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). Both models show a similar increase in TD loss as <inline-formula><mml:math id="inf194"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> increases, although the RNN-S has a slightly lower TD loss at high <inline-formula><mml:math id="inf195"><mml:mi>γ</mml:mi></mml:math></inline-formula> than the FF-TD model. Both models perform substantially better than a random network with weights of comparable magnitude (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1D</xref>).</p><p>Unlike in the one-hot case, there is no ground-truth <inline-formula><mml:math id="inf196"><mml:mi>T</mml:mi></mml:math></inline-formula> matrix for non-one-hot inputs, so representations generated by RNN-S and FF-TD may look different, even at the same TD loss. Therefore, to compare the two models, it is important to compare representations to neural data.</p></sec><sec id="s2-7"><title>RNN-S fits neural data in a random foraging task</title><p>Finally, we tested whether the neural representations learned by the models with behavioral trajectories from <xref ref-type="fig" rid="fig5">Figure 5</xref> match hippocampal firing patterns. We performed new analysis on neural data from <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref> to establish a dataset for comparison. The neural data from <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref> was collected from electrophysiological recordings in titmouse hippocampus during freely foraging behavior (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref> discovered the presence of place cells in this area. We analyzed statistics of place cells recorded in the anterior region of the hippocampus, where homology with rodent dorsal hippocampus is hypothesized (<xref ref-type="bibr" rid="bib119">Tosches et al., 2018</xref>). We calculated the distribution of place field size measured relative to the arena size (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), as well as the distribution of the number of place fields per place cell (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). Interestingly, with similar analysis methods, <xref ref-type="bibr" rid="bib48">Henriksen et al., 2010</xref> see similar statistics in the proximal region of dorsal CA1 in rats, indicating that our analyses could be applicable across organisms.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Comparing place fields from RNN-S to data.</title><p>(<bold>A</bold>) Dataset is from Payne et al, where a Tufted Titmouse randomly forages in a 2D environment while electrophysiological data is collected (replicated with permission from authors). (<bold>B</bold>) Distribution of place cells with some number of fields, aggregated over all cells recorded in all birds. (<bold>C</bold>) Distribution of place cells with some field size as a ratio of the size of the arena, aggregated over all cells recorded in all birds. (<bold>D</bold>) Average proportion of non-place cells in RNN-S, aggregated over simulations of randomly drawn trajectories from Payne et al. Feature encodings are varied by spatial correlation and sparsity as in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Each simulation used 196 neurons. As before, three simulations were run for each spatial correlation and sparsity pairing under each chosen <inline-formula><mml:math id="inf197"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula>. (<bold>E</bold>) As in (<bold>D</bold>), but for average field size of place cells. (<bold>F</bold>) As in (<bold>D</bold>), but for average number of fields per place cell. (<bold>G</bold>) As in (<bold>D</bold>) and (<bold>E</bold>), but comparing place cell statistics using the KL divergence (<inline-formula><mml:math id="inf198"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) between RNN-S and data from Payne et al. At each combination of input spatial correlation and sparsity, the distribution of field sizes is compared to the neural data, as is the distribution of number of fields per neuron, then the two <inline-formula><mml:math id="inf199"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> values are summed. Contour lines are drawn at <inline-formula><mml:math id="inf200"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> values of 1, 1.5, and 2 bits. (<bold>H</bold>) Place fields of cells chosen from the region of lowest KL divergence. (<bold>I</bold>) As in (<bold>G</bold>) but for FF-TD. (<bold>J</bold>) Change in KL divergence for field size as function of <inline-formula><mml:math id="inf201"><mml:mi>γ</mml:mi></mml:math></inline-formula>. Line shows mean, and shading shows 95% confidence interval. (<bold>K</bold>) Same as (<bold>J</bold>), but for number of fields.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Extended place field evaluation plots.</title><p>(<bold>A</bold>) As in <xref ref-type="fig" rid="fig6">Figure 6E–G</xref> of the main text, but for <inline-formula><mml:math id="inf202"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula> (left column) and <inline-formula><mml:math id="inf203"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula> (right column). In addition, the plots showing KL divergence (in bits) for the distribution of field sizes and number of fields per cell are shown. (<bold>B</bold>) As in (<bold>A</bold>) but for FF-TD. (<bold>C</bold>) A in <xref ref-type="fig" rid="fig6">Figure 6H</xref> of the main text, but for FF-TD with <inline-formula><mml:math id="inf204"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula> and (<bold>D</bold>) FF-TD with <inline-formula><mml:math id="inf205"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>E</bold>) Total KL divergence across <inline-formula><mml:math id="inf206"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> for RNN-S, FF-TD, the random network from <xref ref-type="fig" rid="fig6">Figure 6D</xref> (‘Shuffle’), and the split-half noise floor from the Payne et al. dataset (‘Data’). This noise floor is calculated by comparing the place field statistics of a random halves of the neurons from Payne et al. We measure the KL divergence between the distributions calculated from each random half. This is repeated 500 times, and it is representative of a lower bound on KL divergence. Intuitively, it should not be possible to fit the data of Payne et al as well as the dataset itself can.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-fig6-figsupp1-v1.tif"/></fig></fig-group><p>In order to test how spatial representations in the RNN-S are impacted by input features, we performed parameter sweeps over input statistics. As in <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>, we define place cells in the model as cells with at least one statistically significant place field under permutation tests. Under most of the parameter range, all RNN-S neurons would be identified as a place cell (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). However, under conditions of high spatial correlation and low sparsity, a portion of neurons (12%) do not have any fields in the environment. These cells are excluded from further analysis. We measured how the size of place fields varies across the parameter range (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). The size of the fields increases as a function of the spatial correlation of the inputs, but is relatively insensitive to sparsity. This effect can be explained as the spatial correlation of the inputs introducing an additional spatial spread in the neural activity. Similarly, we measured how the number of place fields per cell varies across the parameter range (<xref ref-type="fig" rid="fig6">Figure 6F</xref>). The number of fields is maximal for conditions in which input features are densely encoded and spatial correlation is low. These are conditions in which each neuron receives inputs from multiple, spatially distant states.</p><p>Finally, we wanted to identify regions of parameter space that were similar to the data of <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>. We measured the KL divergence between our model’s place field statistics (<xref ref-type="fig" rid="fig6">Figure 6DE</xref>) and the statistics measured in <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref> (<xref ref-type="fig" rid="fig6">Figure 6BC</xref>). We combined the KL divergence of both these distributions to find the parameter range in which the RNN-S best fits neural data (<xref ref-type="fig" rid="fig6">Figure 6G</xref>). This optimal parameter range occurs when inputs have a spatial correlation of <inline-formula><mml:math id="inf207"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>≈</mml:mo><mml:mn>8.75</mml:mn></mml:mrow></mml:math></inline-formula> cm and sparsity <inline-formula><mml:math id="inf208"><mml:mrow><mml:mi/><mml:mo>≈</mml:mo><mml:mn>0.15</mml:mn></mml:mrow></mml:math></inline-formula>. We note that the split-half noise floor of the dataset of <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref> is a KL divergence of 0.12 bits (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1E</xref>). We can visually confirm that the model fits the data well by plotting the place fields of RNN-S neurons (<xref ref-type="fig" rid="fig6">Figure 6H</xref>).</p><p>We wondered whether the predictive gain (<inline-formula><mml:math id="inf209"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula>) of the representations affects the ability of the RNN-S to fit data. The KL divergence changes only slightly as a function of <inline-formula><mml:math id="inf210"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula>. Mainly, the KL-divergence of the place field size increases as <inline-formula><mml:math id="inf211"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> increases (<xref ref-type="fig" rid="fig6">Figure 6I</xref>), but little effect is seen in the distribution of the number of place fields per neuron (<xref ref-type="fig" rid="fig6">Figure 6J</xref>).</p><p>We next tested whether the neural data was better fit by representations generated by RNN-S or the FF-TD model. Across all parameters of the input features, despite having similar TD loss (<xref ref-type="fig" rid="fig5">Figure 5DE</xref>), the FF-TD model has much higher divergence from neural data (<xref ref-type="fig" rid="fig6">Figure 6GI</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>), similar to a random feedforward network (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1E</xref>).</p><p>Overall, our RNN-S model seems to strike a balance between performance in estimating successor features, similarity to data, and biological plausibility. Furthermore, our analyses provide a prediction of the input structure into the hippocampus that is otherwise not evident in an algorithmic description or in a model that only considers one-hot feature encodings.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Hippocampal memory is thought to support a wide range of cognitive processes, especially those that involve forming associations or making predictions. However, the neural mechanisms that underlie these computations in the hippocampus are not fully understood. A promising biological substrate is the recurrent architecture of the CA3 region of the hippocampus and the plasticity rules observed. Here, we showed how a recurrent network with local learning rules can implement the successor representation, a predictive algorithm that captures many observations of hippocampal activity. We used our neural circuit model to make specific predictions of biological processes in this region.</p><p>A key component of our plasticity rule is a decorrelative term that depresses synapses based on coincident activity. Such anti-Hebbian or inhibitory effects are hypothesized to be broadly useful for learning, especially in unsupervised learning with overlapping input features (<xref ref-type="bibr" rid="bib66">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="bib106">Sadeh and Clopath, 2021</xref>; <xref ref-type="bibr" rid="bib97">Pehlevan et al., 2018</xref>; <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>). Consistent with this hypothesis, anti-Hebbian learning has been implicated in circuits that perform a wide range of computations, from distinguishing patterns (<xref ref-type="bibr" rid="bib31">Földiák, 1990</xref>), to familiarity detection (<xref ref-type="bibr" rid="bib120">Tyulmankov et al., 2022</xref>), to learning birdsong syllables (<xref ref-type="bibr" rid="bib70">Mackevicius et al., 2020</xref>). This inhibitory learning may be useful because it decorrelates redundant information, allowing for greater specificity and capacity in a network (<xref ref-type="bibr" rid="bib106">Sadeh and Clopath, 2021</xref>; <xref ref-type="bibr" rid="bib31">Földiák, 1990</xref>). Our results provide further support of these hypotheses and predict that anti-Hebbian learning is fundamental to a predictive neural circuit.</p><p>We derive an adaptive learning rate that allows our model to quickly learn a probability distribution, and generally adds flexibility to the learning process. The adaptive learning rate changes such that neurons that are more recently active have a slower learning rate. This is consistent with experimental findings of metaplasticity at synapses (<xref ref-type="bibr" rid="bib2">Abraham and Bear, 1996</xref>; <xref ref-type="bibr" rid="bib3">Abraham, 2008</xref>; <xref ref-type="bibr" rid="bib51">Hulme et al., 2014</xref>), and theoretical proposals that metaplasticity tracks the uncertainty of information (<xref ref-type="bibr" rid="bib4">Aitchison et al., 2021</xref>). In RNN-S, the adaptive learning rate improves the speed of learning and better recapitulates hippocampal data. Our adaptive learning rate also has interesting implications for flexible learning. Memory systems must be able to quickly learn new associations throughout their lifetime without catastrophe. Our learning rate is parameterized by a forgetting term <inline-formula><mml:math id="inf212"><mml:mi>λ</mml:mi></mml:math></inline-formula> that controls the timescale in which environmental statistics are expected to be stationary. Although we fixed <inline-formula><mml:math id="inf213"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> in our simulations, there are computational benefits in considering cases where <inline-formula><mml:math id="inf214"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. This parameter provides a natural way for a memory system to forget gradually over time and prioritize recent experiences, in line with other theoretical studies that have also suggested that learning and forgetting on multiple timescales allow for more flexible behavior (<xref ref-type="bibr" rid="bib54">Kaplanis et al., 2018</xref>; <xref ref-type="bibr" rid="bib34">Fusi et al., 2007</xref>).</p><p>We tested the sensitivity of our network to various parameters and found a broad range of valid solutions. Prior work has sought to understand how an emergent property of a network could be generated by multiple unique solutions (<xref ref-type="bibr" rid="bib41">Goldman et al., 2001</xref>; <xref ref-type="bibr" rid="bib101">Prinz et al., 2004</xref>; <xref ref-type="bibr" rid="bib10">Bittner et al., 2021</xref>; <xref ref-type="bibr" rid="bib49">Hertäg and Clopath, 2022</xref>). It has been suggested that redundancy in solution space makes systems more robust, accounting for margins of error in the natural world (<xref ref-type="bibr" rid="bib71">Marder and Goaillard, 2006</xref>; <xref ref-type="bibr" rid="bib72">Marder and Taylor, 2011</xref>). In a similar vein, our parameter sweep over plasticity kernels revealed that a sizeable variety of kernels give solutions that resemble the SR. Although our model was initially sensitive to the value of <inline-formula><mml:math id="inf215"><mml:mi>γ</mml:mi></mml:math></inline-formula>, we found that adding biological components, such as nonlinear dynamics and separate network modes, broadened the solution space of the network.</p><p>Several useful features arise from the fact that RNN-S learns the transition matrix <inline-formula><mml:math id="inf216"><mml:mi>T</mml:mi></mml:math></inline-formula> directly, while separating out the prediction timescale, <inline-formula><mml:math id="inf217"><mml:mi>γ</mml:mi></mml:math></inline-formula>, as a global gain factor. It is important for animals to engage in different horizons of prediction depending on task or memory demands (<xref ref-type="bibr" rid="bib77">Mattar and Lengyel, 2022</xref>; <xref ref-type="bibr" rid="bib7">Bellmund et al., 2020</xref>). In RNN-S, changing the prediction time horizon is as simple as increasing or decreasing the global gain of the network. Mechanistically, this could be accomplished by a neuromodulatory gain factor that boosts <inline-formula><mml:math id="inf218"><mml:mi>γ</mml:mi></mml:math></inline-formula>, perhaps by increasing the excitability of all neurons (<xref ref-type="bibr" rid="bib47">Heckman et al., 2009</xref>; <xref ref-type="bibr" rid="bib89">Nadim and Bucher, 2014</xref>). In RNN-S, it was useful to have low network gain during learning (<inline-formula><mml:math id="inf219"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula>), while allowing higher gain during retrieval to make longer timescale predictions (<inline-formula><mml:math id="inf220"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula>). This could be accomplished by a neuromodulatory factor that switches the network into a learning regime (<xref ref-type="bibr" rid="bib94">Pawlak et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Brzosko et al., 2019</xref>), for example acetylcholine, which reduces the gain of recurrent connections and increases learning rates (<xref ref-type="bibr" rid="bib45">Hasselmo, 1999</xref>; <xref ref-type="bibr" rid="bib46">Hasselmo, 2006</xref>). The idea that the hippocampus might compute the SR with flexible <inline-formula><mml:math id="inf221"><mml:mi>γ</mml:mi></mml:math></inline-formula> could help reconcile recent results that hippocampal activity does not always match high-<inline-formula><mml:math id="inf222"><mml:mi>γ</mml:mi></mml:math></inline-formula> SR (<xref ref-type="bibr" rid="bib124">Widloski and Foster, 2022</xref>; <xref ref-type="bibr" rid="bib26">Duvelle et al., 2021</xref>). Additionally, flexibility in predictive horizons could explain the different timescales of prediction observed across the anatomical axes of the hippocampus and entorhinal cortex (<xref ref-type="bibr" rid="bib53">Jung et al., 1994</xref>; <xref ref-type="bibr" rid="bib25">Dolorfo and Amaral, 1998</xref>; <xref ref-type="bibr" rid="bib15">Brun et al., 2008</xref>; <xref ref-type="bibr" rid="bib57">Kjelstrup et al., 2008</xref>; <xref ref-type="bibr" rid="bib116">Strange et al., 2014</xref>; <xref ref-type="bibr" rid="bib100">Poppenk et al., 2013</xref>; <xref ref-type="bibr" rid="bib16">Brunec and Momennejad, 2022</xref>). Specifically, a series of successor networks with different values of <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> used in retrieval could establish a gradient of predictive timescales. Functionally, this may allow for learning hierarchies of state structure and could be useful for hierarchical planning (<xref ref-type="bibr" rid="bib78">McKenzie et al., 2014</xref>; <xref ref-type="bibr" rid="bib84">Momennejad and Howard, 2018</xref>; <xref ref-type="bibr" rid="bib104">Ribas-Fernandes et al., 2019</xref>).</p><p>Estimating <inline-formula><mml:math id="inf224"><mml:mi>T</mml:mi></mml:math></inline-formula> directly provides RNN-S with a means to sample likely future trajectories, or distributions of trajectories, which is computationally useful for many memory-guided cognitive tasks beyond reinforcement learning, including reasoning and inference (<xref ref-type="bibr" rid="bib93">Ostojic and Fusi, 2013</xref>; <xref ref-type="bibr" rid="bib43">Goodman et al., 2016</xref>). The representation afforded by <inline-formula><mml:math id="inf225"><mml:mi>T</mml:mi></mml:math></inline-formula> may also be particularly accessible in neural circuits. <xref ref-type="bibr" rid="bib93">Ostojic and Fusi, 2013</xref> note that only few general assumptions are needed for synaptic plasticity rules to estimate transition statistics. Thus, it is reasonable to assume that some form of transition statistics are encoded broadly across the brain.</p><p>Interestingly, we also found that the recurrent network fit hippocampal data better than a feedforward network. An interesting direction for further work involves untangling which brain areas and cognitive functions can be explained by deep (feed forward) neural networks (<xref ref-type="bibr" rid="bib12">Bonnen et al., 2021</xref>), and which rely on recurrent architectures, or even richer combinations of generative structures (<xref ref-type="bibr" rid="bib21">Das et al., 2021</xref>). Recurrent networks, such as RNN-S, support generative sequential sampling, reminiscent of hippocampal replay, which has been proposed as a substrate for planning, imagination, and structural inference (<xref ref-type="bibr" rid="bib32">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib111">Singer et al., 2013</xref>; <xref ref-type="bibr" rid="bib84">Momennejad and Howard, 2018</xref>; <xref ref-type="bibr" rid="bib28">Evans and Burgess, 2020</xref>; <xref ref-type="bibr" rid="bib56">Kay et al., 2020</xref>).</p><p>There are inherent limitations to the approach of using a recurrent network to estimate the SR. For instance, network dynamics can be prone to issues of instability due to the recurrent buildup of activity. To prevent this instability, we introduce two different modes of operation, ‘learning’ and ‘retrieval’. An additional limitation is that errors in the estimated one-step transition can propagate over the course of the predictive rollout. This is especially problematic if features are more densely coded or more correlated, which makes one-step transition estimations more difficult. These insights into vulnerabilities of a recurrent network have interesting parallels in biology. Some hippocampal subfields are known to be highly recurrent (<xref ref-type="bibr" rid="bib107">Schaffer, 1892</xref>; <xref ref-type="bibr" rid="bib102">Ramón and Cajal, 1904</xref>; <xref ref-type="bibr" rid="bib82">Miles and Wong, 1986</xref>; <xref ref-type="bibr" rid="bib63">Le Duigou et al., 2014</xref>). This recurrency has been linked to the propensity of the hippocampus to enter unstable regimes, such as those that produce seizures (<xref ref-type="bibr" rid="bib114">Sparks et al., 2020</xref>; <xref ref-type="bibr" rid="bib118">Thom, 2014</xref>; <xref ref-type="bibr" rid="bib68">Lothman et al., 1991</xref>; <xref ref-type="bibr" rid="bib58">Knight et al., 2012</xref>). It remains an open question how a healthy hippocampus maintains stable activity, and to what extent the findings in models such as ours can suggest biological avenues to tame instability.</p><p>Other recent theoretical works have also sought to find biological mechanisms to learn successor representations, albeit with different approaches (<xref ref-type="bibr" rid="bib14">Brea et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">de Cothi and Barry, 2020</xref>; <xref ref-type="bibr" rid="bib13">Bono et al., 2023</xref>; <xref ref-type="bibr" rid="bib64">Lee, 2022</xref>; <xref ref-type="bibr" rid="bib39">George et al., 2023</xref>). For instance, the model from <xref ref-type="bibr" rid="bib39">George et al., 2023</xref> explores a feedforward network that takes advantage of theta phase-precession to learn the SR. They analyze how place cells deform around boundaries and the function of the dorsal-ventral gradient in field size. The model introduced by <xref ref-type="bibr" rid="bib13">Bono et al., 2023</xref> uses a feedforward network with hippocampal replay. They explore how replay can modulate the bias-variance tradeoff of their SR estimate and apply their model to fear-conditioning data. It is important to note that these mechanisms are not mutually exclusive with RNN-S. Taken together with our work, these models suggest that there are multiple ways to learn the SR in a biological circuit and that these representations may be more accessible to neural circuits than previously thought.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Code availability</title><p>Code is posted on Github: <ext-link ext-link-type="uri" xlink:href="https://github.com/chingf/sr-project">https://github.com/chingf/sr-project</ext-link>; <xref ref-type="bibr" rid="bib29">Fang, 2022</xref>.</p></sec><sec id="s4-2"><title>Random walk simulations</title><p>We simulated random walks in 1D (circular track) and 2D (square) arenas. In 1D simulations, we varied the probability of staying in the current state and transitioning forwards or backwards to test different types of biases on top of a purely random walk. In 2D simulations, the probabilities of each possible action were equal. In our simulations, one timestep corresponds to 1/3 second and spatial bins are assumed to be 5 cm apart. This speed of movement (15 cm/s) was chosen to be consistent with previous experiments. In theory, one can imagine different choices of timestep size to access different time horizons of prediction– that is, the choice of timestep interacts with the choice of <inline-formula><mml:math id="inf226"><mml:mi>γ</mml:mi></mml:math></inline-formula> in determining the prediction horizon.</p></sec><sec id="s4-3"><title>RNN-S model</title><p>This section provides details and pseudocode of the RNN-S simulation. Below are explanations of the most relevant variables:</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="middle"><inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">Number of states, also equal to the number of neurons in the RNN</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf228"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">N-length vector of RNN neural activity</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf229"><mml:mi>J</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf230"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>  synaptic weight matrix</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf231"><mml:mi>M</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf232"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>  SR matrix</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf233"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf234"><mml:mi>N</mml:mi></mml:math></inline-formula>-length input vector into network</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf235"><mml:mi>b</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">binary variable indicating learning (0) or retrieval (1) mode</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf236"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Value of <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> the network uses to calculate <inline-formula><mml:math id="inf238"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in learning mode</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf239"><mml:msub><mml:mi>γ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">Value of <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> the network uses to calculate <inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> in retrieval mode</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf242"><mml:mi mathvariant="bold-italic">n</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">Variable that tracks the activity of neurons integrated over time</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf243"><mml:mi>λ</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">Discount value the network uses to calculate <inline-formula><mml:math id="inf244"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf245"><mml:mi mathvariant="bold-italic">η</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">Learning rate</td></tr></tbody></table></table-wrap><p>The RNN-S algorithm is as follows:</p><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="bottom"><bold>Algorithm 1</bold> RNN-S.</td></tr><tr><td align="left" valign="bottom"><bold>Inputs:</bold><break/>  <inline-formula><mml:math id="inf246"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf247"><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula><break/>  <inline-formula><mml:math id="inf248"><mml:mrow><mml:mi>b</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf249"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/><bold>Initialize:</bold><break/>  <inline-formula><mml:math id="inf250"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>J</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mn mathvariant="bold">0</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>  <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mn mathvariant="bold">0</mml:mn><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>  <inline-formula><mml:math id="inf252"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mn mathvariant="bold">0</mml:mn><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> <break/><bold>for</bold> <inline-formula><mml:math id="inf254"><mml:mrow><mml:mi>t</mml:mi><mml:mo mathvariant="normal">∈</mml:mo><mml:mrow><mml:mn mathvariant="normal">1</mml:mn><mml:mo mathvariant="normal">,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo mathvariant="normal">,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> <bold>do</bold> <break/>  <bold>if</bold> <inline-formula><mml:math id="inf255"><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo mathvariant="normal" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo mathvariant="normal" stretchy="false">)</mml:mo></mml:mrow><mml:mo mathvariant="normal">=</mml:mo><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">1</mml:mn></mml:mrow></mml:math></inline-formula> <bold>then</bold>                                // Retrieval Mode <break/>    <inline-formula><mml:math id="inf256"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">←</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>    <inline-formula><mml:math id="inf257"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">←</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/>  <bold>else</bold>                                        // Learning Mode <break/>    <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">←</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>    <inline-formula><mml:math id="inf259"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">←</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>    <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>                           // Learning rate update <break/>    <inline-formula><mml:math id="inf261"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>J</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>            // Calculate weight update <break/>    <inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>                    // Get learning rates (elementwise inversion) <break/>    <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="monospace">min</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo>,</mml:mo><mml:mn>1.0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>                        // Learning rates can’t exceed 1.0 <break/>    <inline-formula><mml:math id="inf264"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                      // Update synaptic weight matrix<break/>  <bold>end if</bold><break/><bold>end for</bold><break/>return <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s4-4"><title>RNN-S with plasticity kernels</title><p>We introduce additional kernel-related variables to the RNN-S model above that are optimized by an evolutionary algorithm (see following methods subsection for more details):</p><table-wrap id="inlinetable3" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td align="center" valign="bottom"><inline-formula><mml:math id="inf266"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="bottom">pre→ post side of the plasticity kernel <inline-formula><mml:math id="inf267"><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="center" valign="bottom"><inline-formula><mml:math id="inf268"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="center" valign="bottom">As above, but for the post→ pre side</td></tr><tr><td align="center" valign="bottom"><inline-formula><mml:math id="inf269"><mml:msub><mml:mi>α</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">Scaling term to allow for different self-synapse updates</td></tr><tr><td align="center" valign="bottom"><inline-formula><mml:math id="inf270"><mml:msub><mml:mi>α</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:math></inline-formula></td><td align="center" valign="bottom">Scaling term to allow for different learning rate updates</td></tr></tbody></table></table-wrap><p>We also define the variable <inline-formula><mml:math id="inf271"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>, which is the length of the temporal support for the plasticity kernel. The value of <italic>t</italic><sub><italic>k</italic></sub> was chosen such that <inline-formula><mml:math id="inf272"><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:math></inline-formula> was negligibly small for the range of <inline-formula><mml:math id="inf273"><mml:mi>τ</mml:mi></mml:math></inline-formula> we were interested in. The update algorithm is the same as in Algorithm 1, except lines 15-16 are replaced with the following:</p><table-wrap id="inlinetable4" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Algorithm 2 Plasticity kernel update</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>                               // Learning rate update<break/><inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>               // Convolution with plasticity kernel<break/><inline-formula><mml:math id="inf276"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula><break/><inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:mrow><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>         // Calculate contribution to update from plasticity kernel<break/><inline-formula><mml:math id="inf278"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:mrow><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>               // Updates to self-synapses use separate scaling<break/><inline-formula><mml:math id="inf279"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>J</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>                       // Calculate weight update</td></tr></tbody></table></table-wrap></sec><sec id="s4-5"><title>Metalearning of RNN parameters</title><p>To learn parameters of the RNN-S model, we use covariance matrix adaptation evolution strategy (CMA-ES) to learn the parameters of the plasticity rule. The training data provided are walks simulated from a random distribution of 1D walks. Walks varied in the number of states, the transition statistics, and the number of timesteps simulated. The loss function was the mean-squared error (MSE) loss between the RNN <inline-formula><mml:math id="inf280"><mml:mi>J</mml:mi></mml:math></inline-formula> matrix and the ideal estimated <inline-formula><mml:math id="inf281"><mml:mi>T</mml:mi></mml:math></inline-formula> matrix at the end of the walk.</p></sec><sec id="s4-6"><title>RNN-S with truncated recurrent steps and nonlinearity</title><p>For the RNN-S model with <inline-formula><mml:math id="inf282"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> recurrent steps, lines 10 and 13 in Algorithm 1 is replaced with <inline-formula><mml:math id="inf283"><mml:mrow><mml:msup><mml:mi>M</mml:mi><mml:mo>⊺</mml:mo></mml:msup><mml:mo>←</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:msubsup><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>J</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>For RNN-S with nonlinear dynamics, there is no closed form solution. So, we select a value for <inline-formula><mml:math id="inf284"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and replace lines 10 and 13 in Algorithm 1 with an iterative update for <inline-formula><mml:math id="inf285"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> steps: <inline-formula><mml:math id="inf286"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:mrow><mml:mtext mathvariant="monospace">tanh</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. We choose <inline-formula><mml:math id="inf287"><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> such that <inline-formula><mml:math id="inf288"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>γ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-7"><title>RNN-S with successor features</title><p>We use a tanh nonlinearity as described above. For simplicity, we set <inline-formula><mml:math id="inf289"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-8"><title>RNN-S with independent normalization</title><p>As in Algorithm 1, but with the following in place of line 16<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-9"><title>FF-TD Model</title><p>In all simulations of the FF-TD model, we use the temporal difference update. We perform a small grid search over the learning rate <inline-formula><mml:math id="inf290"><mml:mi>η</mml:mi></mml:math></inline-formula> to minimize error (for SR, this is the MSE between the true <inline-formula><mml:math id="inf291"><mml:mi>M</mml:mi></mml:math></inline-formula> and estimated <inline-formula><mml:math id="inf292"><mml:mi>M</mml:mi></mml:math></inline-formula>; for successor features, this is the temporal difference error). In the one-hot SR case, the temporal difference update given an observed transition from state <inline-formula><mml:math id="inf293"><mml:mi>s</mml:mi></mml:math></inline-formula> to state <inline-formula><mml:math id="inf294"><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> is:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:mi>γ</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>if </mml:mtext><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>otherwise</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>for all synapses <inline-formula><mml:math id="inf295"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>. Given arbitrarily structured inputs (as in the successor feature case), the temporal difference update is:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>M</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>M</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>or, equivalently,<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-10"><title>Generation of feature encodings for successor feature models</title><p>For a walk with <inline-formula><mml:math id="inf296"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> states, we created <inline-formula><mml:math id="inf297"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>-dimensional feature vectors for each state. We choose an initial sparsity probability <inline-formula><mml:math id="inf298"><mml:mi>p</mml:mi></mml:math></inline-formula> and create feature vectors as random binary vectors with probability <inline-formula><mml:math id="inf299"><mml:mi>p</mml:mi></mml:math></inline-formula> of being ‘on’. The feature vectors were then blurred by a 2D Gaussian filter with variance <inline-formula><mml:math id="inf300"><mml:mi>σ</mml:mi></mml:math></inline-formula> with 1 standard deviation of support. The blurred features were then min-subtracted and max-normalized. The sparsity of each feature vector was calculated as the L1 norm divided by <inline-formula><mml:math id="inf301"><mml:mi>N</mml:mi></mml:math></inline-formula>. The sparsity <inline-formula><mml:math id="inf302"><mml:mi>s</mml:mi></mml:math></inline-formula> of the dataset then was the median of all the sparsity values computed from the feature vectors. To vary the spatial correlation of the dataset we need only vary <inline-formula><mml:math id="inf303"><mml:mi>σ</mml:mi></mml:math></inline-formula>. To vary the sparsity <inline-formula><mml:math id="inf304"><mml:mi>s</mml:mi></mml:math></inline-formula> of the dataset we need to vary <inline-formula><mml:math id="inf305"><mml:mi>p</mml:mi></mml:math></inline-formula>, then measure the final <inline-formula><mml:math id="inf306"><mml:mi>s</mml:mi></mml:math></inline-formula> after blurring with <inline-formula><mml:math id="inf307"><mml:mi>σ</mml:mi></mml:math></inline-formula>. Note that, at large <inline-formula><mml:math id="inf308"><mml:mi>σ</mml:mi></mml:math></inline-formula>, the lowest sparsity values in our parameter sweep were not possible to achieve.</p></sec><sec id="s4-11"><title>Measuring TD loss for successor feature models</title><p>We use the standard TD loss function (<xref ref-type="disp-formula" rid="equ18">Equation 18</xref>). To measure TD loss, at the end of the walk we take a random sample of observed transition pairs <inline-formula><mml:math id="inf309"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. We use these transitions as the dataset to evaluate the loss function.</p></sec><sec id="s4-12"><title>Analysis of place field statistics</title><p>We use the open source dataset from <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>. We select for excitatory cells in the anterior tip of the hippocampus. We then select for place cells using standard measures (significantly place-modulated and stable over the course of the experiment).</p><p>We determined place field boundaries with a permutation test as in <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>. We then calculated the number of fields per neuron and the field size as in <xref ref-type="bibr" rid="bib48">Henriksen et al., 2010</xref>. The same analyses were conducted for simulated neural data from the RNN-S and FF-TD models.</p></sec><sec id="s4-13"><title>Behavioral simulation of Payne et al</title><p>We use behavioral tracking data from <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>. For each simulation, we randomly select an experiment and randomly sample a 28-min window from that experiment. If the arena coverage is less than 85% during the window, we redo the sampling until the coverage requirement is satisfied. We then downsample the behavioral data so that the frame rate is the same as our simulation (3 FPS). Then, we divide the arena into a <inline-formula><mml:math id="inf310"><mml:mrow><mml:mn>14</mml:mn><mml:mo>×</mml:mo><mml:mn>14</mml:mn></mml:mrow></mml:math></inline-formula> grid. We discretize the continuous X/Y location data into these states. This sequence of states makes up the behavioral transitions that the model simulates.</p></sec><sec id="s4-14"><title>Place field plots</title><p>From the models, we get the activity of each model neuron over time. We make firing field plots with the same smoothing parameters as <xref ref-type="bibr" rid="bib95">Payne et al., 2021</xref>.</p></sec><sec id="s4-15"><title>Citation diversity statement</title><p>Systemic discriminatory practices have been identified in neuroscience citations, and a ‘citation diversity statement’ has been proposed as an intervention (<xref ref-type="bibr" rid="bib27">Dworkin et al., 2020</xref>; <xref ref-type="bibr" rid="bib127">Zurn et al., 2020</xref>). There is evidence that quantifying discriminatory practices can lead to systemic improvements in academic settings (<xref ref-type="bibr" rid="bib50">Hopkins, 2002</xref>). Many forms of discrimination could lead to a paper being under-cited, for example authors being less widely known or less respected due to discrimination related to gender, race, sexuality, disability status, or socioeconomic background. We manually estimated the number of male and female first and last authors that we cited, acknowledging that this quantification ignores many known forms of discrimination, and fails to account for nonbinary/intersex/trans folks. In our citations, first-last author pairs were 62% male-male, 19% female-male, 9% male-female, and 10% female-female, somewhat similar to base rates in our field (biaswatchneuro.com). To familiarize ourselves with the literature, we used databases intended to counteract discrimination (blackinneuro.com, anneslist.net, connectedpapers.com). The process of making this statement improved our paper, and encouraged us to adopt less biased practices in selecting what papers to read and cite in the future. We were somewhat surprised and disappointed at how low the number of female authors were, despite being a female-female team ourselves. Citation practices alone are not enough to correct the power imbalances endemic in academic practice <xref ref-type="bibr" rid="bib90">National Academies of Sciences, 2018</xref> — this requires corrections to how concrete power and resources are distributed.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Software, Formal analysis, Funding acquisition, Validation, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Software, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-80680-transrepform1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. Modelling code is publicly available on GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/chingf/sr-project">https://github.com/chingf/sr-project</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:7d0694e03e241f453e530eeb5dd850a85d929de6;origin=https://github.com/chingf/sr-project;visit=swh:1:snp:802a8c5651d1f4615916bbae5ac7d25d89e63748;anchor=swh:1:rev:43320e9b8c15927c67849f768d2a9bf17f68a0ea">swh:1:rev:43320e9b8c15927c67849f768d2a9bf17f68a0ea</ext-link>).</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Payne</surname><given-names>H</given-names></name><name><surname>Lynch</surname><given-names>G</given-names></name><name><surname>Aronov</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Neural representations of space in the hippocampus of a food-caching bird</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.pg4f4qrp7</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported through NSF NeuroNex Award DBI-1707398, the Gatsby Charitable Foundation, the New York Stem Cell Foundation (Robertson Neuroscience Investigator Award), National Institutes of Health (NIH Director’s New Innovator Award (DP2-AG071918)), and the Arnold and Mabel Beckman Foundation (Beckman Young Investigator Award). CF received support from the NSF Graduate Research Fellowship Program. ELM received support from the Simons Society of Fellows. We thank Jack Lindsey and Tom George for comments on the manuscript, as well as Stefano Fusi, William de Cothi, Kimberly Stachenfeld, and Caswell Barry for helpful discussions.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Blum</surname><given-names>KI</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Functional significance of long-term potentiation for sequence learning and prediction</article-title><source>Cerebral Cortex</source><volume>6</volume><fpage>406</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1093/cercor/6.3.406</pub-id><pub-id pub-id-type="pmid">8670667</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>WC</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Metaplasticity: the plasticity of synaptic plasticity</article-title><source>Trends in Neurosciences</source><volume>19</volume><fpage>126</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/s0166-2236(96)80018-x</pub-id><pub-id pub-id-type="pmid">8658594</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>WC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Metaplasticity: tuning synapses and networks for plasticity</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>387</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1038/nrn2356</pub-id><pub-id pub-id-type="pmid">18401345</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aitchison</surname><given-names>L</given-names></name><name><surname>Jegminat</surname><given-names>J</given-names></name><name><surname>Menendez</surname><given-names>JA</given-names></name><name><surname>Pfister</surname><given-names>JP</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Synaptic plasticity as Bayesian inference</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>565</fpage><lpage>571</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00809-5</pub-id><pub-id pub-id-type="pmid">33707754</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amarimber</surname><given-names>S-I</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Characteristics of random nets of analog neuron-like elements</article-title><source>IEEE Transactions on Systems, Man, and Cybernetics</source><volume>SMC-2</volume><fpage>643</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1109/TSMC.1972.4309193</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Barreto</surname><given-names>A</given-names></name><name><surname>Dabney</surname><given-names>W</given-names></name><name><surname>Munos</surname><given-names>R</given-names></name><name><surname>Hunt</surname><given-names>JJ</given-names></name><name><surname>Schaul</surname><given-names>T</given-names></name><name><surname>Hasselt</surname><given-names>HP</given-names></name><name><surname>Silver</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Successor Features for Transfer in Reinforcement Learning</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1606.05312">https://arxiv.org/abs/1606.05312</ext-link></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JLS</given-names></name><name><surname>Polti</surname><given-names>I</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Sequence memory in the hippocampal-entorhinal region</article-title><source>Journal of Cognitive Neuroscience</source><volume>32</volume><fpage>2056</fpage><lpage>2070</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01592</pub-id><pub-id pub-id-type="pmid">32530378</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bi</surname><given-names>GQ</given-names></name><name><surname>Poo</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>10464</fpage><lpage>10472</lpage><pub-id pub-id-type="pmid">9852584</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname><given-names>KC</given-names></name><name><surname>Grienberger</surname><given-names>C</given-names></name><name><surname>Vaidya</surname><given-names>SP</given-names></name><name><surname>Milstein</surname><given-names>AD</given-names></name><name><surname>Macklin</surname><given-names>JJ</given-names></name><name><surname>Suh</surname><given-names>J</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Conjunctive input processing drives feature selectivity in hippocampal CA1 neurons</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1133</fpage><lpage>1142</lpage><pub-id pub-id-type="doi">10.1038/nn.4062</pub-id><pub-id pub-id-type="pmid">26167906</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname><given-names>SR</given-names></name><name><surname>Palmigiano</surname><given-names>A</given-names></name><name><surname>Piet</surname><given-names>AT</given-names></name><name><surname>Duan</surname><given-names>CA</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Cunningham</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Interrogating theoretical models of neural computation with emergent property inference</article-title><source>eLife</source><volume>10</volume><elocation-id>e56265</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56265</pub-id><pub-id pub-id-type="pmid">34323690</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blum</surname><given-names>KI</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A model of spatial MAP formation in the hippocampus of the rat</article-title><source>Neural Computation</source><volume>8</volume><fpage>85</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1162/neco.1996.8.1.85</pub-id><pub-id pub-id-type="pmid">8564805</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnen</surname><given-names>T</given-names></name><name><surname>Yamins</surname><given-names>DLK</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>When the ventral visual stream is not enough: a deep learning account of medial temporal lobe involvement in perception</article-title><source>Neuron</source><volume>109</volume><fpage>2755</fpage><lpage>2766</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.06.018</pub-id><pub-id pub-id-type="pmid">34265252</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bono</surname><given-names>J</given-names></name><name><surname>Zannone</surname><given-names>S</given-names></name><name><surname>Pedrosa</surname><given-names>V</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Learning predictive cognitive maps with spiking neurons during behaviour and replays</article-title><source>eLife</source><volume>12</volume><elocation-id>e80671</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.80671</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brea</surname><given-names>J</given-names></name><name><surname>Gaál</surname><given-names>AT</given-names></name><name><surname>Urbanczik</surname><given-names>R</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Prospective coding by spiking neurons</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005003</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005003</pub-id><pub-id pub-id-type="pmid">27341100</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brun</surname><given-names>VH</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Kjelstrup</surname><given-names>KB</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Progressive increase in grid scale from dorsal to ventral medial entorhinal cortex</article-title><source>Hippocampus</source><volume>18</volume><fpage>1200</fpage><lpage>1212</lpage><pub-id pub-id-type="doi">10.1002/hipo.20504</pub-id><pub-id pub-id-type="pmid">19021257</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname><given-names>IK</given-names></name><name><surname>Momennejad</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Predictive representations in hippocampal and prefrontal hierarchies</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>299</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1327-21.2021</pub-id><pub-id pub-id-type="pmid">34799416</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brzosko</surname><given-names>Z</given-names></name><name><surname>Mierau</surname><given-names>SB</given-names></name><name><surname>Paulsen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuromodulation of spike-timing-dependent plasticity: past, present, and future</article-title><source>Neuron</source><volume>103</volume><fpage>563</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.041</pub-id><pub-id pub-id-type="pmid">31437453</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bubic</surname><given-names>A</given-names></name><name><surname>von Cramon</surname><given-names>DY</given-names></name><name><surname>Schubotz</surname><given-names>RI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Prediction, cognition and the brain</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>25</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00025</pub-id><pub-id pub-id-type="pmid">20631856</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burbank</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mirrored STDP implements autoencoder learning in a network of spiking neurons</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004566</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004566</pub-id><pub-id pub-id-type="pmid">26633645</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corkin</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>What’s new with the amnesic patient h.m.?</article-title><source>Nature Reviews. Neuroscience</source><volume>3</volume><fpage>153</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1038/nrn726</pub-id><pub-id pub-id-type="pmid">11836523</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Das</surname><given-names>R</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Solar-Lezama</surname><given-names>A</given-names></name><name><surname>Tavares</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Autumnsynth: synthesis of reactive programs with structured latent state</article-title><conf-name>Advances in Programming Languages and Neurosymbolic Systems Workshop; 2021</conf-name></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Improving generalization for temporal difference learning: the successor representation</article-title><source>Neural Computation</source><volume>5</volume><fpage>613</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1162/neco.1993.5.4.613</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems</source><publisher-loc>Massachusetts, United States</publisher-loc><publisher-name>The MIT Press</publisher-name></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Cothi</surname><given-names>W</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neurobiological successor features for spatial navigation</article-title><source>Hippocampus</source><volume>30</volume><fpage>1347</fpage><lpage>1355</lpage><pub-id pub-id-type="doi">10.1002/hipo.23246</pub-id><pub-id pub-id-type="pmid">32584491</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolorfo</surname><given-names>CL</given-names></name><name><surname>Amaral</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Entorhinal cortex of the rat: topographic organization of the cells of origin of the perforant path projection to the dentate gyrus</article-title><source>The Journal of Comparative Neurology</source><volume>398</volume><fpage>25</fpage><lpage>48</lpage><pub-id pub-id-type="pmid">9703026</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duvelle</surname><given-names>É</given-names></name><name><surname>Grieves</surname><given-names>RM</given-names></name><name><surname>Liu</surname><given-names>A</given-names></name><name><surname>Jedidi-Ayoub</surname><given-names>S</given-names></name><name><surname>Holeniewska</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>A</given-names></name><name><surname>Nyberg</surname><given-names>N</given-names></name><name><surname>Donnarumma</surname><given-names>F</given-names></name><name><surname>Lefort</surname><given-names>JM</given-names></name><name><surname>Jeffery</surname><given-names>KJ</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Pezzulo</surname><given-names>G</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Hippocampal place cells encode global location but not connectivity in a complex space</article-title><source>Current Biology</source><volume>31</volume><fpage>1221</fpage><lpage>1233</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.01.005</pub-id><pub-id pub-id-type="pmid">33581073</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dworkin</surname><given-names>JD</given-names></name><name><surname>Linn</surname><given-names>KA</given-names></name><name><surname>Teich</surname><given-names>EG</given-names></name><name><surname>Zurn</surname><given-names>P</given-names></name><name><surname>Shinohara</surname><given-names>RT</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The extent and drivers of gender imbalance in neuroscience reference Lists</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>918</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0658-y</pub-id><pub-id pub-id-type="pmid">32561883</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>T</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Replay as Structural Inference in the Hippocampal-Entorhinal System</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.08.07.241547</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Sr-project</data-title><version designator="swh:1:rev:43320e9b8c15927c67849f768d2a9bf17f68a0ea">swh:1:rev:43320e9b8c15927c67849f768d2a9bf17f68a0ea</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:7d0694e03e241f453e530eeb5dd850a85d929de6;origin=https://github.com/chingf/sr-project;visit=swh:1:snp:802a8c5651d1f4615916bbae5ac7d25d89e63748;anchor=swh:1:rev:43320e9b8c15927c67849f768d2a9bf17f68a0ea">https://archive.softwareheritage.org/swh:1:dir:7d0694e03e241f453e530eeb5dd850a85d929de6;origin=https://github.com/chingf/sr-project;visit=swh:1:snp:802a8c5651d1f4615916bbae5ac7d25d89e63748;anchor=swh:1:rev:43320e9b8c15927c67849f768d2a9bf17f68a0ea</ext-link></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>CZH</given-names></name><name><surname>Hahnloser</surname><given-names>RHR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spike-time-dependent plasticity and heterosynaptic competition organize networks to produce long scale-free sequences of neural activity</article-title><source>Neuron</source><volume>65</volume><fpage>563</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.003</pub-id><pub-id pub-id-type="pmid">20188660</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Földiák</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Forming sparse representations by local anti-hebbian learning</article-title><source>Biol Cybern</source><volume>64</volume><fpage>165</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1007/BF02331346</pub-id><pub-id pub-id-type="pmid">2291903</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title><source>Nature</source><volume>440</volume><fpage>680</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/nature04587</pub-id><pub-id pub-id-type="pmid">16474382</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><source>An Introduction to Model-Based Cognitive Neuroscience</source><publisher-loc>New York, NY</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Asaad</surname><given-names>WF</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A neural circuit model of flexible sensorimotor mapping: learning and forgetting on multiple timescales</article-title><source>Neuron</source><volume>54</volume><fpage>319</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.03.017</pub-id><pub-id pub-id-type="pmid">17442251</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gardner-Medwin</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>The recall of events through the learning of associations between their parts</article-title><source>Proceedings of the Royal Society of London. Series B, Biological Sciences</source><volume>194</volume><fpage>375</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1098/rspb.1976.0084</pub-id><pub-id pub-id-type="pmid">11493</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garvert</surname><given-names>MM</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A map of abstract relational knowledge in the human hippocampal-entorhinal cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e17086</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17086</pub-id><pub-id pub-id-type="pmid">28448253</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geerts</surname><given-names>JP</given-names></name><name><surname>Chersi</surname><given-names>F</given-names></name><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A general model of hippocampal and dorsal striatal learning and decision making</article-title><source>PNAS</source><volume>117</volume><fpage>31427</fpage><lpage>31437</lpage><pub-id pub-id-type="doi">10.1073/pnas.2007981117</pub-id><pub-id pub-id-type="pmid">33229541</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>George</surname><given-names>D</given-names></name><name><surname>Rikhye</surname><given-names>RV</given-names></name><name><surname>Gothoskar</surname><given-names>N</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Dedieu</surname><given-names>A</given-names></name><name><surname>Lázaro-Gredilla</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps</article-title><source>Nature Communications</source><volume>12</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1038/s41467-021-22559-5</pub-id><pub-id pub-id-type="pmid">33888694</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>George</surname><given-names>TM</given-names></name><name><surname>de Cothi</surname><given-names>W</given-names></name><name><surname>Stachenfeld</surname><given-names>K</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Rapid learning of predictive maps with STDP and theta phase precession</article-title><source>eLife</source><volume>12</volume><elocation-id>e80663</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.80663</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Moore</surname><given-names>CD</given-names></name><name><surname>Todd</surname><given-names>MT</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Sederberg</surname><given-names>PB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The successor representation and temporal context</article-title><source>Neural Computation</source><volume>24</volume><fpage>1553</fpage><lpage>1568</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00282</pub-id><pub-id pub-id-type="pmid">22364500</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname><given-names>MS</given-names></name><name><surname>Golowasch</surname><given-names>J</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Global structure, robustness, and modulation of neuronal models</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>5229</fpage><lpage>5238</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-14-05229.2001</pub-id><pub-id pub-id-type="pmid">11438598</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Memory without feedback in a neural network</article-title><source>Neuron</source><volume>61</volume><fpage>621</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.012</pub-id><pub-id pub-id-type="pmid">19249281</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>ND</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Contributors</surname><given-names>TP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Probabilistic Models of Cognition</article-title><ext-link ext-link-type="uri" xlink:href="http://probmods.org/">http://probmods.org/</ext-link><date-in-citation iso-8601-date="2022-05-03">May 3, 2022</date-in-citation></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardcastle</surname><given-names>K</given-names></name><name><surname>Maheswaranathan</surname><given-names>N</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A multiplexed, heterogeneous, and adaptive code for navigation in medial entorhinal cortex</article-title><source>Neuron</source><volume>94</volume><fpage>375</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.025</pub-id><pub-id pub-id-type="pmid">28392071</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neuromodulation: acetylcholine and memory consolidation</article-title><source>Trends in Cognitive Sciences</source><volume>3</volume><fpage>351</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(99)01365-0</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The role of acetylcholine in learning and memory</article-title><source>Current Opinion in Neurobiology</source><volume>16</volume><fpage>710</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2006.09.002</pub-id><pub-id pub-id-type="pmid">17011181</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heckman</surname><given-names>CJ</given-names></name><name><surname>Mottram</surname><given-names>C</given-names></name><name><surname>Quinlan</surname><given-names>K</given-names></name><name><surname>Theiss</surname><given-names>R</given-names></name><name><surname>Schuster</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Motoneuron excitability: the importance of neuromodulatory inputs</article-title><source>Clinical Neurophysiology</source><volume>120</volume><fpage>2040</fpage><lpage>2054</lpage><pub-id pub-id-type="doi">10.1016/j.clinph.2009.08.009</pub-id><pub-id pub-id-type="pmid">19783207</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henriksen</surname><given-names>EJ</given-names></name><name><surname>Colgin</surname><given-names>LL</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Spatial representation along the proximodistal axis of CA1</article-title><source>Neuron</source><volume>68</volume><fpage>127</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.08.042</pub-id><pub-id pub-id-type="pmid">20920796</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hertäg</surname><given-names>L</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Prediction-error neurons in circuits with multiple neuron types: formation, refinement, and functional implications</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2115699119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2115699119</pub-id><pub-id pub-id-type="pmid">35320037</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopkins</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A study on the status of women faculty in science at mit in AIP conference proceedings</article-title><source>American Institute of Physics</source><volume>628</volume><fpage>103</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1063/1.1505288</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hulme</surname><given-names>SR</given-names></name><name><surname>Jones</surname><given-names>OD</given-names></name><name><surname>Raymond</surname><given-names>CR</given-names></name><name><surname>Sah</surname><given-names>P</given-names></name><name><surname>Abraham</surname><given-names>WC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mechanisms of heterosynaptic metaplasticity</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>369</volume><elocation-id>1633</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0148</pub-id><pub-id pub-id-type="pmid">24298150</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>How environmental movement constraints shape the neural code for space</article-title><source>Cognitive Processing</source><volume>22</volume><fpage>97</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1007/s10339-021-01045-2</pub-id><pub-id pub-id-type="pmid">34351539</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>Wiener</surname><given-names>SI</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Comparison of spatial firing characteristics of units in dorsal and ventral hippocampus of the rat</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>7347</fpage><lpage>7356</lpage><pub-id pub-id-type="pmid">7996180</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kaplanis</surname><given-names>C</given-names></name><name><surname>Shanahan</surname><given-names>M</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Continual reinforcement learning with complex synapses</article-title><conf-name>Proceedings of the 35th International Conference on Machine Learning</conf-name><fpage>2497</fpage><lpage>2506</lpage></element-citation></ref><ref id="bib55"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Karimi</surname><given-names>P</given-names></name><name><surname>Golkar</surname><given-names>S</given-names></name><name><surname>Friedrich</surname><given-names>J</given-names></name><name><surname>Chklovskii</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Learning a biologically plausible linear controller for nonlinear systems</article-title><conf-name>APS March Meeting 2022</conf-name></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname><given-names>K</given-names></name><name><surname>Chung</surname><given-names>JE</given-names></name><name><surname>Sosa</surname><given-names>M</given-names></name><name><surname>Schor</surname><given-names>JS</given-names></name><name><surname>Karlsson</surname><given-names>MP</given-names></name><name><surname>Larkin</surname><given-names>MC</given-names></name><name><surname>Liu</surname><given-names>DF</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Constant sub-second cycling between representations of possible futures in the hippocampus</article-title><source>Cell</source><volume>180</volume><fpage>552</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.01.014</pub-id><pub-id pub-id-type="pmid">32004462</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kjelstrup</surname><given-names>KB</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Brun</surname><given-names>VH</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Finite scale of spatial representation in the hippocampus</article-title><source>Science</source><volume>321</volume><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1126/science.1157086</pub-id><pub-id pub-id-type="pmid">18599792</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knight</surname><given-names>LS</given-names></name><name><surname>Wenzel</surname><given-names>HJ</given-names></name><name><surname>Schwartzkroin</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Inhibition and interneuron distribution in the dentate gyrus of p35 knockout mice</article-title><source>Epilepsia</source><volume>53 Suppl 1</volume><fpage>161</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1111/j.1528-1167.2012.03487.x</pub-id><pub-id pub-id-type="pmid">22612821</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kulkarni</surname><given-names>TD</given-names></name><name><surname>Saeedi</surname><given-names>A</given-names></name><name><surname>Gautam</surname><given-names>S</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deep Successor Reinforcement Learning</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1606.02396">https://arxiv.org/abs/1606.02396</ext-link></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kullmann</surname><given-names>DM</given-names></name><name><surname>Lamsa</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Long-Term synaptic plasticity in hippocampal interneurons</article-title><source>Nature Reviews. Neuroscience</source><volume>8</volume><fpage>687</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1038/nrn2207</pub-id><pub-id pub-id-type="pmid">17704811</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Bouchard</surname><given-names>K</given-names></name><name><surname>Kitayama</surname><given-names>K</given-names></name><name><surname>Jalali</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2022">2022</year><chapter-title>Non-normality in neural networks</chapter-title><person-group person-group-type="editor"><name><surname>Jalali</surname><given-names>B</given-names></name><name><surname>Kitayama</surname><given-names>K</given-names></name></person-group><source>AI and Optical Data Sciences III</source><publisher-loc>San Francisco, United States</publisher-loc><publisher-name>SPIE</publisher-name><fpage>204</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1117/12.2613472</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamsa</surname><given-names>KP</given-names></name><name><surname>Heeroma</surname><given-names>JH</given-names></name><name><surname>Somogyi</surname><given-names>P</given-names></name><name><surname>Rusakov</surname><given-names>DA</given-names></name><name><surname>Kullmann</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Anti-hebbian long-term potentiation in the hippocampal feedback inhibitory circuit</article-title><source>Science</source><volume>315</volume><fpage>1262</fpage><lpage>1266</lpage><pub-id pub-id-type="doi">10.1126/science.1137450</pub-id><pub-id pub-id-type="pmid">17332410</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Duigou</surname><given-names>C</given-names></name><name><surname>Simonnet</surname><given-names>J</given-names></name><name><surname>Teleñczuk</surname><given-names>MT</given-names></name><name><surname>Fricker</surname><given-names>D</given-names></name><name><surname>Miles</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Recurrent synapses and circuits in the CA3 region of the hippocampus: an associative network</article-title><source>Frontiers in Cellular Neuroscience</source><volume>7</volume><elocation-id>262</elocation-id><pub-id pub-id-type="doi">10.3389/fncel.2013.00262</pub-id><pub-id pub-id-type="pmid">24409118</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Toward the biological model of the hippocampus as the successor representation agent</article-title><source>Bio Systems</source><volume>213</volume><elocation-id>104612</elocation-id><pub-id pub-id-type="doi">10.1016/j.biosystems.2022.104612</pub-id><pub-id pub-id-type="pmid">35093444</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname><given-names>J</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prediction, sequences and the hippocampus</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>364</volume><fpage>1193</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0316</pub-id><pub-id pub-id-type="pmid">19528000</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litwin-Kumar</surname><given-names>A</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title><source>Nature Communications</source><volume>5</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/ncomms6319</pub-id><pub-id pub-id-type="pmid">25395015</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Ramirez</surname><given-names>S</given-names></name><name><surname>Pang</surname><given-names>PT</given-names></name><name><surname>Puryear</surname><given-names>CB</given-names></name><name><surname>Govindarajan</surname><given-names>A</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Optogenetic stimulation of a hippocampal engram activates fear memory recall</article-title><source>Nature</source><volume>484</volume><fpage>381</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1038/nature11028</pub-id><pub-id pub-id-type="pmid">22441246</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lothman</surname><given-names>EW</given-names></name><name><surname>Bertram</surname><given-names>EH</given-names></name><name><surname>Stringer</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Functional anatomy of hippocampal seizures</article-title><source>Progress in Neurobiology</source><volume>37</volume><fpage>1</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1016/0301-0082(91)90011-o</pub-id><pub-id pub-id-type="pmid">1947175</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Love</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Levels of biological plausibility</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>376</volume><elocation-id>1815</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2019.0632</pub-id><pub-id pub-id-type="pmid">33190602</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackevicius</surname><given-names>EL</given-names></name><name><surname>Happ</surname><given-names>MTL</given-names></name><name><surname>Fee</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An avian cortical circuit for chunking tutor song syllables into simple vocal-motor units</article-title><source>Nature Communications</source><volume>11</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1038/s41467-020-18732-x</pub-id><pub-id pub-id-type="pmid">33024101</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marder</surname><given-names>E</given-names></name><name><surname>Goaillard</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Variability, compensation and homeostasis in neuron and network function</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>563</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1038/nrn1949</pub-id><pub-id pub-id-type="pmid">16791145</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marder</surname><given-names>E</given-names></name><name><surname>Taylor</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multiple models to capture the variability in biological neurons and networks</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>133</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nn.2735</pub-id><pub-id pub-id-type="pmid">21270780</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Markus</surname><given-names>EJ</given-names></name><name><surname>Qin</surname><given-names>YL</given-names></name><name><surname>Leonard</surname><given-names>B</given-names></name><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Interactions between location and task affect the spatial and directional firing of hippocampal neurons</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>7079</fpage><lpage>7094</lpage><pub-id pub-id-type="pmid">7472463</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="report"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1976">1976</year><source>From understanding computation to understanding neural circuitry</source><publisher-name>MIT Artifical Intelligence Laboratory</publisher-name><ext-link ext-link-type="uri" xlink:href="https://dspace.mit.edu/handle/1721.1/5782?show=full">https://dspace.mit.edu/handle/1721.1/5782?show=full</ext-link></element-citation></ref><ref id="bib75"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name><name><surname>Willshaw</surname><given-names>D</given-names></name><name><surname>McNaughton</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1991">1991</year><chapter-title>Simple memory: a theory for archicortex</chapter-title><person-group person-group-type="editor"><name><surname>Vaina</surname><given-names>L</given-names></name></person-group><source>From the Retina to the Neocortex</source><publisher-name>Springer</publisher-name><fpage>59</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1007/978-1-4684-6775-8_5</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prioritized memory access explains planning and hippocampal replay</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1609</fpage><lpage>1617</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0232-z</pub-id><pub-id pub-id-type="pmid">30349103</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Planning in the brain</article-title><source>Neuron</source><volume>110</volume><fpage>914</fpage><lpage>934</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.12.018</pub-id><pub-id pub-id-type="pmid">35041804</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenzie</surname><given-names>S</given-names></name><name><surname>Frank</surname><given-names>AJ</given-names></name><name><surname>Kinsky</surname><given-names>NR</given-names></name><name><surname>Porter</surname><given-names>B</given-names></name><name><surname>Rivière</surname><given-names>PD</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hippocampal representation of related and opposing memories develop within distinct, hierarchically organized neural schemas</article-title><source>Neuron</source><volume>83</volume><fpage>202</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.05.019</pub-id><pub-id pub-id-type="pmid">24910078</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Hippocampal synaptic enhancement and information storage within a distributed memory system</article-title><source>Trends in Neurosciences</source><volume>10</volume><fpage>408</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(87)90011-7</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Experience-dependent, asymmetric expansion of hippocampal place fields</article-title><source>PNAS</source><volume>94</volume><fpage>8918</fpage><lpage>8921</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.16.8918</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name><name><surname>Quirk</surname><given-names>MC</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Experience-dependent asymmetric shape of hippocampal receptive fields</article-title><source>Neuron</source><volume>25</volume><fpage>707</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)81072-7</pub-id><pub-id pub-id-type="pmid">10774737</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miles</surname><given-names>R</given-names></name><name><surname>Wong</surname><given-names>RK</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Excitatory synaptic interactions between CA3 neurones in the guinea-pig hippocampus</article-title><source>The Journal of Physiology</source><volume>373</volume><fpage>397</fpage><lpage>418</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1986.sp016055</pub-id><pub-id pub-id-type="pmid">3018233</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name><name><surname>Russek</surname><given-names>EM</given-names></name><name><surname>Cheong</surname><given-names>JH</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The successor representation in human reinforcement learning</article-title><source>Nature Human Behaviour</source><volume>1</volume><fpage>680</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1038/s41562-017-0180-8</pub-id><pub-id pub-id-type="pmid">31024137</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Predicting the Future with Multi-Scale Successor Representations</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/449470</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning structures: predictive representations, replay, and generalization</article-title><source>Current Opinion in Behavioral Sciences</source><volume>32</volume><fpage>155</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.02.017</pub-id><pub-id pub-id-type="pmid">35419465</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monaco</surname><given-names>JD</given-names></name><name><surname>Rao</surname><given-names>G</given-names></name><name><surname>Roth</surname><given-names>ED</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Attentive scanning behavior drives one-trial potentiation of hippocampal place fields</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>725</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1038/nn.3687</pub-id><pub-id pub-id-type="pmid">24686786</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>RU</given-names></name><name><surname>Kubie</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The firing of hippocampal place cells predicts the future position of freely moving rats</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>4101</fpage><lpage>4110</lpage><pub-id pub-id-type="pmid">2592993</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>BK</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Balanced amplification: a new mechanism of selective amplification of neural activity patterns</article-title><source>Neuron</source><volume>61</volume><fpage>635</fpage><lpage>648</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.005</pub-id><pub-id pub-id-type="pmid">19249282</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadim</surname><given-names>F</given-names></name><name><surname>Bucher</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neuromodulation of neurons and synapses</article-title><source>Current Opinion in Neurobiology</source><volume>29</volume><fpage>48</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.05.003</pub-id><pub-id pub-id-type="pmid">24907657</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="book"><person-group person-group-type="author"><collab>National Academies of Sciences</collab></person-group><year iso-8601-date="2018">2018</year><source>Sexual Harassment of Women: Climate, Culture, and Consequences in Academic Sciences, Engineering, and Medicine</source><publisher-loc>Washington, United States</publisher-loc><publisher-name>National Academies of Sciences</publisher-name></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oja</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>A simplified neuron model as a principal component analyzer</article-title><source>Journal of Mathematical Biology</source><volume>15</volume><fpage>267</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1007/BF00275687</pub-id><pub-id pub-id-type="pmid">7153672</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title><source>Nature</source><volume>381</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1038/381607a0</pub-id><pub-id pub-id-type="pmid">8637596</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ostojic</surname><given-names>S</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Synaptic encoding of temporal Contiguity</article-title><source>Frontiers in Computational Neuroscience</source><volume>7</volume><elocation-id>32</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2013.00032</pub-id><pub-id pub-id-type="pmid">23641210</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pawlak</surname><given-names>V</given-names></name><name><surname>Wickens</surname><given-names>JR</given-names></name><name><surname>Kirkwood</surname><given-names>A</given-names></name><name><surname>Kerr</surname><given-names>JND</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Timing is not everything: neuromodulation opens the STDP gate</article-title><source>Frontiers in Synaptic Neuroscience</source><volume>2</volume><elocation-id>146</elocation-id><pub-id pub-id-type="doi">10.3389/fnsyn.2010.00146</pub-id><pub-id pub-id-type="pmid">21423532</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payne</surname><given-names>HL</given-names></name><name><surname>Lynch</surname><given-names>GF</given-names></name><name><surname>Aronov</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural representations of space in the hippocampus of a food-caching bird</article-title><source>Science</source><volume>373</volume><fpage>343</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1126/science.abg2009</pub-id><pub-id pub-id-type="pmid">34437154</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pehlevan</surname><given-names>C</given-names></name><name><surname>Mohan</surname><given-names>S</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Blind nonnegative source separation using biological neural networks</article-title><source>Neural Computation</source><volume>29</volume><fpage>2925</fpage><lpage>2954</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01007</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pehlevan</surname><given-names>C</given-names></name><name><surname>Sengupta</surname><given-names>AM</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Why do similarity matching objectives lead to hebbian/anti-hebbian networks?</article-title><source>Neural Computation</source><volume>30</volume><fpage>84</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01018</pub-id><pub-id pub-id-type="pmid">28957017</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Penfield</surname><given-names>W</given-names></name><name><surname>Milner</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1958">1958</year><article-title>Memory deficit produced by bilateral lesions in the hippocampal zone</article-title><source>A.M.A. Archives of Neurology and Psychiatry</source><volume>79</volume><fpage>475</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1001/archneurpsyc.1958.02340050003001</pub-id><pub-id pub-id-type="pmid">13519951</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>BE</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal place-cell sequences depict future paths to remembered goals</article-title><source>Nature</source><volume>497</volume><fpage>74</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1038/nature12112</pub-id><pub-id pub-id-type="pmid">23594744</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poppenk</surname><given-names>J</given-names></name><name><surname>Evensmoen</surname><given-names>HR</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-axis specialization of the human hippocampus</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>230</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.03.005</pub-id><pub-id pub-id-type="pmid">23597720</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prinz</surname><given-names>AA</given-names></name><name><surname>Bucher</surname><given-names>D</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Similar network activity from disparate circuit parameters</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>1345</fpage><lpage>1352</lpage><pub-id pub-id-type="doi">10.1038/nn1352</pub-id><pub-id pub-id-type="pmid">15558066</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ramón</surname><given-names>S</given-names></name><name><surname>Cajal</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1904">1904</year><source>Textura Del Sistema Nervioso Del Hombre y de Los Vertebrados</source><publisher-name>Imprenta y Librería de Nicolás Moya Madrid</publisher-name></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Recanatesi</surname><given-names>S</given-names></name><name><surname>Farrell</surname><given-names>M</given-names></name><name><surname>Lajoie</surname><given-names>G</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Shea-Brown</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Predictive learning as a network mechanism for extracting low-dimensional latent space representations</article-title><source>Nature Communications</source><volume>12</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41467-021-21696-1</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ribas-Fernandes</surname><given-names>JJF</given-names></name><name><surname>Shahnazian</surname><given-names>D</given-names></name><name><surname>Holroyd</surname><given-names>CB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Subgoal- and goal-related reward prediction errors in medial prefrontal cortex</article-title><source>Journal of Cognitive Neuroscience</source><volume>31</volume><fpage>8</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01341</pub-id><pub-id pub-id-type="pmid">30240308</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Russek</surname><given-names>EM</given-names></name><name><surname>Momennejad</surname><given-names>I</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Predictive representations can link model-based reinforcement learning to model-free mechanisms</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/083857</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadeh</surname><given-names>S</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Excitatory-Inhibitory balance modulates the formation and dynamics of neuronal assemblies in cortical networks</article-title><source>Science Advances</source><volume>7</volume><elocation-id>eabg8411</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abg8411</pub-id><pub-id pub-id-type="pmid">34731002</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaffer</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1892">1892</year><article-title>Beitrag Zur histologie Der ammonshornformation</article-title><source>Archiv Für Mikroskopische Anatomie</source><volume>39</volume><fpage>611</fpage><lpage>632</lpage><pub-id pub-id-type="doi">10.1007/BF02961541</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistical learning of temporal community structure in the hippocampus</article-title><source>Hippocampus</source><volume>26</volume><fpage>3</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1002/hipo.22523</pub-id><pub-id pub-id-type="pmid">26332666</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scoville</surname><given-names>WB</given-names></name><name><surname>Milner</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>Loss of recent memory after bilateral hippocampal lesions</article-title><source>Journal of Neurology, Neurosurgery, and Psychiatry</source><volume>20</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1136/jnnp.20.1.11</pub-id><pub-id pub-id-type="pmid">13406589</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheffield</surname><given-names>MEJ</given-names></name><name><surname>Dombeck</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Calcium transient prevalence across the dendritic arbour predicts place field properties</article-title><source>Nature</source><volume>517</volume><fpage>200</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1038/nature13871</pub-id><pub-id pub-id-type="pmid">25363782</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>AC</given-names></name><name><surname>Carr</surname><given-names>MF</given-names></name><name><surname>Karlsson</surname><given-names>MP</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal SWR activity predicts correct decisions during the initial learning of an alternation task</article-title><source>Neuron</source><volume>77</volume><fpage>1163</fpage><lpage>1173</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.01.027</pub-id><pub-id pub-id-type="pmid">23522050</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience</article-title><source>Science</source><volume>271</volume><fpage>1870</fpage><lpage>1873</lpage><pub-id pub-id-type="doi">10.1126/science.271.5257.1870</pub-id><pub-id pub-id-type="pmid">8596957</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Crisanti</surname><given-names>A</given-names></name><name><surname>Sommers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Chaos in random neural networks</article-title><source>Physical Review Letters</source><volume>61</volume><fpage>259</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.61.259</pub-id><pub-id pub-id-type="pmid">10039285</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sparks</surname><given-names>FT</given-names></name><name><surname>Liao</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Grosmark</surname><given-names>A</given-names></name><name><surname>Soltesz</surname><given-names>I</given-names></name><name><surname>Losonczy</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hippocampal adult-born granule cells drive network activity in a mouse model of chronic temporal lobe epilepsy</article-title><source>Nature Communications</source><volume>11</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41467-020-19969-2</pub-id><pub-id pub-id-type="pmid">33262339</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The hippocampus as a predictive MAP</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1643</fpage><lpage>1653</lpage><pub-id pub-id-type="doi">10.1038/nn.4650</pub-id><pub-id pub-id-type="pmid">28967910</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strange</surname><given-names>BA</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Lein</surname><given-names>ES</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functional organization of the hippocampal longitudinal axis</article-title><source>Nature Reviews. Neuroscience</source><volume>15</volume><fpage>655</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1038/nrn3785</pub-id><pub-id pub-id-type="pmid">25234264</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introduction</source><publisher-name>Stanford University</publisher-name></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thom</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Review: hippocampal sclerosis in epilepsy: a neuropathology review</article-title><source>Neuropathology and Applied Neurobiology</source><volume>40</volume><fpage>520</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1111/nan.12150</pub-id><pub-id pub-id-type="pmid">24762203</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tosches</surname><given-names>MA</given-names></name><name><surname>Yamawaki</surname><given-names>TM</given-names></name><name><surname>Naumann</surname><given-names>RK</given-names></name><name><surname>Jacobi</surname><given-names>AA</given-names></name><name><surname>Tushev</surname><given-names>G</given-names></name><name><surname>Laurent</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Evolution of pallium, hippocampus, and cortical cell types revealed by single-cell transcriptomics in reptiles</article-title><source>Science</source><volume>360</volume><fpage>881</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1126/science.aar4237</pub-id><pub-id pub-id-type="pmid">29724907</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tyulmankov</surname><given-names>D</given-names></name><name><surname>Yang</surname><given-names>GR</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Meta-learning synaptic plasticity and memory addressing for continual familiarity detection</article-title><source>Neuron</source><volume>110</volume><fpage>544</fpage><lpage>557</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.11.009</pub-id><pub-id pub-id-type="pmid">34861149</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Vértes</surname><given-names>E</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A Neurally Plausible Model Learns Successor Representations in Partially Observable Environments</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1906.09480">https://arxiv.org/abs/1906.09480</ext-link></element-citation></ref><ref id="bib122"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Hung</surname><given-names>CC</given-names></name><name><surname>Amos</surname><given-names>D</given-names></name><name><surname>Mirza</surname><given-names>M</given-names></name><name><surname>Ahuja</surname><given-names>A</given-names></name><name><surname>Grabska-Barwinska</surname><given-names>A</given-names></name><name><surname>Rae</surname><given-names>J</given-names></name><name><surname>Mirowski</surname><given-names>P</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Unsupervised Predictive Memory in a Goal-Directed Agent</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1803.10760">https://arxiv.org/abs/1803.10760</ext-link></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The tolman-eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation</article-title><source>Cell</source><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id><pub-id pub-id-type="pmid">33181068</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Widloski</surname><given-names>J</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Flexible rerouting of hippocampal replay sequences around changing barriers in the absence of global place field remapping</article-title><source>Neuron</source><volume>110</volume><fpage>1547</fpage><lpage>1558</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.02.002</pub-id><pub-id pub-id-type="pmid">35180390</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeldenrust</surname><given-names>F</given-names></name><name><surname>Gutkin</surname><given-names>B</given-names></name><name><surname>Denéve</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Efficient and robust coding in heterogeneous recurrent networks</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008673</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008673</pub-id><pub-id pub-id-type="pmid">33930016</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>T</given-names></name><name><surname>Rosenberg</surname><given-names>M</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Endotaxis: A Universal Algorithm for Mapping, Goal-Learning, and Navigation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.09.24.461751</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zurn</surname><given-names>P</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Rust</surname><given-names>NC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The citation diversity statement: a practice of transparency, a way of life</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>669</fpage><lpage>672</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.06.009</pub-id><pub-id pub-id-type="pmid">32762966</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Finding the conditions to retrieve from RNN steady-state activity</title><p>The successor representation is defined as<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>T</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf311"><mml:mi>T</mml:mi></mml:math></inline-formula> is the transition probability matrix such that <inline-formula><mml:math id="inf312"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for current state <inline-formula><mml:math id="inf313"><mml:mi>s</mml:mi></mml:math></inline-formula> and future state <inline-formula><mml:math id="inf314"><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula></p><p>For an RNN with connectivity <inline-formula><mml:math id="inf315"><mml:mi>J</mml:mi></mml:math></inline-formula>, activity <inline-formula><mml:math id="inf316"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, input <inline-formula><mml:math id="inf317"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, and gain <inline-formula><mml:math id="inf318"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the (linear) discrete-time dynamics equation is (<xref ref-type="bibr" rid="bib5">Amarimber, 1972</xref>)<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Furthermore, the steady state solution can be found by setting <inline-formula><mml:math id="inf319"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula><disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Assume that <inline-formula><mml:math id="inf320"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> as a result of the network using some STDP-like learning rule where pre-post connections are potentiated. The transposition is due to notational differences from the RL literature, where the <inline-formula><mml:math id="inf321"><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> th index typically concerns the direction from state <inline-formula><mml:math id="inf322"><mml:mi>i</mml:mi></mml:math></inline-formula> to state <inline-formula><mml:math id="inf323"><mml:mi>j</mml:mi></mml:math></inline-formula>. This is a result of differences in RL and RNN conventions in which inputs are left-multiplied and right-multiplied, respectively. Let <inline-formula><mml:math id="inf324"><mml:mi>γ</mml:mi></mml:math></inline-formula> be a neuromodulatory factor that is applied over the whole network (and, thus, does not need to be encoded in the synaptic weights). Then, the equivalence to <xref ref-type="disp-formula" rid="equ1">equation 12</xref> becomes clear and our steady state solution can be written as:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>This is consistent with the successor representation framework shown in <xref ref-type="bibr" rid="bib115">Stachenfeld et al., 2017</xref>, where the columns of the <inline-formula><mml:math id="inf325"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix represent the firing fields of a neuron, and the rows of the <inline-formula><mml:math id="inf326"><mml:mi>M</mml:mi></mml:math></inline-formula> matrix represent the network response to some input.</p></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Deriving the RNN-S learning rule from TD Error and showing the learning rule is valid under a stability condition</title><p>Transitions between states <inline-formula><mml:math id="inf327"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are observed as features <inline-formula><mml:math id="inf328"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> where <inline-formula><mml:math id="inf329"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is some function. For notational simplicity, we will write these observed feature transitions as <inline-formula><mml:math id="inf330"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. A dataset <inline-formula><mml:math id="inf331"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is comprised of these observed feature transitions over a behavioral trajectory. Successor features are typically learned by some function approximator <inline-formula><mml:math id="inf332"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> that is parameterized by <inline-formula><mml:math id="inf333"><mml:mi>θ</mml:mi></mml:math></inline-formula> and takes in the inputs <inline-formula><mml:math id="inf334"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The SF approximator, <inline-formula><mml:math id="inf335"><mml:mi>ψ</mml:mi></mml:math></inline-formula>, is learned by minimizing the temporal difference (TD) loss function (<xref ref-type="bibr" rid="bib117">Sutton and Barto, 2018</xref>):<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msup><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>for the current policy <inline-formula><mml:math id="inf336"><mml:mi>π</mml:mi></mml:math></inline-formula>. Here, the TD target is <inline-formula><mml:math id="inf337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msup><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Analogous to the model-free setting where the value function <inline-formula><mml:math id="inf338"><mml:mi>V</mml:mi></mml:math></inline-formula> is being learned, <inline-formula><mml:math id="inf339"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is in place of the reward <inline-formula><mml:math id="inf340"><mml:mi>r</mml:mi></mml:math></inline-formula>. Following these definitions, we can view the RNN-S as the function approximator <inline-formula><mml:math id="inf341"><mml:mi>ψ</mml:mi></mml:math></inline-formula>:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ψ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For a single transition <inline-formula><mml:math id="inf342"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> we can write out the loss as follows:<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msup><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For each observed transition, we would like to update <inline-formula><mml:math id="inf343"><mml:mi>ψ</mml:mi></mml:math></inline-formula> such that the loss <inline-formula><mml:math id="inf344"><mml:mi>L</mml:mi></mml:math></inline-formula> is minimized. Thus, we take the gradient of this temporal difference loss function with respect to our parameter <inline-formula><mml:math id="inf345"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msup><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We can make the TD approximation (<xref ref-type="bibr" rid="bib117">Sutton and Barto, 2018</xref>):<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mi>γ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>J</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>J</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mi>J</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>While <inline-formula><mml:math id="inf346"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mo>∇</mml:mo><mml:mi>J</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> gives the direction of steepest descent in the loss, we will consider a linear transformation of the gradient that allows for a simpler update rule. This simpler update rule will be more amenable to a biologically plausible learning rule. We define this modified gradient as <inline-formula><mml:math id="inf347"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mo>∇</mml:mo><mml:mi>J</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf348"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. We must first understand the condition for <inline-formula><mml:math id="inf349"><mml:mi>D</mml:mi></mml:math></inline-formula> to be in a direction of descent:<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula><disp-formula id="equ26"><label>(26)</label><mml:math id="m26"><mml:mrow><mml:mi>Tr</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula><disp-formula id="equ27"><label>(27)</label><mml:math id="m27"><mml:mrow><mml:mi>Tr</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mi>M</mml:mi><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula><disp-formula id="equ28"><label>(28)</label><mml:math id="m28"><mml:mrow><mml:mi>Tr</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula><disp-formula id="equ29"><label>(29)</label><mml:math id="m29"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>Tr</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>J</mml:mi></mml:mrow></mml:msub><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p><p>This expression is satisfied if <inline-formula><mml:math id="inf350"><mml:mrow><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is positive definite (its eigenvalues are positive). Thus, we find that our modified gradient points towards a descent direction if the eigenvalues of <inline-formula><mml:math id="inf351"><mml:mrow><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> are positive. Interestingly, this condition is equivalent to stating that the recurrent network dynamics are stable and do not exhibit non-normal amplification (<xref ref-type="bibr" rid="bib61">Kumar et al., 2022</xref>; <xref ref-type="bibr" rid="bib88">Murphy and Miller, 2009</xref>; <xref ref-type="bibr" rid="bib42">Goldman, 2009</xref>). In other words, as long as the network dynamics are in a stable regime and do not have non-normal amplification, our modified gradient reduces the temporal difference loss. Otherwise, the gradient will not point towards a descent direction.</p><p>We will use the modified gradient <inline-formula><mml:math id="inf352"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>J</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> as our synaptic weight update rule. Our theoretical analysis explains much of the results seen in the main text. As the gain parameter <inline-formula><mml:math id="inf353"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> is increased, the network is closer to the edge of stability (the eigenvalues of <inline-formula><mml:math id="inf354"><mml:mi>M</mml:mi></mml:math></inline-formula> are close to positive values, <xref ref-type="fig" rid="fig3">Figure 3A</xref>). Stability itself is not enough to guarantee that our update rule is valid. We need the additional constraint that non-normal amplification should not be present (eigenvalues of <inline-formula><mml:math id="inf355"><mml:mrow><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> are positive). In practice, however, this does not seem to be a mode that affects our network. That is, the <inline-formula><mml:math id="inf356"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> value for which the error in the network increases coincides with the <inline-formula><mml:math id="inf357"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> value for which the network is no longer stable (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Our theoretical analysis also shows that the gain <inline-formula><mml:math id="inf358"><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:math></inline-formula> can always be decreased such that the eigenvalues of <inline-formula><mml:math id="inf359"><mml:mrow><mml:mi>M</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> are positive and our update rule is valid (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). At the most extreme, one can set <inline-formula><mml:math id="inf360"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> during learning to maintain stability (as we do in <xref ref-type="fig" rid="fig4">Figure 4</xref> and onwards).</p></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Proving the RNN-S update rule calculated on firing rates (<inline-formula><mml:math id="inf361"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) depends only on feedforward inputs (<inline-formula><mml:math id="inf362"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) at steady state</title><p>We will show that our update rule, which uses <inline-formula><mml:math id="inf363"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (neural activity), converges on a solution that depends only on <inline-formula><mml:math id="inf364"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (the feedforward inputs). We will also show that in the one-hot case, we learn the SR exactly.</p><p>As a reminder, our learning rule for each <inline-formula><mml:math id="inf365"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> synapse is:<disp-formula id="equ30"><label>(30)</label><mml:math id="m30"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>J</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>We can solve for the steady state solution of <xref ref-type="disp-formula" rid="equ30">Equation 30</xref> (set <inline-formula><mml:math id="inf366"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). Let <inline-formula><mml:math id="inf367"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> for notational convenience, and recall that in steady state <inline-formula><mml:math id="inf368"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. Let <inline-formula><mml:math id="inf369"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denote the average of <inline-formula><mml:math id="inf370"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> over time.<disp-formula id="equ31"><label>(31)</label><mml:math id="m31"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ32"><label>(32)</label><mml:math id="m32"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>A</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ33"><label>(33)</label><mml:math id="m33"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi>A</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ34"><label>(34)</label><mml:math id="m34"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>Note that, since <inline-formula><mml:math id="inf371"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf372"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>γ</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.<disp-formula id="equ35"><label>(35)</label><mml:math id="m35"><mml:mrow><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>γ</mml:mi></mml:mfrac></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ36"><label>(36)</label><mml:math id="m36"><mml:mrow><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>γ</mml:mi></mml:mfrac></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ37"><label>(37)</label><mml:math id="m37"><mml:mrow><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>γ</mml:mi></mml:mfrac></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Thus,<disp-formula id="equ38"><label>(38)</label><mml:math id="m38"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>γ</mml:mi></mml:mfrac></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Therefore,<disp-formula id="equ39"><label>(39)</label><mml:math id="m39"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:msup><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mrow><mml:mo>⊺</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="equ40"><label>(40)</label><mml:math id="m40"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf373"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the autocorrelation matrix for some time lag <inline-formula><mml:math id="inf374"><mml:mi>τ</mml:mi></mml:math></inline-formula>. Therefore, the RNN-S weight matrix <inline-formula><mml:math id="inf375"><mml:mi>J</mml:mi></mml:math></inline-formula> at steady state is only dependent on the inputs into the RNN over time.</p><p>In the case where <inline-formula><mml:math id="inf376"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is one-hot, we compute the SR exactly. This is because the steady state solution at each <inline-formula><mml:math id="inf377"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> synapse simplifies into the following expression:<disp-formula id="equ41"><label>(41)</label><mml:math id="m41"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>This is the definition of the transition probability matrix and we see that <inline-formula><mml:math id="inf378"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Note that the solution for <inline-formula><mml:math id="inf379"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ41">Equation 41</xref> is undefined if state <inline-formula><mml:math id="inf380"><mml:mi>j</mml:mi></mml:math></inline-formula> is never visited. We assume each relevant state is visited at least once here.</p></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>Deriving the adaptive learning rate update rule</title><p>This section explains how the adaptive learning rate is derived. The logic will be similar to calculating a weighted running average. Let <inline-formula><mml:math id="inf381"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> be a binary function that is 1 if the transition from timestep <inline-formula><mml:math id="inf382"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> to timestep <inline-formula><mml:math id="inf383"><mml:mi>t</mml:mi></mml:math></inline-formula> is state <inline-formula><mml:math id="inf384"><mml:mi>j</mml:mi></mml:math></inline-formula> to state <inline-formula><mml:math id="inf385"><mml:mi>i</mml:mi></mml:math></inline-formula>. Otherwise, it is 0. Assume <inline-formula><mml:math id="inf386"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is one-hot encoded. Notice that in the one-hot case, the RNN-S update rule (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>) simplifies to:<disp-formula id="equ42"><label>(42)</label><mml:math id="m42"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>What <inline-formula><mml:math id="inf387"><mml:mi>η</mml:mi></mml:math></inline-formula> should be used so <inline-formula><mml:math id="inf388"><mml:mi>J</mml:mi></mml:math></inline-formula> approaches <inline-formula><mml:math id="inf389"><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:math></inline-formula> as quickly as possible? During learning, the empirical transition matrix, <inline-formula><mml:math id="inf390"><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, changes at each timestep <inline-formula><mml:math id="inf391"><mml:mi>t</mml:mi></mml:math></inline-formula>, based on transitions the animal has experienced. Define the total number of times that state <inline-formula><mml:math id="inf392"><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> happened prior to time <inline-formula><mml:math id="inf393"><mml:mi>t</mml:mi></mml:math></inline-formula> as <inline-formula><mml:math id="inf394"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and define the running count of transitions from state j to state i as <inline-formula><mml:math id="inf395"><mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. We want <inline-formula><mml:math id="inf396"><mml:mrow><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which necessitates<disp-formula id="equ43"><label>(43)</label><mml:math id="m43"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ44"><label>(44)</label><mml:math id="m44"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Note that <inline-formula><mml:math id="inf397"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf398"><mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, which gives us<disp-formula id="equ45"><label>(45)</label><mml:math id="m45"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ46"><label>(46)</label><mml:math id="m46"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ47"><label>(47)</label><mml:math id="m47"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ48"><label>(48)</label><mml:math id="m48"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Therefore, comparing with <xref ref-type="disp-formula" rid="equ42">Equation 42</xref>, we can see that a learning rate <inline-formula><mml:math id="inf399"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> will let <inline-formula><mml:math id="inf400"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> as quickly as possible. We have defined <inline-formula><mml:math id="inf401"><mml:mi>n</mml:mi></mml:math></inline-formula> in terms of the inputs <inline-formula><mml:math id="inf402"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for this derivation, but in practice the adaptive learning rate as a function of <inline-formula><mml:math id="inf403"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula> works well with the RNN-S update rule (which is also a function of <inline-formula><mml:math id="inf404"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula>). Thus, we use the adaptive learning rate defined over <inline-formula><mml:math id="inf405"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula> in our combined learning rule for increased biological plausibility.</p><p>In its current form, the update equation assumes transitions across all history of inputs are integrated. In reality, there is likely some kind of memory decay. This can be implemented with a decay term <inline-formula><mml:math id="inf406"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>:<disp-formula id="equ49"><label>(49)</label><mml:math id="m49"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf407"><mml:mi>λ</mml:mi></mml:math></inline-formula> determines the recency bias over the observed transitions that make up the <inline-formula><mml:math id="inf408"><mml:mi>T</mml:mi></mml:math></inline-formula> estimate. The addition of <inline-formula><mml:math id="inf409"><mml:mi>λ</mml:mi></mml:math></inline-formula> has the added benefit that it naturally provides a mechanism for learning rates to modulate over time. If <inline-formula><mml:math id="inf410"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the learning rate can only monotonically decrease. If <inline-formula><mml:math id="inf411"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, the learning rate can become strong again over time if a state has not been visited in a while. This provides a mechanism for fast learning of new associations, which is useful for a variety of effects, including remapping.</p></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s12"><title>Endotaxis model and the successor representation</title><p>The learning rule and architecture of our model is similar to a hypothesized “endotaxis” model (<xref ref-type="bibr" rid="bib126">Zhang et al., 2021</xref>). In the endotaxis model, neurons fire most strongly near a reward, allowing the animal to navigate up a gradient of neural activity akin to navigating up an odor gradient. The endotaxis model discovers the structure of an environment and can solve many tasks such as spatial navigation and abstract puzzles. We were interested in similarities between RNN-S and the learning rules for endotaxis, in support of the idea that SR-like representations may be used by the brain for a broad range of intelligent behaviors. Here, we outline similarities and differences between the two model architectures.</p><p>The endotaxis paper (<xref ref-type="bibr" rid="bib126">Zhang et al., 2021</xref>) uses Oja’s rule in an RNN with place-like inputs. The SR can also be learned with an Oja-like learning rule. Oja’s rule is typically written as (<xref ref-type="bibr" rid="bib91">Oja, 1982</xref>):<disp-formula id="equ50"><label>(50)</label><mml:math id="m50"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>If we assume that there is a temporal asymmetry to the potentiation term (e.g., potentiation is more STDP-like than Hebbian), then we have<disp-formula id="equ51"><label>(51)</label><mml:math id="m51"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We then solve for the steady state solution of this equation, when <inline-formula><mml:math id="inf412"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ52"><label>(52)</label><mml:math id="m52"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ53"><label>(53)</label><mml:math id="m53"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ54"><label>(54)</label><mml:math id="m54"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf413"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula> indicates the time-average of some term. Assume that the plasticity rule does not use <inline-formula><mml:math id="inf414"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math></inline-formula> exactly, but instead uses <inline-formula><mml:math id="inf415"><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:math></inline-formula> directly. Given that inputs are one-hot encodings of the animal’s state at some time <inline-formula><mml:math id="inf416"><mml:mi>t</mml:mi></mml:math></inline-formula>, the expression becomes<disp-formula id="equ55"><label>(55)</label><mml:math id="m55"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>If we assume <inline-formula><mml:math id="inf417"><mml:mi>T</mml:mi></mml:math></inline-formula> is symmetric, <inline-formula><mml:math id="inf418"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Alternatively, if we use pre-synaptic normalization as opposed to the standard post-synaptic normalization of Oja’s rule (i.e., index <inline-formula><mml:math id="inf419"><mml:mi>j</mml:mi></mml:math></inline-formula> instead of <inline-formula><mml:math id="inf420"><mml:mi>i</mml:mi></mml:math></inline-formula> in the denominator), we also have <inline-formula><mml:math id="inf421"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>⊺</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Thus, the steady state activity of a RNN with this learning rule retrieves the SR, as shown in subsection 4.14.</p></sec></app><app id="appendix-6"><title>Appendix 6</title><sec sec-type="appendix" id="s13"><title>Independent normalization and successor features</title><p>If we assume the same Oja-like rule as in Appendix 5, we can also arrive at a similar interpretation in the successor feature case as in <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>. By solving for the steady state solution without any assumptions about the inputs <inline-formula><mml:math id="inf422"><mml:mi mathvariant="bold-italic">ϕ</mml:mi></mml:math></inline-formula>, we get the following equation:<disp-formula id="equ56"><label>(56)</label><mml:math id="m56"><mml:mrow><mml:mi>J</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mtext mathvariant="monospace">diag</mml:mtext></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where diag is a function that retains only the diagonal of the matrix. This expression provides a useful way to contrast the learning rule used in RNN-S with an Oja-like alternative. While RNN-S normalizes by the full autocorrelation matrix, an Oja-like rule only normalizes by the diagonal of the matrix. This is the basis of our independent normalization model in <xref ref-type="fig" rid="fig4">Figure 4BC</xref>.</p></sec></app><app id="appendix-7"><title>Appendix 7</title><sec sec-type="appendix" id="s14"><title>Comparing alternate forms of normalizing the synaptic weight matrix</title><p>The anti-Hebbian term of the RNN-S learning rule normalizes the synaptic weight matrix into exactly a transition probability matrix. We wanted to test how important it was to use this exact normalization and whether other forms of the synaptic weight matrix could yield similar results. We simulated representations that would arise from different normalization procedures. For these tests, we simulate a random walk on a circular track, as in <xref ref-type="fig" rid="fig2">Figure 2</xref>, for 10 minutes of simulation time. A model where the synaptic weight matrix exactly estimates the transition probability matrix (as in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>) will give the SR matrix (<xref ref-type="fig" rid="app7fig1">Appendix 7—figure 1A</xref>).</p><p>We test a model where the normalization term for the synaptic weight matrix is removed. Thus, <inline-formula><mml:math id="inf423"><mml:mi>J</mml:mi></mml:math></inline-formula> will be equal to the count of observed transitions, i.e. <inline-formula><mml:math id="inf424"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is equal to the number of experienced transitions from state <inline-formula><mml:math id="inf425"><mml:mi>j</mml:mi></mml:math></inline-formula> to state <inline-formula><mml:math id="inf426"><mml:mi>i</mml:mi></mml:math></inline-formula>. We will refer to this as a count matrix. Without normalization, the values in the count matrix will increase steadily over the course of the simulation. This quickly results in unstable dynamics from the weights of the matrix being too large (<xref ref-type="fig" rid="app7fig1">Appendix 7—figure 1B</xref>). A simple way to prevent instability (specifically, ensure the maximum eigenvalue of the synaptic weight matrix is below 1) is to use an additional scaling factor <inline-formula><mml:math id="inf427"><mml:mi>α</mml:mi></mml:math></inline-formula> over the weights of the matrix, such that <inline-formula><mml:math id="inf428"><mml:mi>J</mml:mi></mml:math></inline-formula> is multiplied by <inline-formula><mml:math id="inf429"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mpadded width="+5pt"><mml:mi>α</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>max</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math></inline-formula>. A careful choice of a scaling value can ensure network activity remains stable within this walk, although this is not a generalizable solution as different scaling values may be needed for different random walks and tasks. However, even with this modification the representations above are not sufficiently predictive compared to the original SR (the off-diagonal elements of the SR are not captured well), and the activity strength seems to be unevenly distributed across the states (<xref ref-type="fig" rid="app7fig1">Appendix 7—figure 1CD</xref>). It is likely that depressing all synapses by the same factor (similar to <xref ref-type="bibr" rid="bib30">Fiete et al., 2010</xref>) does not correct for differences in occupancies. In other words, states that happen to be visited more by chance are likely to dominate the dynamics, even if the transition statistics are identical across all states.</p><p>Final, as a further test of different ways of parameterizing the synaptic weight matrix, we examine the steady state neural activity when the count matrix is instead scaled in a row-by-row fashion (<xref ref-type="fig" rid="app7fig1">Appendix 7—figure 1E</xref>). Specifically, we divide each row <inline-formula><mml:math id="inf430"><mml:mi>i</mml:mi></mml:math></inline-formula> of the count matrix by the maximum of row <inline-formula><mml:math id="inf431"><mml:mi>i</mml:mi></mml:math></inline-formula> (and some global scaling factor to ensure stability). Note that this is in contrast to <inline-formula><mml:math id="inf432"><mml:mi>T</mml:mi></mml:math></inline-formula>, where each row is divided by its sum. This is closer to the SR matrix expected if the synaptic weight matrix estimates <inline-formula><mml:math id="inf433"><mml:mi>T</mml:mi></mml:math></inline-formula>. We see there is a slight unevenness early on in learning in the diagonal of the matrix (<xref ref-type="fig" rid="app7fig1">Appendix 7—figure 1E</xref>). However, given enough observed transitions, the predictive representation looks reasonable and quite similar to the SR matrix.</p><p>Overall, we see that there are likely other formulations of the synaptic weight matrix that can give a representation similar to the SR. The important ingredient for this to happen appears to be some type of row-dependent normalization-- that is, neurons should have their synaptic weights normalized independently of each other. This ensures that occupancy is not conflated with transition statistics.</p><fig id="app7fig1" position="float"><label>Appendix 7—figure 1.</label><caption><title>SR matrices under different forms of normalization.</title><p>(<bold>A</bold>) The resulting SR matrix from a random walk on a circular track for 10minutes, if the synaptic weight matrix exactly estimates the transition probability matrix (as in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>). (<bold>B</bold>) Model as in (<bold>A</bold>), but with normalization removed. Thus, <inline-formula><mml:math id="inf434"><mml:mi>J</mml:mi></mml:math></inline-formula> will be equal to the count of observed transitions, i.e. <inline-formula><mml:math id="inf435"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is equal to the number of experienced transitions from state <inline-formula><mml:math id="inf436"><mml:mi>j</mml:mi></mml:math></inline-formula> to state <inline-formula><mml:math id="inf437"><mml:mi>i</mml:mi></mml:math></inline-formula>. We will refer to this as a count matrix. The plot show the maximum eigenvalue of the weight matrix, where an eigenvalue <inline-formula><mml:math id="inf438"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> indicates instability (<xref ref-type="bibr" rid="bib113">Sompolinsky et al., 1988</xref>). (<bold>C</bold>) As in (<bold>B</bold>), but with an additional scaling factor <inline-formula><mml:math id="inf439"><mml:mi>α</mml:mi></mml:math></inline-formula> over the weights of the matrix, such that <inline-formula><mml:math id="inf440"><mml:mi>J</mml:mi></mml:math></inline-formula> is multiplied by <inline-formula><mml:math id="inf441"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mpadded width="+5pt"><mml:mi>α</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>max</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math></inline-formula>. (<bold>D</bold>) Steady state neural activity of the model in (<bold>C</bold>) with scaling factor 1.75. (<bold>E</bold>) As in (<bold>D</bold>), but the count matrix is instead scaled in a row-by-row fashion. Specifically, we divide each row <inline-formula><mml:math id="inf442"><mml:mi>i</mml:mi></mml:math></inline-formula> of the count matrix by the maximum of row <inline-formula><mml:math id="inf443"><mml:mi>i</mml:mi></mml:math></inline-formula> (and some global scaling factor to ensure stability).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-80680-app7-fig1-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80680.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx6zz33</institution-id><institution>École Normale Supérieure Paris</institution></institution-wrap><country>France</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.05.18.492543" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.05.18.492543"/></front-stub><body><p>This important work provides compelling evidence for the biological plausibility of the Successor Representation (SR) algorithm. The SR is a leading computational hypothesis to explore whether neural representations are consistent with the hypothesis that the neural networks in specific brain areas perform predictive computations. Establishing a biologically plausible learning rule for SR representations to form is of high significance in the field of neuroscience.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80680.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx6zz33</institution-id><institution>École Normale Supérieure Paris</institution></institution-wrap><country>France</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Recanatesi</surname><given-names>Stefano</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>University of Washington</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Juliani</surname><given-names>Arthur</given-names></name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.05.18.492543">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.05.18.492543v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Neural learning rules for generating flexible predictions and computing the successor representation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Timothy Behrens as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Stefano Recanatesi (Reviewer #1); Arthur Juliani (Reviewer #2); Srdjan Ostojic (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Main Comments:</p><p>1) The form of the plasticity rule in Equation 4 is motivated by the requirement that synaptic weights encode a properly normalised transition probability matrix (lines 92-96). But why is the normalisation important? What would change if synaptic weights were simply monotonic functions of transition probabilities, without normalisation? Presumably that would allow for a broader range of plasticity rules.</p><p>2) As the results of the paper strongly rely on the normalizing term in Equation 4. One of the reviewers suggests potentially moving upfront part of the discussion of this term, and enlarging the paragraph that discusses the biological plausibility of this specific term. Clearly laying out, for the non-expert reader, why it is biologically plausible compared to other learning rules. Also consider moving the required material to establish the novelty of such term: a targeted review of the relevant literature (current lines 358-366 and 413-433). This would allow the reader to understand immediately the significance and relative novelty of such term. For example, this reviewer personally wondered while reading the paper of how different was such term from the basic idea of Fiete et al., Neuron 2010 (DOI 10.1016/j.neuron.2010.02.003).</p><p>3) Related to the first point, the text insists on the fact that \γ is not encoded in the synaptic weights (eg line 89). Again, it is not entirely clear why this is important and justified, since γ is an ad-hoc factor in Equation 2. Presumably the proper normalisation of γ relies on the normalisation of J discussed above? It seems that this constraint could be relaxed.</p><p>4) As a consequence of the body of the text being devoted to the analysis of the design choices behind the proposed model, a relatively smaller portion of the work involves direct comparisons with neural data. In these comparisons, while it is apparent that there is a reasonable match between the proposed model and the empirical data, it is difficult to interpret these results. This is because it is unclear what should be expected of a good or bad model given the data being analyzed (TD error and KL divergence), and reasonable baselines to compare against are not presented outside of the traditional TD algorithm, which is shown to be comparable to the proposed RNN based method in a number of cases.</p><p>5) It would be useful to have a &quot;limitations&quot; paragraph in the discussion clearly outlining what this learning rule couldn't achieve. For example, Stachenfeld et al., Nat.Neuro. have many examples where the SR is deployed. Does the learning rule suggested by the authors would always work across the board, or are there limitations that could be highlighted where the framework suggested would not work well. No need to perform more experiments/simulations but simply to share insight regarding the results and the capability of the proposed learning rule.</p><p>Other comments/suggestions:</p><p>– Page 1: The introduction motivates this work with a discussion of hippocampal memory (storage and retrieval), but the work focuses on the SR which is inherently prospective. The first paragraph of the text could be revised to better make this connection beyond simply stating that the hippocampus is involved in both memory and future prediction.</p><p>– Page 2: The end of the introduction would be stronger if the motivation for an RNNs usage was tied to the literature on the known recurrent dynamics of the hippocampus. See for example: https://www.frontiersin.org/articles/10.3389/fncel.2013.00262/full</p><p>– Page 6: It is not clear the extent to which the FF-TD model differs from a canonical tabular SR algorithm or linear SF algorithm. My understanding is that it is the same, but the presentation in Figure 1i for example makes this somewhat unclear.</p><p>– Pages 6 – 11: it may be of benefit to more strongly support the various modifications to the model with connections to known or hypothesized hippocampal neural dynamics.</p><p>– Page 14: It states that &quot;We discretize the arena into a set of states and encode each state as a randomly drawn feature ϕ.&quot; If I understand correctly, these features are not completely random, and instead follow the distribution described in Section 2.5. As it currently reads, it seems that these features might be drawn from a uniform random distribution, which would be misleading.</p><p>– Page 14: In Section 2.6 there is an assumption that a certain level of TD error corresponds to good performance. It is not clear what should objectively be considered a reasonable TD error. This is especially difficult to interpret in the case where both the RNN-S and FF-TD models display comparable performance. Is there perhaps some other baseline you would expect to perform considerably worse?</p><p>– Page 17: In Figure 4 it is somewhat confusing that the KL divergence (subplots G and I) has reversed shading (dark for low values) compared to the other subplots. It would be easier to interpret these graphs if their color coding was more consistent.</p><p>– Page 18: Similar to the difficulty of interpreting the TD error results, it is not clear what a &quot;good&quot; or &quot;bad&quot; KL divergence from the neural data would be. Any hypotheses on how to ground the numbers provided here would help to improve the quality of the results.</p><p>– Page 20: It is mentioned that the predictive timescale may be a separate gain term which the hippocampus takes as input, but there is evidence that different regions of the hippocampus seem to operate on different timescales. See for example: https://www.jneurosci.org/content/42/2/299.abstract. Is there a way to reconcile these ideas?</p><p>– Page 23: Section 4.5 describes the procedure for learning the parameters of the weight update rule as CMA-ES. Mentioning the fact that an evolutionary algorithm is used for learning these weights would help to make Section 2.3 more clear.</p><p>– Figures 5D-E and similar supplementary figures: if there is a parameter region that is unexplored then the color used for such region should be outside of the colormap. One of the reviewers suggests replacing white with gray for such region in these figures.</p><p>– Line 173: the text makes the distinction between an &quot;SR-like&quot; representation, and an &quot;exact SR&quot;. What is the difference? Why is it important to have an exact of the SR in the neural activity, rather then eg a monotonic encoding of the SR?</p><p>– The RNN described in Equation 2 is not of the standard form (the non-linearity is applied after the connectivity matrix, ie f(J x) instead of Jf(x)). Is this detail important? If not, why not use the more standard form to avoid confusion?</p><p>– A line of work in the Fusi lab has examined plasticity rules that lead to the encoding of transition probabilities (eg Fusi et al., Neuron 2007). In particular, a paper by the reviewing editor (Ostojic and Fusi Front Comp Neuro 2013) examined the encoding of transition probabilities using plasticity rules that look similar to this manuscript. This is mentioned just for information, the authors should decide if those papers are relevant.</p><p>– Figures 5D-E and similar supplementary figures: if there is a parameter region that is unexplored then the color used for such region should be outside of the colormap. One of the reviewers suggests replacing white with gray for such region in these figures.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.80680.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Main Comments:</p><p>1) The form of the plasticity rule in Equation 4 is motivated by the requirement that synaptic weights encode a properly normalised transition probability matrix (lines 92-96). But why is the normalisation important? What would change if synaptic weights were simply monotonic functions of transition probabilities, without normalisation? Presumably that would allow for a broader range of plasticity rules.</p></disp-quote><p>The reviewer makes an interesting point that a range of possible rules may yield useful representations even if they do not learn the transition probability matrix exactly. We tested these ideas (see below) and found that normalization is generally important for maintaining stable dynamics in the recurrent network. Many forms of normalization can learn predictive representations similar to the SR, as long as the normalization is performed across rows of the weight matrix independently. We have added a few sentences of text (lines 107-116) and a supplementary figure summarizing and showing these results. The details of our additional analyses and the text added to the manuscript are given below.</p><p>We constructed representations using different normalization procedures. For these tests, we simulated a random walk on a circular track, as in Appendix 7-figure 1B, for 10 minutes of simulation time.</p><p>If the synaptic weight matrix estimates the normalized transition probability matrix (as in equation 4), the resulting SR matrix over the course of the walk is as Appendix 7-figure 1A.</p><p>As an initial test of the role of normalization, we did the same simulation, removing normalization. Thus, $J$ will be equal to the count of observed transitions, i.e. $J_{ij}$ is equal to the number of experienced transitions from state $j$ to state $i$. We refer to this as a count matrix. Note that, without normalization, the values in the count matrix increase steadily over the course of the simulation. This quickly results in unstable dynamics due to the weights of the matrix being too large. We can quantify this instability by plotting the maximum eigenvalue of the weight matrix, where an eigenvalue &gt;= 1 indicates instability (Sompolinsky et al., 1988), Appendix 7-figure 1B.</p><p>A simple way to prevent instability is to scale the weights of the matrix by a constant factor such that the dynamics are in the stable regime (specifically, ensuring that the maximum eigenvalue of the synaptic weight matrix is below 1). A careful choice of a scaling value can ensure network activity remains stable within this walk, although this is not a generalizable solution as different scaling values will be needed for different random walks and tasks.</p><p>Informed by Appendix 7-figure 1C, we chose a scaling factor of 1.75. and tested what neural representations look like throughout the walk.</p><p>Compared to the ground truth SR, the representations above are not very predictive (the off-diagonal elements of the SR are not captured well), and the activity strength seems to be unevenly distributed across states. For instance, there is more activity at state 8 than other states. It is likely that depressing all synapses by the same factor (similar in flavor to Fiete et al., 2010) does not correct for differences in occupancies. In other words, states that happen to be visited more by chance are likely to dominate the dynamics, even if the transition statistics are identical across all states (Appendix 7-figure 1D).</p><p>As a further test of different ways of parameterizing the synaptic weight matrix, we can instead scale the count matrix in a row-by-row fashion. Specifically, we divide each row $i$ of the count matrix by the maximum of row $i$ (and some global scaling factor to ensure stability). Note that this is in contrast to $T$, where each row is divided by its sum. The resulting steady state activity matrices (Appendix 7-figure 1E).</p><p>This is closer to the SR matrix expected if the synaptic weight matrix estimates $T$. There is a slight unevenness early on in learning the diagonal of the matrix. However, given enough observed transitions, the predictive representation looks reasonable and quite similar to the SR matrix.</p><p>Overall, we see that the intuition of the reviewer is correct: there are likely other formulations of the synaptic weight matrix that can give a representation similar to the SR. The important ingredient for this to happen appears to be some form of row-dependent normalization—that is, neurons should have their synaptic weights normalized independently of each other. This ensures that occupancy is not conflated with transition statistics. We added the figures in appendix 7. We also added the following passage to the introduction of the plasticity rule in Results section 2.2 (and use the suggested reference to Fiete 2010):</p><p>“The second term in equation 4 is a form of synaptic depotentiation. Depotentiation has been hypothesized to be broadly useful for stabilizing patterns and sequence learning [37, 49], and similar inhibitory effects are known to be elements of hippocampal learning [50, 51]. In our model, the depotentiation term in equation 4 imposes local anti-Hebbian learning at each neuron—that is, each column of $J$ is normalized independently. This normalizes the observed transitions from each state by the number of visits to that state, such that transition statistics are correctly captured. We note, however, that other ways of column-normalizing the synaptic weight matrix may give similar representations (Figure S1).”</p><disp-quote content-type="editor-comment"><p>2) As the results of the paper strongly rely on the normalizing term in Equation 4. one of the reviewers suggests potentially moving upfront part of the discussion of this term, and enlarging the paragraph that discusses the biological plausibility of this specific term. Clearly laying out, for the non-expert reader, why it is biologically plausible compared to other learning rules. Also consider moving the required material to establish the novelty of such term: a targeted review of the relevant literature (current lines 358-366 and 413-433). This would allow the reader to understand immediately the significance and relative novelty of such term. For example, this reviewer personally wondered while reading the paper of how different was such term from the basic idea of Fiete et al., Neuron 2010 (DOI 10.1016/j.neuron.2010.02.003).</p></disp-quote><p>The reviewer points out that more context and clarity around the plasticity rule would be useful, particularly since an understanding of the plasticity rule is integral to the paper.</p><p>We would like to clarify that, although the RNN-S is more biologically plausible than the FF-TD learning rule, there is likely additional biological complexity/realism that can be added to the RNN-S learning rule. We wanted to find the simplest rule that could capture the essence of the SR, which is why we focused on the particular form of the learning rule we used.</p><p>Aside from plausibility, a key aspect of the RNN-S normalizing term (as discussed in Main Comment 1) is that it independently normalizes each column of the synaptic weight matrix. This is in contrast, say, to the Fiete et al., 2010 paper (which has a global depressive term) and other similar plasticity rules. We directly tested the effect of different normalizations on the RNN representations (see response to Main Comment 1), and find that column-specific normalization is important for capturing transition statistics.</p><p>To make these subtle points more clear to the reader, we added additional sentences about biological realism and other forms of learning rules in the section where the learning rule is introduced:</p><p>“Crucially, the update rule (equation 4) uses information local to each neuron (Figure 1h), an important aspect of biologically plausible learning rules.</p><p>The second term in equation 4 is a form of synaptic depotentiation. Depotentiation has been hypothesized to be broadly useful for stabilizing patterns and sequence learning [37, 49], and similar inhibitory effects are known to be elements of hippocampal learning [50, 51]. In our model, the depotentiation term in equation 4 imposes local anti-Hebbian learning at each neuron-- that is, each column of $J$ is normalized independently. This normalizes the observed transitions from each state by the number of visits to that state, such that transition statistics are correctly captured. We note, however, that other ways of column-normalizing the synaptic weight matrix may give similar representations (Figure S1).”</p><disp-quote content-type="editor-comment"><p>3) Related to the first point, the text insists on the fact that \γ is not encoded in the synaptic weights (eg line 89). Again, it is not entirely clear why this is important and justified, since γ is an ad-hoc factor in Equation 2. Presumably the proper normalisation of γ relies on the normalisation of J discussed above? It seems that this constraint could be relaxed.</p></disp-quote><p>The reviewer is correct that factorizing \γ as a separate factor from the synaptic weights (J) is a notational choice. We include the \γ as a factor distinct from the synaptic strengths for several reasons. The first is for consistency with previous literature. In the SR literature, \γ is factorized out of normalized transition matrices. Similarly, in RNN literature, it is typical to analyze a global gain factor (g), which determines the operating regime of the network (Sompolinsky et al., 1988). Our second is mechanistic. We interpret \γ as a measure of the gain of the network units, that is, as a physiological property of the neurons. The synaptic matrix J, on the other hand, measures the strengths of synapses. Keeping them separate allows for more flexibility, which leads to the third reason. Treating \γ as a separate factor allows the network to retrieve successor representations of different predictive strengths. Importantly, this dynamic predictive ability is achieved without changing any synaptic weights and without additional learning. In other words, a separate \γ allows us to decouple the learning and retrieval processes, providing more flexibility in using the SR.</p><p>To make this point more clearly in the text, we added the following lines to explain this rationale:</p><p>“Here, the factor $\γ$ represents the gain of the neurons in the network, which is factored out of the synaptic strengths characterized by J. Thus, $\γ$ is an independently adjustable factor that can flexibly control the strength of the recurrent dynamics (see [46]). A benefit of this flexibility is that the system can retrieve successor representations of varying predictive strengths by modulating the gain factor $\γ$. In this way, the predictive horizon can be dynamically controlled without any additional learning required.”</p><disp-quote content-type="editor-comment"><p>4) As a consequence of the body of the text being devoted to the analysis of the design choices behind the proposed model, a relatively smaller portion of the work involves direct comparisons with neural data. In these comparisons, while it is apparent that there is a reasonable match between the proposed model and the empirical data, it is difficult to interpret these results. This is because it is unclear what should be expected of a good or bad model given the data being analyzed (TD error and KL divergence), and reasonable baselines to compare against are not presented outside of the traditional TD algorithm, which is shown to be comparable to the proposed RNN based method in a number of cases.</p></disp-quote><p>The reviewer suggests conducting control analyses to help with interpretability of the TD error and KL divergence results. Specifically, they suggest comparing the performance of the RNN and FF network to good and bad models.</p><p>As an example of a “bad” model, we calculate the TD error and KL divergence of a feedforward network with weights randomly drawn from the distribution of weights of the FF-TD model at the end of learning. We call this the Shuffle model, and it is representative of a model without learned structure but with a similar magnitude of weights as the FF-TD model. Specifically, the shuffle model has much higher TD error than the RNN or FF network.</p><p>As an example of a “good” model, we calculate the KL divergence between randomly split halves of the dataset from Payne et al., (2021). Specifically, we compare the place field statistics of a random half of the neurons from Payne et al., (2021) with another random half. We calculate the KL divergence between the distributions calculated from each random half. This is repeated 500 times. We call this “Data” in the plot, and it is representative of a lower bound on KL divergence. Intuitively, it should not be possible to fit the data of Payne et al., as well as the dataset itself can. We compare this KL divergence to the KL divergence between each model and the neural data.</p><p>The KL divergence of the shuffle model is quite close to the FF network, suggesting that most of the “place-like” qualities of the FF network are more likely a reflection of the input features being “place-like” than the learned weights constructing these place fields. Place fields from the RNN-S model are more similar to neural data than the FF-TD or the Shuffle models. The analysis on split halves of the Payne et al., dataset shows a low KL divergence (specifically, around 0.12) that is much smaller than any of the models.</p><p>We add the two plots into the supplementary material (Figure S). Additionally, we report these results in the following sections of the main text:</p><p>In the section introducing TD error:</p><p>“We want to compare the TD loss of RNN-S to that of a non-biological model designed to minimize TD loss… Both models show a similar increase in TD loss as $\γ_R$ increases, although the RNN-S has a slightly lower TD loss at high $\γ$ than the FF-TD model. Both models perform substantially better than a random network with weights of comparable magnitude (Figure S5d).”</p><p>In the section introduced summed KL divergence:</p><p>“We combined the KL divergence of both these distributions to find the parameter range in which the RNN-S best fits neural data (Figure 6g). This optimal parameter range occurs when inputs have a spatial correlation of $\σ \approx 8.75$ cm and sparsity $\approx 0.15$. We note that the split-half noise floor of the dataset of Payne et al., is a KL divergence of $0.12$ bits (Figure S6E).</p><p>…</p><p>We next tested whether the neural data was better fit by representations generated by RNN-S or the FF-TD model. Across all parameters of the input features, despite having similar TD loss (Figure 5de), the FF-TD model has much higher divergence from neural data (Figure 6gi, Figure S6), similar to a random feedforward network (Figure S6E).”</p><disp-quote content-type="editor-comment"><p>5) It would be useful to have a “limitations” paragraph in the discussion clearly outlining what this learning rule couldn’t achieve. For example, Stachenfeld et al., Nat.Neuro. have many examples where the SR is deployed. Does the learning rule suggested by the authors would always work across the board, or are there limitations that could be highlighted where the framework suggested would not work well. No need to perform more experiments/simulations but simply to share insight regarding the results and the capability of the proposed learning rule.</p></disp-quote><p>The reviewer suggests adding further conceptual clarity to the discussion by giving insight into the limitations of the model and its differences from the Stachenfeld et al., simulations. We anticipate that the RNN-S can capture the results seen in Stachenfeld et al., since the SR learned by the algorithm in Stachenfeld et al., is identical to the representation learned by the RNN-S in the one-hot case.</p><p>However, using a recurrent architecture does impose limitations on how the learning rule is structured and how the network can be used. In particular, care must be given to avoid instability in the network due to build-up of recurrent activity. We proposed a ‘learning’ and ‘retrieval’ mode in the network precisely to control such instabilities. Furthermore, the recurrency of the network means that errors in transition structure can compound across a long horizon of prediction. This is especially problematic in the case of non-one-hot features, where greater errors in transition estimation are likely for more densely coded features.</p><p>We added a limitations paragraph in the discussion focusing on the limitations of using a recurrent network model (as opposed to a feedforward network). We also further tie these observations to biological evidence:</p><p>“There are inherent limitations to the approach of using a recurrent network to estimate the SR. For instance, network dynamics can be prone to issues of instability due to the recurrent buildup of activity. To prevent this instability, we introduce two different modes of operation, ``learning’’ and ``retrieval’’. An additional limitation is that errors in the estimated one-step transition can propagate over the course of the predictive rollout. This is especially problematic if features are more densely coded or more correlated, which makes one-step transition estimations more difficult. These insights into vulnerabilities of a recurrent network have interesting parallels in biology. Some hippocampal subfields are known to be highly recurrent [92, 93, 94, 95]. This recurrency has been linked to the propensity of the hippocampus to enter unstable regimes, such as those that produce seizures [96, 97, 98, 99]. It remains an open question how a healthy hippocampus maintains stable activity, and to what extent the findings in models such as ours can suggest biological avenues to tame instability.”</p><disp-quote content-type="editor-comment"><p>Other comments/suggestions:</p><p>– Page 1: The introduction motivates this work with a discussion of hippocampal memory (storage and retrieval), but the work focuses on the SR which is inherently prospective. The first paragraph of the text could be revised to better make this connection beyond simply stating that the hippocampus is involved in both memory and future prediction.</p></disp-quote><p>The reviewer makes an Important point, and in fact the connection between episodic memory and predictive maps in the hippocampus is an active area of research in the hippocampus field. We have edited the first paragraph of the introduction to better explain and flesh out the hypothesized connections between predictive coding in the hippocampus and its function in memory:</p><p><italic>“</italic>To learn from the past, plan for the future, and form an understanding of our world, we require memories of personal experiences. These memories depend on the hippocampus for formation and recall [1, 2, 3], but an algorithmic and mechanistic understanding of memory formation and retrieval in this region remains elusive. From a computational perspective, a key function of memory is to use past experiences to inform predictions of possible futures [4, 5, 6, 7]. This suggests that hippocampal memory is stored in a way that is particularly suitable for forming predictions.”</p><disp-quote content-type="editor-comment"><p>– Page 2: The end of the introduction would be stronger if the motivation for an RNNs usage was tied to the literature on the known recurrent dynamics of the hippocampus. See for example: https://www.frontiersin.org/articles/10.3389/fncel.2013.00262/full</p></disp-quote><p>https://www.frontiersin.org/articles/10.3389/fncel.2013.00262/full</p><p>We add the following sentences in the introduction to further motivate the usage of RNNs with known hippocampal anatomy/dynamics, adding in the suggested reference:</p><p>“A promising direction towards such a neural model of the SR is to use the dynamics of a recurrent neural network (RNN) to perform SR computations [39, 40]. An RNN model is particularly attractive as the hippocampus is highly recurrent, and its connectivity patterns are thought to support associative learning and recall [41, 42, 43, 44]. However, an RNN model of the SR has not been tied to neural learning rules that support its operation and allow for testing of specific hypotheses.”</p><disp-quote content-type="editor-comment"><p>– Page 6: It is not clear the extent to which the FF-TD model differs from a canonical tabular SR algorithm or linear SF algorithm. My understanding is that it is the same, but the presentation in Figure 1i for example makes this somewhat unclear.</p></disp-quote><p>Yes, you’re correct that the FF-TD model is exactly the linear SR/SF algorithm. We’ve added clarifying sentences in the section introducing the FF-TD model to emphasize this:</p><p><italic>“</italic>As an alternative to the RNN-S model, we consider the conditions necessary for a feedforward neural network to compute the SR. Under this architecture, the $M$ matrix must be encoded in the weights from the input neurons to the hidden layer neurons (Figure 1g). This can be achieved by updating the synaptic weights with a temporal difference (TD) learning rule, the standard update used to learn the SR in the usual algorithm… The FF-TD implements the canonical SR algorithm.”</p><disp-quote content-type="editor-comment"><p>– Pages 6 – 11: it may be of benefit to more strongly support the various modifications to the model with connections to known or hypothesized hippocampal neural dynamics.</p></disp-quote><p>The reviewer suggests motivating the modifications to the model by connecting to known biological mechanisms. We currently make these connections in the Discussion section. To make these points earlier in the paper, we summarize some of these points made in the discussion and put them earlier in the paper. Specifically, we make the following additions:</p><p>In the section introducing the anti-Hebbian term:</p><p>“The second term in equation 4 is a form of synaptic depotentiation. Depotentiation has been hypothesized to be broadly useful for stabilizing patterns and sequence learning [37, 49], and similar inhibitory effects are known to be elements of hippocampal learning [50, 51].”</p><p>In the section introducing the adaptive learning rate:</p><p>“If the learning rate of the outgoing synapses from each neuron $j$ is inversely proportional to <inline-formula><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the update equation quickly normalizes the synapses to maintain a valid transition probability matrix (Supplementary Notes 4). Modulating synaptic learning rates as a function of neural activity is consistent with experimental observations of metaplasticity [56, 57, 58]”</p><p>In the section adding a nonlinearity into network dynamics:</p><p>“One way to tame this instability is to add a saturating nonlinearity into the dynamics of the network. This is a feature of biological neurons that is often incorporated in models to prevent unbounded activity [60]. Specifically, instead of assuming the network dynamics are linear ($f$ is the identity function in equation 2), we add a hyperbolic tangent into the dynamics equation.”</p><disp-quote content-type="editor-comment"><p>– Page 14: It states that“&quot;We discretize the arena into a set of states and encode each state as a randomly drawn feature ϕ”&quot; If I understand correctly, these features are not completely random, and instead follow the distribution described in Section 2.5. As it currently reads, it seems that these features might be drawn from a uniform random distribution, which would be misleading.</p></disp-quote><p>Thank you for pointing this ou— it is true that the features in Section 2.6 are constructed the same as in Section 2.5. We’ve made this more explicitly clear in Section 2.6:</p><p><italic>“</italic>We discretize the arena into a set of states and encode each state as in Section $2.5$.”</p><disp-quote content-type="editor-comment"><p>– Page 14: In Section 2.6 there is an assumption that a certain level of TD error corresponds to good performance. It is not clear what should objectively be considered a reasonable TD error. This is especially difficult to interpret in the case where both the RNN-S and FF-TD models display comparable performance. Is there perhaps some other baseline you would expect to perform considerably worse?</p></disp-quote><p>This comment is already raised and addressed in Main Comment 4.</p><disp-quote content-type="editor-comment"><p>– Page 17: In Figure 4 it is somewhat confusing that the KL divergence (subplots G and I) has reversed shading (dark for low values) compared to the other subplots. It would be easier to interpret these graphs if their color coding was more consistent.</p></disp-quote><p>Thanks for the clarifying suggestion. We reversed the color map for KL divergence.</p><disp-quote content-type="editor-comment"><p>– Page 18: Similar to the difficulty of interpreting the TD error results, it is not clear what a“&quot;goo”&quot; or“&quot;ba”&quot; KL divergence from the neural data would be. Any hypotheses on how to ground the numbers provided here would help to improve the quality of the results.</p></disp-quote><p>This comment is already raised and addressed in Main Comment 4.</p><disp-quote content-type="editor-comment"><p>– Page 20: It is mentioned that the predictive timescale may be a separate gain term which the hippocampus takes as input, but there is evidence that different regions of the hippocampus seem to operate on different timescales. See for example: https://www.jneurosci.org/content/42/2/299.abstract. Is there a way to reconcile these ideas?</p></disp-quote><p>The reviewer points out an interesting hippocampal finding that is not obviously explained in the RNN-S model: some anatomical axes of the hippocampal formation appear to contain a continuum of predictive timescales in their neural activity (Dolorfo 1998, Brun 2008). This is a well-supported finding with interesting functional implications, and thus is worth discussing and addressing in the paper.</p><p>One way to model an anatomical gradient of predictive timescales is to use a series of RNN-S systems. Each of these systems would have a different $\γ$ values that is used during retrieval. Thus, despite these systems receiving the same feature inputs, each network can estimate the state of the animal across different timescales.</p><p>Alternatively, the gradient in timescales or granularity could exist on the input level. As in the first hypothesis, we can assume a series of RNN-S systems, except all systems utilize the same $\γ$ value during retrieval. If each system receives inputs that encode different granularities of the animal’s state space (in a spatial example: perhaps one set of inputs uses a state space that divides the arena into quadrants, while another set of inputs uses a state space that divides the arena into a 10x10 grid), then each RNN-S network will naturally develop representations across a continuum of scales.</p><p>Both these hypotheses can be functionally useful as a way to learn hierarchical structure and use that information for planning.</p><p>We choose to emphasize the first hypothesis (a gradient of $\γ$ values), and summarize this idea by add the following sentences into the discussion paragraph on flexible $\γ$:</p><p><italic>“</italic>The idea that the hippocampus might compute the SR with flexible $\γ$ could help reconcile recent results that hippocampal activity does not always match high-$\γ$ SR [79, 80]. Additionally, flexibility in predictive horizons could explain the different timescales of prediction observed across the anatomical axes of the hippocampus and entorhinal cortex [88, 89, 90, 91, 92]. Specifically, a series of successor networks with different values of γ used in retrieval could establish a gradient of predictive timescales. Functionally, this may allow for learning hierarchies of state structure and could be useful for hierarchical planning [93, 94, 95].”</p><disp-quote content-type="editor-comment"><p>– Page 23: Section 4.5 describes the procedure for learning the parameters of the weight update rule as CMA-ES. Mentioning the fact that an evolutionary algorithm is used for learning these weights would help to make Section 2.3 more clear.</p></disp-quote><p>We added additional sentences in Section 2.3 clarifying how parameters were learned:</p><p><italic>“</italic>To systematically explore the space of plasticity kernels that can be used to learn the SR, we performed a grid search over the sign and the time constants of the pre -&gt; post and post -&gt; pre sides of the plasticity kernels. For each fixed sign and time constant, we used an evolutionary algorithm to learn the remaining parameters that determine the plasticity kernel.”</p><disp-quote content-type="editor-comment"><p>– figures 5D-E and similar supplementary figures: if there is a parameter region that is unexplored then the color used for such region should be outside of the colormap. One of the reviewers suggests replacing white with gray for such region in these figures.</p></disp-quote><p>Thanks for the clarifying suggestion. We switched the color of the unexplored region from white to gray.</p><disp-quote content-type="editor-comment"><p>– Line 173: the text makes the distinction between an“&quot;SR-lik”&quot; representation, and an“&quot;exact S”&quot;. What is the difference? Why is it important to have an exact of the SR in the neural activity, rather then eg a monotonic encoding of the SR?</p></disp-quote><p>By “exact SR”, we mean the error between the steady state dynamics matrix and the SR matrix is precisely zero. “SR-like” was our loose way of referring to representation matrices with some amount of mean absolute error from the SR matrix that was still seemingly minimal but not zero.</p><p>The reviewer raises an important question about how crucial it is for the network to learn the SR exactly, versus other representations that may also capture long-horizon predictions.</p><p>This is similar in spirit to the question raised in Main Comment 1. We showed in an analysis for Main Comment 1 that it may not be necessary to learn the SR exactly, and that a range of possible rules may yield similar representations. The SR is convenient as a reasonable formalization of long-horizon predictions. The analysis referenced in line 173 (Figure 2J) also shows that plasticity kernels with varying time constants yield representations that are similar to the SR.</p><p>We clarify the statement previously in line 173 to remove the term “is SR-like” with “has minimal error from the SR matrix”. We also emphasize that the results of the analysis further supports that many predictive representations look similar to each other, and that an exactathemaatical equivalence to the SR is not the most important aspect of a predictive representation:</p><p><italic>“</italic>Finally, we see that even plasticity kernels with slightly different time constants may give results with minimal error from the SR matrix, even if they do not estimate the SR exactly (Figure 2j). This suggests that, although other plasticity rules could be used to model long-horizon predictions, the SR is a reasonable—-though not strictly uniqu— model to describe this class of predictive representations.”</p><disp-quote content-type="editor-comment"><p>– The RNN described in Equation 2 is not of the standard form (the non-linearity is applied after the connectivity matrix, ie f(J x) instead of Jf(x)). Is this detail important? If not, why not use the more standard form to avoid confusion?</p></disp-quote><p>The reviewer points out that our equation uses <inline-formula><mml:math id="sa2m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. It is standard to use either a firing rate representation (<inline-formula><mml:math id="sa2m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mi>r</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) or a voltage representation (<inline-formula><mml:math id="sa2m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>J</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). Choosing between the firing rate or voltage representation is not critical. Indeed, if input is not considered, these forms are equivalent up to a transformation (Miller and Fumarola 2012).</p><p>Nevertheless, the reviewer is correct that we used a non-conventional amalgamation of these two standard forms.</p><p>We re-ran analyses using Jf(x) instead of f(J x). We find that there is no obvious difference in the results generated. We updated the equation in the text to match the standard form. We then updated Figures 3, 5, 6, S3, S5, S6 to reflect this change in the model.</p><disp-quote content-type="editor-comment"><p>– A line of work in the Fusi lab has examined plasticity rules that lead to the encoding of transition probabilities (eg Fusi et al., Neuron 2007). In particular, a paper by the reviewing editor (Ostojic and Fusi Front Comp Neuro 2013) examined the encoding of transition probabilities using plasticity rules that look similar to this manuscript. This is mentioned just for information, the authors should decide if those papers are relevant.</p></disp-quote><p>Thanks for the recommendation— the Ostojic and Fusi paper is indeed quite relevant. It seems like equation 2 of the Ostojic and Fusi paper is the same as our plasticity rule under one-hot encoding assumptions. In the case with more complex input features, the Ostojic and Fusi paper would be identical to the “Independent Normalization” model we present as comparison in Figure 4.</p><p>Overall, it is promising and exciting to find another study that arrives at similar conclusions: “Our study shows that synapses encode transition probabilities under general assumptions and this indicates that temporal contiguity is likely to be encoded and harnessed in almost every neural circuit in the brain.” (from the abstract of Ostojic and Fusi).</p><p>We have updated the discussion to include this reference:</p><p>“Estimating $T$ directly provides RNN-S with a means to sample likely future trajectories, or distributions of trajectories, which is computationally useful for many memory-guided cognitive tasks beyond reinforcement learning, including reasoning and inference (Ostojic et al., 2013, Goodman et al., 2016). The representation afforded by $T$ may also be particularly accessible by neural circuits. Ostojic et al., (2013) note that only few general assumptions are needed for synaptic plasticity rules to estimate transition statistics. Thus, it is reasonable to assume that some form of transition statistics are encoded broadly across the brain.”</p><disp-quote content-type="editor-comment"><p>– Figures 5D-E and similar supplementary figures: if there is a parameter region that is unexplored then the color used for such region should be outside of the colormap. One of the reviewers suggests replacing white with gray for such region in these figures.</p></disp-quote><p>This is a duplicate comment of another comment and has been fixed.</p></body></sub-article></article>