<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">94835</article-id><article-id pub-id-type="doi">10.7554/eLife.94835</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94835.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural coding of multiple motion speeds in visual cortical area MT</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Huang</surname><given-names>Xin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9788-5383</contrib-id><email>xin.huang@wisc.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Ghimire</surname><given-names>Bikalpa</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9004-3201</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Chakrala</surname><given-names>Anjani Sreeprada</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7579-8139</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wiesner</surname><given-names>Steven</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8528-1096</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01y2jtd41</institution-id><institution>Department of Neuroscience, University of Wisconsin-Madison</institution></institution-wrap><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Groh</surname><given-names>Jennifer M</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Duke University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>06</day><month>01</month><year>2026</year></pub-date><volume>13</volume><elocation-id>RP94835</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-01-03"><day>03</day><month>01</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-11-22"><day>22</day><month>11</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.08.532456"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-03-28"><day>28</day><month>03</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94835.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-07-17"><day>17</day><month>07</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94835.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-12-01"><day>01</day><month>12</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94835.3"/></event></pub-history><permissions><copyright-statement>© 2024, Huang et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Huang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-94835-v1.pdf"/><abstract><p>Motion speed is a salient cue for visual segmentation, yet how the visual system represents and differentiates multiple speeds remains unclear. Here, we investigated the encoding and decoding of multiple speeds. We first characterized the perceptual capacity of human and macaque subjects to segment overlapping stimuli moving at different speeds. We then determined how neurons in area MT of macaque monkeys represent multiple speeds. We found that the responses of MT neurons to two speeds showed a robust bias toward the faster speed component. This faster-speed bias occurred when both speeds were slow (≤20°/s) and diminished as stimulus speed increased. Our findings can be explained by a modified divisive normalization model, in which the weights for the speed components are proportional to the responses of a population of neurons (the weighting pool) with a broad range of speed preferences, elicited by the individual speeds. Regarding decoding, a classifier could distinguish MT responses to two speeds from those to a corresponding log-mean speed. We further found that it was possible to decode two speeds from the MT population response, supporting the theoretical framework of coding multiplicity in neuronal populations. The decoded speeds can account for perceptual performance in segmenting two speeds with a large (4x) but not a small (2x) separation. Our findings help define the neural coding rule of multiple speeds. The faster-speed bias in MT could benefit important behavioral tasks, such as figure-ground segregation, as figural objects tend to move faster than the background in the natural environment.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>segmentation</kwd><kwd>transparent motion</kwd><kwd>figure-ground segregation</kwd><kwd>divisive normalization</kwd><kwd>decoding</kwd><kwd>efficient coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03wkg3b53</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R01EY022443</award-id><principal-award-recipient><name><surname>Huang</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Neuronal responses in cortical area MT to two speeds show a robust bias toward the faster speed when stimulus speeds are slow, which could benefit figure-ground segregation in natural scenes.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Neuroscientists have been investigating how neurons in the brain represent sensory information for decades. Previous studies have often focused on the neural coding of a single visual stimulus. However, natural environments are abundant with multiple entities that often co-occupy the receptive fields (RFs) of visual neurons. Segmenting visual objects from one another and their background is a fundamental function of vision (<xref ref-type="bibr" rid="bib11">Braddick, 1993</xref>). Yet, the neural mechanisms underlying the representation of multiple stimuli remain poorly understood. As the field moves toward understanding visual processing under more naturalistic conditions, it becomes increasingly important to uncover the principles by which the brain encodes multiple stimuli. Visual motion is a particularly salient cue for scene segmentation. Elements that share common motion are typically grouped into a single perceptual object, while entities moving at different velocities can often be segregated from each other. For instance, an object moving at a speed distinct from its background is more readily segmented. In this study, we investigated how the primate visual system represents multiple motion speeds.</p><p>The extrastriate area MT plays a crucial role in motion processing and motion-based segmentation (<xref ref-type="bibr" rid="bib1">Allman et al., 1985</xref>; <xref ref-type="bibr" rid="bib15">Britten, 2003</xref>; <xref ref-type="bibr" rid="bib10">Born and Bradley, 2005</xref>; <xref ref-type="bibr" rid="bib55">Pasternak and Tadin, 2020</xref>; <xref ref-type="bibr" rid="bib9">Born et al., 2000</xref>; <xref ref-type="bibr" rid="bib28">Huang et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Huang et al., 2008</xref>). Segmentation of overlapping stimuli moving in different directions and speeds gives rise to the perception of transparent motion (<xref ref-type="bibr" rid="bib12">Braddick, 1997</xref>; <xref ref-type="bibr" rid="bib13">Braddick et al., 2002</xref>; <xref ref-type="bibr" rid="bib46">Mestre et al., 2001</xref>; <xref ref-type="bibr" rid="bib43">Masson et al., 1999</xref>). Previous studies have investigated how neurons in MT represent two directions of transparently moving stimuli (<xref ref-type="bibr" rid="bib71">Snowden et al., 1991</xref>; <xref ref-type="bibr" rid="bib62">Qian et al., 1994</xref>; <xref ref-type="bibr" rid="bib45">McDonald et al., 2014</xref>; <xref ref-type="bibr" rid="bib81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="bib82">Xiao and Huang, 2015</xref>; <xref ref-type="bibr" rid="bib79">Wiesner et al., 2020</xref>; <xref ref-type="bibr" rid="bib73">Stoner and Albright, 1992</xref>; <xref ref-type="bibr" rid="bib37">Krekelberg and van Wezel, 2013</xref>). Although how cortical neurons represent the speed of a single stimulus has been well-studied (<xref ref-type="bibr" rid="bib44">Maunsell and Van Essen, 1983</xref>; <xref ref-type="bibr" rid="bib39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="bib51">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="bib54">Pack et al., 2005</xref>; <xref ref-type="bibr" rid="bib35">Krekelberg et al., 2006a</xref>; <xref ref-type="bibr" rid="bib56">Perrone and Thiele, 2001</xref>; <xref ref-type="bibr" rid="bib59">Priebe et al., 2003</xref>; <xref ref-type="bibr" rid="bib61">Priebe et al., 2006</xref>; <xref ref-type="bibr" rid="bib40">Liu and Newsome, 2003</xref>), how neurons represent multiple speeds of transparently moving stimuli is largely unknown.</p><p>In characterizing how MT neurons represent multiple directions of transparently moving stimuli, we have previously shown that many neurons do not pool two directions equally, but weigh one direction more than the other (<xref ref-type="bibr" rid="bib82">Xiao and Huang, 2015</xref>). We have also found that some MT neurons exhibit response nonlinearity when pooling two directions, in a manner that better represents the individual direction components. The heterogeneous response weights and response nonlinearity in representing multiple directions can benefit the neural coding of multiple stimuli (<xref ref-type="bibr" rid="bib53">Orhan and Ma, 2015</xref>; <xref ref-type="bibr" rid="bib82">Xiao and Huang, 2015</xref>), and may constitute an optimal population representation of visual motion with multiple directions (<xref ref-type="bibr" rid="bib31">Huang et al., 2017</xref>). Unlike two motion directions for which the individual directions appear to be balanced in perceptual quality and salience, visual stimuli moving at two speeds appear to be asymmetrical – one slower and one faster. The goal of this study is to determine the neural coding principle for multiple speeds of overlapping stimuli.</p><p>Visual information is encoded in the brain by populations of neurons, and Bayesian inference provides a robust framework for understanding the population neural code (<xref ref-type="bibr" rid="bib57">Pouget and Snyder, 2000</xref>; <xref ref-type="bibr" rid="bib6">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="bib23">Fiser et al., 2010</xref>). Additionally, the visual system may be optimized to represent information in natural environments and to enhance performance in key behavioral tasks (<xref ref-type="bibr" rid="bib8">Barlow, 1961</xref>; <xref ref-type="bibr" rid="bib4">Atick and Redlich, 1992</xref>; <xref ref-type="bibr" rid="bib70">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="bib25">Ganguli and Simoncelli, 2014</xref>; <xref ref-type="bibr" rid="bib42">Manning et al., 2024</xref>). Within this framework, we consider several scenarios for how MT neurons might encode two speeds within their RFs. (1) <italic>Response averaging</italic>: MT neurons may average the responses elicited by individual speed components, a phenomenon often observed in neural responses to multiple stimuli (e.g. <xref ref-type="bibr" rid="bib63">Recanzone et al., 1997</xref>; <xref ref-type="bibr" rid="bib86">Zoccolan et al., 2005</xref>). When the separation between the two speeds is smaller than the neuron’s tuning width, the population response to two speeds would appear unimodal, peaking at an intermediate speed. While decoding two stimuli from a unimodal response is theoretically possible (<xref ref-type="bibr" rid="bib84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib74">Treue et al., 2000</xref>), response averaging may result in poorer segmentation compared to encoding schemes that emphasize individual components, as demonstrated in neural coding of overlapping motion directions (<xref ref-type="bibr" rid="bib82">Xiao and Huang, 2015</xref>). (2) <italic>Bias toward the stronger component response</italic>: A neuron may favor the speed component that elicits a stronger response, following a soft-max operation (<xref ref-type="bibr" rid="bib64">Riesenhuber and Poggio, 1999</xref>). This scheme allows neurons to preferentially encode stimuli at speeds closer to their preferred speeds and maintain a population code that represents both components. (3) <italic>Bias toward the slower speed component</italic>: Given that slower speeds are more prevalent in natural environments (<xref ref-type="bibr" rid="bib78">Weiss et al., 2002</xref>; <xref ref-type="bibr" rid="bib72">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="bib85">Zhang and Stocker, 2022</xref>), MT neurons may favor slower components. Such encoding would align with the prior probability of natural speed distributions, optimizing for more frequent stimuli. (4) <italic>Bias toward the faster speed component</italic>: Neurons may prioritize faster-moving components. This scheme would enable better segmentation of a faster-moving stimulus from a slower background, facilitating the critical perceptual task of figure-ground segregation. Finally, we investigated whether these encoding rules are dependent on stimulus speeds and the speed preferences of individual neurons.</p><p>Regarding neural decoding, previous studies successfully extracted single stimulus speeds from neuronal populations in MT using decoders, such as vector-averaging and maximum likelihood estimators (<xref ref-type="bibr" rid="bib39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="bib22">Cherian and Maunsell, 2025</xref>; <xref ref-type="bibr" rid="bib60">Priebe and Lisberger, 2004</xref>; <xref ref-type="bibr" rid="bib30">Huang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="bib83">Yang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="bib35">Krekelberg et al., 2006a</xref>; <xref ref-type="bibr" rid="bib36">Krekelberg et al., 2006b</xref>; <xref ref-type="bibr" rid="bib37">Krekelberg and van Wezel, 2013</xref>). However, it is unclear whether simultaneously presented multiple speeds can be extracted from population neural responses, which would be difficult for decoders that only read out a single value. Zemel and colleagues developed a decoding framework that recovers the probabilistic distribution of a stimulus feature (<xref ref-type="bibr" rid="bib84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib58">Pouget et al., 2003</xref>). Decoders of this type remain to be tested with neurophysiological and perceptual data.</p><p>We first characterized the perception of overlapping stimuli that moved simultaneously at two speeds. Our results showed that human and monkey subjects can segment overlapping stimuli based only on speed cues. The performance was better when the separation between the two stimulus speeds was larger, and the ability to segment speeds was reduced when stimulus speeds were fast. Next, we recorded neuronal responses from area MT of macaque monkeys. We made a novel finding that MT neurons exhibited a strong faster-speed bias when stimulus speeds were slow. As stimulus speeds increased, the faster-speed bias gradually shifted toward response averaging. We also demonstrated that a classifier could distinguish between a two-speed stimulus and a single-speed stimulus based on MT responses in a manner generally consistent with perception. We proposed a model in which each speed component was weighted by the responses of a population of neurons with a broad range of speed preferences elicited by that speed component. We also found that information about two speeds was carried in the population neural response in MT, and it was possible to extract either a single speed or two speeds in a way largely consistent with perception, with limitations when two stimulus speeds were less separated from each other. This study helps to fill a gap in understanding the neural coding principle of multiple motion speeds. It provides new insight into the mechanism underlying the neural representation of multiple visual stimuli.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Perception of overlapping stimuli moving at different speeds</title><sec id="s2-1-1"><title>Human psychophysics</title><p>To establish the perceptual basis for our study, we first characterized how human subjects perceived overlapping stimuli moving at different speeds. We used similar visual stimuli in our psychophysics experiments as in our neurophysiology experiments. We asked how perceptual segmentation was impacted by the separation between two stimulus speeds and the mean stimulus speed.</p><p>The visual stimuli consisted of two overlapping random-dot patches presented within a stationary square aperture, 10° wide, and centered at an eccentricity of 11°. The random dots translated within the aperture in the same direction at two different speeds. It has been suggested that the neural encoding of speed in the visual cortex is on a logarithmic scale (<xref ref-type="bibr" rid="bib44">Maunsell and Van Essen, 1983</xref>; <xref ref-type="bibr" rid="bib39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="bib51">Nover et al., 2005</xref>). We used a fixed ratio between two speeds, which resulted in a fixed speed difference on the logarithmic scale. One set of stimuli had a ‘large speed separation,’ and the speed of the faster component was four times that of the slower component. The five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref ref-type="fig" rid="fig1">Figure 1B1</xref>). Another set of stimuli had a ‘small speed separation,’ and the speed ratio was two. The five-speed pairs were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref ref-type="fig" rid="fig1">Figure 1B2</xref>). Experimental trials of bi-speed stimuli that had large and small speed separations were randomly interleaved.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Psychophysical tasks and performance of human subjects.</title><p>(<bold>A</bold>) Illustration of the 2AFC and 3AFC tasks. (<bold>B</bold>) Motion speeds of visual stimuli. The speeds of two stimulus components were plotted versus the log mean speed of each bi-speed stimulus. (<bold>C</bold>) Discriminability of four human subjects performing a standard 2AFC task. Letters are coded symbols for individual subjects. (<bold>D</bold>) In the 3AFC task, the percentage of trials that human subjects reported ‘no two-speeds.’ (<bold>E</bold>) Discriminability of the same subjects performing the 3AFC task. (<bold>B1–E1</bold>) 4x speed separation. (<bold>B2–E2</bold>) 2x speed separation. Each color represents data from one subject. The solid line shows the subject-averaged result. Error bars and error bands represent ± STE. For each subject, five (n=5) blocks of experimental trials were tested, with 40 trials in each block (a total of 200 trials). Number of subjects (n = 4).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig1-v1.tif"/></fig><p>Human subjects first performed a standard two-alternative forced-choice (2AFC) task to discriminate a bi-speed stimulus from the corresponding single-speed stimulus that moved at the log mean speed of the two component speeds. In each trial, the bi-speed and single-speed stimuli were presented in two consecutive time intervals in a random and balanced order (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). At large (4x) speed separation, all four subjects could perform the task well when the component speeds were less than 20 and 80°/s (<xref ref-type="fig" rid="fig1">Figure 1C1</xref>). At 20 and 80°/s, the discrimination performance was poor (mean <italic>d’</italic>=0.74, standard error STE = 0.5), indicating that subjects could not segment the speed components. At the small (2x) speed separation, the discriminability was worse than at the 4x separation. When the component speeds were less than 20 and 40°/s, subjects on average could differentiate the bi-speed stimulus from the single-speed stimulus (<italic>d’</italic>&gt;1.5), but not when speeds were at 20 and 40°/s (mean <italic>d’</italic>=0.17, STE = 0.1) (<xref ref-type="fig" rid="fig1">Figure 1C2</xref>).</p><p>In the standard 2AFC task, it is possible that subjects could not segment the bi-speed stimulus into two separate speeds but were still able to differentiate the bi-speed stimulus from the single-speed stimulus based on their appearance (e.g. the distribution of random dots in the bi-speed stimulus may appear less uniform). To address this concern, we designed a novel 3AFC task to measure discriminability based on perceptual segmentation. In the modified task, subjects still discriminated the bi-speed stimulus from the corresponding single-speed stimulus, but had the option to make a third choice on trials when they thought neither stimulus interval appeared to contain two speeds (‘no two-speeds’ choice) (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Panels D1 and D2 show the percentage of trials in which subjects made the no two-speeds choice (NTC). At 4x speed separation, the percentage of NTC was low at most speed pairs, except for the highest speeds of 20 and 80°/s (<xref ref-type="fig" rid="fig1">Figure 1D1</xref>). At 2x speed separation, the percentage of NTC showed a U-shape as a function of the stimulus speed and was near 100% at 20 and 40°/s (<xref ref-type="fig" rid="fig1">Figure 1D2</xref>). These results confirmed that human subjects had difficulty segmenting two speeds when stimulus speeds were high. In addition, at low stimulus speeds with a small (2x) speed separation, subjects tended to perceive only one speed (<xref ref-type="fig" rid="fig1">Figure 1D2</xref>). We incorporated the NTC into the <italic>d’</italic> calculation by evenly splitting the NTC trials into ‘hit’ trials and ‘false alarm’ trials (see Methods). In this way, the NTC trials were accounted for by <italic>d’</italic>, in the sense that they did not contribute to successful discrimination.</p><p>The <italic>d’</italic> from the 3AFC task were similar to those of the 2AFC task, with a slight reduction across conditions as the NTC trials reduced discrimination performance (<xref ref-type="fig" rid="fig1">Figure 1E1 vs 1C1, 1E2 vs 1C2</xref>). The small performance difference between the 2AFC and 3AFC tasks suggests that human subjects generally relied on speed segmentation to perform the 2AFC task. Based on the results from the 3AFC task, we performed a two-way ANOVA, with the two factors being the mean speed of the stimulus components and the speed separation (4x or 2x). We found that both factors had significant effects. <italic>d’</italic> changed significantly with the mean stimulus speed (F(4,30) = 26.8, <italic>p</italic>=1.60 × 10<sup>–9</sup>) and the <italic>d’</italic> at 4x separation differed significantly from that at 2x separation (F(1,30) = 84.1, <italic>p</italic>=3.29 × 10<sup>–10</sup>). <italic>d’</italic> was higher at 4x than at 2x speed separation except at the fastest speeds of 20 and 80°/s vs. 20 and 40°/s (<xref ref-type="fig" rid="fig1">Figure 1E1 vs 1E2</xref>). Our results also showed that segmentation was significantly worse at fast speeds – <italic>d'</italic> dropped significantly as the stimulus speeds increased from 10 and 40°/s to 20 and 80°/s for 4x separation (one-way ANOVA, F(1,6) = 38.6, <italic>p</italic>=8.1 × 10<sup>–4</sup>) (<xref ref-type="fig" rid="fig1">Figure 1E1</xref>), and from 10 and 20°/s to 20 and 40°/s for 2x separation (one-way ANOVA, F(1,6) = 32.7, <italic>p</italic>=1.24 × 10<sup>–3</sup>) (<xref ref-type="fig" rid="fig1">Figure 1E2</xref>).</p></sec><sec id="s2-1-2"><title>Monkey psychophysics</title><p>We next measured the monkey’s ability to segment overlapping stimuli moving at two speeds. We trained one male macaque monkey to perform a 2AFC task, in which it reported whether a stimulus contained one or two speeds (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, see Methods). The monkey’s performance at 2x speed separation (<xref ref-type="fig" rid="fig2">Figure 2B2</xref>) was very similar in shape to that of humans (<xref ref-type="fig" rid="fig1">Figure 1C2</xref> of the 2AFC task). In addition, the monkey’s performance was generally better at 4x separation than at 2x separation (<xref ref-type="fig" rid="fig2">Figure 2B1 vs B2</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Monkey psychophysics.</title><p>(<bold>A</bold>) The behavioral task and visual stimuli. (<bold>B</bold>) Discriminability of a monkey subject performing a 2AFC task. (<bold>B1</bold>) 4x speed separation. Total 50 trials in 5 sessions for each speed pair. (<bold>B2</bold>) 2x speed separation. Total 90 trials in 9 sessions for each speed pair. Error bars and error bands represent ± STE (n = 5 for 4x, n = 9 for 2x speed separation).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig2-v1.tif"/></fig><p>At 4x separation, performance improved as stimulus speeds increased from 1.25 and 5°/s to 5 and 20°/s. As the stimulus speeds increased from 5 and 20°/s to 20 and 80°/s, the performance declined (<xref ref-type="fig" rid="fig2">Figure 2B1</xref>), similar to the human results (<xref ref-type="fig" rid="fig1">Figure 1C1</xref>). However, the monkey was still able to differentiate the bi-speed and single-speed stimuli at the fastest speeds of 20 and 80°/s (<xref ref-type="fig" rid="fig2">Figure 2B1</xref>), whereas the average human performance was poor (<xref ref-type="fig" rid="fig1">Figure 1C1</xref>). Note that one human subject (NP) performed better than other subjects at 20 and 80°/s (mean <italic>d’</italic>=2.12, STE = 0.12) (<xref ref-type="fig" rid="fig1">Figure 1C1</xref>). The difference between the monkey and human results may be due to species differences or individual variability. The differences in behavioral tasks may also play a role – the monkey received feedback on the correctness of the choice (except for 20 and 80°/s and 20 and 40°/s), whereas human subjects did not.</p><p>Another notable difference between the monkey and human results was that, at low stimulus speeds of 1.25 and 5°/s, human subjects could differentiate the bi-speed stimulus from the corresponding single-speed (2.5°/s) stimulus nearly perfectly. In comparison, the ability of the monkey subject to segment 1.25 and 5°/s was lower (<italic>d’</italic>=2.8, STE = 0.51), although still good (<xref ref-type="fig" rid="fig2">Figure 2B1</xref> vs <xref ref-type="fig" rid="fig1">Figure 1C1</xref>). This may be explained by how the monkey performed the task. For human subjects, while the motion of the faster component (5°/s) of the bi-speed stimulus appeared to be salient, it required effort to notice the very slow component (1.25°/s) to be moving rather than stationary. In some trials, the monkey might be able to segment the 5°/s component from the bi-speed stimulus but consider the slower component of 1.25°/s as stationary and, therefore, reported that the stimulus contained only one speed. Despite some differences between the human and monkey results, the two general trends – better segmentation performance at larger than smaller speed separation and reduced segmentation ability at very fast speeds were consistent across species.</p></sec></sec><sec id="s2-2"><title>Neuronal responses in MT elicited by bi-speed stimuli and single-speed components</title><p>To characterize how neurons in the visual cortex encode overlapping stimuli moving at different speeds, we recorded extracellularly from 100 isolated neurons in area MT of two male macaque monkeys (60 neurons from IM and 40 neurons from MO) while they performed a fixation task. <xref ref-type="fig" rid="fig3">Figure 3</xref> shows the responses from four example neurons. To visualize the relationship between the responses to the bi-speed stimulus (red) and the constituent speed components, the plots of the response tuning curves to the slower (green) and faster (blue) components are shifted horizontally so that the responses elicited by the bi-speed stimulus and its constituent single-speed components are aligned along a vertical line, as illustrated in <xref ref-type="fig" rid="fig3">Figure 3A1</xref>.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Speed tuning curves of four example neurons to bi-speed stimuli and constituent single-speed components.</title><p>(<bold>A</bold>) Illustration of the visual stimuli and the response tuning curves of an example neuron. Green and blue dots in the diagram indicate two overlapping achromatic random-dot patterns moving in the same direction at different speeds. Colors are used for illustration purposes only. The abscissas in green and blue show the speeds of the slower and faster components, respectively. The abscissa in black shows the log mean speed of the two speed components. (<bold>A–D</bold>) Four example neurons are sorted by their preferred speeds (PS) from slow to fast. Error bars represent ±STE. For some data points, error bars were comparable to the symbol size. (<bold>A1–D1</bold>) 4x speed separation. (<bold>A2–D2</bold>) 2x speed separation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig3-v1.tif"/></fig><p>We found that the relationship between the responses elicited by the bi-speed stimulus and the constituent components depended on the stimulus speeds. <xref ref-type="fig" rid="fig3">Figure 3A1–D1</xref> shows the neuronal responses when the speed separation was large (4x). The component speeds were the same as the bi-speed stimuli used in the psychophysics experiments. When the two component speeds were slow (1.25 and 5°/s), the response to the bi-speed stimulus nearly followed the response elicited by the faster-speed component (the leftmost data points in <xref ref-type="fig" rid="fig3">Figure 3A1–D1</xref>). Importantly, the response elicited by the bi-speed stimuli did not simply follow the stronger component response. When the preferred speed of a neuron was sufficiently low such that the response elicited by the faster component was weaker than that elicited by the slower component, the response to the bi-speed stimulus still followed the weaker response elicited by the faster component (<xref ref-type="fig" rid="fig3">Figure 3A1</xref>). When the speeds of the two stimulus components were at 2.5 and 10°/s, the response elicited by the bi-speed stimulus was also biased toward the faster component, albeit to a lesser degree. As the mean speed of the two stimulus components increased, the bi-speed response became closer to the average of the two component responses (<xref ref-type="fig" rid="fig3">Figure 3A1–D1</xref>). We found similar results when the speed separation between the two components was small (2x) (<xref ref-type="fig" rid="fig3">Figure 3A2–D2</xref>).</p><p>We found the same trend in the neural responses averaged across 100 neurons (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). At 4x speed separation, the population-averaged response showed a strong bias toward the faster component when the stimulus speeds were low and shifted toward the average of the component responses as the speeds increased (<xref ref-type="fig" rid="fig4">Figure 4A1</xref>). To determine whether this trend held for neurons with different preferred speeds, we divided the neuron population into three groups with ‘low’ (&lt;2.5°/s), ‘intermediate’ (between 2.5 and 25°/s), and ‘high’ (&gt;25°/s) preferred speeds. For 10 neurons that preferred low speeds, the response to the faster component was weaker than that to the slower component. However, the response to the bi-speed stimuli was strongly biased toward the faster component when the stimulus speeds were low (<xref ref-type="fig" rid="fig4">Figure 4B1</xref>). This finding suggests that the bi-speed response is not biased toward the stimulus component that the neuron prefers when presented alone, but biased toward the faster speed component.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components.</title><p>Speed tuning curves averaged across: (<bold>A</bold>) 100 neurons in our dataset. (<bold>B</bold>) 10 neurons that had preferred speeds (PS) lower than 2.5°/s. (<bold>C</bold>) 61 neurons that had PS between 2.5 and 25°/s. (<bold>D</bold>) 29 neurons that had PS greater than 25°/s. Error bars represent ± STE. For some data points, error bars were comparable to the symbol size. (<bold>A1–D1</bold>) 4x speed separation. (<bold>A2–D2</bold>) 2x speed separation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig4-v1.tif"/></fig><p>For 61 neurons that preferred intermediate speeds (<xref ref-type="fig" rid="fig4">Figure 4C1</xref>) and 29 neurons that preferred high speeds (<xref ref-type="fig" rid="fig4">Figure 4D1</xref>), we also found a strong bias toward the faster speed component when the stimulus speeds were low, and a gradual change toward the average of the component responses as the stimulus speeds increased. At the lowest stimulus speeds of 1.25 and 5°/s, the bi-speed response was nearly identical to that elicited by the faster component, showing ‘faster-component-take-all.’ For neurons that preferred high speeds, faster-component-take-all was also found for the stimulus speeds of 2.5 and 10°/s (<xref ref-type="fig" rid="fig4">Figure 4D1</xref>). At the fastest speeds of 20 and 80°/s, the response to the bi-speed stimuli showed a slight bias toward the slower component (<xref ref-type="fig" rid="fig4">Figure 4D1</xref>). We found similar results at 2x speed separation (<xref ref-type="fig" rid="fig4">Figure 4A2–D2</xref>), although the effect is not as pronounced as 4x speed separation.</p></sec><sec id="s2-3"><title>Relationship between the responses to bi-speed stimuli and constituent stimulus components</title><p>We aimed to quantify the relationship between the response elicited by the bi-speed stimuli and the corresponding component responses. We first assumed that the response <italic>R</italic> of a neuron elicited by two component speeds can be described as a weighted sum of the component responses <italic>R<sub>s</sub></italic> and <italic>R<sub>f</sub></italic> elicited by the slower (<inline-formula><alternatives><mml:math id="inf1"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$v_{s}$\end{document}</tex-math></alternatives></inline-formula>) and faster (<inline-formula><alternatives><mml:math id="inf2"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}$v_{f}$\end{document}</tex-math></alternatives></inline-formula>) component speed, respectively <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>.<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle R\left (v_{s},v_{f}\right)=w_{s}\left (v_{s},v_{f}\right)\bullet R_{s}+w_{f}\left (v_{s},v_{f}\right)\bullet R_{f},$$\end{document}</tex-math></alternatives></disp-formula></p><p>in which, <italic>w<sub>s</sub></italic> and <italic>w<sub>f</sub></italic> are the response weights for the slower and faster speed component <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mspace width="mediummathspace"/><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mspace width="mediummathspace"/><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$v_{s} \\gt and \\gtv_{f}$\end{document}</tex-math></alternatives></inline-formula>, respectively.</p><p>Our goal was to estimate the weights for each speed pair and determine whether the weights change with the stimulus speeds. In our main data set, the two speed components moved in the same direction. To determine the weights of <inline-formula><alternatives><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft4">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula> and <italic>w<sub>f</sub></italic> for each neuron at each speed pair, we have three data points <italic>R, R<sub>s</sub></italic>, and <italic>R<sub>f</sub></italic>, which are trial-averaged responses. Since it is not possible to solve for both variables, <inline-formula><alternatives><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft5">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula> and <italic>w<sub>f</sub></italic>, from a single equation <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> with three data points, we introduced an additional constraint: <inline-formula><alternatives><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft6">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula> + <italic>w<sub>f</sub></italic> = 1. With this constraint, the weighted sum becomes a weighted average. While this constraint may not yield the exact weights that would be obtained with a fully determined system, it nevertheless allows us to characterize how the relative weights vary with stimulus speed. As long as <italic>R<sub>f</sub></italic> ≠ <italic>R<sub>s</sub></italic>, <italic>R</italic> can be expressed as:<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle R=\frac{R_{f}- R}{R_{f}- R_{s}}R_{s}+\frac{R- R_{s}}{R_{f}- R_{s}}R_{f},$$\end{document}</tex-math></alternatives></disp-formula></p><p>The response weights are <inline-formula><alternatives><mml:math id="inf7"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}$w_{s}=\frac{R_{f}- R}{R_{f}- R_{s}}$\end{document}</tex-math></alternatives></inline-formula> , <inline-formula><alternatives><mml:math id="inf8"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft8">\begin{document}$w_{f}=\frac{R- R_{s}}{R_{f}- R_{s}}$\end{document}</tex-math></alternatives></inline-formula>. Intuitively, if <italic>R</italic> were closer to one component response, that stimulus component would have a higher weight. Note that <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> is not intended for fitting the response <italic>R</italic> using <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf10"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft10">\begin{document}$R_{f}$\end{document}</tex-math></alternatives></inline-formula>, but rather to use the relationship among <italic>R,</italic> <inline-formula><alternatives><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft11">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft12">\begin{document}$R_{f}$\end{document}</tex-math></alternatives></inline-formula> to determine the weights for the faster and slower components.</p><p>Using this approach to estimate response weights for individual neurons can be unreliable, particularly when <italic>R<sub>f</sub></italic> and <italic>Rs</italic> are similar. This situation often arises when the two speeds fall on opposite sides of the neuron’s preferred speed, resulting in a small denominator (<italic>R<sub>f</sub> – Rs</italic>) and consequently an artificially inflated weight estimate. We, therefore, used the neuronal responses across the population to determine the response weights (<xref ref-type="fig" rid="fig5">Figure 5</xref>). For each pair of stimulus speeds, we plotted (<italic>R−R<sub>s</sub></italic>) in the ordinate versus (<italic>R<sub>f</sub> − R<sub>s</sub></italic>) in the abscissa. <xref ref-type="fig" rid="fig5">Figure 5A1–E1</xref> shows the results obtained at 4x speed separation. Across the neuronal population, the relationship between (<italic>R - R<sub>s</sub></italic>) and (<italic>R<sub>f</sub> − R<sub>s</sub></italic>) can be described by a linear equation (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) (see <italic>R<sup>2</sup></italic> in <xref ref-type="table" rid="table1">Table 1</xref>). This linearity suggests that the response weights for each speed pair are roughly consistent across the neuronal population.<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle R- R_{s}=k\left (R_{f}- R_{s}\right)+b$$\end{document}</tex-math></alternatives></disp-formula></p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Relationship between the responses to the bi-speed stimuli and the constituent stimulus components.</title><p>(<bold>A–E</bold>) Each panel shows the responses from 100 neurons. Each dot represents the responses from one neuron. <italic>R, R<sub>f</sub></italic>,, and <italic>R<sub>s</sub></italic> were firing rates averaged across all recorded trials for each neuron. The ordinate shows the difference between the responses to a bi-speed stimulus and the slower component (<italic>R - R<sub>s</sub></italic>). The abscissa shows the difference between the responses to the faster and slower components (<italic>R<sub>f</sub> - R<sub>s</sub></italic>). The regression line is shown in red. (<bold>F</bold>) Response weights for the faster stimulus component obtained from the slope of the linear regression based on the recorded responses of 100 neurons (black symbols), and based on simulated responses to the bi-speed stimuli (gray symbols). Error bars represent 95% confidence intervals. (<bold>A1–F1</bold>) 4x speed separation. (<bold>A2–F2</bold>) 2x speed separation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig5-v1.tif"/></fig><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Response weight for faster component based on linear regression (N=100).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top"/><th align="left" valign="top" colspan="5">Large speed difference (4x)</th><th align="left" valign="top" colspan="5">Small speed difference (2x)</th></tr></thead><tbody><tr><td align="left" valign="top"><bold>Components</bold><break/><bold>speeds</bold> (°/s)</td><td align="left" valign="top">1.25/5</td><td align="left" valign="top">2.5/10</td><td align="left" valign="top">5/20</td><td align="left" valign="top">10/40</td><td align="left" valign="top">20/80</td><td align="left" valign="top">1.25/2.5</td><td align="left" valign="top">2.5/5</td><td align="left" valign="top">5/10</td><td align="left" valign="top">10/20</td><td align="left" valign="top">20/40</td></tr><tr><td align="left" valign="top"><bold>Intercept</bold> (<italic>b</italic>)</td><td align="left" valign="top">–0.60</td><td align="left" valign="top">–0.13</td><td align="left" valign="top">2.34</td><td align="left" valign="top">1.79</td><td align="left" valign="top">–0.33</td><td align="left" valign="top">–0.65</td><td align="left" valign="top">–0.45</td><td align="left" valign="top">–0.32</td><td align="left" valign="top">1.23</td><td align="left" valign="top">–0.99</td></tr><tr><td align="left" valign="top"><bold>Slope</bold> (<inline-formula><alternatives><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft13">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>) <bold><italic>and 95% CI</italic></bold></td><td align="left" valign="top"><bold>0.92</bold><break/>±<break/>0.048</td><td align="left" valign="top"><bold>0.83</bold><break/>±<break/>0.056</td><td align="left" valign="top"><bold>0.58</bold><break/>±<break/>0.047</td><td align="left" valign="top"><bold>0.45</bold><break/>±<break/>0.044</td><td align="left" valign="top"><bold>0.46</bold><break/>±<break/>0.052</td><td align="left" valign="top"><bold>0.70</bold><break/>±<break/>0.070</td><td align="left" valign="top"><bold>0.74</bold><break/>±<break/>0.067</td><td align="left" valign="top"><bold>0.64</bold><break/>±<break/>0.059</td><td align="left" valign="top"><bold>0.47</bold><break/>±<break/>0.050</td><td align="left" valign="top"><bold>0.52</bold><break/>±<break/>0.042</td></tr><tr><td align="left" valign="top"><bold>Simulated slope</bold> (<inline-formula><alternatives><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft14">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>) <bold><italic>and 95% CI</italic></bold></td><td align="left" valign="top">0.50<break/>±<break/>0.079</td><td align="left" valign="top">0.50<break/>±<break/>0.078</td><td align="left" valign="top">0.50<break/>±<break/>0.063</td><td align="left" valign="top">0.50<break/>±<break/>0.059</td><td align="left" valign="top">0.50<break/>±<break/>0.089</td><td align="left" valign="top">0.50<break/>±<break/>0.075</td><td align="left" valign="top">0.50<break/>±<break/>0.078</td><td align="left" valign="top">0.50<break/>±<break/>0.072</td><td align="left" valign="top">0.50<break/>±<break/>0.058</td><td align="left" valign="top">0.50<break/>±<break/>0.071</td></tr><tr><td align="left" valign="top"><bold>p-values</bold> (<inline-formula><alternatives><mml:math id="inf15"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft15">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>)<break/>(<inline-formula><alternatives><mml:math id="inf16"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft16">\begin{document}$measured$\end{document}</tex-math></alternatives></inline-formula>&gt;simulated)</td><td align="left" valign="top">&lt;0.001<break/>(***)</td><td align="left" valign="top">&lt;0.001<break/>(***)</td><td align="left" valign="top">0.09</td><td align="left" valign="top">0.86</td><td align="left" valign="top">0.686</td><td align="left" valign="top">0.005<break/>(**)</td><td align="left" valign="top">0.002<break/>(**)</td><td align="left" valign="top">0.017<break/>(*)</td><td align="left" valign="top">0.742</td><td align="left" valign="top">0.432</td></tr><tr><td align="left" valign="top"><bold><italic>R<sup>2</sup></italic></bold></td><td align="left" valign="top"><bold>0.94</bold></td><td align="left" valign="top"><bold>0.90</bold></td><td align="left" valign="top"><bold>0.86</bold></td><td align="left" valign="top"><bold>0.80</bold></td><td align="left" valign="top"><bold>0.76</bold></td><td align="left" valign="top"><bold>0.80</bold></td><td align="left" valign="top"><bold>0.83</bold></td><td align="left" valign="top"><bold>0.82</bold></td><td align="left" valign="top"><bold>0.78</bold></td><td align="left" valign="top"><bold>0.86</bold></td></tr><tr><td align="left" valign="top"><bold>Simulated <italic>R<sup>2</sup></italic></bold><break/><bold><italic>and 95% CI</italic></bold></td><td align="left" valign="top">0.62<break/>±<break/>0.162</td><td align="left" valign="top">0.62<break/>±<break/>0.165</td><td align="left" valign="top">0.71<break/>±<break/>0.111</td><td align="left" valign="top">0.73<break/>±<break/>0.095</td><td align="left" valign="top">0.55<break/>±<break/>0.176</td><td align="left" valign="top">0.64<break/>±<break/>0.159</td><td align="left" valign="top">0.62<break/>±<break/>0.158</td><td align="left" valign="top">0.66<break/>±<break/>0.137</td><td align="left" valign="top">0.75<break/>±<break/>0.098</td><td align="left" valign="top">0.66<break/>±<break/>0.154</td></tr><tr><td align="left" valign="top"><bold>p-values</bold> (<italic>R<sup>2</sup></italic>) (measured &gt; simulated)</td><td align="left" valign="top">&lt;0.001<break/>(***)</td><td align="left" valign="top">&lt;0.001<break/>(***)</td><td align="left" valign="top">&lt;0.001<break/>(***)</td><td align="left" valign="top">0.096</td><td align="left" valign="top">0.003<break/>(**)</td><td align="left" valign="top">0.01<break/>(**)</td><td align="left" valign="top">0.003<break/>(**)</td><td align="left" valign="top">&lt;0.001<break/>(***)</td><td align="left" valign="top">0.311</td><td align="left" valign="top">0.002<break/>(**)</td></tr><tr><td align="left" valign="top"><bold>Slope</bold> (<inline-formula><alternatives><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft17">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>)<break/>± <bold>STD</bold><break/>(<inline-formula><alternatives><mml:math id="inf18"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft18">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> from<break/><inline-formula><alternatives><mml:math id="inf19"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}$\rm {split\,trials}$\end{document}</tex-math></alternatives></inline-formula>)</td><td align="left" valign="top">0.90<break/>±<break/>0.021</td><td align="left" valign="top">0.81<break/>±<break/>0.020</td><td align="left" valign="top">0.56<break/>±<break/>0.015</td><td align="left" valign="top">0.44<break/>±<break/>0.015</td><td align="left" valign="top">0.44<break/>±<break/>0.024</td><td align="left" valign="top">0.63<break/>±<break/>0.075</td><td align="left" valign="top">0.67<break/>±<break/>0.078</td><td align="left" valign="top">0.58<break/>±<break/>0.072</td><td align="left" valign="top">0.44<break/>±<break/>0.058</td><td align="left" valign="top">0.48<break/>±<break/>0.071</td></tr><tr><td align="left" valign="top"><bold><italic>R<sup>2</sup></italic></bold><break/>(<inline-formula><alternatives><mml:math id="inf20"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> from<break/><inline-formula><alternatives><mml:math id="inf21"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft21">\begin{document}$\rm {split\,trials}$\end{document}</tex-math></alternatives></inline-formula>)</td><td align="left" valign="top">0.89</td><td align="left" valign="top">0.85</td><td align="left" valign="top">0.82</td><td align="left" valign="top">0.75</td><td align="left" valign="top">0.67</td><td align="left" valign="top">0.63</td><td align="left" valign="top">0.65</td><td align="left" valign="top">0.66</td><td align="left" valign="top">0.66</td><td align="left" valign="top">0.73</td></tr></tbody></table></table-wrap><p>Because all the regression lines in <xref ref-type="fig" rid="fig5">Figure 5</xref> nearly go through the origin (i.e. intercept <italic>b</italic> ≈ 0, <xref ref-type="table" rid="table1">Table 1</xref>), the slope <italic>k</italic> obtained from the linear regression approximates <inline-formula><alternatives><mml:math id="inf22"><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math><tex-math id="inft22">\begin{document}$\frac{R- R_{s}}{R_{f}- R_{s}}$\end{document}</tex-math></alternatives></inline-formula>, which is the response weight <inline-formula><alternatives><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft23">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula> for the faster component (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>). Hence, for each pair of stimulus speeds, we can estimate the response weight for the faster component using the slope of the linear regression of the responses from the neuronal population.</p><p>Our results showed that the bi-speed response showed a strong bias toward the faster component when the speeds were slow and changed progressively from a scheme of ‘faster-component-take-all’ to ‘response-averaging’ as the speeds of the two stimulus components increased (<xref ref-type="fig" rid="fig5">Figure 5F1</xref>). We found similar results when the speed separation between the stimulus components was small (2x), although the bias toward the faster component at low stimulus speeds was not as strong as 4x speed separation (<xref ref-type="fig" rid="fig5">Figure 5A2–F2</xref> and <xref ref-type="table" rid="table1">Table 1</xref>).</p><p>In the regression between <inline-formula><alternatives><mml:math id="inf24"><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft24">\begin{document}$\left (R- R_{s}\right)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf25"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft25">\begin{document}$\left (R_{f}-R_s\right)$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft26">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> (i.e. the firing rate to the slow component averaged across all trials for each neuron) was a common term and, therefore, could artificially introduce correlations. We wanted to determine whether our estimates of the regression slope (<inline-formula><alternatives><mml:math id="inf27"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft27">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>) were confounded by this factor. We performed two additional analyses.</p><p>First, at each speed pair and for each of the 100 neurons in the data sample shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>, we simulated the response to the bi-speed stimuli (<inline-formula><alternatives><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft28">\begin{document}$R_{e}$\end{document}</tex-math></alternatives></inline-formula>) as a randomly weighted average of <inline-formula><alternatives><mml:math id="inf29"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft29">\begin{document}$R_{f}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft30">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> of the same neuron.<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle R_{e}=aR_{f}+\left (1- a\right)R_{s},$$\end{document}</tex-math></alternatives></disp-formula></p><p>in which <inline-formula><alternatives><mml:math id="inf31"><mml:mi>a</mml:mi></mml:math><tex-math id="inft31">\begin{document}$a$\end{document}</tex-math></alternatives></inline-formula> was a randomly generated weight (between 0 and 1) for <inline-formula><alternatives><mml:math id="inf32"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft32">\begin{document}$R_{f}$\end{document}</tex-math></alternatives></inline-formula>, and the weights for <inline-formula><alternatives><mml:math id="inf33"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft33">\begin{document}$R_{f}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft34">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> summed to one. We then calculated the regression slope and the correlation coefficient between the simulated <inline-formula><alternatives><mml:math id="inf35"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft35">\begin{document}$R_{e}-R_s$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf36"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft36">\begin{document}$R_{f}-R_s$\end{document}</tex-math></alternatives></inline-formula> across the 100 neurons. We repeated the process 1000 times and obtained the mean and 95% confidence interval (CI) of the regression slope and the <italic>R<sup>2</sup></italic>. The mean slope based on the simulated responses was 0.5 across all speed pairs. The estimated slope (<inline-formula><alternatives><mml:math id="inf37"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft37">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>) from the data was significantly greater than the simulated slope at slow speeds of 1.25/5, 2.5/10 (<xref ref-type="fig" rid="fig5">Figure 5F1</xref>), and 1.25/2.5, 2.5/5, and 5/10°/s (<xref ref-type="fig" rid="fig5">Figure 5F2</xref>) (bootstrap test, see p-values in <xref ref-type="table" rid="table1">Table 1</xref>). The estimated <italic>R<sup>2</sup></italic> based on the data was also significantly higher than the simulated <italic>R<sup>2</sup></italic> for most of the speed pairs (<xref ref-type="table" rid="table1">Table 1</xref>).</p><p>Second, we calculated <inline-formula><alternatives><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft38">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> in the ordinate and abscissa of <xref ref-type="fig" rid="fig5">Figure 5A–E</xref> using responses averaged across different subsets of trials, such that <inline-formula><alternatives><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft39">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> was no longer a common term in the ordinate and abscissa. For each neuron, we determined <inline-formula><alternatives><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft40">\begin{document}$R_{s1}$\end{document}</tex-math></alternatives></inline-formula> by averaging the firing rates of <inline-formula><alternatives><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft41">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> across half of the recorded trials, selected randomly. We also determined <inline-formula><alternatives><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft42">\begin{document}$R_{s2}$\end{document}</tex-math></alternatives></inline-formula> by averaging the firing rates of <inline-formula><alternatives><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft43">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> across the rest of the trials. We regressed <inline-formula><alternatives><mml:math id="inf44"><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft44">\begin{document}$\left (R- R_{s1}\right)$\end{document}</tex-math></alternatives></inline-formula> on <inline-formula><alternatives><mml:math id="inf45"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft45">\begin{document}$\left (R_{f}- R_{s2}\right)$\end{document}</tex-math></alternatives></inline-formula>, as well as <inline-formula><alternatives><mml:math id="inf46"><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft46">\begin{document}$\left (R- R_{s2}\right)$\end{document}</tex-math></alternatives></inline-formula> on <inline-formula><alternatives><mml:math id="inf47"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft47">\begin{document}$\left (R_{f}- R_{s1}\right)$\end{document}</tex-math></alternatives></inline-formula>, and repeated the procedure 50 times. The averaged slopes obtained with <inline-formula><alternatives><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft48">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> from the split trials showed the same pattern as those using <inline-formula><alternatives><mml:math id="inf49"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft49">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> from all trials (<xref ref-type="table" rid="table1">Table 1</xref> and <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>), although the coefficient of determination was slightly reduced (<xref ref-type="table" rid="table1">Table 1</xref>). For 4x speed separation, the slopes were nearly identical to those shown in <xref ref-type="fig" rid="fig5">Figure 5F1</xref>. For 2x speed separation, the slopes were slightly smaller than those in <xref ref-type="fig" rid="fig5">Figure 5F2</xref>, but followed the same pattern (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). Together, these analysis results confirmed the faster-speed bias at the slow stimulus speeds and the change of the response weights as stimulus speeds increased.</p></sec><sec id="s2-4"><title>Timecourse of MT responses to bi-speed stimuli</title><p>The temporal dynamics of the response bias toward the faster component may provide a useful constraint on the neural model that accounts for this phenomenon. We, therefore, examined the timecourse of MT response to the bi-speed stimuli. We asked whether the faster-speed bias occurred early in the neuronal response or developed gradually.</p><p><xref ref-type="fig" rid="fig6">Figure 6</xref> shows the timecourse of the normalized responses averaged across 100 neurons in the population. The bias toward the faster speed component occurred at the very beginning of the neuronal response when the stimulus speeds were less than 20°/s (<xref ref-type="fig" rid="fig6">Figure 6A–C</xref>). The first 20–30 ms of the neuronal response elicited by the bi-speed stimulus was nearly identical to the response elicited by the faster component alone, as if the slower component were not present. The early dominance of the faster component on the bi-speed response cannot be explained by the difference in the response latencies of the faster and slower components. Faster stimuli elicit a shorter response latency (<xref ref-type="bibr" rid="bib39">Lisberger and Movshon, 1999</xref>), which can be seen in <xref ref-type="fig" rid="fig6">Figure 6A–C</xref>. However, the bi-speed response still closely followed the faster component for some time after the response to the slower component began to rise. The effect of the slower component on the bi-speed response was delayed for about 25 ms, as indicated by the arrows in <xref ref-type="fig" rid="fig6">Figure 6A–C</xref>. During the rest of the response period, the bias toward the faster component was persistent. As the stimulus speeds increased, the bi-speed response gradually changed to follow the average of the component responses (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). We found similar results when the speed separation between the two stimulus components was 4x (<xref ref-type="fig" rid="fig6">Figure 6A1–E1</xref>) and 2x (<xref ref-type="fig" rid="fig6">Figure 6A2–E2</xref>). At slow speeds, the very early faster-speed bias suggests a likely role of feedforward inputs to MT in the faster-speed bias. The slightly delayed reduction (normalization) in the bi-speed response relative to the stronger component response also helps constrain the circuit model for divisive normalization.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Timecourse of MT responses averaged across neurons to bi-speed stimuli.</title><p>Peristimulus time histograms (PSTHs) were averaged across 100 neurons. The bin width of the PSTH was 10 ms. (<bold>A1–E1</bold>) 4x speed separation. (<bold>A2–E2</bold>) 2x speed separation. In A-C, the left dashed line indicates the latency of the response to a bi-speed stimulus, and the right dashed line and the arrow indicate when the response to a bi-speed stimulus started to diverge from the response to the faster component.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig6-v1.tif"/></fig></sec><sec id="s2-5"><title>Faster-speed bias is still present when attention was directed away from the RFs</title><p>One possible explanation for the faster-speed bias is that bottom-up attention is drawn toward the faster stimulus component, enhancing the response to it. To address this question, we asked whether the faster-speed bias was still present if attention was directed away from the RFs. We trained one monkey (RG) to perform a demanding direction-discrimination task in the visual hemifield opposite to the RFs. The monkey performed the task well with an average correct rate of 86.7 ± 7.3% (mean ± std) (see Methods and <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p><p>We recorded the responses from an additional 48 MT neurons in 23 experimental sessions while the monkey performed the task. Thirty-two out of the 48 neurons were recorded using both the attention-away paradigm and a fixation paradigm. The results obtained using the attention-away paradigm and the fixation paradigm were similar (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>). The faster-speed bias was more evident at 4x speed separation than at 2x speed separation. Based on the neuronal responses across the population, we calculated the weight for the faster stimulus component at each of the five speed pairs using linear regression <xref ref-type="disp-formula" rid="equ2 equ3">Equation 2; Equation 3</xref>, as we did in <xref ref-type="fig" rid="fig5">Figure 5</xref>. When attention was directed away from the RFs, the response weight for the faster component decreased from a strong faster-speed bias to response averaging as the stimulus speeds increased, similar to the results from the fixation paradigm (<xref ref-type="fig" rid="fig7">Figure 7</xref>). These results suggest that the faster-speed bias at low speeds cannot be explained by attention drawn to the faster-speed component.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Comparison of response weights between attention-away and fixation paradigms.</title><p>The red and blue curves indicate the response weights for the faster speed component in an attention-away paradigm and a fixation paradigm, respectively, obtained from the same population of 32 neurons. The black curves are the replot of the data in <xref ref-type="fig" rid="fig5">Figure 5F</xref>, obtained from 100 neurons in a fixation paradigm. (<bold>A</bold>) 4x speed separation. (<bold>B</bold>) 2x speed separation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig7-v1.tif"/></fig></sec><sec id="s2-6"><title>Faster speed bias also occurs when stimulus components move in different directions</title><p>We showed that at low speeds, MT response to the bi-speed stimulus was biased toward the faster stimulus component when two overlapping components moved in the same direction (at the preferred direction of the neuron). We asked whether this faster-speed bias also occurred when visual stimuli moved in different directions. We presented overlapping random-dot stimuli within the RF, moving in two directions separated by 90°. The two stimulus components moved at speeds of 2.5 and 10°/s. The faster speed component moved on the clockwise side of the two directions. We varied the vector-average (VA) direction of the two component directions across 360° to characterize the direction tuning curves. Each neuron’s direction tuning curve was fitted with a spline and circularly shifted such that the VA direction 0° was aligned with the neuron’s preferred direction before averaging across neurons.</p><p><xref ref-type="fig" rid="fig8">Figure 8A</xref> shows the results averaged across 21 neurons (13 from monkey RG, 8 from monkey GE). The peak response to the faster component (<xref ref-type="fig" rid="fig8">Figure 8A</xref>, blue curve) was stronger than that to the slower component (green curve), consistent with the overall speed preference of a large MT neuron population (<xref ref-type="bibr" rid="bib51">Nover et al., 2005</xref>). MT responses elicited by the bi-directional stimuli (red curve) showed a strong bias toward the faster component, more than expected by the average of the two component responses (gray curve). The bi-speed response was biased toward the faster component regardless of whether the response to the faster component was stronger (in positive VA directions) or weaker (in negative VA directions) than that to the slower component (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). The result from an example neuron further demonstrated that, even when the peak firing rates of the faster and slower component responses were similar, the response elicited by the bi-speed stimuli was still biased toward the faster component (<xref ref-type="fig" rid="fig8">Figure 8B</xref>). These results suggest that the bias was not toward the stronger component response of the individual neuron, but to the faster component.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>MT responses to bi-speed stimuli moving in different directions and the linear weighted sum (LWS) and normalization model fits.</title><p>(<bold>A</bold>) Population-averaged direction tuning curves of 21 neurons in response to stimuli moving at two speeds and in two directions separated by 90° (red). The component direction Dir. 1 (blue) moved at 10/s, and the component direction Dir. 2 (green) moved at 2.5°/s. The faster component, Dir. 1, was always on the clockwise side of Dir. 2. The abscissas in blue and green show the directions of stimulus components Dir. 1 and Dir. 2, respectively. The blue and green axes are shifted by 90° relative to each other. The abscissa in black shows the corresponding vector-average (VA) direction of the two direction components. Error bands represent ± STE. The gray curve represents the average of the component responses. The orange and black curves are the linear weighted sum (LWS) and normalization model fits, respectively, of the population-averaged direction-tuning curve to the bi-speed stimuli. (<bold>B</bold>) The direction-tuning curves of an example neuron show similar peak responses to the slower and faster components. The orange and black curves are the LWS and normalization model fits of the bi-speed responses and are nearly identical. The weights of <inline-formula><alternatives><mml:math id="inf50"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft50">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf51"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft51">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula> are from the normalization model fit. (<bold>C</bold>) Response weights for the stimulus components obtained using the LWS model fit. Each circle represents one neuron. (<bold>D</bold>) Response weights obtained using the normalization model fit. The dashed lines in C, D indicate where <inline-formula><alternatives><mml:math id="inf52"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft52">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf53"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft53">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula> sum to one. Although <inline-formula><alternatives><mml:math id="inf54"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft54">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf55"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft55">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula> are not constrained to sum to one in the model fits, the fitted weights are roughly aligned with the dashed lines. (<bold>E</bold>) Population-averaged speed tuning curves of MT neurons recorded in our data sample in response to single speeds. The red circles indicate responses to 2.5 and 10°/s. Error bars represent ± STE.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig8-v1.tif"/></fig><p>To quantify the response weights, for each neuron, we fitted the MT raw firing rates of the direction tuning curve to bi-speed/bi-directional stimuli as a linear weighted sum (LWS) of the direction tuning curves to the individual stimulus components moving at different speeds:<disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle R_{bi}\left (\theta _{1},\theta _{2}\right)=w_{s}\bullet R_{s}\left (\theta _{1}\right)+w_{f}\bullet R_{f}\left (\theta _{2}\right)+c.$$\end{document}</tex-math></alternatives></disp-formula></p><p><inline-formula><alternatives><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft56">\begin{document}$R_{bi}$\end{document}</tex-math></alternatives></inline-formula> is the model-fitted direction-tuning curves to the bi-speed and bi-direction stimuli. <inline-formula><alternatives><mml:math id="inf57"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft57">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft58">\begin{document}$R_{f}$\end{document}</tex-math></alternatives></inline-formula> are the measured direction tuning curves to the slower and faster stimulus components, respectively. <inline-formula><alternatives><mml:math id="inf59"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mspace width="mediummathspace"/><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mspace width="mediummathspace"/><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft59">\begin{document}$\theta _{1} \\gt and \\gt \theta _{2}$\end{document}</tex-math></alternatives></inline-formula> are the motion directions of the two components; <inline-formula><alternatives><mml:math id="inf60"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft60">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf61"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft61">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf62"><mml:mi>c</mml:mi></mml:math><tex-math id="inft62">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> are model parameters, which represent the response weights for the slower and faster components and an offset constant, respectively. <inline-formula><alternatives><mml:math id="inf63"><mml:mi>c</mml:mi></mml:math><tex-math id="inft63">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> was constrained to be between 0 and 100 spikes/s. Because the model can be well constrained by the measured direction-tuning curves, it is not necessary to require <inline-formula><alternatives><mml:math id="inf64"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft64">\begin{document}$w_{s}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf65"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft65">\begin{document}$w_{f}$\end{document}</tex-math></alternatives></inline-formula> to sum to one, which is more general. An implicit assumption of the model is that, at a given pair of stimulus speeds, the response weights for the slower and faster components are fixed across motion directions. The model fitted MT responses very well, accounting for an average of 91.8% of the response variance (std = 7.2%, N=21) (see Methods), which supports the assumption that the response weights are fixed across motion directions. The median response weights for the faster and slower components were 0.74 and 0.26, respectively, and were significantly different (Wilcoxon signed-rank test, <italic>p</italic>=8.0 × 10<sup>–5</sup>). For most neurons (20 out of 21), the response weight for the faster component was larger than that for the slower component (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). This result suggests that at low speeds, the faster-speed bias is a general phenomenon that applies to overlapping stimuli moving either in the same direction or different directions.</p></sec><sec id="s2-7"><title>Normalization model fit of the direction-tuning curves to bi-speed stimuli</title><p>We showed that the neuronal response in MT to a bi-speed stimulus can be described by a weighted sum of the neuron’s responses to the individual speed components. However, what determines the response weights? The divisive normalization model (<xref ref-type="bibr" rid="bib19">Carandini and Heeger, 2012</xref>) has been used to explain a wide array of phenomena, including neuronal responses elicited by multiple visual stimuli (e.g. <xref ref-type="bibr" rid="bib14">Britten and Heuer, 1999</xref>; <xref ref-type="bibr" rid="bib27">Heuer and Britten, 2002</xref>; <xref ref-type="bibr" rid="bib17">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="bib81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="bib82">Xiao and Huang, 2015</xref>; <xref ref-type="bibr" rid="bib7">Bao and Tsao, 2018</xref>; <xref ref-type="bibr" rid="bib22">Cherian and Maunsell, 2025</xref>; <xref ref-type="bibr" rid="bib80">Wiesner et al., 2025</xref>). In the normalization model, while the division by the activity of a population of neurons in the denominator (the normalization pool) is well accepted, the nature of the numerator is less understood. We have previously proposed that the weight of a stimulus component is proportional to the activity of a population of neurons elicited by the stimulus component (<xref ref-type="bibr" rid="bib81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="bib79">Wiesner et al., 2020</xref>). We refer to this neuronal population as the ‘weighting pool.’ Here, we assumed that the weighting pool was composed of neurons with a broad range of speed preferences in response to multiple speed components. So, the summed response of the weighting pool reflects the speed preference of the neuronal population rather than the speed preference of individual neurons. We used the following equation (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>) to fit the direction-tuning curves of each neuron in response to two speed components moving in different directions:<disp-formula id="equ6"><label>(6)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac><mml:mo>∙</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle R_{bi}\left (\theta _{1},\theta _{2}\right)=\frac{S_{s}^{n}}{S_{s}^{n}+\alpha S_{f}^{n}+\sigma }\bullet R_{s}\left (\theta _{1}\right)+\frac{S_{f}^{n}}{S_{s}^{n}+\alpha S_{f}^{n}+\sigma }\bullet R_{f}\left (\theta _{2}\right)+c.$$\end{document}</tex-math></alternatives></disp-formula></p><p><inline-formula><alternatives><mml:math id="inf66"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft66">\begin{document}$R_{bi}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf67"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft67">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf68"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft68">\begin{document}$R_{f}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf69"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft69">\begin{document}$\theta _{1},{\rm and}\, \theta _{2}$\end{document}</tex-math></alternatives></inline-formula> are the same as in <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>. <italic>S<sub>s</sub></italic> and <italic>S<sub>f</sub></italic> are the population neural responses of the weighting pools to the slower and faster component speeds, respectively. <italic>n, σ</italic>, α, and <italic>c</italic> are model parameters and have the following constraints: 0.01≤n ≤ 100, 0 ≤ σ≤500, 0.01 ≤ <italic>α</italic>≤100, 0≤c ≤ 100. α is a parameter that controls for the tuned normalization (<xref ref-type="bibr" rid="bib50">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="bib67">Rust et al., 2006</xref>; <xref ref-type="bibr" rid="bib18">Carandini et al., 1997</xref>). We approximated <italic>S<sub>s</sub></italic> and <italic>S<sub>f</sub></italic> based on the population-averaged responses of our recorded MT neurons (N=100) in response to single speeds moving in the preferred direction of each neuron (<xref ref-type="fig" rid="fig8">Figure 8E</xref>). For the speeds of 2.5 and 10°/s, <italic>S<sub>s</sub></italic> = 36.7 and <italic>S<sub>f</sub></italic> = 62.5 spikes/s (red circles in <xref ref-type="fig" rid="fig8">Figure 8E</xref>). The normalization model fitted the data well, accounting for an average of 90.5% of the response variance (std = 7.1%, N=21), slightly smaller but comparable to the fit by the LWS model. The median response weights obtained from the normalization model for the faster and slower components were 0.78 and 0.15, respectively, and were significantly different (Wilcoxon signed-rank test, <italic>p</italic>=6.0 × 10<sup>–5</sup>) (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). The median values of the fitted parameters across 21 neurons are n=4.13, σ=123, <italic>α</italic>=1.57, c=0.03.</p><p>So far, we have described the neural encoding of multiple speeds in area MT. We will next examine the decoding of speed(s) from population neural responses in MT and compare the performance of decoding with perceptual performance.</p></sec><sec id="s2-8"><title>Discriminate bi-speed and single-speed stimuli based on neuronal responses in area MT</title><p>We asked whether the responses of MT neurons contained information about bi-speed and single-speed stimuli suitable for supporting the perceptual discrimination of these stimuli. To address this question, we first examined the responses elicited by the bi-speed and single-speed stimuli from a population of MT neurons with different preferred speeds. Next, we used a classifier to discriminate the bi-speed stimuli from the single, log-mean speed stimuli based on MT responses.</p><p>In different experimental sessions, we centered visual stimuli on neurons’ RFs. The visual stimuli were identical across experimental sessions except for the spatial location of the RF. This allowed us to pool the trial-averaged responses recorded from different neurons to form a pseudo-population (see Methods). One can interpret the responses as from a population of neurons elicited by the same visual stimulus. <xref ref-type="fig" rid="fig9">Figure 9</xref> shows the pseudo-population neural response (referred to in brief as the population response) plotted as a function of neurons’ preferred speed, constructed from 100 neurons that we recorded using a fixation paradigm (see Methods). To capture the population response evenly across a full range of preferred speeds, we spline-fitted the recorded response elicited by the bi-speed stimulus (the red curves) and by the single, log-mean speed (the black curves) (<xref ref-type="fig" rid="fig9">Figure 9A–E</xref>). At 4x and 2x speed separations, the population responses elicited by two speeds did not show two separate peaks. Instead, they had a single hump that shifted from low to high preferred speed as the stimulus speeds increased. At 4x speed separation across all five speed pairs, the population response elicited by two speeds was broader and flatter than that elicited by the single log-mean speed (<xref ref-type="fig" rid="fig9">Figure 9A1–E1</xref>).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Population neural responses elicited by the bi-speed and single-speed stimuli and the performance of a linear classifier.</title><p>A population response of 100 recorded neurons was reconstructed by pooling across recordings in different experimental sessions. Each neuron’s response was averaged across experimental trials and normalized by the maximum response of the spline-fitted speed tuning curve to single speeds. Each dot represents the response from one neuron plotted as the neuron’s preferred speed (PS) in the natural logarithm scale. The curves represent the spline-fitted population neural responses. Red: response to the bi-speed stimulus; Black: the response to the corresponding single, log-mean speed. (<bold>A1–F1</bold>) 4x speed separation. The speeds of the bi-speed stimuli are 1.25 and 5°/s (<bold>A1</bold>), 2.5 and 10°/s (<bold>B1</bold>), 5 and 20°/s (<bold>C1</bold>), 10 and 40°/s (<bold>D1</bold>), 20 and 80°/s (<bold>E1</bold>). (<bold>A2–F2</bold>) 2x speed separation. The speeds of the bi-speed stimuli are 1.25 and 2.5°/s (<bold>A2</bold>), 2.5 and 5°/s (<bold>B2</bold>), 5 and 10°/s (<bold>C2</bold>), 10 and 20°/s (<bold>D2</bold>), 20 and 40°/s (<bold>E2</bold>). Two red dots on the X-axis indicate two component speeds; the black dot indicates the log-mean speed. (<bold>F1, F2</bold>) Performance of a linear classifier to discriminate the population neural responses to the bi-speed stimulus and the corresponding single log-mean speed. Error bars represent STE.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig9-v1.tif"/></fig><p>In our experiments, we directly measured the neuronal responses elicited by the log-mean speed of 4x but not 2x speed separation. Because we had characterized each neuron’s tuning curve to single speeds, we could infer the responses elicited by the log-mean speed of 2x separation by interpolating the speed tuning curve using a spline fit. At 2x speed separation, the population response elicited by two speeds was similar to that elicited by the single log-mean speed, with the two-speed population response slightly broader (<xref ref-type="fig" rid="fig9">Figure 9A2–E2</xref>).</p><p>We used a linear classifier to perform a discrimination task to evaluate the discriminability between MT population responses elicited by the bi-speed stimulus and the corresponding log-mean speed. Trial-by-trial population responses were generated randomly according to a Poisson process, and the mean response of each neuron was set to the trial-averaged neuronal response. The classifier was trained and tested using k-fold cross-validation. The classifier determined whether a population response from the recorded 100 neurons in our data set was elicited by two speeds or a single speed (see Methods). Discriminability of the classifier was measured in <italic>d’</italic> as in our psychophysics study.</p><p>Consistent with perceptual discrimination (<xref ref-type="fig" rid="fig1">Figures 1E</xref> and <xref ref-type="fig" rid="fig2">2B</xref>), the classifier’s performance at 4x speed separation (<xref ref-type="fig" rid="fig9">Figure 9F1</xref>) was better than that at 2x speed separation (<xref ref-type="fig" rid="fig9">Figure 9F2</xref>). This provides a neural correlate with better perceptual speed segmentation at larger speed separation. At 4x speed separation, the discriminability of the classifier was slightly decreased as the stimulus speed increased (<xref ref-type="fig" rid="fig9">Figure 9F1</xref>), which was generally consistent with the human psychophysics results (<xref ref-type="fig" rid="fig1">Figure 1E1</xref>). However, one difference was that at 20 and 80°/s, the classifier’s performance did not drop to a low level as human performance (compare <xref ref-type="fig" rid="fig9">Figure 9F1</xref> with <xref ref-type="fig" rid="fig1">Figure 1E1</xref>), but was more comparable to that of the monkey subject (<xref ref-type="fig" rid="fig2">Figure 2B1</xref>). At 2x speed separation, the classifier’s performance (<xref ref-type="fig" rid="fig9">Figure 9F2</xref>) had a similar shape as that of the human (<xref ref-type="fig" rid="fig1">Figure 1E2</xref>) and monkey (<xref ref-type="fig" rid="fig2">Figure 2B2</xref>) subjects, but the performance was not as good as the perceptual performance at intermediate speeds.</p><p>When the stimulus speeds were 20 and 80°/s, the population responses elicited by the bi-speed stimulus and the single log-mean speed stimulus were noticeably different (<xref ref-type="fig" rid="fig9">Figure 9E1</xref>), which explains the good performance of the classifier in differentiating the two stimuli. However, the differences in population neural responses may contribute to perceptual differences in quality other than motion speeds, and the monkey subject might be able to detect these perceptual cues at high speeds to aid task performance. To directly evaluate whether the population neural responses elicited by the bi-speed stimulus carry information about two speeds, it is important to conduct a decoding analysis to extract speed(s) from MT population responses.</p></sec><sec id="s2-9"><title>Decoding either a single speed or two speeds from trial-averaged population neural response</title><p>Since the population responses elicited by the 4x and 2x speed separations only had a single peak centered between the two component speeds (<xref ref-type="fig" rid="fig9">Figure 9A–E</xref>), this raised the question of how neuronal populations represent multiple speeds of the motion components. To address this question, we used a decoding approach motivated by the theoretical framework of coding multiplicity and probability distribution of visual features in neuronal populations proposed by Zemel et al. (<xref ref-type="bibr" rid="bib84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib58">Pouget et al., 2003</xref>; also see <xref ref-type="bibr" rid="bib74">Treue et al., 2000</xref>). Our decoder extracted speeds that minimized the difference (sum squared error) between the estimated population response elicited by the extracted speeds and the reconstructed population neural response based on the neural recording (<xref ref-type="disp-formula" rid="equ7 equ8 equ9 equ10">Equations 7–10</xref>, see Methods). Rather than searching for a probability distribution of speed, we constrained the search to either a single speed or two speeds. We also constrained the weights for the extracted speeds to sum to one, consistent with a probability distribution.</p><p>Our approach is akin to the forward encoding model for decoding that is often used in brain imaging studies (e.g. <xref ref-type="bibr" rid="bib34">Kay et al., 2008</xref>; <xref ref-type="bibr" rid="bib16">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib49">Naselaris et al., 2011</xref>; <xref ref-type="bibr" rid="bib77">Vintch and Gardner, 2014</xref>; <xref ref-type="bibr" rid="bib76">van Bergen et al., 2015</xref>). We applied an encoding rule and found that the visual stimuli generating a population response best matched the recorded neural response. Our assumed encoding rule in the decoder is that a neuron’s response to multiple speeds is the linear sum of the neuron’s responses to individual speed components presented alone, based on the neuron’s speed tuning curve and weighted by the strength (or probability) of each speed component. The decision to use this encoding model for decoding, rather than the encoding rule characterized in this study, was made primarily for practical reasons. Our experimental data only covered two speed separations (4x and 2x) and 5 log mean speeds. We do not yet know a general encoding rule for two speeds across all different speed separations and log mean speeds. However, if the linear encoding of the two speeds, as characterized in this study, generalizes across a broader range of speed combinations – such that only the weights of the speed components vary within the general encoding rule – then our choice of encoding model for decoding would not alter the decoded speeds themselves, but would merely affect the estimated weights associated with those speeds (<xref ref-type="disp-formula" rid="equ7">Equation 7</xref>).</p><p><xref ref-type="fig" rid="fig10">Figure 10</xref> shows the decoding procedure and the results of extracting speed(s) from the population neural responses reconstructed based on the trial-averaged responses of the recorded neurons to the bi-speed stimuli. To capture the population neural response across a full range of preferred speeds, we spline-fitted the recorded (red dots) and estimated (blue dots) population responses. The estimated population responses (<xref ref-type="fig" rid="fig10">Figure 10</xref>, blue curves) matched the recorded neural responses well (<xref ref-type="fig" rid="fig10">Figure 10</xref>, red curves) (for five speed pairs, R<sup>2</sup>&gt;0.96 at 4x speed separation; R<sup>2</sup>&gt;0.99 at 2x speed separation). At 4x speed separation, the decoder extracted two speeds for all speed combinations (<xref ref-type="fig" rid="fig10">Figure 10A–E</xref>). The readout speeds were generally close to the veridical stimulus speeds. At low stimulus speeds of 1.25 and 5°/s (<xref ref-type="fig" rid="fig10">Figure 10A</xref>) and 2.5 and 10°/s (<xref ref-type="fig" rid="fig10">Figure 10B</xref>), the decoded faster speed component had a higher weight than the slower component. At the highest speeds of 20 and 80°/s, the decoder extracted two speeds (<xref ref-type="fig" rid="fig10">Figure 10E</xref>), whereas human subjects could not perceive two speeds (<xref ref-type="fig" rid="fig1">Figure 1E1</xref>) (see <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>). At 2x speed separation, the decoder extracted two speeds only at low stimulus speeds of 1.25 and 2.5°/s (<xref ref-type="fig" rid="fig10">Figure 10F</xref>). At higher stimulus speeds, the decoder extracted a dominant speed that was between the two component speeds, with or without a second nearby speed that had a very low weight (<xref ref-type="fig" rid="fig10">Figure 10G–J</xref>). In contrast, human subjects could perceive two speeds when stimulus speeds were below 20 and 40°/s (<xref ref-type="fig" rid="fig1">Figure 1E2</xref>) (see below and Discussion).</p><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Illustration of the decoding procedure and extraction of speed(s) from population responses reconstructed based on the trial-averaged neuronal responses to the bi-speed stimuli.</title><p>(<bold>A–E</bold>) 4x speed separation. (<bold>F–J</bold>) 2x speed separation. The neural population contains 100 recorded neurons, as shown in <xref ref-type="fig" rid="fig9">Figure 9</xref>. Each red dot represents the trial-averaged response from one neuron plotted versus the preferred speed (PS) of the neuron in the natural logarithm scale. The red curve represents the spline-fitted population neural response. The decoder found either one speed or two speeds with different weights (vertical green bars on the X-axis), giving rise to the estimated and spline-fitted population response (blue curve) that best fitted the recorded and spline-fitted population neural response (red curve). Each blue dot represents the estimated response from one neuron, and the blue curve represents the spline-fitted estimated population response. Two red dots on the X-axis indicate the stimulus speeds. The Y-axis on the right side shows the weight of the readout speed (<bold>A, F</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig10-v1.tif"/></fig></sec><sec id="s2-10"><title>Decoding speeds from trial-by-trial population neural responses</title><p>To determine the distribution of the readout speed across trials, we randomly generated 200 trials based on the trial-averaged responses of 100 recorded neurons in our data sample. In each simulated trial, a given neuron’s response was determined by a Poisson process, with the mean set to the spike count averaged across the recorded trials. The trial-by-trial response of each neuron was normalized to construct the population response and then spline-fitted for decoding. The speeds extracted from the recorded neural responses to single stimulus speeds (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3A–G</xref>) and from the inferred responses to the log-mean speed of 2x speed separation (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3H–L</xref>) generally matched the single stimulus speed well (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3M</xref>).</p><p><xref ref-type="fig" rid="fig11">Figure 11</xref> shows the speeds extracted from the neural response to the bi-speed stimuli. The decoder often extracted two speeds across trials. In some trials, the readout of one speed component had a minimal weight. We considered a trial having a ‘single’ readout speed if the weight difference between the two readout speeds was greater than 0.7 (i.e. the weaker weight &lt;0.15). This usually happened when the readout speed having a minimal weight was either at one of the boundaries of the speed range (i.e. 1.25°/s or 80°/s) or separated from the other readout speed by a large speed separation (27.86x, which was the largest speed separation searched by the algorithm) (see Methods). These small weights were likely artifacts due to the boundaries of the stimulus speeds used in our experiments or the range of speed separation searched by the decoder.</p><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>Trial-by-trial readout speeds decoded from population neural responses to the bi-speed stimuli.</title><p>The neural population contains 100 recorded neurons, and the trial-by-trial responses are randomly generated based on a Poisson process. The convention is the same as in <xref ref-type="fig" rid="fig10">Figure 10</xref>. (<bold>A–E</bold>) Speeds decoded from population responses to ×4 speed separation. The vertical red lines indicate two component speeds, which are 1.25 and 5⁰/s (<bold>A</bold>), 2.5 and 10⁰/s (<bold>B</bold>), 5 and 20⁰/s (<bold>C</bold>), 10 and 40⁰/s (<bold>D</bold>), 20 and 80⁰/s (<bold>E</bold>). (<bold>F–J</bold>) Speeds decoded from population responses to ×2 speed separation. The red vertical line indicates two component speeds, and the black vertical line indicates the log mean speed. The component speeds are 1.25 and 2.5⁰/s (<bold>F</bold>), 2.5 and 5⁰/s (<bold>G</bold>), 5 and 10⁰/s (<bold>H</bold>), 10 and 20⁰/s (<bold>I</bold>), 20 and 40⁰/s (<bold>J</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig11-v1.tif"/></fig><p>At 4x speed separation, the decoder was able to extract the speeds of the stimulus components (<xref ref-type="fig" rid="fig11">Figure 11A–D</xref>), except at the fastest speeds of 20 and 80°/s. At low stimulus speeds of 1.25 and 5°/s, and 2.5 and 10°/s, the readout speed around the faster stimulus component usually had a higher weight than that around the slower stimulus component (<xref ref-type="fig" rid="fig11">Figure 11A and B</xref>). At stimulus speeds of 1.25 and 5°/s, in trials with two readout speeds (<xref ref-type="fig" rid="fig11">Figure 11A</xref>, on the white background), the faster readout speeds were close to the faster stimulus speed of 5°/s. The slower readout speeds were closely aligned with the slower stimulus speed of 1.25°/s, which was also the lower boundary of the speed range. In trials considered to have a single readout speed, the readout was very close to the faster stimulus speed of 5°/s (<xref ref-type="fig" rid="fig11">Figure 11A</xref>, on the grey background). For some of these trials (at the top of <xref ref-type="fig" rid="fig11">Figure 11A</xref>), the faster readout speed was near the upper-speed boundary of 80°/s and had a minimal weight (&lt;0.15). Those faster readout speeds were considered boundary artifacts.</p><p>At stimulus speeds of 2.5 and 10°/s, the decoder extracted two speeds that had a separation close to the veridical separation (<xref ref-type="fig" rid="fig11">Figures 11B</xref> and <xref ref-type="fig" rid="fig12">12B</xref>). In trials considered to have a single-speed readout, the readout speed was close to the faster stimulus speed of 10°/s. In some single- and two-readout speed trials, the slower readout speeds aligned with the 1.25°/s boundary and had a small weight, suggesting they were boundary artifacts.</p><fig id="fig12" position="float"><label>Figure 12.</label><caption><title>Discrimination between single- and bi-speed stimuli based on decoded speeds.</title><p>(<bold>A–J</bold>) The distributions of the speed separation between two readout speeds in each trial in response to either the bi-speed stimuli (yellow) or the corresponding single, log-mean speed (blue). The abscissa is shown on a natural logarithm scale. The bin width is 0.05. The red dotted line indicates veridical speed separation. (<bold>A–E</bold>) ×4 speed separation. The speeds of the bi-speed stimuli are 1.25 and 5⁰/s (<bold>A</bold>), 2.5 and 10⁰/s (<bold>B</bold>), 5 and 20⁰/s (<bold>C</bold>), 10 and 40⁰/s (<bold>D</bold>), 20 and 80⁰/s (<bold>E</bold>). (<bold>F-J</bold>) ×2 speed separation. The speeds of the bi-speed stimuli are 1.25 and 2.5⁰/s (<bold>F</bold>), 2.5 and 5⁰/s (<bold>G</bold>), 5 and 10⁰/s (<bold>H</bold>), 10 and 20⁰/s (<bold>I</bold>), 20 and 40⁰/s (<bold>J</bold>). (<bold>K–L</bold>) The performance of discriminating a bi-speed stimulus from the corresponding log-mean speed is based on the speed separation of the decoded speeds. (<bold>K</bold>) ×4 speed separation; (<bold>L</bold>) ×2 speed separation. The black triangles in A-J indicate the speed separation threshold of 1.3x (0.26 on the log scale) used for discriminating bi-speed and single-speed stimuli.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-fig12-v1.tif"/></fig><p>At stimulus speeds of 5 and 20°/s, nearly all trials had two readout speeds with a separation well aligned with the veridical speed separation (<xref ref-type="fig" rid="fig11">Figures 11C</xref> and <xref ref-type="fig" rid="fig12">12C</xref>). At stimulus speeds of 10 and 40°/s, the decoder was able to extract two speeds for most of the trials (<xref ref-type="fig" rid="fig11">Figure 11D</xref>). A small percentage of the trials (~10%) were considered to have a single readout speed, which was close to the log mean speed of the two stimulus speeds (20°/s) (blue dots at the top of <xref ref-type="fig" rid="fig11">Figure 11D</xref> on the grey background).</p><p>At the fastest stimulus speeds of 20 and 80°/s, about 40% of the total trials were considered to have only a single readout speed, which was near the log mean speed of the stimulus components (40°/s) (<xref ref-type="fig" rid="fig11">Figure 11E</xref>). In other trials, the decoder extracted two speeds – the slower readout speeds were generally higher than the slower stimulus speed (20°/s), and the faster readout speeds aligned with the faster stimulus speed (80°/s), which was also the upper boundary speed. However, an examination of the objective function as the decoder searched for the best-fit population response across speed separations revealed that the trial-averaged objective function was flat within a big range of speed separations (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4A</xref>). Further analysis showed that the decoder was uncertain about how many speeds were in the visual stimuli and, therefore, had difficulty segmenting the visual stimuli at these fast stimulus speeds of 20 and 80°/s (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>).</p><p>At 2x speed separation, the decoder was not able to extract two speeds of the stimulus components, except at the slowest speeds of 1.25 and 2.5°/s (<xref ref-type="fig" rid="fig11">Figure 11F–J</xref>). At stimulus speeds of 1.25 and 2.5°/s (<xref ref-type="fig" rid="fig11">Figure 11F</xref>), in 38% of total trials considered to have a single readout speed, the readout speed was close to the faster stimulus speed of 2.5°/s (mean = 1.97°/s, STD = 1.08). In trials that had two readout speeds, the slower readout speeds roughly followed the slower stimulus speed (1.25°/s), which was also the lower boundary of the speed range (<xref ref-type="fig" rid="fig11">Figure 11F</xref>). At stimulus speeds higher than 1.25 and 2.5°/s, most trials were considered to have a single readout speed (<xref ref-type="fig" rid="fig11">Figure 11G–J</xref>). The mean speeds of the single readout-speed trials were 3.9°/s (STD = 1.07), 7.3°/s (STD = 1.99), 13.5°/s (STD = 1.06), and 31°/s (STD = 1.07), respectively, for stimulus speeds of 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s. These mean readout speeds were close to the log mean speeds of the two stimulus speeds (3.54°/s, 7.07°/s, 14.14°/s, and 28.28°/s, respectively).</p></sec><sec id="s2-11"><title>Discrimination between single- and bi-speed stimuli based on decoded speeds</title><p>To compare the perceptual discrimination between bi-speed stimuli and the log-mean speed, we used the decoding results to perform a discrimination task similar to that used in our psychophysical experiments. <xref ref-type="fig" rid="fig12">Figure 12</xref> shows the distributions of the speed separation between two readout speeds extracted from the reconstructed population neural responses to the bi-speed stimuli, and the corresponding single log-mean speed. As stated above, when the difference between the weights of two readout speeds in a trial was greater than 0.7, the trial was considered to have a single readout speed, and the speed separation was set to zero.</p><p>At 4x speed separation, the separations between the readout speeds extracted from the response to the bi-speed stimuli generally matched the veridical speed separation. They were larger than those extracted from the response to single log-mean speed (<xref ref-type="fig" rid="fig12">Figure 12A–E</xref>). Based on the distributions of the decoded speeds, we used a speed separation threshold of 1.3x (i.e. 0.26 on the log scale, marked by a black triangle in <xref ref-type="fig" rid="fig12">Figure 12</xref>) to distinguish single- and bi-speed stimuli and to evaluate the hit rate and false alarm rate. The choice of the threshold within a range from 1.1x to 1.7x did not change the results qualitatively. We calculated <italic>d’</italic> to measure the ability to discriminate the bi-speed stimuli from the corresponding single log-mean speed. The <italic>d’</italic> (<xref ref-type="fig" rid="fig12">Figure 12K</xref>) was similar to the psychophysical performance of the monkey subject (<xref ref-type="fig" rid="fig2">Figure 2B1</xref>), reaching its peak at 5 and 20°/s. Although <italic>d’s</italic> at stimulus speeds of 1.25 and 5°/s and 2.5 and 10°/s were smaller than those of human subjects (<xref ref-type="fig" rid="fig1">Figure 1C1 and E</xref>), the fact that in many trials, the readout speeds matched the faster stimulus speeds (<xref ref-type="fig" rid="fig11">Figure 11A and B</xref>) indicated that the decoder was able to segment the visual stimuli when stimulus speeds were low.</p><p>At 2x speed separation, except at 1.25 and 2.5°/s, the distribution of the speed separation extracted from the response to the bi-speed stimuli was similar to that extracted from the inferred response to single log-mean speed (see Methods) (i.e. orange and blue bars overlapping) (<xref ref-type="fig" rid="fig12">Figure 12F–J</xref>). The <italic>d’</italic> calculated based on the decoded speed separation (<xref ref-type="fig" rid="fig12">Figure 12L</xref>) was smaller than the psychophysical performance of human and monkey subjects (<xref ref-type="fig" rid="fig1">Figure 1C2 and E2</xref>; <xref ref-type="fig" rid="fig2">Figure 2B2</xref>), suggesting that the decoder was not able to segment the visual stimuli at 2x speed separation, with a potential exception at the lowest speeds of 1.5 and 2.5°/s.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Perceptual segmentation of multiple motion speeds</title><p>Our human psychophysical study employed a novel 3AFC task. The task combined an identification task (to report whether a stimulus had one or two speeds) with a discrimination task (to compare a two-speed stimulus with a single-speed stimulus) (<xref ref-type="fig" rid="fig1">Figure 1A, E and E2</xref>). This approach allowed us to characterize discriminability based on perceptual segmentation, rather than other perceptual appearances of the stimuli. We made two findings. First and intuitively, the performance of speed segmentation was better when the separation between two stimulus speeds was larger. Second, at a fixed speed separation, speed segmentation became harder at fast speeds. Our results are consistent with previous studies. <xref ref-type="bibr" rid="bib43">Masson et al., 1999</xref> showed that the speed segmentation threshold increased sharply when the mean stimulus speed increased from 8°/s to 16°/s. By varying the width of a speed notch, <xref ref-type="bibr" rid="bib65">Rocchi et al., 2018</xref> showed that transparent motion perception was stronger with a wider notch width, and that transparent motion was well perceived at slow speeds (mean speed = 4.6°/s) but not at faster speeds (mean speed = 20.6°/s) at a range of notch widths from 1 to 6°/s. Our study tested a larger range of speeds and showed that the segmentation performance dropped sharply at speeds of 20 and 80°/s (4x), and 20 and 40°/s (2x), faster than those shown in the previous studies. This discrepancy is likely due to the larger speed separations used in our study and the difference in stimuli. The visual stimuli used in our study had either one or two speeds, whereas those used by <xref ref-type="bibr" rid="bib65">Rocchi et al., 2018</xref> were sampled from a distribution of motion speeds and had multiple elements.</p></sec><sec id="s3-2"><title>Neural encoding of multiple speeds and implications for efficient coding</title><p>We found that, at low stimulus speeds, MT neurons showed a faster-speed bias in representing two speeds of overlapping stimuli. We also showed that faster-speed bias in MT is a robust phenomenon regardless of whether the stimulus components move in the same or different directions. A faster-speed bias in representing two motion speeds is a novel finding. It adds to a growing body of studies demonstrating that visual neurons do not necessarily average the responses elicited by individual stimulus components in response to multiple stimuli (e.g. <xref ref-type="bibr" rid="bib50">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="bib7">Bao and Tsao, 2018</xref>). Our laboratory has previously reported that the responses of MT neurons to multiple moving stimuli can show a bias toward the stimulus component with a higher signal strength, such as motion coherence or luminance contrast (<xref ref-type="bibr" rid="bib81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="bib79">Wiesner et al., 2020</xref>), a directional side bias toward one of two motion directions, even when the stimulus components have the same signal strength (<xref ref-type="bibr" rid="bib82">Xiao and Huang, 2015</xref>), and a disparity bias toward one of two surfaces moving at different stereoscopic depths (<xref ref-type="bibr" rid="bib21">Chakrala et al., 2024</xref>). These different response biases enhance the representation of individual stimulus components and can help to facilitate the segmentation of multiple moving stimuli (<xref ref-type="bibr" rid="bib53">Orhan and Ma, 2015</xref>).</p><p>While the faster-speed bias reported in this study may facilitate the segregation of faster-moving stimuli, it may come at the cost of reduced ability to segregate slower speeds. Why does the primate visual system encode multiple speeds in this way? An efficient way to represent sensory information is to devote limited resources to better represent signals that occur more frequently in the natural environment (<xref ref-type="bibr" rid="bib5">Attneave, 1954</xref>; <xref ref-type="bibr" rid="bib8">Barlow, 1961</xref>; <xref ref-type="bibr" rid="bib70">Simoncelli and Olshausen, 2001</xref>). Previous studies have suggested that slow speeds are more likely to occur than fast speeds in natural scenes (<xref ref-type="bibr" rid="bib78">Weiss et al., 2002</xref>; <xref ref-type="bibr" rid="bib72">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="bib85">Zhang and Stocker, 2022</xref>). If neurons in the primate visual cortex are optimized to efficiently represent speeds that are more likely to occur in natural scenes, one may expect to find neurons showing a slower-speed bias rather than a faster-speed bias. However, besides maximizing information about the environment, neural representation in the sensory cortices may be optimized for other goals, such as maximizing the performance of certain behavioral tasks (<xref ref-type="bibr" rid="bib70">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="bib42">Manning et al., 2024</xref>). Since a figural object tends to move faster than its background in natural scenes (<xref ref-type="bibr" rid="bib32">Huang et al., 2019</xref>; <xref ref-type="bibr" rid="bib24">Friedman et al., 2025</xref>), a neural representation of multiple motions with a faster-speed bias would help to identify the figure and, therefore, benefit the performance of an essential behavioral task – figure/ground segregation. Our finding of a faster-speed bias at slow stimulus speeds underscores the possibility that, when choosing between efficiently representing the most commonly occurring features in natural scenes (e.g. slow speeds) and enhancing behavioral performance in critical tasks (e.g. figure-ground segregation), some brain areas in the visual system may prioritize enhancing the behavioral performance.</p></sec><sec id="s3-3"><title>Potential mechanisms underlying the neural encoding of multiple speeds</title><p>We found that the faster-speed bias was still present when attention was directed away from the RFs, suggesting that the faster-speed bias cannot be explained by an attentional modulation. The faster-speed bias cannot be explained by the apparent contrast of the stimulus component either – the random dots of the faster-speed component had shorter dwell time on the video display and appeared dimmer than the slower component. We suggest a modified normalization model that may explain why the faster-speed bias in MT occurs at low stimulus speeds and diminishes at high speeds.</p><p>Previous studies that characterize the neural representation of multiple stimuli have used stimulus strength to weigh the component responses in the divisive normalization model (e.g. <xref ref-type="bibr" rid="bib17">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="bib50">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="bib81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="bib27">Heuer and Britten, 2002</xref>). In comparison to the standard normalization model, we suggest that the response of a population of neurons (i.e. the weighting pool) defines the numerator of the normalization equation (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>). The weighting pool may or may not be the same as the normalization pool that defines the response in the denominator. We suggest that the weighting pool contains a population of neurons with a broad range of speed preferences. In this way, the summed (or averaged) response of the weighting pool depends mainly on the stimulus speed, and therefore, the weighting is less sensitive to the individual neuron’s speed preference. In this study, we used MT population-averaged responses to single speeds to approximate the responses of the weighting pool. MT population-averaged speed tuning in our data peaked around 20°/s (<xref ref-type="fig" rid="fig8">Figure 8E</xref>), consistent with previous studies (<xref ref-type="bibr" rid="bib44">Maunsell and Van Essen, 1983</xref>; <xref ref-type="bibr" rid="bib39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="bib51">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="bib30">Huang and Lisberger, 2009</xref>). At stimulus speeds less than 20°/s, the population speed tuning has a positive slope, and a faster component would elicit a stronger population response than a slower component. This insight explains the faster-speed bias at low stimulus speeds and why it tends to be stronger at 4x than at 2x speed separation. Conceptually, this model can also explain why faster-speed bias diminishes at higher speeds. When two stimulus speeds are at opposite sides of the population’s preferred speed, they elicit similar population responses in the weighting pool. This model also predicts that when both stimulus speeds exceed the preferred speed of the weighting pool, the response weight for the slower component should be greater than that for the faster component.</p><p>This modified normalization model well described our data on MT responses to two stimuli moving in different directions at 2.5 and 10°/s (<xref ref-type="fig" rid="fig8">Figure 8</xref>). However, our current data set has limitations to validate this model fully. This normalization model (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>) can reasonably describe our data on MT responses to bi-speed stimuli moving in the same direction across five speed pairs (<xref ref-type="fig" rid="fig5">Figure 5</xref>) (results not shown). However, since the responses of each neuron to the bi-speed stimuli only have five data points (see <xref ref-type="fig" rid="fig3">Figure 3</xref>) and our model has four free parameters (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>), the model is under-constrained. In future work, it will be important to extend the experiment to include pairs of stimuli moving in different directions at varying combinations of speeds across a broader range. By incorporating full direction tuning curves to better constrain the model (as shown in <xref ref-type="fig" rid="fig8">Figure 8</xref>) and systematically varying speed combinations, future studies could test the model’s prediction that the response bias shifts from a faster-speed bias to response averaging and eventually to a slower-speed bias, as the stimulus speeds increase.</p><p>Although in our model, we used the responses of a population of MT neurons to estimate the responses of the weighting pool, the weighting pool may be composed of neurons that feed signals into MT and have similar population-averaged speed tuning as MT neurons. MT neurons receive feedforward motion-selective input mainly from V1, and also from V2 and V3 (<xref ref-type="bibr" rid="bib75">Ungerleider and Desimone, 1986</xref>; <xref ref-type="bibr" rid="bib48">Movshon and Newsome, 1996</xref>; <xref ref-type="bibr" rid="bib2">Anderson et al., 1998</xref>; <xref ref-type="bibr" rid="bib3">Anderson and Martin, 2002</xref>; <xref ref-type="bibr" rid="bib66">Rockland, 2002</xref>). Speed-selective complex cells in V1 have preferred speeds in a range similar to that of MT neurons, but the mean preferred speed is slower than MT (<xref ref-type="bibr" rid="bib47">Mikami et al., 1986</xref>; <xref ref-type="bibr" rid="bib52">Orban et al., 1986</xref>; <xref ref-type="bibr" rid="bib61">Priebe et al., 2006</xref>). Future studies examining the transition speeds at which faster-speed bias changes to response averaging and slower-speed bias may help to differentiate whether the weighting pool consists of neurons in MT or early visual areas, such as V1.</p></sec><sec id="s3-4"><title>Decoding multiple speeds from population neural responses</title><p>Theoretical studies have proposed neural coding of probability distribution and multiplicity of a visual attribute (<xref ref-type="bibr" rid="bib57">Pouget and Snyder, 2000</xref>). The key idea of this framework is that neurons do not code a single stimulus value but instead code the distribution of the stimulus (<xref ref-type="bibr" rid="bib84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="bib58">Pouget et al., 2003</xref>). However, neurophysiological evidence supporting this framework on coding multiplicity is limited. Previous studies have not demonstrated the ability to extract multiple speeds from population neural responses. Our results provide support for this framework of coding multiplicity. Our decoding analysis reveals that the population neural response in MT carries information about multiple speeds of overlapping stimuli, and it is possible to extract multiple speeds and their weights even when the population neural response has a unimodal distribution.</p><p>At large (4x) speed separation, our decoding results captured several key features of humans' and monkeys’ perception of multiple speeds – the decoded speeds support perceptual segmentation at low to intermediate speeds (<xref ref-type="fig" rid="fig11">Figures 11A–E</xref>–<xref ref-type="fig" rid="fig12">12A–K</xref>). At 20 and 80°/s, the decoder was uncertain about whether a single speed or two speeds were present in the visual stimuli and, therefore, had difficulty segmenting the visual stimuli at these fast speeds (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>). However, at small (2x) speed separation, the decoding results showed very little segmentation (<xref ref-type="fig" rid="fig11">Figures 11G–J</xref>–<xref ref-type="fig" rid="fig12">12L</xref>), except at very low speeds. This result differs from the perception at stimulus speeds less than 20 and 40°/s (<xref ref-type="fig" rid="fig1">Figures 1C2, E2</xref>, <xref ref-type="fig" rid="fig2">2B2</xref>). What are the potential reasons for the decoder’s inadequacy in segmenting small speed separations? The best-fit population response predicted by the encoding rule of the decoder matched the neural responses remarkably well (<italic>R<sup>2</sup></italic>&gt;0.99 for all five speed pairs of 2x separation, <xref ref-type="fig" rid="fig10">Figure 10F–J</xref>). So, the encoding model for decoding effectively described the population neural responses to the bi-speed stimuli. Because we found the same results when performing decoding based on neural responses averaged across experimental trials (<xref ref-type="fig" rid="fig10">Figure 10G–J</xref>), this inadequacy was unlikely due to our assumption of the trial-by-trial response variability following a Poisson process. We consider several factors that may contribute to this discrepancy.</p><p>First, this may be attributed to the limited sample size of our dataset. If we had a much larger MT neuron population, potential differences in neuronal responses to bi-speed stimuli and the single log mean speed might be captured by the data, which may lead to better decoding. Second, it may be due to the choice of the ‘objective function.’ Our decoder minimized the sum of squared error between the predicted population response and the recorded neural response. In contrast, <xref ref-type="bibr" rid="bib84">Zemel et al., 1998</xref> found motion directions that maximized the posterior probability <italic>P</italic>(<bold><italic>s</italic></bold><italic>|</italic><bold><italic>r</italic></bold>) using a maximum a posteriori (MAP) estimate. It remains to be determined whether maximizing the posterior probability can improve the resolution of segmenting multiple speeds. Third, in different sensory areas, neuronal responses to two stimuli can fluctuate from trial to trial, representing one stimulus component over the other (<xref ref-type="bibr" rid="bib38">Li et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Jun et al., 2022</xref>; <xref ref-type="bibr" rid="bib68">Schmehl et al., 2024</xref>; <xref ref-type="bibr" rid="bib26">Groh et al., 2024</xref>). If this trial-varying stimulus multiplexing also occurred for representing two speeds with a small separation, information about individual speed components would be lost in the trial-averaged responses (with added variability based on a Poisson process), as in our decoding procedure. Future studies with a large number of repeated experimental trials would be needed to test this possibility. Finally, while area MT is clearly important for motion-based segmentation, other motion-sensitive brain areas may be important for segmenting speeds with a small difference.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>We conducted psychophysical experiments using human subjects, and psychophysical and neurophysiological experiments using macaque monkeys.</p><sec id="s4-1"><title>Human psychophysics</title><sec id="s4-1-1"><title>Subjects</title><p>Four adult human subjects (<italic>CN, CO, IN, NP</italic>), two men and two women, with normal or corrected-to-normal visual acuity, participated in the psychophysics experiments. Subject <italic>CN</italic> was naive about the purposes of the experiments. Subjects CO and IN had a general idea about this study but did not know the specific design of the experiments. Informed consent was obtained from the subjects. All aspects of the study were in accordance with the principles of the Declaration of Helsinki and were approved by the Institutional Review Board at the University of Wisconsin-Madison (2015–0808).</p></sec><sec id="s4-1-2"><title>Apparatus</title><p>Visual stimuli were generated by a Linux workstation using an OpenGL application and displayed on a 19-inch CRT monitor. The monitor had a resolution of 1024×768 pixels and a refresh rate of 100 Hz. The output of the video monitor was measured with a photometer (LS-110, Minolta) and was gamma-corrected. Stimulus presentation was controlled by a real-time data acquisition and stimulus control program ‘Maestro’ (<ext-link ext-link-type="uri" xlink:href="https://sites.google.com/a/srscicomp.com/maestro/">https://sites.google.com/a/srscicomp.com/maestro/</ext-link>) as in the animal behavior and neurophysiology experiments. Subjects viewed the visual stimuli in a dark room with dim background illumination. The viewing distance was 58 cm. A chin rest and forehead support were used to restrict the head movements of the observers. During experimental trials, human subjects maintained fixation on a small spot within a 2 × 2° window. Eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1 kHz.</p></sec><sec id="s4-1-3"><title>Visual stimuli</title><p>Visual stimuli were two spatially overlapping random-dot patches presented within a square aperture 10° wide. Each square stimulus was centered 11° to the right of the fixation spot, therefore, covering 6° to 16° eccentricity. This range roughly matched the RF eccentricity of the recorded MT neurons in our neurophysiological experiments. The random dots were achromatic. Each random dot was 3 pixels and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was 0.03 cd/m<sup>2</sup>. The dot density of each random dot patch was 2 dots/degree². The two random-dot patches translated horizontally in the same direction. To reduce adaptation, the motion direction was either leftward or rightward in half of the trials, and stimulus trials were randomly interleaved. In one set of trials, two overlapping random-dot patches had a ‘large speed separation’ and the speed of the faster component was always four times (4x) that of the slower component. In another set of trials, visual stimuli had a ‘small speed separation’ and the speed of the faster component was always twice (2x) that of the slower component (see <xref ref-type="fig" rid="fig1">Figure 1B1 and B2</xref>). For each bi-speed stimulus, there was a corresponding single-speed stimulus composed of two overlapping random-dot patches moving in the same direction at the same speed. The single speed was the natural logarithmic (log) mean speed of the bi-speed stimulus: <inline-formula><alternatives><mml:math id="inf70"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft70">\begin{document}$Spd_{mean}=e^{\left [ln \left (Spd_{1}\right)+ln \left (Spd_{2}\right)\right ]/2}$\end{document}</tex-math></alternatives></inline-formula>, in which <italic>Spd<sub>1</sub></italic> and <italic>Spd<sub>2</sub></italic> were the two component speeds. The motion coherence of each random-dot patch was always 100%.</p></sec><sec id="s4-1-4"><title>Procedure</title><p>In a standard two-alternative-forced-choice (2AFC) task, subjects discriminated a bi-speed stimulus from the corresponding single log-mean speed stimulus. The bi-speed and single-speed stimuli were presented in two consecutive time intervals with a 500 ms gap in between, in random, balanced order. In each time interval, the visual stimulus appeared, remained stationary for 250 ms, and then moved for 500 ms. At the end of each trial, subjects reported which time interval contained a bi-speed stimulus by pressing one of two buttons (left or right) within a 1500 ms window. After the button press, the inter-trial interval was 1300 ms. Each block of trials contained 40 trials, i.e., 5 speed pairs × 2 speed separations × 2 temporal orders (the bi-speed stimulus appeared in the first or second time interval) × 2 motion directions (visual stimuli moved either to the left or right). Each experimental session typically contained five blocks, i.e., 200 trials.</p><p>Subjects also performed a 3AFC task. As in the 2AFC task, subjects discriminated a bi-speed stimulus from the corresponding single log-mean speed stimulus but had the option to make a third choice by pressing the middle button on trials when they thought neither stimulus interval appeared to contain two speeds (‘no two-speeds’ choice). When subjects thought one of the two stimulus intervals contained two speeds, subjects then pressed either the left or the right button to indicate which interval had two speeds.</p></sec><sec id="s4-1-5"><title>Data analysis</title><p>The hit rate was calculated as the percentage of trials in which a subject correctly picked the bi-speed stimulus as having two speeds. The false alarm rate was calculated as the percentage of trials in which a subject incorrectly identified the single-speed stimulus as having two speeds. As a measure of discriminability between the bi-speed and the corresponding single-speed stimuli, we calculated the discriminability index <italic>d′</italic>=<italic>norminv</italic>(hit rate) – <italic>norminv</italic>(false alarm rate). <italic>norminv</italic> is a MATLAB function that calculates the inverse of the normal cumulative distribution function, with the mean and standard deviation set to 0 and 1, respectively. When the hit or false alarm rate was occasionally close to 1, to avoid infinite d’ values, d' was calculated using a modified formula: <italic>d'</italic>=norminv{[(100 × hit rate)+1]/102} - norminv{[(100 × false alarm rate)+1]/102}. In analyzing the results of the 3AFC task, we incorporated the NTC trials into the <italic>d’</italic> calculation by evenly splitting the NTC trials into ‘hit’ trials and ‘false alarm’ trials. In this way, the NTC trials were still accounted for by the hit rate and false alarm rate, in the sense that they did not contribute to the discrimination. We also examined the percentage of trials in which subjects made the NTC choice at different stimulus speeds.</p></sec></sec><sec id="s4-2"><title>Neurophysiological and psychophysical experiments</title><sec id="s4-2-1"><title>Subjects</title><p>Five male adult rhesus monkeys (<italic>Macaca mulatta</italic>) were used in the experiments. Four monkeys were used in the neurophysiological experiments, and one was used in the psychophysical experiment. Experimental protocols were approved by the Institutional Animal Care and Use Committee at the University of Wisconsin–Madison (G005924), and were in strict compliance with U.S. Department of Agriculture regulations and the National Institutes of Health <italic>Guide for the Care and Use of Laboratory Animals</italic>.</p></sec><sec id="s4-2-2"><title>Apparatus and electrophysiological recording</title><p>Procedures for surgical preparation and electrophysiological recording were routine and similar to those described previously (<xref ref-type="bibr" rid="bib30">Huang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="bib81">Xiao et al., 2014</xref>). For subjects IM and MO, horizontal and vertical eye positions were monitored using the search coil method at a sampling rate of 1 kHz on each channel. For subjects RG, GE, and BJ, eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1 kHz. For electrophysiological recordings, we lowered single-contact tungsten microelectrodes (Thomas Recording or FHC) either using the MiniMatrix microdrive (Thomas Recording) or the NAN drive (NAN Instruments) into the posterior bank of the superior temporal sulcus. The impedances of the electrodes were 1∼3 MΩ. We identified area MT by its characteristically large proportion of directionally selective neurons, small classical RFs relative to those in the neighboring medial superior temporal area, and location on the posterior bank of the superior temporal sulcus. Electrical signals were filtered, amplified, and digitized conventionally. Single units were identified with a real-time template-matching system (Plexon). Spikes were carefully sorted using the Plexon offline sorter.</p><p>Stimulus presentation and the behavioral paradigm were controlled by a real-time data acquisition program Maestro as described in the human psychophysics experiment. For neurophysiological recordings from IM and MO, visual stimuli were presented on a 20-inch CRT monitor at a viewing distance of 38 cm. Monitor resolution was 1280×1024 pixels and the refresh rate was 85 Hz. For RG, GE, and BJ, visual stimuli were presented on a 25-inch CRT monitor at a viewing distance of 63 cm. Monitor resolution was 1024×768 pixels and the refresh rate was 100 Hz. Visual stimuli were generated by a Linux workstation using an OpenGL application that communicated with the main experimental-control computer over a dedicated Ethernet link. The output of the video monitor was gamma-corrected.</p></sec><sec id="s4-2-3"><title>Visual stimuli and experimental procedure of the main experiment</title><p>All visual stimuli were presented in individual trials while monkeys maintained fixation. Monkeys were required to maintain fixation within a 1.5×1.5° window centered around a fixation spot during each trial to receive juice rewards, although actual fixation was typically more accurate. In a trial, visual stimuli were illuminated after the animal had acquired fixation for 200 ms. To assist the isolation of directional-selective neurons in area MT, we used circular translation of a large random-dot patch (30×30°) as a search stimulus (<xref ref-type="bibr" rid="bib69">Schoppmann and Hoffmann, 1976</xref>). After an MT neuron was isolated, we characterized the direction tuning using randomly interleaved trials of 30×30° random-dot patches moving at 10°/s in eight different directions, ranging from 0 to 315° in 45° steps. Next, we mapped the RF by recording responses to a series of 5×5° patches of random dots that moved in the preferred direction of the neuron at 10°/s. The location of the patch was varied randomly to tile the screen in 5° steps without overlap, covering an area of either 40×30° or 35×25°. The raw map of the RF was interpolated using the Matlab function <italic>interp2</italic> at an interval of 0.5°, and the location giving rise to the highest firing rate was taken as the center of the RF. In the following experiments, testing stimuli were centered on the RF.</p><p>Monkeys IM and MO were tested with the main visual stimuli used in our experiments, which were two spatially overlapping random-dot patches presented within a square aperture 10° wide. The random dots were achromatic. The dot density of each random-dot patch was 2 dots/degree<sup>2</sup>. Each random dot was 3 pixels at a side and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was &lt;0.2 cd/m<sup>2</sup>. In each trial, the random dots moved within the aperture. The two random-dot patches were translated at two different speeds, both at 100% motion coherence, in the same direction (the preferred direction of the recorded neuron). The ratio between the two component speeds was fixed either at 4 (i.e. the large speed separation) or 2 (i.e. the small speed separation) (see Methods for human psychophysics above). At 4x speed separation, the five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref ref-type="fig" rid="fig1">Figure 1B1</xref>). At 2x speed separation, the speed pairs used were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref ref-type="fig" rid="fig1">Figure 1B2</xref>). Experimental trials of bi-speed stimuli that had 4x or 2x speed separations were randomly interleaved. Also randomly interleaved were trials that showed only a single random-dot patch moving at a speed of 1.25, 2.5, 5, 10, 20, 40, or 80°/s, which were the individual stimulus components of the bi-speed stimuli.</p><p>Monkeys RG and GE were tested with a variation of the main visual stimuli, where two overlapping random-dot stimulus components moved at fixed speeds of 2.5 and 10°/s, respectively, in two different directions separated by 90°. The diameter of the stimulus aperture was 3°. The faster component moved at the clockwise side of the two component directions (illustrated in <xref ref-type="fig" rid="fig8">Figure 8</xref>). We varied the vector average direction of the two stimulus components across 360° in a step of 15° to characterize the direction-tuning curves of MT neurons. We also measured the direction-tuning curves to a single stimulus moving at the individual component speeds.</p></sec><sec id="s4-2-4"><title>Behavioral paradigm and visual stimuli of attention control</title><p>Monkey RG was also tested in a control experiment in which the attention of the animal was directed away from the RFs of MT neurons. The attended stimulus was a random-dot patch moving in a single direction at 100% motion coherence within a stationary circular aperture that had a diameter of 5°. The stimulus patch was centered 10° to the left of the fixation spot, in the visual hemifield contralateral to the hemifield of the recorded MT neurons’ RFs. The monkey performed a direction discrimination task to report whether the motion direction of the attended stimulus moved at the clockwise or counter-clockwise side relative to the vertical direction. While the animal fixated on a point at the center of the monitor, both the attended stimulus and the RF stimulus were turned on and remained stationary for 250 ms before they moved for 500 ms. The attended stimulus translated at a speed of 10°/s and in a direction either clockwise or counter-clockwise from an invisible vertical (upward) direction by an offset of 10°, 15°, or 20°. The RF stimuli were the same as our main visual stimuli, with either a single-speed or bi-speed stimulus moving in the same direction. All trials were randomly interleaved. After the motion period, all the visual stimuli were turned off, and two reporting targets appeared 10° eccentric on the left and right sides of the fixation point. To receive a juice reward, the animal was required to make a saccadic eye movement within 400 ms after the fixation spot was turned off, either to the left or right target, depending on whether the motion direction of the attended stimulus was counter-clockwise or clockwise to the vertical direction, respectively.</p></sec><sec id="s4-2-5"><title>Monkey psychophysics</title><p>Monkey BJ was trained to perform a 2AFC discrimination task. The visual stimuli were the same as our main visual stimuli in the neurophysiological experiments, except that the stimulus moving at a single speed was also composed of two overlapping random-dot patches moving in the same direction at the same speed, the same as in the human psychophysics experiments. In this way, the single-speed stimulus and the bi-speed stimuli had the same dot density. Visual stimuli were random-dot patches moving within a square aperture of 10°×10°, centered 10° to the right of the fixation spot. The motion direction of the visual stimuli was always rightward. Experimental trials of bi-speed stimuli that had 4x or 2x speed separations, as well as the single-speed stimulus that moved at the log mean speed of the bi-speed stimuli, were randomly interleaved. Visual stimuli were turned on, remained stationary for 250 ms, and then moved for 500 ms. Following the stimulus offset, two reporting targets (dots) were presented 5.7° away from the fixation spot, at upper right (4°, 4°) and lower left (–4°, –4°) positions relative to the fixation spot. To receive a juice reward, the animal was required to make a saccadic eye movement to one of the two targets within 300 ms after the fixation spot was turned off. In most of the experiment trials, the animal received juice rewards for selecting the upper-right target when visual stimuli moved at two different speeds, and for selecting the lower-left target when visual stimuli moved at a single speed. Guided by our human psychophysics results, we made an exception to always reward the animal when the bi-speed stimuli moved at 20 and 80°/s or at 20 and 40°/s, regardless of which target was selected to avoid biasing the monkey’s choice by veridically rewarding the animal. This was because, at these fast speeds, human subjects could not segment the bi-speed stimuli. During training, the animal was never presented with the bi-speed stimuli of 20 and 80°/s, and 20 and 40°/s. During testing, the trials of 20 and 80°/s, and 20 and 40°/s were randomly interleaved with bi-speed and single-speed trials that were rewarded veridically to anchor the task rule. Among all testing trials, only 10% of the trials were rewarded with a 100% rate. We collected 50 trials of data for 4x speed separation across five experimental sessions, and 90 trials for 2x speed separation across nine sessions during the testing phase. The hit rate, false alarm rate, and <italic>d’</italic> were calculated in the same way as in the human psychophysics experiments.</p></sec><sec id="s4-2-6"><title>Model fit of the tuning curves to bi-speed stimuli</title><p>We used a linear weighted summation model (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>) to fit the direction-tuning curves to overlapping stimuli moving in different directions and at different speeds. We also fitted the direction-tuning curves to the bi-speed/bi-directional stimuli using a modified divisive normalization model (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>). These model fits were obtained using the constrained minimization tool ‘fmincon’ (MATLAB) to minimize the sum of squared error. To evaluate the goodness of fit of models for the response tuning curves, we calculated the percentage of variance (PV) accounted for by the model as follows: PV = 100 × (<inline-formula><alternatives><mml:math id="inf71"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft71">\begin{document}$1 - \frac{SSE}{SST}$\end{document}</tex-math></alternatives></inline-formula>), where SSE is the sum of squared errors between the model fit and the neuronal data, and SST is the sum of squared differences between the data and the mean of the data.</p></sec><sec id="s4-2-7"><title>Construction of population neural response</title><p>For each recorded MT neuron, we plotted the trial-averaged speed tuning curve in response to the single speed and spline-fitted the tuning curve using the Matlab function <italic>csaps</italic> with the smoothing parameter <italic>p</italic> set to 0.93. We found <italic>p</italic>=0.93 best captured the trend of the speed tuning, without obvious overfitting. We then found the preferred speed of the neuron, defined as the speed at which the maximum firing rate was reached in the spline-fitted tuning curve. The neuron’s responses to all single-speed and bi-speed stimuli were normalized by the maximum firing rate at the preferred speed. To construct the population neural response to a given stimulus, we took the normalized firing rate of each neuron elicited by that stimulus and plotted it against the preferred speed of the neuron. Because the preferred speeds of the neurons in our data sample did not cover the full speed range evenly, we spline-fitted (with a smoothing parameter of 0.93) the population neural response to capture it evenly across the full range of preferred speed.</p></sec><sec id="s4-2-8"><title>Discrimination of population neural responses using a classifier</title><p>We trained a linear classifier to discriminate between the constructed population neural responses to a bi-speed stimulus and those to the corresponding single-speed stimulus moving at the log mean speed. Constructed trial-by-trial population responses were generated randomly according to a Poisson process with the mean set to the recorded neuronal response averaged across experimental trials. For each speed combination, we generated 200 trials of responses to both the bi-speed stimulus and the corresponding single-speed stimulus. Constructed population responses were partitioned into training and testing sets using k-fold cross-validation (k=40). The 200 generated trials were randomly divided into 40 folds. The classifier was trained on 39 data folds and tested on the remaining fold, and the process was repeated 40 times to ensure that each fold was used for testing exactly once. The MATLAB <italic>fitclinear</italic> function was used to fit a linear classifier to the training data. The logistic learner and lasso regularization techniques were specified during the model training. The Stochastic Gradient Descent solver was used to optimize the objective function during the training of the classifier. The performance of the classifier was evaluated by <italic>d'</italic>, calculated using the hit rate and false alarm rate as described in human psychophysics.</p></sec><sec id="s4-2-9"><title>Population decoding</title><p>We define a given probability distribution of stimulus speed as:  <inline-formula><alternatives><mml:math id="inf72"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>∅</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft72">\begin{document}$\varnothing _{m}=\left \{P_{m,j}\right \}$\end{document}</tex-math></alternatives></inline-formula>, in which <inline-formula><alternatives><mml:math id="inf73"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft73">\begin{document}$P_{m,j}$\end{document}</tex-math></alternatives></inline-formula> is the probability of speed <inline-formula><alternatives><mml:math id="inf74"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft74">\begin{document}$S_{j}$\end{document}</tex-math></alternatives></inline-formula><italic>, j</italic>=1, 2, 3, …, 121, and <italic>j</italic> evenly samples speeds from 1.25°/s to 80°/s (referred to as the ‘full speed range’) on a natural logarithm scale and at a ‘<italic>speed interval’</italic> of 0.0347. Because <inline-formula><alternatives><mml:math id="inf75"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft75">\begin{document}$\varnothing _{m}$\end{document}</tex-math></alternatives></inline-formula> is a probability distribution, <inline-formula><alternatives><mml:math id="inf76"><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft76">\begin{document}$\sum _{j}P_{m,j}=1$\end{document}</tex-math></alternatives></inline-formula>. <italic>m</italic> is an index for different distributions.</p><p>The estimated response (<italic>ES</italic>) of neuron <italic>i</italic> to the stimulus speeds with a probability distribution <inline-formula><alternatives><mml:math id="inf77"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft77">\begin{document}$\varnothing _{m}$\end{document}</tex-math></alternatives></inline-formula> is a linear sum of the responses of neuron <italic>i</italic> to each single speed <inline-formula><alternatives><mml:math id="inf78"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft78">\begin{document}$S_{j}$\end{document}</tex-math></alternatives></inline-formula> within the full speed range, weighted by the probability of each speed in <inline-formula><alternatives><mml:math id="inf79"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft79">\begin{document}$\varnothing _{m}$\end{document}</tex-math></alternatives></inline-formula>. The probability can also be considered as the weight (signal strength) of the speed.<disp-formula id="equ7"><label>(7)</label><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>∅</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  ES_i(\varnothing_m)=\sum_j{P_{m,j}\,f_i(S_j)},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf80"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft80">\begin{document}$f_{i}$\end{document}</tex-math></alternatives></inline-formula> is the spline-fitted speed tuning curve of neuron <italic>i</italic> in response to single speeds.</p><p>The estimated population response (<italic>EP</italic>) of <italic>N</italic> neurons to <inline-formula><alternatives><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft81">\begin{document}$\varnothing _{m}$\end{document}</tex-math></alternatives></inline-formula> is:<disp-formula id="equ8"><label>(8)</label><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>ln</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>∅</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  EP_m({\ln}(PS_i))=ES_i(\varnothing_m),$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf82"><mml:msub><mml:mrow><mml:mi>P</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft82">\begin{document}$PS_{i}$\end{document}</tex-math></alternatives></inline-formula> is the preferred speed of neuron <italic>i</italic>, <inline-formula><alternatives><mml:math id="inf83"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft83">\begin{document}$i=1, 2, 3,\dots, N$\end{document}</tex-math></alternatives></inline-formula>. N=100 in our neural data.</p><p>We then spline-fitted the estimated population response <inline-formula><alternatives><mml:math id="inf84"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>E</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft84">\begin{document}$EP_{m}\left ({\rm ln} \left (PS_{i}\right)\right)$\end{document}</tex-math></alternatives></inline-formula> using a smoothing parameter of 0.93, interpolating the PS within the full speed range from 1.25°/s to 80°/s in natural logarithm with 121 evenly spaced values. The spline-fitted estimated population response is represented as <inline-formula><alternatives><mml:math id="inf85"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>E</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft85">\begin{document}$spEP_{m}\left ({\rm ln} \left (PS_{j}\right)\right)$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf86"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>121</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft86">\begin{document}$i=1,2,3,\dots,121$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Similarly, we spline-fitted the recorded and normalized population neural response <inline-formula><alternatives><mml:math id="inf87"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>R</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft87">\begin{document}$RP_{m}\left ({\rm ln} \left (PS_{i}\right)\right)$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf88"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>100</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft88">\begin{document}$i=1, 2, 3,\dots, 100$\end{document}</tex-math></alternatives></inline-formula>, and interpolated the PS to the same 121-speed values on a logarithm scale within the full speed range as above. The spline-fitted, recorded population neural response is represented as <inline-formula><alternatives><mml:math id="inf89"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft89">\begin{document}$spRP_{m}\left ({\rm ln} \left (PS_{j}\right)\right)$\end{document}</tex-math></alternatives></inline-formula>, .<inline-formula><alternatives><mml:math id="inf90"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>121</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft90">\begin{document}$j=1,2,3\dots,121$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The decoded probability distribution of the stimulus speed <inline-formula><alternatives><mml:math id="inf91"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft91">\begin{document}$\varnothing _{e}$\end{document}</tex-math></alternatives></inline-formula> is the <inline-formula><alternatives><mml:math id="inf92"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft92">\begin{document}$\varnothing _{m}$\end{document}</tex-math></alternatives></inline-formula> that maximizes the objective function (OF), which is defined as the negative value of the SSE (sum squared error) between the spline-fitted estimated population response and the recorded neural response:<disp-formula id="equ9"><label>(9)</label><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>∅</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>E</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle   OF(\varnothing_m) = - \sum_{j} \left\{\left[ spEP_m\left(\ln(PS_j)\right) - spRP_m\left(\ln(PS_j)\right) \right]^2\right\}, $$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ10"><label>(10)</label><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>∅</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>∅</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>∅</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle \varnothing_e={\rm arg\, max}_{\varnothing_m}[OF(\varnothing_m)].$$\end{document}</tex-math></alternatives></disp-formula></p><p>Rather than finding an arbitrary distribution, we constrained <inline-formula><alternatives><mml:math id="inf93"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft93">\begin{document}$\varnothing _{e}$\end{document}</tex-math></alternatives></inline-formula> to contain either a single speed with a probability (referred to as the ‘weight’) of 1 or two speeds with the same or different weights that sum to 1.</p></sec><sec id="s4-2-10"><title>An algorithm to search for the probability distribution of stimulus speed</title><p>We first searched for the best-fit distribution <inline-formula><alternatives><mml:math id="inf94"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft94">\begin{document}$\varnothing _{e1}$\end{document}</tex-math></alternatives></inline-formula> that contained a single speed <italic>SP</italic> with non-zero probability (<italic>p</italic>=1) and gave rise to the maximum OF across the full speed range (<inline-formula><alternatives><mml:math id="inf95"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft95">\begin{document}$OF_{max1}$\end{document}</tex-math></alternatives></inline-formula>). We next searched for the best-fit distribution <inline-formula><alternatives><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft96">\begin{document}$\varnothing _{e2}$\end{document}</tex-math></alternatives></inline-formula> that contained two speeds <inline-formula><alternatives><mml:math id="inf97"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft97">\begin{document}$SP_{1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf98"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft98">\begin{document}$SP_{2}$\end{document}</tex-math></alternatives></inline-formula> with non-zero probability and gave rise to the maximum OF for two speeds (<inline-formula><alternatives><mml:math id="inf99"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>O</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft99">\begin{document}$OF_{max2}$\end{document}</tex-math></alternatives></inline-formula>). We varied the speed separation, the center position (i.e. the log mean speed), and the probabilities of the two speeds. For each speed separation and center position, the probabilities of <inline-formula><alternatives><mml:math id="inf100"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft100">\begin{document}$SP_{1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf101"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft101">\begin{document}$SP_{2}$\end{document}</tex-math></alternatives></inline-formula> were varied from 0 to 1 at a step of 0.01, with the constraint that they summed to 1. We searched through the speed separation, ln(<inline-formula><alternatives><mml:math id="inf102"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>S</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft102">\begin{document}$SP_{2}$\end{document}</tex-math></alternatives></inline-formula>)−ln(<inline-formula><alternatives><mml:math id="inf103"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>S</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft103">\begin{document}$SP_{1}$\end{document}</tex-math></alternatives></inline-formula>) from 0.0693 (i.e. 2 <italic>speed intervals</italic>) to 3.3271 (i.e. 96 <italic>speed intervals</italic>), in a step of 0.0693. The search range covered the speed ratio <inline-formula><alternatives><mml:math id="inf104"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft104">\begin{document}$SP_{2}$\end{document}</tex-math></alternatives></inline-formula>/<inline-formula><alternatives><mml:math id="inf105"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft105">\begin{document}$SP_{1}$\end{document}</tex-math></alternatives></inline-formula> from 1.07x to 27.86x, sufficiently broader than 2x and 4x used in our visual stimuli. For each speed separation, we started the search where the center position of the two speeds [ln(<inline-formula><alternatives><mml:math id="inf106"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>S</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft106">\begin{document}$SP_{1}$\end{document}</tex-math></alternatives></inline-formula>)+ln(<inline-formula><alternatives><mml:math id="inf107"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>S</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft107">\begin{document}$SP_{2}$\end{document}</tex-math></alternatives></inline-formula>)]/2 was in the middle of the 121 possible speed values, referred to as the ‘speed axis.’ We then moved the center position toward the left border of ln(1.25) at a step of 0.0347 to find the maximum OF value (<inline-formula><alternatives><mml:math id="inf108"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft108">\begin{document}$OF_{leftmax}$\end{document}</tex-math></alternatives></inline-formula>) along the left half of the speed axis. If the OF value at the center position next to the current position was higher, the search moved to the next position. Otherwise, the current position was considered a local maximum. After we found a local maximum, the search continued in the same direction for up to another 30 <italic>speed intervals</italic>. This continued until one of the component speeds hit a border, 30 intervals were reached, or an OF value greater than the previous local maximum was found. If a larger OF was found, the local maximum was updated and the search jumped to that position, and the procedure was repeated until <inline-formula><alternatives><mml:math id="inf109"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft109">\begin{document}$OF_{leftmax}$\end{document}</tex-math></alternatives></inline-formula> was found. We then returned to the middle of the speed axis and searched through speed pairs toward the right border ln(80) to find the maximum <inline-formula><alternatives><mml:math id="inf110"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft110">\begin{document}$OF_{rightmax}$\end{document}</tex-math></alternatives></inline-formula>. The larger one of <inline-formula><alternatives><mml:math id="inf111"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft111">\begin{document}$OF_{leftmax}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf112"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft112">\begin{document}$OF_{rightmax}$\end{document}</tex-math></alternatives></inline-formula> was the maximum OF for two speeds (<inline-formula><alternatives><mml:math id="inf113"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>O</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft113">\begin{document}$OF_{max2}$\end{document}</tex-math></alternatives></inline-formula>). The <inline-formula><alternatives><mml:math id="inf114"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft114">\begin{document}$\varnothing _{e}$\end{document}</tex-math></alternatives></inline-formula> was either <inline-formula><alternatives><mml:math id="inf115"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft115">\begin{document}$\varnothing _{e1}$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf116"><mml:msub><mml:mrow><mml:mi>∅</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft116">\begin{document}$\varnothing _{e2}$\end{document}</tex-math></alternatives></inline-formula>, whichever gave rise to the larger value of <inline-formula><alternatives><mml:math id="inf117"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft117">\begin{document}$OF_{max1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf118"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft118">\begin{document}$OF_{max2}$\end{document}</tex-math></alternatives></inline-formula>.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con4"><p>Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Informed consent was obtained from the subjects. All aspects of the study were in accordance with the principles of the Declaration of Helsinki and were approved by the Institutional Review Board at the University of Wisconsin-Madison (2015-0808).</p></fn><fn fn-type="other"><p>Experimental protocols were approved by the Institutional Animal Care and Use Committee at the University of Wisconsin-Madison (G005924) and were in strict compliance with U.S. Department of Agriculture regulations and the National Institutes of Health Guide for the Care and Use of Laboratory Animals.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-94835-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The datasets and neural data files for this study, along with the MATLAB code used for data analysis, are available on OSF (<ext-link ext-link-type="uri" xlink:href="https://osf.io/dg5n9">https://osf.io/dg5n9</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Wiesner</surname><given-names>S</given-names></name><name><surname>Ghimire</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Neural coding of multiple motion speeds in visual cortical area MT</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/dg5n9">dg5n9</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Dr. Steven Lisberger for his support in the early phase of this project, Emily Ausloos and Jianbo Xiao for data collection in early human psychophysics experiments, Bryce Arseneau for animal training, and Ying Cao for collecting additional neural data. We also thank Drs. Jennifer Coonen and Kevin Brunner at the Wisconsin National Primate Research Center for excellent veterinary care and surgical assistance, Kechen Zhang for helpful suggestions on the study, and Emily Cooper and Greg DeAngelis for their valuable comments on the manuscript. Research reported in this publication was supported by the National Eye Institute of the NIH grant R01EY022443 (XH). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allman</surname><given-names>J</given-names></name><name><surname>Miezin</surname><given-names>F</given-names></name><name><surname>McGuinness</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Direction- and velocity-specific responses from beyond the classical receptive field in the middle temporal visual area (MT)</article-title><source>Perception</source><volume>14</volume><fpage>105</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1068/p140105</pub-id><pub-id pub-id-type="pmid">4069941</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JC</given-names></name><name><surname>Binzegger</surname><given-names>T</given-names></name><name><surname>Martin</surname><given-names>KA</given-names></name><name><surname>Rockland</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The connection from cortical area V1 to V5: a light and electron microscopic study</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>10525</fpage><lpage>10540</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-24-10525.1998</pub-id><pub-id pub-id-type="pmid">9852590</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>JC</given-names></name><name><surname>Martin</surname><given-names>KAC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Connection from cortical area V2 to MT in macaque monkey</article-title><source>The Journal of Comparative Neurology</source><volume>443</volume><fpage>56</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1002/cne.10100</pub-id><pub-id pub-id-type="pmid">11793347</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Atick</surname><given-names>JJ</given-names></name><name><surname>Redlich</surname><given-names>AN</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>What does the retina know about natural scenes?</article-title><source>Neural Computation</source><volume>4</volume><fpage>196</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1162/neco.1992.4.2.196</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attneave</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1954">1954</year><article-title>Some informational aspects of visual perception</article-title><source>Psychological Review</source><volume>61</volume><fpage>183</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1037/h0054663</pub-id><pub-id pub-id-type="pmid">13167245</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural correlations, population coding and computation</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nrn1888</pub-id><pub-id pub-id-type="pmid">16760916</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>P</given-names></name><name><surname>Tsao</surname><given-names>DY</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Representation of multiple objects in macaque category-selective areas</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1774</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04126-7</pub-id><pub-id pub-id-type="pmid">29720645</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name></person-group><year iso-8601-date="1961">1961</year><chapter-title>Possible principles underlying the transformations of sensory messages</chapter-title><person-group person-group-type="editor"><name><surname>Rosenblith</surname><given-names>W</given-names></name></person-group><source>Sensory Communication</source><publisher-name>MIT Press</publisher-name><fpage>217</fpage><lpage>234</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>RT</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name><name><surname>Zhao</surname><given-names>R</given-names></name><name><surname>Lukasewycz</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Segregation of object and background motion in visual area MT: effects of microstimulation on eye movements</article-title><source>Neuron</source><volume>26</volume><fpage>725</fpage><lpage>734</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)81208-8</pub-id><pub-id pub-id-type="pmid">10896167</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>RT</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Structure and function of visual area MT</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>157</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.26.041002.131052</pub-id><pub-id pub-id-type="pmid">16022593</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braddick</surname><given-names>O</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Segmentation versus integration in visual motion processing</article-title><source>Trends in Neurosciences</source><volume>16</volume><fpage>263</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(93)90179-p</pub-id><pub-id pub-id-type="pmid">7689769</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braddick</surname><given-names>O</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Local and global representations of velocity: transparency, opponency, and global direction perception</article-title><source>Perception</source><volume>26</volume><fpage>995</fpage><lpage>1010</lpage><pub-id pub-id-type="doi">10.1068/p260995</pub-id><pub-id pub-id-type="pmid">9509159</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braddick</surname><given-names>OJ</given-names></name><name><surname>Wishart</surname><given-names>KA</given-names></name><name><surname>Curran</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Directional performance in motion transparency</article-title><source>Vision Research</source><volume>42</volume><fpage>1237</fpage><lpage>1248</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(02)00018-4</pub-id><pub-id pub-id-type="pmid">12044756</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Heuer</surname><given-names>HW</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Spatial summation in the receptive fields of MT neurons</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>5074</fpage><lpage>5084</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-12-05074.1999</pub-id><pub-id pub-id-type="pmid">10366640</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name></person-group><year iso-8601-date="2003">2003</year><chapter-title>The middle temporal area: motion processing and the link to perception</chapter-title><person-group person-group-type="editor"><name><surname>Chalupa</surname><given-names>JW LM</given-names></name></person-group><source>The Visual Neurosciences</source><publisher-name>MIT Press</publisher-name><fpage>1203</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.7551/mitpress/7131.003.0093</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding and reconstructing color from responses in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>13992</fpage><lpage>14003</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3577-09.2009</pub-id><pub-id pub-id-type="pmid">19890009</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname><given-names>L</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title><source>Neuron</source><volume>64</volume><fpage>931</fpage><lpage>942</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.004</pub-id><pub-id pub-id-type="pmid">20064398</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>8621</fpage><lpage>8644</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-21-08621.1997</pub-id><pub-id pub-id-type="pmid">9334433</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Normalization as a canonical neural computation</article-title><source>Nature Reviews Neuroscience</source><volume>13</volume><fpage>51</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/nrn3136</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Glynn</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Willett</surname><given-names>SM</given-names></name><name><surname>Zaman</surname><given-names>A</given-names></name><name><surname>Ebihara</surname><given-names>AF</given-names></name><name><surname>Estrada</surname><given-names>R</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single neurons may encode simultaneous stimuli by switching between activity patterns</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2715</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05121-8</pub-id><pub-id pub-id-type="pmid">30006598</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chakrala</surname><given-names>AS</given-names></name><name><surname>Xiao</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The role of binocular disparity and attention in the neural representation of multiple moving stimuli in the visual cortex</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.06.25.546480</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cherian</surname><given-names>C</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Neuronal normalization in monkey MT is an intensity-weighted average</article-title><source>PNAS</source><volume>122</volume><elocation-id>e2522104122</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2522104122</pub-id><pub-id pub-id-type="pmid">41196346</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname><given-names>J</given-names></name><name><surname>Berkes</surname><given-names>P</given-names></name><name><surname>Orbán</surname><given-names>G</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>119</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.01.003</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>CT</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Yerxa</surname><given-names>T</given-names></name><name><surname>Arseneau</surname><given-names>BA</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Cooper</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Statistical regularities in natural scenes that support figure-ground segregation by neural populations</article-title><source>PLOS Computational Biology</source><volume>21</volume><elocation-id>e1013573</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1013573</pub-id><pub-id pub-id-type="pmid">41105706</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganguli</surname><given-names>D</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Efficient sensory encoding and Bayesian inference with heterogeneous neural populations</article-title><source>Neural Computation</source><volume>26</volume><fpage>2103</fpage><lpage>2134</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00638</pub-id><pub-id pub-id-type="pmid">25058702</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Groh</surname><given-names>JM</given-names></name><name><surname>Schmehl</surname><given-names>MN</given-names></name><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Signal switching may enhance processing power of the brain</article-title><source>Trends in Cognitive Sciences</source><volume>28</volume><fpage>600</fpage><lpage>613</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2024.04.008</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heuer</surname><given-names>HW</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Contrast dependence of response normalization in area MT of the rhesus macaque</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>3398</fpage><lpage>3408</lpage><pub-id pub-id-type="doi">10.1152/jn.00255.2002</pub-id><pub-id pub-id-type="pmid">12466456</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name><name><surname>Stoner</surname><given-names>GR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Adaptive surround modulation in cortical area MT</article-title><source>Neuron</source><volume>53</volume><fpage>761</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.01.032</pub-id><pub-id pub-id-type="pmid">17329214</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name><name><surname>Stoner</surname><given-names>GR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Stimulus dependency and mechanisms of surround modulation in cortical area MT</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>13889</fpage><lpage>13906</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1946-08.2008</pub-id><pub-id pub-id-type="pmid">19091978</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Noise correlations in cortical area MT and their potential impact on trial-by-trial variation in the direction and speed of smooth-pursuit eye movements</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>3012</fpage><lpage>3030</lpage><pub-id pub-id-type="doi">10.1152/jn.00010.2009</pub-id><pub-id pub-id-type="pmid">19321645</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>W</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Information-theoretic interpretation of tuning curves for multiple motion directions</article-title><conf-name>2017 51st Annual Conference on Information Sciences and Systems (CISS)</conf-name><conf-loc>Baltimore, MD, USA</conf-loc><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1109/CISS.2017.7926142</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Arseneau</surname><given-names>B</given-names></name><name><surname>Yerxa</surname><given-names>TE</given-names></name><name><surname>Cooper</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Natural Scene Statistics of Depth and Motion Pertinent to Figure-Ground Segregation</source><publisher-name>Society for Neuroscience (SfN) Abstract</publisher-name></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>NY</given-names></name><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Kramer</surname><given-names>LE</given-names></name><name><surname>Bowes</surname><given-names>B</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Coordinated multiplexing of information about separate objects in visual cortex</article-title><source>eLife</source><volume>11</volume><elocation-id>e76452</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.76452</pub-id><pub-id pub-id-type="pmid">36444983</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname><given-names>KN</given-names></name><name><surname>Naselaris</surname><given-names>T</given-names></name><name><surname>Prenger</surname><given-names>RJ</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Identifying natural images from human brain activity</article-title><source>Nature</source><volume>452</volume><fpage>352</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1038/nature06713</pub-id><pub-id pub-id-type="pmid">18322462</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krekelberg</surname><given-names>B</given-names></name><name><surname>van Wezel</surname><given-names>RJA</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2006">2006a</year><article-title>Adaptation in macaque MT reduces perceived speed and improves speed discrimination</article-title><source>Journal of Neurophysiology</source><volume>95</volume><fpage>255</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1152/jn.00750.2005</pub-id><pub-id pub-id-type="pmid">16192331</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krekelberg</surname><given-names>B</given-names></name><name><surname>van Wezel</surname><given-names>RJA</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2006">2006b</year><article-title>Interactions between speed and contrast tuning in the middle temporal area: implications for the neural code for speed</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>8988</fpage><lpage>8998</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1983-06.2006</pub-id><pub-id pub-id-type="pmid">16943555</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krekelberg</surname><given-names>B</given-names></name><name><surname>van Wezel</surname><given-names>RJA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural mechanisms of speed perception: transparent motion</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>2007</fpage><lpage>2018</lpage><pub-id pub-id-type="doi">10.1152/jn.00333.2013</pub-id><pub-id pub-id-type="pmid">23926031</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>K</given-names></name><name><surname>Kozyrev</surname><given-names>V</given-names></name><name><surname>Kyllingsbæk</surname><given-names>S</given-names></name><name><surname>Treue</surname><given-names>S</given-names></name><name><surname>Ditlevsen</surname><given-names>S</given-names></name><name><surname>Bundesen</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neurons in primate visual cortex alternate between responses to multiple stimuli in their receptive field</article-title><source>Frontiers in Computational Neuroscience</source><volume>10</volume><elocation-id>141</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2016.00141</pub-id><pub-id pub-id-type="pmid">28082892</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisberger</surname><given-names>SG</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Visual motion analysis for pursuit eye movements in area MT of macaque monkeys</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>2224</fpage><lpage>2246</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-06-02224.1999</pub-id><pub-id pub-id-type="pmid">10066275</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Functional organization of speed tuned neurons in visual area MT</article-title><source>Journal of Neurophysiology</source><volume>89</volume><fpage>246</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1152/jn.00097.2002</pub-id><pub-id pub-id-type="pmid">12522176</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id><pub-id pub-id-type="pmid">17057707</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manning</surname><given-names>TS</given-names></name><name><surname>Alexander</surname><given-names>E</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Cooper</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Transformations of sensory information in the brain suggest changing criteria for optimality</article-title><source>PLOS Computational Biology</source><volume>20</volume><elocation-id>e1011783</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1011783</pub-id><pub-id pub-id-type="pmid">38206969</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masson</surname><given-names>GS</given-names></name><name><surname>Mestre</surname><given-names>DR</given-names></name><name><surname>Stone</surname><given-names>LS</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Speed tuning of motion segmentation and discrimination</article-title><source>Vision Research</source><volume>39</volume><fpage>4297</fpage><lpage>4308</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(99)00143-1</pub-id><pub-id pub-id-type="pmid">10789424</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maunsell</surname><given-names>JH</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Functional properties of neurons in middle temporal visual area of the macaque monkey. I. Selectivity for stimulus direction, speed, and orientation</article-title><source>Journal of Neurophysiology</source><volume>49</volume><fpage>1127</fpage><lpage>1147</lpage><pub-id pub-id-type="doi">10.1152/jn.1983.49.5.1127</pub-id><pub-id pub-id-type="pmid">6864242</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDonald</surname><given-names>JS</given-names></name><name><surname>Clifford</surname><given-names>CWG</given-names></name><name><surname>Solomon</surname><given-names>SS</given-names></name><name><surname>Chen</surname><given-names>SC</given-names></name><name><surname>Solomon</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Integration and segregation of multiple motion signals by neurons in area MT of primate</article-title><source>Journal of Neurophysiology</source><volume>111</volume><fpage>369</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1152/jn.00254.2013</pub-id><pub-id pub-id-type="pmid">24155007</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mestre</surname><given-names>DR</given-names></name><name><surname>Masson</surname><given-names>GS</given-names></name><name><surname>Stone</surname><given-names>LS</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Spatial scale of motion segmentation from speed cues</article-title><source>Vision Research</source><volume>41</volume><fpage>2697</fpage><lpage>2713</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(01)00162-6</pub-id><pub-id pub-id-type="pmid">11587721</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikami</surname><given-names>A</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Wurtz</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Motion selectivity in macaque visual cortex. I. Mechanisms of direction and speed selectivity in extrastriate area MT</article-title><source>Journal of Neurophysiology</source><volume>55</volume><fpage>1308</fpage><lpage>1327</lpage><pub-id pub-id-type="doi">10.1152/jn.1986.55.6.1308</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Visual response properties of striate cortical neurons projecting to area MT in macaque monkeys</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>7733</fpage><lpage>7741</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-23-07733.1996</pub-id><pub-id pub-id-type="pmid">8922429</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naselaris</surname><given-names>T</given-names></name><name><surname>Kay</surname><given-names>KN</given-names></name><name><surname>Nishimoto</surname><given-names>S</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Encoding and decoding in fMRI</article-title><source>NeuroImage</source><volume>56</volume><fpage>400</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.073</pub-id><pub-id pub-id-type="pmid">20691790</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>AM</given-names></name><name><surname>Ray</surname><given-names>S</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Tuned normalization explains the size of attention modulations</article-title><source>Neuron</source><volume>73</volume><fpage>803</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.006</pub-id><pub-id pub-id-type="pmid">22365552</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nover</surname><given-names>H</given-names></name><name><surname>Anderson</surname><given-names>CH</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A logarithmic, scale-invariant representation of speed in macaque middle temporal area accounts for speed discrimination performance</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>10049</fpage><lpage>10060</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1661-05.2005</pub-id><pub-id pub-id-type="pmid">16251454</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orban</surname><given-names>GA</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Bullier</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Velocity sensitivity and direction selectivity of neurons in areas V1 and V2 of the monkey: influence of eccentricity</article-title><source>Journal of Neurophysiology</source><volume>56</volume><fpage>462</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1152/jn.1986.56.2.462</pub-id><pub-id pub-id-type="pmid">3760931</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orhan</surname><given-names>AE</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural population coding of multiple stimuli</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>3825</fpage><lpage>3841</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4097-14.2015</pub-id><pub-id pub-id-type="pmid">25740513</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pack</surname><given-names>CC</given-names></name><name><surname>Hunter</surname><given-names>JN</given-names></name><name><surname>Born</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Contrast dependence of suppressive influences in cortical area MT of alert macaque</article-title><source>Journal of Neurophysiology</source><volume>93</volume><fpage>1809</fpage><lpage>1815</lpage><pub-id pub-id-type="doi">10.1152/jn.00629.2004</pub-id><pub-id pub-id-type="pmid">15483068</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasternak</surname><given-names>T</given-names></name><name><surname>Tadin</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Linking neuronal direction selectivity to perceptual decisions about visual motion</article-title><source>Annual Review of Vision Science</source><volume>6</volume><fpage>335</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-121219-081816</pub-id><pub-id pub-id-type="pmid">32936737</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perrone</surname><given-names>JA</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Speed skills: measuring the visual speed analyzing properties of primate MT neurons</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>526</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1038/87480</pub-id><pub-id pub-id-type="pmid">11319562</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Computational approaches to sensorimotor transformations</article-title><source>Nature Neuroscience</source><volume>3 Suppl</volume><fpage>1192</fpage><lpage>1198</lpage><pub-id pub-id-type="doi">10.1038/81469</pub-id><pub-id pub-id-type="pmid">11127837</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Zemel</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Inference and computation with population codes</article-title><source>Annual Review of Neuroscience</source><volume>26</volume><fpage>381</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.26.041002.131112</pub-id><pub-id pub-id-type="pmid">12704222</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Cassanello</surname><given-names>CR</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The neural representation of speed in macaque area MT/V5</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>5650</fpage><lpage>5661</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-13-05650.2003</pub-id><pub-id pub-id-type="pmid">12843268</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Estimating target speed from the population response in visual area MT</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>1907</fpage><lpage>1916</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4233-03.2004</pub-id><pub-id pub-id-type="pmid">14985431</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Tuning for spatiotemporal frequency and speed in directionally selective neurons of macaque striate cortex</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>2941</fpage><lpage>2950</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3936-05.2006</pub-id><pub-id pub-id-type="pmid">16540571</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qian</surname><given-names>N</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name><name><surname>Adelson</surname><given-names>EH</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Transparent motion perception as detection of unbalanced motion signals. III. Modeling</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>7381</fpage><lpage>7392</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-12-07381.1994</pub-id><pub-id pub-id-type="pmid">7996183</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Recanzone</surname><given-names>GH</given-names></name><name><surname>Wurtz</surname><given-names>RH</given-names></name><name><surname>Schwarz</surname><given-names>U</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Responses of MT and MST neurons to one and two moving objects in the receptive field</article-title><source>Journal of Neurophysiology</source><volume>78</volume><fpage>2904</fpage><lpage>2915</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.78.6.2904</pub-id><pub-id pub-id-type="pmid">9405511</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Hierarchical models of object recognition in cortex</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>1019</fpage><lpage>1025</lpage><pub-id pub-id-type="doi">10.1038/14819</pub-id><pub-id pub-id-type="pmid">10526343</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rocchi</surname><given-names>F</given-names></name><name><surname>Ledgeway</surname><given-names>T</given-names></name><name><surname>Webb</surname><given-names>BS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Criterion-free measurement of motion transparency perception at different speeds</article-title><source>Journal of Vision</source><volume>18</volume><elocation-id>5</elocation-id><pub-id pub-id-type="doi">10.1167/18.4.5</pub-id><pub-id pub-id-type="pmid">29614154</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rockland</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Visual cortical organization at the single axon level: a beginning</article-title><source>Neuroscience Research</source><volume>42</volume><fpage>155</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/s0168-0102(01)00321-2</pub-id><pub-id pub-id-type="pmid">11900825</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rust</surname><given-names>NC</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>How MT cells analyze the motion of visual patterns</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1421</fpage><lpage>1431</lpage><pub-id pub-id-type="doi">10.1038/nn1786</pub-id><pub-id pub-id-type="pmid">17041595</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmehl</surname><given-names>MN</given-names></name><name><surname>Caruso</surname><given-names>VC</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Jun</surname><given-names>NY</given-names></name><name><surname>Willett</surname><given-names>SM</given-names></name><name><surname>Mohl</surname><given-names>JT</given-names></name><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>M</given-names></name><name><surname>Ebihara</surname><given-names>AF</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Tokdar</surname><given-names>ST</given-names></name><name><surname>Groh</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Multiple objects evoke fluctuating responses in several regions of the visual pathway</article-title><source>eLife</source><volume>13</volume><elocation-id>e91129</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.91129</pub-id><pub-id pub-id-type="pmid">38489224</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schoppmann</surname><given-names>A</given-names></name><name><surname>Hoffmann</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Continuous mapping of direction selectivity in the cat’s visual cortex</article-title><source>Neuroscience Letters</source><volume>2</volume><fpage>177</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1016/0304-3940(76)90011-2</pub-id><pub-id pub-id-type="pmid">19604837</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Natural image statistics and neural representation</article-title><source>Annual Review of Neuroscience</source><volume>24</volume><fpage>1193</fpage><lpage>1216</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.1193</pub-id><pub-id pub-id-type="pmid">11520932</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snowden</surname><given-names>RJ</given-names></name><name><surname>Treue</surname><given-names>S</given-names></name><name><surname>Erickson</surname><given-names>RG</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>The response of area MT and V1 neurons to transparent motion</article-title><source>The Journal of Neuroscience</source><volume>11</volume><fpage>2768</fpage><lpage>2785</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.11-09-02768.1991</pub-id><pub-id pub-id-type="pmid">1880548</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>AA</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Noise characteristics and prior expectations in human visual speed perception</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>578</fpage><lpage>585</lpage><pub-id pub-id-type="doi">10.1038/nn1669</pub-id><pub-id pub-id-type="pmid">16547513</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stoner</surname><given-names>GR</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Neural correlates of perceptual motion coherence</article-title><source>Nature</source><volume>358</volume><fpage>412</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1038/358412a0</pub-id><pub-id pub-id-type="pmid">1641024</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treue</surname><given-names>S</given-names></name><name><surname>Hol</surname><given-names>K</given-names></name><name><surname>Rauber</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Seeing multiple directions of motion-physiology and psychophysics</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>270</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1038/72985</pub-id><pub-id pub-id-type="pmid">10700260</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ungerleider</surname><given-names>LG</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Cortical connections of visual area MT in the macaque</article-title><source>The Journal of Comparative Neurology</source><volume>248</volume><fpage>190</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1002/cne.902480204</pub-id><pub-id pub-id-type="pmid">3722458</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Bergen</surname><given-names>RS</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Pratte</surname><given-names>MS</given-names></name><name><surname>Jehee</surname><given-names>JFM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sensory uncertainty decoded from visual cortex predicts behavior</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1728</fpage><lpage>1730</lpage><pub-id pub-id-type="doi">10.1038/nn.4150</pub-id><pub-id pub-id-type="pmid">26502262</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vintch</surname><given-names>B</given-names></name><name><surname>Gardner</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical correlates of human motion perception biases</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>2592</fpage><lpage>2604</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2809-13.2014</pub-id><pub-id pub-id-type="pmid">24523549</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiss</surname><given-names>Y</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Adelson</surname><given-names>EH</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Motion illusions as optimal percepts</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>598</fpage><lpage>604</lpage><pub-id pub-id-type="doi">10.1038/nn0602-858</pub-id><pub-id pub-id-type="pmid">12021763</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiesner</surname><given-names>S</given-names></name><name><surname>Baumgart</surname><given-names>IW</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Spatial Arrangement drastically changes the neural representation of multiple visual stimuli that compete in more than one feature domain</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>1834</fpage><lpage>1848</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1950-19.2020</pub-id><pub-id pub-id-type="pmid">31937557</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wiesner</surname><given-names>S</given-names></name><name><surname>Ghimire</surname><given-names>B</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Mechanisms of Neural Representation and Segregation of Multiple Spatially Separated Visual Stimuli</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2025.09.11.675659</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>J</given-names></name><name><surname>Niu</surname><given-names>YQ</given-names></name><name><surname>Wiesner</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Normalization of neuronal responses in cortical area MT across signal strengths and motion directions</article-title><source>Journal of Neurophysiology</source><volume>112</volume><fpage>1291</fpage><lpage>1306</lpage><pub-id pub-id-type="doi">10.1152/jn.00700.2013</pub-id><pub-id pub-id-type="pmid">24899674</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distributed and dynamic neural encoding of multiple motion directions of transparently moving stimuli in cortical area MT</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>16180</fpage><lpage>16198</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2175-15.2015</pub-id><pub-id pub-id-type="pmid">26658869</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Relationship between adapted neural population responses in MT and motion adaptation in speed and direction of smooth-pursuit eye movements</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>2693</fpage><lpage>2707</lpage><pub-id pub-id-type="doi">10.1152/jn.00061.2009</pub-id><pub-id pub-id-type="pmid">19225178</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zemel</surname><given-names>RS</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Probabilistic interpretation of population codes</article-title><source>Neural Computation</source><volume>10</volume><fpage>403</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1162/089976698300017818</pub-id><pub-id pub-id-type="pmid">9472488</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>LQ</given-names></name><name><surname>Stocker</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Prior expectations in visual speed perception predict encoding characteristics of neurons in area MT</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>2951</fpage><lpage>2962</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1920-21.2022</pub-id><pub-id pub-id-type="pmid">35169018</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoccolan</surname><given-names>D</given-names></name><name><surname>Cox</surname><given-names>DD</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Multiple object response normalization in monkey inferotemporal cortex</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>8150</fpage><lpage>8164</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2058-05.2005</pub-id><pub-id pub-id-type="pmid">16148223</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Additional analysis of the weight for the fast component, using the firing rates in response to the slower component from split trials</title><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Weights for the faster stimulus component obtained from the slope of the linear regression, based on the recorded responses of 100 neurons.</title><p>The black curves are a replot of those in <xref ref-type="fig" rid="fig5">Figure 5F1 and F2</xref>, with the <italic>Rs</italic> (the response to the slower component) calculated based on the average firing rate across all trials for each neuron at each speed pair. The red curves were calculated the same way as the black curves, except that the <italic>Rs</italic> used for the linear regression between <inline-formula><alternatives><mml:math id="inf119"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft119">\begin{document}$(R-R_s)$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf120"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft120">\begin{document}$(R_f-R_s)$\end{document}</tex-math></alternatives></inline-formula> was averaged across different subsets of trials. For each neuron and at each speed pair, we determined <inline-formula><alternatives><mml:math id="inf121"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft121">\begin{document}$R_{s1}$\end{document}</tex-math></alternatives></inline-formula> by averaging the firing rates of <inline-formula><alternatives><mml:math id="inf122"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft122">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> across half of the recorded trials, selected randomly. If the number of trials (<bold>n</bold>) was odd, we selected (n+1)/2 trials. We also determined <inline-formula><alternatives><mml:math id="inf123"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft123">\begin{document}$R_{s2}$\end{document}</tex-math></alternatives></inline-formula> by averaging the firing rates of <inline-formula><alternatives><mml:math id="inf124"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft124">\begin{document}$R_{s}$\end{document}</tex-math></alternatives></inline-formula> across the rest of the trials. We regressed <inline-formula><alternatives><mml:math id="inf125"><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft125">\begin{document}$\left (R- R_{s1}\right)$\end{document}</tex-math></alternatives></inline-formula> on <inline-formula><alternatives><mml:math id="inf126"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft126">\begin{document}$\left (R_{f}- R_{s2}\right)$\end{document}</tex-math></alternatives></inline-formula>, as well as <inline-formula><alternatives><mml:math id="inf127"><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft127">\begin{document}$\left (R- R_{s2}\right)$\end{document}</tex-math></alternatives></inline-formula> on <inline-formula><alternatives><mml:math id="inf128"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>−</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><tex-math id="inft128">\begin{document}$\left (R_{f}- R_{s1}\right)$\end{document}</tex-math></alternatives></inline-formula>, and repeated the procedure 50 times. We then averaged the slope for each speed pair across a total of 100 regressions. Red error bars represent the standard deviation (N=100 regressions). (<bold>A</bold>) 4x speed separation. (<bold>B</bold>) 2x speed separation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-app1-fig1-v1.tif"/></fig></sec><sec sec-type="appendix" id="s9"><title>Behavioral performance of the fine-direction discrimination task and MT response properties when the attention was directed away from MT neurons’ RFs</title><p>The monkey RG performed a direction discrimination task with an average correct rate of 86.7 ± 7.3% (mean ± std) across 23 sessions and over 5000 trials. The correct rates for 10°, 15°, and 20° direction offsets of the direction discrimination task were 78.8 ± 9.7%, 87.5 ± 8.3%, and 93.9 ± 5.8%, respectively (see Methods).</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components recorded in an attention-away and a fixation paradigm.</title><p>Speed tuning curves from one monkey (RG) averaged across: (<bold>A1–D1</bold>) five neurons that had preferred speed (PS) ≤2.5°/s, (<bold>A2–D2</bold>) six neurons that had PS between 2.5 and 25°/s, (<bold>A3–D3</bold>) 21 neurons that had PS &gt;25°/s. Error bars represent ± STE. (<bold>A1–A3</bold>) and (<bold>B1–B3</bold>) 4x speed separation; (<bold>C1–C3</bold>) and (<bold>D1–D3</bold>) 2x speed separation. (<bold>A1–A3</bold>) and (<bold>C1–C3</bold>) Attention directed away from the receptive fields (RFs); (<bold>B1–B3</bold>) and (<bold>D1–D3</bold>) Fixation paradigm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-app1-fig2-v1.tif"/></fig></sec><sec sec-type="appendix" id="s10"><title>Trial-by-trial readouts from population neural responses to single speeds</title><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Trial-by-trial readout speeds decoded from population neural responses to single speeds.</title><p>The neural population contained 100 recorded neurons, as shown in <xref ref-type="fig" rid="fig9">Figure 9</xref>. The trial-by-trial responses were randomly generated based on a Poisson process, with the mean set to the spike count averaged across the recorded trials. Each row in A-L shows the readout speed(s) from one trial, and each dot’s size is proportional to the weight of the readout speed. If only one speed is decoded in a trial, that readout speed is shown in red. In trials with two readout speeds, the slower and faster readout speeds are shown in green and blue, respectively. The white background indicates trials with a weight difference between two readout speeds of less than 0.7, which are considered to have two readout speeds. The gray background indicates trials with a weight difference greater than 0.7, which are considered to have only one readout speed. The vertical black line and the speed marked in each panel indicate the stimulus speed. (<bold>A–G</bold>) Speeds decoded from recorded population neural responses to single speeds from 1.25 to 80°/s. Note that, at the stimulus speed of 80°/s (<bold>G</bold>), in addition to picking up the veridical speed of 80°/s (log speed of 4.382), the decoder often picked up a slower speed at 2.872°/s (log speed of 1.055), which was at the largest speed separation from 80°/s used in our searching algorithm (27.86x, log value 3.327). This border effect can also be seen at the stimulus speed of 1.25°/s (<bold>A</bold>), where a weaker and faster speed was sometimes picked up around 34.8°/s (log speed of 3.55). (<bold>H–L</bold>) Speeds decoded from inferred population neural response to single speeds, which are the log-mean speeds of the bi-speed stimuli with 2x speed separation. The responses of these log mean speeds of 2x speed separation were obtained from the splined-fitted, trial-averaged speed-tuning curve of each neuron. (<bold>M</bold>) Comparison of the readout speeds and the stimulus speeds. The diagonal line is the unity line. The ordinate represents the speed at the peak of the readout speed distribution pooled across simulated trials (not shown). At the stimulus speed of 1.77°/s (<bold>H</bold>), the distribution of the readout speed has two peaks, indicated by a solid circle (at 1.77°/s) and an open circle (at 1.25°/s). At the stimulus speed of 80°/s (<bold>G</bold>), the distribution of the readout speed also has two peaks; only the readout speed for the higher peak is shown in M.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-app1-fig3-v1.tif"/></fig></sec><sec sec-type="appendix" id="s11"><title>Analysis of decoded speeds of the bi-speed stimulus with the speeds of 20 and 80°/s</title><p>At the fastest stimulus speeds of 20 and 80°/s, across all trials, the mean objective function value peaked at speed separation of 3.25x (mean OF = –0.17, std = 0.14) (purple vertical line in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4A</xref>). However, the peak value is not significantly different from the mean objective function value at the largest speed separation (27.86x, 3.3 on the log scale) searched (mean OF = –0.19, std=0.14) (paired t-test, <italic>p</italic>=0.31) (orange vertical line in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4A</xref>). The flat objective function suggests high uncertainty of the extracted speed separation at this speed pair.</p><p>We divided the trials into two subgroups, based on whether they had one or two readout speeds, and calculated the objective function for each subgroup.</p><p>For trials considered to have two readout speeds, the objective function peaked at the speed separation of 3.25x (1.18 on the log scale) (purple vertical line in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4B</xref>), corresponding to two readout speeds of 17.8 and 58.0°/s (the intersection points between the purple vertical line with the thick navy blue and thick green curves) (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4C</xref>).</p><p>For trials considered to have one readout speed, the mean objective function showed a peak at the speed separation of 27.86x (3.3 on the log scale), which was the largest speed separation searched (orange vertical line in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4E</xref>). As shown in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4F</xref>, the dominant faster readout speed approached the log mean speed (40°/s, 3.7 on log scale) (thick navy blue curve) and the mean weight increased to 0.94 (cyan curve), as the searched speed separation increased. In contrast, as the searched speed separation increased, the slower readout speed approached the lower boundary speed (1.25°/s) (thick green curve) with the weight diminishing to negligible 0.06 (thin green curve) (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4F</xref>), likely a border artifact.</p><p>Furthermore, we compared the population neural responses averaged across the one-readout-speed trials and the two-readout-speed trials. The spline-fitted population responses of the two subgroups were highly correlated (R<sup>2</sup>=0.99) and statistically indistinguishable (paired t-test, <italic>p</italic>=0.30) (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4D</xref>). This indicates that a tiny change in the population response (e.g. a slightly higher peak near log preferred speed of 3.7) would lead the decoder to exact one speed rather than two speeds (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4D</xref>). In other words, the decoder was uncertain about how many speeds were in the visual stimuli and, therefore, had difficulty segmenting the visual stimuli at these fast stimulus speeds of 20 and 80°/s.</p><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Analysis of decoding the bi-speed stimulus with the speeds of 20 and 80°/s.</title><p>(<bold>A</bold>) Values of the objective function averaged across all 200 trials as the decoder searched through different speed separations. The red dot on the X-axis indicates the ground-truth speed separation of the stimulus speeds. (<bold>B, E</bold>) Values of the objective functions averaged across trials considered to have two (<bold>B</bold>) and one (<bold>E</bold>) readout speed(s). In A, B, and E, the error bands indicate ± STE. The black arrow indicates the speed separation where the objective function reaches its peak. The horizontal dotted line indicates the peak value of the objective function. (<bold>C, F</bold>) Values of the readout speeds (darker and thick lines in green and blue) and their weights (lighter and thin lines in green and cyan) as the decoder searched through different speed separations in trials considered to have two (<bold>C</bold>) and one (<bold>F</bold>) readout speed(s). (<bold>D</bold>) Population neural responses averaged across trials that are considered to have two readout speeds (purple) and one readout speed (orange). Each dot represents the trial-averaged response of one neuron. The curves represent the spline-fitted population neural responses. The two red dots on the X-axis indicate stimulus speeds of 20 and 80°/s.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94835-app1-fig4-v1.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94835.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Groh</surname><given-names>Jennifer M</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Duke University</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion. The study is <bold>valuable</bold> because little is known about how the visual pathway segments and preserves information about multiple stimuli, and the study involves perceptual reports from both humans and one monkey regarding whether there are one or two speeds in the stimulus. The study presents <bold>compelling</bold> evidence that (on average) MT neurons shift from faster-speed-takes-all at low speeds to representing the average of the two speeds at higher speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information could potentially be lost in an average response as described here, depending on assumptions about how MT activity is evaluated by other visual areas.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94835.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Most studies in sensory neuroscience investigate how individual sensory stimuli are represented in the brain (e.g., the motion or color of a single object). This study starts tackling the more difficult question of how the brain represents multiple stimuli simultaneously and how these representations help to segregate objects from cluttered scenes with overlapping objects.</p><p>Strengths:</p><p>The authors first document the ability of humans to segregate two motion patterns based on differences in speed. Then they show that a monkey's performance is largely similar; thus establishing the monkey as a good model to study the underlying neural representations.</p><p>Careful quantification of the neural responses in the middle temporal area during the simultaneous presentation of fast and slow speeds leads to the surprising finding that, at low average speeds, many neurons respond as if the slowest speed is not present, while they show averaged responses at high speeds. This unexpected complexity of the integration of multiple stimuli is key to the model developed in this paper.</p><p>One experiment in which attention is drawn away from the receptive field supports the claim that this is not due to the involuntary capture of attention by fast speeds.</p><p>A classifier using the neuronal response and trained to distinguish single speed from bi-speed stimuli shows a similar overall performance and dependence on the mean speed as the monkey. This supports the claim that these neurons may indeed underlie the animal's decision process.</p><p>The authors expand the well-established divisive normalization model to capture the responses to bi-speed stimuli. The incremental modeling (eq 9 and 10) clarifies which aspects of the tuning curves are captured by the parameters.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94835.4.sa2</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion.</p><p>Strengths:</p><p>The study is valuable because little is known about how the visual pathway segments and preserves information about multiple stimuli. The study presents compelling evidence that (on average) MT neurons shift from faster-speed-takes-all at low speeds to representing the average of the two speeds at higher speeds. An additional strength of the study is the inclusion of perceptual reports from both humans and one monkey participant performing a task in which they judged whether the stimuli involved one vs two different speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information is potentially lost in an average response as described here.</p><p>Reviewing Editor comment on revised version:</p><p>The remaining concern was resolved.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94835.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Huang</surname><given-names>Xin</given-names></name><role specific-use="author">Author</role><aff><institution>University of Wisconsin-Madison</institution><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Ghimire</surname><given-names>Bikalpa</given-names></name><role specific-use="author">Author</role><aff><institution>University of Wisconsin-Madison</institution><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Chakrala</surname><given-names>Anjani Sreeprada</given-names></name><role specific-use="author">Author</role><aff><institution>University of Wisconsin-Madison</institution><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Wiesner</surname><given-names>Steven</given-names></name><role specific-use="author">Author</role><aff><institution>University of Wisconsin-Madison</institution><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations for the authors):</bold></p><p>The authors have done an excellent job of addressing most comments, but my concerns about Figure 5 remain. I appreciate the authors' efforts to address the problem involving Rs being part of the computation on both the x and y axes of Figure 5, but addressing this via simulation addresses statistical significance but overlooks effect size. I think the authors may have misunderstood my original suggestion, so I will attempt to explain it better here. Since &quot;Rs&quot; is an average across all trials, the trials could be subdivided in two halves to compute two separate averages - for example, an average of the even numbered trials and an average of the odd numbered trials. Then you would use the &quot;Rs&quot; from the even numbered trials for one axis and the &quot;Rs&quot; from the odd numbered trials for the other. You would then plot R-Rs_even vs Rf-Rs_odd. This would remove the confound from this figure, and allow the text/interpretation to be largely unchanged (assuming the results continue to look as they do).</p></disp-quote><p>We have added a description and the result of the new analysis (line #321 to #332), and a supplementary figure (Suppl. Fig. 1) (line #1464 to #1477).</p><p>“We calculated 𝑅<sub>𝑠</sub> in the ordinate and abscissa of Figure 5A-E using responses averaged across different subsets of trials, such that 𝑅<sub>𝑠</sub> was no longer a common term in the ordinate and abscissa. For each neuron, we determined 𝑅<sub>𝑠1</sub> by averaging the firing rates of 𝑅<sub>𝑠</sub> across half of the recorded trials, selected randomly. We also determined 𝑅<sub>𝑠2</sub> by averaging the firing rates of 𝑅<sub>𝑠</sub> across the rest of the trials. We regressed (𝑅 − 𝑅<sub>𝑠1</sub>) on (𝑅<sub>𝑓</sub> − 𝑅<sub>𝑠2</sub>) , as well as (𝑅<sub>𝑠</sub> - 𝑅<sub>𝑠2</sub>) on (𝑅<sub>𝑓</sub> − 𝑅<sub>𝑠1</sub>), and repeated the procedure 50 times. The averaged slopes obtained with 𝑅<sub>𝑠</sub> from the split trials showed the same pattern as those using 𝑅<sub>𝑠</sub> from all trials (Table 1 and Supplementary Fig. 1), although the coefficient of determination was slightly reduced (Table 1). For ×4 speed separation, the slopes were nearly identical to those shown in Figure 5F1. For ×2 speed separation, the slopes were slightly smaller than those in Figure 5F2, but followed the same pattern (Supplementary Fig. 1). Together, these analysis results confirmed the faster-speed bias at the slow stimulus speeds, and the change of the response weights as stimulus speeds increased.”</p><disp-quote content-type="editor-comment"><p>An additional remaining item concerns the terminology weighted sum, in the context of the constraint that wf and ws must sum to one. My opinion is that it is non-standard to use weighted sum when the computation is a weighted average, but as long as the authors make their meaning clear, the reader will be able to follow. I suggest adding some phrasing to explain to the reader the shift in interpretation from the more general weighted sum to the more constrained weighted average. Specifically, &quot;weighted sum&quot; first appears on line 268, and then the additional constraint of ws + wf = 1 is introduced on line 278. Somewhere around line 278, it would be useful to include a sentence stating that this constraint means the weighted sum is constrained to be a weighted average.</p></disp-quote><p>Thanks for the suggestion. We have modified the text as follows. Since we made other modifications in the text, the line numbers are slightly different from the last version.</p><p>Line #274 to 275:</p><p>“Since it is not possible to solve for both variables, 𝑤<sub>𝑠</sub> and 𝑤<sub>𝑓</sub>, from a single equation (Eq. 5) with three data points, we introduced an additional constraint: 𝑤<sub>𝑠</sub> + 𝑤<sub>𝑓</sub> = 1. With this constraint, the weighted sum becomes a weighted average.”</p><p>Also on line #309:</p><p>“First, at each speed pair and for each of the 100 neurons in the data sample shown in Figure 5, we simulated the response to the bi-speed stimuli (𝑅<sub>𝑒</sub>) as a randomly weighted average of 𝑅<sub>𝑓</sub> and 𝑅<sub>𝑠</sub> of the same neuron.<disp-formula id="sa3equ1"><alternatives><mml:math id="sa3m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle R_{e}=a R_{f}+(1-a) R_{s}$$\end{document}</tex-math></alternatives></disp-formula></p><p>in which 𝑎 was a randomly generated weight (between 0 and 1) for 𝑅<sub>𝑓</sub>, and the weights for 𝑅<sub>𝑓</sub> and 𝑅<sub>𝑠</sub> summed to one.”</p></body></sub-article></article>