<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">53275</article-id><article-id pub-id-type="doi">10.7554/eLife.53275</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Human Biology and Medicine</subject></subj-group></article-categories><title-group><article-title>A synthetic dataset primer for the biobehavioural sciences to promote reproducibility and hypothesis generation</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-137412"><name><surname>Quintana</surname><given-names>Daniel S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2876-0004</contrib-id><email>daniel.quintana@medisin.uio.no</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>Norwegian Centre for Mental Disorders Research (NORMENT), Division of Mental Health and Addiction, University of Oslo, and Oslo University Hospital</institution><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Zaidi</surname><given-names>Mone</given-names></name><role>Reviewing Editor</role><aff><institution>Icahn School of Medicine at Mount Sinai</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Senior Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>11</day><month>03</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e53275</elocation-id><history><date date-type="received" iso-8601-date="2019-11-01"><day>01</day><month>11</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2020-03-11"><day>11</day><month>03</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Quintana</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Quintana</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-53275-v2.pdf"/><abstract><p>Open research data provide considerable scientific, societal, and economic benefits. However, disclosure risks can sometimes limit the sharing of open data, especially in datasets that include sensitive details or information from individuals with rare disorders. This article introduces the concept of synthetic datasets, which is an emerging method originally developed to permit the sharing of confidential census data. Synthetic datasets mimic real datasets by preserving their statistical properties and the relationships between variables. Importantly, this method also reduces disclosure risk to essentially nil as no record in the synthetic dataset represents a real individual. This practical guide with accompanying R script enables biobehavioural researchers to create synthetic datasets and assess their utility via the <italic>synthpop</italic> R package. By sharing synthetic datasets that mimic original datasets that could not otherwise be made open, researchers can ensure the reproducibility of their results and facilitate data exploration while maintaining participant privacy.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>It is becoming increasingly common for scientists to share their data with other researchers. This makes it possible to independently verify reported results, which increases trust in research. Sometimes it is not possible to share certain datasets because they include sensitive information about individuals. In psychology and medicine, scientists have tried to remove identifying information from datasets before sharing them by, for example, adding minor artificial errors. But, even when researchers take these steps, it may still be possible to identify individuals, and the introduction of artificial errors can make it harder to verify the original results.</p><p>One potential alternative to sharing sensitive data is to create ‘synthetic datasets’. Synthetic datasets mimic original datasets by maintaining the statistical properties of the data but without matching the original recorded values. Synthetic datasets are already being used, for example, to share confidential census data. However, this approach is rarely used in other areas of research. Now, Daniel S. Quintana demonstrates how synthetic datasets can be used in psychology and medicine.</p><p>Three different datasets were studied to ensure that synthetic datasets performed well regardless of the type or size of the data. Quintana evaluated freely available software that could generate synthetic versions of these different datasets, which essentially removed any identifying information. The results obtained by analysing the synthetic datasets closely mimicked the original results.</p><p>These tools could allow researchers to verify each other’s results more easily without jeopardizing the privacy of participants. This could encourage more collaboration, stimulate ideas for future research, and increase data sharing between research groups.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>meta-research</kwd><kwd>data</kwd><kwd>statistics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100009708</institution-id><institution>Novo Nordisk Foundation</institution></institution-wrap></funding-source><award-id>Excellence grant NNF16OC0019856</award-id><principal-award-recipient><name><surname>Quintana</surname><given-names>Daniel S</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Sharing synthetic datasets that mimic original datasets that could not otherwise be made publicly available can help ensure reproducibility and facilitate data exploration while maintaining participant privacy.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Openly accessible biomedical research data provide enormous utility for science, society, and the economy (<xref ref-type="bibr" rid="bib4">Arzberger et al., 2004</xref>; <xref ref-type="bibr" rid="bib22">Munafò et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Murdoch and Detsky, 2013</xref>; <xref ref-type="bibr" rid="bib30">Piwowar et al., 2011</xref>). With open data, scholars can verify results, generate new knowledge, form new hypotheses, and reduce the unnecessary duplication of data collection (<xref ref-type="bibr" rid="bib5">Asendorpf et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Nosek et al., 2012</xref>). However, the benefits of data sharing need to be considered in light of disclosure risk. Researchers who wish to share data while reducing the risk of disclosure have traditionally used data anonymization procedures, in which explicit identifiers such as names, addresses, and national identity numbers are removed (<xref ref-type="bibr" rid="bib14">Hrynaszkiewicz et al., 2010</xref>). To add additional disclosure protection, particularly sensitive variables (e.g., age) are sometimes aggregated and random noise may be added to the dataset. Despite these anonymization efforts, specific individuals can still be identified in anonymized datasets with high accuracy (<xref ref-type="bibr" rid="bib28">Ohm, 2009</xref>; <xref ref-type="bibr" rid="bib39">Rocher et al., 2019</xref>). Data aggregation and random noise can also distort the relationships between variables in the dataset (<xref ref-type="bibr" rid="bib31">Purdam and Elliot, 2007</xref>), which can interfere with reproducibility and exploratory data analysis.</p><p>The creation of synthetic datasets can substantially overcome replicability issues, as this method creates a new dataset that mimics an original dataset by preserving its statistical properties and relationships between variables (<xref ref-type="bibr" rid="bib18">Little, 1993</xref>; <xref ref-type="bibr" rid="bib36">Reiter, 2005b</xref>; <xref ref-type="bibr" rid="bib35">Reiter, 2005a</xref>; <xref ref-type="bibr" rid="bib38">Reiter and Raghunathan, 2007</xref>; <xref ref-type="bibr" rid="bib41">Rubin, 1993</xref>). Synthetic datasets also reduce disclosure risk to essentially zero, as no complete casewise record in the new dataset represents a real individual (<xref ref-type="bibr" rid="bib11">Duncan and Elliot, 2011</xref>). Synthetic datasets also allow researchers to fit exploratory models in the synthetic datasets, which the data custodians can verify in the original data. Finally, synthetic datasets enable readers and reviewers to better understand the data, as they can recreate the reported analyses and explore data distributions, variance, outliers, and means.</p><p>Synthetic datasets were originally developed for sharing sensitive population-level data (for a summary, see <xref ref-type="bibr" rid="bib6">Bonnéry et al., 2019</xref>). The use of synthetic data for sharing sensitive information is beginning to emerge in the biobehavioural sciences (e.g., <xref ref-type="bibr" rid="bib3">Arslan et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">Newbury et al., 2018</xref>); however, this approach is not widely known in the field. Given the benefits of synthetic data, the purpose of this article is to introduce this concept using examples and an accompanying R script. The R script and datasets to reproduce the analyses described in this paper are available online at <ext-link ext-link-type="uri" xlink:href="https://github.com/dsquintana/synthpop-primer">https://github.com/dsquintana/synthpop-primer</ext-link> (<xref ref-type="bibr" rid="bib32">Quintana, 2019</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/synthpop-primer">https://github.com/elifesciences-publications/synthpop-primer</ext-link>). This website also includes a link to a RStudio Server instance of the primary analysis and results, which recreates the complete computational environment used for this manuscript (i.e., the R version and R package versions used) and facilitates straightforward reproducibility of the analysis described in this article via any modern web browser.</p></sec><sec id="s2" sec-type="methods"><title>Methods, materials, and results</title><p>Three open datasets will be used to demonstrate how the generation of a synthetic dataset can produce a dataset that mimics the original, via the <italic>synthpop</italic> R package (version 1.5–1; <xref ref-type="bibr" rid="bib26">Nowok et al., 2016</xref>) in the R statistical environment (version 3.6.0). Synthetic datasets are created by replacing some or all of the data by sampling from an appropriate probability distribution, in a similar fashion to multiple imputation (<xref ref-type="bibr" rid="bib9">Drechsler, 2011</xref>; <xref ref-type="bibr" rid="bib34">Raghunathan et al., 2003</xref>; <xref ref-type="bibr" rid="bib36">Reiter, 2005b</xref>). This approach preserves the statistical properties and the relationships between variables in the original dataset while safeguarding anonymity as no individual in the new dataset represents a real individual. The default synthesis method in <italic>synthpop</italic> is the classification and regression tree (CART) procedure (<xref ref-type="bibr" rid="bib36">Reiter, 2005b</xref>), which will be used in this primer. The CART procedure is more flexible and generally performs better than other synthesis methods, such as random forests and bagging (<xref ref-type="bibr" rid="bib10">Drechsler and Reiter, 2011</xref>). If data synthesis happens to recreate a replicate of a real individual by chance, these replicates can be easily identified and removed from the dataset to reduce the risk of de-identification.</p><p>There are two broad approaches for assessing the utility of a synthesized dataset: general utility and specific utility (<xref ref-type="bibr" rid="bib44">Snoke et al., 2018</xref>). General utility reflects the overall similarities in the statistical properties and multivariate relationships between the synthetic and original datasets. The first step in assessing general utility is data visualisation (<xref ref-type="bibr" rid="bib26">Nowok et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Raab et al., 2017</xref>). The compare() function in <italic>synthpop</italic> can be used to construct side-by-side univariate distributions of variables in the synthetic and observed datasets. Visualizing bivariate comparisons between specific variables of interest is also recommended, as two datasets might have similar statistical properties despite different distributions (e.g., Anscombe’s quartet; <xref ref-type="bibr" rid="bib2">Anscombe, 1973</xref>). Confirming general utility is a necessary step for making inferences from the synthetic dataset and is especially important for data exploration in the synthetic dataset (<xref ref-type="bibr" rid="bib44">Snoke et al., 2018</xref>).</p><p>Specific utility for fitted synthetic models can be assessed by calculating the lack-of-fit against the same model in the original data (<xref ref-type="bibr" rid="bib26">Nowok et al., 2016</xref>). Specific coefficients in synthetic models can also be compared against coefficients in the original models by assessing the differences in standardized coefficients and confidence interval (CI) overlap (<xref ref-type="bibr" rid="bib16">Karr et al., 2006</xref>), which is the ratio of the overlap of the intervals to an average of their lengths. Higher overlap is indicative of greater specific utility, which suggests that inference from fitted synthetic models is valid.</p><p>Finally, there is a risk that individuals coming across the synthetic data without context (i.e., a direct link to a data file) may believe the data are real. Thus, to remove any possible confusion, synthetic datasets prepared for export will have a single string ‘FAKE_DATA’ variable added to the front of the dataset using the sdc() function in <italic>synthpop</italic>, as recommended by <xref ref-type="bibr" rid="bib27">Nowok et al. (2017)</xref>.</p><sec id="s2-1"><title>Example 1: Oxytocin and self-reported spirituality</title><p><xref ref-type="bibr" rid="bib48">Van Cappellen et al. (2016)</xref> investigated the impact of oxytocin administration on self-reported spirituality and deposited the raw study data online (<ext-link ext-link-type="uri" xlink:href="https://osf.io/rk2x7/">https://osf.io/rk2x7/</ext-link>). In a between-participants design, volunteers were randomly assigned to self-administer an intranasal oxytocin (N = 41) or intranasal placebo spray (N = 42). Approximately forty minutes after receiving the nasal spray, participants were asked “Right now, would you say that spirituality is important in your life?”. The reported outcome from an ANCOVA suggested that when accounting for religious affiliation, participants who self-administered the oxytocin nasal spray reported that spirituality was more important in their lives compared to those who self-administered the placebo spray. A synthetic version of the original dataset was created using the syn() function from the <italic>synthpop</italic> package. A comparison of the four main variables of interest revealed similar distributions between the synthetic and the original datasets and no individual extreme values (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). There were also no replicated unique sets of values. A bivariate comparison of self-reported spiritualty (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) and religious affiliation (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>) between the nasal spray groups suggested that the counts between the synthesized and original datasets were similar. The relationship between age and self-reported spirituality was also similar between datasets (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). Altogether, these visualisations were indicative that the synthetic dataset has good general utility.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>General and specific utility of synthetic data from a study on the impact of intranasal oxytocin on self-reported spirituality.</title><p>A comparison of the four variables of interest revealed similar distributions in both the observed and the synthetic datasets, which is indicative of good general utility (<bold>A</bold>). Direct comparisons of coefficient estimates and 95% confidence intervals from linear models calculated from synthetic and observed datasets revealed no significant differences and high confidence interval overlap (<bold>B–D</bold>), which is indicative of good specific utility.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Differences in self-reported spirituality, stratified by nasal spray condition and dataset.</title><p>After receiving either the oxytocin or placebo nasal spray (depending on randomization), participants were asked on a scale from 0 (Not at all) to 7 (Completely), “Right now, would you say that spirituality is important for you?”. The difference in counts between the observed dataset (obs) and the synthetic dataset (syn) are shown for each possible response on the scale (0–7). As the counts were similar between datasets for each possible response, this suggests that the synthetic dataset has good utility. There were no missing datapoints (NA).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Differences in religious affiliation, stratified by nasal spray condition and dataset.</title><p>The difference in counts between the observed dataset (obs) and the synthetic dataset (syn) are shown for two religious affiliation categories: affiliated with a religion and non-affiliated with any religion. As the counts were similar between datasets for both categories, this suggests that the synthetic dataset has good utility.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>The relationship between age and self-reported spirituality in the observed and synthetic datasets.</title><p>As the scatterplot and density plots appear similar between the observed and synthetic datasets, this suggests that the synthetic dataset has good utility.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig1-figsupp3-v2.tif"/></fig></fig-group><p>Nasal spray group differences in self-reported spiritualty will be examined using both an independent samples Welch’s <italic>t</italic>-test and a linear regression model equivalent, with the former required to assess specific utility. This analysis in the original dataset suggested no significant difference in spirituality ratings between the nasal spray groups [<italic>t</italic> = 1.14, 95% CI (−0.45, 1.63), p=0.26]. An equivalent linear regression model yielded the same outcome, as expected. Estimating this linear model in the synthesized dataset revealed the same p-value outcome (<italic>t</italic> = −1.12, p=0.26).</p><p>The lack-of-fit test comparing the models generated in the original and synthetic datasets was not statistically significant, <italic>X</italic><sup>2</sup> (2)=0.01, p=0.995. This suggests that the method used for synthesis retained all the relationships between variables that influenced the model fitting parameters. The standardized difference of the nasal spray condition coefficient between the synthesized and the observed data for this <italic>t</italic>-test was 0.003, which was not statistically significant (p=0.998). A comparison of confidence intervals revealed 99.94% CI overlap between the synthetic and original datasets (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Overall, these results indicate that the model from the synthesized data demonstrates high specific utility for this <italic>t</italic>-test. This particular outcome was not reported in the original article; however, this provides a demonstration of how synthetic data can be used for data exploration. The analysis script underlying exploratory analysis can be shared with the owners of the original dataset, for the easy verification of the analysis. In this case, applying this model to the synthetic data produces almost precisely the same results as the original dataset.</p><p>Next, let’s explore the correlation between age and self-reported spirituality. A Pearson correlation test revealed no statistically significant correlation between age and self-reported spirituality [<italic>r</italic> = 0.04, 95% CI (−0.19, 0.26), p=0.75], which is the same result as the linear model equivalent. Estimating this model using the synthetic dataset revealed a similar Pearson’s <italic>r</italic> value and a non-significant result (<italic>r</italic> = 0.08, p=0.5). The lack-of-fit test comparing the models generated in the original and synthetic datasets was not statistically significant, <italic>X</italic><sup>2</sup> (2)=0.13, p=0.94. Moreover, the test of the standardized differences between the synthetic and original data for the relationship coefficient was not statistically significant (p=0.72) and there was 90.8% CI overlap between the synthetic and observed data (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), suggesting high specific utility.</p><p>Finally, let’s explore the main reported outcomes from this study, that oxytocin increased self-reported spirituality controlling for religious affiliation. First, the original outcome was verified [F(1,75)=4.87, p=0.03] and then the analysis was structured as a linear regression model. This analysis yielded the same p-value of .03, which was associated with a <italic>t</italic>-statistic of −2.2. Estimating this model using the synthetic dataset revealed similar <italic>t-</italic>statistic and a p-value that was on the border of statistical significance (<italic>t</italic> = −1.8, p=0.07).</p><p>The lack-of-fit test for the full model was not statistically significant, <italic>X</italic><sup>2</sup> (3)=0.91, p=0.82. The test of the standardized differences between the synthetic and original data for the nasal spray coefficient was not statistically significant (p=0.63) and there was 87.8% overlap between the synthetic and observed data (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Although the synthetic model nasal spray coefficient was not statistically significant, like the original model, this matters little given the considerable overlap between the confidence intervals of the synthetic and original models. It is worth a reminder at this point that just because one coefficient is significant and the other is not, this does not necessarily mean that these coefficients are significantly different from each other (<xref ref-type="bibr" rid="bib13">Gelman and Stern, 2006</xref>). The primary interest in the comparison of synthetic and original models is effect size estimation and confidence interval overlap. The test of the standardized differences between the synthetic and original data for the religious affiliation coefficient was not statistically significant (p=0.49) and there was 82.3% overlap between the synthetic and observed data (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Overall, these results are indicative of high specific utility for the overall synthesized model and its coefficients.</p></sec><sec id="s2-2"><title>Example 2: Sociosexual orientation and self-rated attractiveness</title><p>Sociosexual orientation is described as an individual’s propensity to participate in uncommitted sexual relationships. Given the personal nature of sociosexual orientation, this a good example of the type of sensitive data that individuals may be hesitant to share in some cases, thus demonstrating the benefit of releasing of synthetic data. <xref ref-type="bibr" rid="bib15">Jones and DeBruine, 2019</xref> collected sociosexual orientation data from 9627 individuals using a revised version of the sociosexual orientation inventory (<xref ref-type="bibr" rid="bib29">Penke and Asendorpf, 2008</xref>) both in the laboratory and online, along with data on self-rated attractiveness and basic demographic information. Fourteen variables were synthesized from the original dataset, which has been archived online (<ext-link ext-link-type="uri" xlink:href="https://osf.io/6bk3w/">https://osf.io/6bk3w/</ext-link>). The synthetic data demonstrated good general utility, as the distributions of variables were comparable between the original and synthetic datasets (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). A model was fitted to examine if self-rated attractiveness, data collection location (laboratory or online), and age predicted the number of times someone has had sexual intercourse on only a single occasion with another individual. Both self-rated attractiveness (<italic>t</italic> = 13.64, p&lt;0.001) and age (<italic>t</italic> = 27.69, p&lt;0.001) were statistically significant predictors, whereas location was not a significant predictor (<italic>t</italic> = 0.05, p=0.96). Estimating this linear model in the synthesized dataset revealed relatively similar <italic>t</italic>-statistic outcomes (self-rated attractiveness: <italic>t</italic> = 14, p&gt;0.001; age: <italic>t</italic> = 27.51, p&lt;0.001; location: <italic>t</italic> = 1.12, p=0.26).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>General and specific utility of synthetic data from an investigation on sociosexual orientation.</title><p>A comparison of the fourteen variables of interest revealed similar distributions in both the observed and the synthetic datasets, which is indicative of good general utility (<bold>A</bold>). Direct comparisons of coefficient estimates and 95% confidence intervals from a linear model calculated from synthetic and observed datasets revealed no significant differences and high confidence interval overlap (<bold>B</bold>), which is indicative of good specific utility. The coefficient estimates and 95% confidence intervals of the same model derived from the synthetic dataset with 213 replicated individuals removed also demonstrated high confidence interval overlap (<bold>C</bold>). This demonstrates that reducing disclosure risk has little effect on specific utility.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig2-v2.tif"/></fig><p>The lack-of-fit test was not statistically significant, [<italic>X</italic><sup>2</sup> (4)=1.5, p=0.83], suggesting that the method used for synthesis retained all the relationships between variables that influenced the parameters of the fit. The standardized difference of the self-rated attractiveness coefficient between the synthesized and the observed data was 0.32, which was not statistically significant (p=0.75). A comparison of confidence intervals revealed 91.8% CI overlap between the synthetic and original datasets (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The standardized difference of the age coefficient between the synthesized and the observed data for this <italic>t</italic>-test was −0.28, which was not statistically significant (p=0.78). A comparison of confidence intervals revealed 92.9% CI overlap between the synthetic and original datasets (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The standardized difference of the location coefficient between the synthesized and the observed data for this <italic>t</italic>-test was 1.08, which was not statistically significant (p=0.28). A comparison of confidence intervals revealed 72.4% CI overlap between the synthetic and original datasets (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Overall, these results indicate that this model from the synthesized data demonstrated high specific utility.</p><p>A comparison of the original and synthetic datasets revealed 213 replicated individuals (2.3% of the total sample). To reduce disclosure risk, these replicated values were removed and models were refitted to examine the effects of removal on outcomes. The lack-of-fit test between the original model and synthetic model with replicated individuals was not statistically significant, <italic>X</italic><sup>2</sup> (4)=2.8, p=0.6. The refitted model coefficients yielded similar results to the model derived from the original data (self-rated attractiveness: standardized difference = 0.3, p=0.77, CI overlap = 92.4%; age: standardized difference = −0.74, p=0.46, CI overlap = 81.2%; location: standardized difference = 0.95, p=0.34, CI overlap = 75.8%; <xref ref-type="fig" rid="fig2">Figure 2C</xref>). Therefore, reducing the risk of disclosure by removing replicated individuals in the synthetic dataset maintains specific utility, in this case.</p></sec><sec id="s2-3"><title>Example 3: Heart rate variability and fitness levels in a series of simulated datasets</title><p>Heart Rate Variability (HRV) is a non-invasive measure of autonomic cardiac control (<xref ref-type="bibr" rid="bib1">Akselrod et al., 1981</xref>) and thought to be positively correlated with fitness level (<xref ref-type="bibr" rid="bib8">Dixon et al., 1992</xref>). The Root Mean Square of Successive Differences (RMSSD) is a commonly used HRV measure, however, its distribution tends to be positively skewed (e.g., <xref ref-type="bibr" rid="bib17">Kobayashi et al., 2012</xref>). Moreover, missing data are common in HRV investigations due to equipment malfunction. To demonstrate the effects of the distribution pattern of HRV (normal, low skew, high skew), and missing data (none, 5%, 20%) for a range of sample sizes (40, 100, 10000), twenty-seven data sets with four variables (heart rate, weight, fitness level, and HRV) were simulated for the creation of synthetic datasets, which included outliers (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). For all datasets, HRV and fitness level were modelled to have a relationship that is typically associated with a medium effect size (<italic>r</italic> = 0.3).</p><p>The specific utility of synthetic datasets was examined by comparing the relationship between HRV and fitness in each synthetic dataset to its respective original dataset. None of the lack-of-fit tests were statistically significant (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>), suggesting that the method used for synthesis retained all the relationships between variables that influenced the parameters of the fit. A comparison of confidence intervals revealed strong overlap between the synthetic and original datasets for most (but not all) of the 27 analyses and none of the standardized coefficient differences between the synthesized and the observed datasets were statistically significant (all p’s &gt; 0.05; <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref>–<xref ref-type="fig" rid="fig3s2">2</xref>). However, the overlap between the synthetic and original models were on the border of statistical significance when synthesizing data with a low skew in the simulated samples with 10,000 cases (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). All 27 synthetic datasets also demonstrated good general utility, regardless of the parameters (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplements 3</xref>–<xref ref-type="fig" rid="fig3s5">5</xref>). Thus, synthetic dataset generation in <italic>synthpop</italic> seems to be relatively robust against differences in sample size, missingness, and skew in these simulated samples, however, there were indications of poorer performance in some of larger datasets with 10,000 (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Altogether, it is crucial that general and specific utility is assessed for each synthesised dataset, as it is difficult to predict <italic>before</italic> synthesis how well the procedure will perform.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Specific utility of synthetic data from a range of simulated datasets with 100 cases that model the relationship between Heart Rate Variability (HRV) and fitness.</title><p>Nine datasets with 100 cases were simulated, which varied on skewness for the HRV variable (none, low, high) and missingness for all variables (0%, 5%, 20%). The x-axes values represent Z-values for the HRV coefficient. The dark-blue triangles and confidence intervals represent the HRV estimates for the synthetic data and the light-blue circles and confidence intervals represent the HRV estimates for the observed data. In general, there was a high overlap between the synthetic and original estimates (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). The confidence interval range overlap between the synthetic and observed estimates from the dataset with normally distributed HRV and 5% missing data were 60.5%. While the standardized difference was not statistically significant (p=0.12), caution would be warranted in terms of specific utility in this case, given the relatively low confidence interval range overlap.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Specific utility of synthetic data from a range of simulated datasets with 40 cases that model the relationship between Heart Rate Variability (HRV) and fitness.</title><p>Nine datasets with 40 cases were simulated, which varied on skewness for the HRV variable (none, low, high) and missingness for all variables (0%, 5%, 20%). The x-axes represent Z-values for the HRV coefficient. The dark-blue triangles and confidence intervals represent the HRV estimates for the synthetic data and the light-blue circles and confidence intervals represent the HRV estimates for the observed data. There was high overlap between the synthetic and original estimates for the samples and the standardized differences between models derived from the synthetic and observed datasets were not statistically significant (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Thus, these synthetic datasets demonstrate good specific utility.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Specific utility of synthetic data from a range of simulated datasets with 10,000 cases that model the relationship between Heart Rate Variability (HRV) and fitness.</title><p>Nine datasets with 10,000 cases were simulated, which varied on skewness for the HRV variable (none, low, high) and missingness for all variables (0%, 5%, 20%). The x-axes represent Z-values for the HRV coefficient. The dark-blue triangles and confidence intervals represent the HRV estimates for the synthetic data and the light-blue circles and confidence intervals represent the HRV estimates for the observed data. There was high overlap between the synthetic and original estimates for the samples in which HRV was normally distributed (top row) and highly skewed (bottom row). For the datasets in which HRV had a low skew, the standardized differences between models derived from the synthetic and observed datasets were associated with p-values that can be considered on the border of statistical significance (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) and the confidence interval range overlap ranged from 53.5% to 28.9% (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Altogether, evidence for specific utility in these samples in which HRV had a low skew would not be considered to be strong.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>General utility of nine simulated datasets with 40 cases.</title><p>Datasets varied on the shape of the distribution of heart rate variability (HRV) and the percentage of missing data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>General utility of nine simulated datasets with 100 cases.</title><p>Datasets varied on the shape of the distribution of heart rate variability (HRV) and the percentage of missing data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>General utility of nine simulated datasets with 10,000 cases.</title><p>Datasets varied on the shape of the distribution of heart rate variability (HRV) and the percentage of missing data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53275-fig3-figsupp5-v2.tif"/></fig></fig-group></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Researchers need to consider the trade-off between the risk of identification and the utility of open datasets when deciding whether to make their research data openly available. Open data can provide substantial utility, but this may expose research participants to the risk of identification. Conversely, closed datasets decrease the risk of disclosure to essentially zero, but have almost no public utility. The generation of synthetic datasets provides an appealing compromise, as synthetic data can offer comparable levels of utility as the original datasets while substantially reducing disclosure risk. The adoption of synthetic datasets in the biobehavioural sciences will improve reproducibility and secondary data exploration, as it will facilitate the sharing of data that would otherwise not be made available.</p><p>Study participants are generally in favour of researchers sharing their deidentified data (<xref ref-type="bibr" rid="bib20">Ludman et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Mello et al., 2018</xref>). Thus, when planning future studies researchers should include data sharing provisions when receiving participant consent (<xref ref-type="bibr" rid="bib46">Taichman et al., 2016</xref>). Obtaining updated consent to share data from participants who have not provided this when originally participating in a study can be resource intensive. Some have suggested that sharing deidentified datafiles should not require new re-consent from participants (<xref ref-type="bibr" rid="bib47">Taichman et al., 2017</xref>), but as mentioned above, many commonly used data deidentification approaches may not sufficiently reduce disclosure risk (<xref ref-type="bibr" rid="bib28">Ohm, 2009</xref>; <xref ref-type="bibr" rid="bib39">Rocher et al., 2019</xref>). In some circumstances, datasets may include extremely sensitive information that is difficult to anonymise. For instance, <xref ref-type="bibr" rid="bib3">Arslan et al. (2018)</xref> collected highly sensitive data examining the role of ovulatory changes on sexual desire and behavior in women but did not request consent from participants to share data considering valid privacy concerns. Instead, a synthetic version of the dataset was created using <italic>synthpop</italic> and made available on a publicly accessible repository. Releasing this synthetic dataset provides considerable utility, as other researchers can verify the analysis and fit novel models using this dataset, which can be confirmed by the data custodians with the original data. An additional step of removing individuals that have been fully replicated in the synthesized data set can further reduce disclosure risk, without necessarily reducing general or specific utility. Therefore, synthetic data can offer a valuable solution for sharing data collected under conditions where participants did not specifically provide consent for sharing data (and where re-consent is impractical), as well as for situations in which a dataset contains especially sensitive information. In addition to the verification of results and hypothesis generation, synthetic datasets can also benefit the training of machine learning algorithms in research areas with a dearth of data, such as rare condition research (<xref ref-type="bibr" rid="bib12">Ekbatani et al., 2017</xref>; <xref ref-type="bibr" rid="bib42">Sabay et al., 2018</xref>), via the creation of additional synthetic datasets that closely match real datasets.</p><p>One criticism of sharing raw data is that research groups would not have the first opportunity to analyse the data and report outcomes to their satisfaction (<xref ref-type="bibr" rid="bib19">Lo, 2015</xref>; <xref ref-type="bibr" rid="bib40">Ross et al., 2012</xref>). It has been recommended that secondary data analysts should seek collaborations with teams that collected the original data in recognition of their investment in collecting the data (<xref ref-type="bibr" rid="bib46">Taichman et al., 2016</xref>), but this is difficult to enforce in practice. To make meaningful inferences with synthetic data, secondary data analysts need to verify their synthetic models against models from the original data, which is in the possession of the original authors who can verify these inferences (<xref ref-type="bibr" rid="bib37">Reiter et al., 2009</xref>). This would increase the likelihood of co-authored collaborations, at least compared to the status-quo in which secondary analysts could publish their results without necessarily collaborating with the original authors. Thus, open synthetic data provide an opportunity for secondary analysists scholars to fit models that the original authors may not have considered, while also encouraging them to collaborate with the original authors to verify their models in the real dataset. Of course, secondary analysts could still report results from synthetic datasets without verification from the primary authors, but it would need to be made explicit that analyses were conducted on a synthetic dataset, and generated models may not necessarily mirror the models generated from the original dataset.</p><p>Journals have adopted a spectrum of public data archiving (PDA) policies, ranging from the policies that data should be made “available upon request” all the way to mandated data deposition in peer-reviewed journals dedicated to open data (<xref ref-type="bibr" rid="bib43">Sholler et al., 2019</xref>). While an “available upon request” PDA policy is better than no policy at all (<xref ref-type="bibr" rid="bib45">Stodden et al., 2018</xref>), such datasets are often difficult to retrieve in practice as corresponding authors can become unreachable or original datasets are lost (<xref ref-type="bibr" rid="bib7">Couture et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Stodden et al., 2018</xref>; <xref ref-type="bibr" rid="bib49">Wicherts et al., 2006</xref>). Sharing data with published papers would remove these impediments for accessing data, with synthetic data offering a solution for when it is not possible to share the original dataset due to disclosure concerns.</p><p>Despite the benefits of synthetic datasets, this approach is not without limitations. First, it is possible for synthetic data to have poor general and specific utility, which would diminish the benefits of sharing in terms of reproducibility and secondary data exploration. While a synthetic dataset with poor utility would still provide a valuable guide for reproducing reported analyses, these are likely to provide substantially different estimates and exploratory analyses may not produce accurate models. Second, current synthetic data methods limit the types of statistical inference that can be performed on synthetic data to linear models. In practice, this means that only linear models can be for comparison in order to demonstrate specific utility. Of course, scholars are free to perform any type of analysis on the synthetic data, which should provide approximately the same outcome as the original data as long as the synthetic data offer good general utility. Third, as mentioned above, the risk of identity disclosure from synthetic datasets is negligible but this only holds under two conditions: that none of the complete synthetic data records match with the original data and that there are no extreme single individual values in the dataset that can be linked to an individual (<xref ref-type="bibr" rid="bib9">Drechsler, 2011</xref>; <xref ref-type="bibr" rid="bib11">Duncan and Elliot, 2011</xref>). Therefore, to reduce disclosure risk and the possibility that participants will recognise themselves in the dataset, complete matching records (i.e., when all variables in the original dataset for a case matches a case in the synthetic dataset) should be identified and removed. Additionally, in the case of categorical variables with only a few observations, scholars should consider collapsing these into another category (e.g., if there are only a few observations in an age band of 70–79 years old, this can be collapsed into the previous age band of 60–69 years old). If there are uncommon continuous values above or below a certain threshold, it may be prudent to collapse these into another category or creating a new category (e.g., top-coding a new ‘70+’ age variable for any age equal to or above 70). While recoding may lead to synthetic datasets with less utility, this approach might be required to reduce disclosure risk, something that data synthesizers will have to carefully consider in light of the sensitivity of the dataset along with national laws and guidelines.</p><p>When the creation of synthetic datasets for disclosure control was first proposed in the early 1990s, it was considered “rather radical” at the time (pg. 461; <xref ref-type="bibr" rid="bib41">Rubin, 1993</xref>). Researchers have continued improving this method since these initial proposals (<xref ref-type="bibr" rid="bib36">Reiter, 2005b</xref>; <xref ref-type="bibr" rid="bib35">Reiter, 2005a</xref>; <xref ref-type="bibr" rid="bib38">Reiter and Raghunathan, 2007</xref>), but only more recently has an easy-to-implement tool for creating synthetic data become available. The <italic>synthpop</italic> R package enables researchers to generate and share synthetic datasets that mimic original datasets with sensitive information. Importantly, the use synthetic data will improve the reproducibility of biobehavioral research and help generate novel hypotheses for future research (<xref ref-type="bibr" rid="bib6">Bonnéry et al., 2019</xref>).</p></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This research was supported by an Excellence Grant from the Novo Nordisk Foundation to DSQ (NNF16OC0019856). The author would like to thank Steve Haroz, who provided helpful feedback on an earlier version of this manuscript.</p></ack><sec id="s4" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology</p></fn></fn-group></sec><sec id="s5" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Specific utility of simulated datasets.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-53275-supp1-v2.xlsx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-53275-transrepform-v2.docx"/></supplementary-material></sec><sec id="s6" sec-type="data-availability"><title>Data availability</title><p>Data and analysis scripts are available at the article's Open Science Framework webpage <ext-link ext-link-type="uri" xlink:href="https://osf.io/z524n/">https://osf.io/z524n/</ext-link>.</p><p>The following previously published datasets were used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Van</surname><given-names>Cappellen P</given-names></name><name><surname>Way</surname><given-names>BM</given-names></name><name><surname>Isgett</surname><given-names>SF</given-names></name><name><surname>Fredrickson</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Effects of oxytocin administration on spirituality and emotional responses to meditation</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="archive" xlink:href="https://osf.io/rk2x7/">https://osf.io/rk2x7/</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>BC</given-names></name><name><surname>DeBruine</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Sociosexuality and self-rated attractiveness</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="archive" xlink:href="https://osf.io/6bk3w/">DOI: 10.17605/OSF.IO/6BK3W</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akselrod</surname> <given-names>S</given-names></name><name><surname>Gordon</surname> <given-names>D</given-names></name><name><surname>Ubel</surname> <given-names>FA</given-names></name><name><surname>Shannon</surname> <given-names>DC</given-names></name><name><surname>Berger</surname> <given-names>AC</given-names></name><name><surname>Cohen</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Power spectrum analysis of heart rate fluctuation: a quantitative probe of beat-to-beat cardiovascular control</article-title><source>Science</source><volume>213</volume><fpage>220</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1126/science.6166045</pub-id><pub-id pub-id-type="pmid">6166045</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anscombe</surname> <given-names>FJ</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Graphs in statistical analysis</article-title><source>The American Statistician</source><volume>27</volume><fpage>17</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1080/00031305.1973.10478966</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arslan</surname> <given-names>RC</given-names></name><name><surname>Schilling</surname> <given-names>KM</given-names></name><name><surname>Gerlach</surname> <given-names>TM</given-names></name><name><surname>Penke</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Using 26,000 diary entries to show ovulatory changes in sexual desire and behavior</article-title><source>Journal of Personality and Social Psychology</source><volume>26</volume><elocation-id>208</elocation-id><pub-id pub-id-type="doi">10.1037/pspp0000208</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arzberger</surname> <given-names>P</given-names></name><name><surname>Schroeder</surname> <given-names>P</given-names></name><name><surname>Beaulieu</surname> <given-names>A</given-names></name><name><surname>Bowker</surname> <given-names>G</given-names></name><name><surname>Casey</surname> <given-names>K</given-names></name><name><surname>Laaksonen</surname> <given-names>L</given-names></name><name><surname>Moorman</surname> <given-names>D</given-names></name><name><surname>Uhlir</surname> <given-names>P</given-names></name><name><surname>Wouters</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Promoting access to public research data for scientific, economic, and social development</article-title><source>Data Science Journal</source><volume>3</volume><fpage>135</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.2481/dsj.3.135</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asendorpf</surname> <given-names>JB</given-names></name><name><surname>Conner</surname> <given-names>M</given-names></name><name><surname>De Fruyt</surname> <given-names>F</given-names></name><name><surname>De Houwer</surname> <given-names>J</given-names></name><name><surname>Denissen</surname> <given-names>JJA</given-names></name><name><surname>Fiedler</surname> <given-names>K</given-names></name><name><surname>Fiedler</surname> <given-names>S</given-names></name><name><surname>Funder</surname> <given-names>DC</given-names></name><name><surname>Kliegl</surname> <given-names>R</given-names></name><name><surname>Nosek</surname> <given-names>BA</given-names></name><name><surname>Perugini</surname> <given-names>M</given-names></name><name><surname>Roberts</surname> <given-names>BW</given-names></name><name><surname>Schmitt</surname> <given-names>M</given-names></name><name><surname>van Aken</surname> <given-names>MAG</given-names></name><name><surname>Weber</surname> <given-names>H</given-names></name><name><surname>Wicherts</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Recommendations for increasing replicability in psychology</article-title><source>European Journal of Personality</source><volume>27</volume><fpage>108</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1002/per.1919</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnéry</surname> <given-names>D</given-names></name><name><surname>Feng</surname> <given-names>Y</given-names></name><name><surname>Henneberger</surname> <given-names>AK</given-names></name><name><surname>Johnson</surname> <given-names>TL</given-names></name><name><surname>Lachowicz</surname> <given-names>M</given-names></name><name><surname>Rose</surname> <given-names>BA</given-names></name><name><surname>Shaw</surname> <given-names>T</given-names></name><name><surname>Stapleton</surname> <given-names>LM</given-names></name><name><surname>Woolley</surname> <given-names>ME</given-names></name><name><surname>Zheng</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The promise and limitations of synthetic data as a strategy to expand access to State-Level Multi-Agency longitudinal data</article-title><source>Journal of Research on Educational Effectiveness</source><volume>12</volume><fpage>616</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1080/19345747.2019.1631421</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Couture</surname> <given-names>JL</given-names></name><name><surname>Blake</surname> <given-names>RE</given-names></name><name><surname>McDonald</surname> <given-names>G</given-names></name><name><surname>Ward</surname> <given-names>CL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A funder-imposed data publication requirement seldom inspired data sharing</article-title><source>PLOS ONE</source><volume>13</volume><elocation-id>e0199789</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0199789</pub-id><pub-id pub-id-type="pmid">29979709</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dixon</surname> <given-names>EM</given-names></name><name><surname>Kamath</surname> <given-names>MV</given-names></name><name><surname>McCartney</surname> <given-names>N</given-names></name><name><surname>Fallen</surname> <given-names>EL</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Neural regulation of heart rate variability in endurance Athletes and sedentary controls</article-title><source>Cardiovascular Research</source><volume>26</volume><fpage>713</fpage><lpage>719</lpage><pub-id pub-id-type="doi">10.1093/cvr/26.7.713</pub-id><pub-id pub-id-type="pmid">1423437</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Drechsler</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>Synthetic Datasets for Statistical Disclosure Control: Theory and Implementation</source><publisher-name>Springer-Verlag</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4614-0326-5</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drechsler</surname> <given-names>J</given-names></name><name><surname>Reiter</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>An empirical evaluation of easily implemented, nonparametric methods for generating synthetic datasets</article-title><source>Computational Statistics &amp; Data Analysis</source><volume>55</volume><fpage>3232</fpage><lpage>3243</lpage><pub-id pub-id-type="doi">10.1016/j.csda.2011.06.006</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Duncan</surname> <given-names>GT</given-names></name><name><surname>Elliot</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>Statistical Confidentiality: Principles and Practice</source><publisher-name>Springer-Verlag</publisher-name><pub-id pub-id-type="doi">10.1007/978-1-4419-7802-8</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ekbatani</surname> <given-names>HK</given-names></name><name><surname>Pujol</surname> <given-names>O</given-names></name><name><surname>Segui</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Synthetic data generation for deep learning in counting pedestrians</article-title><conf-name>Proceedings of the 6th International Conference on Pattern Recognition Applications and Methods - Volume 1: ICPRAM</conf-name><fpage>318</fpage><lpage>323</lpage><pub-id pub-id-type="doi">10.5220/0006119203180323</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelman</surname> <given-names>A</given-names></name><name><surname>Stern</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The difference between “Significant” and “Not Significant” is not Itself Statistically Significant</article-title><source>The American Statistician</source><volume>60</volume><fpage>328</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1198/000313006X152649</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hrynaszkiewicz</surname> <given-names>I</given-names></name><name><surname>Norton</surname> <given-names>ML</given-names></name><name><surname>Vickers</surname> <given-names>AJ</given-names></name><name><surname>Altman</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Preparing raw clinical data for publication: guidance for journal editors, authors, and peer reviewers</article-title><source>Trials</source><volume>11</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1186/1745-6215-11-9</pub-id><pub-id pub-id-type="pmid">20113465</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="data"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>BC</given-names></name><name><surname>DeBruine</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Sociosexuality and self-rated attractiveness</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="doi">10.17605/OSF.IO/6BK3W</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karr</surname> <given-names>AF</given-names></name><name><surname>Kohnen</surname> <given-names>CN</given-names></name><name><surname>Oganian</surname> <given-names>A</given-names></name><name><surname>Reiter</surname> <given-names>JP</given-names></name><name><surname>Sanil</surname> <given-names>AP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A framework for evaluating the utility of data altered to protect confidentiality</article-title><source>The American Statistician</source><volume>60</volume><fpage>224</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1198/000313006X124640</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobayashi</surname> <given-names>H</given-names></name><name><surname>Park</surname> <given-names>BJ</given-names></name><name><surname>Miyazaki</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Normative references of heart rate variability and salivary alpha-amylase in a healthy young male population</article-title><source>Journal of Physiological Anthropology</source><volume>31</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1186/1880-6805-31-9</pub-id><pub-id pub-id-type="pmid">22738348</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Little</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Statistical analysis of masked data</article-title><source>Journal of Official Statistics</source><volume>9</volume><elocation-id>407</elocation-id><pub-id pub-id-type="doi">10.1016/S0169-7161(01)20020-0</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lo</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sharing clinical trial data: maximizing benefits, minimizing risk</article-title><source>Jama</source><volume>313</volume><fpage>793</fpage><lpage>794</lpage><pub-id pub-id-type="doi">10.1001/jama.2015.292</pub-id><pub-id pub-id-type="pmid">25594500</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludman</surname> <given-names>EJ</given-names></name><name><surname>Fullerton</surname> <given-names>SM</given-names></name><name><surname>Spangler</surname> <given-names>L</given-names></name><name><surname>Trinidad</surname> <given-names>SB</given-names></name><name><surname>Fujii</surname> <given-names>MM</given-names></name><name><surname>Jarvik</surname> <given-names>GP</given-names></name><name><surname>Larson</surname> <given-names>EB</given-names></name><name><surname>Burke</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Glad you asked: participants' opinions of re-consent for dbGap data submission</article-title><source>Journal of Empirical Research on Human Research Ethics</source><volume>5</volume><fpage>9</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1525/jer.2010.5.3.9</pub-id><pub-id pub-id-type="pmid">20831417</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mello</surname> <given-names>MM</given-names></name><name><surname>Lieou</surname> <given-names>V</given-names></name><name><surname>Goodman</surname> <given-names>SN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Clinical trial participants' Views of the risks and benefits of data sharing</article-title><source>New England Journal of Medicine</source><volume>378</volume><fpage>2202</fpage><lpage>2211</lpage><pub-id pub-id-type="doi">10.1056/NEJMsa1713258</pub-id><pub-id pub-id-type="pmid">29874542</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Munafò</surname> <given-names>MR</given-names></name><name><surname>Nosek</surname> <given-names>BA</given-names></name><name><surname>Bishop</surname> <given-names>DVM</given-names></name><name><surname>Button</surname> <given-names>KS</given-names></name><name><surname>Chambers</surname> <given-names>CD</given-names></name><name><surname>Percie du Sert</surname> <given-names>N</given-names></name><name><surname>Simonsohn</surname> <given-names>U</given-names></name><name><surname>Wagenmakers</surname> <given-names>E-J</given-names></name><name><surname>Ware</surname> <given-names>JJ</given-names></name><name><surname>Ioannidis</surname> <given-names>JPA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A manifesto for reproducible science</article-title><source>Nature Human Behaviour</source><volume>1</volume><elocation-id>0021</elocation-id><pub-id pub-id-type="doi">10.1038/s41562-016-0021</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murdoch</surname> <given-names>TB</given-names></name><name><surname>Detsky</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The inevitable application of big data to health care</article-title><source>Jama</source><volume>309</volume><fpage>1351</fpage><lpage>1352</lpage><pub-id pub-id-type="doi">10.1001/jama.2013.393</pub-id><pub-id pub-id-type="pmid">23549579</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newbury</surname> <given-names>DF</given-names></name><name><surname>Simpson</surname> <given-names>NH</given-names></name><name><surname>Thompson</surname> <given-names>PA</given-names></name><name><surname>Bishop</surname> <given-names>DVM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Stage 2 registered report: variation in neurodevelopmental outcomes in children with sex chromosome trisomies: testing the double hit hypothesis</article-title><source>Wellcome Open Research</source><volume>3</volume><elocation-id>85</elocation-id><pub-id pub-id-type="doi">10.12688/wellcomeopenres.14677.1</pub-id><pub-id pub-id-type="pmid">30271887</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nosek</surname> <given-names>BA</given-names></name><name><surname>Spies</surname> <given-names>JR</given-names></name><name><surname>Motyl</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Scientific utopia: ii. restructuring incentives and practices to promote truth over publishability</article-title><source>Perspectives on Psychological Science : A Journal of the Association for Psychological Science</source><volume>7</volume><fpage>615</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1177/1745691612459058</pub-id><pub-id pub-id-type="pmid">26168121</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nowok</surname> <given-names>B</given-names></name><name><surname>Raab</surname> <given-names>GM</given-names></name><name><surname>Dibben</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Synthpop : bespoke creation of synthetic data in <italic>R</italic></article-title><source>Journal of Statistical Software</source><volume>74</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.18637/jss.v074.i11.</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nowok</surname> <given-names>B</given-names></name><name><surname>Raab</surname> <given-names>GM</given-names></name><name><surname>Dibben</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Providing bespoke synthetic data for the UK longitudinal studies and other sensitive data with the synthpop package for R1</article-title><source>Statistical Journal of the IAOS</source><volume>33</volume><fpage>785</fpage><lpage>796</lpage><pub-id pub-id-type="doi">10.3233/SJI-150153</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohm</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Broken promises of privacy: responding to the surprising failure of anonymization</article-title><source>UCLA Law Review</source><volume>57</volume><fpage>1701</fpage></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Penke</surname> <given-names>L</given-names></name><name><surname>Asendorpf</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Beyond global sociosexual orientations: a more differentiated look at Sociosexuality and its effects on courtship and romantic relationships</article-title><source>Journal of Personality and Social Psychology</source><volume>95</volume><fpage>1113</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.95.5.1113</pub-id><pub-id pub-id-type="pmid">18954197</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piwowar</surname> <given-names>HA</given-names></name><name><surname>Vision</surname> <given-names>TJ</given-names></name><name><surname>Whitlock</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Data archiving is a good investment</article-title><source>Nature</source><volume>473</volume><elocation-id>285</elocation-id><pub-id pub-id-type="doi">10.1038/473285a</pub-id><pub-id pub-id-type="pmid">21593852</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purdam</surname> <given-names>K</given-names></name><name><surname>Elliot</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A case study of the impact of statistical disclosure control on data quality in the individual UK samples of anonymised records</article-title><source>Environment and Planning A: Economy and Space</source><volume>39</volume><fpage>1101</fpage><lpage>1118</lpage><pub-id pub-id-type="doi">10.1068/a38335</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Quintana</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>A primer on using the synthpop package for the biobehavioral sciences: An executable R script (Version 1.1.0) [Computer software]</data-title><ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5281/zenodo.3404199">http://doi.org/10.5281/zenodo.3404199</ext-link></element-citation></ref><ref id="bib33"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Raab</surname> <given-names>GM</given-names></name><name><surname>Nowok</surname> <given-names>B</given-names></name><name><surname>Dibben</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Guidelines for producing useful synthetic data</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1712.04078">https://arxiv.org/abs/1712.04078</ext-link></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raghunathan</surname> <given-names>TE</given-names></name><name><surname>Reiter</surname> <given-names>JP</given-names></name><name><surname>Rubin</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Multiple imputation for statistical disclosure limitation</article-title><source>Journal of Official Statistics</source><volume>19</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.1002/sim.3974</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reiter</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2005">2005a</year><article-title>Releasing multiply imputed, synthetic public use microdata: an illustration and empirical study</article-title><source>Journal of the Royal Statistical Society: Series A</source><volume>168</volume><fpage>185</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1111/j.1467-985X.2004.00343.x</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reiter</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2005">2005b</year><article-title>Using CART to generate partially synthetic public use microdata</article-title><source>Journal of Official Statistics</source><volume>21</volume><elocation-id>441</elocation-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reiter</surname> <given-names>JP</given-names></name><name><surname>Oganian</surname> <given-names>A</given-names></name><name><surname>Karr</surname> <given-names>AF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Verification servers: Enabling analysts to assess the quality of inferences from public use data</article-title><source>Computational Statistics &amp; Data Analysis</source><volume>53</volume><fpage>1475</fpage><lpage>1482</lpage><pub-id pub-id-type="doi">10.1016/j.csda.2008.10.006</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reiter</surname> <given-names>JP</given-names></name><name><surname>Raghunathan</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The multiple adaptations of multiple imputation</article-title><source>Journal of the American Statistical Association</source><volume>102</volume><fpage>1462</fpage><lpage>1471</lpage><pub-id pub-id-type="doi">10.1198/016214507000000932</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rocher</surname> <given-names>L</given-names></name><name><surname>Hendrickx</surname> <given-names>JM</given-names></name><name><surname>de Montjoye</surname> <given-names>YA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Estimating the success of re-identifications in incomplete datasets using generative models</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>3069</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10933-3</pub-id><pub-id pub-id-type="pmid">31337762</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname> <given-names>JS</given-names></name><name><surname>Lehman</surname> <given-names>R</given-names></name><name><surname>Gross</surname> <given-names>CP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The importance of clinical trial data sharing</article-title><source>Circulation: Cardiovascular Quality and Outcomes</source><volume>5</volume><fpage>238</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1161/CIRCOUTCOMES.112.965798</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Statistical disclosure limitation</article-title><source>Journal of Official Statistics</source><volume>9</volume><fpage>461</fpage><lpage>468</lpage></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabay</surname> <given-names>A</given-names></name><name><surname>Harris</surname> <given-names>L</given-names></name><name><surname>Bejugama</surname> <given-names>V</given-names></name><name><surname>Jaceldo-Siegl</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Overcoming small data limitations in heart disease prediction by using surrogate data</article-title><source>SMU Data Science Review</source><volume>1</volume><elocation-id>12</elocation-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sholler</surname> <given-names>D</given-names></name><name><surname>Ram</surname> <given-names>K</given-names></name><name><surname>Boettiger</surname> <given-names>C</given-names></name><name><surname>Katz</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Enforcing public data archiving policies in academic publishing: a study of ecology journals</article-title><source>Big Data &amp; Society</source><volume>6</volume><elocation-id>205395171983625</elocation-id><pub-id pub-id-type="doi">10.1177/2053951719836258</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snoke</surname> <given-names>J</given-names></name><name><surname>Raab</surname> <given-names>GM</given-names></name><name><surname>Nowok</surname> <given-names>B</given-names></name><name><surname>Dibben</surname> <given-names>C</given-names></name><name><surname>Slavkovic</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>General and specific utility measures for synthetic data</article-title><source>Journal of the Royal Statistical Society: Series A</source><volume>181</volume><fpage>663</fpage><lpage>688</lpage><pub-id pub-id-type="doi">10.1111/rssa.12358</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stodden</surname> <given-names>V</given-names></name><name><surname>Seiler</surname> <given-names>J</given-names></name><name><surname>Ma</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>An empirical analysis of journal policy effectiveness for computational reproducibility</article-title><source>PNAS</source><volume>115</volume><fpage>2584</fpage><lpage>2589</lpage><pub-id pub-id-type="doi">10.1073/pnas.1708290115</pub-id><pub-id pub-id-type="pmid">29531050</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taichman</surname> <given-names>DB</given-names></name><name><surname>Backus</surname> <given-names>J</given-names></name><name><surname>Baethge</surname> <given-names>C</given-names></name><name><surname>Bauchner</surname> <given-names>H</given-names></name><name><surname>de Leeuw</surname> <given-names>PW</given-names></name><name><surname>Drazen</surname> <given-names>JM</given-names></name><name><surname>Fletcher</surname> <given-names>J</given-names></name><name><surname>Frizelle</surname> <given-names>FA</given-names></name><name><surname>Groves</surname> <given-names>T</given-names></name><name><surname>Haileamlak</surname> <given-names>A</given-names></name><name><surname>James</surname> <given-names>A</given-names></name><name><surname>Laine</surname> <given-names>C</given-names></name><name><surname>Peiperl</surname> <given-names>L</given-names></name><name><surname>Pinborg</surname> <given-names>A</given-names></name><name><surname>Sahni</surname> <given-names>P</given-names></name><name><surname>Wu</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sharing clinical trial data: a proposal from the international committee of medical journal editors</article-title><source>Annals of Internal Medicine</source><volume>164</volume><elocation-id>505</elocation-id><pub-id pub-id-type="doi">10.7326/M15-2928</pub-id><pub-id pub-id-type="pmid">26792258</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taichman</surname> <given-names>DB</given-names></name><name><surname>Sahni</surname> <given-names>P</given-names></name><name><surname>Pinborg</surname> <given-names>A</given-names></name><name><surname>Peiperl</surname> <given-names>L</given-names></name><name><surname>Laine</surname> <given-names>C</given-names></name><name><surname>James</surname> <given-names>A</given-names></name><name><surname>Hong</surname> <given-names>ST</given-names></name><name><surname>Haileamlak</surname> <given-names>A</given-names></name><name><surname>Gollogly</surname> <given-names>L</given-names></name><name><surname>Godlee</surname> <given-names>F</given-names></name><name><surname>Frizelle</surname> <given-names>FA</given-names></name><name><surname>Florenzano</surname> <given-names>F</given-names></name><name><surname>Drazen</surname> <given-names>JM</given-names></name><name><surname>Bauchner</surname> <given-names>H</given-names></name><name><surname>Baethge</surname> <given-names>C</given-names></name><name><surname>Backus</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Data sharing statements for clinical trials: a requirement of the international committee of medical journal editors</article-title><source>Jama</source><volume>317</volume><fpage>2491</fpage><lpage>2492</lpage><pub-id pub-id-type="doi">10.1001/jama.2017.6514</pub-id><pub-id pub-id-type="pmid">28586895</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Cappellen</surname> <given-names>P</given-names></name><name><surname>Way</surname> <given-names>BM</given-names></name><name><surname>Isgett</surname> <given-names>SF</given-names></name><name><surname>Fredrickson</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Effects of oxytocin administration on spirituality and emotional responses to meditation</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>11</volume><fpage>1579</fpage><lpage>1587</lpage><pub-id pub-id-type="doi">10.1093/scan/nsw078</pub-id><pub-id pub-id-type="pmid">27317929</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wicherts</surname> <given-names>JM</given-names></name><name><surname>Borsboom</surname> <given-names>D</given-names></name><name><surname>Kats</surname> <given-names>J</given-names></name><name><surname>Molenaar</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The poor availability of psychological research data for reanalysis</article-title><source>American Psychologist</source><volume>61</volume><fpage>726</fpage><lpage>728</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.61.7.726</pub-id><pub-id pub-id-type="pmid">17032082</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.53275.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Zaidi</surname><given-names>Mone</given-names></name><role>Reviewing Editor</role><aff><institution>Icahn School of Medicine at Mount Sinai</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Bishop</surname><given-names>Dorothy V M</given-names></name><role>Reviewer</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>We feel that the study is important as it touches on an emerging area of data sharing, provenance and reproducibility – a nascent movement towards achieving rigor and transparency that is being adopted by funding agencies, journal editors and industry alike. Applying the concept of synthetic datasets, in this case using SynthpopR, is seen as innovative and applicable to a wide range of investigations, importantly to those where full data and identity disclosure are not possible. The tool is likely to be utilized widely in translational and clinical research.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Synthetic datasets: A primer for the biobehavioural sciences to promote reproducibility and hypothesis-generation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by Christian Büchel as the Senior Editor, Mone Zaidi as the Reviewing Editor, and two reviewers. The following individual involved in review of your submission has agreed to reveal their identity: Dorothy VM Bishop (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>Creation of synthetic datasets has been adopted in some areas of social science where large survey datasets are used, and where full anonymisation is difficult or impossible. Here, the author demonstrates the usefulness of the synthpop R package for generating synthetic data in a different field, where datasets are typically smaller and simpler.</p><p>While the paper does not add new empirical observations or analysis approaches, it is, as its title indicates, a primer for others who might wish to try this approach. It highlights the benefits of synthetic datasets as compared to open research data. Importantly, the use of synthetic datasets shows reliable general utility in terms of data reproducibility of original findings. As long as the risk of identity disclosure is eliminated, synthetic datasets can and should be employed given the reproducibility of scientific data in biomedical sciences is a growing issue. The inclusion of oxytocin data re-analyzed in the synthetic datasets is a strength. The data are strong and well presented. The manuscript is clearly written for the most part and delivers a straightforward message that would be useful to a general readership. Nonetheless several areas need improvement and further analysis.</p><p>Essential revisions:</p><p>1) It would be preferable to have more diversity in the illustrative datasets – perhaps even demonstrating a case when synthpop does not perform as well. In particular, questions were raised regarding data with unusual distributions, evident outliers, or a hierarchical structure, for example, those with a code for family, and then family members.</p><p>2) There is mention in the Discussion section about cases where the synthetic dataset has poor utility. Perhaps, this cannot be predicted in advance, but it would be interesting to test this with datasets that may have the kinds of characteristics that are noted in point 1 (above). Indeed, this would all get rather meta, but one could simulate data that has specific features, such as striking outliers or non-normal distributions, to determine how far synthpop could retain its utility in such situations. Maybe this would be a better use of the second demonstration (see point 3). Would it be possible to take the original dataset and throw in some outliers or transform distributions to push synthpop to determine how well it stands up to non-normal data and the likes.</p><p>3) The three illustrative cases seem repetitive. Examples 1 and 3 show how the package worked with relatively large and small datasets, respectively, but example 2 seemed unnecessary. It is suggested that this part of an online appendix or is utilized it as noted in point 2 (above).</p><p>4) There is the issue about discarding data points that happen to replicate a real individual by chance. It is mentioned in the Introduction, again in Results section and in the Discussion section. A reviewer isn't sure about the logic of removing these. How would the individual – or anyone else – know this was their data? There is a problem with de-identification in a real dataset. For example, one knows that someone is a 55-year-old, left-handed woman, and there is only one of those in the sample. But if one knows that a dataset is synthesized, one could not be confident that the remainder of the data in that row came from this person.</p><p>5) It would be critical to model missing data. This might have an impact on fidelity of the synthetic data.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.53275.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) It would be preferable to have more diversity in the illustrative datasets – perhaps even demonstrating a case when synthpop does not perform as well. In particular, questions were raised regarding data with unusual distributions, evident outliers, or a hierarchical structure, for example, those with a code for family, and then family members.</p></disp-quote><p>To increase diversity of the illustrative datasets, I have now removed one of the datasets (example 2) and included a series of simulated datasets instead (subsection “Example 2: Sociosexual orientation and self-rated attractiveness”). There are several approaches for how to simulate data to demonstrate synthpop’s robustness (or where it performs suboptimally). To best represent common characteristics of unusual datasets, I have simulated datasets that differ in sample size, skew, and the percentage of missing data. Outliers are also included among the simulated datasets.</p><p>These simulated datasets are modelled off common cardiovascular and demographic variables (heart rate variability, heart rate, fitness level, weight). In total, 3 groups (n = 40, n = 100, n = 10,000) of datasets have been simulated, and each group contains 9 datasets with the following characteristics:</p><p>Normal distribution and no missing data</p><p>Normal distribution and 5% missing data</p><p>Normal distribution and 20% missing data</p><p>Low skew and no missing data</p><p>Low skew and 5% missing data</p><p>Low skew and no missing data</p><p>High skew and no missing data</p><p>High skew and 5% missing data</p><p>High skew and no missing data</p><p>Thus, a total of 27 datasets are presented in the new illustrative example.</p><disp-quote content-type="editor-comment"><p>2) There is mention in the Discussion section about cases where the synthetic dataset has poor utility. Perhaps, this cannot be predicted in advance, but it would be interesting to test this with datasets that may have the kinds of characteristics that are noted in point 1 (above). Indeed, this would all get rather meta, but one could simulate data that has specific features, such as striking outliers or non-normal distributions, to determine how far synthpop could retain its utility in such situations. Maybe this would be a better use of the second demonstration (see point 3). Would it be possible to take the original dataset and throw in some outliers or transform distributions to push synthpop to determine how well it stands up to non-normal data and the likes.</p></disp-quote><p>As mentioned above I have created a new illustrative example with 27 simulated datasets. Instead of transforming the original dataset, I created a set of simulated datasets from scratch for more fine-grained control of the parameters. For each dataset, I present general and specific utility diagnostics. These simulations demonstrate that synthpop is remarkably robust in most cases to non-normal data and missing data, at least for these examples. However, the utility of simulated datasets is suboptimal for some of the samples. For example, the model generated for the synthetic version of the dataset with 100 cases, HRV data with a low skew, and 5% missing data overall only had a 60.5% confidence interval overlap with the model generated from the observed data. While the standardized difference between these two estimates was not significantly different, one should not place too much confidence in the synthetic model given the relatively modest confidence interval overlap, as this is indicative of weak specific utility. As suggested by the reviewer, it is difficult to predict which datasets will perform poorly a priori based on the dataset characteristics alone. Thus, it is crucial that each generated synthetic dataset is checked for general and specific utility.</p><disp-quote content-type="editor-comment"><p>3) The three illustrative cases seem repetitive. Examples 1 and 3 show how the package worked with relatively large and small datasets, respectively, but example 2 seemed unnecessary. It is suggested that this part of an online appendix or is utilized it as noted in point 2 (above).</p></disp-quote><p>As mentioned above, this example has been replaced by a set of simulated datasets.</p><disp-quote content-type="editor-comment"><p>4) There is the issue about discarding data points that happen to replicate a real individual by chance. It is mentioned in the Introduction, again in Results section and in the Discussion section. A reviewer isn't sure about the logic of removing these. How would the individual – or anyone else – know this was their data? There is a problem with de-identification in a real dataset. For example, one knows that someone is a 55-year-old, left-handed woman, and there is only one of those in the sample. But if one knows that a dataset is synthesized, one could not be confident that the remainder of the data in that row came from this person.</p></disp-quote><p>To clarify, my intention was to highlight the potential issue of the replication of cases in which all variables (rather than some variables) happen to replicate a real case. I have now made this clearer in the manuscript, as follows:</p><p>In the Introduction:</p><p>“Synthetic datasets also reduce disclosure risk to essentially zero, as no complete casewise record in the new dataset represents a real individual (Duncan et al., 2011).”</p><p>And in the Discussion section:</p><p>“Therefore, to reduce disclosure risk and the possibility that participants will recognise themselves in the dataset, complete matching records (i.e., when all variables in the original dataset for a case matches a case in the synthetic dataset) should be identified and removed”</p><disp-quote content-type="editor-comment"><p>5) It would be critical to model missing data. This might have an impact on fidelity of the synthetic data.</p></disp-quote><p>As mentioned above, I have now modelled the effects of missing data on the creation of synthetic datasets. The degree of missingness (none, 5%, or 20%) seems to make little systematic difference in terms of general or specific utility.</p></body></sub-article></article>