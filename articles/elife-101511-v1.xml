<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">101511</article-id><article-id pub-id-type="doi">10.7554/eLife.101511</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.101511.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Non-feature-specific elevated responses and feature-specific backward replay in human brain induced by visual sequence exposure</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>He</surname><given-names>Tao</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1009-0500</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Gong</surname><given-names>Xizi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0005-6263-0774</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Qian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2347-8798</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Zhu</surname><given-names>Xinyi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7722-5150</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Yunzhe</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0836-9403</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Fang</surname><given-names>Fang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7718-2354</contrib-id><email>ffang@pku.edu.cn</email><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03te2zs36</institution-id><institution>Center for the Cognitive Science of Language, Beijing Language and Culture University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03te2zs36</institution-id><institution>Key Laboratory of Language Cognitive Science (Ministry of Education), Beijing Language and Culture University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>School of Psychological and Cognitive Sciences and Beijing Key Laboratory of Behavior and Mental Health, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>IDG/McGovern Institute for Brain Research, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/029819q61</institution-id><institution>Chinese Institute for Brain Research</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking-Tsinghua Center for Life Sciences, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Key Laboratory of Machine Perception (Ministry of Education), Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kok</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>The University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>08</day><month>05</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP101511</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-07-26"><day>26</day><month>07</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-08-08"><day>08</day><month>08</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.09.07.556631"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-10-11"><day>11</day><month>10</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.101511.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-03-25"><day>25</day><month>03</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.101511.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-04-24"><day>24</day><month>04</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.101511.3"/></event></pub-history><permissions><copyright-statement>© 2024, He et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>He et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-101511-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-101511-figures-v1.pdf"/><abstract><p>The ability of cortical circuits to adapt in response to experience is a fundamental property of the brain. After exposure to a moving dot sequence, flashing a dot as a cue at the starting point of the sequence can elicit successive elevated responses even in the absence of the sequence. These cue-triggered elevated responses have been shown to play a crucial role in predicting future events in dynamic environments. However, temporal sequences we are exposed to typically contain rich feature information. It remains unknown whether the elevated responses are feature-specific and, more crucially, how the brain organizes sequence information after exposure. To address these questions, participants were exposed to a predefined sequence of four motion directions for about 30 min, followed by the presentation of the start or end motion direction of the sequence as a cue. Surprisingly, we found that cue-triggered elevated responses were not specific to any motion direction. Interestingly, motion direction information was spontaneously reactivated, and the motion sequence was backward replayed in a time-compressed manner. These effects were observed even after brief exposure. Notably, no replay events were observed when the second or third motion direction of the sequence served as a cue. Further analyses revealed that activity in the medial temporal lobe (MTL) preceded the ripple power increase in visual cortex at the onset of replay, implying a coordinated relationship between the activities in the MTL and visual cortex. Together, these findings demonstrate that visual sequence exposure induces twofold brain plasticity that may simultaneously serve for different functional purposes. The non-feature-specific elevated responses may facilitate general processing of upcoming stimuli, whereas the feature-specific backward replay may underpin passive learning of visual sequences.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>visual cortex</kwd><kwd>sequence exposure</kwd><kwd>magnetic field</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>National Science and Technology Innovation 2030 Major Project</institution></institution-wrap></funding-source><award-id>2022ZD0204802</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Fang</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>T2421004</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Fang</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004826</institution-id><institution>Beijing Natural Science Foundation</institution></institution-wrap></funding-source><award-id>5244044</award-id><principal-award-recipient><name><surname>He</surname><given-names>Tao</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100013139</institution-id><institution>Humanities and Social Science Foundation of Ministry of Education of China</institution></institution-wrap></funding-source><award-id>23YJCZH071</award-id><principal-award-recipient><name><surname>He</surname><given-names>Tao</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32400874</award-id><principal-award-recipient><name><surname>He</surname><given-names>Tao</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31930053</award-id><principal-award-recipient><name><surname>Fang</surname><given-names>Fang</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Visual sequence exposure induces non-feature-specific elevated responses and time-compressed feature-specific backward replay, revealing twofold brain plasticity in the human brain.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The capacity of cortical circuits to undergo plasticity in response to experience is a fundamental feature of the brain (<xref ref-type="bibr" rid="bib7">Buonomano and Merzenich, 1998</xref>; <xref ref-type="bibr" rid="bib15">Costandi, 2016</xref>; <xref ref-type="bibr" rid="bib49">Li, 2016</xref>). This plasticity can be induced not only by active, task-dependent training, such as visual perceptual learning (<xref ref-type="bibr" rid="bib78">Watanabe and Sasaki, 2015</xref>; <xref ref-type="bibr" rid="bib13">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib56">Lu and Dosher, 2022</xref>), but also by passive, repetitive exposure (<xref ref-type="bibr" rid="bib31">Gutnisky et al., 2009</xref>; <xref ref-type="bibr" rid="bib71">Sasaki et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Ekman et al., 2017</xref>). For instance, after repeated exposure to a moving dot sequence, flashing a dot (i.e. cue) at the starting point of the sequence elicits successive elevated neural responses in visual cortex, akin to those induced by the actual moving dot sequence in both humans (<xref ref-type="bibr" rid="bib21">Ekman et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Ekman et al., 2023</xref>; <xref ref-type="bibr" rid="bib55">Lu et al., 2021</xref>) and animals (<xref ref-type="bibr" rid="bib19">Eagleman and Dragoi, 2012</xref>; <xref ref-type="bibr" rid="bib82">Xu et al., 2012</xref>). This cue-triggered reactivation is thought to be driven by expectations and is prediction-related (<xref ref-type="bibr" rid="bib21">Ekman et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Ekman et al., 2023</xref>), as it facilitates the prediction of upcoming stimuli and influences the perception of sensory information (<xref ref-type="bibr" rid="bib31">Gutnisky et al., 2009</xref>; <xref ref-type="bibr" rid="bib4">Baker et al., 2014</xref>; <xref ref-type="bibr" rid="bib65">Pojoga et al., 2020</xref>).</p><p>Unlike the simple white dot sequences used in previous studies (<xref ref-type="bibr" rid="bib82">Xu et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Ekman et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Ekman et al., 2023</xref>; <xref ref-type="bibr" rid="bib55">Lu et al., 2021</xref>), temporal sequences to which we are exposed in daily life usually contain rich feature information. However, it remains unknown whether cue-triggered elevated responses are feature-specific. On the one hand, if these responses are not feature-specific, they may reflect a general state of cortical readiness for any upcoming stimuli. On the other hand, if these responses are indeed specific to a particular feature in the sequence, they would selectively facilitate the processing of specific future events. This aligns with the view that expectation sharpens neural tuning and enhances the processing of expected stimuli (<xref ref-type="bibr" rid="bib40">Kok et al., 2012</xref>). For instance, expectation has been shown to elevate the pre-stimulus baseline activity of sensory neurons tuned to expected stimuli (<xref ref-type="bibr" rid="bib81">Wyart et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Kok et al., 2014</xref>) and to preactivate stimulus templates in both the visual (<xref ref-type="bibr" rid="bib42">Kok et al., 2017</xref>) and auditory (<xref ref-type="bibr" rid="bib16">Demarchi et al., 2019</xref>) cortices. Notably, however, all these prediction-related, feature-specific activities were observed in static contexts. Whether prediction-related responses in dynamic temporal contexts (e.g. visual sequences) are feature-specific remains unclear.</p><p>After exposure to a feature-contained temporal sequence, another important question is how the feature information in the sequence is encoded and organized in neural activity following the cue. Previous studies have demonstrated that memory consolidation (<xref ref-type="bibr" rid="bib12">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib30">Gridchyn et al., 2020</xref>; <xref ref-type="bibr" rid="bib28">Gillespie et al., 2021</xref>) or learning process <xref ref-type="bibr" rid="bib37">Igata et al., 2021</xref>; <xref ref-type="bibr" rid="bib53">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib54">Liu et al., 2022</xref> following training with a temporal sequence is associated with a neural phenomenon known as replay. Replay refers to the sequential reactivation of neural activity patterns associated with the trained sequence in both sleep (<xref ref-type="bibr" rid="bib48">Lee and Wilson, 2002</xref>) and awake (<xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>) states. During replay, the neural representation of the trained sequence is temporally compressed and can occur in either a forward or backward direction (<xref ref-type="bibr" rid="bib12">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib39">Joo and Frank, 2018</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>; <xref ref-type="bibr" rid="bib54">Liu et al., 2022</xref>; <xref ref-type="bibr" rid="bib58">McFadyen et al., 2023</xref>). These replay events frequently coincide with sharp-wave ripples (SWRs), which are high-frequency (150–220 Hz) oscillations (<xref ref-type="bibr" rid="bib61">O’Keefe and Nadel, 1978</xref>; <xref ref-type="bibr" rid="bib8">Bush et al., 2022</xref>) detected in hippocampal local field potentials (<xref ref-type="bibr" rid="bib9">Buzsáki, 1986</xref>; <xref ref-type="bibr" rid="bib11">Buzsáki, 2015</xref>). To date, replay has been observed in tasks involving sequences, such as nonlocal reinforcement learning (<xref ref-type="bibr" rid="bib53">Liu et al., 2021b</xref>) and episodic memory retrieval (<xref ref-type="bibr" rid="bib80">Wimmer et al., 2020</xref>). It remains unclear whether simple visual exposure to temporal sequences could also trigger replay events in humans.</p><p>In the current study, we used magnetoencephalography (MEG) to investigate whether cue-triggered elevated brain responses following visual sequence exposure are feature-specific and, more importantly, to determine how feature information in the exposed sequence is encoded and organized in the brain after exposure. To address these questions, participants were initially exposed to a predetermined motion sequence. We then decoded motion direction information during the blank period following the presentation of either the first or last motion direction in the sequence as a cue. Surprisingly, we found that cue-triggered elevated responses were not specific to any motion direction. Interestingly, motion direction information was spontaneously reactivated during the blank period, and the motion sequence was backward replayed in a time-compressed manner. This backward replay was identified even after brief exposure. However, neither forward nor backward replay was detected when an intermediate motion direction in the sequence was presented as a cue. Lastly, MEG source reconstruction analysis revealed that medial temporal lobe (MTL) activation preceded visual cortical activation, implying that the replay events observed in visual cortex may be triggered by activities in the MTL.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>The visual stimuli used in the study were four random-dot kinematograms (RDKs). All dots in an RDK moved in a single direction (i.e. 0°, 90°, 180°, or 270°) with 100% coherence. In Experiment 1, we included three trial conditions: full sequence trials, start-only trials, and end-only trials (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). In a full sequence trial, participants were exposed to a predefined sequence of the four RDKs presented either clockwise (i.e. 0° → 90° → 180° → 270°) or counterclockwise at the center of the screen, with an interstimulus interval of 300 ms between every two RDKs. In a start- or end-only trial, the first or last RDK of the sequence was presented at the beginning of the trial, followed by a blank period of 2.4 s. Participants were instructed to complete three successive phases: functional localizer phase, exposure phase, and main phase (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The functional localizer data were used to train models to decode each motion direction in the sequence. During this phase, one of the four RDKs was randomly presented for 1 s in each trial. During the exposure phase, participants were exposed only to full sequence trials for about 30 min. In the main phase, 50%, 25%, and 25% of all trials were full sequence, start- and end-only trials, respectively. The full sequence trials served as a topping-up exposure to maintain the exposure effect.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Stimuli, experimental procedure, and evoked responses in Experiment 1.</title><p>(<bold>A</bold>) Participants were presented with random-dot kinematograms (RDKs) in three conditions. In the full sequence trial condition, four successive RDKs were presented. In the start- or end-only condition, only the first or last RDK in the sequence was presented at the beginning of the trial. (<bold>B</bold>) During magnetoencephalography (MEG) scanning, the participants were presented with two functional localizer runs (i.e. functional localizer phase) before providing any sequence information. Next, they were exposed to four full sequence runs (i.e. exposure phase). Finally, in the main phase, full sequence, start- and end-only trials were presented in a pseudorandomized order. (<bold>C</bold>) Evoked neural responses as a function of time relative to trial onset (n = 18) in the full sequence, start- and end-only trial conditions, respectively. Bold black lines at the bottom indicate temporal clusters in which they reached significance when compared to the pre-stimulus baseline. Inset figures at the top-right corner show the peak amplitudes during the four corresponding RDK intervals after baseline correction.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig1-v1.tif"/></fig><sec id="s2-1"><title>Cue-triggered elevated responses are not feature-specific</title><p>We first measured the event-related field (ERF) activity evoked by RDKs in the three trial conditions using all occipital gradiometer sensors (see Materials and methods). <xref ref-type="fig" rid="fig1">Figure 1C</xref> shows the evoked responses for full sequence trials (left panel, cluster-based permutation test with a cluster forming threshold of t&gt;3.1 and 5000 permutations). Remarkably, start- and end-only trials elicited similar wave-like responses as the full sequence trials, despite the absence of stimuli following the first RDK (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, middle and right panels, cluster-based permutation test with a cluster forming threshold of t&gt;3.1 and 5000 permutations). To further quantify the ERF peak amplitudes in the three conditions while mitigating baseline confounds, we calculated each peak amplitude using the 300ms blank period just preceding the onset of the corresponding RDK as the baseline (see Materials and methods). We found that the four successive RDKs in the full sequence trials evoked four comparable peaks after stimulus onset (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, inset figure in the left panel; two-tailed t-test; all ts<sub>(17)</sub> &gt; 6.8072, all ps&lt;10<sup>–5</sup>). Interestingly, in start- and end-only trials, significant peaks were still observed during the periods corresponding to the intervals of the second and third RDKs in the full sequence trials (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, inset figures in the middle and right panels; start-only condition, two-tailed t-test; all ts<sub>(17)</sub> &gt; 4.5790, all ps&lt;10<sup>–3</sup>; end-only condition, two-tailed t-test; all ts<sub>(17)</sub> &gt; 6.0140, all ps &lt;10<sup>–4</sup>). However, no significant peak was observed during the period corresponding to the interval of the last RDK (start-only condition, two-tailed t-test; t<sub>(17)</sub> = 1.3221, p=0.2036; end-only condition, two-tailed t-test; t<sub>(17)</sub> = 0.2473, p=0.8076). These results demonstrate cue-triggered elevated neural responses following visual exposure to the RDK sequences, resembling previous studies using simple white dot sequences (<xref ref-type="bibr" rid="bib21">Ekman et al., 2017</xref>; <xref ref-type="bibr" rid="bib55">Lu et al., 2021</xref>).</p><p>Given that we observed elevated responses even in the absence of stimuli following the cue, we next examined whether these responses were specific to a particular feature (i.e. motion direction). Specifically, we asked whether motion directions could be successfully decoded in start- and end-only trials, particularly during the blank periods corresponding to the intervals of the second and third RDKs in full sequence trials. To this end, we applied a time-resolved decoding analysis. For each participant, we trained a one-versus-rest Lasso logistic regression model using the functional localizer data to classify the neural activity pattern elicited by each motion direction in the main phase. MEG signals from 72 occipital sensors were selected as features for the training model.</p><p>To validate the reliability of our model, we first used a leave-one-out cross-validation scheme on the localizer data to independently estimate decoding accuracy at each time point. At the group level, decoding accuracies peaked at 411 ms, 464ms, 444 ms, and 434 ms after stimulus onset for motion directions 0° (55.37%±1.21), 90° (58.10%±1.14), 180° (54.07%±1.47), and 270° (53.64%±1.34), respectively. There were no significant differences among the four motion directions in terms of either latency (F(3, 51)=0.375, p=0.7716, <italic>η</italic><sub>p</sub><sup>2</sup>=0.0159) or decoding accuracy (F(3, 51)=2.757, p=0.0517, <italic>η</italic><sub>p</sub><sup>2</sup>=0.091) at the peak time point. Next, we trained a model using the localizer data averaged between 100 ms and 500 ms after stimulus onset. The trained model was then applied to the MEG signals recorded in the three trial conditions in the main phase. Finally, we calculated the decoding probability (<xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>; <xref ref-type="bibr" rid="bib76">Turner et al., 2023</xref>) for each motion direction at each time point at the group level (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Here, decoding probability for each motion direction reflects the likelihood that the decoded stimulus had a specific motion direction at a given time point (see Materials and methods). Therefore, it provides a time-resolved decoding preference for each motion direction, rather than only a single decoded label (e.g. 0°, 90°, 180°, or 270°).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Time-resolved decoding probability for each motion direction.</title><p>(<bold>A</bold>) Visualization of the time-resolved decoding probability in the three trial conditions. Each row shows the decoding probabilities for the four motion directions at that time point, and each column indicates one of the four motion directions. (<bold>B</bold>) The line plots of the time-resolved decoding probability for the three trial conditions. Each colored line shows the time course of the decoding probability for each motion direction. For the start- and end-only conditions, we calculated the permutation threshold estimated by randomly shuffling the labels and re-decoding; only the decoding probability of the cue surpassed the threshold.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig2-v1.tif"/></fig><p>In full sequence trials, the motion direction information could be successfully decoded, as evidenced by the highest decoding probability during the interval corresponding to the presentation of the respective RDK (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, left panels). In start- and end-only trials, we could also reliably decode the motion direction of the first RDK (i.e. the cue) after stimulus onset (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, middle and right panels, only the decoding probability of the first RDK surpasses the peak-level significance threshold obtained from a nonparametric permutation test, FWE corrected across time). Surprisingly, however, subsequent motion direction information was absent at the group level during the post-cue blank period, where the cue-triggered elevated responses were previously observed (i.e. 0.4–2.8 s after stimulus onset). Together, these results demonstrate that the cue-triggered elevated response induced by visual sequence exposure was not consistently specific to a particular feature across participants and trials.</p></sec><sec id="s2-2"><title>Time-compressed backward replay of exposed motion sequence</title><p>How is the motion direction information encoded and organized in the brain during the post-cue blank period? Clearly, the motion direction representation is not time-locked to the onset of the cue in either start- or end-only trials. However, it is possible that individual motion directions are encoded in the MEG signals in a spontaneous way but are sequentially organized (<xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>).</p><p>To test this hypothesis, we trained four decoding models using the localizer data to capture the neural features of the four motion directions. We employed four decoding models because our aim was to build feature-specific classifiers, each sensitive to only one motion direction. These classifiers were designed to quantify the evidence of feature-specific sequence in subsequent analyses. The models used a one-versus-rest Lasso logistic regression algorithm, with MEG signals from 72 occipital sensors as features (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). For each participant and motion direction, we then selected the time point with the highest decoding accuracy, which was estimated during the validation of the functional localizer data, as the optimal time point. These optimal time points were chosen because they are believed to carry the richest feature information (<xref ref-type="bibr" rid="bib59">Mo et al., 2019</xref>). For subsequent analyses, we obtained four classifiers that were trained on the localizer data at their respective optimal time points. Each classifier yielded significant decoding probability only when the stimulus matched the motion direction it was trained to detect (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). We did not find any spatial correlation between any two trained classifiers (highest correlation r&lt;0.12, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Since the optimal time point varied across participants and motion directions, we circularly shifted the decoding probabilities over time and aligned them to a common time point (arbitrarily set to 200 ms after stimulus onset) for visualization at the group level (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Illustration of replay analysis pipeline: temporally delayed linear modeling (TDLM).</title><p>(<bold>A</bold>) A Lasso logistic regression model was trained for each participant and motion direction using magnetoencephalography (MEG) signals from the functional localizer data. (<bold>B</bold>) The four feature-specific models that were trained using functional localizer data. The decoding probabilities were aligned at 200 ms poststimulus onset according to their corresponding optimal time point per participant and motion direction. Each colored line indicates the decoding results of a model applied to a motion direction dataset. The dashed horizontal line indicates the permutation threshold estimated by random shuffling of the labels and re-decoding. (<bold>C</bold>) The four models were next applied to MEG signals during the post-cue blank period to derive a decoded reactivation matrix [time × motion direction]. An illustration of backward sequential reactivations of motion direction is shown on the left. Reactivation probabilities correspond to the decoding probabilities derived from the four models. (<bold>D</bold>) Using TDLM, we quantified the evidence for sequential replay of the motion sequence during the post-cue blank period in start- and end-only conditions. We first performed a time-lagged regression to generate a [4×4] empirical regression coefficient matrix for each time lag by regressing each lagged predictor matrix, X(Δt), onto the original reactivation matrix, Y (i.e. first-level GLM analysis). Next, we used a second-level GLM analysis to evaluate the extent to which the empirical transition matrix follows a model transition matrix (e.g. forward or backward transitions) (i.e. second-level GLM analysis). Finally, we calculated the difference between the second-level regression coefficients for forward and backward transitions, referred to as ‘sequenceness’. We tested the magnitude of this ‘sequenceness’ at each time lag independently for all transition lags up to 600 ms. The dashed line represents the corrected nonparametric statistical significance threshold. The green area indicates the lags when the evidence of ‘sequenceness’ in the backward direction exceeded the permutation threshold.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Sensor maps and spatial correlation of trained Lasso logistic regression models.</title><p>(<bold>A</bold>) Left: Sensor map for each state decoding model in Experiment 1; magnetoencephalography (MEG) signals from 72 occipital sensors were selected as features while training the classifier. Right: Correlation matrix among classifiers. No spatial correlation was found among trained classifiers (highest correlation; r&lt;0.12). (<bold>B and C</bold>) Same as (<bold>A</bold>), except the sensor maps and correlation matrix correspond to Experiments 2 (Panel B, highest correlation; r&lt;0.1) and 3 (Panel C, highest correlation; r&lt;0.1), respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Decoded feature representations in start- and end-only conditions.</title><p>Time series of reactivation probability output from the four regression models on an example trial. Time zero corresponds to trial onset. Both participants S08 and S12 were exposed to a fixed motion sequence of 0° → 90° → 180° → 270°.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig3-figsupp2-v1.tif"/></fig></fig-group><p>Having established the classifiers for each participant and motion direction, we then applied the classifiers to the MEG signals during the post-cue blank period in start- and end-only conditions to estimate the reactivation probability (i.e. decoding probability) for each motion direction at each time point (<xref ref-type="fig" rid="fig3">Figure 3C</xref>; <xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib80">Wimmer et al., 2020</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>). Example trials for the start- and end-only conditions are shown in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>. The results revealed that motion direction reactivations occurred sparsely during the post-cue blank period, rather than crowded within intervals corresponding to the RDK presentations in the full sequence condition, suggesting that motion direction information might be reactivated in a spontaneous way. Next, we applied temporally delayed linear modeling (TDLM) to quantify whether and how these spontaneous reactivations followed the order of the exposed sequence (<xref ref-type="fig" rid="fig3">Figure 3D</xref>; <xref ref-type="bibr" rid="bib45">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>). This algorithm includes two-level regression analyses. The first-level regression quantifies the evidence for each pairwise transition (e.g. 0° → 90°), resulting in an empirical transition matrix. The second-level regression evaluates the extent to which this empirical transition matrix aligns with a specific sequence of interest. Finally, we defined ‘sequenceness’ as a metric of forward (i.e. 0° → 90° → 180° → 270°) or backward (i.e. 270° → 180° → 90° → 0°) replay (see Materials and methods).</p><p>As shown in <xref ref-type="fig" rid="fig4">Figure 4A and B</xref>, in the start-only condition, we found evidence of backward replay of the exposed motion sequence (i.e. the replay sequence was 270° → 180° → 90° → 0° when the exposed motion sequence was 0° → 90° → 180° → 270°) during the post-cue blank period, with a peak transition lag at 28–40 ms (maximal effect at 32 ms-lag: β = −0.0202±0.002, p&lt;1/24 ≈ 0.042, peak-level significance threshold derived from a nonparametric permutation test, FWE corrected across lags, <xref ref-type="fig" rid="fig4">Figure 4B</xref>). For visualization, an example of backward replay of the motion sequence is illustrated in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. This effect was observed in most participants (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). In the end-only condition, we also found evidence of backward replay during the post-cue blank period, with a peak transition lag at 28–36 ms (maximal effect at 32 ms-lag: β = −0.0145±0.0016, p&lt;1/24 ≈ 0.042, peak-level significance threshold obtained from a nonparametric permutation test, FWE corrected across lags; <xref ref-type="fig" rid="fig4">Figure 4E</xref>). <xref ref-type="fig" rid="fig4">Figure 4D</xref> shows an example of backward replay of the motion sequence in this condition found in most participants (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Note that the time lag in the horizontal axis in <xref ref-type="fig" rid="fig4">Figure 4B and E</xref> indicates the interval between the onsets of every two items in the replayed motion sequence. We found that the replayed sequence was approximately 10 times faster than the evoked activity sequence in the full sequence condition.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Backward replay in both start- and end-only conditions.</title><p>(<bold>A</bold> and <bold>D</bold>) Examples of backward sequential reactivation in start- (<bold>A</bold>) and end- (<bold>D</bold>) only conditions from a representative participant. Each row represents the reactivation probabilities for the four motion directions at that time point, and each column indicates one of the four motion directions. (<bold>B</bold> and <bold>E</bold>) Backward replay of the exposed motion sequence with peak transition lags at 28–40 ms in the start-only condition (<bold>B</bold>) and at 28–36 ms in the end-only condition (<bold>E</bold>). Horizontal dashed lines represent corrected significance levels from a nonparametric permutation test at the second-level GLM analysis of temporally delayed linear modeling (TDLM). The sequenceness on the y-axis is a unitless measure. The lag on the x-axis represents the time lag (Δt) between sequential reactivations, rather than absolute time. The red shaded areas indicate the lags when the evidence of sequenceness exceeded the permutation-based significance threshold. (<bold>C</bold> and <bold>F</bold>) Backward replay of the exposed motion sequence predominantly appeared at 1.2–1.8 s in the start-only condition (<bold>C</bold>) and 0.6–1.8 s in the end-only condition (<bold>F</bold>) after the onset of the blank period.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Sequenceness distribution across participants.</title><p>(<bold>A</bold>) In Experiment 1, of the 18 participants, 14 showed backward replay at 32 ms-lag for the start-only condition (left), and 13 showed backward replay at 32 ms-lag for the end-only condition (right). Each dot represents an individual participant. Backward and forward sequenceness is denoted by blue and yellow dots, respectively. The inset histogram shows the distribution of deviations from the unity line. (<bold>B</bold>) Same as described in (<bold>A</bold>), but for the results of Experiment 2 in the second-only (left) and third-only (right) conditions, respectively. (<bold>C</bold>) Same as described in (<bold>A</bold>) but for the results of Experiment 3 in the start- (left) and end-only (right) conditions, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Sequenceness for each of the 24 possible orders.</title><p>(<bold>A</bold>) In the start-only condition of Experiment 1, only the backward sequence [4 → 3 → 2 → 1] with lags at 28–40 ms was significantly different (gray panels). The horizontal dashed lines represent significance thresholds derived from state label permutation at the second-level GLM matrix of temporally delayed linear modeling. (<bold>B</bold>) Same as described in (<bold>A</bold>) but for the end-only condition in Experiment 1.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig4-figsupp2-v1.tif"/></fig></fig-group><p>To further examine the period during which the backward replay occurred most frequently, we divided the blank period (2.4 s) into four stages, each lasting 600 ms. In start-only trials, we found that the backward replay predominantly appeared within the third stage of the blank period (1.2–1.8 s after the onset of the blank period, Wilcoxon signed-rank test, p=0.0108), but there were no significant sequenceness in the other three stages (first stage, p=0.7112; second stage, p=0.5566; fourth stage, p=0.6791; <xref ref-type="fig" rid="fig4">Figure 4C</xref>). In end-only trials, the backward replay was more likely to occur during the second and third stages of the blank period, although the results approached, but did not reach, significance (Wilcoxon signed-rank test, second stage, p=0.0936; third stage, p=0.0642; <xref ref-type="fig" rid="fig4">Figure 4F</xref>). In contrast, the replay was not frequently observed during the first and last stages (Wilcoxon signed-rank test, first stage, p=0.9479; fourth stage, p=0.4997). Finally, in a control analysis, we conducted a comprehensive examination of all 24 potential sequences. Only the backward replay was detected in both start- and end-only conditions (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p></sec><sec id="s2-3"><title>Backward replay is cue-dependent and depends on the amount of exposure</title><p>So far, we have demonstrated that the cue-triggered elevated responses induced by the motion sequence exposure were not motion direction specific. However, motion information was spontaneously reactivated, and the motion sequence was backward replayed in a time-compressed manner. It remains unknown whether the observed backward replay of the motion sequence was cue-dependent. In other words, does the replay of the motion sequence occur irrespective of which item of the sequence is presented as a cue? To address this question, we conducted Experiment 2, mirroring the design of Experiment 1 but with a different cue. Instead of flashing the first or last RDK, we presented the second or third RDK as a cue (second-only or third-only condition, see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> and Materials and methods) to examine whether these two non-terminal cues could induce replay during the post-cue blank period. We found no evidence of either forward or backward replay in either condition (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; maximal nonsignificant effect at 32 ms-lag: second-only condition, β = −0.0024±0.0014; third-only condition, β = −0.0018±0.0015).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Backward replay is cue-dependent and depends on the amount of exposure.</title><p>(<bold>A</bold>) No evidence for replay was found in either the second-only (left) or third-only (right) condition in Experiment 2. Horizontal dashed lines have the same meaning as those in <xref ref-type="fig" rid="fig4">Figure 4B and E</xref>. (<bold>B</bold>) In Experiment 3, immediately after the functional localizer phase, participants entered the main phase without the exposure phase. In the end-only condition, backward replay was observed; however, in the start-only condition, no such replay was observed.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Stimuli and experimental procedures in Experiments 2 and 3.</title><p>(<bold>A</bold>) We presented the second (second-only condition) or third random-dot kinematogram (RDK) (third-only condition) as a cue in Experiment 2. (<bold>B</bold>) The procedure of Experiment 3 was identical to that of Experiment 1 except for removing the exposure phase.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig5-figsupp1-v1.tif"/></fig></fig-group><p>Another interesting question is how varying the amount of exposure would affect replay events during the blank period. To explore this issue, we conducted Experiment 3, also similar to Experiment 1 except for the removal of the exposure phase. Accordingly, only full sequence trials (50% trials) in the main phase served for exposure (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> and Materials and methods). In the start-only condition, we found a numerical trend of backward replay at transition lags at 20–40 ms, although it did not reach statistical significance (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, left panel; maximum effect at 28 ms-lag: β = −0.0139±0.0021). In the end-only condition, the evidence for backward replay just reached the significance level at transition lags at 20–40 ms (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, right panel; maximal effect at 24 ms-lag: β = −0.0147±0.0019, p&lt;1/24 ≈ 0.042, using the peak-level significance threshold from a nonparametric permutation test, FWE corrected across lags).</p></sec><sec id="s2-4"><title>Power increase in replay-associated SWR frequencies</title><p>Previous studies on rodents and humans showed that replay events are associated with increased high-frequency ripple power (<xref ref-type="bibr" rid="bib11">Buzsáki, 2015</xref>; <xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>). To investigate whether such replay-associated power increase could be observed in our study, we performed a time-frequency analysis using combined data from the start- and end-only conditions in Experiment 1. We first identified putative replay onsets during the post-cue blank period in each trial. Replay onsets were determined by choosing time points with a high (&gt;95th percentile) probability for backward replay with a 32 ms-lag transition (maximal replay effect at the group level for both start- and end-only conditions, <xref ref-type="fig" rid="fig4">Figure 4B and E</xref>; see Materials and methods). Using the MEG signals recorded from whole-brain sensors, we found a transient ripple power increase at 120–180 Hz at the onset of replay events, compared to the baseline period of 50–100 ms prior to replay onset (<xref ref-type="fig" rid="fig6">Figure 6A</xref>; cluster-based permutation test with cluster forming threshold t&gt;3.1 and 5000 permutations).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Replay events align with ripple power, with source activation in the medial temporal lobe (MTL) preceding activation in visual cortex.</title><p>(<bold>A</bold>) Top: In Experiment 1, a time-frequency decomposition of sensor-level data revealing a brief increase in high-frequency oscillatory power at replay onset. Bottom: A cluster-based permutation test (cluster forming threshold, t&gt;3.1; number of permutations = 5000) could identify a significant cluster around 140 Hz (n = 18). (<bold>B</bold>) Source localization of ripple-band power 30 ms before replay onset showing significant activation in the MTL (peak Montreal Neurological Institute [MNI] coordinates: X=21, Y=21, Z=13, neurological orientation). (<bold>C</bold>) Source localization of ripple-band power at replay onset showing significant activation in visual cortex (peak MNI coordinates: X=20, Y=8, Z=17). (<bold>D</bold>) The activation time course of the MTL at its peak MNI coordinate is shown in red, whereas that of visual cortex at its peak MNI coordinate is displayed in green. The MTL reached its peak activation before visual cortex.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101511-fig6-v1.tif"/></fig></sec><sec id="s2-5"><title>Visual cortical activation lags MTL activation</title><p>Since replay events were obtained based on decoding probabilities of motion directions from occipital sensors only, we next examined whether the observed replay onsets were related to power increase within visual cortex. Using a linearly constrained minimum variance (LCMV) beamforming algorithm (<xref ref-type="bibr" rid="bib77">Van Veen et al., 1997</xref>), we first epoched the data using replay onsets combined from both start- and end-only conditions and then beamformed the broadband power into the source space (see Materials and methods). We found that the power increase at replay onset was localized to sources in bilateral visual cortex (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). Moreover, the right MTL, including the hippocampus and amygdala, was associated with power increase prior to the onset of replay events (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Specifically, activation (i.e. power increase) in the MTL occurred 30 ms earlier than that in visual cortex (p&lt;0.05, corrected, whole-brain nonparametric permutation test). For display purposes, we extracted activations from the 10 most activated voxels within the MTL and visual cortex, respectively, and plotted the time courses of their broadband power. Peak activation in visual cortex at replay onset was preceded by peak activation in the MTL (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), implying an information flow from the MTL to visual cortex.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We found the coexistence of time-locked, non-feature-specific elevated responses and non-time-locked, feature-specific backward replay after visual sequence exposure in human brain. The feature-specific backward replay occurred in a time-compressed manner and could be triggered only by the first or last stimulus of the sequence. Interestingly, even brief exposure to the sequence could still induce a trend for the backward replay. Finally, we observed that MTL activity preceded the ripple power increase in visual cortex at replay onset.</p><p>Our study provides two new findings in the fields of vision and learning. First, different from many previous studies showing that expectation-based responses in static contexts are feature-specific (<xref ref-type="bibr" rid="bib81">Wyart et al., 2012</xref>; <xref ref-type="bibr" rid="bib41">Kok et al., 2014</xref>; <xref ref-type="bibr" rid="bib42">Kok et al., 2017</xref>), we show here that prediction-related elevated responses in the dynamic temporal context are not. This non-feature-specific elevated response potentially facilitates the general processing of any upcoming stimuli, rather than stimuli with a specific feature. Second, contrary to the prevailing notion that replay in learning and memory requires lengthy training with a task, our study shows that even brief exposure to a visual sequence is sufficient to induce replay. The replay we unveiled here may play a critical role in memorizing the visual sequence.</p><p>Regarding the twofold neural consequences following the visual sequence exposure, the non-feature-specific elevated responses could be induced by rhythmic entrainment. Substantial evidence supports that rhythmic stimulation can entrain neural oscillations, which in turn facilitates predictions about future inputs and enhances the brain’s readiness for incoming stimuli (<xref ref-type="bibr" rid="bib46">Lakatos et al., 2008</xref>; <xref ref-type="bibr" rid="bib47">Lakatos et al., 2013</xref>; <xref ref-type="bibr" rid="bib34">Herrmann et al., 2016</xref>; <xref ref-type="bibr" rid="bib5">Barne et al., 2022</xref>). For instance, recent findings demonstrate that even task-irrelevant information could be more effectively decoded when presented at moments close to a highly probable target presentation (<xref ref-type="bibr" rid="bib3">Auksztulewicz et al., 2019</xref>). In our study, the rhythmic presentation of the motion sequence may have entrained oscillatory activity in the brain, leading to periodic activation of sensory cortices. This rhythmic entrainment likely serves as a possible mechanism supporting the general facilitation of neural processing for any upcoming stimuli, independent of specific stimulus features.</p><p>In contrast, feature-specific replay may operate through a different mechanism driven by intrinsic neural processes rather than direct external stimuli. Therefore, this intrinsic activity is not time-locked to stimulus onset, but instead manifests in a spontaneous way. Furthermore, since replay often occurs during offline periods (e.g. rest or blank period), it allows the neural system to reactivate and consolidate past experiences without interference from ongoing external inputs. As a result, feature-specific replay may facilitate the integration of fragmented experiences into coherent representations, thereby subserving visual sequence learning and memory.</p><p>Another interesting question regarding the twofold neural responses is whether the elevated responses and the backward replay share the same neural origin, for instance, originating from the hippocampus or other brain areas. For the elevated responses, the cue serves to provide temporal information for upcoming stimuli but without detailed feature information, thereby priming the cortices for activation and facilitating the general processing of future events. Previous animal studies (<xref ref-type="bibr" rid="bib82">Xu et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Gavornik and Bear, 2014</xref>) showed that this process can be implemented through a simple local synaptic mechanism in visual cortex (<xref ref-type="bibr" rid="bib82">Xu et al., 2012</xref>) without top-down guidance. Moreover, <xref ref-type="bibr" rid="bib22">Ekman et al., 2023</xref>, recently found no functional relationship between activities in V1 and the hippocampus when exposing human participants to a white dot sequence, further suggesting that the elevated responses may indeed originate in visual cortex.</p><p>Different from the elevated responses, the replay events are likely initiated by the hippocampus. This speculation is supported by two key findings. First, the replay of the motion direction information manifested in a backward direction and a time-compressed manner. Second, the replay is observed regardless of whether the cue is the first or last RDK in the sequence. Both of these two properties cannot be explained by a simple local synaptic mechanism (<xref ref-type="bibr" rid="bib82">Xu et al., 2012</xref>) or a pattern completion-like mechanism (<xref ref-type="bibr" rid="bib35">Hindy et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Ekman et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Kok and Turk-Browne, 2018</xref>) within visual cortex alone. Instead, the replay entails reorganizing the motion direction sequence in the brain. Therefore, we propose the involvement of active communication between the hippocampus and visual cortex in the occurrence of replay events, consistent with the view that the hippocampus encodes relationships among stimuli, whereas visual cortex primarily acts as a platform for the manifestation of replay events (<xref ref-type="bibr" rid="bib79">Whittington et al., 2020</xref>). Previous studies on memory consolidation considered the exchange of information between these two regions critical for facilitating replay events through hippocampal-neocortical circuits (<xref ref-type="bibr" rid="bib10">Buzsáki, 1996</xref>; <xref ref-type="bibr" rid="bib38">Ji and Wilson, 2007</xref>; <xref ref-type="bibr" rid="bib12">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib63">Ólafsdóttir et al., 2016</xref>; <xref ref-type="bibr" rid="bib6">Buch et al., 2021</xref>). Functionally, replay events offer a mechanism for transferring recent experience from the hippocampus to the cortex, enabling the encoding of stimulus relationships in the cortex (<xref ref-type="bibr" rid="bib57">Marr and Brindley, 1971</xref>; <xref ref-type="bibr" rid="bib1">Alvarez and Squire, 1994</xref>; <xref ref-type="bibr" rid="bib66">Redish and Touretzky, 1998</xref>; <xref ref-type="bibr" rid="bib18">Dimakopoulos et al., 2022</xref>).</p><p>A natural behavioral consequence of visual sequence exposure is visual sequence learning (<xref ref-type="bibr" rid="bib4">Baker et al., 2014</xref>; <xref ref-type="bibr" rid="bib24">Finnie et al., 2021</xref>; <xref ref-type="bibr" rid="bib22">Ekman et al., 2023</xref>). How is the learning implemented through hippocampus-dependent replay in visual cortex? Three key processes are considered here. First, the hippocampus is involved in encoding relationships among stimuli (<xref ref-type="bibr" rid="bib73">Staresina and Davachi, 2009</xref>; <xref ref-type="bibr" rid="bib75">Turk-Browne et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Hsieh et al., 2014</xref>; <xref ref-type="bibr" rid="bib26">Garvert et al., 2017</xref>); in fact, the ability to encode such relationships drastically decreases when the hippocampus is damaged (<xref ref-type="bibr" rid="bib14">Chun and Phelps, 1999</xref>; <xref ref-type="bibr" rid="bib32">Hannula et al., 2006</xref>; <xref ref-type="bibr" rid="bib44">Konkel et al., 2008</xref>; <xref ref-type="bibr" rid="bib72">Schapiro et al., 2014</xref>; <xref ref-type="bibr" rid="bib24">Finnie et al., 2021</xref>). Second, visual cortical areas act as a ‘cognitive blackboard’ where task-relevant features are highlighted through feedback connections (<xref ref-type="bibr" rid="bib69">Roelfsema and de Lange, 2016</xref>). Such a blackboard can be flexibly written or edited. Third, there are strong bidirectional connections between the hippocampus and sensory cortices (<xref ref-type="bibr" rid="bib20">Eichenbaum et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Henke, 2010</xref>). As proposed by the hippocampal-cortical backward projection model (<xref ref-type="bibr" rid="bib70">Rolls, 2000</xref>), sequential reactivations of feature information initially generated in the hippocampus can be quickly and accurately sent back to the sensory cortices, consistent with the findings of <xref ref-type="bibr" rid="bib38">Ji and Wilson, 2007</xref>. A recent study also provided direct evidence that visual sequence plasticity is impaired when the hippocampus is damaged (<xref ref-type="bibr" rid="bib24">Finnie et al., 2021</xref>), supporting the hypothesis of functional feedback information flow.</p><p>Why does the replay manifest in a reverse order? To date, there is no consensus on this issue. In rodents, a seminal study of replay during the awake state showed that when animals stopped at the end of a rewarded pathway, place cells were reactivated in the reverse order of the previously experienced direction (<xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>). However, a later study revealed that awake replay could occur in either a forward or backward direction relative to behavioral experience (<xref ref-type="bibr" rid="bib17">Diba and Buzsáki, 2007</xref>). Similarly, in humans, both directions have been observed in different nonspatial cognitive tasks (<xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib80">Wimmer et al., 2020</xref>). Forward replay may be associated with planning (<xref ref-type="bibr" rid="bib62">Ólafsdóttir et al., 2015</xref>; <xref ref-type="bibr" rid="bib28">Gillespie et al., 2021</xref>), providing information pertaining to the assessment of future pathways (<xref ref-type="bibr" rid="bib17">Diba and Buzsáki, 2007</xref>). Backward replay may be more related to experience, as often observed at the end of runs when animals consume a reward (<xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>). Nevertheless, the exact function of the replay direction remains mysterious, as both forward and backward replays are modulated by task demands (<xref ref-type="bibr" rid="bib64">Ólafsdóttir et al., 2017</xref>). Thus, the underlying neural mechanisms of backward replay in visual cortex remain to be investigated.</p><p>Finally, we also found that replay occurrence is modulated by the cue. This result highlights the importance of the start and end points of the sequence in the replay. One fascinating proposal is that the replay event is sensitive to sequence boundaries, as indicated by the role of the start or end point of the sequence as salient boundaries that anchor place cell firing (<xref ref-type="bibr" rid="bib68">Rivard et al., 2004</xref>). Accordingly, previous studies have shown that when rats are trained to run along a linear track starting at different points, place fields tend to be anchored to either the start or end of the journey (<xref ref-type="bibr" rid="bib29">Gothard et al., 1996</xref>; <xref ref-type="bibr" rid="bib67">Redish et al., 2000</xref>), suggesting that a boundary is essential to sequence integrity and may play a pivotal role in triggering replay onset. An alternative explanation to these findings posits that the onset of the second or third stimulus in the sequence reinstates the neural representations of a partial visual sequence (<xref ref-type="bibr" rid="bib22">Ekman et al., 2023</xref>). For example, for a given sequence, A → B → C → D, flashing the third stimulus (i.e. C) only trigger a backward reactivation of the sequence giving C → B → A during the blank period.</p><p>Taken together, we found that simple visual sequence exposure could concurrently induce twofold brain plasticity, i.e., non-feature-specific elevated responses and feature-specific backward replay in the human visual cortex. We speculate that the non-feature-specific elevated responses may enhance general processing of upcoming visual stimuli, whereas the feature-specific backward replay may subserve visual sequence learning and memory. These findings significantly advance our understanding of the task independence and the multifaceted nature of brain plasticity in response to visual experience.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>A total of 59 healthy participants (29 females) were involved in the three experiments (Experiment 1: n=21, 11 females, 22.1±2.61 years; Experiment 2: n=18, 10 females, 23.56±3.29 years; Experiment 3: n=20, 10 females, 20.65±2.62 years). In Experiment 1, data from three participants were excluded before analyses, as two showed large head motion (&gt;20 mm), and the behavioral performance of one was at chance level. In Experiment 3, data from two participants were excluded before analyses because of large head motion (&gt;20 mm). No statistical methods were used to predetermine sample sizes, but our sample sizes are comparable to previous studies (<xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib59">Mo et al., 2019</xref>). All participants were recruited in exchange for monetary compensation (100 RMB/hr). They reported normal or corrected-to-normal vision and had no history of neurological disorders. They were naive to the purposes of the study. The experiments reported here were carried out in accordance with the guidelines expressed in the Declaration of Helsinki. All participants provided written informed consent in accordance with the procedures and protocols approved by the Human Subject Review Committee of Peking University.</p></sec><sec id="s4-2"><title>Task</title><sec id="s4-2-1"><title>Experiment 1</title><p>Visual stimuli were RDKs with 100% coherence. All dots in an RDK moved in the same direction (luminance: 2.86 cd/m<sup>2</sup>; diameter: 0.1°; speed: 8°/s) and were presented against a gray background (luminance: 16.7 cd/m<sup>2</sup>). At any one moment, 400 dots were visible within a 9° circular aperture and moved in one of the four directions: 0° (right), 90° (up), 180° (left), and 270° (down). Each participant completed three phases successively in the MEG scanner, namely, the functional localizer phase, the exposure phase, and the main phase (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). In the functional localizer phase, each trial started with the presentation of an RDK for 1 s followed by a 1–1.5 s intertrial interval (ITI). Participants did not need to perform any task in this phase. The motion direction of the RDK was randomly chosen from the four directions. Each participant performed two functional localizer runs, and each run comprised 100 trials, resulting in a total of 50 trials per motion direction. The localizer data were used to train motion direction classifiers. This phase took approximately 10 min.</p><p>In the exposure phase, we showed participants the four RDKs in either clockwise or counterclockwise order (e.g. 0° → 90° → 180° → 270°, <xref ref-type="fig" rid="fig1">Figure 1A and C</xref>); each was displayed for 400 ms, followed by 300 ms of a blank screen with a fixation only. Therefore, the full sequence lasted for 2.8 s. The order was counterbalanced among participants, but once decided, it was fixed for each participant. Participants were instructed to detect an oddball RDK by pressing a button, i.e., in 20% trials, dots in one of the four RDKs traveled at a faster speed (9°/s). Each participant completed four runs of 50 trials.</p><p>In the main phase, participants were presented with trials in three different conditions: full sequence condition (50% trials), start-only condition (25% trials), and end-only condition (25% trials). Trials in the full sequence condition were identical to those in the exposure phase, which served as ‘topping-up’ exposure to maintain the exposure effect, similar to ‘topping-up’ adaptation in visual adaptation studies (<xref ref-type="bibr" rid="bib23">Fang et al., 2005</xref>). In the start- and end-only conditions; however, we only presented the first RDK (start-only condition) or the last RDK (end-only condition) of the full sequence. For a given run, the order of the three conditions was pseudorandomized with the restriction that the start- and end-only trials were always preceded or followed by a full sequence trial. Participants performed an identical oddball detection task as during the exposure phase. The oddball occurred only in 10% of full sequence trials. Finally, each participant completed four runs of 48 trials, yielding a total of 96 full sequence trials, 48 start-only trials, and 48 end-only trials.</p></sec><sec id="s4-2-2"><title>Experiments 2 and 3</title><p>In Experiment 2, we only presented the second or third RDK as a cue at the start of the trial, referred to as the second-only and third-only conditions, respectively. The procedure of Experiment 2 was similar to that of Experiment 1, except that the start- and end-only conditions were replaced with the second-only and third-only conditions. Experiment 3 followed the same procedure as Experiment 1, except that the exposure phase was removed.</p></sec></sec><sec id="s4-3"><title>Quantification and statistical analysis</title><sec id="s4-3-1"><title>MEG acquisition and preprocessing</title><p>Neuromagnetic signals were recorded continuously at 1000 Hz with a 306-channel (204 planar gradiometers; 102 magnetometers), whole-head MEG system (Elekta Neuromag TRIUX) in a magnetically shielded room. Before scanning, four-headed position indicator coils attached to the scalp determined the head position with respect to the sensor array. Coil location was digitized with respect to three anatomical landmarks (nasion and preauricular points) with a 3D digitizer (Polhemus Isotrak system). Participants sat upright inside the scanner, while the stimuli were projected onto a screen suspended in front of them. Participants responded using a MEG-compatible button box held in their right hand.</p><p>To reduce noise from external environment, the temporal extension of signal-space separation method was applied at the preprocessing stage using the Elekta Neuromag MaxFilter software (<xref ref-type="bibr" rid="bib74">Taulu and Simola, 2006</xref>). MEG signals were high-pass filtered at 0.5 Hz using a first-order IIR filter to remove slow drifts. Data were then downsampled from 1000 Hz to 250 Hz for sequenceness analysis or 500 Hz for time-frequency analysis. Excessively noisy segments and sensors were automatically removed before independent component analysis (FastICA, <ext-link ext-link-type="uri" xlink:href="http://research.ics.aalto.fi/ica/fastica">http://research.ics.aalto.fi/ica/fastica</ext-link>) and performed to remove artifacts including cardiac signals, eye movements and blinks, and environmental noise. Artifact components were removed by visual inspection of spatial topography, time course, kurtosis of the time course, and frequency spectrum of all components. Only 72 sensors (including both gradiometers and magnetometers) covering the occipital lobe, labeled as ‘occipital’ in the MEG data acquisition system, were used for MEG data analyses, except for source localization. The sensor selection was primarily motivated by the main objective of the study, examining replay events in visual cortex.</p></sec></sec><sec id="s4-4"><title>Event-related fields</title><p>To calculate the ERFs, MEG epochs were segmented around trial onset for each trial and baseline-corrected using the mean activity in the time window of [−0.3 s, 0] before trial onset. Only 48 planar gradiometers of ‘occipital’ sensors were used to calculate the ERFs. The planar-combined ERF activity was then averaged for each condition. To minimize potential baseline confounds caused by the short interval between every two RDKs, we further calculated the ERF peak amplitude using the mean activity in the time window of [−0.3 s, 0] before the onset of the corresponding RDK as the baseline. Subsequently, peak amplitude during each of the four RDK intervals was calculated as the difference between the peak and its corresponding baseline.</p></sec><sec id="s4-5"><title>Multivariate pattern analyses</title><p>Multivariate pattern analyses were performed to classify the neural activity patterns elicited by the motion directions of the four RDKs in the main phase. A one-versus-rest Lasso-regularized logistic regression model was trained using the MEG signals from the 72 occipital sensors in the functional localizer phase. Specifically, we trained a five-class classifier, including four classes from trials in which the four RDKs were presented, and an additional class comprising an equivalent amount of null data extracted from the 1–1.5 s ITI. Null data were included to reduce the spatial correlation among the classes, thereby concurrently lowering the decoding probabilities for all classes (<xref ref-type="bibr" rid="bib52">Liu et al., 2021a</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>). Class weights were balanced by adjusting inversely proportional to class frequencies (i.e. trial numbers) in the training procedure. To reduce noise, MEG signals were averaged across every five trials within the same class before decoding.</p><p>The trained classifier was then applied to MEG signals at each time point in the main phase, and decoding probabilities were computed as the outputs of the classifier. Different from the conventional decoding accuracy, where the classifier predicts a single label at each time point, decoding probabilities provide a likelihood estimate for each class. In our study, the classifier outputs a five-column matrix for all trials, where each row represents a single trial and each column represents the probability for one class (i.e. one of the four RDKs and blank ITI). The probabilities in each row sum to 1, reflecting the relative likelihoods across all classes for that trial. The highest probability determines the decoded label when computing decoding accuracy. Finally, averaging these probabilities across trials yields five values that indicate the overall likelihood of the predicted stimulus belonging to a given class.</p></sec><sec id="s4-6"><title>Optimal time point of motion direction representation</title><p>The optimal time point of motion direction representation was considered as the time point with the highest decoding accuracy in the functional localizer data. To index the optimal time point of each motion direction for each participant, we conducted a time-resolved motion direction decoding analysis on the functional localizer data using Lasso-regularized logistic regression models. A leave-one-trial-out cross-validation procedure was used to train the classifier to determine one of the four motion directions, yielding a decoding accuracy at each time point for each participant. Finally, the time point with the highest decoding accuracy was independently extracted for each participant and each motion direction. These time points are referred to as optimal time points and were used for training feature-specific decoding models.</p></sec><sec id="s4-7"><title>Sequenceness measure</title><p>To identify sequenceness during the post-cue blank period in each trial, we trained models to detect transient spontaneous neural reactivation of each motion direction representation. Therefore, a one-versus-rest Lasso-regularized logistic regression model was trained separately for each participant and motion direction using the functional localizer data. MEG signals from the 72 occipital sensors obtained throughout all localizer scanning sessions were used to train the decoding models. As our aim was to quantify the evidence of feature-specific sequence, for each motion direction, we trained a binomial classifier, using positive instances from trials in which that feature (e.g. 0°) was presented and negative instances from trials in which all other features (e.g. 90°, 180°, and 270°) were presented, together with an equivalent amount of null data from the 1–1.5 s ITI. The sensor distributions of beta estimates and the spatial correlation among the classifiers are shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>.</p><p>The analysis pipeline of sequenceness is illustrated in <xref ref-type="fig" rid="fig3">Figure 3</xref>. We first applied the trained models to MEG signals at each time point during the blank period to generate a [time × motion direction] reactivation probability (i.e. decoding probability) matrix for each trial (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). The TDLM framework was then used to quantify evidence for sequential reactivations consistent with the exposed motion sequence (<xref ref-type="bibr" rid="bib53">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>).</p><p>TDLM is a multiple linear regression approach to quantify the extent to which a lagged reactivation time course of one motion direction i (denoted as X(∆t)<sub>i</sub>, where ∆t indicates lag time) can predict the reactivation time course of another motion direction j (denoted as X<sub>j</sub>). Two steps were included in this pipeline. First, we performed multiple separate regressions using the reactivation time course of each motion direction j (where j ∈ [1: 4]) as the dependent variable. The predictors were the time-lagged reactivation time courses of all four motion directions i (where i ∈ [1: 4]). The regression model can be expressed as:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mi>X</mml:mi><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The predictor X(∆t)<sub>i</sub> was a ∆t-lagged copy of the reactivation time course of X<sub>i</sub>. The regression coefficients β(∆t)<sub>i,j</sub> quantified the strength of the empirical reactivation pattern from motion direction i to motion direction j at a given time lag, ∆t. For example, if X<sub>j</sub> represents the reactivation time course of 0° during the blank period in the main phase, and X<sub>i</sub> represents the reactivation time course of 90° during the same period, then β(∆t)<sub>i,j</sub> is the coefficient that captures the unique variance in the reactivation time course of 0° explained by the ∆t-lagged reactivation time course of 90° (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, first-level GLM analysis). Finally, all such first-level coefficients were placed in a lag-specific [4×4] empirical transition matrix Β, representing evidence for all possible transitions at a specific lag.</p><p>In the second step, we quantified the extent to which this empirical transition matrix Β could be predicted by a model transition matrix reflecting the sequence of interest, e.g., the exposed motion sequence (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, second-level GLM analysis; 1 for transitions of interest and 0 otherwise). We separately modeled forward transitions (T<sub>F</sub>), which followed the order of the motion sequence, and backward transitions (T<sub>B</sub>), which followed the reverse order. The strength of these sequences was measured by:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where Β is the [4×4] empirical (lag-specific) transition matrix obtained from the data, T<sub>r</sub> is a [4×4] model transition matrix (for regressor r), and Z<sub>r</sub> is the scalar regression coefficient quantifying the extent to which the model transition matrix T<sub>r</sub> predicts the empirical transitions, Β. We included four model transition matrices as regressors: (1) T<sub>F</sub>: transitions as in the motion sequence in the forward direction (transitions corresponding to [0° → 90° → 180° → 270°]), (2) T<sub>B</sub>: transitions opposite to the motion sequence in the backward direction ([270° → 180° → 90° → 0°], T<sub>B</sub> is the transpose of T<sub>F</sub>), (3) T<sub>auto</sub>: self-transitions to control for autocorrelation ([4×4] identity matrix), and (4) T<sub>const</sub>: a constant matrix to model away the average of all transitions, ensuring that any weight on T<sub>F</sub> and T<sub>B</sub> was not due to general background neural dynamics.</p><p>Notably, the estimate of sequence strength, Z<sub>r</sub>, is a relative measure. For instance, a Z<sub>r</sub> value of zero for the transition from 0° to 90° does not indicate an absence of replay for that transition; rather, it reflects that the strength of replay of 0° → 90° is not stronger than that of other transitions. Repeating the regression in Equation 2 at each time lag (∆t=4, 8, 12,…, 600 ms) results in both forward (i.e. Z<sub>1</sub>) and backward (i.e. Z<sub>2</sub>) sequence strength as a function of time lag. Shorter lags indicate greater time compression, corresponding to faster speeds.</p><p>In the current study, sequenceness was defined as the contrast between the evidence for replay of the motion sequence in the forward direction ([0° → 90° → 180° → 270°]) versus the backward direction ([270° → 180° → 90° → 0°]). Specifically, sequenceness was calculated as the difference between the regression coefficients for forward and backward transitions (i.e. Z<sub>1</sub> – Z<sub>2</sub>). This contrast controls for between-participant variance in the sequential replay per se, which may arise from factors such as task engagement or measurement sensitivity (<xref ref-type="bibr" rid="bib52">Liu et al., 2021a</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>). As sequenceness is derived from regression coefficients, it is inherently a unitless measure. Positive sequenceness values indicate replay in a predominantly forward direction, whereas negative sequenceness values indicate replay in a predominantly backward direction.</p><p>For statistical inference, we used nonparametric permutation tests involving all possible permutations of the stimulus labels at the second-level regression, equivalent to permuting the rows and columns together of the transition matrices used to calculate sequenceness. For each permutation, we calculated the peak absolute mean sequence strength over participants and across lags (controlling for multiple comparisons across lags). Sequence strength in unpermuted data was considered significant if its absolute magnitude was &gt;95% of the within-permutation peak.</p></sec><sec id="s4-8"><title>Identifying replay onsets and analyzing time-frequency</title><p>Having identified that the replay transition at the group level was a 32 ms-lag, we next identified replay onsets. Replay onset was defined as the time point when a strong reactivation of one motion direction (e.g. 0°) was followed by a strong reactivation of the next motion direction (e.g. 90°) in the sequence, with a 32 ms-lag (<xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib60">Nour et al., 2021</xref>). We first generated a matrix Orig as<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>O</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:mo>∗</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where X is the [time × motion direction] reactivation matrix, and T is the backward transition matrix. The transition matrix T defines the mapping between the motion direction corresponding to column i in X and column i in Orig. For example, column 1 in X is the reactivation time course of the motion direction 0°, while column 1 in Orig is the reactivation time course of the motion direction 90°. We then shifted each column of X by ∆t=32 ms to generate another matrix Proj,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where row i in Proj corresponds to row i+32 ms in X. Next, we multiplied Proj and Orig elementwise, summing over the columns of the resulting matrix; therefore, creating a [time × 1] vector, R, in which each element (i.e. row) indicates the strength of replay with a 32 ms-lag at a given time.<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:mi>O</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>j</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Finally, we identified putative replay event onsets by thresholding R at its 95th percentile, preceded by a 100 ms pre-onset baseline exhibiting a low probability of replay at each time point.</p><p>We then epoched MEG data in the blank period surrounding each onset and computed a frequency decomposition (wavelet transformation) in the time window of −100 ms to 150 ms using all sensors. We aimed to find evidence for the power increase in the high-frequency (120–160 Hz) region of interest at replay onset, compared with a pre-onset baseline (−100 ms to −50 ms from onset), similar to a previous study (<xref ref-type="bibr" rid="bib50">Liu et al., 2019</xref>). Finally, we generated two separate [time × frequency] matrices (i.e. using forward and backward transition matrices separately) by averaging estimates over sensors and events, capturing the typical spectrum-resolved power change at replay onset.</p></sec><sec id="s4-9"><title>MEG source reconstruction</title><p>We identified the neural sources associated with increased ripple power at putative replay onsets. Forward models were generated based on a single shell using the superposition of basic functions that approximately correspond to the plane tangential to the MEG sensor array. LCMV beamforming (<xref ref-type="bibr" rid="bib77">Van Veen et al., 1997</xref>) was used to reconstruct the epoched MEG data to a grid in MNI space (grid step, 5 mm). The sensor covariance matrix for beamforming was estimated using broadband power data across all frequencies. The baseline activity was the mean activity averaged over −100 ms to −50 ms relative to replay onset. All nonartifactual replay epochs were baseline-corrected at source level. We obtained whole-brain results for voxels predicted by participant-specific ripple power at replay onset. Nonparametric permutation tests were performed on the volume of interest to compute the multiple comparison p values of clusters &gt;10 voxels (whole-brain corrected, cluster-defining threshold; t=3.1, n=5000 permutations).</p></sec><sec id="s4-10"><title>Statistical analysis</title><p>Statistical analyses for MEG data are described in the corresponding Materials and methods section. Specifically, all statistical tests were performed using nonparametric permutation methods. For ERFs, nonparametric cluster-based one-sample t-tests were conducted with a cluster-defining threshold of t=3.1. Clusters spanning more than 10 consecutive time points were considered significant, based on 5000 permutations. For TDLM, nonparametric permutation tests were performed by permuting all possible stimulus label assignments at the second-level regression. Sequenceness was considered significant if its absolute magnitude was &gt;95% of the within-permutation peak. For time-frequency analyses, a nonparametric cluster-based permutation test was applied (cluster-forming threshold: t&gt;3.1; 5000 permutations). For MEG source reconstruction, nonparametric permutation tests were conducted within the volume of interest to identify significant clusters (&gt;10 voxels) using a cluster-defining threshold of t=3.1 and 5000 permutations. All statistical analyses were performed using custom Python scripts.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Validation, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Supervision, Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con5"><p>Supervision, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Resources, Supervision, Funding acquisition, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>The experiments reported here were carried out in accordance with the guidelines expressed in the Declaration of Helsinki. All participants provided written informed consent in accordance with the procedures and protocols approved by the Human Subject Review Committee of Peking University (#2021-10-13).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-101511-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>TDLM MATLAB code is available on <ext-link ext-link-type="uri" xlink:href="https://github.com/YunzheLiu/TDLM">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib51">Liu, 2021</xref>). Custom code and data have been deposited at the Open Science Framework (<ext-link ext-link-type="uri" xlink:href="https://osf.io/hdjtr/">https://osf.io/hdjtr/</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>He</surname><given-names>T</given-names></name><name><surname>Gong</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Fang</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Non-feature-specific elevated responses and feature-specific backward replay in human brain induced by visual sequence exposure</data-title><source>Open Science Framework</source><pub-id pub-id-type="doi">10.17605/OSF.IO/HDJTR</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This study was supported by the National Science and Technology Innovation 2030 Major Program (2022ZD0204802) to FF, the National Natural Science Foundation of China (T2421004, 31930053) to FF, the National Natural Science Foundation of China (32400874) to TH, Beijing Natural Science Foundation (5244044) to TH, and the Young Scientists Fund of the Humanities and Social Science Foundation of Ministry of Education of China (23YJCZH071) to TH.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarez</surname><given-names>P</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Memory consolidation and the medial temporal lobe: a simple network model</article-title><source>PNAS</source><volume>91</volume><fpage>7041</fpage><lpage>7045</lpage><pub-id pub-id-type="doi">10.1073/pnas.91.15.7041</pub-id><pub-id pub-id-type="pmid">8041742</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ambrose</surname><given-names>RE</given-names></name><name><surname>Pfeiffer</surname><given-names>BE</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reverse replay of hippocampal place cells is uniquely modulated by changing reward</article-title><source>Neuron</source><volume>91</volume><fpage>1124</fpage><lpage>1136</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.047</pub-id><pub-id pub-id-type="pmid">27568518</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auksztulewicz</surname><given-names>R</given-names></name><name><surname>Myers</surname><given-names>NE</given-names></name><name><surname>Schnupp</surname><given-names>JW</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Rhythmic temporal expectation boosts neural activity by increasing neural gain</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>9806</fpage><lpage>9817</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0925-19.2019</pub-id><pub-id pub-id-type="pmid">31662425</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>R</given-names></name><name><surname>Dexter</surname><given-names>M</given-names></name><name><surname>Hardwicke</surname><given-names>TE</given-names></name><name><surname>Goldstone</surname><given-names>A</given-names></name><name><surname>Kourtzi</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning to predict: exposure to temporal sequences facilitates prediction of future events</article-title><source>Vision Research</source><volume>99</volume><fpage>124</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2013.10.017</pub-id><pub-id pub-id-type="pmid">24231115</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barne</surname><given-names>LC</given-names></name><name><surname>Cravo</surname><given-names>AM</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name><name><surname>Spaak</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Temporal prediction elicits rhythmic preactivation of relevant sensory cortices</article-title><source>The European Journal of Neuroscience</source><volume>55</volume><fpage>3324</fpage><lpage>3339</lpage><pub-id pub-id-type="doi">10.1111/ejn.15405</pub-id><pub-id pub-id-type="pmid">34322927</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buch</surname><given-names>ER</given-names></name><name><surname>Claudino</surname><given-names>L</given-names></name><name><surname>Quentin</surname><given-names>R</given-names></name><name><surname>Bönstrup</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Consolidation of human skill linked to waking hippocampo-neocortical replay</article-title><source>Cell Reports</source><volume>35</volume><elocation-id>109193</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.109193</pub-id><pub-id pub-id-type="pmid">34107255</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buonomano</surname><given-names>DV</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>CORTICAL PLASTICITY: from synapses to maps</article-title><source>Annual Review of Neuroscience</source><volume>21</volume><fpage>149</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.21.1.149</pub-id><pub-id pub-id-type="pmid">9530495</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Ripple band phase precession of place cell firing during replay</article-title><source>Current Biology</source><volume>32</volume><fpage>64</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.10.033</pub-id><pub-id pub-id-type="pmid">34731677</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Hippocampal sharp waves: their origin and significance</article-title><source>Brain Research</source><volume>398</volume><fpage>242</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(86)91483-6</pub-id><pub-id pub-id-type="pmid">3026567</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The hippocampo-neocortical dialogue</article-title><source>Cerebral Cortex</source><volume>6</volume><fpage>81</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1093/cercor/6.2.81</pub-id><pub-id pub-id-type="pmid">8670641</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal sharp wave-ripple: a cognitive biomarker for episodic memory and planning</article-title><source>Hippocampus</source><volume>25</volume><fpage>1073</fpage><lpage>1188</lpage><pub-id pub-id-type="doi">10.1002/hipo.22488</pub-id><pub-id pub-id-type="pmid">26135716</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname><given-names>MF</given-names></name><name><surname>Jadhav</surname><given-names>SP</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>147</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1038/nn.2732</pub-id><pub-id pub-id-type="pmid">21270783</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>N</given-names></name><name><surname>Cai</surname><given-names>P</given-names></name><name><surname>Zhou</surname><given-names>T</given-names></name><name><surname>Thompson</surname><given-names>B</given-names></name><name><surname>Fang</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Perceptual learning modifies the functional specializations of visual cortical areas</article-title><source>PNAS</source><volume>113</volume><fpage>5724</fpage><lpage>5729</lpage><pub-id pub-id-type="doi">10.1073/pnas.1524160113</pub-id><pub-id pub-id-type="pmid">27051066</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Memory deficits for implicit contextual information in amnesic subjects with hippocampal damage</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>844</fpage><lpage>847</lpage><pub-id pub-id-type="doi">10.1038/12222</pub-id><pub-id pub-id-type="pmid">10461225</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Costandi</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Neuroplasticity</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/10499.001.0001</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demarchi</surname><given-names>G</given-names></name><name><surname>Sanchez</surname><given-names>G</given-names></name><name><surname>Weisz</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Automatic and feature-specific prediction-related neural activity in the human auditory system</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>3440</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-11440-1</pub-id><pub-id pub-id-type="pmid">31371713</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diba</surname><given-names>K</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1241</fpage><lpage>1242</lpage><pub-id pub-id-type="doi">10.1038/nn1961</pub-id><pub-id pub-id-type="pmid">17828259</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimakopoulos</surname><given-names>V</given-names></name><name><surname>Mégevand</surname><given-names>P</given-names></name><name><surname>Stieglitz</surname><given-names>LH</given-names></name><name><surname>Imbach</surname><given-names>L</given-names></name><name><surname>Sarnthein</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Information flows from hippocampus to auditory cortex during replay of verbal working memory items</article-title><source>eLife</source><volume>11</volume><elocation-id>e78677</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.78677</pub-id><pub-id pub-id-type="pmid">35960169</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eagleman</surname><given-names>SL</given-names></name><name><surname>Dragoi</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Image sequence reactivation in awake V4 networks</article-title><source>PNAS</source><volume>109</volume><fpage>19450</fpage><lpage>19455</lpage><pub-id pub-id-type="doi">10.1073/pnas.1212059109</pub-id><pub-id pub-id-type="pmid">23129638</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenbaum</surname><given-names>H</given-names></name><name><surname>Yonelinas</surname><given-names>AP</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The medial temporal lobe and recognition memory</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>123</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.30.051606.094328</pub-id><pub-id pub-id-type="pmid">17417939</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>M</given-names></name><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Time-compressed preplay of anticipated events in human primary visual cortex</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>15276</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms15276</pub-id><pub-id pub-id-type="pmid">28534870</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>M</given-names></name><name><surname>Kusch</surname><given-names>S</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Successor-like representation guides the prediction of future events in human visual cortex and hippocampus</article-title><source>eLife</source><volume>12</volume><elocation-id>e78904</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.78904</pub-id><pub-id pub-id-type="pmid">36729024</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fang</surname><given-names>F</given-names></name><name><surname>Murray</surname><given-names>SO</given-names></name><name><surname>Kersten</surname><given-names>D</given-names></name><name><surname>He</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Orientation-tuned FMRI adaptation in human visual cortex</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>4188</fpage><lpage>4195</lpage><pub-id pub-id-type="doi">10.1152/jn.00378.2005</pub-id><pub-id pub-id-type="pmid">16120668</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finnie</surname><given-names>PSB</given-names></name><name><surname>Komorowski</surname><given-names>RW</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The spatiotemporal organization of experience dictates hippocampal involvement in primary visual cortical plasticity</article-title><source>Current Biology</source><volume>31</volume><fpage>3996</fpage><lpage>4008</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.06.079</pub-id><pub-id pub-id-type="pmid">34314678</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title><source>Nature</source><volume>440</volume><fpage>680</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/nature04587</pub-id><pub-id pub-id-type="pmid">16474382</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garvert</surname><given-names>MM</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A map of abstract relational knowledge in the human hippocampal-entorhinal cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e17086</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17086</pub-id><pub-id pub-id-type="pmid">28448253</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gavornik</surname><given-names>JP</given-names></name><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learned spatiotemporal sequence recognition and prediction in primary visual cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>732</fpage><lpage>737</lpage><pub-id pub-id-type="doi">10.1038/nn.3683</pub-id><pub-id pub-id-type="pmid">24657967</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gillespie</surname><given-names>AK</given-names></name><name><surname>Astudillo Maya</surname><given-names>DA</given-names></name><name><surname>Denovellis</surname><given-names>EL</given-names></name><name><surname>Liu</surname><given-names>DF</given-names></name><name><surname>Kastner</surname><given-names>DB</given-names></name><name><surname>Coulter</surname><given-names>ME</given-names></name><name><surname>Roumis</surname><given-names>DK</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Hippocampal replay reflects specific past experiences rather than a plan for subsequent choice</article-title><source>Neuron</source><volume>109</volume><fpage>3149</fpage><lpage>3163</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.07.029</pub-id><pub-id pub-id-type="pmid">34450026</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gothard</surname><given-names>KM</given-names></name><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>Moore</surname><given-names>KM</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Binding of hippocampal CA1 neural activity to multiple reference frames in a landmark-based navigation task</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>823</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-02-00823.1996</pub-id><pub-id pub-id-type="pmid">8551362</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gridchyn</surname><given-names>I</given-names></name><name><surname>Schoenenberger</surname><given-names>P</given-names></name><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Assembly-specific disruption of hippocampal replay leads to selective memory deficit</article-title><source>Neuron</source><volume>106</volume><fpage>291</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.01.021</pub-id><pub-id pub-id-type="pmid">32070475</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gutnisky</surname><given-names>DA</given-names></name><name><surname>Hansen</surname><given-names>BJ</given-names></name><name><surname>Iliescu</surname><given-names>BF</given-names></name><name><surname>Dragoi</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention alters visual plasticity during exposure-based learning</article-title><source>Current Biology</source><volume>19</volume><fpage>555</fpage><lpage>560</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2009.01.063</pub-id><pub-id pub-id-type="pmid">19268592</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hannula</surname><given-names>DE</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Cohen</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The long and the short of it: relational memory impairments in amnesia, even at short lags</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>8352</fpage><lpage>8359</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5222-05.2006</pub-id><pub-id pub-id-type="pmid">16899730</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henke</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A model for memory systems based on processing modes rather than consciousness</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>523</fpage><lpage>532</lpage><pub-id pub-id-type="doi">10.1038/nrn2850</pub-id><pub-id pub-id-type="pmid">20531422</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrmann</surname><given-names>B</given-names></name><name><surname>Henry</surname><given-names>MJ</given-names></name><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Obleser</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temporal expectations and neural amplitude fluctuations in auditory cortex interactively influence perception</article-title><source>NeuroImage</source><volume>124</volume><fpage>487</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.09.019</pub-id><pub-id pub-id-type="pmid">26386347</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hindy</surname><given-names>NC</given-names></name><name><surname>Ng</surname><given-names>FY</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Linking pattern completion in the hippocampus to predictive coding in visual cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>665</fpage><lpage>667</lpage><pub-id pub-id-type="doi">10.1038/nn.4284</pub-id><pub-id pub-id-type="pmid">27065363</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsieh</surname><given-names>LT</given-names></name><name><surname>Gruber</surname><given-names>MJ</given-names></name><name><surname>Jenkins</surname><given-names>LJ</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hippocampal activity patterns carry information about objects in temporal context</article-title><source>Neuron</source><volume>81</volume><fpage>1165</fpage><lpage>1178</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.015</pub-id><pub-id pub-id-type="pmid">24607234</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Igata</surname><given-names>H</given-names></name><name><surname>Ikegaya</surname><given-names>Y</given-names></name><name><surname>Sasaki</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Prioritized experience replays on a hippocampal predictive map for learning</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2011266118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2011266118</pub-id><pub-id pub-id-type="pmid">33443144</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>D</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Coordinated memory replay in the visual cortex and hippocampus during sleep</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>100</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1038/nn1825</pub-id><pub-id pub-id-type="pmid">17173043</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joo</surname><given-names>HR</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampal sharp wave-ripple in memory retrieval for immediate use and consolidation</article-title><source>Nature Reviews. Neuroscience</source><volume>19</volume><fpage>744</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.1038/s41583-018-0077-1</pub-id><pub-id pub-id-type="pmid">30356103</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Jehee</surname><given-names>JFM</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Less is more: expectation sharpens representations in the primary visual cortex</article-title><source>Neuron</source><volume>75</volume><fpage>265</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.034</pub-id><pub-id pub-id-type="pmid">22841311</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Failing</surname><given-names>MF</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Prior expectations evoke stimulus templates in the primary visual cortex</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>1546</fpage><lpage>1554</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00562</pub-id><pub-id pub-id-type="pmid">24392894</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Mostert</surname><given-names>P</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Prior expectations induce prestimulus sensory templates</article-title><source>PNAS</source><volume>114</volume><fpage>10473</fpage><lpage>10478</lpage><pub-id pub-id-type="doi">10.1073/pnas.1705652114</pub-id><pub-id pub-id-type="pmid">28900010</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>P</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Associative prediction of visual shape in the hippocampus</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>6888</fpage><lpage>6899</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0163-18.2018</pub-id><pub-id pub-id-type="pmid">29986875</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Konkel</surname><given-names>A</given-names></name><name><surname>Warren</surname><given-names>D</given-names></name><name><surname>Duff</surname><given-names>M</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Cohen</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Hippocampal amnesia impairs all manner of relational memory</article-title><ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/article/10.3389/neuro.09.015.2008">https://www.frontiersin.org/article/10.3389/neuro.09.015.2008</ext-link><date-in-citation iso-8601-date="2022-05-26">May 26, 2022</date-in-citation></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Economides</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fast sequences of non-spatial state representations in humans</article-title><source>Neuron</source><volume>91</volume><fpage>194</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.028</pub-id><pub-id pub-id-type="pmid">27321922</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Karmos</surname><given-names>G</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Ulbert</surname><given-names>I</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Entrainment of neuronal oscillations as a mechanism of attentional selection</article-title><source>Science</source><volume>320</volume><fpage>110</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1126/science.1154735</pub-id><pub-id pub-id-type="pmid">18388295</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Musacchia</surname><given-names>G</given-names></name><name><surname>O’Connel</surname><given-names>MN</given-names></name><name><surname>Falchier</surname><given-names>AY</given-names></name><name><surname>Javitt</surname><given-names>DC</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The spectrotemporal filter mechanism of auditory selective attention</article-title><source>Neuron</source><volume>77</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.034</pub-id><pub-id pub-id-type="pmid">23439126</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title><source>Neuron</source><volume>36</volume><fpage>1183</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01096-6</pub-id><pub-id pub-id-type="pmid">12495631</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Perceptual learning: use-dependent cortical plasticity</article-title><source>Annual Review of Vision Science</source><volume>2</volume><fpage>109</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-111815-114351</pub-id><pub-id pub-id-type="pmid">28532348</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Human replay spontaneously reorganizes experience</article-title><source>Cell</source><volume>178</volume><fpage>640</fpage><lpage>652</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id><pub-id pub-id-type="pmid">31280961</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>TDLM</data-title><version designator="swh:1:rev:015c0e90a14d3786e071345760b97141700d6c85">swh:1:rev:015c0e90a14d3786e071345760b97141700d6c85</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:6822eebf5feccfabbbe8c533d5349143143693bd;origin=https://github.com/YunzheLiu/TDLM;visit=swh:1:snp:ab7bd472ff9da660c539a38b210347cb4ad44e3e;anchor=swh:1:rev:015c0e90a14d3786e071345760b97141700d6c85">https://archive.softwareheritage.org/swh:1:dir:6822eebf5feccfabbbe8c533d5349143143693bd;origin=https://github.com/YunzheLiu/TDLM;visit=swh:1:snp:ab7bd472ff9da660c539a38b210347cb4ad44e3e;anchor=swh:1:rev:015c0e90a14d3786e071345760b97141700d6c85</ext-link></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Higgins</surname><given-names>C</given-names></name><name><surname>Penagos</surname><given-names>H</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Temporally delayed linear modelling (TDLM) measures replay in both animals and humans</article-title><source>eLife</source><volume>10</volume><elocation-id>e66917</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.66917</pub-id><pub-id pub-id-type="pmid">34096501</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Experience replay is associated with efficient nonlocal learning</article-title><ext-link ext-link-type="uri" xlink:href="https://science.sciencemag.org/content/372/6544/eabf1357">https://science.sciencemag.org/content/372/6544/eabf1357</ext-link><date-in-citation iso-8601-date="2021-05-21">May 21, 2021</date-in-citation></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Nour</surname><given-names>MM</given-names></name><name><surname>Schuck</surname><given-names>NW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Decoding cognition from spontaneous neural activity</article-title><source>Nature Reviews. Neuroscience</source><volume>23</volume><fpage>204</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1038/s41583-022-00570-z</pub-id><pub-id pub-id-type="pmid">35260845</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>J</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Fang</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cue-triggered activity replay in human early visual cortex</article-title><source>Science China. Life Sciences</source><volume>64</volume><fpage>144</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1007/s11427-020-1726-5</pub-id><pub-id pub-id-type="pmid">32557289</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>ZL</given-names></name><name><surname>Dosher</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Current directions in visual perceptual learning</article-title><source>Nature Reviews Psychology</source><volume>1</volume><fpage>654</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1038/s44159-022-00107-2</pub-id><pub-id pub-id-type="pmid">37274562</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name><name><surname>Brindley</surname><given-names>GS</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Simple memory: a theory for archicortex</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>262</volume><fpage>23</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1098/rstb.1971.0078</pub-id><pub-id pub-id-type="pmid">4399412</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFadyen</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Differential replay of reward and punishment paths predicts approach and avoidance</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>627</fpage><lpage>637</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01287-7</pub-id><pub-id pub-id-type="pmid">37020116</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mo</surname><given-names>C</given-names></name><name><surname>Lu</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>B</given-names></name><name><surname>Jia</surname><given-names>J</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name><name><surname>Fang</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Competing rhythmic neural representations of orientations during concurrent attention to multiple orientation features</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>5264</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-13282-3</pub-id><pub-id pub-id-type="pmid">31748562</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nour</surname><given-names>MM</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Arumuham</surname><given-names>A</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Impaired neural replay of inferred relationships in schizophrenia</article-title><source>Cell</source><volume>184</volume><fpage>4315</fpage><lpage>4328</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2021.06.012</pub-id><pub-id pub-id-type="pmid">34197734</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The Hippocampus as a Cognitive Map</source><publisher-loc>Oxford : New York</publisher-loc><publisher-name>Clarendon Press ; Oxford University Press</publisher-name></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal place cells construct reward related sequences through unexplored space</article-title><source>eLife</source><volume>4</volume><elocation-id>e06063</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06063</pub-id><pub-id pub-id-type="pmid">26112828</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Carpenter</surname><given-names>F</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Coordinated grid and place cell replay during rest</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>792</fpage><lpage>794</lpage><pub-id pub-id-type="doi">10.1038/nn.4291</pub-id><pub-id pub-id-type="pmid">27089021</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Carpenter</surname><given-names>F</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Task demands predict a dynamic switch in the content of awake hippocampal replay</article-title><source>Neuron</source><volume>96</volume><fpage>925</fpage><lpage>935</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.035</pub-id><pub-id pub-id-type="pmid">29056296</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pojoga</surname><given-names>SA</given-names></name><name><surname>Kharas</surname><given-names>N</given-names></name><name><surname>Dragoi</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Perceptually unidentifiable stimuli influence cortical processing and behavioral performance</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>6109</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-19848-w</pub-id><pub-id pub-id-type="pmid">33257683</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redish</surname><given-names>AD</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The role of the hippocampus in solving the Morris water maze</article-title><source>Neural Computation</source><volume>10</volume><fpage>73</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1162/089976698300017908</pub-id><pub-id pub-id-type="pmid">9501505</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redish</surname><given-names>AD</given-names></name><name><surname>Rosenzweig</surname><given-names>ES</given-names></name><name><surname>Bohanick</surname><given-names>JD</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Dynamics of hippocampal ensemble activity realignment: time versus space</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>9298</fpage><lpage>9309</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-24-09298.2000</pub-id><pub-id pub-id-type="pmid">11125009</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rivard</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Lenck-Santini</surname><given-names>PP</given-names></name><name><surname>Poucet</surname><given-names>B</given-names></name><name><surname>Muller</surname><given-names>RU</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Representation of objects in space by two classes of hippocampal pyramidal cells</article-title><source>The Journal of General Physiology</source><volume>124</volume><fpage>9</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1085/jgp.200409015</pub-id><pub-id pub-id-type="pmid">15197223</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Early visual cortex as a multiscale cognitive blackboard</article-title><source>Annual Review of Vision Science</source><volume>2</volume><fpage>131</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-111815-114443</pub-id><pub-id pub-id-type="pmid">28532363</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Hippocampo-cortical and cortico-cortical backprojections</article-title><source>Hippocampus</source><volume>10</volume><fpage>380</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1002/1098-1063(2000)10:4&lt;380::AID-HIPO4&gt;3.0.CO;2-0</pub-id><pub-id pub-id-type="pmid">10985277</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sasaki</surname><given-names>Y</given-names></name><name><surname>Nanez</surname><given-names>JE</given-names></name><name><surname>Watanabe</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Advances in visual perceptual learning and plasticity</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>53</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1038/nrn2737</pub-id><pub-id pub-id-type="pmid">19953104</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Gregory</surname><given-names>E</given-names></name><name><surname>Landau</surname><given-names>B</given-names></name><name><surname>McCloskey</surname><given-names>M</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The necessity of the medial temporal lobe for statistical learning</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>1736</fpage><lpage>1747</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00578</pub-id><pub-id pub-id-type="pmid">24456393</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Mind the gap: binding experiences across space and time in the human hippocampus</article-title><source>Neuron</source><volume>63</volume><fpage>267</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.06.024</pub-id><pub-id pub-id-type="pmid">19640484</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taulu</surname><given-names>S</given-names></name><name><surname>Simola</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spatiotemporal signal space separation method for rejecting nearby interference in MEG measurements</article-title><source>Physics in Medicine and Biology</source><volume>51</volume><fpage>1759</fpage><lpage>1768</lpage><pub-id pub-id-type="doi">10.1088/0031-9155/51/7/008</pub-id><pub-id pub-id-type="pmid">16552102</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Scholl</surname><given-names>BJ</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name><name><surname>Johnson</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural evidence of statistical learning: efficient detection of visual regularities without awareness</article-title><source>Journal of Cognitive Neuroscience</source><volume>21</volume><fpage>1934</fpage><lpage>1945</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21131</pub-id><pub-id pub-id-type="pmid">18823241</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>W</given-names></name><name><surname>Blom</surname><given-names>T</given-names></name><name><surname>Hogendoorn</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Visual information is predictively encoded in occipital alpha/low-beta oscillations</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>5537</fpage><lpage>5545</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0135-23.2023</pub-id><pub-id pub-id-type="pmid">37344235</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Veen</surname><given-names>BD</given-names></name><name><surname>van Drongelen</surname><given-names>W</given-names></name><name><surname>Yuchtman</surname><given-names>M</given-names></name><name><surname>Suzuki</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Localization of brain electrical activity via linearly constrained minimum variance spatial filtering</article-title><source>IEEE Transactions on Bio-Medical Engineering</source><volume>44</volume><fpage>867</fpage><lpage>880</lpage><pub-id pub-id-type="doi">10.1109/10.623056</pub-id><pub-id pub-id-type="pmid">9282479</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>T</given-names></name><name><surname>Sasaki</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Perceptual learning: toward a comprehensive theory</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>197</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015214</pub-id><pub-id pub-id-type="pmid">25251494</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The tolman-eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation</article-title><source>Cell</source><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id><pub-id pub-id-type="pmid">33181068</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>GE</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Vehar</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Episodic memory retrieval success is associated with rapid replay of episode content</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1025</fpage><lpage>1033</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0649-z</pub-id><pub-id pub-id-type="pmid">32514135</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dissociable prior influences of signal probability and relevance on visual contrast sensitivity</article-title><source>PNAS</source><volume>109</volume><fpage>3593</fpage><lpage>3598</lpage><pub-id pub-id-type="doi">10.1073/pnas.1120118109</pub-id><pub-id pub-id-type="pmid">22331901</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>S</given-names></name><name><surname>Jiang</surname><given-names>W</given-names></name><name><surname>Poo</surname><given-names>M-M</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Activity recall in a visual cortical ensemble</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>449</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1038/nn.3036</pub-id><pub-id pub-id-type="pmid">22267160</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101511.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kok</surname><given-names>Peter</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study investigates both online responses to, and offline replay of, visual motion sequences. Sophisticated MEG analyses provide <bold>convincing</bold> evidence for both feature-specific and non-specific sequence representations. These intriguing findings will be of interest to perception and learning researchers alike.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101511.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The study identifies two types of activation: one that is cue-triggered and non-specific to motion directions, and another that is specific to the exposed motion directions but occurs in a reversed manner. The finding that activity in the medial temporal lobe (MTL) preceded that in the visual cortex suggests that the visual cortex may serve as a platform for the manifestation of replay events, which potentially enhance visual sequence learning.</p><p>Evaluations:</p><p>Identifying the two types of activation after exposure to a sequence of motion directions is very interesting. The experimental design, procedures and analyses are solid. The findings are interesting and novel.</p><p>In the original submission, it was not immediately clear to me why the second type of activation was suggested to occur spontaneously. The procedural differences in the analyses that distinguished between the two types of activation need to be a little better clarified. However, this concern has been satisfactorily addressed in the revision.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101511.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This paper shows and analyzes an interesting phenomenon. It shows that when people are exposed to sequences of moving dots (That is moving dots in one direction, followed by another direction etc.), that showing either the starting movement direction, or ending movement direction causes a coarse-grained brain response that is similar to that elicited by the complete sequence of 4 directions. However, they show by decoding the sensor responses that this brain activity actually does not carry information about the actual sequence and the motion directions, at least not on the time scale of the initial sequence. They also show a reverse reply on a highly-compressed time scale, which is elicited during the period of elevated activity, and activated by the first and last elements of the sequence, but not others. Additionally, these replays seem to occur during periods of cortical ripples, similar to what is found in animal studies.</p><p>These results are intriguing. They are based on MEG recordings in humans, and finding such replays in humans is novel. Also, this is based on what seems to be sophisticated statistical analysis. The statistical methodology seems valid, but due to its complexity it is not easy to understand. The methods especially those described in figures 3 and 4 should be explained better.</p><p>Comments on second revised version by editorial team:</p><p>In response to the reviewer, the authors have substantially expanded and clarified their description of the methodology in this version of the manuscript.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101511.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>He</surname><given-names>Tao</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Gong</surname><given-names>Xizi</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Qian</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhu</surname><given-names>Xinyi</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Yunzhe</given-names></name><role specific-use="author">Author</role><aff><institution>Chinese Institute for Brain Research</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Fang</surname><given-names>Fang</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>The study identifies two types of activation: one that is cue-triggered and nonspecific to motion directions, and another that is specific to the exposed motion directions but occurs in a reversed manner. The finding that activity in the medial temporal lobe (MTL) preceded that in the visual cortex suggests that the visual cortex may serve as a platform for the manifestation of replay events, which potentially enhance visual sequence learning.</p><p>Evaluations:</p><p>Identifying the two types of activation after exposure to a sequence of motion directions is very interesting. The experimental design, procedures and analyses are solid. The findings are interesting and novel.</p><p>In the original submission, it was not immediately clear to me why the second type of activation was suggested to occur spontaneously. The procedural differences in the analyses that distinguished between the two types of activation need to be a little better clarified. However, this concern has been satisfactorily addressed in the revision.</p></disp-quote><p>We thank the reviewer for his/her positive evaluation and thoughtful comments.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>This paper shows and analyzes an interesting phenomenon. It shows that when people are exposed to sequences of moving dots (That is moving dots in one direction, followed by another direction etc.), that showing either the starting movement direction, or ending movement direction causes a coarsegrained brain response that is similar to that elicited by the complete sequence of 4 directions. However, they show by decoding the sensor responses that this brain activity actually does not carry information about the actual sequence and the motion directions, at least not on the time scale of the initial sequence. They also show a reverse reply on a highly-compressed time scale, which is elicited during the period of elevated activity, and activated by the first and last elements of the sequence, but not others. Additionally, these replays seem to occur during periods of cortical ripples, similar to what is found in animal studies.</p><p>These results are intriguing. They are based on MEG recordings in humans, and finding such replays in humans is novel. Also, this is based on what seems to be sophisticated statistical analysis. The statistical methodology seems valid, but due to its complexity it is not easy to understand. The methods especially those described in figures 3 and 4 should be explained better.</p></disp-quote><p>We thank the reviewer’s detailed evaluation. As suggested, we have further revised the Methods and Results sections, particularly the descriptions related to Figures 3 and 4, to enhance clarity. Please see the revisions highlighted in red in the revised manuscript.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>The most important results here are in Figure 4, and they rely on methods explained in Figure 3. Figure 4 and the results in the figure are confusing.</p><p>What is the red bar in 4B,E. What are the units of the Y axis in figure 4B,E?</p><p>Does sequenceness have units? How do we interpret these magnitudes apart from the line of statistical significance? Shouldn't there be two lines, one for forward replay and the other for backward replay rather than a single line with positive and negative values? The term sequnceness is defined in figure 3, and is key. The replayed sequence in figure 4A,D seems to last about 120 ms.</p><p>What is the meaning of having significance only within a window of 28-36 ms?</p></disp-quote><p>We thank the reviewer’s careful reading and insightful comments. We apologize for the lack of clarity regarding these details in the previous version. As mentioned above, we have revised the Methods and Results sections to enhance clarity throughout the manuscript. For convenience, we provide detailed explanations addressing the specific points raised by the reviewer below.</p><p>First, the red bars in Figures 4B and 4E indicate the lags when the evidence of sequenceness surpassed the statistical significance threshold, as determined by permutation testing. We have now explicitly clarified this in the revised figure captions.</p><p>Second, sequenceness doesn’t have units. It corresponds to the regression coefficient (β) obtained from the second-level GLM in the TDLM framework. Specifically, in the first step of TDLM, we constructed an empirical transition matrix that quantifies the evidence for all possible transitions (e.g., 0° → 90°) at each time lag (Δt). In the second step, we evaluated the extent to which each model transition matrix (e.g., forward or backward transitions) predicts the empirical transition matrix at each Δt, yielding second-level β values. Sequenceness is defined as the difference between the β values for the forward and backward transition models, reflecting the relative strength and directionality of sequential replay. As it is derived from regression coefficients, sequenceness is inherently a unitless measure.</p><p>Regarding the interpretation of sequenceness magnitudes beyond statistical significance, the β values reflect the extent to which the model transition matrix explains variance in the empirical transition matrix. While larger β values suggest stronger sequenceness, absolute magnitudes are influenced by various factors, such as between-participant noise. Therefore, the key criterion for interpreting these values is whether they surpass permutationbased significance thresholds, which indicate that the observed sequenceness is unlikely to have occurred by chance.</p><p>Third, as the reviewer correctly pointed out, we initially computed two separate regression lines, one for forward replay and the other for backward replay. We then defined sequenceness as the contrast between the forward and backward replay (forward minus backward). This contrast approach is commonly used in previous studies to remove between-participant variance in the sequential replay per se, which may arise due to variability in task engagement or measurement sensitivity (Liu et al., 2021; Nour et al., 2021).</p><p>Finally, regarding the duration of replay events, the example sequences shown in Figures 4A and 4D indeed span about 120 ms in total. However, the time lag (Δt) between successive reactivation peaks within these sequences is about 30 ms. This is in line with the findings shown in Figures 4B and 4E, where statistical significance is observed at a time lag window of 28 – 36 ms on the x-axis. It is important to note that the x-axis in these plots represents the time lag (Δt) between sequential reactivations, rather than absolute time.</p><p>We hope these clarifications address the reviewer’s concerns, and we have revised the manuscript accordingly to make these points clearer to readers.</p><disp-quote content-type="editor-comment"><p>The methods here are not simple and not simple to explain. The new version is easier to understand. From the new version it seems that the methodology is sound. It should be still clarified and better explained.</p></disp-quote><p>We have carefully revised the manuscript to better explain the methodology. We appreciate the reviewer’s feedback, which is valuable in improving the clarity of our work.</p><disp-quote content-type="editor-comment"><p>Now that I understand what they mean by decoding probability, I think that this term is confusing or even misleading. The decoding accuracy is the probability that the direction of motion classification was correct. It seems the so-called decoding probability is value of the logistic regression after normalizing the sum to 1. If this is a standard term it can probably be kept, if not another term would be better.</p></disp-quote><p>Thank you for the reviewer’s comment. We agree that the term decoding probability may initially seem confusing. However, decoding probability is a commonly used term in the neural decoding literature, particularly in human studies (e.g., Liu et al., 2019; Nour et al., 2021; Turner et al., 2023). To maintain consistency with previous work, we have kept this term in the manuscript. We appreciate the opportunity to clarify this point.</p><p>References</p><p>Liu, Y., Dolan, R. J., Higgins, C., Penagos, H., Woolrich, M. W., Ólafsdóttir, H. F., Barry, C., Kurth-Nelson, Z., &amp; Behrens, T. E. (2021). Temporally delayed linear modelling (TDLM) measures replay in both animals and humans. eLife, 10, e66917. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.66917">https://doi.org/10.7554/eLife.66917</ext-link></p><p>Liu, Y., Dolan, R. J., Kurth-Nelson, Z., &amp; Behrens, T. E. J. (2019). Human Replay Spontaneously Reorganizes Experience. Cell, 178(3), 640-652.e14. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cell.2019.06.012">https://doi.org/10.1016/j.cell.2019.06.012</ext-link></p><p>Nour, M. M., Liu, Y., Arumuham, A., Kurth-Nelson, Z., &amp; Dolan, R. J. (2021). Impaired neural replay of inferred relationships in schizophrenia. Cell, 184(16), 4315-4328.e17. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cell.2021.06.012">https://doi.org/10.1016/j.cell.2021.06.012</ext-link></p><p>Turner, W., Blom, T., &amp; Hogendoorn, H. (2023). Visual Information Is Predictively Encoded in Occipital Alpha/Low-Beta Oscillations. Journal of Neuroscience, 43(30), 5537–5545. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0135-23.2023">https://doi.org/10.1523/JNEUROSCI.0135-23.2023</ext-link></p></body></sub-article></article>