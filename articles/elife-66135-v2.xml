<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">66135</article-id><article-id pub-id-type="doi">10.7554/eLife.66135</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>Decoding locomotion from population neural activity in moving <italic>C. elegans</italic></article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-221861"><name><surname>Hallinen</surname><given-names>Kelsey M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4081-6699</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-221862"><name><surname>Dempsey</surname><given-names>Ross</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0881-8814</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-136030"><name><surname>Scholz</surname><given-names>Monika</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2186-410X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">‡</xref></contrib><contrib contrib-type="author" id="author-221863"><name><surname>Yu</surname><given-names>Xinwei</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8699-3546</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-221864"><name><surname>Linder</surname><given-names>Ashley</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-221867"><name><surname>Randi</surname><given-names>Francesco</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6200-7254</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-108809"><name><surname>Sharma</surname><given-names>Anuj K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5061-9731</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-17888"><name><surname>Shaevitz</surname><given-names>Joshua W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8809-4723</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-30795"><name><surname>Leifer</surname><given-names>Andrew M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5362-5093</contrib-id><email>leifer@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Physics, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Princeton Neuroscience Institute, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Lewis-Sigler Institute of Integrative Genomics, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Reviewing Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Senior Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>‡</label><p>Max Planck Research Group Neural Information Flow, Center of Advanced European Studies and Research (caesar), Bonn, Germany</p></fn><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>29</day><month>07</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e66135</elocation-id><history><date date-type="received" iso-8601-date="2020-12-29"><day>29</day><month>12</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-07-26"><day>26</day><month>07</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2018-10-17"><day>17</day><month>10</month><year>2018</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/445643"/></event></pub-history><permissions><copyright-statement>© 2021, Hallinen et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Hallinen et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-66135-v2.pdf"/><abstract><p>We investigated the neural representation of locomotion in the nematode <italic>C. elegans</italic> by recording population calcium activity during movement. We report that population activity more accurately decodes locomotion than any single neuron. Relevant signals are distributed across neurons with diverse tunings to locomotion. Two largely distinct subpopulations are informative for decoding velocity and curvature, and different neurons’ activities contribute features relevant for different aspects of a behavior or different instances of a behavioral motif. To validate our measurements, we labeled neurons AVAL and AVAR and found that their activity exhibited expected transients during backward locomotion. Finally, we compared population activity during movement and immobilization. Immobilization alters the correlation structure of neural activity and its dynamics. Some neurons positively correlated with AVA during movement become negatively correlated during immobilization and vice versa. This work provides needed experimental measurements that inform and constrain ongoing efforts to understand population dynamics underlying locomotion in <italic>C. elegans</italic>.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural dynamics</kwd><kwd>calcium imaging</kwd><kwd>locomotion</kwd><kwd>decoding</kwd><kwd>population code</kwd><kwd>behavior</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>C. elegans</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>IOS-1845137</award-id><principal-award-recipient><name><surname>Leifer</surname><given-names>Andrew M</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>PHY-1734030</award-id><principal-award-recipient><name><surname>Hallinen</surname><given-names>Kelsey M</given-names></name><name><surname>Shaevitz</surname><given-names>Joshua W</given-names></name><name><surname>Leifer</surname><given-names>Andrew M</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>MH065214</award-id><principal-award-recipient><name><surname>Linder</surname><given-names>Ashley</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>324285</award-id><principal-award-recipient><name><surname>Leifer</surname><given-names>Andrew M</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>Swartz Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Randi</surname><given-names>Francesco</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Neurons in the brain exhibit activity with various relations to locomotion and these signals are best decoded by combining activities from many neurons.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Patterns of activity in an animal’s brain should contain information about that animal's actions and movements. Systems neuroscience has long sought to understand how the brain represents behavior. Many of these investigations have necessarily focused on single-unit recordings of individual neurons. Such efforts have successfully revealed place cells (<xref ref-type="bibr" rid="bib49">O'Keefe and Dostrovsky, 1971</xref>) and head direction cells (<xref ref-type="bibr" rid="bib60">Taube et al., 1990</xref>; <xref ref-type="bibr" rid="bib25">Hafting et al., 2005</xref>), for example. But there has also been a long history of seeking to understand how neural populations represent motion (<xref ref-type="bibr" rid="bib20">Georgopoulos et al., 1986</xref>; <xref ref-type="bibr" rid="bib11">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib9">Chen et al., 2018</xref>). For example, population recordings from the central complex in <italic>Drosophila</italic> reveal that the animal’s heading is represented in the population by a bump of neural activity in a ring attractor network (<xref ref-type="bibr" rid="bib33">Kim et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Green et al., 2017</xref>). As population and whole-brain recording methods become accessible, it has become clear that locomotory signals are more prevalent and pervasive throughout the brain than previously appreciated. For example, neural signals that correlate with rodent facial expression and body motion were recently reported in sensory areas such as visual cortex (<xref ref-type="bibr" rid="bib58">Stringer et al., 2019</xref>) and in executive decision making areas of dorsal cortex (<xref ref-type="bibr" rid="bib45">Musall et al., 2019</xref>).</p><p>The known locomotory circuitry in <italic>C. elegans</italic> focuses on a collection of pre-motor neurons and interneurons, including AVA, AVE, AVB, AIB, AIZ, RIM, RIA, RIV, RIB, and PVC that have many connections amongst themselves and send signals to downstream motor neurons involved in locomotion such as the A- or B-type or SMD motor neurons (<xref ref-type="bibr" rid="bib66">White et al., 1976</xref>; <xref ref-type="bibr" rid="bib7">Chalfie et al., 1985</xref>; <xref ref-type="bibr" rid="bib70">Zheng et al., 1999</xref>; <xref ref-type="bibr" rid="bib22">Gray et al., 2005</xref>; <xref ref-type="bibr" rid="bib21">Gordus et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>). These neurons can be grouped into categories that are related to forward locomotion, backward locomotion or turns. For example, AVA, AIB, and RIM are part of a backward locomotory circuit (<xref ref-type="bibr" rid="bib70">Zheng et al., 1999</xref>; <xref ref-type="bibr" rid="bib51">Pirri et al., 2009</xref>; <xref ref-type="bibr" rid="bib21">Gordus et al., 2015</xref>). AVB and PVC are part of a forward locomotion circuit (<xref ref-type="bibr" rid="bib22">Gray et al., 2005</xref>; <xref ref-type="bibr" rid="bib7">Chalfie et al., 1985</xref>; <xref ref-type="bibr" rid="bib70">Zheng et al., 1999</xref>; <xref ref-type="bibr" rid="bib37">Li et al., 2011</xref>; <xref ref-type="bibr" rid="bib53">Roberts et al., 2016</xref>; <xref ref-type="bibr" rid="bib68">Xu et al., 2018</xref>); and RIV, RIB, and RIA are related to turns (<xref ref-type="bibr" rid="bib22">Gray et al., 2005</xref>; <xref ref-type="bibr" rid="bib37">Li et al., 2011</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>; <xref ref-type="bibr" rid="bib27">Hendricks et al., 2012</xref>). Much of what we know about these neurons comes from recordings or manipulations of either single neurons at a time, or a selection of neurons simultaneously using sparse promoters (<xref ref-type="bibr" rid="bib22">Gray et al., 2005</xref>; <xref ref-type="bibr" rid="bib24">Guo et al., 2009</xref>; <xref ref-type="bibr" rid="bib2">Ben Arous et al., 2010</xref>; <xref ref-type="bibr" rid="bib31">Kawano et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Piggott et al., 2011</xref>; <xref ref-type="bibr" rid="bib19">Gao et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>). Only recently has it been possible to record from large populations of neurons first in immobile (<xref ref-type="bibr" rid="bib54">Schrödel et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Prevedel et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>) and then moving animals (<xref ref-type="bibr" rid="bib47">Nguyen et al., 2016</xref>; <xref ref-type="bibr" rid="bib61">Venkatachalam et al., 2016</xref>).</p><p>There has not yet been a systematic exploration of the types and distribution of locomotor related signals present in the neural population during movement and their tunings. So for example, it is not known whether all forward related neurons exhibit duplicate neural signals or whether a variety of distinct signals are combined. Interestingly, results from recordings in immobile animals suggest that population neural state space trajectories in a low dimensional space may encode global motor commands (<xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>), but this has yet to be explored in moving animals. Despite growing interest in the role of population dynamics in the worm, their dimensionality, and their relation to behavior (<xref ref-type="bibr" rid="bib12">Costa et al., 2019</xref>; <xref ref-type="bibr" rid="bib38">Linderman et al., 2019</xref>; <xref ref-type="bibr" rid="bib4">Brennan and Proekt, 2019</xref>; <xref ref-type="bibr" rid="bib17">Fieseler et al., 2020</xref>) it is not known how locomotory related information contained at the population level compares to that contained at the level of single neurons. And importantly, current findings of population dynamics related to locomotion in <italic>C. elegans</italic> are from immobilized animals. While there are clear benefits in studying fictive locomotion (<xref ref-type="bibr" rid="bib1">Ahrens et al., 2012</xref>; <xref ref-type="bibr" rid="bib5">Briggman et al., 2005</xref>; <xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>), it is not known for <italic>C. elegans</italic> how neural population dynamics during immobile fictive locomotion compare to population dynamics during actual movement.</p><p>In this work, we investigate neural representations of locomotion at the population level by recording whole-brain neural activity as the animal crawls on agar. We further construct a decoder to predict the animal’s current locomotion from a linear combination of neural activity alone. The performance of the decoder gives us confidence in our ability to find locomotory signals, and allows us to study how those signals are distributed and represented in the brain.</p><p>We show that distinct subpopulations of neurons encode velocity and body curvature, and that these populations include neurons with varied tuning. We also find that the decoder relies on different neurons to contribute crucial information at different times. Finally, we compared brain-wide neural activity during movement and immobilization and observe that immobilization alters the correlation structure of neural dynamics.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>To investigate locomotory-related signals in the brain, we simultaneously recorded calcium activity from the majority of the 188 neurons in the head of <italic>C. elegans</italic> as the animal moved, <xref ref-type="fig" rid="fig1">Figure 1a–c</xref>, (<xref ref-type="bibr" rid="bib47">Nguyen et al., 2016</xref>). The animal expressed the calcium indicator GCaMP6s and a fluorescent protein RFP in the nuclei of all neurons (strain AML310).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Population calcium activity and tuning of select neurons during spontaneous animal movement.</title><p>Recording AML310_A. (<bold>a</bold>) Calcium activity of 134 neurons is simultaneously recorded during locomotion. Activity is displayed as motion-corrected fluorescent intensity <inline-formula><mml:math id="inf1"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Neurons are numbered according to agglomerative hierarchical clustering. White space indicates time-points where neural tracking failed. (<bold>b</bold>) Body bend velocity and body curvature derived from an eigenvalue decomposition, and (<bold>c</bold>) position on the plate during recording are shown. (<bold>d</bold>) Example neurons significantly tuned to velocity. Examples are those with the highest Pearson’s correlation coefficient in each category: activity (or its derivative) with positive (or negative) correlation to velocity. P-values are derived from a shuffling procedure that preserves per-neuron correlation structure. All tuning curves shown are significant at 0.05% after Bonferroni correction for multiple hypothesis testing (<inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>1.9</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). Boxplot shows median and interquartile range. Blue or orange shaded circles show neural activity at each time point during behavior. (<bold>e</bold>) Example neurons highly tuned to curvature were selected similarly. No neurons with negative <inline-formula><mml:math id="inf3"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> tuning to curvature passed our significance threshold.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Additional details and examples of velocity tuning.</title><p>Additional examples of velocity tuning curves for <inline-formula><mml:math id="inf4"><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:math></inline-formula> (top) and <inline-formula><mml:math id="inf5"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> (bottom) from recording AML310_A are shown. The correlation coefficient ρ captures the relation between each neuron’s activity and curvature and is plotted with a corresponding p-value (middle). The p-value is calculated from a time-lag shuffle and tests the null hypothesis that such a correlation would be found due to chance. Dashed line indicates a significance level of 0.05 after a Bonferonni correction for multiple hypothesis testing (<inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>1.9</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Additional details and examples of curvature tuning.</title><p>Additional examples of curvature tuning for <inline-formula><mml:math id="inf7"><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:math></inline-formula> (top) and <inline-formula><mml:math id="inf8"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> (bottom) from recording AML310_A are shown. The correlation coefficient ρ captures the relation between each neuron’s activity and velocity and is plotted with a corresponding p-value (middle). The p-value is calculated from a time-lag shuffle and tests the null hypothesis that such a correlation would be found due to chance. Dashed line indicates a significance level of 0.05 after a Bonferonni correction for multiple hypothesis test (<inline-formula><mml:math id="inf9"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>1.9</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig1-figsupp2-v2.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Number of significantly tuned neurons across recordings.</title><p>Pearson’s correlation coefficient ρ was calculated for each neuron in 11 GCaMP recordings and 11 GFP control recordings that lacked a calcium indicator. Neurons were counted as significantly tuned if their Pearson’s correlation coefficient passed a recording-specific multiple-hypothesis corrected significance test and exceeded an absolute value of 0.4. Bar shows median. Whiskers show inter-quartile range.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig1-figsupp3-v2.tif"/></fig></fig-group><p>We report calcium activity as a motion-corrected fluorescence intensity <inline-formula><mml:math id="inf10"><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:math></inline-formula>, described in methods. We measured two features of locomotion: velocity and body curvature. Velocity is computed from the movement of a point on the head of the worm as described in the methods. Body curvature is calculated as the mean curvature along the animal’s centerline and has large deviations from zero during turning or coiling.</p><p>We found multiple neurons with calcium activity significantly tuned to either velocity or curvature (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Some neurons were more active during forward locomotion while others were more active during backward locomotion (<xref ref-type="fig" rid="fig1">Figure 1d</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Similarly some neurons were active during dorsal bends and others during ventral bends (<xref ref-type="fig" rid="fig1">Figure 1e</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). In some cases, the derivative of the activity was also significantly correlated with features of locomotion. We recorded from additional animals for a total of 11 animals expressing GCaMP6s (strain AML310 or AML32) and 11 control animals expressing GFP (strain AML18) and tabulated the number of significantly tuned neurons in each recording, <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>. To be classified as ‘significantly tuned’ the neuron’s Pearson's correlation coefficient had to both pass a multiple-hypothesis corrected statistical test based on a recording-specific shuffle (described in the Materials and methods), and exceed a minimum absolute value of 0.4. The existence of neural signals correlated with these behaviors is broadly consistent with single-unit or sparse recordings during forward and backward locomotion (<xref ref-type="bibr" rid="bib2">Ben Arous et al., 2010</xref>; <xref ref-type="bibr" rid="bib31">Kawano et al., 2011</xref>; <xref ref-type="bibr" rid="bib21">Gordus et al., 2015</xref>; <xref ref-type="bibr" rid="bib57">Shipley et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>) and turning (<xref ref-type="bibr" rid="bib34">Kocabas et al., 2012</xref>; <xref ref-type="bibr" rid="bib15">Donnelly et al., 2013</xref>; <xref ref-type="bibr" rid="bib55">Shen et al., 2016</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Neuron pair AVA is active during backward locomotion and exhibits expected tuning during moving population recordings.</title><p>(<bold>a</bold>) AVAR and AVAL are labeled by BFP under a <italic>rig-3</italic> promoter in strain AML310. Two optical planes are shown from a single volume recorded during movement. Planes are near the top and bottom of the optical stack, corresponding to the animals’ extreme right and left. The recording is the same as in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Top row shows BFP. Bottom row shows RFP in the nuclei of all neurons. Segmented neurons centered in the optical plane are labeled with ⊕, while neurons from nearby optical planes are labeled with ○. Arrow indicates AVAR or AVAL. Numbering corresponds to <xref ref-type="fig" rid="fig1">Figure 1a</xref>. (<bold>b</bold>) Calcium activity of AVAR and AVAL during locomotion in recording AML310_A, same as in <xref ref-type="fig" rid="fig1">Figure 1</xref>. (<bold>c</bold>) Aggregate tuning of AVA across four individuals (seven neurons). Boxplot shows median and interquartile range. Lightly shaded blue or orange circles show activity at each time point during behavior.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Sum of AVAL and AVAR activity.</title><p>Activity of AVAL and AVAR from AML310_A in <xref ref-type="fig" rid="fig2">Figure 2b</xref> are shown summed together. This permits comparison to recordings that do not resolve the two neurons separately.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig2-figsupp1-v2.tif"/></fig></fig-group><p>To validate our population recordings, we investigated the well-characterized neuron pair AVAL and AVAR. We labeled those neurons using blue fluorescent protein (BFP) which is spectrally separated from the other two colors we use for neuron localization and activity (strain AML310), see <xref ref-type="fig" rid="fig2">Figure 2a</xref>. These two neurons, called AVA, are a bilaterally symmetric pair with gap junctions between them that have been shown to exhibit large calcium transients that begin with the onset of backward locomotion, peak around the end of backward locomotion during the onset of forward locomotion, and then slowly decay (<xref ref-type="bibr" rid="bib2">Ben Arous et al., 2010</xref>; <xref ref-type="bibr" rid="bib31">Kawano et al., 2011</xref>; <xref ref-type="bibr" rid="bib16">Faumont et al., 2011</xref>; <xref ref-type="bibr" rid="bib57">Shipley et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Gordus et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>). Our measure of AVA’s activity, recorded simultaneously with 131 other neurons during movement, is consistent with prior recordings where AVA was recorded alone. We note that single-unit recordings of AVA used in previous studies lacked the optical sectioning needed to resolve these neurons separately. Here we resolve both AVAL and AVAR and find that their activities are similar to one another, and they both exhibit the expected transients timed to backward locomotion, <xref ref-type="fig" rid="fig2">Figure 2b</xref>. Signal-to-noise in AVAR is higher than AVAL because in this recording AVAR lies closer to the imaging objective lens, while AVAL is on the opposite side of the head and therefore must be imaged through the rest of the brain. We also report the sum of the individual traces in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. The similarity we observe between activities of AVAL and AVAR, and the similarities between our recordings of AVA and those previously reported in the literature serves to validate our ability to simultaneously record neural activity accurately from across the brain. It also suggests that the noise in this recording is modest compared to the features of interest in AVA’s calcium transients.</p><p>We recorded from three additional animals and identified AVA neurons in each. The temporal derivative of AVA’s activity has previously been shown to correlate with velocity over the range of negative (but not positive) velocities (<xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>). Consistent with these reports, the derivative of AVA’s activity, <inline-formula><mml:math id="inf11"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>mc</mml:mi></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, aggregated across the four population recordings has a negative correlation to velocity over the range of negative velocities, <xref ref-type="fig" rid="fig2">Figure 2c</xref>.</p><p>In our exemplar recording, AVA’s activity (not its temporal derivative) also correlates with body curvature (<xref ref-type="fig" rid="fig1">Figure 1e</xref>, neuron #110). Correlation to curvature likely arises because our exemplar recording includes many long reversals culminating in deep ventral bends called ‘omega turns,’ that coincide in time with AVA’s peak activity. Taken together, AVA’s activity simultaneously recorded from the population is in agreement with prior reports where AVA activity was recorded alone.</p><sec id="s2-1"><title>Population decoder outperforms best single neuron</title><p>AVA’s activity is related to the animal’s velocity, but its activity alone is insufficient to robustly decode velocity. For example, AVA is informative during backward locomotion, but contains little information about velocity during forward locomotion, <xref ref-type="fig" rid="fig2">Figure 2c</xref>. To gain reliable information about velocity, the nervous system will need more than the information contained in the activity of AVA. In primate motor cortex, for example, linear combinations of activity from the neural population provides more information about the direction of a monkey’s arm motion during a reach task than a single neuron (<xref ref-type="bibr" rid="bib20">Georgopoulos et al., 1986</xref>). In <italic>C. elegans</italic>, recordings from single or sparse sets of neurons show that multiple neurons have activity related to the animal’s velocity or curvature (<xref ref-type="bibr" rid="bib2">Ben Arous et al., 2010</xref>; <xref ref-type="bibr" rid="bib34">Kocabas et al., 2012</xref>; <xref ref-type="bibr" rid="bib31">Kawano et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Piggott et al., 2011</xref>; <xref ref-type="bibr" rid="bib21">Gordus et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>). Recordings from immobilized animals further suggest that population neural dynamics in a simple low dimensional space may represent locomotion (<xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>), but this has yet to be explored in moving animals.</p><p>We sought to explicitly compare the information about velocity and curvature contained in the population to that contained in a single neuron. To access information in the population, we constructed a decoder that uses linear regression with regularization to relate the weighted sum of neurons’ activity to either velocity or curvature. Ridge regression (<xref ref-type="bibr" rid="bib28">Hoerl and Kennard, 1970</xref>) was performed on 60% of the recording (training set) and the decoder was evaluated on a held-out test-set made up of the remaining 40% of the recording (shaded green in <xref ref-type="fig" rid="fig3">Figure 3a,c</xref>). Evaluating performance on held-out data mitigates potential concerns that performance gains merely reflect over-fitting. In the context of held-out data, models with more parameters, even those that are over-fit, will not inherently perform better. Cross-validation was used to set hyper-parameters. Two regression coefficients are assigned to each neuron, one weight for activity and one for its temporal derivative. We compared performance of the population decoder on the held-out test set to that of the most correlated single neuron or its derivative on the same held-out test set. Performance is reported as a coefficient of determination on the mean-subtracted held out test set <inline-formula><mml:math id="inf12"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>ms</mml:mi><mml:mo>,</mml:mo><mml:mi>test</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Population neural activity decodes locomotion.</title><p>(<bold>a–d</bold>) Performance of the best single neuron (BSN) is compared to a linear population model in decoding velocity and body curvature for the exemplar recording AML310_A shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>. (<bold>a</bold>) Predictions on the held-out test set are compared to measured velocity. Light green shaded region indicates held-out test set. Red arrows indicate examples of features that the population captures better than the BSN. (<bold>b</bold>) Performance is reported as a coefficient of determination <inline-formula><mml:math id="inf13"><mml:msubsup><mml:mi>R</mml:mi><mml:mi>MS</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> evaluated on the mean-subtracted held-out test data (green points). (<bold>c,d</bold>) Model predictions are compared to measured curvature. (<bold>e</bold>) Performance of velocity decoding is shown for recordings of <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:math></inline-formula> individuals (strain AML310 and AML32) and for recordings of <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:math></inline-formula> GFP control animals lacking a calcium indicator (strain AML18). Two-sided Wilcoxon rank test is used to test significance of population performance compared to BSN, <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>3.9</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Welch’s unequal variance t-test is used to test significance of population performance compared to GFP control, <inline-formula><mml:math id="inf17"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>3.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>f</bold>) Performance of curvature decoding is shown for all recordings. Each recording is colored the same as in e. <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>3.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1.8</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> for comparisons of population performance to that of BSN, and GFP control, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Performance correlates with maximal GCaMP Fano Factor, a metric of signal.</title><p>Decoding performance is plotted against maximal GCaMP Fano Factor for each recording for velocity and curvature. Maximal GCaMP Fano Factor is the Fano Factor of the raw GCaMP activity for the neuron in each recording with the highest Fano Factor, <inline-formula><mml:math id="inf20"><mml:mrow><mml:msub><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>GCaMP</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>GCaMP</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Labels for each recording are shown. Dashed red line is the line of best fit (correlation coefficient between fit and data is <inline-formula><mml:math id="inf21"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.46</mml:mn></mml:mrow></mml:math></inline-formula> for velocity and <inline-formula><mml:math id="inf22"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.49</mml:mn></mml:mrow></mml:math></inline-formula> for curvature).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Neural activity and behavior for all moving calcium imaging recordings (AML310 and AML32).</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Neural activity and behavior for all moving GFP control recordings (AML18).</title><p>Neural activity and behavior for all moving GFP control recordings (AML18).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Alternative population models.</title><p>Performance of alternative population models for decoding velocity. Traces are shown for exemplar recording AML310_A. Mean across all moving GCaMP recordings is also listed. Gray shading shows held-out test set. (<bold>a</bold>) The population model used throughout the paper. This model uses ridge regression with fluorescence signals and their temporal derivatives as features. (<bold>b</bold>) A linear model using ridge regression, with only fluorescence (not temporal derivative) signals as features. (<bold>c</bold>) A linear model using fluorescence signals and their temporal derivatives as features, regularized with a combination of a ridge penalty and the squared error of the temporal derivative of behavior. (<bold>d</bold>) The model in c, but using only fluorescence signals as features. (<bold>e</bold>) A linear model using fluorescence signals and their temporal derivatives as features, regularized with an ElasticNet penalty with an <italic>L</italic><sub>1</sub> ratio of <inline-formula><mml:math id="inf23"><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>. (<bold>f</bold>) The model in e, but using only fluorescence signals as features. (<bold>g</bold>) The multivariate adaptive regression splines (MARS) model, using fluorescence signals and their temporal derivatives as features. (<bold>h</bold>) A linear model together with a shallow decision tree, using fluorescence signals and their temporal derivative as features.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Nonlinear fits using best single neuron.</title><p>Performance of polynomial regression models for decoding velocity on 11 GCaMP recordings using the best single neuron. The best single neuron is defined as the one with the best decoding performance using a linear model on the training data. We compare the performance of these regression models to that of the population model using a two-sided Wilcoxon rank test. The population model significantly (p &lt; 0.05) outperforms polynomial regression models up to fourth order.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig3-figsupp5-v2.tif"/></fig></fig-group><p>For the exemplar recording shown in <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig2">Figure 2a–b</xref>, the population performed better on the held-out-test set than the most correlated single neuron (or its temporal derivative) for both velocity and body curvature, see <xref ref-type="fig" rid="fig3">Figure 3</xref>. For velocity, population performance was <inline-formula><mml:math id="inf24"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>ms</mml:mi><mml:mo>,</mml:mo><mml:mi>test</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.76</mml:mn></mml:mrow></mml:math></inline-formula> compared to <inline-formula><mml:math id="inf25"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>ms</mml:mi><mml:mo>,</mml:mo><mml:mi>test</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.43</mml:mn></mml:mrow></mml:math></inline-formula> for the best single neuron; and for curvature population performance was <inline-formula><mml:math id="inf26"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>ms</mml:mi><mml:mo>,</mml:mo><mml:mi>test</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.60</mml:mn></mml:mrow></mml:math></inline-formula> compared to <inline-formula><mml:math id="inf27"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>ms</mml:mi><mml:mo>,</mml:mo><mml:mi>test</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.34</mml:mn></mml:mrow></mml:math></inline-formula> for the best single neuron. Red arrows in <xref ref-type="fig" rid="fig3">Figure 3</xref> highlight striking behavior features that the best single neuron misses but that the population decoder captures. We also explored alternative population models, including both linear and non-linear models with different features, cost penalties, and differing number of parameters <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref> (parameters described in Materials and methods and Table 5) Of the populations models we tried, the model used here was one of the simplest and also had one of the best mean performances at decoding velocity across all recordings, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>.</p><p>Activity was recorded from a total of 11 moving animals (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) and the linear population model was used to decode each recording (<inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula> recordings of strain AML32; <inline-formula><mml:math id="inf29"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> recordings of strain AML310, also shown in <xref ref-type="fig" rid="fig2">Figure 2c</xref>). The population model was compared to the best single neuron in each recording. Because the correspondence between neurons across animals is not known in these recordings, the identities of neurons used by the population decoder and that of the specific best single neuron may vary from recording to recording. The population significantly outperformed the best single neuron at decoding the held-out portions of the recordings for both velocity and curvature (p &lt; 0.05 two-sided Wilcoxon rank test).</p><p>There was large worm-to-worm variability in the performance of the decoders. Performance across recordings correlated with one metric of the signal in our recordings, the maximal Fano factor across neurons of the raw time-varying GCaMP fluorescence intensity,<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:msub><mml:mi>Fano</mml:mi><mml:mi>GCaMP</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>GCaMP</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>GCaMP</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo rspace="7.5pt">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>max</italic><sub><italic>i</italic></sub> indicates the maximum over all neurons in the recording, and <inline-formula><mml:math id="inf30"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> and μ are the variance and mean respectively of the raw GCaMP activity of the neuron, see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. Here, the variance term is related to the signal in the recording. The recording with the highest <inline-formula><mml:math id="inf31"><mml:msub><mml:mi>Fano</mml:mi><mml:mi>GCaMP</mml:mi></mml:msub></mml:math></inline-formula> performed best at decoding velocity and curvature. This suggests that variability in performance may be due in part to variability in the amount of neural signal in our recordings.</p><p>In some recordings, where the population outperforms the best single neuron, it does so in part because the population decodes a fuller range of the animal’s behavior compared to the best single neuron. Recording AML32_A shows a striking example: the best single neuron captures velocity dynamics for negative velocities, but saturates at positive velocities. The population decoder, by contrast, captures velocity dynamics during both forward and backward locomotion during the held-out test set, and covers a larger fraction of the held-out velocity range, see <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Example where population decoded a fuller range of animal behavior.</title><p>(<bold>a</bold>) The decoding from the best single neuron and the population model are compared to the measured velocity for example recording AML32_A. (<bold>b</bold>) Predictions from the best single neuron saturate at a velocity of approximately 0.1 mm s<sup>−1</sup>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig4-v2.tif"/></fig><p>Motion artifact is of potential concern because it may resemble neural signals correlated to behavior (<xref ref-type="bibr" rid="bib47">Nguyen et al., 2016</xref>; <xref ref-type="bibr" rid="bib8">Chen et al., 2013</xref>). For example, if a neuron is compressed during a head bend, it may increase local fluorophore density causing a calcium-independent increase in fluorescence that would erroneously appear correlated with head bends. We address this concern in all our recordings by extracting a motion corrected calcium signal derived from a comparison of GCaMP and RFP dynamics in the same neuron. All strains in this work express a calcium-insensitive RFP in every neuron in addition to GCaMP. Motion artifacts should affect both fluorophores similarly. Therefore, the motion correction algorithm subtracts off those dynamics that are common to both GCaMP and RFP timeseries (details in Materials and methods).</p><p>To validate our motion correction, and to rule out the possibility that our decoder primarily relies on non-neural signals such as those from motion artifact, we recorded from control animals lacking calcium indicators. These animals expressed GFP in place of GCaMP (11 individuals, strain AML18, RFP was also expressed in all neurons). GFP emits a similar range of wavelengths to GCaMP but is insensitive to calcium. Recordings from these control animals were subject to similar motion artifact but contained no neural activity because they lack calcium sensors (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Recordings from GFP control animals were subject to the same motion correction as GCaMP animals. For both velocity and curvature, the average population model performance was significantly worse at decoding calcium-insensitive GFP control recordings than the calcium-sensitive GCaMP recordings (<xref ref-type="fig" rid="fig3">Figure 3e–f</xref>, median performance <inline-formula><mml:math id="inf32"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>ms, test</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.56</mml:mn></mml:mrow></mml:math></inline-formula> for GCaMP compared to 0.30 for GFP control at decoding velocity, and median performance <inline-formula><mml:math id="inf33"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>ms, test</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.29</mml:mn></mml:mrow></mml:math></inline-formula> for GCaMP compared to 0.04 for GFP control for curvature (p &lt; 0.05 Welch’s unequal variance test), suggesting that the decoder’s performance relies on neural signals. Taken together, we find that a simple linear combination of neurons performs better at decoding velocity or curvature than the best single neuron, and that the population decoder is not primarily relying on motion artifact.</p></sec><sec id="s2-2"><title>Types of signals used to decode from the population</title><p>We further sought to understand how information across the population was utilized by the decoder. We were interested in this for two reasons, first because it should provide insights into how the population model is able to decode effectively. And second, because an effective strategy adopted by the decoder may also be available to the brain, therefore understanding how the decoder works also illustrates plausible strategies that the brain could employ to represent locomotion.</p><p>To investigate how the decoder utilizes information from the population, we inspect the neural weights assigned by the decoder. The decoder assigns one weight for each neuron’s activity, <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>W</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:math></inline-formula>, and another for the temporal derivative of its activity, <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>W</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:msub></mml:math></inline-formula>. It uses ridge regularization to penalize weights with large amplitudes, which is equivalent to a Bayesian estimation of the weights assuming a zero-mean Gaussian prior. In the exemplar recording from <xref ref-type="fig" rid="fig1">Figure 1</xref>, the distribution of weights for both velocity and curvature are indeed both well-approximated by a Gaussian distribution centered at zero. This suggests that the decoder does not need to deviate significantly from the prior in order to perform well. In particular, although changing the sign of any weight would not incur a regularization penalty, the decoder relies roughly equally on neurons that are positively and negatively tuned to velocity, and similarly for curvature.</p><p>At the population level, the decoder assigns weights that are roughly distributed evenly between activity signals <inline-formula><mml:math id="inf36"><mml:mi>F</mml:mi></mml:math></inline-formula> and temporal derivative of activity signals <inline-formula><mml:math id="inf37"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5a,b</xref>). But at the level of individual neurons, the weight assigned to a neuron’s activity <inline-formula><mml:math id="inf38"><mml:msub><mml:mi>W</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:math></inline-formula> was not correlated with the weight assigned to the temporal derivative of its activity <inline-formula><mml:math id="inf39"><mml:msub><mml:mi>W</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Again, this is consistent with the model’s prior distribution of the weights. However, given that the model could have relied more heavily on either activity signals <inline-formula><mml:math id="inf40"><mml:mi>F</mml:mi></mml:math></inline-formula> or on temporal derivative signals <inline-formula><mml:math id="inf41"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> without penalty, we find it interesting that the decoder did not need to deviate from weighting them roughly equally in order to perform well.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Weights assigned to neurons by the population model in the exemplar recording, and their respective tuning.</title><p>(<bold>a</bold>) The weight <inline-formula><mml:math id="inf42"><mml:mi>W</mml:mi></mml:math></inline-formula> assigned to each neuron’s activity (<inline-formula><mml:math id="inf43"><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:math></inline-formula>) or its temporal derivative (<inline-formula><mml:math id="inf44"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>) by the velocity population decoder is plotted against its Pearson’s Correlation coefficient ρ which characterizes its tuning to velocity. Recording AML310_A is shown, same as in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Dashed red line shows line of best fit. Right panel shows the observed distribution of weights. A zero-mean Gaussian with standard deviation set to the empirically observed standard deviation is also shown. (<bold>b</bold>) Same as in a, but for curvature. (<bold>c</bold>) Tuning and activity of the top highest amplitude weighted neurons for velocity is shown. Activity of each neuron is time aligned to the observed behavior (top row). Neurons are labeled corresponding to their number in the heatmap in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Their rank and weight <inline-formula><mml:math id="inf45"><mml:mi>W</mml:mi></mml:math></inline-formula> in the decoder is listed. Red arrows highlight peaks in the temporal derivative of activity of neuron #24 and #110, while cyan arrows highlight peaks of neuron #44. Y- and X-axes labels and scales are preserved within individual rows and columns, respectively. Light green shading indicates the held-out portion of the recording. (<bold>d</bold>) Same as c but for curvature. Red and cyan arrows show two sets of deep ventral bends that are captured by different neurons. Green arrows show dorsal bends.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Comparison of weights assigned to a neuron’s activity versus its temporal derivative.</title><p>Comparison of weights assigned to a neuron’s activity versus its temporal derivative for velocity (left) or curvature (right) decoders. Comparison of weights assigned to a neuron’s activity <inline-formula><mml:math id="inf46"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> by the population decoder, versus the weights assigned to its temporal derivative <inline-formula><mml:math id="inf47"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> for each neuron in recording AML310_A.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Comparison of weights assigned for decoding velocity vs decoding curvature.</title><p>Comparison of weights assigned for decoding velocity vs decoding curvature. (<bold>a</bold>) The magnitude of the weight assigned to each neuron in recording AML310_A for velocity <inline-formula><mml:math id="inf48"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>vel</mml:mi></mml:msup><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula> is compared to the magnitude of its assigned weight for curvature <inline-formula><mml:math id="inf49"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mi>curv</mml:mi></mml:msup><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula>. Each neuron is plotted twice, once for the weight assigned to its activity and once for the weight assigned to the temporal derivative of its activity. (<bold>b</bold>) Same as in (<bold>a</bold>), except here the higher weight of either activity or its temporal derivative is plotted.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Example traces of highly weighted neurons used to decode curvature in AML32_A.</title><p>Traces of top five highest weighted neurons used to decode curvature in AML32_A. Same recording as in <xref ref-type="fig" rid="fig4">Figure 4</xref>. Arrows indicate activity peaks corresponding to ventral (blue shades, top) or dorsal turns (red shades, bottom). Different neurons contribute activity peaks to different sets of turns.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig5-figsupp3-v2.tif"/></fig></fig-group><p>We wondered what types of signals are combined by the decoder. For example, it is conceptually useful to consider a simple null hypothesis in which multiple neurons exhibit exact copies of the same behavior-related signal with varying levels of noise. In that case, the population decoder would outperform the best single neuron merely by summing over duplicate noisy signals. We inspected the activity traces of the top weighted neurons in our exemplar recording (<xref ref-type="fig" rid="fig5">Figure 5c,d</xref>). Some highly weighted neurons had activity traces that appeared visually similar to the animal’s locomotory trace for the duration of the recording (e.g.#80 for curvature) and other neurons had activity that might plausibly be noisy copies of each other (e.g. #12 and #60 for velocity). But other highly weighted neurons had activity traces that were distinct or only matched specific features of the locomotory behavior. For example, negatively weighted neuron #59 exhibited distinct positive peaks during dorsal turns (green arrows), but did not consistently exhibit corresponding negative peaks during ventral turns. This is consistent with prior reports of neurons such as SMDD that are known to exhibit peaks during dorsal but not ventral head bends (<xref ref-type="bibr" rid="bib27">Hendricks et al., 2012</xref>; <xref ref-type="bibr" rid="bib55">Shen et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Kaplan et al., 2020</xref>).</p><p>In the recording shown, we also find some neurons that have activity matched to only specific instances of a behavior motif. For example, the temporal derivative of the activity of neuron #84 contributes distinct peaks to ventral bends at approximately 105 s and 210 s, but not during similar ventral turns at other time points (<xref ref-type="fig" rid="fig5">Figure 5d</xref>, blue arrows). Conversely, highly weighted neuron #77 contributes sharp peaks corresponding to four other ventral bends (<xref ref-type="fig" rid="fig5">Figure 5d</xref>, red arrows) that are absent from neuron #84. Similarly (although perhaps less striking) for velocity, neurons #24 and #110 contribute peaks for one set of reversals (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, red arrows), while neuron #44 contributes peaks to a complimentary set of two reversals (<xref ref-type="fig" rid="fig5">Figure 5c</xref>, blue arrows). Similarly in recording AML32_A, different neurons contribute peaks of activity corresponding to different sets of ventral or dorsal turns, <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>. While we observed this effect in some recordings, it was not obviously present in every recording.</p><p>From this inspection of highly weighted neurons, we conclude that in at least some recordings the decoder is not primarily averaging over duplicate signals. Instead the decoder sums together different types of neural signals, including those that capture only a certain feature of a behavior (e.g. dorsal turns or ventral turns, but not both) or that seemingly capture only certain instance of the same behavior motif (some reversals but not others).</p><sec id="s2-2-1"><title>Majority of decoder’s performance is provided by a subset of neurons</title><p>We wondered how many neurons the model relies upon to achieve most of its performance. The magnitude of a neuron’s assigned weight reflects its relative usefulness in decoding locomotion. Therefore we investigated performance of a restricted population model that had access to only those <inline-formula><mml:math id="inf50"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons that were most highly weighted by the full model. We sequentially increased the number of neurons <inline-formula><mml:math id="inf51"><mml:mi>N</mml:mi></mml:math></inline-formula> and evaluated the partial model performance (<xref ref-type="video" rid="fig6video1">Figure 6—video 1</xref>). In this way, we estimated the number of neurons needed to first achieve a given performance (<xref ref-type="fig" rid="fig6">Figure 6a</xref>). Because we were interested in probing the particular successful set of weights that the model had found, we constrained the relative weights of neurons in the partial model to match those of the full model. We note that adding a neuron gave the model access to both that neuron’s activity and its temporal derivative. We define the number of neurons needed to first achieve 90% full model performance as the <italic>N</italic><sub>90</sub> and use this value as an estimate of the number of important neurons for decoding. For the exemplar recording AML310_A, 90% of the model’s performance was achieved when including only 13 neurons for velocity, and only four neurons for curvature.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Number of neurons needed by the model to decode velocity and curvature.</title><p>(<bold>a</bold>) The minimum number of neurons needed for a restricted model to first achieve a given performance is plotted from recording AML310_A in <xref ref-type="fig" rid="fig1">Figure 1</xref>. Performance, <inline-formula><mml:math id="inf52"><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>MS,all</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> is reported separately for velocity (blue) and curvature (green) and is calculated on the entire recording (test and train). Intersect refers to the intersection of the set of neurons included in both partial models (velocity and curvature) for a given performance. Red dashed line, <italic>N</italic><sub>90</sub>, indicates number of neurons needed to achieve 90% of full model performance. (<bold>b</bold>) <italic>N</italic><sub>90</sub> is computed for velocity and curvature for all recordings. The number of neurons present in both populations at 90% performance level (intersection) is shown. Box shows median and interquartile range. (<bold>c</bold>) <italic>N</italic><sub>90</sub> for all recordings is shown plotted versus the performance of the full population velocity or curvature decoder, respectively. Number of intersection neurons (red ’x’) is plotted at the higher of either the velocitys or curvature’s performance.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig6-v2.tif"/></fig><media id="fig6video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-66135-fig6-video1.mp4"><label>Figure 6—video 1.</label><caption><title>Animation showing partial model performance as neurons are added, corresponding to <xref ref-type="fig" rid="fig6">Figure 6a</xref>.</title><p>Top panel shows performance <inline-formula><mml:math id="inf53"><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>MS,all</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> evaluated on both test and training set. Bottom left shows measured velocity (black) and decoded velocity (blue). Gray shading indicates test set. Bottom right shows measured velocity compared to decoded velocity for training (blue) and test set (green).</p></caption></media></fig-group><p>Across all recordings, we saw large variability in the number of important neurons <italic>N</italic><sub>90</sub> (<xref ref-type="fig" rid="fig6">Figure 6b,c</xref> and <xref ref-type="table" rid="table1">Table 1</xref>) with a median of 27 neurons for velocity and 31 for curvature. By comparison, our recordings contained a median total of 121 neurons. On average, the decoder relies on roughly a quarter of the neurons in a recording to achieve the majority of its decoding performance.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Number of neurons needed to achieve 90% of full model performance, <italic>N</italic><sub>90</sub>, reported as (median ± standard deviation), across all 11 recordings.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Velocity <italic>N</italic><sub>90</sub></th><th>Curvature <italic>N</italic><sub>90</sub></th><th>Intersection <italic>N</italic><sub>90</sub></th><th>Total recorded</th></tr></thead><tbody><tr><td>27 ± 16</td><td>31 ± 18</td><td>7 ± 5</td><td>121 ± 12</td></tr></tbody></table></table-wrap></sec><sec id="s2-2-2"><title>Largely distinct sub-populations contain information for velocity and curvature</title><p>We wondered how a neuron’s role in decoding velocity relates to its role in decoding curvature. Most neurons that have been well characterized in the literature, such as AVE and SMD, have been ascribed roles to either velocity or curvature but not both. RIB may be exception, and has recently been proposed to be involved in both reversals and turns (<xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>). In the exemplar recording AML310_A, there was no obvious population-wide trend between the magnitude of a neuron’s weight at decoding velocity and the magnitude of its weight at decoding curvature for either <inline-formula><mml:math id="inf54"><mml:mi>F</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf55"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> or both, see <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>. Furthermore, only one neuron had overlap between the <inline-formula><mml:math id="inf56"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mn>90</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:math></inline-formula> neurons needed to achieve 90% of full model performance at decoding velocity and the <inline-formula><mml:math id="inf57"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mn>90</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> neurons needed for curvature in this recording, see <xref ref-type="fig" rid="fig6">Figure 6a</xref>. Across all recordings, only <inline-formula><mml:math id="inf58"><mml:mrow><mml:mn>7</mml:mn><mml:mo>±</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> (median ± std) neurons were included in both <italic>N</italic><sub>90</sub> for the velocity and curvature sub-populations, labeled ‘intersect’ neurons in <xref ref-type="fig" rid="fig6">Figure 6b,c</xref> and <xref ref-type="table" rid="table1">Table 1</xref>. Taken together, this suggests that largely distinct sub-populations of neurons in the brain contain the majority of information important for decoding velocity and curvature.</p></sec></sec><sec id="s2-3"><title>Immobilization alters the correlation structure of neural dynamics</title><p>Recordings of brain-wide calcium activity of immobilized <italic>C. elegans</italic> provided evidence to suggest that the population may be involved in representing locomotion or motor commands (<xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>). Specifically these motor commands may be represented as neural trajectories through a low-dimensional state space defined by principal components determined by the correlation structure of population neural activity in the recording. Those experiments also noted some differences between the activity of neurons in immobilized population recordings and the same neuron recorded alone in a moving animal. For example, neuron RIM exhibited seemingly slower dynamics in immobilized population recordings than in sparse recordings during movement. We wondered what changes may exist at the population level between moving and immobilized animals.</p><p>We recorded population activity from a moving animal crawling in a microfluidic chip and then immobilized that animal partway through the recording by delivering the paralytic levamisole, as has been used previously (<xref ref-type="bibr" rid="bib21">Gordus et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>). Neural dynamics from the same population of neurons in the same animal were therefore directly compared during movement and immobilization, <xref ref-type="fig" rid="fig7">Figure 7</xref>.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Immobilization alters the correlation structure of neural activity.</title><p>(<bold>a</bold>) Calcium activity is recorded from an animal as it moves and then is immobilized with a paralytic drug, recording AML310_E. (<bold>b</bold>) Activity of AVAL and AVAR from (<bold>a</bold>). (<bold>c</bold>) Population activity (or its temporal derivative) from (<bold>a</bold>) is shown projected onto its first three PCs, as determined by only the immobilized portion of the recording. (<bold>d</bold>) Neural state space trajectories from (<bold>c</bold>) are shown split into moving and immobile portions, color coded by time. Scale, axes and PCs are the same in both plots. (<bold>e</bold>) Pairwise correlations of neural activity <inline-formula><mml:math id="inf59"><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are shown as heatmaps for all neurons during movement and immobilization, sorted via a clustering algorithm. Top row is sorted to movement, bottom row is sorted to immobilization. (<bold>f</bold>) Dissimilarity between correlation matrices for moving and immobile portions of a recording are shown compared to the dissimilarity observed between correlation matrices taken at similar time windows within moving-only recordings. Dissimilarity is <inline-formula><mml:math id="inf60"><mml:msqrt><mml:mrow><mml:mo>⟨</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>⟩</mml:mo></mml:mrow></mml:msqrt></mml:math></inline-formula>. Dissimilarity was measured in three moving-immobile recordings with paralytic and 11 moving-only recordings. <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, Welch’s unequal variance t-test. Boxes show median and interquartile range.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Example from additional moving-to-immobile recording.</title><p>Calcium activity is recorded from an animal as it moves and then is immobilized with a paralytic drug, recording AML32_H. Activity and behavior. (<bold>b</bold>) Population activity (or its derivative) from (<bold>a</bold>) is shown projected onto its first three PCs, as determined by only the immobilized portion of the recording. (<bold>c</bold>) Neural state space trajectories from (<bold>b</bold>) are plotted in 3D and shown split into moving and immobile portions. (<bold>d</bold>) Pairwise correlations of neural activity <inline-formula><mml:math id="inf62"><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are shown as heatmaps for all neurons during movement and immobilization, sorted via clustering algorithm. Top and bottom rows are sorted to movement or immobilization, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig7-figsupp1-v2.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Immobile-only recording.</title><p>Calcium activity is recorded from an animal immobilized with nano-beads, recording AML310_G. (<bold>a</bold>) Calcium activity. (<bold>b</bold>) Activity of neurons AVAL and AVAR. (<bold>c</bold>) Population activity (or its temporal derivative) from (<bold>a</bold>) is shown projected onto its first three PCs, as determined by only the immobilized portion of the recording. (<bold>d</bold>) Neural state space trajectories from (<bold>b</bold>) are plotted in 3D.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig7-figsupp2-v2.tif"/></fig></fig-group><p>Immobilization changed the correlation structure of neural activity. Clusters of neurons that had been correlated with one another during movement were no longer correlated during immobilization (see <xref ref-type="fig" rid="fig7">Figure 7e</xref>, top row, blocks of contiguous yellow on the diagonal during movement that are absent or disrupted during immobilization ). Notably, many neurons that had been only weakly positively correlated or had negative correlations during movement became strongly positively correlated with one another during immobilization forming a large block (<xref ref-type="fig" rid="fig7">Figure 7e</xref>, bottom, large contiguous yellow square that appears on the lower right along the diagonal during immobilization).</p><p>To further quantify the change in correlation structure, we defined a dissimilarity metric, the root mean squared change in pairwise correlations <inline-formula><mml:math id="inf63"><mml:msqrt><mml:mrow><mml:mo>⟨</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>⟩</mml:mo></mml:mrow></mml:msqrt></mml:math></inline-formula>, and applied it to the correlation matrices during movement and immobilization within this recording, and also to two additional recordings with paralytic. As a control, we also measured the change in correlation structure across two similar time windows in the 11 moving recordings. The change in correlations from movement to immobilization was significantly larger than changes observed in correlations in the moving-only recordings (<inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, Welch’s unequal variance t-test), <xref ref-type="fig" rid="fig7">Figure 7f</xref>. This suggests that immobilization alters the correlation structure more than would occur by chance in a moving worm.</p><p>We next inspected the neural dynamics themselves (<xref ref-type="fig" rid="fig7">Figure 7a,c</xref>). Low-dimensional stereotyped trajectories, called manifolds, have been suggested to represent <italic>C. elegans</italic> locomotion in a neural state-space defined by the first three principal components of the temporal derivative of neural activity (<xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>). We therefore performed Principal Components Analysis (PCA) on the neural activity (or its temporal derivative) of our recording during the immobilization period, so as to generate a series of principal components or PC’s that capture the major orthogonal components of the variance during immobilization. Population activity during the entire recording was then projected into these first three PCs defined during immobilization, <xref ref-type="fig" rid="fig7">Figure 7c</xref>. Neural state space trajectories during immobilization were more structured and stereotyped than during movement and exhibited similarities to previous reports, see <xref ref-type="fig" rid="fig7">Figure 7c,d</xref>.</p><p>Recordings from a second animal was similar and showed pronounced cyclic activity in the first PC of the temporal derivative of neural activity, see <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1b,c</xref>. Neural state space trajectories were even more striking and periodic in recordings where the animal had been immobilized for many minutes prior to recording (see <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, especially PC1). The emergence of structured neural state-space dynamics during immobilization is consistent with the significant change to the correlation structure observed in neural activity. Taken together, these measurements suggest that immobilization alters the correlation structure and dynamics of neural activity and may have implications for the interpretation of immobile neural dynamics.</p><p>We further investigated the activity of neuron pair AVA and its correlation to other neurons during movement and immobilization in the recording shown in <xref ref-type="fig" rid="fig7">Figure 7</xref>. AVA’s activity was roughly consistent with prior reports. During movement AVA exhibited a sharp rise in response to most instances of the animal’s backward locomotion, as expected (<xref ref-type="fig" rid="fig7">Figure 7b</xref>). During immobilization, AVA exhibited slow cycles of activity captured in one of the first three PCs.</p><p>And during both movement and immobilization AVAL and AVAR were consistently highly correlated with one another (<inline-formula><mml:math id="inf65"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.89</mml:mn></mml:mrow></mml:math></inline-formula>) and participated in a small cluster of positively correlated neurons (most clearly visible in <xref ref-type="fig" rid="fig7">Figure 7e</xref> bottom row, small block around AVA).</p><p>Interestingly, immobilization induced many neurons to change the sign of their correlations with AVA. For example, some neurons, such as #43 and #44, that had negative correlation coefficients with respect to AVA during movement but had positive correlation coefficients during immobilization (Fig <xref ref-type="fig" rid="fig8">Figure 8a,b,d</xref>). Similarly, some neurons, such as #23 and #33 that had positive correlation coefficients with respect to AVA during movement, had negative correlation coefficients with respect to AVA during immobilization. On average, neurons in this recording become significantly more positively correlated to AVA upon immobilization than during movement (p = 0.019 Wilcoxon ranked test), <xref ref-type="fig" rid="fig8">Figure 8c</xref>.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Correlations with respect to AVAL and AVAR during movement and immobilization.</title><p>(<bold>a</bold>) The Pearson’s correlation of each neuron’s activity to AVAR and AVAL is shown during movement and immobilization. Selected neurons are numbered as in <xref ref-type="fig" rid="fig7">Figure 7</xref> (same recording, AML310_E). Neurons are sorted according to their correlation during movement. (<bold>b</bold>) Scatter plot shows relation between a neuron’s correlation to AVA during movement and its correlation during immobilization. Gray squares and blue circles indicate correlation to AVAL and AVAR, respectively. (<bold>c</bold>) On average, neurons become more positively correlated to AVA upon immobilization, p = 0.019 Wilcoxon ranked test. Box shows median and interquartile range. (<bold>d</bold>) Activity traces of selected neurons are shown time aligned to AVA. Green and purple shading indicate positive or negative correlation to AVA, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66135-fig8-v2.tif"/></fig><p>Taken together, our measurements show that immobilization significantly alters the correlation structure of neural activity. Immobilization also causes neurons to change their correlation with known well-characterized neurons, like AVA, from negatively correlated to positively correlated, or vice versa.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our measurements show that a linear decoder can predict the animal’s current velocity and body curvature from neural signals in the population. This suggests that a linear combination of activity from different neurons is one plausible mechanism that the brain may employ to represent behavior. However, our results do not preclude the brain from using other methods for representing behavior. And in all cases, the measurements here do not distinguish between neural signals that drive locomotion, such as motor commands; and neural signals that monitor locomotion generated elsewhere, such as proprioceptive feedback (<xref ref-type="bibr" rid="bib65">Wen et al., 2012</xref>). The decoder likely uses a mix of both. Future perturbation studies are needed to distinguish population-level signals that drive locomotion from those that monitor locomotion.</p><p>How should we interpret the finding that the decoder is linear? It has been observed that even very non-linear neural systems can encode information linearly. For example, the vertebrate retina has many highly non-linear connections but a linear decoder performs indistinguishably from an (nonlinear) artificial neural network at decoding visual signals from populations of retinal ganglion cells (<xref ref-type="bibr" rid="bib64">Warland et al., 1997</xref>). <italic>C. elegans</italic> may be another example, like the retina, of a non-linear system that represents information linearly. The <italic>C. elegans</italic> nervous system, however, also contains known instances of connections that appear linear over a physiologically relevant range of activities (<xref ref-type="bibr" rid="bib40">Liu et al., 2009</xref>; <xref ref-type="bibr" rid="bib39">Lindsay et al., 2011</xref>; <xref ref-type="bibr" rid="bib46">Narayan et al., 2011</xref>). So, it is also possible that the linear representation of behavior in <italic>C. elegans</italic> reflects linear circuitry in the brain.</p><p>We note that our exploration of non-linear models was not exhaustive. Although we tested a selection of non-linear models at the single neuron <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref> and population level <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, it is possible that a different non-linear model would perform better. And it is also possible that one of the non-linear models we did test would perform better with more training data. Complex models, including non-linear models, tend to have more parameters and are therefore prone to overfitting when trained on limited data. If a non-linear model performed poorly on our held-out data due to overfitting, it may perform better when trained with longer recordings. Poor performance here therefore does not inherently preclude a non-linear model from being useful for describing behavior signals in the <italic>C. elegans</italic> nervous system. Future work with longer recordings or the ability to aggregate training across multiple recordings is needed to better evaluate whether more complex models would outperform the simple linear decoder.</p><p>The types of signals used by the decoder are informative. The decoder uses a mix of neural activity signals and their temporal derivatives. This is consistent with prior reports that for some neurons, like AVA, it is the temporal derivative of activity that correlates with aspects of locomotion (<xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>) while for other neurons, such as AIY, it is the activity itself (<xref ref-type="bibr" rid="bib43">Luo et al., 2014</xref>). Temporal derivatives are one way for a model to incorporate temporal information. That the temporal derivative is informative, suggests that the nervous system cares not only about activity at this instant in time, but also about preceding moments. Future models could explicitly assign weights to the same neural activity at more time points, although this would likely require more training data to avoid overfitting.</p><p>Some of the signals used by the decoder were consistently correlated with locomotion throughout the duration of the recording. But other signals used by the decoder had pronounced peaks of activity that were relevant only for particular aspects. For example, some neurons had peaks that corresponded only to ventral but not dorsal turns, or vice versa. This is consistent with neurons such as RIVL/R that are active during ventral turns (<xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>) or the SMDDs or SMDVs that have activity peaks during either dorsal or ventral head bends, respectively (<xref ref-type="bibr" rid="bib27">Hendricks et al., 2012</xref>; <xref ref-type="bibr" rid="bib55">Shen et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Kaplan et al., 2020</xref>). Intriguingly, the decoder sometimes used signals that had peaks of activity only for particular instances of what appeared to be the same behavior motif, for example one reversal event but not another. By summing up contributions from multiple neurons, the population model was able to capture relevant activity from different neurons at different times to decode all instances of the behavioral motif.</p><p>One possible explanation is that superficially similar behavioral features like turns may actually consist of different underlying behaviors. For example, seemingly similar turns, on closer inspection, can be further subdivided into distinct groups (<xref ref-type="bibr" rid="bib6">Broekmans et al., 2016</xref>). The neural representation associated with a motif may also depend on its behavioral context, including the behaviors that follow or proceed it. For example, the temporal derivative of activity of AIB has been shown to be elevated during those reversals that are followed by turns compared to those followed by forward locomotion (<xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>). The population may contain a variety of such neurons, each tuned to only a specific context of a given behavior, which would give rise to the neurons used by the decoder that are seemingly tuned to some instances of a motif and not others. The granularity with which to classify behaviors and how to take into account context and behavioral hierarchies remains an active area of research in <italic>C. elegans</italic> (<xref ref-type="bibr" rid="bib41">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Kaplan et al., 2020</xref>) and in other model systems (<xref ref-type="bibr" rid="bib3">Berman et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Datta et al., 2019</xref>). Ultimately, finding distinct neural signals may help inform our understanding of distinct behavior states and vice versa.</p><p>A related possibility is that the same behavior motifs are initiated in the head through different neural pathways. Previous work has suggested that activity in either of two different sets of head interneurons, AVA/AVE/AVD or AIB/RIM, are capable of inducing reversal behavior independently (<xref ref-type="bibr" rid="bib50">Piggott et al., 2011</xref>). If these or other neurons were active only for a subset of reversals, it could explain why some neurons seem to have activity relevant for some behavioral instances but not others. The specific neurons listed in <xref ref-type="bibr" rid="bib50">Piggott et al., 2011</xref> do not fit the pattern observed in our measurements in part because we observe that AVA shows expected activity transients for nearly all large reversals. But it is possible that other neurons in the two subsets, or indeed other subsets of neurons, provide relevant activity for only some instances of a behavior.</p><p>Similarly, different sensory modalities such as mechanosensation (<xref ref-type="bibr" rid="bib7">Chalfie et al., 1985</xref>), thermosensation (<xref ref-type="bibr" rid="bib13">Croll, 1975</xref>) and chemosensation (<xref ref-type="bibr" rid="bib63">Ward, 1973</xref>) are known to evoke common behavioral outputs via sensory pathways that have both common and distinct elements. For example, both polymodal nociceptive stimuli detected from ASH (<xref ref-type="bibr" rid="bib44">Mellem et al., 2002</xref>) and anterior mechanosensory stimuli detected from soft touch neurons ALM and AVM (<xref ref-type="bibr" rid="bib67">Wicks and Rankin, 1995</xref>) activate reversals through shared circuitry containing AVA, among other common neurons. It is possible that the neural activities we observe for different behavioral motifs reflect sensory signals that arrive through different sensory pathways to evoke a common downstream motor response.</p><p>By inspecting the neural weights assigned by our model, we found that only a fraction of neurons are necessary for the model to achieve 90% of its performance. Sub-populations of neurons with modest overlap contribute the majority of information for decoding velocity and curvature, respectively. This is consistent with other reports, including recent work suggesting that turning and reverse circuits are largely distinct modules except for a select few neurons, such as RIB, which may be involved in both (<xref ref-type="bibr" rid="bib62">Wang et al., 2020</xref>). Future studies using newly developed methods for identifying neurons (<xref ref-type="bibr" rid="bib69">Yemini et al., 2021</xref>) are needed to reveal the identities of those neurons weighted by the decoder for decoding velocity, curvature, or both.</p><p>That <italic>C. elegans</italic> neural dynamics exhibit different correlation structure during movement than during immobilization has implications for neural representations of locomotion. For example, it is now common to use dimensionality reduction techniques like PCA to search for low-dimensional trajectories or manifolds that relate to behavior or decision making in animals undergoing movement (<xref ref-type="bibr" rid="bib11">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib26">Harvey et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Shenoy et al., 2013</xref>) or in immobilized animals undergoing fictive locomotion (<xref ref-type="bibr" rid="bib5">Briggman et al., 2005</xref>; <xref ref-type="bibr" rid="bib30">Kato et al., 2015</xref>). PCA critically depends on the correlation structure to define its principal components. In <italic>C. elegans</italic>, the low-dimensional neural trajectories observed in immobilized animals undergoing fictive locomotion, and the underlying correlation structure that defines those trajectories, are being used to draw conclusions about neural dynamics of actual locomotion. Our measurements suggest that to obtain a more complete picture of <italic>C. elegans</italic> neural dynamics related to locomotion, it will be helpful to probe neural state space trajectories recorded during actual locomotion: both because the neural dynamics themselves may differ during immobilization, but also because the correlation structure observed in the network, and consequently the relevant principal components, change upon immobilization. These changes may be due to proprioception (<xref ref-type="bibr" rid="bib65">Wen et al., 2012</xref>), or due to different internal states associated with fictive versus actual locomotion.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type (species) or resource</th><th>Designation</th><th>Source or reference</th><th>Identifiers</th><th>Additional information</th></tr></thead><tbody><tr><td>Strain, strain background (<italic>C. elegans</italic>)</td><td>AML310</td><td>this work</td><td/><td>Details in <xref ref-type="table" rid="table2">Table 2</xref></td></tr><tr><td>Strain, strain background (<italic>C. elegans</italic>)</td><td>AML32</td><td><xref ref-type="bibr" rid="bib48">Nguyen et al., 2017</xref></td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/WBI-STRAIN:WBStrain00000192">WBI-STRAIN:WBStrain00000192</ext-link></td><td/></tr><tr><td>Strain, strain background (<italic>C. elegans</italic>)</td><td>AML18</td><td><xref ref-type="bibr" rid="bib47">Nguyen et al., 2016</xref></td><td>RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/WBI-STRAIN:WBStrain00000191">WBI-STRAIN:WBStrain00000191</ext-link></td><td/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Strains</title><p>Three strains were used in this study, see <xref ref-type="table" rid="table2">Table 2</xref>. AML32 (<xref ref-type="bibr" rid="bib48">Nguyen et al., 2017</xref>) and AML310 were used for calcium imaging. AML18 (<xref ref-type="bibr" rid="bib47">Nguyen et al., 2016</xref>) served as a calcium insensitive control. Strain AML310 is similar to AML32 but includes additional labels to identify AVA neurons. AML310 was generated by injecting 30 ng/ul of P<italic>rig-3</italic>::tagBFP plasmid into AML32 strains (wtfIs5[P<italic>rab-3</italic>::NLS ::GCaMP6s; P<italic>rab-3</italic>::NLS::tagRFP]). AML310 worms were selected and maintained by picking individuals expressing BFP fluorescence in the head. Animals were cultivated in the dark on NGM plates with a bacterial lawn of OP50.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Strains used.</title><p>Associated Research Resource Identifiers are listed in Key Resources.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Strain</th><th>Genotype</th><th>Expression</th><th>Role</th><th>Reference</th></tr></thead><tbody><tr><td>AML310</td><td>wtfIs5[P<italic>rab-3</italic>::NLS::GCaMP6s; P<italic>rab-3</italic>::NLS::tagRFP]; wtfEx258 [P<italic>rig-3</italic>::tagBFP::unc-54]</td><td>tag-RFP and GCaMP6s in neuronal nuclei; BFP in cytoplasm of AVA and some pharyngeal neurons (likely I1, I4, M4 and NSM)</td><td>Calcium imaging with AVA label</td><td>This Study</td></tr><tr><td>AML32</td><td>wtfIs5[P<italic>rab-3</italic>::NLS::GCaMP6s; P<italic>rab-3</italic>::NLS::tagRFP]</td><td>tag-RFP and GCaMP6s in neuronal nuclei</td><td>Calcium imaging</td><td><xref ref-type="bibr" rid="bib48">Nguyen et al., 2017</xref></td></tr><tr><td>AML18</td><td>wtfIs3[P<italic>rab-3</italic>::NLS::GFP, P<italic>rab-3</italic>::NLS::tagRFP]</td><td>tag-RFP and GFP in neuronal nuclei</td><td>Control</td><td><xref ref-type="bibr" rid="bib47">Nguyen et al., 2016</xref></td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>Whole brain imaging</title><sec id="s4-2-1"><title>Whole brain imaging in moving animals</title><p>Whole brain imaging of moving animals was performed as described previously (<xref ref-type="bibr" rid="bib47">Nguyen et al., 2016</xref>). <xref ref-type="table" rid="table3">Table 3</xref> lists all recording used in the study, and <xref ref-type="table" rid="table4">Table 4</xref> cross-lists the recordings according to figure. Briefly, adult animals were placed on an imaging plate (a modified NGM media lacking cholesterol and with agarose in place of agar) and covered with mineral oil to provide optical index matching to improve contrast for behavior imaging (<xref ref-type="bibr" rid="bib35">Leifer et al., 2011</xref>). A coverslip was placed on top of the plate with 100 m plastic spacers between the coverglass and plate surface. The coverslip was fixed to the agarose plate with valap. Animals were recorded on a custom whole brain imaging system, which simultaneously records four video streams to image the calcium activity of the brain while simultaneously capturing the animal’s behavior as the animal crawls on agar in two-dimensions. We record ×10 magnification darkfield images of the body posture, ×10x magnification fluorescence images of the head for real-time tracking, and two ×40 magnification image streams of the neurons in the head, one showing tagRFP and one showing either GCaMP6s, GFP, or BFP. The ×10 images are recorded at 50 frames/s, and the 40x fluorescence images are recorded at a rate of 200 optical slices/s, with a resulting acquisition rate of 6 head volumes/s. Recordings were stopped when the animal ran to the edge of the plate, when they left the field of view, or when photobleaching decreased the contrast between tag-RFP and background below a minimum level. Intensity of excitation light for fluorescent imaging was adjusted from recording to recording to achieve different tradeoffs between fluorescence intensity and recording duration.</p><p>Moving recordings had to meet the following criteria. The animal had to be active and the recording had to be at least 200 s. The tag-RFP neurons also had to be successfully segmented and tracked via our analysis pipeline.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Recordings used in this study.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Unique ID</th><th>Strain</th><th>Duration (mins)</th><th>Notes</th></tr></thead><tbody><tr><td>AML310_A</td><td rowspan="4">AML310</td><td>4</td><td rowspan="4">Ca<sup>2+</sup> imaging w/ AVA label, moving</td></tr><tr><td>AML310_B</td><td>4</td></tr><tr><td>AML310_C</td><td>4</td></tr><tr><td>AML310_D</td><td>4</td></tr><tr><td>AML310_E</td><td rowspan="2">AML310</td><td>8</td><td rowspan="2">Ca<sup>2+</sup> imaging w/ AVA label, moving-to-immobile</td></tr><tr><td>AML310_F</td><td>8</td></tr><tr><td>AML310_G</td><td>AML310</td><td>15</td><td>Ca<sup>2+</sup> imaging w/ AVA label, immobile</td></tr><tr><td>AML32_A</td><td rowspan="7">AML32</td><td>11</td><td rowspan="7">Ca<sup>2+</sup> imaging, moving</td></tr><tr><td>AML32_B</td><td>11</td></tr><tr><td>AML32_C</td><td>10</td></tr><tr><td>AML32_D</td><td>11</td></tr><tr><td>AML32_E</td><td>4</td></tr><tr><td>AML32_F</td><td>5</td></tr><tr><td>AML32_G</td><td>4</td></tr><tr><td>AML32_H</td><td>AML32</td><td>13</td><td>Ca<sup>2+</sup> imaging, moving-to-immobile</td></tr><tr><td>AML18_A</td><td rowspan="11">AML18</td><td>10</td><td rowspan="11">GFP control, moving</td></tr><tr><td>AML18_B</td><td>10</td></tr><tr><td>AML18_C</td><td>7</td></tr><tr><td>AML18_D</td><td>5</td></tr><tr><td>AML18_E</td><td>5</td></tr><tr><td>AML18_F</td><td>6</td></tr><tr><td>AML18_G</td><td>9</td></tr><tr><td>AML18_H</td><td>6</td></tr><tr><td>AML18_I</td><td>7</td></tr><tr><td>AML18_J</td><td>6</td></tr><tr><td>AML18_K</td><td>6</td></tr></tbody></table></table-wrap><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>List of recordings included in each figure.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Figure</th><th>Recordings</th></tr></thead><tbody><tr><td><xref ref-type="fig" rid="fig1">Figure 1</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>; <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>;</td><td>AML310_A</td></tr><tr><td><xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref></td><td>AML310_A-D, AML32_A-G, AML18_A-K</td></tr><tr><td><xref ref-type="fig" rid="fig2">Figure 2a,b</xref>; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref></td><td>AML310_A</td></tr><tr><td><xref ref-type="fig" rid="fig2">Figure 2c</xref></td><td>AML310_A-D</td></tr><tr><td><xref ref-type="fig" rid="fig3">Figure 3a–d</xref></td><td>AML310_A</td></tr><tr><td><xref ref-type="fig" rid="fig3">Figure 3e,f</xref></td><td>AML310_A-D, AML32_A-G, AML18_A-K</td></tr><tr><td><xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>; <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>; <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref></td><td>AML310_A-D, AML32_A-G</td></tr><tr><td><xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref></td><td>AML18_A-K</td></tr><tr><td><xref ref-type="fig" rid="fig4">Figure 4</xref></td><td>AML32_A</td></tr><tr><td><xref ref-type="fig" rid="fig5">Figure 5</xref>; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref></td><td>AML310_A</td></tr><tr><td><xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref></td><td>AML32_A</td></tr><tr><td><xref ref-type="fig" rid="fig6">Figure 6a,b</xref>; <xref ref-type="video" rid="fig6video1">Figure 6—video 1</xref></td><td>AML310_A</td></tr><tr><td><xref ref-type="fig" rid="fig6">Figure 6c</xref></td><td>AML310_A-D, AML32_A-G</td></tr><tr><td><xref ref-type="fig" rid="fig7">Figure 7a–f</xref></td><td>AML310_E</td></tr><tr><td><xref ref-type="fig" rid="fig7">Figure 7g</xref></td><td>AML310_A-F, AML32_A-H</td></tr><tr><td><xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref></td><td>AML32_H</td></tr><tr><td><xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref></td><td>AML310_G</td></tr><tr><td><xref ref-type="fig" rid="fig8">Figure 8</xref></td><td>AML310_E</td></tr></tbody></table></table-wrap></sec><sec id="s4-2-2"><title>Moving to immobile transition experiments</title><p>Adult animals were placed in a PDMS microfluidic artificial dirt style chip (<xref ref-type="bibr" rid="bib42">Lockery et al., 2008</xref>) filled with M9 medium where the animal could crawl. The chip was imaged on the whole brain imaging system. A computer controlled microfluidic pump system delivered either M9 buffer or M9 buffer with the paralytic levamisole or tetramisole to the microfluidic chip. Calcium activity was recorded from the worm as M9 buffer flowed through the chip with a flow rate of order a milliliter a minute. Partway through the recording, the drug buffer mixture was delivered at the same flow rate. At the conclusion of the experiment for AML310 worms, BFP was imaged.</p><p>Different drug concentrations were tried for different recordings to find a good balance between rapidly immobilizing the animal without also inducing the animal to contract and deform. Paralytic concentrations used were: 400 μM for AML310_E, 100 μM for AML310_F, and 5 μM for AML32_H.</p><p>Recordings were performed until a recording achieved the following criteria for inclusion: (1) the animal showed robust locomotion during the moving portion of the recording, including multiple reversals. (2) The animal quickly immobilized upon application of the drug. (3) The animal remained immobilized for the remainder of the recording except for occasional twitches, (4) the immobilization portion of the recording was of sufficient duration to allow us to see multiple cycles of the stereotyped neural state space trajectories if present and (5) for strain AML310, neurons AVAL and AVAR were required to be visible and tracked throughout the entirety of the recording. For the statistics of correlation structure in <xref ref-type="fig" rid="fig7">Figure 7f</xref>, recording AML310_F was also included even though it did not meet all criteria (it lacked obvious reversals).</p></sec><sec id="s4-2-3"><title>Whole brain imaging in immobile animals</title><p>We performed whole brain imaging in adult animals immobilized with 100 nm polystyrene beads (<xref ref-type="bibr" rid="bib32">Kim et al., 2013</xref>). The worms were then covered with a glass slide, sealed with valap, and imaged using the Whole Brain Imager.</p></sec><sec id="s4-2-4"><title>Neuron segmentation, tracking, and fluorescence extraction</title><p>Neurons were segmented and tracked using the Neuron Registration Vector Encoding (NeRVE) and clustering approach described previously (<xref ref-type="bibr" rid="bib48">Nguyen et al., 2017</xref>) with minor modifications which are highlighted below. As before, video streams were spatially aligned with beads and then synchronized using light flashes. The animals' posture was extracted using an active contour fit to the ×10 magnification darkfield images. But in a departure from the method in <xref ref-type="bibr" rid="bib48">Nguyen et al., 2017</xref>, the high magnification fluorescent images are now straightened using a different centerline extracted directly from the fluorescent images. As in <xref ref-type="bibr" rid="bib48">Nguyen et al., 2017</xref>, the neural dynamics were then extracted by segmenting the neuronal nuclei in the red channel and straightening the image according to the body posture. Using repeated clustering, neurons are assigned identities over time. The GCaMP signal was extracted using the neural positions found from tracking. The pipeline returns datasets containing RFP and GCaMP6s fluorescence values for each successfully tracked neuron over time, and the centerline coordinates describing the posture of the animal over time. These are subsequently processed to extract neural activity or behavior features.</p><p>The paralytic used in moving-to-immobile recordings (<xref ref-type="fig" rid="fig7">Figure 7</xref>) caused the animal’s head to contract, which would occasionally confuse our tracking algorithm. In those instances the automated NeRVE tracking and clustering was run separately on the moving and immobile portions of the recording (before and after contraction), and then a human manually tracked neurons during the transition period (1–2 min) so as to stitch the moving and immobile tracks together.</p></sec><sec id="s4-2-5"><title>Photobleaching correction, outlier detection, and pre-processing</title><p>The raw extracted RFP or GCaMP fluorescent intensity timeseries were preprocessed to correct for photobleaching. Each time-series was fit to a decaying exponential. Those that were well fit by the exponential were normalized by the exponential and then rescaled to preserve the timeseries’ original mean and variance as in <xref ref-type="bibr" rid="bib10">Chen et al., 2019</xref>. Timeseries that were poorly fit by an exponential were left as is. If the majority of neurons in a recording were poorly fit by an exponential, this indicated that the animal may have photobleached prior to the recording and the recording was discarded.</p><p>Outlier detection was performed to remove transient artifacts from the fluorescent time series. Fluorescent time points were flagged as outliers and omitted if they met any of the following conditions: the fluorescence deviated from the mean by a certain number of standard deviations (<inline-formula><mml:math id="inf66"><mml:mrow><mml:mi>F</mml:mi><mml:mo>&lt;</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf67"><mml:mrow><mml:mi>F</mml:mi><mml:mo>&gt;</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>⁢</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> for RFP; <inline-formula><mml:math id="inf68"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>F</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>⁢</mml:mo><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> for GCaMP); the RFP fluorescence dropped below a threshold; the ratio of GCaMP to RFP fluorescence dropped below a threshold; a fluorescence timepoint was both preceded by and succeeded by missing timepoints or values deemed to be outliers; or if the majority of other neurons measured during the same volume were also deemed to be outliers.</p><p>Fluorescent time series were smoothed by convolution with a Gaussian (<inline-formula><mml:math id="inf69"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.83</mml:mn></mml:mrow></mml:math></inline-formula> s) after interpolation. Omitted time points, or gaps where the neuron was not tracked, were excluded from single-neuron analyses, such as the calculation of each neuron’s tuning curve. It was not practical to exclude missing time points from the population-level analyses such as linear decoding. In these population-level analyses, interpolated values were used. Time points in which the majority of neurons had missing fluoresecent values were excluded, even in population level analyses. Those instances are shown as white vertical stripes in the fluorescent activity heatmaps, for example, as visible in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p></sec><sec id="s4-2-6"><title>Motion-correction</title><p>We used the GCaMP fluorescence together with the RFP fluorescence to calculate a motion corrected fluorescence, <inline-formula><mml:math id="inf70"><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> used through the paper. Note sometimes the subscript <inline-formula><mml:math id="inf71"><mml:msub><mml:mi/><mml:mtext>mc</mml:mtext></mml:msub></mml:math></inline-formula> is omitted for brevity. Motion and deformation in the animal’s head introduce artifacts into the fluorescent time-series. We assume that these artifacts are common to both GCaMP and RFP fluorescence, up to a scale factor, because both experience the same motion. For example, if a neuron is compressed during a head bend, the density of both GCaMP and RFP should increase, causing an increase in the fluorescence in both time-series. We expect that the RFP time series is entirely dominated by artifacts because, in the absence of motion, the RFP fluorescent intensity would be constant. If we further assume that motion artifacts are additive, then a simple correction follows naturally. To correct for motion in the GCaMP fluorescence <inline-formula><mml:math id="inf72"><mml:mi>G</mml:mi></mml:math></inline-formula>, we subtract off a scaled RFP fluorescence, <inline-formula><mml:math id="inf73"><mml:mi>R</mml:mi></mml:math></inline-formula>,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where α is a scaling factor that is fit for each neuron so as to minimize <inline-formula><mml:math id="inf74"><mml:mrow><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. This approach has similarities to <xref ref-type="bibr" rid="bib59">Tai et al., 2004</xref>. The final motion corrected signal <inline-formula><mml:math id="inf75"><mml:msub><mml:mi>F</mml:mi><mml:mtext>mc</mml:mtext></mml:msub></mml:math></inline-formula> is mean-subtracted.</p><p>When presenting heatmaps of calcium activity, we use the colormap to convey information about the relative presence of calcium activity compared to motion artifact in the underlying recording. The limits on the colormap are determined by the uncorrected green fluorescent timeseries, specifically the 99th percentile of <inline-formula><mml:math id="inf76"><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of all neurons at all time points in the recording. With this colormap, recordings in which the neurons contain little signal compared to motion artifact will appear dim, while recordings in which neurons contain signal with large dynamics compared to the motion artifact will appear bright.</p></sec><sec id="s4-2-7"><title>Temporal derivative</title><p>The temporal derivatives of motion corrected neuron signals are estimated using a Gaussian derivative kernel of width 2.3 s. For brevity we denote this kernel-based estimate as <inline-formula><mml:math id="inf77"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula>.</p></sec><sec id="s4-2-8"><title>Identifying AVA</title><p>AVAL and AVAR were identified in recordings of AML310 by their known location and the presence of a BFP fluorescent label expressed under the control of the <italic>rig-3</italic> promoter. BFP was imaged immediately after calcium imaging was completed, usually while the worm was still moving. To image BFP, a 488 nm laser was blocked and the worm was then illuminated with 405 nm laser light. In one of the recordings, only one of the two AVA neurons was clearly identifiable throughout the duration of the recording. For that recording, only one of the AVA neurons was included in analysis.</p></sec></sec><sec id="s4-3"><title>Measuring and representing locomotion</title><p>To measure the animal’s velocity <inline-formula><mml:math id="inf78"><mml:mi>v</mml:mi></mml:math></inline-formula>, we first find the velocity vector that describes the motion of a point on the animal’s centerline 15% of its body length back from the tip of its head. We then project this velocity vector onto a head direction vector of unit length. The head direction is taken to be the direction between two points along the animal’s centerline, 10% and 20% posterior of the tip of the head.</p><p>To calculate this velocity, the centerline and stage position measurements were first Hampel filtered and then interpolated onto a common time axis of 200 Hz (the rate at which we query stage position). Velocity was then obtained by convolving the position with the derivative of a Gaussian with <inline-formula><mml:math id="inf79"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> s.</p><p>To measure the animal’s average curvature <inline-formula><mml:math id="inf80"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula> at each time point, we calculated the curvature <inline-formula><mml:math id="inf81"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> at each of 100 segments along the worm’s centerline, where <inline-formula><mml:math id="inf82"><mml:mi>s</mml:mi></mml:math></inline-formula> refers to the arc length of the centerline. We then took the mean of the curvatures of the middle segments that span an anterior-posterior region from 15% to 80% along the animal’s centerline. This region was chosen to exclude curvature from small nose deflections (sometimes referred to as foraging) and to exclude the curvature of the tip of the tail.</p></sec><sec id="s4-4"><title>Relating neural activity to behavior</title><sec id="s4-4-1"><title>Tuning curves</title><p>The Pearson’s correlation coefficient ρ is reported for each neurons’ tuning, as in <xref ref-type="fig" rid="fig1">Figure 1d,e</xref>. To reject the null hypothesis that a neuron is correlated with behavior by chance we took a shuffling approach and applied a Bonferroni correction for multiple hypothesis testing. We shuffled our data in such a way as to preserve the correlation structure in our recording. To calculate the shuffle, each neuron’s activity was time-reversed and circularly shifted relative to behavior by a random time lag and then the Pearson’s correlation coefficient was computed. Shuffling was repeated for each neuron in a recording <inline-formula><mml:math id="inf83"><mml:mi>M</mml:mi></mml:math></inline-formula> times to build up a distribution of <inline-formula><mml:math id="inf84"><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> values of ρ, where <inline-formula><mml:math id="inf85"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of neurons in the recording. For AML310_A, we shuffled each neuron in the recording <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>5000</mml:mn></mml:mrow></mml:math></inline-formula> times. For other datasets we shuffled each neuron <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow></mml:math></inline-formula> times. To reject the null hypothesis at 0.05% confidence, we apply a Bonferonni correction such that a correlation coefficient greater than ρ (or less than, depending on the sign) must have been observed in the shuffled distribution with a probability less than <inline-formula><mml:math id="inf88"><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The factor of <inline-formula><mml:math id="inf89"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> arises from accounting for multiple hypothesis testing for tuning of both <inline-formula><mml:math id="inf90"><mml:mi>F</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf91"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> for each neuron.</p></sec><sec id="s4-4-2"><title>Population model</title><p>We use a ridge regression (<xref ref-type="bibr" rid="bib28">Hoerl and Kennard, 1970</xref>) model to decode behavior signals <inline-formula><mml:math id="inf92"><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (the velocity and the body curvature). The model prediction is given by a linear combination of neural activities and their time derivatives,<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Note here we are omitting the <inline-formula><mml:math id="inf93"><mml:mpadded lspace="3.3pt" width="+3.3pt"><mml:msub><mml:mi/><mml:mi>mc</mml:mi></mml:msub></mml:mpadded></mml:math></inline-formula> subscript for convenience, but these still refer to the motion corrected fluorescence signal.</p><p>We scale all these features to have zero mean and unit variance, so that the magnitudes of weights can be compared to each other. To determine the parameters <inline-formula><mml:math id="inf94"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>, we hold out a test set comprising the middle 40% of the recording, and use the remainder of the data for training. We minimize the cost function<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mtext>Train</mml:mtext></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The hyperparameter λ sets the strength of the ridge penalty in the second term. We choose λ by splitting the training set further into a second training set and a cross-validation set, and training on the second training set with various values of λ. We choose the value which gives the best performance on the cross-validation set.</p><p>To evaluate the performance of our model, we use a mean-subtracted coefficient of determination metric, <inline-formula><mml:math id="inf95"><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>MS</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, on the test set. This is defined by<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>MS</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mi>y</mml:mi><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we use the conventional definition of <inline-formula><mml:math id="inf96"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>, defined here for an arbitrary true signal <inline-formula><mml:math id="inf97"><mml:mi>z</mml:mi></mml:math></inline-formula> and corresponding model prediction <inline-formula><mml:math id="inf98"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mtext>Test</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mtext>Test</mml:mtext></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Note that <inline-formula><mml:math id="inf99"><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>MS</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> can take any value on <inline-formula><mml:math id="inf100"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-4-3"><title>Restricted models</title><p>To assess the distribution of locomotive information throughout the animal’s brain, we compare with two types of restricted models. First, we use a Best Single Neuron model in which all but one of the coefficients <inline-formula><mml:math id="inf101"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> are constrained to vanish. We thus attempt to represent behavior as a linear function of a single neural activity, or its time derivative These models are shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Second, after training the population model, we sort the neurons in descending order of <inline-formula><mml:math id="inf102"><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We then construct models using a subset of the most highly weighted neurons, with the relative weights on their activities and time derivatives fixed by those used in the population model. The performance of these truncated models can be tabulated as a function of the number of neurons included to first achieve a given performance, as shown in <xref ref-type="fig" rid="fig6">Figure 6</xref>. Note that when reporting fraction of total model performance for this partial model, we evaluate performance on the entire dataset (held-out and training, denoted <inline-formula><mml:math id="inf103"><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>MS,all</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>) because all relative weights for the model have already been frozen in place and there is no risk of overfitting.</p></sec><sec id="s4-4-4"><title>Alternative models</title><p>The population model used throughout this work refers to a linear model with derivatives using ridge regression. In <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, we show the performance of seven alternative population models at decoding velocity for our exemplar recording. The models are summarized in <xref ref-type="table" rid="table5">Table 5</xref>. Many of these models perform similarly to the linear population model used throughout the paper. Our chosen model was selected both for its relative simplicity and because it showed one of the highest mean performances at decoding velocity across recordings.</p><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Alternative models explored.</title><p>Most are linear models, using either the Ridge or ElasticNet regularization. In some cases, we add an additional term to the cost function which penalizes errors in the temporal derivative of model output (which, for velocity models, corresponds to the error in the predicted acceleration). For features, we use either the neural activities alone, or the neural activities together with their temporal derivatives. We also explore two nonlinear models: MARS <xref ref-type="bibr" rid="bib18">Friedman, 1991</xref>, and a shallow decision tree which chooses between two linear models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Model</th><th>Penalty</th><th>Features</th><th>Number of parameters</th></tr></thead><tbody><tr><td>Linear</td><td>Ridge</td><td><inline-formula><mml:math id="inf104"><mml:mi>F</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf105"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf106"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Linear</td><td>Ridge</td><td><inline-formula><mml:math id="inf107"><mml:mi>F</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf108"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Linear</td><td>Ridge + Acceleration Penalty</td><td><inline-formula><mml:math id="inf109"><mml:mi>F</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf110"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf111"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Linear</td><td>Ridge + Acceleration Penalty</td><td><inline-formula><mml:math id="inf112"><mml:mi>F</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf113"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Linear</td><td>ElasticNet</td><td><inline-formula><mml:math id="inf114"><mml:mi>F</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf115"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf116"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Linear</td><td>ElasticNet</td><td><inline-formula><mml:math id="inf117"><mml:mi>F</mml:mi></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf118"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td>MARS (nonlinear)</td><td>MARS</td><td><inline-formula><mml:math id="inf119"><mml:mi>F</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf120"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula></td><td>variable</td></tr><tr><td>Linear with Decision Tree (nonlinear)</td><td>Ridge</td><td><inline-formula><mml:math id="inf121"><mml:mi>F</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf122"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf123"><mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula></td></tr></tbody></table></table-wrap><p><xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4a–b</xref> show the model we use throughout the paper, and the same model but with only fluorescence signals (and not their time derivatives) as features. The latter model attains a slightly lower score of <inline-formula><mml:math id="inf124"><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mtext>MS</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.60</mml:mn></mml:mrow></mml:math></inline-formula>. Note that while adding features is guaranteed to improve performance on the training set, performance on the held-out test set did not necessarily have to improve. Nonetheless, we generally found that including the time derivatives led to better predictions on the test set.</p><p><xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4c–d</xref> show a variant of the linear model where we add an acceleration penalty to the model error. Our cost function becomes (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>).<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mtext>Train</mml:mtext></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the derivatives <inline-formula><mml:math id="inf125"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="inf126"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula> are estimated using a Gaussian derivative filter. The parameter μ is set to 10. For our exemplar recording, adding the acceleration penalty hurts the model when derivatives are not included as features, but has little effect when they are.</p><p><xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4e–f</xref> show a variant where we use an ElasticNet penalty instead of a ridge penalty (<xref ref-type="bibr" rid="bib71">Zou and Hastie, 2005</xref>). If we write the ridge penalty as the <italic>L</italic><sub>2</sub> norm of the weight vector, so that<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" stretchy="false">∥</mml:mo><mml:mi>W</mml:mi><mml:mo fence="true" stretchy="false">∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>the ElasticNet penalty is defined by<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo fence="true" stretchy="false">∥</mml:mo><mml:mi>W</mml:mi><mml:mo fence="true" stretchy="false">∥</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true" stretchy="false">∥</mml:mo><mml:mi>W</mml:mi><mml:mo fence="true" stretchy="false">∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:msub><mml:mrow><mml:mo fence="true" stretchy="false">∥</mml:mo><mml:mi>W</mml:mi><mml:mo fence="true" stretchy="false">∥</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>is the <italic>L</italic><sub>1</sub> norm of the weight vector. The quantity <inline-formula><mml:math id="inf127"><mml:mi>r</mml:mi></mml:math></inline-formula> is known as the <italic>L</italic><sub>1</sub> ratio, and in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref> it is set to 10<sup>−2</sup>. We have also tried setting <inline-formula><mml:math id="inf128"><mml:mi>r</mml:mi></mml:math></inline-formula> via cross-validation, and found similar results.</p><p><xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4g</xref> uses the multivariate adaptive regression splines (MARS) model (<xref ref-type="bibr" rid="bib18">Friedman, 1991</xref>). The MARS model incorporates nonlinearity by using rectified linear functions of the features, or products of such functions. Generally, they have the advantage of being more flexible than linear models while remaining more interpretable than a neural network or other more complicated nonlinear model. However, we find that MARS somewhat underperforms a linear model on our data.</p><p><xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4h</xref> uses a decision tree classifier trained to separate the data into forward-moving and backward-moving components, and then trains separate linear models on each component. For our exemplar recording, this model performs slightly better than the model we use throughout the paper. This is likely a result of the clear AVAR signal in <xref ref-type="fig" rid="fig2">Figure 2</xref>, which can be used by the classifier to find the backward-moving portions of the data. Across all our recordings, this model underperforms the simple linear model.</p></sec></sec><sec id="s4-5"><title>Correlation structure analysis</title><p>The correlation structure of neural activity was visualised as the correlation matrix, <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. To observe changes in correlation structure, a correlation matrix for the moving portion of the recording was calculated separately from the immobile portion. The time immediately following delivery of the paralytic when the animal was not yet paralzed was excluded (usually one to two minutes). To quantify the magnitude of the change in correlation structure, a dissimilarity metric was defined as the root mean-squared change in each neuron’s pairwise correlations, <inline-formula><mml:math id="inf130"><mml:msqrt><mml:mrow><mml:mo>⟨</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>⟩</mml:mo></mml:mrow></mml:msqrt></mml:math></inline-formula>. As a control, changes to correlation structure were measured in moving animals. In this case the correlation structure of the first 30% of the recording was compared to the correlation structure of latter 60% of the recording, so as to mimic the relative timing in the moving-to-immobile recordings.</p></sec><sec id="s4-6"><title>Software</title><p>Analysis scripts are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/leiferlab/PredictionCode">https://github.com/leiferlab/PredictionCode</ext-link> (<xref ref-type="bibr" rid="bib36">Leifer, 2021</xref>, copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:84b8b9383f5602ab9109bee37a01dd5455c3354e;origin=https://github.com/leiferlab/PredictionCode;visit=swh:1:snp:453835ab64a044fdcf67a305b15754f114d333d8;anchor=swh:1:rev:ca59416112a9c10a8d6a3179092a7d3c888bcd4e">swh:1:rev:ca59416112a9c10a8d6a3179092a7d3c888bcd4e</ext-link>).</p></sec><sec id="s4-7"><title>Data</title><p>Data from all experiments including calcium activity traces and animal pose and position are publicly available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/DPR3H">https://doi.org/10.17605/OSF.IO/DPR3H</ext-link>.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>Thanks to Sandeep Kumar and Kevin Chen for critical comments on the manuscript. This work was supported in part by the National Science Foundation, through the Center for the Physics of Biological Function (PHY-1734030 to JWS, AML, KMH) and an NSF CAREER Award (IOS-1845137 to AML) and by the Simons Foundation (SCGB #324285, and SCGB #543003, AML). ANL is supported by a National Institutes of Health institutional training grant NIH T32 MH065214 through the Princeton Neuroscience Institute. FR was supported by the Swartz Foundation via the Swartz Fellowship for Theoretical Neuroscience. Strains are distributed by the CGC, which is funded by the NIH Office of Research Infrastructure Programs (P40 OD010440).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Formal analysis, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Resources, Software, Formal analysis, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Resources, Software, Formal analysis, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Resources, Methodology, Writing - review and editing, Developed instrumentation</p></fn><fn fn-type="con" id="con7"><p>Resources, Methodology, Writing - review and editing, Generated all transgenics</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Supervision, Funding acquisition, Writing - review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Visualization, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-66135-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data associated with this manuscript has been deposited in a publicly accessible repository hosted by the Open Science Framework at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/DPR3H">https://doi.org/10.17605/OSF.IO/DPR3H</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Hallinen</surname><given-names>KM</given-names></name><name><surname>Dempsey</surname><given-names>R</given-names></name><name><surname>Scholz</surname><given-names>M</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Linder</surname><given-names>A</given-names></name><name><surname>Randi</surname><given-names>F</given-names></name><name><surname>Sharma</surname><given-names>A</given-names></name><name><surname>Shaevitz</surname><given-names>JW</given-names></name><name><surname>Leifer</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Decoding locomotion from population neural activity in moving C. elegans</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="doi">10.17605/OSF.IO/R5TB3</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahrens</surname> <given-names>MB</given-names></name><name><surname>Li</surname> <given-names>JM</given-names></name><name><surname>Orger</surname> <given-names>MB</given-names></name><name><surname>Robson</surname> <given-names>DN</given-names></name><name><surname>Schier</surname> <given-names>AF</given-names></name><name><surname>Engert</surname> <given-names>F</given-names></name><name><surname>Portugues</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Brain-wide neuronal dynamics during motor adaptation in zebrafish</article-title><source>Nature</source><volume>485</volume><fpage>471</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1038/nature11057</pub-id><pub-id pub-id-type="pmid">22622571</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben Arous</surname> <given-names>J</given-names></name><name><surname>Tanizawa</surname> <given-names>Y</given-names></name><name><surname>Rabinowitch</surname> <given-names>I</given-names></name><name><surname>Chatenay</surname> <given-names>D</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Automated imaging of neuronal activity in freely behaving <italic>Caenorhabditis elegans</italic></article-title><source>Journal of Neuroscience Methods</source><volume>187</volume><fpage>229</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.01.011</pub-id><pub-id pub-id-type="pmid">20096306</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname> <given-names>GJ</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Predictability and hierarchy in <italic>Drosophila</italic> behavior</article-title><source>PNAS</source><volume>113</volume><fpage>11943</fpage><lpage>11948</lpage><pub-id pub-id-type="doi">10.1073/pnas.1607601113</pub-id><pub-id pub-id-type="pmid">27702892</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennan</surname> <given-names>C</given-names></name><name><surname>Proekt</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A quantitative model of conserved macroscopic dynamics predicts future motor commands</article-title><source>eLife</source><volume>8</volume><elocation-id>e46814</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.46814</pub-id><pub-id pub-id-type="pmid">31294689</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggman</surname> <given-names>KL</given-names></name><name><surname>Abarbanel</surname> <given-names>HD</given-names></name><name><surname>Kristan</surname> <given-names>WB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Optical imaging of neuronal populations during decision-making</article-title><source>Science</source><volume>307</volume><fpage>896</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1126/science.1103736</pub-id><pub-id pub-id-type="pmid">15705844</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broekmans</surname> <given-names>OD</given-names></name><name><surname>Rodgers</surname> <given-names>JB</given-names></name><name><surname>Ryu</surname> <given-names>WS</given-names></name><name><surname>Stephens</surname> <given-names>GJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Resolving coiled shapes reveals new reorientation behaviors in <italic>C. elegans</italic></article-title><source>eLife</source><volume>5</volume><elocation-id>e17227</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17227</pub-id><pub-id pub-id-type="pmid">27644113</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chalfie</surname> <given-names>M</given-names></name><name><surname>Sulston</surname> <given-names>JE</given-names></name><name><surname>White</surname> <given-names>JG</given-names></name><name><surname>Southgate</surname> <given-names>E</given-names></name><name><surname>Thomson</surname> <given-names>JN</given-names></name><name><surname>Brenner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The neural circuit for touch sensitivity in <italic>Caenorhabditis elegans</italic></article-title><source>The Journal of Neuroscience</source><volume>5</volume><fpage>956</fpage><lpage>964</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.05-04-00956.1985</pub-id><pub-id pub-id-type="pmid">3981252</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>JL</given-names></name><name><surname>Pfäffli</surname> <given-names>OA</given-names></name><name><surname>Voigt</surname> <given-names>FF</given-names></name><name><surname>Margolis</surname> <given-names>DJ</given-names></name><name><surname>Helmchen</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Online correction of licking-induced brain motion during two-photon imaging with a tunable Lens</article-title><source>The Journal of Physiology</source><volume>591</volume><fpage>4689</fpage><lpage>4698</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2013.259804</pub-id><pub-id pub-id-type="pmid">23940380</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>X</given-names></name><name><surname>Mu</surname> <given-names>Y</given-names></name><name><surname>Hu</surname> <given-names>Y</given-names></name><name><surname>Kuan</surname> <given-names>AT</given-names></name><name><surname>Nikitchenko</surname> <given-names>M</given-names></name><name><surname>Randlett</surname> <given-names>O</given-names></name><name><surname>Chen</surname> <given-names>AB</given-names></name><name><surname>Gavornik</surname> <given-names>JP</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name><name><surname>Engert</surname> <given-names>F</given-names></name><name><surname>Ahrens</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Brain-wide organization of neuronal activity and convergent sensorimotor transformations in larval zebrafish</article-title><source>Neuron</source><volume>100</volume><fpage>876</fpage><lpage>890</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.09.042</pub-id><pub-id pub-id-type="pmid">30473013</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>X</given-names></name><name><surname>Randi</surname> <given-names>F</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Searching for collective behavior in a small brain</article-title><source>Physical Review E</source><volume>99</volume><elocation-id>052418</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.99.052418</pub-id><pub-id pub-id-type="pmid">31212571</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Foster</surname> <given-names>JD</given-names></name><name><surname>Nuyujukian</surname> <given-names>P</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname> <given-names>AC</given-names></name><name><surname>Ahamed</surname> <given-names>T</given-names></name><name><surname>Stephens</surname> <given-names>GJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Adaptive, locally linear models of complex dynamics</article-title><source>PNAS</source><volume>116</volume><fpage>1501</fpage><lpage>1510</lpage><pub-id pub-id-type="doi">10.1073/pnas.1813476116</pub-id><pub-id pub-id-type="pmid">30655347</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Croll</surname> <given-names>NA</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Behavioural analysis of nematode movement</article-title><source>Advances in Parasitology</source><volume>13</volume><fpage>71</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1016/s0065-308x(08)60319-x</pub-id><pub-id pub-id-type="pmid">1169872</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname> <given-names>SR</given-names></name><name><surname>Anderson</surname> <given-names>DJ</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name><name><surname>Perona</surname> <given-names>P</given-names></name><name><surname>Leifer</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational neuroethology: a call to action</article-title><source>Neuron</source><volume>104</volume><fpage>11</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.038</pub-id><pub-id pub-id-type="pmid">31600508</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donnelly</surname> <given-names>JL</given-names></name><name><surname>Clark</surname> <given-names>CM</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name><name><surname>Pirri</surname> <given-names>JK</given-names></name><name><surname>Haburcak</surname> <given-names>M</given-names></name><name><surname>Francis</surname> <given-names>MM</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Monoaminergic orchestration of motor programs in a complex <italic>C. elegans</italic> behavior</article-title><source>PLOS Biology</source><volume>11</volume><elocation-id>e1001529</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001529</pub-id><pub-id pub-id-type="pmid">23565061</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faumont</surname> <given-names>S</given-names></name><name><surname>Rondeau</surname> <given-names>G</given-names></name><name><surname>Thiele</surname> <given-names>TR</given-names></name><name><surname>Lawton</surname> <given-names>KJ</given-names></name><name><surname>McCormick</surname> <given-names>KE</given-names></name><name><surname>Sottile</surname> <given-names>M</given-names></name><name><surname>Griesbeck</surname> <given-names>O</given-names></name><name><surname>Heckscher</surname> <given-names>ES</given-names></name><name><surname>Roberts</surname> <given-names>WM</given-names></name><name><surname>Doe</surname> <given-names>CQ</given-names></name><name><surname>Lockery</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>An image-free opto-mechanical system for creating virtual environments and imaging neuronal activity in freely moving <italic>Caenorhabditis elegans</italic></article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e24666</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0024666</pub-id><pub-id pub-id-type="pmid">21969859</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fieseler</surname> <given-names>C</given-names></name><name><surname>Zimmer</surname> <given-names>M</given-names></name><name><surname>Kutz</surname> <given-names>JN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Unsupervised learning of control signals and their encodings in <italic>Caenorhabditis elegans</italic> whole-brain recordings</article-title><source>Journal of the Royal Society Interface</source><volume>17</volume><elocation-id>20200459</elocation-id><pub-id pub-id-type="doi">10.1098/rsif.2020.0459</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Multivariate adaptive regression splines</article-title><source>The Annals of Statistics</source><volume>19</volume><fpage>1</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1214/aos/1176347963</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname> <given-names>S</given-names></name><name><surname>Guan</surname> <given-names>SA</given-names></name><name><surname>Fouad</surname> <given-names>AD</given-names></name><name><surname>Meng</surname> <given-names>J</given-names></name><name><surname>Kawano</surname> <given-names>T</given-names></name><name><surname>Huang</surname> <given-names>YC</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Alcaire</surname> <given-names>S</given-names></name><name><surname>Hung</surname> <given-names>W</given-names></name><name><surname>Lu</surname> <given-names>Y</given-names></name><name><surname>Qi</surname> <given-names>YB</given-names></name><name><surname>Jin</surname> <given-names>Y</given-names></name><name><surname>Alkema</surname> <given-names>M</given-names></name><name><surname>Fang-Yen</surname> <given-names>C</given-names></name><name><surname>Zhen</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Excitatory motor neurons are local oscillators for backward locomotion</article-title><source>eLife</source><volume>7</volume><elocation-id>e29915</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.29915</pub-id><pub-id pub-id-type="pmid">29360035</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname> <given-names>A</given-names></name><name><surname>Schwartz</surname> <given-names>A</given-names></name><name><surname>Kettner</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Neuronal population coding of movement direction</article-title><source>Science</source><volume>233</volume><fpage>1416</fpage><lpage>1419</lpage><pub-id pub-id-type="doi">10.1126/science.3749885</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordus</surname> <given-names>A</given-names></name><name><surname>Pokala</surname> <given-names>N</given-names></name><name><surname>Levy</surname> <given-names>S</given-names></name><name><surname>Flavell</surname> <given-names>SW</given-names></name><name><surname>Bargmann</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Feedback from network states generates variability in a probabilistic olfactory circuit</article-title><source>Cell</source><volume>161</volume><fpage>215</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.02.018</pub-id><pub-id pub-id-type="pmid">25772698</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname> <given-names>JM</given-names></name><name><surname>Hill</surname> <given-names>JJ</given-names></name><name><surname>Bargmann</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A circuit for navigation in <italic>Caenorhabditis elegans</italic></article-title><source>PNAS</source><volume>102</volume><fpage>3184</fpage><lpage>3191</lpage><pub-id pub-id-type="doi">10.1073/pnas.0409009101</pub-id><pub-id pub-id-type="pmid">15689400</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname> <given-names>J</given-names></name><name><surname>Adachi</surname> <given-names>A</given-names></name><name><surname>Shah</surname> <given-names>KK</given-names></name><name><surname>Hirokawa</surname> <given-names>JD</given-names></name><name><surname>Magani</surname> <given-names>PS</given-names></name><name><surname>Maimon</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A neural circuit architecture for angular integration in <italic>Drosophila</italic></article-title><source>Nature</source><volume>546</volume><fpage>101</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1038/nature22343</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Hart</surname> <given-names>AC</given-names></name><name><surname>Ramanathan</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Optical interrogation of neural circuits in <italic>Caenorhabditis elegans</italic></article-title><source>Nature Methods</source><volume>6</volume><fpage>891</fpage><lpage>896</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1397</pub-id><pub-id pub-id-type="pmid">19898486</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Molden</surname> <given-names>S</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Choice-specific sequences in parietal cortex during a virtual-navigation decision task</article-title><source>Nature</source><volume>484</volume><fpage>62</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1038/nature10918</pub-id><pub-id pub-id-type="pmid">22419153</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hendricks</surname> <given-names>M</given-names></name><name><surname>Ha</surname> <given-names>H</given-names></name><name><surname>Maffey</surname> <given-names>N</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Compartmentalized calcium dynamics in a <italic>C. elegans</italic> interneuron encode head movement</article-title><source>Nature</source><volume>487</volume><fpage>99</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1038/nature11081</pub-id><pub-id pub-id-type="pmid">22722842</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoerl</surname> <given-names>AE</given-names></name><name><surname>Kennard</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Ridge regression: biased estimation for nonorthogonal problems</article-title><source>Technometrics</source><volume>12</volume><fpage>55</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1080/00401706.1970.10488634</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaplan</surname> <given-names>HS</given-names></name><name><surname>Salazar Thula</surname> <given-names>O</given-names></name><name><surname>Khoss</surname> <given-names>N</given-names></name><name><surname>Zimmer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Nested neuronal dynamics orchestrate a behavioral hierarchy across timescales</article-title><source>Neuron</source><volume>105</volume><fpage>562</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.10.037</pub-id><pub-id pub-id-type="pmid">31786012</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname> <given-names>S</given-names></name><name><surname>Kaplan</surname> <given-names>HS</given-names></name><name><surname>Schrödel</surname> <given-names>T</given-names></name><name><surname>Skora</surname> <given-names>S</given-names></name><name><surname>Lindsay</surname> <given-names>TH</given-names></name><name><surname>Yemini</surname> <given-names>E</given-names></name><name><surname>Lockery</surname> <given-names>S</given-names></name><name><surname>Zimmer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Global brain dynamics embed the motor command sequence of <italic>Caenorhabditis elegans</italic></article-title><source>Cell</source><volume>163</volume><fpage>656</fpage><lpage>669</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.09.034</pub-id><pub-id pub-id-type="pmid">26478179</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawano</surname> <given-names>T</given-names></name><name><surname>Po</surname> <given-names>MD</given-names></name><name><surname>Gao</surname> <given-names>S</given-names></name><name><surname>Leung</surname> <given-names>G</given-names></name><name><surname>Ryu</surname> <given-names>WS</given-names></name><name><surname>Zhen</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>An imbalancing act: gap junctions reduce the backward motor circuit activity to Bias <italic>C. elegans</italic> for forward locomotion</article-title><source>Neuron</source><volume>72</volume><fpage>572</fpage><lpage>586</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.005</pub-id><pub-id pub-id-type="pmid">22099460</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>E</given-names></name><name><surname>Sun</surname> <given-names>L</given-names></name><name><surname>Gabel</surname> <given-names>CV</given-names></name><name><surname>Fang-Yen</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-term imaging of <italic>Caenorhabditis elegans</italic> using nanoparticle-mediated immobilization</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e53419</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0053419</pub-id><pub-id pub-id-type="pmid">23301069</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>SS</given-names></name><name><surname>Rouault</surname> <given-names>H</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ring attractor dynamics in the <italic>Drosophila</italic> central brain</article-title><source>Science</source><volume>356</volume><fpage>849</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1126/science.aal4835</pub-id><pub-id pub-id-type="pmid">28473639</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kocabas</surname> <given-names>A</given-names></name><name><surname>Shen</surname> <given-names>CH</given-names></name><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Ramanathan</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Controlling interneuron activity in <italic>Caenorhabditis elegans</italic> to evoke chemotactic behaviour</article-title><source>Nature</source><volume>490</volume><fpage>273</fpage><lpage>277</lpage><pub-id pub-id-type="doi">10.1038/nature11431</pub-id><pub-id pub-id-type="pmid">23000898</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leifer</surname> <given-names>AM</given-names></name><name><surname>Fang-Yen</surname> <given-names>C</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Optogenetic manipulation of neural activity in freely moving <italic>Caenorhabditis elegans</italic></article-title><source>Nature Methods</source><volume>8</volume><fpage>147</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1554</pub-id><pub-id pub-id-type="pmid">21240279</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Leifer</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>PredictionCode</data-title><source>Software Heritage</source><version designator="swh:1:rev:ca59416112a9c10a8d6a3179092a7d3c888bcd4e">swh:1:rev:ca59416112a9c10a8d6a3179092a7d3c888bcd4e</version><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:84b8b9383f5602ab9109bee37a01dd5455c3354e;origin=https://github.com/leiferlab/PredictionCode;visit=swh:1:snp:453835ab64a044fdcf67a305b15754f114d333d8;anchor=swh:1:rev:ca59416112a9c10a8d6a3179092a7d3c888bcd4e">https://archive.softwareheritage.org/swh:1:dir:84b8b9383f5602ab9109bee37a01dd5455c3354e;origin=https://github.com/leiferlab/PredictionCode;visit=swh:1:snp:453835ab64a044fdcf67a305b15754f114d333d8;anchor=swh:1:rev:ca59416112a9c10a8d6a3179092a7d3c888bcd4e</ext-link></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>W</given-names></name><name><surname>Kang</surname> <given-names>L</given-names></name><name><surname>Piggott</surname> <given-names>BJ</given-names></name><name><surname>Feng</surname> <given-names>Z</given-names></name><name><surname>Xu</surname> <given-names>XZ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neural circuits and sensory channels mediating harsh touch sensation in <italic>Caenorhabditis elegans</italic></article-title><source>Nature Communications</source><volume>2</volume><elocation-id>315</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1308</pub-id><pub-id pub-id-type="pmid">21587232</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Linderman</surname> <given-names>S</given-names></name><name><surname>Nichols</surname> <given-names>A</given-names></name><name><surname>Blei</surname> <given-names>D</given-names></name><name><surname>Zimmer</surname> <given-names>M</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hierarchical recurrent state space models reveal discrete and continuous dynamics of neural activity in <italic>C. elegans</italic></article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/621540</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindsay</surname> <given-names>TH</given-names></name><name><surname>Thiele</surname> <given-names>TR</given-names></name><name><surname>Lockery</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Optogenetic analysis of synaptic transmission in the central nervous system of the nematode <italic>Caenorhabditis elegans</italic></article-title><source>Nature Communications</source><volume>2</volume><elocation-id>306</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms1304</pub-id><pub-id pub-id-type="pmid">21556060</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>Q</given-names></name><name><surname>Hollopeter</surname> <given-names>G</given-names></name><name><surname>Jorgensen</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Graded synaptic transmission at the <italic>Caenorhabditis elegans</italic> neuromuscular junction</article-title><source>PNAS</source><volume>106</volume><fpage>10823</fpage><lpage>10828</lpage><pub-id pub-id-type="doi">10.1073/pnas.0903570106</pub-id><pub-id pub-id-type="pmid">19528650</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>M</given-names></name><name><surname>Sharma</surname> <given-names>AK</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Temporal processing and context dependency in <italic>Caenorhabditis elegans</italic> response to mechanosensation</article-title><source>eLife</source><volume>7</volume><elocation-id>e36419</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.36419</pub-id><pub-id pub-id-type="pmid">29943731</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lockery</surname> <given-names>SR</given-names></name><name><surname>Lawton</surname> <given-names>KJ</given-names></name><name><surname>Doll</surname> <given-names>JC</given-names></name><name><surname>Faumont</surname> <given-names>S</given-names></name><name><surname>Coulthard</surname> <given-names>SM</given-names></name><name><surname>Thiele</surname> <given-names>TR</given-names></name><name><surname>Chronis</surname> <given-names>N</given-names></name><name><surname>McCormick</surname> <given-names>KE</given-names></name><name><surname>Goodman</surname> <given-names>MB</given-names></name><name><surname>Pruitt</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Artificial dirt: microfluidic substrates for nematode neurobiology and behavior</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>3136</fpage><lpage>3143</lpage><pub-id pub-id-type="doi">10.1152/jn.91327.2007</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname> <given-names>L</given-names></name><name><surname>Wen</surname> <given-names>Q</given-names></name><name><surname>Ren</surname> <given-names>J</given-names></name><name><surname>Hendricks</surname> <given-names>M</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Qin</surname> <given-names>Y</given-names></name><name><surname>Greenwood</surname> <given-names>J</given-names></name><name><surname>Soucy</surname> <given-names>ER</given-names></name><name><surname>Klein</surname> <given-names>M</given-names></name><name><surname>Smith-Parker</surname> <given-names>HK</given-names></name><name><surname>Calvo</surname> <given-names>AC</given-names></name><name><surname>Colón-Ramos</surname> <given-names>DA</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dynamic encoding of perception, memory, and movement in a <italic>C. elegans</italic> chemotaxis circuit</article-title><source>Neuron</source><volume>82</volume><fpage>1115</fpage><lpage>1128</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.05.010</pub-id><pub-id pub-id-type="pmid">24908490</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mellem</surname> <given-names>JE</given-names></name><name><surname>Brockie</surname> <given-names>PJ</given-names></name><name><surname>Zheng</surname> <given-names>Y</given-names></name><name><surname>Madsen</surname> <given-names>DM</given-names></name><name><surname>Maricq</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Decoding of polymodal sensory stimuli by postsynaptic glutamate receptors in <italic>C. elegans</italic></article-title><source>Neuron</source><volume>36</volume><fpage>933</fpage><lpage>944</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)01088-7</pub-id><pub-id pub-id-type="pmid">12467596</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname> <given-names>S</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Juavinett</surname> <given-names>AL</given-names></name><name><surname>Gluf</surname> <given-names>S</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narayan</surname> <given-names>A</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name><name><surname>Sternberg</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Transfer characteristics of a thermosensory synapse in <italic>Caenorhabditis elegans</italic></article-title><source>PNAS</source><volume>108</volume><fpage>9667</fpage><lpage>9672</lpage><pub-id pub-id-type="doi">10.1073/pnas.1106617108</pub-id><pub-id pub-id-type="pmid">21606366</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname> <given-names>JP</given-names></name><name><surname>Shipley</surname> <given-names>FB</given-names></name><name><surname>Linder</surname> <given-names>AN</given-names></name><name><surname>Plummer</surname> <given-names>GS</given-names></name><name><surname>Liu</surname> <given-names>M</given-names></name><name><surname>Setru</surname> <given-names>SU</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Whole-brain calcium imaging with cellular resolution in freely behaving <italic>Caenorhabditis elegans</italic></article-title><source>PNAS</source><volume>113</volume><fpage>E1074</fpage><lpage>E1081</lpage><pub-id pub-id-type="doi">10.1073/pnas.1507110112</pub-id><pub-id pub-id-type="pmid">26712014</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname> <given-names>JP</given-names></name><name><surname>Linder</surname> <given-names>AN</given-names></name><name><surname>Plummer</surname> <given-names>GS</given-names></name><name><surname>Shaevitz</surname> <given-names>JW</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automatically tracking neurons in a moving and deforming brain</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005517</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005517</pub-id><pub-id pub-id-type="pmid">28545068</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Dostrovsky</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>The Hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><volume>34</volume><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id><pub-id pub-id-type="pmid">5124915</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piggott</surname> <given-names>BJ</given-names></name><name><surname>Liu</surname> <given-names>J</given-names></name><name><surname>Feng</surname> <given-names>Z</given-names></name><name><surname>Wescott</surname> <given-names>SA</given-names></name><name><surname>Xu</surname> <given-names>XZ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neural circuits and synaptic mechanisms underlying motor initiation in <italic>C. elegans</italic></article-title><source>Cell</source><volume>147</volume><fpage>922</fpage><lpage>933</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2011.08.053</pub-id><pub-id pub-id-type="pmid">22078887</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pirri</surname> <given-names>JK</given-names></name><name><surname>McPherson</surname> <given-names>AD</given-names></name><name><surname>Donnelly</surname> <given-names>JL</given-names></name><name><surname>Francis</surname> <given-names>MM</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A tyramine-gated chloride channel coordinates distinct motor programs of a <italic>Caenorhabditis elegans</italic> escape response</article-title><source>Neuron</source><volume>62</volume><fpage>526</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.04.013</pub-id><pub-id pub-id-type="pmid">19477154</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prevedel</surname> <given-names>R</given-names></name><name><surname>Yoon</surname> <given-names>YG</given-names></name><name><surname>Hoffmann</surname> <given-names>M</given-names></name><name><surname>Pak</surname> <given-names>N</given-names></name><name><surname>Wetzstein</surname> <given-names>G</given-names></name><name><surname>Kato</surname> <given-names>S</given-names></name><name><surname>Schrödel</surname> <given-names>T</given-names></name><name><surname>Raskar</surname> <given-names>R</given-names></name><name><surname>Zimmer</surname> <given-names>M</given-names></name><name><surname>Boyden</surname> <given-names>ES</given-names></name><name><surname>Vaziri</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy</article-title><source>Nature Methods</source><volume>11</volume><fpage>727</fpage><lpage>730</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2964</pub-id><pub-id pub-id-type="pmid">24836920</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberts</surname> <given-names>WM</given-names></name><name><surname>Augustine</surname> <given-names>SB</given-names></name><name><surname>Lawton</surname> <given-names>KJ</given-names></name><name><surname>Lindsay</surname> <given-names>TH</given-names></name><name><surname>Thiele</surname> <given-names>TR</given-names></name><name><surname>Izquierdo</surname> <given-names>EJ</given-names></name><name><surname>Faumont</surname> <given-names>S</given-names></name><name><surname>Lindsay</surname> <given-names>RA</given-names></name><name><surname>Britton</surname> <given-names>MC</given-names></name><name><surname>Pokala</surname> <given-names>N</given-names></name><name><surname>Bargmann</surname> <given-names>CI</given-names></name><name><surname>Lockery</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A stochastic neuronal model predicts random search behaviors at multiple spatial scales in <italic>C. elegans</italic></article-title><source>eLife</source><volume>5</volume><elocation-id>e12572</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12572</pub-id><pub-id pub-id-type="pmid">26824391</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schrödel</surname> <given-names>T</given-names></name><name><surname>Prevedel</surname> <given-names>R</given-names></name><name><surname>Aumayr</surname> <given-names>K</given-names></name><name><surname>Zimmer</surname> <given-names>M</given-names></name><name><surname>Vaziri</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain-wide 3D imaging of neuronal activity in <italic>Caenorhabditis elegans</italic> with sculpted light</article-title><source>Nature Methods</source><volume>10</volume><fpage>1013</fpage><lpage>1020</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2637</pub-id><pub-id pub-id-type="pmid">24013820</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname> <given-names>Y</given-names></name><name><surname>Wen</surname> <given-names>Q</given-names></name><name><surname>Liu</surname> <given-names>H</given-names></name><name><surname>Zhong</surname> <given-names>C</given-names></name><name><surname>Qin</surname> <given-names>Y</given-names></name><name><surname>Harris</surname> <given-names>G</given-names></name><name><surname>Kawano</surname> <given-names>T</given-names></name><name><surname>Wu</surname> <given-names>M</given-names></name><name><surname>Xu</surname> <given-names>T</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An extrasynaptic GABAergic signal modulates a pattern of forward movement in <italic>Caenorhabditis elegans</italic></article-title><source>eLife</source><volume>5</volume><elocation-id>e14197</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.14197</pub-id><pub-id pub-id-type="pmid">27138642</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical control of arm movements: a dynamical systems perspective</article-title><source>Annual Review of Neuroscience</source><volume>36</volume><fpage>337</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150509</pub-id><pub-id pub-id-type="pmid">23725001</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipley</surname> <given-names>FB</given-names></name><name><surname>Clark</surname> <given-names>CM</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Simultaneous optogenetic manipulation and calcium imaging in freely moving <italic>C. elegans</italic></article-title><source>Frontiers in Neural Circuits</source><volume>8</volume><elocation-id>28</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2014.00028</pub-id><pub-id pub-id-type="pmid">24715856</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Reddy</surname> <given-names>CB</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>eaav7893</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tai</surname> <given-names>DC</given-names></name><name><surname>Caldwell</surname> <given-names>BJ</given-names></name><name><surname>LeGrice</surname> <given-names>IJ</given-names></name><name><surname>Hooks</surname> <given-names>DA</given-names></name><name><surname>Pullan</surname> <given-names>AJ</given-names></name><name><surname>Smaill</surname> <given-names>BH</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Correction of motion artifact in transmembrane voltage-sensitive fluorescent dye emission in hearts</article-title><source>American Journal of Physiology. Heart and Circulatory Physiology</source><volume>287</volume><fpage>H985</fpage><lpage>H993</lpage><pub-id pub-id-type="doi">10.1152/ajpheart.00574.2003</pub-id><pub-id pub-id-type="pmid">15130885</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taube</surname> <given-names>JS</given-names></name><name><surname>Muller</surname> <given-names>RU</given-names></name><name><surname>Ranck</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Head-direction cells recorded from the postsubiculum in freely moving rats. I. description and quantitative analysis</article-title><source>The Journal of Neuroscience</source><volume>10</volume><fpage>420</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-02-00420.1990</pub-id><pub-id pub-id-type="pmid">2303851</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Venkatachalam</surname> <given-names>V</given-names></name><name><surname>Ji</surname> <given-names>N</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Clark</surname> <given-names>C</given-names></name><name><surname>Mitchell</surname> <given-names>JK</given-names></name><name><surname>Klein</surname> <given-names>M</given-names></name><name><surname>Tabone</surname> <given-names>CJ</given-names></name><name><surname>Florman</surname> <given-names>J</given-names></name><name><surname>Ji</surname> <given-names>H</given-names></name><name><surname>Greenwood</surname> <given-names>J</given-names></name><name><surname>Chisholm</surname> <given-names>AD</given-names></name><name><surname>Srinivasan</surname> <given-names>J</given-names></name><name><surname>Alkema</surname> <given-names>M</given-names></name><name><surname>Zhen</surname> <given-names>M</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pan-neuronal imaging in roaming <italic>Caenorhabditis elegans</italic></article-title><source>PNAS</source><volume>113</volume><fpage>E1082</fpage><lpage>E1088</lpage><pub-id pub-id-type="doi">10.1073/pnas.1507109113</pub-id><pub-id pub-id-type="pmid">26711989</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Xin</surname> <given-names>Q</given-names></name><name><surname>Hung</surname> <given-names>W</given-names></name><name><surname>Florman</surname> <given-names>J</given-names></name><name><surname>Huo</surname> <given-names>J</given-names></name><name><surname>Xu</surname> <given-names>T</given-names></name><name><surname>Xie</surname> <given-names>Y</given-names></name><name><surname>Alkema</surname> <given-names>MJ</given-names></name><name><surname>Zhen</surname> <given-names>M</given-names></name><name><surname>Wen</surname> <given-names>Q</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Flexible motor sequence generation during stereotyped escape responses</article-title><source>eLife</source><volume>9</volume><elocation-id>e56942</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56942</pub-id><pub-id pub-id-type="pmid">32501216</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Chemotaxis by the nematode <italic>Caenorhabditis elegans</italic>: identification of attractants and analysis of the response by use of mutants</article-title><source>PNAS</source><volume>70</volume><fpage>817</fpage><lpage>821</lpage><pub-id pub-id-type="doi">10.1073/pnas.70.3.817</pub-id><pub-id pub-id-type="pmid">4351805</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warland</surname> <given-names>DK</given-names></name><name><surname>Reinagel</surname> <given-names>P</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Decoding visual information from a population of retinal ganglion cells</article-title><source>Journal of Neurophysiology</source><volume>78</volume><fpage>2336</fpage><lpage>2350</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.78.5.2336</pub-id><pub-id pub-id-type="pmid">9356386</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname> <given-names>Q</given-names></name><name><surname>Po</surname> <given-names>MD</given-names></name><name><surname>Hulme</surname> <given-names>E</given-names></name><name><surname>Chen</surname> <given-names>S</given-names></name><name><surname>Liu</surname> <given-names>X</given-names></name><name><surname>Kwok</surname> <given-names>SW</given-names></name><name><surname>Gershow</surname> <given-names>M</given-names></name><name><surname>Leifer</surname> <given-names>AM</given-names></name><name><surname>Butler</surname> <given-names>V</given-names></name><name><surname>Fang-Yen</surname> <given-names>C</given-names></name><name><surname>Kawano</surname> <given-names>T</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name><name><surname>Whitesides</surname> <given-names>G</given-names></name><name><surname>Wyart</surname> <given-names>M</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name><name><surname>Zhen</surname> <given-names>M</given-names></name><name><surname>Samuel</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Proprioceptive coupling within motor neurons drives <italic>C. elegans</italic> forward locomotion</article-title><source>Neuron</source><volume>76</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.039</pub-id><pub-id pub-id-type="pmid">23177960</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname> <given-names>JG</given-names></name><name><surname>Southgate</surname> <given-names>E</given-names></name><name><surname>Thomson</surname> <given-names>JN</given-names></name><name><surname>Brenner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>The structure of the ventral nerve cord of <italic>Caenorhabditis elegans</italic></article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>275</volume><fpage>327</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1098/rstb.1976.0086</pub-id><pub-id pub-id-type="pmid">8806</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wicks</surname> <given-names>SR</given-names></name><name><surname>Rankin</surname> <given-names>CH</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Integration of mechanosensory stimuli in <italic>Caenorhabditis elegans</italic></article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>2434</fpage><lpage>2444</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-03-02434.1995</pub-id><pub-id pub-id-type="pmid">7891178</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>T</given-names></name><name><surname>Huo</surname> <given-names>J</given-names></name><name><surname>Shao</surname> <given-names>S</given-names></name><name><surname>Po</surname> <given-names>M</given-names></name><name><surname>Kawano</surname> <given-names>T</given-names></name><name><surname>Lu</surname> <given-names>Y</given-names></name><name><surname>Wu</surname> <given-names>M</given-names></name><name><surname>Zhen</surname> <given-names>M</given-names></name><name><surname>Wen</surname> <given-names>Q</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Descending pathway facilitates undulatory wave propagation in <italic>Caenorhabditis elegans</italic> through gap junctions</article-title><source>PNAS</source><volume>115</volume><fpage>E4493</fpage><lpage>E4502</lpage><pub-id pub-id-type="doi">10.1073/pnas.1717022115</pub-id><pub-id pub-id-type="pmid">29686107</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yemini</surname> <given-names>E</given-names></name><name><surname>Lin</surname> <given-names>A</given-names></name><name><surname>Nejatbakhsh</surname> <given-names>A</given-names></name><name><surname>Varol</surname> <given-names>E</given-names></name><name><surname>Sun</surname> <given-names>R</given-names></name><name><surname>Mena</surname> <given-names>GE</given-names></name><name><surname>Samuel</surname> <given-names>ADT</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Venkatachalam</surname> <given-names>V</given-names></name><name><surname>Hobert</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>NeuroPAL: a multicolor atlas for Whole-Brain neuronal identification in <italic>C. elegans</italic></article-title><source>Cell</source><volume>184</volume><fpage>272</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.12.012</pub-id><pub-id pub-id-type="pmid">33378642</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname> <given-names>Y</given-names></name><name><surname>Brockie</surname> <given-names>PJ</given-names></name><name><surname>Mellem</surname> <given-names>JE</given-names></name><name><surname>Madsen</surname> <given-names>DM</given-names></name><name><surname>Maricq</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neuronal control of locomotion in <italic>C. elegans</italic> is modified by a dominant mutation in the GLR-1 ionotropic glutamate receptor</article-title><source>Neuron</source><volume>24</volume><fpage>347</fpage><lpage>361</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80849-1</pub-id><pub-id pub-id-type="pmid">10571229</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname> <given-names>H</given-names></name><name><surname>Hastie</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Regularization and variable selection via the elastic net</article-title><source>Journal of the Royal Statistical Society: Series B</source><volume>67</volume><fpage>301</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66135.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Calabrese</surname><given-names>Ronald L</given-names></name><role>Reviewing Editor</role><aff><institution>Emory University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/445643">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/445643v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper will be of interest to a wide range of systems neuroscientists seeking to understanding the relationship between neuronal activity and behavior. Building on previous technical advances in brain-wide imaging of neuronal activity (Ca signals) in freely moving animals (<italic>Caenorhabditis elegans</italic>), it demonstrates that a linear regression model is sufficient reconstruct key parameters of locomotion – velocity and body curvature – from the imaging data and documents differences in activity between freely moving and immobilized worms.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Decoding locomotion from population neural activity in moving <italic>C. elegans</italic>&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Ronald Calabrese as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential Revisions:</p><p>1) Please address concerns by Reviewers #1 and #2 about identifying eigenworms with velocity and curvature (detailed in Recommendations for the authors).</p><p>2) Please address the questions with respect to tuning and noise that are raised by Reviewer #2 (detailed in Recommendations for the authors).</p><p>3) Both Reviewer #1 and #3 (detailed in Recommendations for the authors) require that you address your conclusion that the population decoder outperforms the best single neuron. Is this a meaningful comparison, and how should such coding be interpreted?</p><p>4) The concerns of Reviewers #2 and #3 about the significance of the distribution of weights assigned by the decoder for how behavior is represented in the brain should be addressed (detailed in Recommendations for the authors).</p><p>5) All Reviewers (detailed in Recommendations for the authors) have strong suggestions for reorganizing the text and amplifying and deepening Introduction and Discussion. Reviewer #3's concerns about the functional implications of the decoding should be addressed. Limitations of the analysis should be clearly addressed in Discussion.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>I hope that the authors focus on improving results and discussions sections of their strength (see above), including additional analyses, precise terminology, simplified statements, clarified discussions, and perhaps structural reorganization. I have a few concerns that I ask them to address or respond to, so that this work can be appreciated by and benefit the field. They are raised below, and should be viewed as suggestions for this purpose.</p><p>(1) Line 71-85: This first Results section (which lacks a title) is a brief definition of the locomotion features for velocity and curvature as used throughout the paper.</p><p>I am uncomfortable with the brevity of the introduction and justification of using eigenworms to represent velocity and curvature. These are two widely used biological terms, and the introduction would confuse many readers and even misled them (in the case of 'curvature').</p><p>I share the authors' opinion on the deficiency of defining velocity by the animal's centroid displacement. However, they should be equally clear that their presentation for 'velocity' did not directly address this deficit: their analysis did not calculate and present the wave velocity – the speed of bending wave propagation – which would have the units of mm/sec or body lengths/sec as opposed to radians/sec.</p><p>Moreover, in Figure 1-Figure S1, the authors demonstrated that their eigenvalue-derived velocity was well correlated with that of centroid-derived velocity values. This, to me, was a good validation to justify their choice of parameters as a proxy for velocity in later analyses. However, the authors did not cite this validation figure as its purpose, but instead in the context of a statement for the weakness of the centroid-based velocity measure. This is a misleading manipulation of citation of the authors' results.</p><p>I have a bigger concern for referencing the third eigenworm as the 'curvature', specifically Lines 82-84 (&quot;Here we report body curvature as a dimensionless quantity that captures bending in the dorsoventral plane, calculated by projecting the animal's body posture onto the third principal component of the eigenvalue decomposition.&quot;). To my understanding, this component best represents the body postures during turning. Their relationship with 'curvature' – which most would interpret not as a dimensionless quantity but as a precise measure of the degree of body bending per unit length – should be demonstrated similar to how the authors did so for velocity in Figure 1, Supplementary Figure 1. I personally consider it inappropriate to use 'curvature' when referring to the projections of the third eigenworm.</p><p>2) I found their motion correction important, interesting, and potentially useful to the community. The authors should definitely highlight it and elaborate in the text as a separate section instead of putting it away in Methods and at the end of the following Results section (Line 125: Population decoder outperforms best single neuron – this long result section can definitely benefit from 'de-mixing'.)</p><p>To me, it would be very helpful to show the example data for the authors' methods for motion correction, including the raw traces of GCaMP and RFP before and after they performed correction by their ICA analyses (e.g. I think that it did not work as well for AVAL in Figure 2b; knowing what the trace was like before the correction would help me to examine why). I also would be curious to know why these authors limited their ICA to give two components instead of collecting all components and subtracting the ones correlated with RFP. It would be good if authors treated the number of ICA components as a parameter and explored the choice of this parameter on the performance of motion correction. A discussion on systematic ways to estimate this parameter would also be very welcome.</p><p>3) Section 'Population decoder outperforms best single neuron' and Figure 3a.</p><p>Here I have trouble appreciating the significance of this comparison. Previous studies have shown that forward, backward, and turning are three separate motor motifs of <italic>C. elegans</italic> locomotion. It is possible that multiple neurons may participate in multiple motor behaviors, but it would be truly astonishing (to me at least) if a single neuron plays a dominating role of all motifs of locomotion. Given the state of the field, scientifically it would be much more meaningful to compare the performance of a population decoder to the combination of the four best single neurons e.g. the best for positive velocity, the best for negative velocity, the best for dorsal turning, and the best for ventral turning, instead of one single best neuron.</p><p>The authors could also make it clear to readers that due to the lack of knowledge of neuronal identity, as well as the fact that each recording was capturing ~2/3 of the total neuronal population, the best single neuron decoder in each recording was only 'relative' to the captured neuronal population, and likely differed per recording.</p><p>4) The organization of multiple Results sections appear lengthy and redundant. They should be combined, compressed, and reorganized. For example, the last section on correlations with AVA seems to contain the same information as &quot;immobilization alters the correlation structure of neural activity&quot;. The sections / subsections &quot;Population code for locomotion&quot; (line 193) and &quot;Largely distinct sub-populations contain information for velocity and curvature&quot; (line 256) can be better organized.</p><p>I also view AVAL and AVAR coupling more as a benchmarking tool to give the readers confidence that their method works in the non-immobilized setting instead of an interesting new finding as it seems to be portraited in the abstract. Combining these results with an expanded sections to describe their imaging processing pipeline may be a better organization solution.</p><p>5) I personally found that among all results from the model, the notion that the simplest linear model works the best is the most interesting. It would be interesting to hear the authors' thoughts on its implication of the <italic>C. elegans</italic> brain network on motor states and their transitions.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>My enthusiasm is diminished by a series of major concerns that I believe should be possible to address:</p><p>1) An important and interesting claim in the paper is that different neurons have different &quot;tunings&quot; for behavior – for example, some neurons are associated with forward velocity fluctuations, while others are associated with forward/reverse transitions. However, this is not very well explored in the paper. Some example data are shown, but that's about it. I'd suggest characterizing the full range of possible tunings that neurons can display and showing how many neurons in each of their datasets display such tunings. This could be a major strength of the paper if it is clearly characterized and communicated.</p><p>2) If the tunings are indeed diverse/complex (i.e. not just linear relationships), I'd suggest trying to predict behavior from single neurons using non-linear decoders. What is the best performance that can be obtained from single neurons using these more complex decoders? (and how does it compare to population-level decoders).</p><p>3) While it is readily apparent that the regression models perform better when trained from the full set of neurons (compared to the &quot;best single neurons&quot;), the authors' interpretation that this is because different neurons have different tunings does not yet seem fully supported. My main concern is that there is substantial levels of noise in their GCaMP measurements and that training models from more neurons may simply overcome this noise (the authors actually show that SNR impacts their predictive power in Figure 3-S1). For example, suppose that there were 2 neurons with perfectly correlated ground-truth activity and that they were both perfectly correlated with a behavior. If the activity measurements from these neurons had uncorrelated noise (noise in one neuron was not correlated with noise in the second), then a classifier trained to predict behavior would perform better if both neurons were used. In this case, this would not be due to any difference in the underlying tunings of the neurons. Are such effects occurring here? It is possible that one way to estimate the impact of these types of effects would be to compare models trained on similar amounts of data (e.g. 10min of data from one neuron vs. 5min of data from two simultaneously correlated neurons) or something like that. Another possibility would be to record single neurons (not in a whole brain context) in order to obtain higher SNR recordings and compare classifiers trained on these single neurons to those trained on the full population. (This would require knowing some of the &quot;best single neurons&quot;)</p><p>4) Related to the above point, models with more parameters almost always perform better. To determine whether the increased model performance justified the use of additional parameters, I'd suggest using AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion) formulations.</p><p>5) The Introduction does not properly introduce what is known about the neural circuitry that gives rise to locomotion in <italic>C. elegans</italic>. The roles of many neurons have been carefully characterized – it would be useful to introduce what is known about their &quot;tunings&quot; from previous work and whether the field already thinks that a population code for locomotion may exist (or not).</p><p>6) In Figure 1 -S1 the authors compare velocity in their datasets, as measured by eigenworm analysis vs. center of mass movement. While they are correlated, I was surprised by how frequently they disagree. Why do they disagree at times? Are there errors in one or both of these methods?</p><p>7) In Figure 5, I believe it would be important to only present exemplary data from timepoints in the testing datasets, not the training datasets (i.e. only present correlation coefficients for datapoints in testing data; and only show examples of neural activity and behavior from testing data). For example, it is hard to know whether the relationships in Figure 5C are meaningful or just represent overfitting of the model if they are from the training data. (If these are test data already, please just make this clear in figure legend)</p><p>8) It is not clear that analyzing the weights in Figure 5A is really all that informative with regards to the underlying roles of the neurons. The fact that the model can predict behavior in withheld data is highly informative, but the specific weights recovered are influenced by the regularization method used, whether a neuron's activity contains information redundant with some other neuron's activity, etc.</p><p>9) There are no across-animal summary data of the effects that the authors show in Figure 5. This is just exemplary data. Are these observations consistent across animals?</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>1) Abstract would benefit from a statement of the main conclusion and its significance.</p><p>2) It would be helpful to motivate the immobilization experiment by first describing the state of knowledge concerning neuronal dynamics in worms (rather than waiting until the discussion).</p><p>3) What is the meaning of the shading in Figure 1d,e and similar places in the paper?</p><p>4) For readers unfamiliar with the <italic>C. elegans</italic> nervous system, it would be useful to make clear what fraction of all head neurons is being recorded, and also what fraction of all neurons is being recorded.</p><p>5) It might be more appropriate to move the section on correcting for motion artifacts (pg. 7 [171-182ff]) earlier in the paper, where this correction is first used. Or, move it to Methods.</p><p>6) Subscript (i) in Equation 1 is misplaced on pg. 7.</p><p>7) For those unfamiliar with the Fano factor, it might be worth pointing out that in Equation 1, the variance (numerator) refers to the signal, not the noise.</p><p>8) pg. 15 [379…]. &quot;Our measurements suggest that neural dynamics from immobilized animals may not entirely reﬂect the neural dynamics of locomotion.&quot; Consider rephrasing. This sentence is almost a tautology as it says &quot;…neural dynamics in the absence of locomotion may not entirely reflect the dynamics in the presence of locomotion.&quot;</p><p>9) Line 104-5: please add Faumont et al., 2011.</p><p>10) Line 198: Do you mean &quot;Figure 5a,b&quot;?</p><p>11) Line 206-7: Is neuron #29 actually in Figure 5x?</p><p>12) Line 344-5: Can you unpack this statement?</p><p>13) Line 359-361: Give particular examples of some circuit in which this statement is true.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66135.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential Revisions:</p><p>1) Please address concerns by Reviewers #1 and #2 about identifying eigenworms with velocity and curvature (detailed in Recommendations for the authors).</p></disp-quote><p>In response to reviewer feedback, we have replaced the eigenworm analysis with more familiar definitions of velocity and curvature. Velocity is now the velocity of a point on the worm’s head in mm/s. Curvature is now the mean curvature of the centerline in κ = 𝑑θ radians/bodylength. We have revised all figures, and recalculated all models using these definitions. The conclusions remain the same. We thank the reviewers for this feedback and hope that these metrics of behavior will be more straightforward and perhaps more relevant to readers.</p><disp-quote content-type="editor-comment"><p>2) Please address the questions with respect to tuning and noise that are raised by Reviewer #2 (detailed in Recommendations for the authors).</p></disp-quote><p>Based on feedback from Reviewer #1 and #2, we have performed a new analysis and generated three new supplementary figures to characterize the full range of tunings and the number of tuned neurons in each dataset.</p><p>1. Figure 1 —figure supplement 1 shows the full range of F and dF/dT tunings with respect to velocity, including additional example tuning curves.</p><p>2. Figure 1 —figure supplement 2 shows the same for curvature.</p><p>3. Figure 1 —figure supplement 3 shows the number of significantly tuned neurons in each recording by type.</p><p>We respond to specific questions about noise in the more detailed response to Reviewer #2 further down. Briefly, AVA recordings shown in Figure 2 suggest that noise is not interfering with key features in our recordings. We thank the reviewer for posing an alternative hypothesis that multiple neurons may share the same ground truth signal and that population performance may merely reflect averaging over noisy copies of identical signals. In the new rewritten results section we now consider this explicitly and explain why our findings in Figure 5 suggest that it is unlikely the case. We have excerpted the relevant text in the detailed response to Reviewer #2.</p><disp-quote content-type="editor-comment"><p>3) Both Reviewer #1 and #3 (detailed in Recommendations for the authors) require that you address your conclusion that the population decoder outperforms the best single neuron. Is this a meaningful comparison, and how should such coding be interpreted?</p></disp-quote><p>We reorganized and revised the introduction, results and discussion to make three of our main points more clear:</p><p>1. The role of the population at representing locomotion has never before been explicitly tested in moving <italic>C. elegans.</italic></p><p>2. Tuning of neurons across the population has not been systematically characterized in moving animals.</p><p>3. The combined result that the population performs better by leveraging diversity of tuning across the population constitutes a new and meaningful conclusion.</p><p>Reviewers #1 and #3 ask whether these conclusions are obvious or predictable. We argue they are not. We point to Reviewer #2 who wonders whether our findings might “not be due to any difference in the underlying tunings of the neurons” as further evidence that these findings are far from being a foregone conclusion. More details are in the individual responses to Reviewers #1 and #3.</p><disp-quote content-type="editor-comment"><p>4) The concerns of Reviewers #2 and #3 about the significance of the distribution of weights assigned by the decoder for how behavior is represented in the brain should be addressed (detailed in Recommendations for the authors).</p></disp-quote><p>We have rewritten that portion of the Results section to better motivate our analysis of neural weights and to clarify their significance. In particular, we now explicitly distinguish between aspects of the weights that are likely dictated by the choice of model and those aspects that are not penalized by the model. For example, the model could choose a different balance between positive and negative weights, or between weights assigned to neural activity and its temporal derivative, each without penalty. That these are roughly balanced, is more likely to reflect properties of behavior-related neural signals in the brain.</p><p>“To investigate how the decoder utilizes information from the population, we inspect the neural weights assigned by the decoder. The decoder assigns one weight for each neuron’s activity, W<sub>F</sub>, and another for the temporal derivative of its activity, 𝑊 <sub>𝑑𝑓/𝑑𝑡</sub>. It uses ridge regularization to penalize weights with large amplitudes, which is equivalent to a Bayesian estimation of the weights assuming a zero-mean Gaussian prior. In the exemplar recording from Figure 1, the distribution of weights for both velocity and curvature are indeed both well-approximated by a Gaussian distribution centered at zero. This suggests that the decoder does not need to deviate significantly from the prior in order to perform well. In particular, although changing the sign of any weight would not incur a regularization penalty, the decoder relies roughly equally on neurons that are positively and negatively tuned to velocity, and similarly for curvature. At the population level, the decoder assigns weights that are roughly distributed evenly between activity signals F and temporal derivative of activity signals dF /dt (Figure 5a,b). But at the level of individual neurons, the weight assigned to a neuron’s activity 𝑊<sub>𝐹</sub> was not correlated with the weight assigned to the temporal derivative of its activity 𝑊 <sub>𝑑𝑓/𝑑𝑡</sub> (Figure 5—figure supplement 1). Again, this is consistent with the model’s prior distribution of the weights. However, given that the model could have relied more heavily on either activity signals F or on temporal derivative signals dF /dt without penalty, we find it interesting that the decoder did not need to deviate from an even distribution of weights between them in order to perform well.”</p><disp-quote content-type="editor-comment"><p>5) All Reviewers (detailed in Recommendations for the authors) have strong suggestions for reorganizing the text and amplifying and deepening Introduction and Discussion. Reviewer #3's concerns about the functional implications of the decoding should be addressed. Limitations of the analysis should be clearly addressed in Discussion.</p></disp-quote><p>In response to this and other comments, we have rewritten the introduction and discussion We also explicitly include limitations of the analysis, for example:</p><p>“However, our results do not preclude the brain from using other methods for representing behavior. And in all cases, the measurements here do not distinguish between neural signals that drive locomotion, such as motor commands; and neural signals that monitor locomotion generated elsewhere, such as proprioceptive feedback (Wen et al., 2012). The decoder likely uses a mix of both. Future perturbation studies are needed to distinguish population-level signals that drive locomotion from those that monitor locomotion”</p><p>“And it is also possible that one of the non-linear models we did test would perform better with more training data. Complex models, including non-linear models, tend to have more parameters and are therefore prone to overfitting when trained on limited data. If a non-linear model performed poorly on our held-out data due to overfitting, it may perform better when trained with longer recordings. Poor performance here therefore does not inherently preclude a non-linear model from being useful for describing behavior signals in the <italic>C. elegans</italic> nervous system. Future work with longer recordings or the ability to aggregate training across multiple recordings is needed to better evaluate whether more complex models would outperform the simple linear decoder.”</p><p>“Future studies using newly developed methods for identifying neurons (Yemeni et al., 2020) are needed to reveal the identities of those neurons weighted by the decoder for decoding velocity, curvature, or both.”</p><p>We discuss these and other changes in more detail below.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):I hope that the authors focus on improving results and discussions sections of their strength (see above), including additional analyses, precise terminology, simplified statements, clarified discussions, and perhaps structural reorganization. I have a few concerns that I ask them to address or respond to, so that this work can be appreciated by and benefit the field. They are raised below, and should be viewed as suggestions for this purpose. (1) Line 71-85: This first Results section (which lacks a title) is a brief definition of the locomotion features for velocity and curvature as used throughout the paper.</p><p>I am uncomfortable with the brevity of the introduction and justification of using eigenworms to represent velocity and curvature. These are two widely used biological terms, and the introduction would confuse many readers and even misled them (in the case of 'curvature').</p><p>I share the authors' opinion on the deficiency of defining velocity by the animal's centroid displacement. However, they should be equally clear that their presentation for 'velocity' did not directly address this deficit: their analysis did not calculate and present the wave velocity – the speed of bending wave propagation – which would have the units of mm/sec or body lengths/sec as opposed to radians/sec.</p><p>Moreover, in Figure 1-Figure S1, the authors demonstrated that their eigenvalue-derived velocity was well correlated with that of centroid-derived velocity values. This, to me, was a good validation to justify their choice of parameters as a proxy for velocity in later analyses. However, the authors did not cite this validation figure as its purpose, but instead in the context of a statement for the weakness of the centroid-based velocity measure. This is a misleading manipulation of citation of the authors' results.</p><p>I have a bigger concern for referencing the third eigenworm as the 'curvature', specifically Lines 82-84 (&quot;Here we report body curvature as a dimensionless quantity that captures bending in the dorsoventral plane, calculated by projecting the animal's body posture onto the third principal component of the eigenvalue decomposition.&quot;). To my understanding, this component best represents the body postures during turning. Their relationship with 'curvature' – which most would interpret not as a dimensionless quantity but as a precise measure of the degree of body bending per unit length – should be demonstrated similar to how the authors did so for velocity in Figure 1, Supplementary Figure 1. I personally consider it inappropriate to use 'curvature' when referring to the projections of the third eigenworm.</p></disp-quote><p>Based on this feedback, and on feedback from the other reviewers, we now use more familiar definitions of velocity and curvature. We now report velocity based on the movement of a point on the worm’s head in mm/s, and we report curvature as kappa or dtheta/dt in units of radians/bodylength. We updated all figures, recalculated all models, and rewrote the relevant methods sections. Many of the specific numerical values have changed, but the conclusions remain the same.</p><p>“To measure the animal's velocity we first find the velocity vector 𝑣 that describes the motion of a point on the animal's centerline 15% of its body length back from the tip of its head. We then project this velocity vector onto a head direction vector of unit length.</p><p>The head direction is taken to be the direction between two points along the animal's centerline, 10% and 20% posterior of the tip of the head. To calculate this velocity, the centerline and stage position measurements were first Hampel filtered and then interpolated onto a common time axis of 200 Hz (the rate at which we query stage position). Velocity was then obtained by convolving the position with the derivative of a Gaussian with σ = 0. 5s.</p><p>To measure the animal's average curvature &lt; κ &gt; at each time point, we calculated the curvature 𝑑θ/𝑑𝑠at each of 100 segments along the worm's centerline, where 𝑠 refers to the arc length of the centerline. We then took the mean of the curvatures of the middle segments that span an anterior-posterior region from 15% to 80% along the animal's centerline. This region was chosen to exclude curvature from small nose deflections (sometimes referred to as foraging) and to exclude the curvature of the tip of the tail.”</p><disp-quote content-type="editor-comment"><p>2) I found their motion correction important, interesting, and potentially useful to the community. The authors should definitely highlight it and elaborate in the text as a separate section instead of putting it away in Methods and at the end of the following Results section (Line 125: Population decoder outperforms best single neuron – this long result section can definitely benefit from 'de-mixing'.)</p><p>To me, it would be very helpful to show the example data for the authors' methods for motion correction, including the raw traces of GCaMP and RFP before and after they performed correction by their ICA analyses (e.g. I think that it did not work as well for AVAL in Figure 2b; knowing what the trace was like before the correction would help me to examine why). I also would be curious to know why these authors limited their ICA to give two components instead of collecting all components and subtracting the ones correlated with RFP. It would be good if authors treated the number of ICA components as a parameter and explored the choice of this parameter on the performance of motion correction. A discussion on systematic ways to estimate this parameter would also be very welcome.</p></disp-quote><p>We appreciate the reviewer’s interest. ICA is one of many approaches we have tried as we continue to search for an optimal motion correction algorithm. Because motion correction is not the focus of this paper, we hesitated to dive into a deeper exploration of ICA. Ultimately, we decided to remove the ICA approach and replace it with a simpler regression approach that is better motivated and is easier to justify. The new simpler approach is described in the methods and excerpted below. It is well motivated under the assumption of linear additive noise; is computationally efficient; has only one free parameter; and is entirely deterministic, unlike common implementations of ICA. We have updated all figures and models using the new motion correction algorithm and revised the methods section. While numeric values throughout the paper changed, none of our conclusions changed upon switching motion correction algorithms.</p><p>“We used the GCaMP fluorescence together with the RFP fluorescence to calculate a motion corrected fluorescence, 𝐹<sub>𝑚𝑐</sub> used through the paper. Note sometimes the subscript <sub>𝑚𝑐</sub> is omitted for brevity. Motion and deformation in the animal's head</p><p>introduce artifacts into the fluorescent time-series. We assume that these artifacts are common to both GCaMP and RFP fluorescence, up to a scale factor, because both experience the same motion. For example, if a neuron is compressed during a head bend, the density of both GCaMP and RFP should increase, causing an increase in the fluorescence in both time-series. We expect that the RFP time series is entirely dominated by artifacts because, in the absence of motion, the RFP fluorescent intensity</p><p>would be constant. If we further assume that motion artifacts are additive, then a simple correction follows naturally. To correct for motion in the GCaMP fluorescence 𝐺, we subtract off a scaled RFP fluorescence, 𝑅, <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mtext>mc</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>G</mml:mi><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>R</mml:mi><mml:mo>&gt;</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> where α is a scaling factor that is fit for each neuron so as to minimize <inline-formula><mml:math id="inf132"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow/><mml:mrow/></mml:msubsup><mml:mrow><mml:mo form="prefix" stretchy="true">(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo form="prefix" stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>R</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo form="postfix" stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula></p><p>The final motion corrected signal 𝐹<sub>𝑚𝑐</sub> is mean-subtracted.”</p><p>We note we have also revised how we set color bars for visualizing heatmaps of neural activity, as described in the methods:</p><p>“When presenting heatmaps of calcium activity, we set the colormap to visualize the motion-corrected data with the original, uncorrected dynamic range. Recordings in which neurons contain little signal compared to motion artifact will appear dimmer, while recordings in which neurons contain signal with large dynamics compared to the motion artifact will appear brighter. The limits on the colormap are determined by the uncorrected green fluorescent timeseries, specifically the 99th percentile of of all neurons at all time points <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:mo>&lt;</mml:mo><mml:mi>G</mml:mi><mml:mo>&gt;</mml:mo></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> in the recording.”</p><p>Here are requested, smoothed, AVA traces before and after motion correction with the revised motion correction algorithm (mean-subtracted). We attribute the lower quality of the AVAL trace to AVAL’s spatial location at the far end of the animal relative to the microscope objective, as mentioned in the text. The difference between the original (F) and motion corrected (F<sub>mc</sub>) signals are subtle, as we expect. Note that previous recordings of AVA in moving worms report the sum of AVAR and AVAL because they cannot resolve the two independently. We now also report the sum in new Figure 2 —figure supplement 1 to facilitate comparison to the literature.</p><disp-quote content-type="editor-comment"><p>3) Section 'Population decoder outperforms best single neuron' and Figure 3a</p><p>Here I have trouble appreciating the significance of this comparison. Previous studies have shown that forward, backward, and turning are three separate motor motifs of <italic>C. elegans</italic> locomotion. It is possible that multiple neurons may participate in multiple motor behaviors, but it would be truly astonishing (to me at least) if a single neuron plays a dominating role of all motifs of locomotion. Given the state of the field, scientifically it would be much more meaningful to compare the performance of a population decoder to the combination of the four best single neurons e.g. the best for positive velocity, the best for negative velocity, the best for dorsal turning, and the best for ventral turning, instead of one single best neuron.</p></disp-quote><p>This comparison has never been done before, and it is important to establish. We have revised our framing and added text clarifying the significance of the comparison. From the introduction:</p><p>“Despite growing interest in the role of population dynamics in the worm, their dimensionality, and their relation to behavior (Costa et al., 2019; Linderman et al., 2019; Brennan et al., 2019; Fieseler et al., 2020) it is not known how locomotory related information contained at the population level compares to that contained at the level of single neurons.”</p><p>In particular, we are also interested in how those signals combine:</p><p>“There has not yet been a systematic exploration of the types and distribution of locomotor related signals present in the neural population during movement and their tunings. So for example, it is not known whether all forward related neurons exhibit duplicate neural signals or whether a variety of distinct signals are combined.”</p><p>While it would be interesting to explore the four best single neurons, we worried that this would add confusion and disrupt the flow. We hope with the new framing the reviewers and editors see value in comparing against a single neuron.</p><disp-quote content-type="editor-comment"><p>The authors could also make it clear to readers that due to the lack of knowledge of neuronal identity, as well as the fact that each recording was capturing ~2/3 of the total neuronal population, the best single neuron decoder in each recording was only 'relative' to the captured neuronal population, and likely differed per recording.</p></disp-quote><p>We now clarify in the text:</p><p>“Because the correspondence between neurons across animals is not known in these recordings, the identities of neurons used by the population decoder and that of the specific best single neuron may vary from recording to recording.”</p><disp-quote content-type="editor-comment"><p>4) The organization of multiple Results sections appear lengthy and redundant. They should be combined, compressed, and reorganized. For example, the last section on correlations with AVA seems to contain the same information as &quot;immobilization alters the correlation structure of neural activity&quot;. The sections / subsections &quot;Population code for locomotion&quot; (line 193) and &quot;Largely distinct sub-populations contain information for velocity and curvature&quot; (line 256) can be better organized.</p></disp-quote><p>Based on this feedback we have removed many of the subsection headings, combined others, and streamlined the text in places.</p><disp-quote content-type="editor-comment"><p>I also view AVAL and AVAR coupling more as a benchmarking tool to give the readers confidence that their method works in the non-immobilized setting instead of an interesting new finding as it seems to be portraited in the abstract. Combining these results with an expanded sections to describe their imaging processing pipeline may be a better organization solution.</p></disp-quote><p>We agree that the AVA recordings serve a benchmarking role. We have revised the abstract Accordingly:</p><p>“To validate our measurements, we labeled neurons AVAL and AVAR and found that their activity exhibited expected transients during backward locomotion.”</p><p>and updated the text in the Results section:</p><p>“To validate our population recordings, we investigated the well-characterized neuron pair AVAL and AVAR.”</p><p>We have left Figure 2 in the main text because the AVA recordings are an important and useful validation of our measurements.</p><disp-quote content-type="editor-comment"><p>5) I personally found that among all results from the model, the notion that the simplest linear model works the best is the most interesting. It would be interesting to hear the authors' thoughts on its implication of the <italic>C. elegans</italic> brain network on motor states and their transitions.</p></disp-quote><p>We have now added two paragraphs to the discussion:</p><p>“How should we interpret the finding that the decoder is linear? It has been observed that even very non-linear neural systems can encode information linearly. For example, the vertebrate retina has many highly non-linear connections but a linear decoder</p><p>performs indistinguishably from an artificial neural network at decoding visual signals from populations of retinal ganglian cells (Warland et al., 1997). <italic>C. elegans</italic> may be another example, like the retina, of a non-linear system that represents information</p><p>linearly. The <italic>C. elegans</italic> nervous system, however, also contains known instances of connections that appear linear over a physiologically relevant range of activities (Liu eet al., 2009; Lindsay et al., 2011, Narayan et al., 2011). So, it is also possible that the linear representation of behavior in <italic>C. elegans</italic> reflects linear circuitry in the brain.</p><p>We note that our exploration of non-linear models was not exhaustive. Although we tested a selection of non-linear models at the single neuron Figure 3 – Figure Supplement 5 and population level Figure 3 —figure supplement 4, it is possible that a different non-linear model would perform better. And it is also possible that one of the non-linear models we did test would perform better with more training data. Complex models, including non-linear models, tend to have more parameters and are therefore prone to overfitting when trained on limited data. If a non-linear model performed poorly on our held-out data due to overfitting, it may perform better when trained with longer recordings. Poor performance here therefore does not inherently preclude a non-linear model from being useful for describing behavior signals in the <italic>C. elegans</italic> nervous system. Future work with longer recordings or the ability to aggregate training across multiple recordings is needed to better evaluate whether more complex models would outperform the simple linear decoder.”</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>My enthusiasm is diminished by a series of major concerns that I believe should be possible to address:</p><p>1) An important and interesting claim in the paper is that different neurons have different &quot;tunings&quot; for behavior – for example, some neurons are associated with forward velocity fluctuations, while others are associated with forward/reverse transitions. However, this is not very well explored in the paper. Some example data are shown, but that's about it. I'd suggest characterizing the full range of possible tunings that neurons can display and showing how many neurons in each of their datasets display such tunings. This could be a major strength of the paper if it is clearly characterized and communicated.</p></disp-quote><p>Based on this feedback, and feedback from Reviewer #1, we added three new supplementary figures to characterize the full range of tunings and the number of tuned neurons in each dataset.</p><p>1. Figure 1 —figure supplement 1 shows the full range of F and dF/dT tunings with respect to velocity, including example tuning curves selected from neurons with a range of Pearson’s correlation coefficients.</p><p>2. Figure 1 —figure supplement 2 shows the full range of tunings with respect to curvature.</p><p>3. Figure 1 —figure supplement 3 shows the number of significantly tuned neurons by category in each recording.</p><disp-quote content-type="editor-comment"><p>2) If the tunings are indeed diverse/complex (i.e. not just linear relationships), I'd suggest trying to predict behavior from single neurons using non-linear decoders. What is the best performance that can be obtained from single neurons using these more complex decoders? (and how does it compare to population-level decoders).</p></disp-quote><p>Thank you for this suggestion. We now added Figure 3 —figure supplement 5 to show how various non-linear single neuron models compare to the linear population model.</p><disp-quote content-type="editor-comment"><p>3) While it is readily apparent that the regression models perform better when trained from the full set of neurons (compared to the &quot;best single neurons&quot;), the authors' interpretation that this is because different neurons have different tunings does not yet seem fully supported. My main concern is that there is substantial levels of noise in their GCaMP measurements and that training models from more neurons may simply overcome this noise (the authors actually show that SNR impacts their predictive power in Figure 3-S1). For example, suppose that there were 2 neurons with perfectly correlated ground-truth activity and that they were both perfectly correlated with a behavior. If the activity measurements from these neurons had uncorrelated noise (noise in one neuron was not correlated with noise in the second), then a classifier trained to predict behavior would perform better if both neurons were used. In this case, this would not be due to any difference in the underlying tunings of the neurons. Are such effects occurring here? It is possible that one way to estimate the impact of these types of effects would be to compare models trained on similar amounts of data (e.g. 10min of data from one neuron vs. 5min of data from two simultaneously correlated neurons) or something like that. Another possibility would be to record single neurons (not in a whole brain context) in order to obtain higher SNR recordings and compare classifiers trained on these single neurons to those trained on the full population. (This would require knowing some of the &quot;best single neurons&quot;)</p></disp-quote><p>Quality varies across recordings, and we mention this in the text. But the evidence in Figure 2 does not suggest substantial levels of noise. Prior recordings (Ben Arous et al., 2010; Shipley et al., 2014) report the sum of AVAL and AVAR together because they cannot resolve the individual neurons. We now also report the sum of AVAL and AVAR’s activity in Figure 2 - Supplementary Figure 1 to make it easier to compare noise levels to previous reports. By comparing this trace with previous reports we conclude that the noise in this recording is not dramatically larger than in prior reports and, crucially, the noise is small compared to the relevant features of interest.</p><p>&quot;We also report the sum of the individual traces in Figure 2—figure supplement 1. The similarity we observe between activities of AVAL and AVAR, and the similarities between our recordings of AVA and those previously reported in the literature serves to validate our ability to simultaneously record neural activity accurately from across the brain. It also suggests that the noise in this recording is modest compared to the features of interest in AVA’s calcium transients.&quot;</p><p>The evidence in Figure 5 suggests that the population decoder does not derive its performance simply by averaging over noisy neurons with the same ground-truth signals. In Figure 5d highly weighted neuron #77 has activity peaks at certain ventral turns while highly weighted neuron #84 has activity peaks at a complimentary set. It is unlikely that these neurons have the same ground truth signals, especially because we know from Figure 2 that the noise in this recording is small compared to features of interest (and these are from the same recording). The simplest explanation is that the decoder uses a variety of different types of neural signals from the population to decode. We thank the reviewer for raising this hypothesis because it is interesting and important to explore, and we now use it to frame this portion of our rewritten Results section:</p><p>“We wondered what types of signals are combined by the decoder. For example, it is conceptually useful to consider a simple null hypothesis in which multiple neurons exhibit exact copies of the same behavior-related signal with varying levels of noise. In that case, the population decoder would outperform the best single neuron merely by summing over duplicate noisy signals. We inspected the activity traces of the top weighted neurons in our exemplar recording (Figure 5c,d). Some highly weighted neurons had activity traces that appeared visually similar to the animal’s locomotory trace for the duration of the recording (e.g.#80 for curvature) and other neurons had activity that might plausibly be noisy copies of each other (e.g. #12 and #60 for velocity). But other highly weighted neurons had activity traces that were distinct or only matched specific features of the locomotory behavior. For example negatively weighted neuron #59 exhibited distinct positive peaks during dorsal turns (green arrows), but did not consistently exhibit corresponding negative peaks during ventral turns. This is consistent with prior reports of neurons such as SMDD that are known to exhibit peaks during dorsal but not ventral head bends (Hendricks et al., 2012; Shen et al., 2016; Kaplan et al., 2020).</p><p>In the recording shown, we also find some neurons that have activity matched to only specific instances of a behavior motif. For example, the temporal derivative of the activity of neuron #84 contributes distinct peaks to ventral bends at approximately 105 s and 210 s, but not during similar ventral turns at other time points (Figure 5d, blue arrows). Conversely, highly weighted neuron #77 contributes sharp peaks corresponding to four other ventral bends (Figure 5d, red arrows) that are absent from neuron #84. Similarly (although perhaps less striking) for velocity, neurons #24 and #110 contribute peaks for one set of reversals (Figure 5c, red arrows), while neuron #44 contributes peaks to a complimentary set of two reversals (Figure 5c, blue arrows). Similarly in recording AML32_A, different neurons contribute peaks of activity corresponding to different sets of ventral or dorsal turns, Figure 5 —figure supplement 3. While we observed this effect in some recordings, it was not obviously present in every recording. From this inspection of highly weighted neurons, we conclude that in at least some recordings the decoder is not primarily averaging over duplicate signals. Instead the decoder sums together different types of neural signals, including those that capture only a certain feature of a behavior (e.g. dorsal turns or ventral turns, but not both) or that seemingly capture only certain instance of the same behavior motif (some reversals but not others).&quot;</p><disp-quote content-type="editor-comment"><p>4) Related to the above point, models with more parameters almost always perform better. To determine whether the increased model performance justified the use of additional parameters, I'd suggest using AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion) formulations.</p></disp-quote><p>We address concerns about overfitting by evaluating the model on held-out data. On held-out data, increasing the number of parameters does not always cause a performance increase. For example, Figure 3 —figure supplement 4h shows that a decision tree actually performs the worst of all models tested even though it has the most parameters (more than twice as many as any other model, as detailed in Table 5). We now explain this more clearly in the text:</p><p>“Evaluating performance on held-out data mitigates potential concerns that performance gains merely reflect over-fitting. In the context of held-out data, models with more parameters, even those that are over-fit, will not inherently perform better.”</p><p>And also in another section:</p><p>“Note that while adding features is guaranteed to improve performance on the training set, performance on the held-out test set did not necessarily have to improve.”</p><p>And we discuss implications of the over-fitting problem in the rewritten Discussion section:</p><p>“Complex models, including non-linear models, tend to have more parameters and are therefore prone to overfitting when trained on limited data. If a non-linear model performed poorly on our held-out data due to overfitting, it may perform better when trained with longer recordings. Poor performance here therefore does not inherently preclude a non-linear model from being useful for describing behavior signals in the C. elegans nervous system. Future work with longer recordings or the ability to aggregate training across multiple recordings is needed to better evaluate whether more complex models would outperform the simple linear decoder.”</p><disp-quote content-type="editor-comment"><p>5) The Introduction does not properly introduce what is known about the neural circuitry that gives rise to locomotion in <italic>C. elegans</italic>. The roles of many neurons have been carefully characterized – it would be useful to introduce what is known about their &quot;tunings&quot; from previous work and whether the field already thinks that a population code for locomotion may exist (or not).</p></disp-quote><p>Based on this, and other feedback, we have expanded the introduction to discuss more about what is known:</p><p>“The known locomotory circuitry in <italic>C. elegans</italic> focuses on a collection of pre-motor neurons and interneurons, including AVA, AVE, AVB, AIB, AIZ, RIM, RIA, RIV, RIB and PVC that have many connec-tions amongst themselves and send signals to downstream motor neurons involved in locomotion such as the A- or B-type or SMD motor neurons (White et al., 1976; Chalfie et al., 1985; Zheng et al., 1999; Gray et al., 2005; Gordus et al., 2015; Wang et al., 2020). These neurons can be grouped into categories that are related to forward locomotion, backward locomotion or turns. For example, AVA, AIB, RIM are part of a backward locomotory circuit (Zheng et al., 1999; Pirri et al., 2009; Gordus et al., 2015). AVB and PVC are part of a forward locomotion circuit (Gray et al., 2005; Chalfie et al., 1985; Zheng et al., 1999; Li et al., 2011; Xu et al., 2018) and RIV, RIB and RIA are related to turns (Gray et al., 2005; Li et al., 2011; Wang et al., 2020; Hendricks et al., 2012). Much of what we know about these neurons comes from recordings or manipulations of either single neurons at a time, or a selection of neurons simultaneously using sparse promoters (Gray et al., 2005; Guo et al., 2009; Arous et al., 2010; Kawano et al., 2011; Piggott et al., 2011; Gao et al., 2018; Wang et al., 2020). Only recently has it been possible to record from large populations of neurons first in immobile (Schrödel et al., 2013; Prevedel et al., 2014; Kato et al., 2015) and then moving animals (Nguyen et al., 2016; Venkatachalam et al., 2016).”</p><p>In the results and Discussion section we also try to provide more context and background. Selected examples:</p><p>“This is consistent with neurons such as RIVL/R that are active during ventral turns (Wang et al., 2020) or the SMDDs or SMDVs that have activity peaks during either dorsal or ventral head bends respectively (Hendricks et al., 2012; Shen et al., 2016; Kaplan et al., 2020).”</p><p>“This is consistent with other reports, including recent work suggesting that turning and reverse circuits are largely distinct modules except for a select few neurons, such as RIB, which may be involved in both (Wang et al., 2020)”</p><p>“…the temporal derivative of activity of AIB has been shown to be elevated during those reversals that are followed by turns compared to those followed by forward locomotion (Wang et al., 2020).”</p><p>“This is consistent with prior reports that for some neurons, like AVA, it is the temporal derivative of activity that correlates with aspects of locomotion (Kato et al., 2015) while for other neurons, such as AIY, it is the activity itself (Luo et al., 2014).”</p><disp-quote content-type="editor-comment"><p>6) In Figure 1 -S1 the authors compare velocity in their datasets, as measured by eigenworm analysis vs. center of mass movement. While they are correlated, I was surprised by how frequently they disagree. Why do they disagree at times? Are there errors in one or both of these methods?</p></disp-quote><p>For simplicity we now report velocity based on a point on the animal’s head, as described in the methods. All figures have been regenerated to reflect this change. We discuss this change in more detail in response to similar concerns raised by Reviewer #1.</p><p>“To measure the animal's velocity we first find the velocity vector 𝑣 that describes the motion of a point on the animal's centerline 15% of its body length back from the tip of its head. We then project this velocity vector onto a head direction vector of unit length. The head direction is taken to be the direction between two points along the animal's centerline, 10% and 20% posterior of the tip of the head. To calculate this velocity, the centerline and stage position measurements were first Hampel filtered and then interpolated onto a common time axis of 200 Hz (the rate at which we query stage position). Velocity was then obtained by convolving the position with the derivative of a Gaussian with σ = 0. 5s.”</p><disp-quote content-type="editor-comment"><p>(7) In Figure 5, I believe it would be important to only present exemplary data from timepoints in the testing datasets, not the training datasets (i.e. only present correlation coefficients for datapoints in testing data; and only show examples of neural activity and behavior from testing data). For example, it is hard to know whether the relationships in Figure 5C are meaningful or just represent overfitting of the model if they are from the training data. (if these are test data already, please just make this clear in figure legend)</p></disp-quote><p>Thank you for the suggestion. We now show which portion of the recording is held-out by adding light green shading to the traces in Figure 5c,d (same as Figure 3a,c) and we clarify in the caption.</p><disp-quote content-type="editor-comment"><p>8) It is not clear that analyzing the weights in Figure 5A is really all that informative with regards to the underlying roles of the neurons. The fact that the model can predict behavior in withheld data is highly informative, but the specific weights recovered are influenced by the regularization method used, whether a neuron's activity contains information redundant with some other neuron's activity, etc.</p></disp-quote><p>We agree that some properties of the neural weights are predetermined by choice of regularization. But many properties are not. We now clarify explicitly which features of the neural weights are expected from model choice, and which are not penalized by the model and therefore may more likely reflect properties of the brain:</p><p>“To investigate how the decoder utilizes information from the population, we inspect the neural weights assigned by the decoder. The decoder assigns one weight for each neuron’s activity, 𝑊<sub>𝐹 ,</sub> and another for the temporal derivative of its activity, 𝑊<sub>𝑑𝑓/𝑑𝑡.</sub> It uses ridge regularization to penalize weights with large amplitudes, which is equivalent to a Bayesian estimation of the weights assuming a zero-mean Gaussian prior. In the exemplar recording from Figure 1, the distribution of weights for both velocity and curvature are indeed both well-approximated by a Gaussian distribution centered at zero. This suggests that the decoder does not need to deviate significantly from the prior in order to perform well. In particular, although changing the sign of any weight would not incur a regularization penalty, the decoder relies roughly equally on neurons that are positively and negatively tuned to velocity, and similarly for curvature.</p><p>At the population level, the decoder assigns weights that are roughly distributed evenly between activity signals F and temporal derivative of activity signals dF /dt (Figure 5a,b). But at the level of individual neurons, the weight assigned to a neuron’s activity 𝑊<sub>𝐹</sub> was not correlated with the weight assigned to the temporal derivative of its activity 𝑊<sub>𝑑𝑓/𝑑𝑡</sub> (Figure 5—figure supplement 1). Again, this is consistent with the model’s prior distribution of the weights. However, given that the model could have relied more heavily on either activity signals F or on temporal derivative signals dF /dt without penalty, we find it interesting that the decoder did not need to deviate from an even distribution of weights between them in order to perform well.”</p><disp-quote content-type="editor-comment"><p>9) There are no across-animal summary data of the effects that the authors show in Figure 5. This is just exemplary data. Are these observations consistent across animals?</p></disp-quote><p>We do not know of a satisfactory quantitative method for summarizing the effect in Figure 5 across recordings. Instead we now added a new example from a different recording in figure 5 —figure supplement 3. And we now clarify explicitly in the text:</p><p>“While we observed this effect in some recordings, it was not obviously present in every recording.”</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>1) Abstract would benefit from a statement of the main conclusion and its significance.</p></disp-quote><p>A major significance of this work is that it provides needed experimental measurements to inform and constrain the interpretation of population dynamics. There is a growing body of literature interpreting population dynamics of locomotion (Kato et al., 2015, Costa et al., 2019, Linderman et al., 2019, Fieseler et al., 2020), yet until now fundamental measurements have been missing, such as the information in the population vs the single neuron or the relevance of immobile dynamics to study locomotion. We have revised the abstract to allude to this.</p><p>“We investigated the neural representation of locomotion in the nematode <italic>C. elegans</italic> by recording population calcium activity during movement. We report that population activity more accurately decodes locomotion than any single neuron. Relevant signals are distributed across neurons with diverse tunings to locomotion. Two largely distinct</p><p>subpopulations are informative for decoding velocity and curvature, and different neurons' activities contribute features relevant for different aspects of a behavior or different instances of a behavioral motif. To validate our measurements, we labeled neurons AVAL and AVAR and found that their activity exhibited expected transients during backward locomotion. Finally, we compared population activity during movement and immobilization. Immobilization alters the correlation structure of neural activity and its dynamics. Some neurons positively correlated with AVA during movement become negatively correlated during immobilization and vice versa. This work provides needed experimental measurements that inform and constrain ongoing efforts to understand population dynamics underlying locomotion in <italic>C. elegans</italic>.”</p><p>And we have better introduced these points in the introduction, excerpt is included in response to next item, below.</p><disp-quote content-type="editor-comment"><p>2) It would be helpful to motivate the immobilization experiment by first describing the state of knowledge concerning neuronal dynamics in worms (rather than waiting until the discussion).</p></disp-quote><p>We now do this, as suggested:</p><p>&quot;Interestingly, results from recordings in immobile animals suggest that population neural state space trajectories in a low dimensional space may encode global motor commands (Kato et al., 2015), but this has yet to be explored in moving animals. Despite growing interest in the role of population dynamics in the worm, their dimensionality, and their relation to behavior (Costa et al., 2019; Linderman et al., 2019; Brennan and Proekt, 2019; Fieseler et al., 2020) it is not known how locomotory related information contained at the population level compares to that contained at the level of single neurons. And importantly, current findings of population dynamics related to locomotion in <italic>C. elegans</italic> are from immobilized animals. While there are clear benefits in studying fictive locomotion (Ahrens et al., 2012; Briggman et al., 2005; Kato et al., 2015), it is not known for <italic>C. elegans</italic> how neural population dynamics during immobile fictive locomotion compare to population dynamics during actual movement.&quot;</p><disp-quote content-type="editor-comment"><p>3) What is the meaning of the shading in Figure 1d,e and similar places in the paper?</p></disp-quote><p>Shaded circles show individual fluorescent time points. We now clarify:</p><p>“Blue or orange shaded circles show neural activity at each time point during behavior.”</p><disp-quote content-type="editor-comment"><p>4) For readers unfamiliar with the <italic>C. elegans</italic> nervous system, it would be useful to make clear what fraction of all head neurons is being recorded, and also what fraction of all neurons is being recorded.</p></disp-quote><p>Changed:</p><p>“To investigate locomotory-related signals in the brain, we simultaneously recorded calcium activity from the majority of the 188 neurons in the head…”</p><disp-quote content-type="editor-comment"><p>5) It might be more appropriate to move the section on correcting for motion artifacts (pg. 7 [171-182ff]) earlier in the paper, where this correction is first used. Or, move it to Methods.</p></disp-quote><p>We ultimately decided to keep that discussion of motion correction in its current location because it is pertinent when thinking about issues of noise, for example as raised by Reviewer #2. We also cover the key points in the section of the methods entitled “Motion-correction.”</p><disp-quote content-type="editor-comment"><p>6) Subscript (i) in Equation 1 is misplaced on pg. 7.</p></disp-quote><p>Thanks. Fixed.</p><disp-quote content-type="editor-comment"><p>7) For those unfamiliar with the Fano factor, it might be worth pointing out that in Equation 1, the variance (numerator) refers to the signal, not the noise.</p></disp-quote><p>Thank you for the suggestion:</p><p>“Here the variance term is related to the signal in the recording.”</p><disp-quote content-type="editor-comment"><p>8) pg. 15 [379…]. &quot;Our measurements suggest that neural dynamics from immobilized animals may not entirely reﬂect the neural dynamics of locomotion.&quot; Consider rephrasing. This sentence is almost a tautology as it says &quot;…neural dynamics in the absence of locomotion may not entirely reflect the dynamics in the presence of locomotion.&quot;</p></disp-quote><p>We have rewritten that section, reworded that statement and added context:</p><p>“That <italic>C. elegans</italic> neural dynamics exhibit different correlation structure during movement than during immobilization has implications for neural representations of locomotion. For example, it is now common to use dimensionality reduction techniques like PCA to search for low-dimensional trajectories or manifolds that relate to behavior or decision making in animals undergoing movement (Churchland et al., 2012; Harvey et al., 2012; Shenoy et al., 2013) or in immobilized animals undergoing fictive locomotion (Briggman et al., 2005; Kato et al., 2015). PCA critically depends on the correlation structure to define its principal components. In <italic>C. elegans</italic>, the low-dimensional neural trajectories observed in immobilized animals undergoing fictive locomotion, and the underlying correlation structure that defines those trajectories, are being used to draw conclusions about neural dynamics of actual locomotion. Our measurements suggest that to obtain a more complete picture of <italic>C. elegans</italic> neural dynamics related to locomotion, it will be helpful to probe neural state space trajectories recorded during actual locomotion: both because the neural dynamics themselves may differ during immobilization, but also because the correlation structure observed in the network, and consequently the relevant principal components, change upon immobilization. These changes may be due to proprioception (Wen et al., 2012), or due to different internal states associated with fictive versus actual locomotion.&quot;</p><disp-quote content-type="editor-comment"><p>9) Line 104-5: please add Faumont et al., 2011.</p></disp-quote><p>Added.</p><disp-quote content-type="editor-comment"><p>10) Line 198: Do you mean &quot;Figure 5a,b&quot;?</p></disp-quote><p>Yes. Thank you. Fixed.</p><disp-quote content-type="editor-comment"><p>11) Line 206-7: Is neuron #29 actually in Figure 5x?</p></disp-quote><p>This should be Figure 5c. Fixed. Thanks.</p><disp-quote content-type="editor-comment"><p>12) Line 344-5: Can you unpack this statement?</p></disp-quote><p>We have clarified with an example:</p><p>“One possible explanation is that superficially similar behavioral features like turns may actually consist of different underlying behaviors. For example, seemingly similar turns, on closer inspection, can be further subdivided into distinct groups (Broekmans et al., 2016).”</p><p>And we have added a related example:</p><p>“The neural representation associated with a motif may also depend on its behavioral context, including the behaviors that follow or proceed it. For example, the temporal derivative of activity of AIB has been shown to be elevated during those reversals that</p><p>are followed by turns compared to those followed by for- ward locomotion (Wang et al., 2020). The population may contain a variety of such neurons, each tuned to only a specific context of a given behavior, which would give rise to the neurons used by the decoder that are seemingly tuned to some instances of a motif and not others. The granularity with which to classify behaviors and how to take into account context and behavioral hierarchies remains an active area of research in <italic>C. elegans</italic> (Liu et al., 2018; Kaplan et al., 2020) and in other model systems (Berman et al., 2016; Datta et al., 2019). Ultimately, finding distinct neural signals may help inform our understanding of distinct behavior states and vice versa.&quot;</p><disp-quote content-type="editor-comment"><p>13) Line 359-361: Give particular examples of some circuit in which this statement is true.</p></disp-quote><p>We now provide an example:</p><p>&quot;For example, both polymodal nociceptive stimuli detected from ASH (Mellem et al., 2002) and anterior mechanosensory stimuli detected from soft touch neurons ALM and AVM (Wicks and Rankin, 1995) activate reversals through shared circuitry containing AVA, among other common neurons. It is possible that the neural activities we observe for different behavioral motifs reflect sensory signals that arrive through different sensory pathways to evoke a common downstream motor response.&quot;</p></body></sub-article></article>