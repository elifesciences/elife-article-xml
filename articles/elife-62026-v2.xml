<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">62026</article-id><article-id pub-id-type="doi">10.7554/eLife.62026</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Scanned optogenetic control of mammalian somatosensory input to map input-specific behavioral outputs</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-203516"><name><surname>Schorscher-Petcu</surname><given-names>Ara</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5808-5172</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-203517"><name><surname>Takács</surname><given-names>Flóra</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-202056"><name><surname>Browne</surname><given-names>Liam E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5693-7703</contrib-id><email>liam.browne@ucl.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution>Wolfson Institute for Biomedical Research, and Department of Neuroscience, Physiology and Pharmacology, University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Abdus-Saboor</surname><given-names>Ishmail</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>29</day><month>07</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e62026</elocation-id><history><date date-type="received" iso-8601-date="2020-08-11"><day>11</day><month>08</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-07-28"><day>28</day><month>07</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-08-10"><day>10</day><month>08</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.08.10.244046"/></event></pub-history><permissions><copyright-statement>© 2021, Schorscher-Petcu et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Schorscher-Petcu et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-62026-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-62026-figures-v2.pdf"/><abstract><p>Somatosensory stimuli guide and shape behavior, from immediate protective reflexes to longer-term learning and higher-order processes related to pain and touch. However, somatosensory inputs are challenging to control in awake mammals due to the diversity and nature of contact stimuli. Application of cutaneous stimuli is currently limited to relatively imprecise methods as well as subjective behavioral measures. The strategy we present here overcomes these difficulties, achieving ‘remote touch’ with spatiotemporally precise and dynamic optogenetic stimulation by projecting light to a small defined area of skin. We mapped behavioral responses in freely behaving mice with specific nociceptor and low-threshold mechanoreceptor inputs. In nociceptors, sparse recruitment of single-action potentials shapes rapid protective pain-related behaviors, including coordinated head orientation and body repositioning that depend on the initial body pose. In contrast, activation of low-threshold mechanoreceptors elicited slow-onset behaviors and more subtle whole-body behaviors. The strategy can be used to define specific behavioral repertoires, examine the timing and nature of reflexes, and dissect sensory, motor, cognitive, and motivational processes guiding behavior.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>To safely navigate their world, animals need to be able to tell apart a gentle touch from an eye-watering pinch, detect cold water or sense the throbbing pain stemming from an infected cut. These ‘somatic’ sensations are relayed through thousands of nerve endings embedded in the skin and other tissues. Yet the neurological mechanisms that underpin these abilities are complex and still poorly understood.</p><p>Indeed, these nerve endings can be stimulated by extreme temperatures, harmful chemicals, friction or even internal signals such as inflammation. One event can also recruit many different types of endings: a cut for example, will involve responses to mechanical pressure, tissue damage and local immune response. To disentangle these different actors and how they affect behavior, scientists need to develop approaches that allow them to deliver specific stimuli with increased precision, and to monitor the impact on an animal.</p><p>To achieve this goal, Schorscher-Petcu et al. used mice in which blue light could trigger specific types of nerve endings. For instance, depending on the genetic background of the animals, a laser could either activate nerve endings involved in pain or gentle touch. Crucially, this could be done from a distance by beaming light with exquisite precision onto the paws of the mice without physically touching or disturbing the animals.</p><p>How the mice responded could then be observed without any interference. Their behavior was analyzed using a combination of high-speed videos, computer-driven recording systems, and machine learning. This revealed subtle changes in behavior that had not been detected before, spotting microscopic movements of the stimulated paw and mapping simultaneous whole-body movements such as changes in posture or head orientation. The approach therefore allows scientists to assess the impact of touch, pain or temperature sensation in freely behaving mice. It could also be harnessed to develop much needed treatments against chronic pain.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>somatosensation</kwd><kwd>pain</kwd><kwd>touch</kwd><kwd>machine vision</kwd><kwd>behavior</kwd><kwd>optogenetics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>Sir Henry Dale Fellowship 109372/Z/15/Z</award-id><principal-award-recipient><name><surname>Browne</surname><given-names>Liam E</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000288</institution-id><institution>Royal Society</institution></institution-wrap></funding-source><award-id>Sir Henry Dale Fellowship 109372/Z/15/Z</award-id><principal-award-recipient><name><surname>Browne</surname><given-names>Liam E</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A system to generate ‘remote touch’ in freely behaving mice can be utilized to map behavior caused by precise somatosensory inputs.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The survival of an organism depends on its ability to detect and respond appropriately to its environment. Afferent neurons innervating the skin provide sensory information to guide and refine behavior (<xref ref-type="bibr" rid="bib36">Seymour, 2019</xref>; <xref ref-type="bibr" rid="bib42">Zimmerman et al., 2014</xref>). Cutaneous stimuli are used to study a wide range of neurobiological mechanisms since neurons densely innervating skin function to provide diverse information as the body interfaces with its immediate environment. These afferents maintain the integrity of the body by recruiting rapid sensorimotor responses, optimize movement through feedback loops, provide teaching signals that drive learning, and update internal models of the environment through higher-order perceptual and cognitive processes (<xref ref-type="bibr" rid="bib6">Barik et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Brecht, 2017</xref>; <xref ref-type="bibr" rid="bib15">Corder et al., 2019</xref>; <xref ref-type="bibr" rid="bib17">de Haan and Dijkerman, 2020</xref>; <xref ref-type="bibr" rid="bib20">Haggard et al., 2013</xref>; <xref ref-type="bibr" rid="bib23">Huang et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Petersen, 2019</xref>; <xref ref-type="bibr" rid="bib36">Seymour, 2019</xref>). Damaging stimuli, for example, evoke rapid motor responses to minimize immediate harm and generate pain that motivates longer-term behavioral changes.</p><p>Compared to visual, olfactory, and auditory stimuli, somatosensory inputs are challenging to deliver in awake unrestrained mammals. This is due to the nature of stimuli that require contact and the diversity of stimulus features encoded by afferents that innervate skin. Cutaneous afferent neurons are functionally and genetically heterogeneous, displaying differential tuning, spike thresholds, adaptation rates, and conduction velocities (<xref ref-type="bibr" rid="bib3">Abraira and Ginty, 2013</xref>; <xref ref-type="bibr" rid="bib18">Dubin and Patapoutian, 2010</xref>; <xref ref-type="bibr" rid="bib19">Gatto et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Häring et al., 2018</xref>). The arborization of their peripheral terminals can delineate spatial and temporal dimensions of the stimulus (<xref ref-type="bibr" rid="bib33">Pruszynski and Johansson, 2014</xref>), particularly once many inputs are integrated by the central nervous system (<xref ref-type="bibr" rid="bib32">Prescott et al., 2014</xref>). Cutaneous stimulation in freely moving mice often requires the experimenter to manually touch or approach the skin. This results in inaccurate timing, duration, and localization of stimuli. The close proximity of the experimenter can cause observer-induced changes in animal behavior (<xref ref-type="bibr" rid="bib38">Sorge et al., 2014</xref>). Stimuli also activate a mixture of sensory neuron populations. For example, intense stimuli can co-activate fast-conducting low-threshold afferents that encode innocuous stimuli simultaneously with more slowly conducting high-threshold afferents (<xref ref-type="bibr" rid="bib40">Wang et al., 2018</xref>). The latter are nociceptors that trigger fast protective behaviors and pain. Consequently, mixed cutaneous inputs recruit cells, circuits, and behaviors that are not specific to the neural mechanism under study. A way to control genetically defined afferent populations is to introduce opsins into these afferents and optogenetically stimulate them through the skin (<xref ref-type="bibr" rid="bib1">Abdo et al., 2019</xref>; <xref ref-type="bibr" rid="bib5">Arcourt et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Barik et al., 2018</xref>; <xref ref-type="bibr" rid="bib7">Beaudry et al., 2017</xref>; <xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>; <xref ref-type="bibr" rid="bib16">Daou et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Iyer et al., 2014</xref>). However, these methods in their current form do not fully exploit the properties of light.</p><p>The behaviors that are evoked by cutaneous stimuli are also typically measured with limited and often subjective means. Manual scoring introduces unnecessary experimenter bias and omits key features of behavior. Behavioral assays have traditionally focused on a snapshot of the stimulated body part rather than dynamics of behavior involving the body as a whole (<xref ref-type="bibr" rid="bib19">Gatto et al., 2019</xref>). Recent advances in machine vision and markerless pose estimation have enabled the dissection of animal behavioral sequences (<xref ref-type="bibr" rid="bib29">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib30">Pereira et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Wiltschko et al., 2015</xref>). However, these have not been adapted to study behavioral outputs relating to specific cutaneous inputs.</p><p>Here we developed an approach to project precise optogenetic stimuli onto the skin of freely behaving mice (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The strategy elicits time-locked individual action potentials in genetically targeted afferents innervating a small stimulation field targeted to the skin. Stimuli can be delivered remotely as predefined microscale patterns, lines, or moving points. The utility of the system was demonstrated by precisely stimulating nociceptors, or Aβ low threshold mechanoreceptors (LTMRs), in freely behaving mice to map behavioral outputs at high speed. We provide an analysis toolkit that quantifies the millisecond-timescale dynamics of behavioral responses using machine vision methods. We dissect discrete behavioral components of local paw responses, head orienting and body repositioning behaviors, and determine how these specific behavioral components relate to precise somatosensory inputs.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Remote and precise somatosensory input and analysis of behavior.</title><p>(<bold>A</bold>) Afferent neurons expressing ChR2 are controlled remotely in freely behaving mice by projecting laser light with sub-millimeter precision to the skin. This enables precise non-contact stimulation with microscale patterns, lines, and points using scanned transdermal optogenetics. Time-locked triggering of single-action potential volleys is achieved through high temporal control of the laser. Behavioral responses can be automatically recorded and analyzed using a combination of computational methods. (<bold>B</bold>) Schematic of the stimulation laser (in blue) and infrared imaging (in red) paths. Mirrors (M1 and M2) direct the laser beam through a set of lenses (L1–L3), which allow the beam to be focused manually to pre-calibrated spot sizes. A dichroic mirror (DM) guides the laser beam into a pair of galvanometer mirrors, which are remotely controlled to enable precise targeting of the beam onto the glass platform. Near-infrared frustrated total internal reflection (NIR-FTIR) signal from the glass platform is descanned through the galvanometers and imaged using a high-speed infrared camera. A second wide-field camera is used to concomitantly record a below view of the entire glass platform. (<bold>C</bold>) Rendering of the assembled components. A Solidworks assembly is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/browne-lab/throwinglight">https://github.com/browne-lab/throwinglight</ext-link>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Technical calibration of the optical system.</title><p>(<bold>A</bold>) Average spot areas calculated from triplicate measures taken at nine distinct coordinates of the experimental glass platform. The stability of spot size area over time was demonstrated by re-sampling area measurements for S<sub>1</sub> and S<sub>6</sub> 6 months after extensive use of the system (orange). (<bold>B</bold>) Uniformity of laser spot area across the surface of the experimental glass platform. Heatmaps of average areas for spot sizes S<sub>1</sub> to S<sub>8</sub> as measured in triplicates at nine distinct coordinates covering the entire glass platform and fitted with a two-dimensional polynomial equation. (<bold>C</bold>) Uniformity of laser power across the glass platform was demonstrated by measuring laser power in triplicates at five distinct locations using spot size S<sub>1</sub> and 100 mW laser output.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Hardware and software information flow used in the optical system.</title><p>Schematic illustrating the information flow between the system’s operating software and the different hardware components. A master computer allows user input to be transformed into digital signals, which are fed into a multifunction I/O device to coordinate the triggering of the laser, cameras, and analog control of the galvanometers. The same computer is used to record high-speed paw and full-body behaviors acquired through two separate cameras. Automated analysis is performed offline.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig1-figsupp2-v2.tif"/></fig></fig-group></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Design of the optical approach</title><p>The design of the optical strategy had eight criteria: (1) that somatosensory stimuli are delivered non-invasively without touching or approaching the mice; (2) localization of stimuli are spatially precise and accurate (&lt;10 μm); (3) freely moving mice can be targeted anywhere within a relatively large (400 cm<sup>2</sup>) arena; (4) stimuli can be controlled with a computer interface from outside the behavior room; (5) stimulation patterns, lines, and points are generated by rapidly scanning the stimuli between predefined locations; (6) stimulation size can be controlled down to ≥150 μm diameter; (7) stimuli are temporally precise to control individual action potentials using sub-millisecond time-locked pulses; and (8) behavioral responses are recorded at high speed at the stimulated site and across the whole body simultaneously. An optical system was assembled to meet these specific criteria (<xref ref-type="fig" rid="fig1">Figure 1B and C</xref>).</p><p>The stimulation path uses two mirror galvanometers to remotely target the laser stimulation to any location on a large glass stimulation floor. A series of lenses expands the beam and then focuses it down to 0.018 mm<sup>2</sup> (150 μm beam diameter) at the surface of this floor. This was defocused to provide a range of calibrated stimulation spot sizes up to 2.307 mm<sup>2</sup>, with separable increments that were stable over long periods of time (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). The optical power density could be kept equal between these different stimulation spot sizes. The glass floor was far (400 mm) from the galvanometers, resulting in a maximum focal length variability of &lt;1.5% (see Materials and methods). This design yielded a spatial targeting resolution of 6.2 μm while minimizing variability in laser stimulation spot sizes across the large stimulation plane (coefficient of variation ≤0.1, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). The beam ellipticity was 74.3% ± 14.3% (median± MAD, range of 36–99%) for all spot sizes. The optical power was uniform across the stimulation plane (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). The galvanometers allow rapid small angle step (300 µs) responses to scan the laser beam between adjacent positions and shape stimulation patterns using brief laser pulses (diode laser rise and fall time: 2.5 ns). Custom software (see Materials and methods) was developed to remotely control the laser stimulation position, trigger laser pulses, synchronize galvanometer jumps, and trigger the camera acquisition (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p><p>The camera acquisition path was used to manually target the location of the laser stimulation pulse(s); the path was descanned through the galvanometers so that the alignment between the laser and camera is fixed (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The camera feed is displayed in the user interface and enables the operator to use this image to target the laser to the desired location. High signal-to-noise recordings were obtained using near-infrared frustrated total internal reflection (NIR-FTIR) in the glass stimulation floor (Roberson, D. P. et al., manuscript submitted). If a medium (skin, hair, tail, etc.) is within a few hundred microns of the glass, it causes reflection of the evanescent wave and this signal decreases non-linearly with distance from the glass such that very minor movements of the paw can be detected. The acquisition camera acquired the NIR-FTIR signal in high-speed (up to 1000 frames/s) with a pixel size of 110 μm. A second camera was used to record the entire arena and capture behaviors involving the whole body before and after stimulation. Offline quantification was carried out using custom analysis code combined with markerless tracking tools (<xref ref-type="bibr" rid="bib29">Mathis et al., 2018</xref>).</p></sec><sec id="s2-2"><title>Mapping high-speed local responses to nociceptive input</title><p>To validate the strategy, we first crossed <italic>Trpv1</italic>-IRES-Cre (TRPV1<sup>Cre</sup>) and R26-CAG-LSL-ChR2-tdTomato mice to obtain a line (TRPV1<sup>Cre</sup>::ChR2) in which ChR2 is selectively expressed in a broad class of nociceptors innervating glabrous skin (<xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>). These mice were allowed to freely explore individual chambers placed on the stimulation plane. When mice were idle (still and awake), a time-locked laser pulse was targeted to the hind paw. Stimuli could be controlled remotely from outside the behavior room. We recorded paw withdrawal dynamics with millisecond resolution. For example, a single, small 1 ms laser pulse initiated a behavioral response at 29 ms, progressing to complete removal of the hind paw from the glass floor just 5 ms later (<xref ref-type="fig" rid="fig2">Figure 2A</xref> and <xref ref-type="video" rid="fig2video1">Figure 2—video 1</xref>). The stimulus used for this protocol was S<sub>6</sub>, 0.577 mm<sup>2</sup> in area, which corresponds to less than 1% of the glabrous paw area and highlights the sensitivity of the nociceptive system. Motion energy, individual pixel latencies, and response dynamics could be extracted from these high-speed recordings (<xref ref-type="fig" rid="fig2">Figure 2B and C</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Scanned optogenetic stimuli reveal relationships with local behaviors.</title><p>(<bold>A</bold>) Millisecond-timescale changes in hind paw near-infrared frustrated total internal reflection (NIR-FTIR) signal in response to a single 1 ms laser pulse (laser spot size S<sub>6</sub> = 0.577 mm<sup>2</sup>) recorded at 1000 frames/s. (<bold>B</bold>) Motion energy analysis (left) and response latencies calculated for each pixel (right) for the same trial as in (<bold>A</bold>). (<bold>C</bold>) Example traces of the NIR-FTIR signal time course as measured within a circular region of interest centered on the stimulation site. Six traces from two animals are depicted (1 ms pulse, spot size S<sub>6</sub> = 0.577 mm<sup>2</sup>). The red trace corresponds to the example trial illustrated in (<bold>A</bold>) and (<bold>B</bold>). (<bold>D</bold>) Paw response probability increases as a function of laser pulse duration when stimulation size is constant (spot size S<sub>6</sub> = 0.577 mm<sup>2</sup>; 37–42 trials for each pulse duration from eight mice, mean probability ± SEM). Light pulses 10 ms or less with the same intensity and wavelength have been shown to generate just a single-action potential in each nociceptor activated in the TRPV1<sup>Cre</sup>::ChR2 line (<xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>). Note that a 30 ms might generate more than one action potential but the response already plateaus at 10 ms duration, suggesting one action potential per nociceptor shapes the response. (<bold>E</bold>) Paw response probability increases as a function of laser stimulation spot size when pulse duration is constant. Data are 34–45 trials for each spot size per pulse duration from 7 to 8 mice, shown as mean probability ± SEM. The dataset for (<bold>D</bold>) and (<bold>E</bold>) is provided in <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>. (<bold>F</bold>) Stimulation patterning shows that the absolute size, rather than the geometric shape, of the nociceptive stimulus determines the withdrawal probability (Friedman’s non-parametric test for within subject repeated measures S(5) = 22.35, p=0.0004). Paw response probabilities in response to a single large laser spot (S<sub>7</sub> = 1.15 mm<sup>2</sup>), a single small spot (S<sub>4</sub> = 0.176 mm<sup>2</sup>; p=0.018 compared to S<sub>7</sub> and p=0.013 compared to the line pattern), a 10 ms train of seven small 1 ms spots targeting the same site (p=0.039, compared to S<sub>7</sub> and p=0.030 compared to the line pattern) or spatially translated to produce different patterns. Note that the cumulative area of the seven small spots approximates the area of the large spot, and no statistically significant difference was detected between any of their response probabilities. Data shown as mean probability ± SEM are from n = 6 mice, with each 6–10 trials per pattern. The dataset for (<bold>F</bold>) is provided in <xref ref-type="supplementary-material" rid="fig2sdata2">Figure 2—source data 2</xref>.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Time courses of paw movement recorded at 1000 frames/s with stimuli that vary in duration and size.</title><p>Stimuli (40 mW/mm<sup>2</sup>) were delivered at 0 ms. Data are from TRPV1<sup>Cre</sup>::ChR2 mice and littermate controls.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-62026-fig2-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig2sdata2"><label>Figure 2—source data 2.</label><caption><title>Time courses of paw movement recorded at 500 frames/s with single point and patterned stimuli.</title><p>Stimuli (1 ms, 40 mW/mm<sup>2</sup>) were delivered at 0 ms. Data are from TRPV1<sup>Cre</sup>::ChR2 mice and littermate controls.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-62026-fig2-data2-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Microscale mapping of sensitivity to noxious optogenetic stimulation.</title><p>Paw response probabilities at 11 discrete 0.0185 mm<sup>2</sup> stimulation locations across the hind paw glabrous skin using single-pulse stimulations (3 ms) in n = 8 mice. Response probabilities were determined manually.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Littermate controls do not respond to optogenetic stimulation.</title><p>(<bold>A</bold>) Examples of the near-infrared frustrated total internal reflection hind paw signal before, during, and after laser stimulation (arrow). (<bold>B</bold>) Examples of bottom-view camera recordings before, during, and after laser stimulation. (<bold>C</bold>) Raster plots of hind paw dynamics in response to a single 30 ms pulse (spot size S<sub>8</sub> = 2.307 mm<sup>2</sup>) in TRPV1<sup>Cre</sup>::ChR2 mice (32 trials from seven mice) and littermate controls (16 trials from four mice). Where applicable, the paw response latency is indicated in red.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig2-figsupp2-v2.tif"/></fig><media id="fig2video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-62026-fig2-video1.mp4"><label>Figure 2—video 1.</label><caption><title>Pain-related hind paw withdrawals.</title><p>Millisecond-timescale changes in hind paw near-infrared frustrated total internal reflection signal in response to a single 1 ms laser pulse (laser spot size <italic>S</italic><sub><italic>5</italic></sub> = 0.577 mm<sup>2</sup>) recorded at 1000 frames/s. Six individual trials from two different TRPV1<sup>Cre</sup>::ChR2 mice are shown.</p></caption></media></fig-group><p>We probed multiple sites across the plantar surface and digits and found that the hind paw heel gave the most robust responses (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). This region was targeted in all subsequent experiments. Littermates that did not express the Cre recombinase allele confirmed that the laser stimulation did not produce non-specific responses. These mice did not show any behavioral responses, even with the largest stimuli (spot size S<sub>8</sub>, 30 ms pulse, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). We next provide some examples of the utility of the strategy by examining the relationship between nociceptive input and protective behaviors.</p></sec><sec id="s2-3"><title>Probabilistic nociceptor recruitment determines the nature, timing, and extent of behavior</title><p>Fast protective withdrawal behaviors can be triggered by the first action potential arriving at the spinal cord from cutaneous nociceptors. A brief optogenetic stimulus generates just a single-action potential in each nociceptor activated (<xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>). This is due to the rapid closing rate of ChR2 relative to the longer minimal interspike interval of nociceptors. The same transient optogenetic stimulus (<xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>), or a pinprick stimulus (<xref ref-type="bibr" rid="bib5">Arcourt et al., 2017</xref>), initiates behavior before a second action potential would have time to arrive at the spinal cord. That the first action potential can drive protective behaviors places constraints on how stimulus intensity can be encoded, suggesting that the total population of nociceptors firing a single-action potential can provide information as a &quot;Boolean array.&quot; The consequences of this have not been investigated previously as precise control of specific nociceptive input had not been possible. We predicted that the relative number of nociceptors firing a single-action potential determines the features of the behavioral response.</p><p>Varying the pulse duration with nanosecond precision influences the probability of each nociceptor generating a single-action potential within the stimulation site. A pulse as short as 300 μs elicited behavioral responses but with relatively low probability (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This probability increased with pulse duration until it approached unity, closely matching the on-kinetics of the ChR2 used (<italic>τ</italic> = 1.9 ms; <xref ref-type="bibr" rid="bib27">Lin, 2011</xref>). We next controlled the spatial, rather than temporal, properties of the stimulation in two further experiments. Firstly, we find that the total area of stimulated skin determines the behavioral response probability, such that the larger the nociceptive input the larger the response probability (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). Secondly, we generated different stimulation patterns. We find that sub-threshold stimulations are additive (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). Specifically, seven spatially displaced small sub-threshold stimulations could reproduce the response probability of a single large stimulation that was approximately seven times their size. This could not be achieved by repeated application of the small stimulations to the same site (<xref ref-type="fig" rid="fig2">Figure 2F</xref>).</p><p>Time-locking the stimulus enabled us to examine the hind paw responses with high temporal resolution. The nociceptive input size influenced the behavioral response latency: for example, a 3 ms pulse resulted in response latencies of 27 ± 1 ms, 30 ± 2 ms, 33 ± 5 ms, and 112 ± 46 ms for spot sizes S<sub>8</sub>, S<sub>7</sub>, S<sub>6</sub>, and S<sub>5</sub>, respectively (<xref ref-type="fig" rid="fig3">Figure 3A and B</xref>). The shorter latencies are consistent with medium-conduction velocity Aδ-fibers that arrive at the spinal cord before slower C-fiber action potentials (&gt;35 ms) (<xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>). The rank order of response latencies follows the nociceptive input size for both pulse durations, and they fit well with log-log regressions (3 ms pulse <italic>R<sup>2</sup></italic> = 0.87, 1 ms pulse <italic>R<sup>2</sup></italic> = 0.90). Once a hind limb motor response was initiated, it developed rapidly, lifting from the glass with rise times that show the vigor of the motor response was also dependent on nociceptive input size (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). These responses, in &gt;65% of cases, proceeded to full withdrawal. However, in a fraction of trials the paw moved but did not withdraw (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), highlighting the sensitivity of the acquisition system. Even the smallest of nociceptive inputs still produced a large fraction of full withdrawal responses, despite decreases in response probability (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). The fraction of full withdrawal responses increased with the size of nociceptive input. The onset latency of both full and partial responses decreased as nociceptive input increased (<xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Paw response latency and magnitude are influenced by the sparse recruitment of nociceptors.</title><p>(<bold>A</bold>) Raster plots of hind paw responses for five different 3 ms laser stimulation sizes, sorted by response latency. The paw response latency is indicated in red. (<bold>B</bold>) Paw response latencies to trials with single 3 ms (blue, top) and 1 ms (green, bottom) stimulations at different spot sizes, sorted by latency. (<bold>C</bold>) Response vigor (hind paw rise time, 20–80%) to single 3 ms (blue, top) or 1 ms (green, bottom) pulses with a range of stimulation spot sizes. Rise times to a 3 ms pulse were 4 ± 1 ms, 4 ± 1 ms, 4 ± 1 ms, and 9 ± 5 ms for spot sizes S<sub>8</sub>, S<sub>7</sub>, S<sub>6</sub>, and S<sub>5</sub>, respectively, and to a 1 ms pulse were 4 ± 1 ms, 5 ± 2 ms, and 6 ± 3 ms for spot sizes S<sub>8</sub>, S<sub>7</sub>, and S<sub>6</sub>, respectively. (<bold>D</bold>) Extent of responses (%NIR-FTIR signal decrease). The threshold for a full response and partial response is 75% of baseline signal (red line). (<bold>E</bold>) The probability of responses to reach completion (full response) as a function of the probability of response for four stimulation spot sizes and two pulse durations (green 1 ms; blue 3 ms). (<bold>F</bold>) Response latency distributions for trials that reach completion (full response) shown with Gaussian kernel density estimation of data (left). Rug plot inset representing individual response latencies for each color-coded spot size. No correlation was observed between response latency and extent for partial responses when stimulation duration was 3 ms. Data from 7 to 8 mice with 39–44 trials per spot size for 1 ms pulse duration and 34–44 per spot size for 3 ms pulse duration. The dataset is provided in <xref ref-type="supplementary-material" rid="fig2sdata1">Figure 2—source data 1</xref>. NIR-FTIR: near-infrared frustrated total internal reflection.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig3-v2.tif"/></fig></sec><sec id="s2-4"><title>Whole-body behavioral responses to remote and precise nociceptive input</title><p>Pain-related responses are not limited to the affected limb but involve simultaneous movement of other parts of the body (<xref ref-type="bibr" rid="bib8">Blivis et al., 2017</xref>; <xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>). These non-local behaviors theoretically serve several protective purposes: to investigate and identify the potential source of danger, move the entire body away from this danger, attend to the affected area of the body (<xref ref-type="bibr" rid="bib23">Huang et al., 2019</xref>) and to maintain balance (<xref ref-type="bibr" rid="bib37">Sherrington, 1910</xref>). Whole-body movements were quantified as motion energy (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>) and high-speed recordings show this initiated with a mean response latency of 30 ± 1 ms, with the first movement bout displaying a mean duration of 136 ± 14 ms (80 trials from 10 mice) (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). The magnitude of whole-body movement increased with the stimulation spot size (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>). Peak motion energy had a lognormal relationship with nociceptive input size (<italic>R<sup>2</sup></italic> = 0.99). This indicates that global behaviors are also proportional to the relative size of the nociceptive input; the recruited nociceptors firing a single-action potential (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>).</p></sec><sec id="s2-5"><title>Sparse nociceptor stimulation triggers coordinated postural adjustments</title><p>Most behaviors arise from the complex coordination of discrete body parts, which can be tracked individually. To dissect specific components of these behaviors, we implemented DeepLabCut (<xref ref-type="bibr" rid="bib29">Mathis et al., 2018</xref>) by training a network using frames from the high-speed (400 frames/s) videos to track 18 user-defined body parts across the mouse (for details, refer to Materials and methods<italic>, Global behaviors during optogenetic stimulation</italic>). The high-speed video recordings of stimulation trials were analyzed using this network. Specific nociceptive input at the hind paw (S<sub>8</sub>, 2.307 mm<sup>2</sup>, 10 ms pulse) causes behavior that initiates simultaneously across the body. Inspection of the movements of each body part relative to the baseline pose (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) shows fast outward movement of the stimulated and contralateral hind paws, and concomitant initiation of head orientation (two example responses in <xref ref-type="fig" rid="fig4">Figure 4B</xref>). Based on these observations, we examined the behavioral trajectories in the first 115 ms across the population of 80 trials. The first three principal components (PCs) were fit using six body part x and y values at 115 ms after the stimulus onset. These PCs explain 88.8% of the variance (50.4, 26.5, and 11.9% for PC1, PC2, and PC3, respectively). PC1 is dominated by hind paw translation, PC2 by head and body movement, and PC3 by head orientation (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Projecting the entire time course onto these same PCs can explain 78.1% of the variance (37.1, 24.3, and 16.7% for PC1, PC2, and PC3, respectively). The response trajectories revealed that movements occur largely in same direction within PC space with a circular standard deviation of 52.9° (<xref ref-type="fig" rid="fig4">Figure 4D and E</xref>). Shuffling body parts on each trial gave non-directional trajectories with a circular standard deviation of 126.8° (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). Behavioral trajectories also show that the response magnitude in PC space can be partly explained by initial PC1 and PC2 values (<xref ref-type="fig" rid="fig4">Figure 4F and G</xref>). This suggests that the initial pose influences these fast behavioral responses.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Mapping whole-body behavioral repertoires to precise nociceptive input.</title><p>(<bold>A</bold>) Example spatiotemporal structure of a noxious stimulus response superimposed on the baseline image taken immediately before stimulus. The color indicates the timing of nose and hind paw trajectories. In this example, the left hind paw of the mouse was stimulated, which is the right hind paw as viewed in the image. For ease, we refer to the stimulation side as viewed in the image, rather than the side with respect to the mouse. (<bold>B</bold>) Example graphical representation showing the sequence of postural adjustment following nociceptive stimulus in two trials. Left: the left (as viewed) hind paw was stimulated. Right: the right (as viewed) hind paw was stimulated. (<bold>C</bold>) Principal component analysis of the x and y values for six body parts – nose, left hind paw digits, left hind paw heel, right hind paw digits, right hind paw heel, and tail base – across all 80 trials. Coordinates were egocentrically aligned by the baseline pose, setting the tail base as origin and the stimulated paw on the right. This allowed the reconstruction of these locations using the first three principal components (PCs). Using the mean values of PC1, PC2, and PC3 with the stimulated hind paw indicated in blue (top); the mean values of PC2 and PC3, while varying PC1 either side of its mean by one standard deviation (middle-top); the mean values of PC1 and PC3, while varying PC2 (middle-bottom); and the mean values of PC1 and PC2, varying PC3 (bottom). (<bold>D</bold>) Behavioral trajectories of the 80 trials in PC space, showing 35–115 ms after stimulation. Only the first two PCs are shown for clarity. (<bold>E</bold>) PC vectors based on (<bold>D</bold>) show that trajectories are largely in the same direction. (<bold>F</bold>) The response magnitude (shown by colors that represent shift in PC2) varies as a function the initial pose, reduced to the first two PCs. (<bold>G</bold>) The initial PC values correlate with the shift in PC2 (left three plots). The initial PC3 value also correlates with the shift in PC3 (right). Least-squares linear fits are shown in blue and <italic>r</italic> values are Pearson’s correlation coefficients. (<bold>H</bold>) Raster plots of the distances that each tracked body part moves relative to baseline in 80 trials from 10 mice. All raster plots are sorted by maximum distances achieved by the stimulated paw within 300 ms of the stimulation. (<bold>I</bold>) Six representative traces showing the Euclidean distance between the stimulated paw and nose. (<bold>J</bold>) This expansion and shortening of Euclidean distance between the stimulated paw and the nose are shown up to 300 ms post-stimulus for all 80 trials by plotting the maximum distances as a function of the minimum distance. Corresponding rug plots (orange ticks) and a kernel density estimate (gray lines) are shown. (<bold>K</bold>) Traces showing the angle of the nose normalized to mean baseline angle between the nose and tail base. The tail base reflects the origin in these calculations. 80 trials are shown, with stimulation on the left hind paw and right hind paw (top). Average traces are shown in <italic>blue</italic> and <italic>red</italic> for left and right hind paw stimulations, respectively. Polar histograms for mean nose yaw during 300 ms post-stimulus, corresponding to the traces directly above (below). The dataset is provided in <xref ref-type="supplementary-material" rid="fig4sdata2">Figure 4—source data 2</xref>.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Whole-body motion energy recorded at 40 frames/s with different size stimuli.</title><p>Stimuli (3 ms, 40 mW/mm<sup>2</sup>) were delivered at 0 ms. Data are from TRPV1<sup>Cre</sup>::ChR2 mice.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-62026-fig4-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig4sdata2"><label>Figure 4—source data 2.</label><caption><title>Time courses for coordinates of six tracked body parts recorded at 400 frames/s.</title><p>Stimuli (10 ms, 40 mW/mm<sup>2</sup>, laser spot size <italic>S<sub>8</sub></italic> = 2.307 mm<sup>2</sup>) were delivered at 0 ms and body parts tracked with DeepLabCut. Data are from TRPV1<sup>Cre</sup>::ChR2 mice.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-62026-fig4-data2-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Motion energy analysis of behavior evoked by precisely controlled nociceptive input size.</title><p>(<bold>A </bold>) Left: example image from the below-view camera, recording whole-body behavior at 40 frames/s, 75 ms after stimulus delivery (3 ms pulse, spot size S<sub>6</sub> = 0.577 mm<sup>2</sup>). (Right) Motion energy calculated 75 ms after the stimulus. (<bold>B</bold>) Motion energy increases with larger spot sizes when pulse duration is kept constant at 3 ms. Violin plots with 41–47 trials per spot size from eight mice. Individual trials are shown, along with the associated median in black. The dataset is provided in <xref ref-type="supplementary-material" rid="fig4sdata1">Figure 4—source data 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Motion energy analysis of high-speed recordings.</title><p>(<bold>A</bold>) Example motion energy trace acquired from 400 fps videos (top). The stimulus time is shown in red. Example image of animal motion detected by subtraction of neighboring frames (bottom). Pixels that change intensity are shown in black. (<bold>B</bold>) Raster plots of the motion energy time course from 10 TRPV1<sup>Cre</sup>::ChR2 mice from two litters (top; 80 trials from 10 mice) and control littermate mice from the same two litters (bottom; 40 trials from 5 mice). Trials are sorted according to their maximum peak response. The red vertical line represents stimulus. (<bold>C</bold>) Histogram of latencies for stimulus-evoked full-body movements. Latencies were detected at time points when motion energy pixel counts exceeded 10 times standard deviation of the mean baseline signal. (<bold>D</bold>) Histogram of the duration of stimulus-evoked full-body movements. Termination of movement was detected when motion energy pixel counts returned below 10 times standard deviation of baseline signal.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Principal component analysis of shuffled behavioral data.</title><p>Body part labels were shuffled on each trial and dimensionality reduction carried out identically as for non-shuffled data in <xref ref-type="fig" rid="fig4">Figure 4</xref>. The first principal component (PC1) explained 22.2% of variance, the second (PC2) 16.4%, and the third (PC3) 13.5%. Left: shuffled data show trajectories that were static compared to non-shuffled data. Right: trajectories were not uniformly directional.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig4-figsupp3-v2.tif"/></fig><media id="fig4video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-62026-fig4-video1.mp4"><label>Figure 4—video 1.</label><caption><title>Markerless tracking of behavior in response to nociceptive stimulation.</title><p>Markerless tracking of postural adjustments in a TRPV1<sup>Cre</sup>::ChR2 mouse, in response to a 10 ms optogenetic noxious stimulation (laser spot size <italic>S</italic><sub><italic>8</italic></sub> = 2.307 mm<sup>2</sup>). Body parts are labeled with multicolor points and the hind paws and nose connected with magenta lines. The time shown is relative to the stimulus onset.</p></caption></media></fig-group><p>Examining specific features of these behaviors over a slightly longer period (300 ms) provides further insights. Displacement of each body part relative to their baseline position reveals the response timing, extent, and coordination (<xref ref-type="fig" rid="fig4">Figure 4H</xref>). The stimulated paw started moving at 29 ± 1 ms, the contralateral hind paw at 34 ± 4 ms, and the nose at 33 ± 2 ms (80 trials from 10 mice). With this intense stimulus, only in 6% of trials did the hind paws or single body parts move alone, although the magnitude of the head movement varied between trials. The distance traveled by the nose positively correlates with the distance for the stimulated paw (Pearson’s <italic>r</italic> = 0.64, n = 80 trials from 10 mice). Examining the relative distance between the nose and stimulated hind paw shows a reliably short latency (<xref ref-type="fig" rid="fig4">Figure 4I</xref>), indicating that these responses are driven by Aδ-nociceptor input rather than more slowly conducting C-fibers. A diversity of responses was observed: the head and stimulated paw move closer together in some trials and in others moved further apart (<xref ref-type="fig" rid="fig4">Figure 4I and J</xref>). This could result from the head moving towards or away from the stimulated paw but also the stimulated paw moving backwards as the body rotates. Indeed, consistent with initial observations (<xref ref-type="fig" rid="fig4">Figure 4A and B</xref>) and principal component analysis (PCA; <xref ref-type="fig" rid="fig4">Figure 4C–G</xref>), we find that the head selectively and rapidly orients to the stimulated side (<xref ref-type="fig" rid="fig4">Figure 4K</xref>). The presence of head orientation suggests that a brief nociceptive input can rapidly generate a coordinated spatially organized behavioral response. This is likely integral to protective pain-related behaviors and might function to gather sensory information about the stimulus or its consequences, and potentially provides coping strategies. Protective behaviors can be statistically categorized (<xref ref-type="bibr" rid="bib2">Abdus-Saboor et al., 2019</xref>) and computational discrimination of high-speed hind paw responses used as a score of pain (<xref ref-type="bibr" rid="bib25">Jones et al., 2020</xref>). We have shown that the analysis can easily be customized to incorporate computational tools that facilitate quantification and reveal insights into complex behavioral responses.</p></sec><sec id="s2-6"><title>Behavioral responses to precise LTMR input</title><p>The vesicular glutamate transporter-1 (Vglut1) is a known marker of Aβ-LTMRs (<xref ref-type="bibr" rid="bib4">Alvarez et al., 2004</xref>; <xref ref-type="bibr" rid="bib12">Brumovsky et al., 2007</xref>). To demonstrate the utility of the system in the broader context of somatosensation, we crossed <italic>Slc17a7-</italic>IRES2-Cre-D (Vglut1<sup>Cre</sup>) mice with R26-CAG-LSL-ChR2-tdTomato mice to generate a line (Vglut1<sup>Cre</sup>::ChR2) that express ChR2 in LTMRs (<xref ref-type="bibr" rid="bib22">Harris et al., 2014</xref>). A recent detailed anatomical and physiological characterization of Vglut1<sup>Cre</sup>::ChR2 mice further confirmed that in DRG neurons, ChR2 is restricted to broad class of myelinated Aβ-LTMRs (<xref ref-type="bibr" rid="bib14">Chamessian et al., 2019</xref>). Here, we find that a single 3 ms stimulus (S<sub>7</sub> = 1.155 mm<sup>2</sup>) precisely delivered to the hind paw of these mice rarely elicited hind paw responses (mean paw withdrawal probability = 0.10 ± 0.03 SEM, 99 trials from n = 11 mice), with the earliest response occurring at 206 ms after stimulation (<xref ref-type="fig" rid="fig5">Figure 5A and B</xref>), which is an order of magnitude slower than we observed in TRPV1<sup>Cre</sup>::ChR2 mice (fastest response: 19 ms). Trains of five pulses, however, frequently elicited responses, showing mean paw withdrawal probabilities of 0.31 ± 0.09 (SEM, 108 trials from n = 12 mice) for 5 Hz and 0.40 ± 0.10 (SEM, 117 trials from n = 12 mice) for 10 Hz trains (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Increasing stimulation frequency to 20 Hz did not result in higher withdrawal probabilities, which may reflect ChR2 desensitization, rather than a physiological process (<xref ref-type="bibr" rid="bib27">Lin, 2011</xref>). While the responses at first seem to be frequency-dependent (<xref ref-type="fig" rid="fig5">Figure 5D</xref>, left), inspection of recordings indicated that these occurred after the second or third pulse in most trials, regardless of stimulation frequency (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). We find that the response distributions superimpose when withdrawal latencies are normalized to the interstimulus interval (pulse-matched latencies in <xref ref-type="fig" rid="fig5">Figure 5D</xref>, right). This observation suggests that response probability is likely driven by pulse summation, rather than by stimulation frequency. Indeed, we find that the probabilities and latencies can be explained by the probability sum rule, using the values for a single pulse to predict the values for five pulses (<xref ref-type="fig" rid="fig5">Figure 5C and D</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Scanned transdermal optogenetic activation of Aβ-LTMRs triggers slow-onset responses.</title><p>(<bold>A</bold>) Example traces of the near-infrared frustrated total internal reflection signal time course for three different stimulation protocols in Vglut1<sup>Cre</sup>::ChR2 mice: single pulse, five pulses at 5 Hz, and five pulses at 10 Hz (pulse duration 3 ms, spot size <italic>S<sub>7</sub></italic> = 1.155 mm<sup>2</sup>). (<bold>B</bold>) Corresponding raster plots of hind paw responses sorted by latency. The paw response latency is indicated in red (99–103 trials/protocol from n = 11–12 mice) and the 3 ms laser stimuli shown with blue carets. (<bold>C</bold>) Paw response probability peaks at 10 Hz stimulation frequency in Vglut1<sup>Cre</sup>::ChR2 mice (pulse duration 3 ms, spot size <italic>S<sub>7</sub></italic> = 1.155 mm<sup>2</sup>; 99–103 trials/protocol from n = 11–12 mice, mean probability ± SEM). (<bold>D</bold>) Left panel: paw response latencies in trials with a single 3 ms stimulation or with trains of five 3 ms stimuli at 5 Hz or at 10 Hz. Right panel: paw response latencies normalized to the interstimulus interval. The estimated probability in (<bold>C</bold>) and (<bold>D</bold>) (dashed gray lines) was calculated using <italic>P</italic>(<italic>X</italic> ≥ 1) = 1–(1–<italic>p</italic>)<italic><sup>n</sup></italic>, where <italic>p</italic> is the probability of a response on a single pulse (0.096) and <italic>n</italic> is the number of pulses (5). The dataset is provided in <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Time courses of paw movement recorded at 1000 frames/s with stimuli that vary in frequency.</title><p>Stimuli (3 ms, laser spot size <italic>S<sub>7</sub></italic> = 1.181 mm<sup>2</sup>, 40 mW/mm<sup>2</sup>) were delivered at 0 ms. Data are from Vglut1<sup>Cre</sup>::ChR2 mice and littermate controls.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-62026-fig5-data1-v2.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata2"><label>Figure 5—source data 2.</label><caption><title>Whole-body motion energy recorded at 400 frames/s with stimuli that vary in frequency.</title><p>Stimuli (3 ms, laser spot size <italic>S<sub>7</sub></italic> = 1.181 mm<sup>2</sup>, 40 mW/mm<sup>2</sup>) were delivered at 0 ms. Data are from Vglut1<sup>Cre</sup>::ChR2 mice.</p></caption><media mime-subtype="csv" mimetype="application" xlink:href="elife-62026-fig5-data2-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Motion energy analysis of full-body behavior-evoked Aβ-LTMRs.</title><p>Motion energy is not affected by stimulation frequency single 3 ms pulse or five pulses of 3 ms at 5 Hz, 10 Hz, or 20 Hz; spot size <italic>S<sub>7</sub></italic> = 1.155 mm<sup>2</sup>. Violin plots with 51–80 trials per protocol from 11 to 12 mice. Individual trials are shown, along with the associated median in black. The dataset is provided in <xref ref-type="supplementary-material" rid="fig5sdata2">Figure 5—source data 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62026-fig5-figsupp1-v2.tif"/></fig></fig-group><p>The magnitude of whole-body motion was not altered by increasing frequencies (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). In contrast to the TRPV1<sup>Cre</sup>::ChR2 line, whole-body behaviors in response to optogenetic stimulation of Vglut1<sup>Cre</sup>::ChR2 mice were subtle: visual inspection of high-speed whole-body behavior videos revealed that responses were mostly limited to small hind paw lifts or shifts towards the center of the body in cases where the stimulated paw was initially further away from the body. In most instances, these movements did not disturb balance or alter the animal’s posture. Interestingly, we observed that whisking and, to a lesser extent, circular movements of the upheld forepaws would precede hind paw responses and initiate as early as the first pulse, even in trials that would not proceed to withdrawal. We speculate that mice may perceive the stimulation early on, but only act on this after a delay.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We describe a strategy for remote, precise, dynamic somatosensory input and behavioral mapping in awake unrestrained mice. The approach can remotely deliver spatiotemporally accurate optogenetic stimuli to the skin with predefined size, geometry, duration, timing, and location, while simultaneously monitoring behavior in the millisecond timescale. Microscale optogenetic stimulation can be used to simulate patterns, edges, and moving points on the skin. Responses to these precisely defined points and patterns can be mapped using machine vision approaches. The design is modular, for example, additional lasers for multicolor optogenetic control or naturalistic infrared stimuli can be added and complementary machine vision analysis approaches readily implemented. As an example, we combine this with DeepLabCut (<xref ref-type="bibr" rid="bib29">Mathis et al., 2018</xref>), for markerless tracking of individual body parts to further dissect specific components of whole-body responses.</p><p>We validated the system in two transgenic mouse lines, providing optical control of broad-class Aδ and C-nociceptors, and Aβ-LTMRs. Advances in transcriptional profiling have identified a vast array of genetically defined primary afferent neuron populations involved in specific aspects of temperature, mechanical, and itch sensation (<xref ref-type="bibr" rid="bib39">Usoskin et al., 2015</xref>). Selective activation of these populations is expected to recruit a specific combination of downstream cells and circuits depending on their function. For example, nociceptive input generates immediate sensorimotor responses and also pain that acts as a teaching signal. This strategy can be thus combined with techniques to modify genes, manipulate cells and neural circuits, and record neural activity in freely behaving mice to probe these mechanisms (<xref ref-type="bibr" rid="bib9">Boyden et al., 2005</xref>; <xref ref-type="bibr" rid="bib26">Kim et al., 2017</xref>). We provide approaches to map behavioral responses to defined afferent inputs across the spectrum of somatosensory modalities (<xref ref-type="bibr" rid="bib11">Browne et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Huang et al., 2019</xref>).</p><p>We find that the probabilistic recruitment of nociceptors determines the behavioral response probability, latency, and magnitude. We propose that the aggregate number of first action potentials arriving from nociceptors to the spinal cord can be utilized to optimize the timing and extent of rapid protective responses. These first action potentials could be summated by spinal neurons so that appropriate behaviors are selected based on thresholds. Resultant fast behaviors are diverse but include coordinated head orientation and body repositioning that depends on the initial pose. In contrast, responses to optogenetic activation of Aβ-LTMRs occurred with slower onset, lower probability, and resulted in more subtle whole-body movements. Using a fixed number of pulses, we find that responses from multiple Aβ-LTMR inputs can be explained by the sum rule of probabilities rather than frequency-dependence (<xref ref-type="bibr" rid="bib14">Chamessian et al., 2019</xref>). This does not, however, rule out the tuning of responses to more spatially or temporally complex stimuli. We used broad-class Cre driver lines to selectively stimulate either nociceptors or Aβ-LTMRs, and it is possible that their respective subpopulations exploit a diversity of coding strategies. This optical approach can reveal how such subpopulation and their specific downstream circuits guide behavior.</p><p>In summary, we have developed a strategy to precisely control afferents in the skin without touching or approaching them by projecting light to optogenetically generate somatosensory input in patterns, lines, or points. This is carried out non-invasively in awake freely behaving mice in a way that is remote yet precise. Remote control of temporally and spatially precise input addresses the many limitations of manually applied contact stimuli. The timing, extent, directionality, and coordination of resultant millisecond-timescale behavioral responses can be investigated computationally with specific sensory inputs. This provides a way to map behavioral responses, circuits, and cells recruited by defined afferent inputs and dissect the neural basis of processes associated with pain and touch. This strategy thus enables the investigation of sensorimotor, perceptual, cognitive, and motivational processes that guide and shape behavior in health and disease.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Genetic reagent (<italic>Mus musculus</italic>)</td><td align="left" valign="bottom">R26-CAG-LSL-hChR2(H134R)-tdTomato (Ai27D)</td><td align="left" valign="bottom">Jackson Laboratory</td><td align="left" valign="bottom">Stock #: 012567RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:IMSR_JAX:012567">IMSR_JAX:012567</ext-link></td><td align="left" valign="bottom">PMID:<ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/22446880/">22446880</ext-link></td></tr><tr><td align="left" valign="bottom">Genetic reagent (<italic>M. musculus</italic>)</td><td align="left" valign="bottom"><italic>Trpv1</italic>-IRES-Cre (TRPV1<sup>Cre</sup>)</td><td align="left" valign="bottom">Jackson Laboratory</td><td align="left" valign="bottom">Stock #: 017769RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:IMSR_JAX:017769">IMSR_JAX:017769</ext-link></td><td align="left" valign="bottom">PMID:<ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/21752988/">21752988</ext-link></td></tr><tr><td align="left" valign="bottom">Genetic reagent (<italic>M. musculus</italic>)</td><td align="left" valign="bottom"><italic>Slc17a7-</italic>IRES2-Cre-D(Vglut1<sup>Cre</sup>)</td><td align="left" valign="bottom">Jackson Laboratory</td><td align="left" valign="bottom">Stock #: 023527RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:IMSR_JAX:023527">IMSR_JAX:023527</ext-link></td><td align="left" valign="bottom">PMID:<ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/21752988/">21752988</ext-link></td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">RStudio</td><td align="left" valign="bottom">RStudio <ext-link ext-link-type="uri" xlink:href="http://www.rstudio.com/">http://www.rstudio.com/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_000432">SCR_000432</ext-link></td><td align="left" valign="bottom">Version 1.2.5019</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Python</td><td align="left" valign="bottom">Python <ext-link ext-link-type="uri" xlink:href="http://www.python.org/">http://www.python.org/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_008394">SCR_008394</ext-link></td><td align="left" valign="bottom">Version3.6.8</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Fiji</td><td align="left" valign="bottom">Fiji <ext-link ext-link-type="uri" xlink:href="http://fiji.sc">http://fiji.sc</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002285">SCR_002285</ext-link></td><td align="left" valign="bottom">Version2.0.0</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Prism 7</td><td align="left" valign="bottom">GraphPad Prism <ext-link ext-link-type="uri" xlink:href="http://www.graphpad.com/">http://www.graphpad.com/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002798">SCR_002798</ext-link></td><td align="left" valign="bottom">Version 7</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Seaborn</td><td align="left" valign="bottom">Seaborn <ext-link ext-link-type="uri" xlink:href="http://www.seaborn.pydata.org">http://www.seaborn.pydata.org</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_018132">SCR_018132</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Adobe Illustrator</td><td align="left" valign="bottom">Adobe <ext-link ext-link-type="uri" xlink:href="http://www.adobe.com">http://www.adobe.com</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_010279">SCR_010279</ext-link></td><td align="left" valign="bottom">Version 24.0</td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Optical system design, components, and assembly</title><p>Optical elements, optomechanical components, mirror galvanometers, the diode laser, LEDs, controllers, machine vision cameras, and structural parts for the optical platform are listed in the table in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. These components were assembled on an aluminum breadboard as shown in the Solidworks rendering in <xref ref-type="fig" rid="fig1">Figure 1C</xref>. The laser was aligned to the center of all lenses and exiting the midpoint of the mirror galvanometer housing aperture when the mirrors were set to the center of their working range. A series of lenses (L1–L3) expanded the beam before focusing it on to the glass stimulation plane, on which mice are placed during experiments. The glass stimulation platform was constructed of 5-mm-thick borosilicate glass framed by aluminum extrusions. NIR-FTIR was achieved by embedding an infrared LED ribbon inside the aluminum frame adjacent to the glass edges (Roberson, D. P. et al., manuscript submitted). The non-rotating L1 lens housing was calibrated to obtain eight defined laser spot sizes, ranging from 0.0185 mm<sup>2</sup> to 2.307 mm<sup>2</sup>, by translating this lens along the beam path at set points to defocus the laser spot at the 200 mm × 200 mm stimulation plane. The beam size can be altered manually using this rotating lens tube per design, but this is modular and could be altered by the user. To ensure a relatively flat field in the stimulation plane, the galvanometer housing aperture was placed at a distance of 400 mm from its center. In this configuration, the corners of the stimulation plane were at a distance of 424 mm from the galvanometer housing aperture and variability of the focal length was below 1.5%.</p><p>Optical power density was kept constant by altering the laser power according to the laser spot area. Neutral density (ND) filters were used so that the power at the laser aperture was above a minimum working value (≥8 mW) and to minimize potential changes in the beam profile at the stimulation plane. The laser and mirror galvanometers were controlled through a multifunction DAQ (National Instruments, USB-6211) using custom software written in LabVIEW. The software displays the NIR-FTIR camera feed, whose path through the mirror galvanometers is shared with the laser beam, so that they are always in alignment with one another. Computationally adjusting mirror galvanometer angles causes identical shifts in both the descanned NIR-FTIR image field of view and intended laser stimulation site, so that the laser can be targeted to user-identified locations. Shaped stimulation patterns were achieved by programmatically scaling the mirror galvanometer angles to the glass stimulation plane using a calibration grid array (Thorlabs, R1L3S3P). The timings of laser pulse trains were synchronized with the mirror galvanometers to computationally implement predefined shapes and lines using small angle steps that could be as short as 300 µs. The custom software also synchronized image acquisition from the two cameras, so that time-locked high-speed local paw responses were recorded (camera 1: 160 pixels × 160 pixels, 250–1000 frames/s depending on the experiment). Time-locked global whole-body responses were recorded above video-frame rate (camera 2: 664 pixels × 660 pixels, 40 frames/s) or at high speed (camera 2: 560 pixels × 540 pixels, 400 frames/s) across the entire stimulation platform.</p></sec><sec id="s4-2"><title>Technical calibration and characterization of the optical system</title><p>To calibrate the L1 lens housing and ensure consistency of laser spot sizes across the glass stimulation platform, we designed a 13.90 ± 0.05 mm thick aluminum alignment mask. This flat aluminum mask was used to replace the glass stimulation platform and was combined with custom acrylic plates that align the aperture of a rotating scanning-slit optical beam profiler (Thorlabs, BP209-VIS/M) to nine defined coordinates at different locations covering the stimulation plane. The laser power was set to a value that approximates powers used in behavioral experiments (40 mW). The laser power was then attenuated with an ND filter to match the operating range of the beam profiler. Using Thorlabs Beam Software, Gaussian fits were used to determine x-axis and y-axis 1/e<sup>2</sup> diameters and ellipticities for each laser spot size over three replicates at all nine coordinates. The averages of replicates were used to calculate the area of the eight different laser spot sizes that were measured in each of the nine coordinates (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>) and then fitted with a two-dimensional polynomial equation in MATLAB to create heatmaps (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> B).</p><p>The average values over the nine coordinates were defined for each laser spot size: S<sub>1</sub> = 0.0185 mm<sup>2</sup>, S<sub>2</sub> = 0.0416 mm<sup>2</sup>, S<sub>3</sub> = 0.0898 mm<sup>2</sup>, S<sub>4</sub> = 0.176 mm<sup>2</sup>, S<sub>5</sub> = 0.308 mm<sup>2</sup>, S<sub>6</sub> = 0.577 mm<sup>2</sup>, S<sub>7</sub> = 1.155 mm<sup>2</sup>, S<sub>8</sub> = 2.307 mm<sup>2</sup>. These measurements were repeated 6 months after extensive use of the optical system to ensure stability over time (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). In addition, the uniformity of laser power was assessed by measuring optical power at five positions of the experimental platform with a power meter (Thorlabs, PM100D) (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>).</p></sec><sec id="s4-3"><title>Experimental animals</title><p>Experiments were performed using mice on a C57BL/6j background. Targeted expression of ChR2-tdTomato in broad-class cutaneous nociceptors was achieved by breeding mice homozygous for Cre-dependent ChR2(H134R)-tdTomato at the Rosa26 locus (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:IMSR_JAX:012567">IMSR_JAX:012567</ext-link>, R26-CAG-LSL-hChR2(H134R)-tdTomato, Ai27D; <xref ref-type="bibr" rid="bib28">Madisen et al., 2012</xref>) with mice that have Cre recombinase inserted downstream of the <italic>Trpv1</italic> gene in one allele (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:IMSR_JAX:017769">IMSR_JAX:017769</ext-link>, <italic>Trpv1</italic>-IRES-Cre, TRPV1<sup>Cre</sup>; <xref ref-type="bibr" rid="bib13">Cavanaugh et al., 2011</xref>). Aβ-LTMRs were selectively stimulated by breeding homozygous Ai27D mice with mice in which Cre recombinase is targeted to cells expressing the vesicular glutamate transporter 1 (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:IMSR_JAX">IMSR_JAX</ext-link>: 023527, Slc17a7-IRES2-Cre-D, Vglut1<sup>Cre</sup>; <xref ref-type="bibr" rid="bib22">Harris et al., 2014</xref>). Resultant mice were heterozygous for both transgenes and were housed with control littermates that do not encode Cre recombinase but do encode Cre-dependent ChR2-tdTomato. Adult (2–4 months old) male and female mice were used in experiments. Mice were given ad libitum access to food and water and were housed in 21°C ± 2°C, 55% relative humidity and a 12 hr light:12 hr dark cycle. Experiments were carried out on at least two separate cohorts of mice, each cohort contained 4–6 mice. Experiments were spaced by at least one day in the case where the same cohort of mice was used in different experiments. All animal procedures were approved by University College London ethical review committees and conformed to UK Home Office regulations.</p></sec><sec id="s4-4"><title>Optogenetic stimulation and resultant behaviors</title><p>Prior to the first experimental day, mice underwent two habituation sessions during which each mouse was individually placed in a plexiglass chamber (100 mm × 100 mm, 130 mm tall) on a mesh wire floor for 1 hr, then on a glass platform for another hour. On the experimental day, mice were again placed on the mesh floor for 1 hr, then up to six mice were transferred to six enclosures (95 mm × 60 mm, 75 mm tall) positioned on the 200 mm × 200 mm glass stimulation platform. Mice were allowed to settle down and care was taken to stimulate mice that were calm, still, and awake in an ‘idle’ state. The laser was remotely targeted to the hind paw glabrous skin using the descanned NIR-FTIR image feed. The laser spot size was manually set using the calibrated L1 housing, while laser power and neutral density filters were used to achieve a power density of 40 mW/mm<sup>2</sup> regardless of spot size. The software was then employed to trigger a laser pulse of defined duration (between 100 μs and 30 ms) and simultaneously acquire high-speed (1000, 500, or 250 frames/s depending on experiment) NIR-FTIR recordings of the stimulated paw, as well as a global view of the mice with a second camera (400 frames/s or 40 frames/s) (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Recordings of stimulations of TRPV1<sup>Cre</sup>::ChR2 mice were 1500 ms in duration, with the laser pulse initiated at 500 ms. For each stimulation protocol, six pulses, three on each hind paw, spaced by at least 1 min were delivered to eight mice, split into two cohorts. For experiments involving Vglut1<sup>Cre</sup>::ChR2 mice, we used a single stimulation spot size (S<sub>7</sub> = 1.155 mm<sup>2</sup>) and duration (3 ms). In addition to the single-pulse stimulation, these mice received a train of five pulses applied at 5, 10, or 20 Hz. The recording time for each trial was extended to 2000 ms to accommodate for the longer stimulation period. For each protocol, Vglut1<sup>Cre</sup>::ChR2 mice were stimulated in 10 trials, split equally between the two hind paws. Data was collected from 12 Vglut1<sup>Cre</sup>::ChR2 mice and 8 littermate controls lacking Cre recombinase split into five cohorts. In all experiments, the behavioral withdrawal of the stimulated hind paw was also manually recorded by the experimenter.</p></sec><sec id="s4-5"><title>Patterned stimulation protocols</title><p>TRPV1<sup>Cre</sup>::ChR2 mice were stimulated on the heel of the hind paw with each of the following protocols: (1) a single 1 ms pulse with spot size S<sub>7</sub> (1.155 mm<sup>2</sup>); (2) a single 1 ms pulse with spot size S<sub>4</sub> (0.176 mm<sup>2</sup>); (3) seven 1 ms pulses with spot size S<sub>4</sub>, superimposed on the same stimulation site and spaced by 500 μs intervals; (4) seven 1 ms pulses with spot size S<sub>4</sub>, spaced by 500 μs intervals and spatially displacing stimuli with 0.3791 mm jumps such as to draw a small hexagon; (5) seven 1 ms pulses with spot size S<sub>4</sub>, spaced by 500 μs intervals and spatially displacing stimuli with 0.5687 mm jumps such as to draw a hexagon expanded by 50% compared to the previous shape; and (6) seven 1 ms pulses with spot size S<sub>4</sub>, spaced by 500 μs intervals and spatially displacing stimuli with 0.3791 mm jumps such as to draw a straight line. The power density of the stimulations was kept constant at 40 mW/mm<sup>2</sup> as before. Seven mice, split into two cohorts, received 10 stimulations per protocol (five on each hind paw) after a baseline epoch of 500 ms. An additional cohort of four littermates lacking Cre recombinase were stimulated in the same way and served as negative controls. Finally, three TRPV1<sup>Cre</sup>::ChR2 mice were stimulated (spot size S<sub>8</sub>, 10 ms pulse duration) with a single pulse adjacent to the hind paw, five times on each side, in order to control for potential off-target effects. The NIR-FTIR signal was recorded at 500 frames/s.</p></sec><sec id="s4-6"><title>Whole-body behaviors during optogenetic stimulation</title><p>To obtain recordings optimized for markerless tracking with DeepLabCut, a single acrylic chamber (100 mm × 100 mm, 150 mm tall) was centered on the glass stimulation platform of the system. Rapid movements were recorded at 400 frames/s using a below-view camera (FLIR, BFS-U3-04S2M-CS). Two white and two infrared LED panels illuminated the sides of the behavioral chamber in order to optimize lighting for these short exposure times and achieve high contrast images. NIR-FTIR was not used in this configuration. TRPV1<sup>Cre</sup>::ChR2 mice received between 10 and 20 single-shot laser pulse stimulations of 10 ms each, at least 1 min apart and equally split between right and left hind paw and using spot size S<sub>8</sub> (2.31 mm<sup>2</sup>). The first 10 trials that exceeded quality control were used (see <italic>Markerless tracking of millisecond-timescale global behaviors, Data processing</italic>). Each trial consisted of a 500 ms baseline and 4000 ms after-stimulus recording epoch.</p></sec><sec id="s4-7"><title>Automated analysis of optogenetically evoked local withdrawal events</title><p>High-speed NIR-FTIR recordings were saved as uncompressed AVI files. A Python script was implemented in Fiji to verify the integrity of the high-speed NIR-FTIR recordings and extract average 8-bit intensity values from all frames within a circular region of interest on the stimulation site (60 pixels diameter). This output was then fed into RStudio to calculate the average intensity and associated standard deviation of the baseline recording (first 500 ms). A hind paw response was defined as a drop of intensity equal to or below the mean of the baseline minus five times its standard deviation. Paw response latency was defined as time between the start of the pulse and the time at which a hind paw response was first detected. For purposes of quality control, only recordings with a baseline NIR-FTIR intensity mean ≥ 3 and a standard deviation/mean of the baseline ratio ≥23 were retained for analysis. Another criterion was that response latencies are not 10 ms or shorter since this would be too short to be generated by the stimulus itself. Only one trial out of 2369 trials did not meet this criterion (spot size S<sub>6</sub>, 1 ms pulse, 8 ms response latency). In addition to this two-step workflow using Fiji/Python to process AVI files and then RStudio to analyze the resulting output, alternative code was written in Python 3, which combines both steps and also computes individual pixel latencies and motion energy using NumPy and Pandas packages. A median filter (radius = 2 pixels) was applied to the NIR-FTIR recordings used to create the representative time series in <xref ref-type="fig" rid="fig2">Figure 2A</xref> and <xref ref-type="video" rid="fig2video1">Figure 2—video 1</xref>. For raster plots of hind paw response dynamics in <xref ref-type="fig" rid="fig4">Figure 4A</xref>, NIR-FTIR intensity values were normalized to the average baseline value. For the patterned stimulation experiments in <xref ref-type="fig" rid="fig2">Figure 2F</xref> and Vglut1<sup>Cre</sup>::ChR2 experiments in <xref ref-type="fig" rid="fig5">Figure 5A–D</xref>, trials were analyzed as stated to compute local response probabilities, but an additional rule was introduced to further minimize the risk of false positives. A response required the signal to fall by 20% and exceed a threshold of four times the standard deviation of baseline. Compared to the performance of an experimenter manually processing the videos with Fiji, the automated analysis pipeline was substantially faster for similar accuracy. For example, it took an experimenter two working days to analyze 127 videos, whereas the Fiji/Python pipeline generated the identical output within 90 s.</p></sec><sec id="s4-8"><title>Automated analysis of whole-body protective behavior</title><p>Videos of the entire stimulation platform were cropped into individual mouse chambers (200 × 315 pixels) and then analyzed using RStudio to quantify the amount of whole-body movements, including those stemming from the response of the stimulated limb, herein referred to as global behavior (GB). GB was approximated as the binarized motion energy: the summed number of pixels changing by more than five 8-bit values between two subsequent frames (Pixel Change). Briefly, for each pixel<italic><sub>n</sub></italic> (n = 63,000 pixels/frame), the 8-bit value at a given frame (<italic>F<sub>n</sub></italic>) was subtracted from the corresponding pixel<italic><sub>n</sub></italic> at the previous frame (<italic>F<sub>n-1</sub></italic>). If the resulting absolute value was ≤5, 0 would be assigned to the pixel. If the absolute resulting value was &gt;5, 1 would be assigned to the pixel. The threshold was chosen to discard background noise from the recording. The pixel binary values were then summed for each frame pair to obtain binarized motion energy. Normalized binarized motion energy was calculated by subtracting each post-stimulus frame binarized motion energy from the average baseline binarized motion energy. As an alternative to this analysis strategy, we have developed code in Python that processes the video files and calculates motion energy. The peak normalized binarized motion energy was determined and only trials displaying a peak response ≥5 standard deviations of the baseline mean were retained for further analysis and plotting. For TRPV1<sup>Cre</sup>::ChR2 mice, the analysis was restricted to a time window of 100 ms after stimulus onset (first three frame pairs proceeding the stimulus frame) to enable time-locking to the stimulus. Between 41 and 47 videos from eight mice were analyzed per spot size. For experiments with Vglut1<sup>Cre</sup>::ChR2 mice, the peak normalized binary motion energy exceeding five standard deviations of the baseline mean was determined for the entire 1.5 s recording epoch proceeding stimulus onset. Between 51 and 80 trials from 11 to 12 mice were analyzed per stimulation frequency.</p></sec><sec id="s4-9"><title>Markerless tracking of millisecond-timescale global behaviors</title><sec id="s4-9-1"><title>DeepLabCut installation</title><p>DeepLabCut (version 2.0.1) was installed on a computer (Intel-Core-i7-7800 × 3.5 GHz CPU, NVIDIA GTX GeForce 1080 Ti GPU, quad-core 64 GB RAM, Windows 10, manufactured by PC Specialist Ltd.) with an Anaconda virtual environment and was coupled to Tensorflow-GPU (v.1.8.0, with CUDA v.9.01 and cUdNN v. 5.4).</p></sec><sec id="s4-9-2"><title>Data compression</title><p>All recordings were automatically cropped with Python MoviePy package and compressed with standard compression using the H.264 format, then saved in mp4 format. This compression method was previously shown to result in robust improvement of processing rate with minimal compromise on detection error.</p></sec><sec id="s4-9-3"><title>Training the network</title><p>DeepLabCut was used with default network and training settings. Pilot stimulation trials were collected for initial training with 1,030,000 iterations from 253 labeled images from 50 videos. The videos were selected to represent the whole range of behavioral responses and conditions (25 videos of males and 25 videos of females from six different recording sessions). Out of the 25 videos, 15 were selected from the most vigorous responses, 5 were selected from less vigorous responses, and 5 from control mice. Ground truth images were selected manually, aiming to include the most variable images from each video (up to 14 frames per video). 18 body parts were labeled, namely the nose, approximate center of the mouse, two points on each sides of the torso and one point at each side of the neck, the fore paws, distal and proximal points on the hind paw, between the hind limbs, and three points on the tail. While most of these labels were not used in subsequent analysis, labeling more body parts on the image enhanced performance. The resulting network output was visually assessed. Erroneously labeled frames were manually corrected and used to retrain the network while also adding new recordings. Four sequential retraining sessions with 1,030,000 iterations each were conducted adding a total of 109 frames from 38 videos. This resulted in a reduction in the pixel root mean square error (RMSE) from 4.97 down to 2.66 on the test set, which is comparable to human ground truth variability quantified elsewhere.</p></sec><sec id="s4-9-4"><title>Data processing</title><p>Only labels of interest were used for analysis. These were ipsilateral and contralateral hind paws (distal), the tail base, and the nose labels. To minimize error, points were removed if they (1) were labeled with less than 0.95 p-cutoff confidence by DeepLabCut, (2) jumped at least 10 pixels in one single frame compared to the previous frame, (3) had not returned on the subsequent frame, and (4) were from the five stimulation frames. Code for data processing was written in Python using the NumPy and Pandas packages. Additional post-hoc quality control was performed on the network output to identify and remove poorly labeled trials. To this end, heatmaps of distances between labels were created and inspected for dropped labels and sudden changes in distance. Trials identified in this manner were then manually inspected and removed if more than 10% of labels were missing or more than 10 frames were mislabeled. In total, 4.7% of trials were discarded. Only the first eight trials for each of the 10 mice that met this video quality control were used in analysis.</p></sec><sec id="s4-9-5"><title>Automated detection of the stimulated limb</title><p>Disabling NIR-FTIR illumination reduces the baseline saturation and thus allowed us to automate stimulated paw detection using pixel saturation from the stimulation laser. To determine which of the left or right paw had been stimulated in a given trial, the number of saturated pixels within a 60 × 60 pixels window close to the hind paw label was compared 7.5 ms prior and 5 ms after stimulus onset.</p></sec><sec id="s4-9-6"><title>Detection of movement latency of discrete body parts</title><p>Movement latencies of hind paws and head (nose) were computed based on significant changes from the baseline position. Baseline positions were calculated as the average x and y values from 10 consecutive frames prior to stimulus onset. A post-stimulus response was considered to be meaningful if the position of the label changed by at least 0.5 pixels (~0.16 mm) compared to baseline and continued moving at a rate of at least 0.5 pixel/frame for the subsequent 10 frames.</p></sec><sec id="s4-9-7"><title>Dimensionality reduction</title><p>We carried out dimensionality reduction on x and y values for six body parts (nose, left hind paw digits, left hind paw heel, right hind paw digits, right hind paw heel, and tail base) determined at a single time point. These were egocentrically aligned using the tail base as the origin, and the stimulated paw always on the right. PCA was carried out by extracting the first three PCs using these 12 features at 115 ms after stimulus onset. The PCA was cross-validated by pseudo-randomly splitting the 80 trials into training and test datasets (80:20). The training dataset showed 49.5, 27.4, and 12.3% variance was explained by PC1, PC2, and PC3, respectively. The same PCs explained 53.5, 23.2, and 10.1% variance in the test dataset. PCA of these 80 trials together (at 115 ms) gave explained variance values 50.4% (PC1), 26.5% (PC2), and 11.9% (PC3). Projecting the time courses onto these same PCs resulted in explained variance values 37.1% (PC1), 24.3% (PC2), and 16.7% (PC3). In all cases, the shifts seen in PC1–3 were similar to that shown in <xref ref-type="fig" rid="fig4">Figure 4C</xref>.</p></sec></sec><sec id="s4-10"><title>Motion energy calculations in millisecond-timescale global behaviors</title><p>GB was analyzed within a 1 ms time frame following stimulation by computing the binarized motion energy relative to a baseline reference frame 5 ms prior to stimulation as described above. Here, the threshold for pixel change was set to seven 8-bit values. The binarized motion energy (sum of pixel binaries) of a given frame was normalized to the total number of pixels within that frame after removing those frames that had been affected by the stimulation laser pulse. The global response latency of movement initiation was determined as the time when binarized motion energy was greater than 10 times the standard deviation at baseline. Termination of movement was determined as the time point when binarized motion energy returned below 10 times standard deviation from baseline following the first movement bout.</p></sec><sec id="s4-11"><title>Statistical analysis</title><p>Data was analyzed in RStudio 1.2.5019, Python 3.6.8, ImageJ/Fiji 2.0.0 and Prism 7 and visualized using Seaborn, Prism 7, and Adobe Illustrator 24.0. In all experiments, repeated measurements were taken from multiple mice. Paw responses to patterned stimulation were reported as mean probabilities ± standard error of the mean (SEM) and analyzed using Friedman’s non-parametric test for within-subject repeated measures followed by Dunn’s signed-rank test for multiple comparisons (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). In this experiment, one of the seven TRPV1<sup>Cre</sup>::ChR2 mice was removed from the dataset because it displayed saturating responses to Protocol 3 preventing comparison of values across a dynamic range. Response latencies, response rise times, and response durations were computed using a hierarchical bootstrap procedure (<xref ref-type="bibr" rid="bib34">Saravanan et al., 2020</xref>) modified to acquire bootstrap estimates of the median with balanced resampling. Briefly, mice are sampled with replacement for the number of times that there are mice. For each mouse within this sample, its trials were sampled with replacement, but the number of selected trials was balanced, ensuring each mouse contributes equally to the number of trials in the sample. The median was taken for this resampled population and this entire process was repeated 10,000 times. Bootstrap estimates from 1000 simulated experiments show that an additional 1.6–3.1% of values fall within 1% of the population median for seven mice with between 2 and 6 responses. Values provided are the mean bootstrap estimate of the median ± the standard error of this estimate. The median bias was small due to the resampled population size from hierarchically nested data and only moderate distribution skew. Global peak motion energy (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) was examined in a similar way, except the mean of resampled populations was used as it represents a better estimator of the population mean. In this case, we report the mean bootstrap estimate of the mean ± the standard error of this estimate. Pearson’s correlation coefficients were determined to compare maximum distances moved from baseline for each body part (<xref ref-type="fig" rid="fig4">Figure 4F</xref>). Experimental units and n values are indicated in the figure legends.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>none</p></fn><fn fn-type="COI-statement" id="conf2"><p>None</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Investigation, Methodology, Software, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Methodology, Software, Visualization, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Software, Supervision, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal procedures were approved by University College London ethical review committees and conformed to UK Home Office regulations.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>List of components for the assembly of the optical system.</title><p>List of parts used in system. A Solidworks assembly, the optical system control and acquisition software, and behavioral analysis toolkit are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/browne-lab/throwinglight">https://github.com/browne-lab/throwinglight</ext-link> (<xref ref-type="bibr" rid="bib35">Schorscher-Petcu and Browne, 2020</xref>).</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-62026-supp1-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-62026-transrepform1-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All components necessary to assemble the optical system are listed in Supplementary file 1. A Solidworks assembly, the optical system control and acquisition software and behavioral analysis toolkit are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/browne-lab/throwinglight">https://github.com/browne-lab/throwinglight</ext-link>. The data that support the findings of this study are provided as source data files.</p></sec><ack id="ack"><title>Acknowledgements</title><p>We are grateful to Dr Mehmet Fisek and Dr Adam M Packer for initial advice on the optical system, and thank Dr David P Roberson and the Woolf lab for sharing the NIR-FTIR technology. We gratefully acknowledge feedback on the manuscript from Dr Adam M Packer and Professor John N Wood. This work was supported by a Sir Henry Dale Fellowship jointly funded by the Wellcome Trust and the Royal Society (109372/Z/15/Z).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdo</surname><given-names>H</given-names></name><name><surname>Calvo-Enrique</surname><given-names>L</given-names></name><name><surname>Lopez</surname><given-names>JM</given-names></name><name><surname>Song</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>MD</given-names></name><name><surname>Usoskin</surname><given-names>D</given-names></name><name><surname>El Manira</surname><given-names>A</given-names></name><name><surname>Adameyko</surname><given-names>I</given-names></name><name><surname>Hjerling-Leffler</surname><given-names>J</given-names></name><name><surname>Ernfors</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Specialized cutaneous Schwann cells initiate pain sensation</article-title><source>Science</source><volume>365</volume><fpage>695</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1126/science.aax6452</pub-id><pub-id pub-id-type="pmid">31416963</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdus-Saboor</surname><given-names>I</given-names></name><name><surname>Fried</surname><given-names>NT</given-names></name><name><surname>Lay</surname><given-names>M</given-names></name><name><surname>Burdge</surname><given-names>J</given-names></name><name><surname>Swanson</surname><given-names>K</given-names></name><name><surname>Fischer</surname><given-names>R</given-names></name><name><surname>Jones</surname><given-names>J</given-names></name><name><surname>Dong</surname><given-names>P</given-names></name><name><surname>Cai</surname><given-names>W</given-names></name><name><surname>Guo</surname><given-names>X</given-names></name><name><surname>Tao</surname><given-names>YX</given-names></name><name><surname>Bethea</surname><given-names>J</given-names></name><name><surname>Ma</surname><given-names>M</given-names></name><name><surname>Dong</surname><given-names>X</given-names></name><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Luo</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Development of a mouse pain scale using sub-second behavioral mapping and statistical modeling</article-title><source>Cell Reports</source><volume>28</volume><fpage>1623</fpage><lpage>1634</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2019.07.017</pub-id><pub-id pub-id-type="pmid">31390574</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraira</surname><given-names>VE</given-names></name><name><surname>Ginty</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The sensory neurons of touch</article-title><source>Neuron</source><volume>79</volume><fpage>618</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.051</pub-id><pub-id pub-id-type="pmid">23972592</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarez</surname><given-names>FJ</given-names></name><name><surname>Villalba</surname><given-names>RM</given-names></name><name><surname>Zerda</surname><given-names>R</given-names></name><name><surname>Schneider</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Vesicular glutamate transporters in the spinal cord, with special reference to sensory primary afferent synapses</article-title><source>The Journal of Comparative Neurology</source><volume>472</volume><fpage>257</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1002/cne.20012</pub-id><pub-id pub-id-type="pmid">15065123</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arcourt</surname><given-names>A</given-names></name><name><surname>Gorham</surname><given-names>L</given-names></name><name><surname>Dhandapani</surname><given-names>R</given-names></name><name><surname>Prato</surname><given-names>V</given-names></name><name><surname>Taberner</surname><given-names>FJ</given-names></name><name><surname>Wende</surname><given-names>H</given-names></name><name><surname>Gangadharan</surname><given-names>V</given-names></name><name><surname>Birchmeier</surname><given-names>C</given-names></name><name><surname>Heppenstall</surname><given-names>PA</given-names></name><name><surname>Lechner</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Touch receptor-derived sensory information alleviates acute pain signaling and fine-tunes nociceptive reflex coordination</article-title><source>Neuron</source><volume>93</volume><fpage>179</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.027</pub-id><pub-id pub-id-type="pmid">27989460</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barik</surname><given-names>A</given-names></name><name><surname>Thompson</surname><given-names>JH</given-names></name><name><surname>Seltzer</surname><given-names>M</given-names></name><name><surname>Ghitani</surname><given-names>N</given-names></name><name><surname>Chesler</surname><given-names>AT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A brainstem-spinal circuit controlling nocifensive behavior</article-title><source>Neuron</source><volume>100</volume><fpage>1491</fpage><lpage>1503</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.037</pub-id><pub-id pub-id-type="pmid">30449655</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaudry</surname><given-names>H</given-names></name><name><surname>Daou</surname><given-names>I</given-names></name><name><surname>Ase</surname><given-names>AR</given-names></name><name><surname>Ribeiro-da-Silva</surname><given-names>A</given-names></name><name><surname>Séguéla</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct behavioral responses evoked by selective optogenetic stimulation of the major trpv1+ and mrgd+ subsets of c-fibers</article-title><source>Pain</source><volume>158</volume><fpage>2329</fpage><lpage>2339</lpage><pub-id pub-id-type="doi">10.1097/j.pain.0000000000001016</pub-id><pub-id pub-id-type="pmid">28708765</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blivis</surname><given-names>D</given-names></name><name><surname>Haspel</surname><given-names>G</given-names></name><name><surname>Mannes</surname><given-names>PZ</given-names></name><name><surname>O’Donovan</surname><given-names>MJ</given-names></name><name><surname>Iadarola</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Identification of a novel spinal nociceptive-motor gate control for aδ pain stimuli in rats</article-title><source>eLife</source><volume>6</volume><elocation-id>e23584</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23584</pub-id><pub-id pub-id-type="pmid">28537555</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyden</surname><given-names>ES</given-names></name><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>Bamberg</surname><given-names>E</given-names></name><name><surname>Nagel</surname><given-names>G</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Millisecond-timescale, genetically targeted optical control of neural activity</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1263</fpage><lpage>1268</lpage><pub-id pub-id-type="doi">10.1038/nn1525</pub-id><pub-id pub-id-type="pmid">16116447</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brecht</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The Body Model Theory of Somatosensory Cortex</article-title><source>Neuron</source><volume>94</volume><fpage>985</fpage><lpage>992</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.018</pub-id><pub-id pub-id-type="pmid">28595055</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Browne</surname><given-names>LE</given-names></name><name><surname>Latremoliere</surname><given-names>A</given-names></name><name><surname>Lehnert</surname><given-names>BP</given-names></name><name><surname>Grantham</surname><given-names>A</given-names></name><name><surname>Ward</surname><given-names>C</given-names></name><name><surname>Alexandre</surname><given-names>C</given-names></name><name><surname>Woolf</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Time-Resolved Fast Mammalian Behavior Reveals the Complexity of Protective Pain Responses</article-title><source>Cell Reports</source><volume>20</volume><fpage>89</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.06.024</pub-id><pub-id pub-id-type="pmid">28683326</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brumovsky</surname><given-names>P</given-names></name><name><surname>Watanabe</surname><given-names>M</given-names></name><name><surname>Hokfelt</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Expression of the vesicular glutamate transporters-1 and -2 in adult mouse dorsal root ganglia and spinal cord and their regulation by nerve injury</article-title><source>Neuroscience</source><volume>147</volume><fpage>469</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2007.02.068</pub-id><pub-id pub-id-type="pmid">17577523</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanaugh</surname><given-names>DJ</given-names></name><name><surname>Chesler</surname><given-names>AT</given-names></name><name><surname>Bráz</surname><given-names>JM</given-names></name><name><surname>Shah</surname><given-names>NM</given-names></name><name><surname>Julius</surname><given-names>D</given-names></name><name><surname>Basbaum</surname><given-names>AI</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Restriction of transient receptor potential vanilloid-1 to the peptidergic subset of primary afferent neurons follows its developmental downregulation in nonpeptidergic neurons</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>10119</fpage><lpage>10127</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1299-11.2011</pub-id><pub-id pub-id-type="pmid">21752988</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chamessian</surname><given-names>A</given-names></name><name><surname>Matsuda</surname><given-names>M</given-names></name><name><surname>Young</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>ZJ</given-names></name><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Ji</surname><given-names>RR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Is Optogenetic Activation of Vglut1-Positive Abeta Low-Threshold Mechanoreceptors Sufficient to Induce Tactile Allodynia in Mice after Nerve Injury</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>6202</fpage><lpage>6215</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2064-18.2019</pub-id><pub-id pub-id-type="pmid">31152125</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corder</surname><given-names>G</given-names></name><name><surname>Ahanonu</surname><given-names>B</given-names></name><name><surname>Grewe</surname><given-names>BF</given-names></name><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name><name><surname>Scherrer</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>An amygdalar neural ensemble that encodes the unpleasantness of pain</article-title><source>Science</source><volume>363</volume><fpage>276</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1126/science.aap8586</pub-id><pub-id pub-id-type="pmid">30655440</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daou</surname><given-names>I</given-names></name><name><surname>Tuttle</surname><given-names>AH</given-names></name><name><surname>Longo</surname><given-names>G</given-names></name><name><surname>Wieskopf</surname><given-names>JS</given-names></name><name><surname>Bonin</surname><given-names>RP</given-names></name><name><surname>Ase</surname><given-names>AR</given-names></name><name><surname>Wood</surname><given-names>JN</given-names></name><name><surname>De Koninck</surname><given-names>Y</given-names></name><name><surname>Ribeiro-da-Silva</surname><given-names>A</given-names></name><name><surname>Mogil</surname><given-names>JS</given-names></name><name><surname>Séguéla</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Remote optogenetic activation and sensitization of pain pathways in freely moving mice</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>18631</fpage><lpage>18640</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2424-13.2013</pub-id><pub-id pub-id-type="pmid">24259584</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Haan</surname><given-names>EHF</given-names></name><name><surname>Dijkerman</surname><given-names>HC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Somatosensation in the Brain: A Theoretical Re-evaluation and a New Model</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>529</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.04.003</pub-id><pub-id pub-id-type="pmid">32430229</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dubin</surname><given-names>AE</given-names></name><name><surname>Patapoutian</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Nociceptors: The sensors of the pain pathway</article-title><source>The Journal of Clinical Investigation</source><volume>120</volume><fpage>3760</fpage><lpage>3772</lpage><pub-id pub-id-type="doi">10.1172/JCI42843</pub-id><pub-id pub-id-type="pmid">21041958</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatto</surname><given-names>G</given-names></name><name><surname>Smith</surname><given-names>KM</given-names></name><name><surname>Ross</surname><given-names>SE</given-names></name><name><surname>Goulding</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuronal diversity in the somatosensory system: bridging the gap between cell type and function</article-title><source>Current Opinion in Neurobiology</source><volume>56</volume><fpage>167</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.03.002</pub-id><pub-id pub-id-type="pmid">30953870</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haggard</surname><given-names>P</given-names></name><name><surname>Iannetti</surname><given-names>GD</given-names></name><name><surname>Longo</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial sensory organization and body representation in pain perception</article-title><source>Current Biology</source><volume>23</volume><fpage>R164</fpage><lpage>R176</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.01.047</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Häring</surname><given-names>M</given-names></name><name><surname>Zeisel</surname><given-names>A</given-names></name><name><surname>Hochgerner</surname><given-names>H</given-names></name><name><surname>Rinwa</surname><given-names>P</given-names></name><name><surname>Jakobsson</surname><given-names>JET</given-names></name><name><surname>Lönnerberg</surname><given-names>P</given-names></name><name><surname>La Manno</surname><given-names>G</given-names></name><name><surname>Sharma</surname><given-names>N</given-names></name><name><surname>Borgius</surname><given-names>L</given-names></name><name><surname>Kiehn</surname><given-names>O</given-names></name><name><surname>Lagerström</surname><given-names>MC</given-names></name><name><surname>Linnarsson</surname><given-names>S</given-names></name><name><surname>Ernfors</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuronal atlas of the dorsal horn defines its architecture and links sensory input to transcriptional cell types</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>869</fpage><lpage>880</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0141-1</pub-id><pub-id pub-id-type="pmid">29686262</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Gu</surname><given-names>H</given-names></name><name><surname>Mills</surname><given-names>M</given-names></name><name><surname>Ng</surname><given-names>LL</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Mortrud</surname><given-names>M</given-names></name><name><surname>Ouellette</surname><given-names>B</given-names></name><name><surname>Kidney</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>KA</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Sunkin</surname><given-names>S</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Oh</surname><given-names>SW</given-names></name><name><surname>Madisen</surname><given-names>L</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Anatomical characterization of cre driver mice for neural circuit mapping and manipulation</article-title><source>Frontiers in Neural Circuits</source><volume>8</volume><elocation-id>76</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2014.00076</pub-id><pub-id pub-id-type="pmid">25071457</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>T</given-names></name><name><surname>Lin</surname><given-names>S-H</given-names></name><name><surname>Malewicz</surname><given-names>NM</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Goulding</surname><given-names>M</given-names></name><name><surname>LaMotte</surname><given-names>RH</given-names></name><name><surname>Ma</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Identifying the pathways required for coping behaviours associated with sustained pain</article-title><source>Nature</source><volume>565</volume><fpage>86</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0793-8</pub-id><pub-id pub-id-type="pmid">30532001</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iyer</surname><given-names>SM</given-names></name><name><surname>Montgomery</surname><given-names>KL</given-names></name><name><surname>Towne</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>SY</given-names></name><name><surname>Ramakrishnan</surname><given-names>C</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Delp</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Virally mediated optogenetic excitation and inhibition of pain in freely moving nontransgenic mice</article-title><source>Nature Biotechnology</source><volume>32</volume><fpage>274</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1038/nbt.2834</pub-id><pub-id pub-id-type="pmid">24531797</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>JM</given-names></name><name><surname>Foster</surname><given-names>W</given-names></name><name><surname>Twomey</surname><given-names>CR</given-names></name><name><surname>Burdge</surname><given-names>J</given-names></name><name><surname>Ahmed</surname><given-names>OM</given-names></name><name><surname>Pereira</surname><given-names>TD</given-names></name><name><surname>Wojick</surname><given-names>JA</given-names></name><name><surname>Corder</surname><given-names>G</given-names></name><name><surname>Plotkin</surname><given-names>JB</given-names></name><name><surname>Abdus-Saboor</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A machine-vision approach for automated pain measurement at millisecond timescales</article-title><source>eLife</source><volume>9</volume><elocation-id>e57258</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57258</pub-id><pub-id pub-id-type="pmid">32758355</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>CK</given-names></name><name><surname>Adhikari</surname><given-names>A</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Integration of optogenetics with complementary methodologies in systems neuroscience</article-title><source>Nature Reviews. Neuroscience</source><volume>18</volume><fpage>222</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nrn.2017.15</pub-id><pub-id pub-id-type="pmid">28303019</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>JY</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A user’s guide to channelrhodopsin variants: features, limitations and future developments</article-title><source>Experimental Physiology</source><volume>96</volume><fpage>19</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1113/expphysiol.2009.051961</pub-id><pub-id pub-id-type="pmid">20621963</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madisen</surname><given-names>L</given-names></name><name><surname>Mao</surname><given-names>T</given-names></name><name><surname>Koch</surname><given-names>H</given-names></name><name><surname>Zhuo</surname><given-names>J</given-names></name><name><surname>Berenyi</surname><given-names>A</given-names></name><name><surname>Fujisawa</surname><given-names>S</given-names></name><name><surname>Hsu</surname><given-names>Y-WA</given-names></name><name><surname>Garcia</surname><given-names>AJ</given-names></name><name><surname>Gu</surname><given-names>X</given-names></name><name><surname>Zanella</surname><given-names>S</given-names></name><name><surname>Kidney</surname><given-names>J</given-names></name><name><surname>Gu</surname><given-names>H</given-names></name><name><surname>Mao</surname><given-names>Y</given-names></name><name><surname>Hooks</surname><given-names>BM</given-names></name><name><surname>Boyden</surname><given-names>ES</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Ramirez</surname><given-names>JM</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Han</surname><given-names>X</given-names></name><name><surname>Turner</surname><given-names>EE</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A toolbox of cre-dependent optogenetic transgenic mice for light-induced activation and silencing</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>793</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1038/nn.3078</pub-id><pub-id pub-id-type="pmid">22446880</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deeplabcut: Markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>TD</given-names></name><name><surname>Aldarondo</surname><given-names>DE</given-names></name><name><surname>Willmore</surname><given-names>L</given-names></name><name><surname>Kislin</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>SS</given-names></name><name><surname>Murthy</surname><given-names>M</given-names></name><name><surname>Shaevitz</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fast animal pose estimation using deep neural networks</article-title><source>Nature Methods</source><volume>16</volume><fpage>117</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0234-5</pub-id><pub-id pub-id-type="pmid">30573820</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>CCH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sensorimotor processing in the rodent barrel cortex</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>533</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0200-y</pub-id><pub-id pub-id-type="pmid">31367018</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prescott</surname><given-names>SA</given-names></name><name><surname>Ma</surname><given-names>Q</given-names></name><name><surname>De Koninck</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Normal and abnormal coding of somatosensory stimuli causing pain</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>183</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1038/nn.3629</pub-id><pub-id pub-id-type="pmid">24473266</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Johansson</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Edge-orientation processing in first-order tactile neurons</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1404</fpage><lpage>1409</lpage><pub-id pub-id-type="doi">10.1038/nn.3804</pub-id><pub-id pub-id-type="pmid">25174006</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saravanan</surname><given-names>V</given-names></name><name><surname>Berman</surname><given-names>GJ</given-names></name><name><surname>Sober</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Application of the hierarchical bootstrap to multi-level data in neuroscience</article-title><source>Neurons, Behavior, Data Analysis and Theory</source><volume>3</volume><elocation-id>819334</elocation-id><pub-id pub-id-type="doi">10.1101/819334</pub-id><pub-id pub-id-type="pmid">33644783</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Schorscher-Petcu</surname><given-names>A</given-names></name><name><surname>Browne</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>throwinglight</data-title><version designator="f5b5d9d">f5b5d9d</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/browne-lab/throwinglight">https://github.com/browne-lab/throwinglight</ext-link></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seymour</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Pain: A precision signal for reinforcement learning and control</article-title><source>Neuron</source><volume>101</volume><fpage>1029</fpage><lpage>1041</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.055</pub-id><pub-id pub-id-type="pmid">30897355</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherrington</surname><given-names>CS</given-names></name></person-group><year iso-8601-date="1910">1910</year><article-title>Flexion-reflex of the limb, crossed extension-reflex, and reflex stepping and standing</article-title><source>The Journal of Physiology</source><volume>40</volume><fpage>28</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1910.sp001362</pub-id><pub-id pub-id-type="pmid">16993027</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorge</surname><given-names>RE</given-names></name><name><surname>Martin</surname><given-names>LJ</given-names></name><name><surname>Isbester</surname><given-names>KA</given-names></name><name><surname>Sotocinal</surname><given-names>SG</given-names></name><name><surname>Rosen</surname><given-names>S</given-names></name><name><surname>Tuttle</surname><given-names>AH</given-names></name><name><surname>Wieskopf</surname><given-names>JS</given-names></name><name><surname>Acland</surname><given-names>EL</given-names></name><name><surname>Dokova</surname><given-names>A</given-names></name><name><surname>Kadoura</surname><given-names>B</given-names></name><name><surname>Leger</surname><given-names>P</given-names></name><name><surname>Mapplebeck</surname><given-names>JCS</given-names></name><name><surname>McPhail</surname><given-names>M</given-names></name><name><surname>Delaney</surname><given-names>A</given-names></name><name><surname>Wigerblad</surname><given-names>G</given-names></name><name><surname>Schumann</surname><given-names>AP</given-names></name><name><surname>Quinn</surname><given-names>T</given-names></name><name><surname>Frasnelli</surname><given-names>J</given-names></name><name><surname>Svensson</surname><given-names>CI</given-names></name><name><surname>Sternberg</surname><given-names>WF</given-names></name><name><surname>Mogil</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Olfactory exposure to males, including men, causes stress and related analgesia in rodents</article-title><source>Nature Methods</source><volume>11</volume><fpage>629</fpage><lpage>632</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2935</pub-id><pub-id pub-id-type="pmid">24776635</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Usoskin</surname><given-names>D</given-names></name><name><surname>Furlan</surname><given-names>A</given-names></name><name><surname>Islam</surname><given-names>S</given-names></name><name><surname>Abdo</surname><given-names>H</given-names></name><name><surname>Lönnerberg</surname><given-names>P</given-names></name><name><surname>Lou</surname><given-names>D</given-names></name><name><surname>Hjerling-Leffler</surname><given-names>J</given-names></name><name><surname>Haeggström</surname><given-names>J</given-names></name><name><surname>Kharchenko</surname><given-names>O</given-names></name><name><surname>Kharchenko</surname><given-names>PV</given-names></name><name><surname>Linnarsson</surname><given-names>S</given-names></name><name><surname>Ernfors</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Unbiased classification of sensory neuron types by large-scale single-cell RNA sequencing</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>145</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1038/nn.3881</pub-id><pub-id pub-id-type="pmid">25420068</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Bélanger</surname><given-names>E</given-names></name><name><surname>Côté</surname><given-names>SL</given-names></name><name><surname>Desrosiers</surname><given-names>P</given-names></name><name><surname>Prescott</surname><given-names>SA</given-names></name><name><surname>Côté</surname><given-names>DC</given-names></name><name><surname>De Koninck</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Sensory afferents use different coding strategies for heat and cold</article-title><source>Cell Reports</source><volume>23</volume><fpage>2001</fpage><lpage>2013</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.04.065</pub-id><pub-id pub-id-type="pmid">29768200</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname><given-names>AB</given-names></name><name><surname>Johnson</surname><given-names>MJ</given-names></name><name><surname>Iurilli</surname><given-names>G</given-names></name><name><surname>Peterson</surname><given-names>RE</given-names></name><name><surname>Katon</surname><given-names>JM</given-names></name><name><surname>Pashkovski</surname><given-names>SL</given-names></name><name><surname>Abraira</surname><given-names>VE</given-names></name><name><surname>Adams</surname><given-names>RP</given-names></name><name><surname>Datta</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mapping Sub-Second Structure in Mouse Behavior</article-title><source>Neuron</source><volume>88</volume><fpage>1121</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.031</pub-id><pub-id pub-id-type="pmid">26687221</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimmerman</surname><given-names>A</given-names></name><name><surname>Bai</surname><given-names>L</given-names></name><name><surname>Ginty</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The gentle touch receptors of mammalian skin</article-title><source>Science</source><volume>346</volume><fpage>950</fpage><lpage>954</lpage><pub-id pub-id-type="doi">10.1126/science.1254229</pub-id><pub-id pub-id-type="pmid">25414303</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.62026.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Abdus-Saboor</surname><given-names>Ishmail</given-names></name><role>Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>We acknowledge the effort and time the authors took to address all of the comments made by reviewers which have improved this paper. We strongly believe that this approach will be widely adopted in the somatosensory research community to deliver &quot;remote optogenetic touch&quot; to freely behaving animals in a highly spatial and temporal fashion. The addition of a non-nociceptive line to this paper, with distinct behavioral outputs from the nociceptive line, is an added major strength of this work.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Scanned optogenetic control of mammalian somatosensory input to map input-specific behavioral outputs&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our board of Reviewing Editors and the evaluation has been overseen by Andrew King as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The manuscript by Schorscher-Petcu is a very innovative study approaching an important problem in pain and somatosensory neuroscience – precise and remote delivery of sensory stimuli. This work is timely, and there are many clear applications to understanding peripheral somatosensory encoding using this strategy. The rationale for such a tool developed here is widely agreed upon in the field, and if others can easily adopt this strategy, this could become the standard for peripheral optogenetic stimulation of the hind paw. Nonetheless, the reviewers would like the authors to address the points listed here before consideration of publication in <italic>eLife</italic>.</p><p>1. The strength of this paper was in the technique and not the new biology uncovered. We would like the authors to remove any language of a &quot;sparse code&quot; proposition because the data presented here do not support such a claim.</p><p>2. More detail on how to use this system so that new users can use this off-the-shelf. In particular: we had a hard time evaluating the hierarchical bootstrap procedure, which references a pre-print. Is this method really ensuring that the results are more rigorous? How do the authors define a withdraw? More detail and commentary on how this approach interfaces with Deep Lab Cut. In general, focus more on the technique and less on biology.</p><p>3. For widespread applicability and to determine the range, strengths, and weaknesses of this new tool to the pain field, the authors should extend their behavioral analyses. The reviewers preferred the authors to do as they mention in the discussion, which is to add an additional somatosensory line (perhaps a non-pain line) and see how their platform performs in comparison to Trpv1-ChR2. The less preferred option if the authors are not able to breed new somatosensory lines in reasonable time, is to try the Trpv1-ChR2 line in different contexts (inflammatory and/or neuropathic pain). In either case, at baseline or during chronic pain states in the Trpv1-ChR2 line, the authors should use an analgesic and show that their tool is modular and can detect decreases in pain-related signatures. The authors should take care to have N numbers closer to 10 animals per group, as the N of 4 in their studies is on the lower side.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.62026.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>1. The strength of this paper was in the technique and not the new biology uncovered. We would like the authors to remove any language of a &quot;sparse code&quot; proposition because the data presented here do not support such a claim.</p></disp-quote><p>We thank the reviewers and agree that as a technical report we should focus on the technical aspects. In demonstrating the utility of the system, we reveal biological insights that should be described clearly and fully. The language used is critical, so based on the reviewers comments we have removed the term &quot;sparse code&quot;. We agree that &quot;code&quot; unintentionally implied that we show noxious stimuli are encoded naturally in this manner in this combination of broad-class nociceptors. More precisely, we are reporting that the relative size of a single action potential nociceptor volley can determine the nature, timing and extent of resultant protective behaviors. This relationship between nociceptive input and behavior has not been demonstrated before and so it is important to describe this. We do however retain the use of the term &quot;sparse&quot; as this summarizes the optogenetic stimulus for the reasons below.</p><p>First, the input is spatially sparse – stimuli activate a small percentage of nociceptors in the total population. In Figure 2D, we show even an area as small as 0.6 mm² can tune the behavioral response. We now emphasize this point in the manuscript “The stimulus used for this protocol was S6, 0.577 mm² in area, which corresponds to less than 1% of the glabrous paw area and highlights the sensitivity of the nociceptive system”. Second, the input is temporally sparse – the stimuli only generate a single action potential in each nociceptor and this is enough to generate coordinated behaviors. That this is temporally sparse is in line with common usage of the term (e.g. Hahnloser et al., Nature 2002). This builds on our previous work that showed that a single pulse only generates a single action potential in each nociceptor.</p><p>We confirm that the subtle difference in laser rise times have no implications on generalizing the previous findings. Indeed, the TRPV1-lineage used here have long refractory periods (minimum interspike intervals, ~20 ms), as measured by patch clamp recordings (Browne et al., Cell Reports 2017). We had previously reported that even a 10 ms optogenetic stimulation of this mouse line does not generate more than a single action potential (see Browne et al., Cell Reports 2017 Supplementary Information, in vitro electrophysiology), but this is perhaps not prominent enough in the previous paper. In the system we describe here, the diode laser delivers the same wavelength and intensity of light as before. The light reaches a stable intensity in less than 1 microsecond, which allowed us to precisely compare the effects of short pulses as the ChR2 kinetics (tau=1.9 ms, Lin, 2011) and are what limits the rate of depolarization, not these lasers. Figure 2E uses 1 ms and 3 ms pulses only, and Figure 2F uses 1 ms pulses. We show that paw response probability increases from 0.3 ms up to 10 ms (Figure 2D), which is not long enough to generate more than one action potential. We now point out alongside Figure 2D in the legend that the 30 ms pulse duration may result in more than one action potential but it is important to note this does not alter the interpretation as the probability already plateaued at 10 ms.</p><p>Sparse recruitment of broad-class nociceptors was achieved by gaining precise control over the pulse width and spatial properties (size and shape) of the stimuli. It is not known whether certain pulse durations are more selective for the fibers they activate, so we have used a range of approaches to control stimulation size. We find that the larger the stimulus, irrespective of increasing the spot size or increasing the duration of the pulse, the shorter the response latencies. As illumination area increases so does the probability that Aδ and C fibres are activated. Our analysis of hind paw latencies was focused on Aδ responses. This is possible due to the stimuli being time-locked and the differential conduction velocities of these fibres – the responses typically initiate before 35 ms when the C-fiber action potentials (1.5 m/s) will only just be arriving at the spinal cord. We have previously shown using electrophysiology that TRPV1-Cre::ChR2 drives expression of ChR2 in broad-class nociceptors including Aδ and C fibers (Browne et al., Cell Reports, 2017). This is also in line with evidence from Usoskin et al., (Nature Neuroscience, 2015) showing the PEP2 population expresses TRPV1, and discussed by Caterina and Julius (Annual Review of Neuroscience, 2001) and Mitchell et al., (Mol Pain 2010).</p><disp-quote content-type="editor-comment"><p>2. More detail on how to use this system so that new users can use this off-the-shelf. In particular: we had a hard time evaluating the hierarchical bootstrap procedure, which references a pre-print. Is this method really ensuring that the results are more rigorous? How do the authors define a withdraw? More detail and commentary on how this approach interfaces with Deep Lab Cut. In general, focus more on the technique and less on biology.</p></disp-quote><p>We thank the reviewers and have made changes throughout. Specific responses and actions are given below.</p><p>Bootstrap. The bootstrap procedure allows statistical error to be calculated and provides better estimates of central tendency in skewed distributions. Here, we use hierarchical bootstrap, which as the now peer-reviewed article from Sober and colleagues points out (Saravanan et al., Neuron Behav Data Anal Theory, 2020), is an extensively used statistical method for nested data. We modified this to ensure that each mouse contributes equally to the number of trials in the sample, to avoid bias. By running our own analysis of this procedure, we confirm that the results are more rigorous; for 7 mice with between 2 and 6 responses, an additional 1.6-3.1% of bootstrap estimates from 1000 simulated experiments (with skewed distributions) fall within 1% of the population median. We have added this to the manuscript.</p><p>Targeting stimuli. The laser is fixed to the center of view in the targeting camera, which is displayed in real time in the GUI. This is due to the &quot;descanned&quot; configuration of the laser and targeting camera both using the same path through the galvanometers. Moving the target location of the laser moves the field of view that is displayed. The experimenter chooses what exact location of the mouse to stimulate by aiming the laser with this camera feed. We used a computer mouse cursor to rapidly target stimuli. On triggering a trial, the same camera records 0.5 seconds before the stimulus and 1.5 second after stimulus onset. These high-speed (up to 1000 fps) videos are used to verify if any movement occurred prior to the stimulation. There are occasions when the mouse moves before the stimulation is delivered, which is unavoidable in freely moving mice but the pre-stimulus baseline from all recordings are examined for movement using our code. In practical terms, we assess whether there has been movement occurring during the 0.5 seconds preceding the stimulus by calculating the mean signal intensity for this epoch and dividing it by its standard deviation. If the animal is still, the standard deviation will be small and the incurring ratio large. If the mouse moved, the standard deviation will be high and the ratio small. We empirically determined a threshold value, which we found to reliably indicate whether the animal is not moving up until the delivery of the stimulation. If there is any movement, the trial will not be used thus removing the possibility of recordings with unintended stimulus delivery.</p><p>To provide clarification on the targeting of stimuli, we have added further description to the Results section Design and assembly of the optical stimulation approach, which now states:</p><p>“The camera-feed is displayed in the user interface and enables the operator to use this image to target the laser to the desired location”.</p><p>This makes it clearer how the laser is remotely targeted. The reader may also refer to the Materials and methods section for a more detailed description:</p><p>“The software displays the NIR-FTIR camera feed, whose path through the mirror galvanometers is shared with the laser beam, so that they are always in alignment with one another. Computationally adjusting mirror galvanometer angles causes identical shifts in both the descanned NIR-FTIR image field of view and intended laser stimulation site, so that the laser can be targeted to user-identified locations.”</p><p>Paw responses. We define a hind paw response as a decrease in the intensity equal to or below the mean of the baseline minus five times its standard deviation. This is stated in Materials and methods section <italic>Automated analysis of optogenetically evoked local withdrawal events</italic>. By this definition, a paw response does not require the paw to lift / withdraw. We examine the extent of the response and can categorize partial and full responses. For example, if only part of the paw moves without lifting from the floor this is not a full paw withdrawal but still considered a response and it contains information that can be included in the analysis. The responses are detected using frustrated total internal reflection of infrared light at 1,000 frames per second. These resultant videos reveal nuance that would not be detected with the human eye. The videos are analyzed with code written in R and Python. We extract each of the 25,600 pixels for each frame and statistically analyze changes in each pixel or the intensity across a region of interest. The code is freely available. The videos are inspected by eye to validate findings. We have made changes in the manuscript that make this clearer.</p><p>Open science. We provide all information required to build the system: a solidworks assembly, part list, software and analysis code, along with technical specifications of the system in the Results section and Materials and methods sections <italic>Optical system design, components and assembly</italic> and <italic>Patterned stimulation protocols</italic>.</p><p>DeepLabCut. We have added additional details and discussion regarding the implementation of DeepLabCut to the Results section Sparse nociceptor stimulation triggers coordinated postural adjustments, and in the Discussion.</p><disp-quote content-type="editor-comment"><p>3. For widespread applicability and to determine the range, strengths, and weaknesses of this new tool to the pain field, the authors should extend their behavioral analyses. The reviewers preferred the authors to do as they mention in the discussion, which is to add an additional somatosensory line (perhaps a non-pain line) and see how their platform performs in comparison to Trpv1-ChR2. The less preferred option if the authors are not able to breed new somatosensory lines in reasonable time, is to try the Trpv1-ChR2 line in different contexts (inflammatory and/or neuropathic pain). In either case, at baseline or during chronic pain states in the Trpv1-ChR2 line, the authors should use an analgesic and show that their tool is modular and can detect decreases in pain-related signatures. The authors should take care to have N numbers closer to 10 animals per group, as the N of 4 in their studies is on the lower side.</p></disp-quote><p>This is an excellent suggestion. We have included an additional somatosensory Cre driver line, which took time to obtain and breed but substantially improves the manuscript. The somatosensory line we use is the Vglut1-Cre::ChR2-tdTomato line, which was originally characterized by Ru-Rong Ji and colleagues (Chamessian et al., J. Neurosci. 2019) in a relevant context. Here, we show that behavioral responses are specific to this stimulus. We therefore demonstrate the system is sensitive enough to detect behavioral responses associated with specific non-nociceptive and nociceptive input, and these responses can be readily discriminated.</p><p>Centrally acting analgesics (morphine, for example) may or may not suppress single-shot optogenetic stimuli; the interpretation of such an experiment does not address if pain is or is not experienced by such a stimulus, as they typically have other effects on arousal and locomotion that confound responses to mild inputs. A grooming or sleeping mouse, for example, does not respond to noxious stimuli as often as when it is at rest (Browne et al., Cell Reports 2017). We have previously shown that local lidocaine injection can block the optogenetic-evoked responses in these TRPV1-Cre::ChR2 mice (Browne et al., Cell Reports 2017). This blocks the input from the periphery. Further, the editor has previously developed a mouse pain scale and showed clearly that optogenetic stimulation causes pain-like responses (Abdus-Saboor et al., Cell Reports 2019). Therefore, experiments with analgesics would not contribute further to the existing understanding here. Computational classification of pain vs non-pain behaviors is an exciting area of research but is outside of the purpose of this paper. Our goal is to describe an approach for &quot;remote touch&quot; in freely behaving mice and provide some clear examples of its utility.</p><p>We have substantially extended our behavioral analysis of the TRPV1-Cre::ChR2 mice not to discriminate between pain vs non-pain, but based on the excellent suggestion to examine whole-body movement “…using a vector instead of a scalar”. We have extended the DeepLabCut analysis and reworked Figure 4, providing in depth computational analysis of the behavioral trajectories, demonstrating coordinated head orienting and body reposition. This further demonstrates the analysis and insights that can be achieved using this technical advance.</p><p>Regarding n numbers, all experiments used between 7 and 12 mice with one exception; the patterned stimulation experiment in Figure 2F used 6 mice, and 3 littermate controls and 4 off-target controls to confirm that these stimuli were indeed specific. These controls together show no responses, supporting what is already known with optogenetic stimulation of this mouse line. We have made the numbers of mice used clearer throughout the manuscript.</p></body></sub-article></article>