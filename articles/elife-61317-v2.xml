<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">61317</article-id><article-id pub-id-type="doi">10.7554/eLife.61317</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Processing of motion boundary orientation in macaque V2</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-96928"><name><surname>Ma</surname><given-names>Heng</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0322-278X</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-200604"><name><surname>Li</surname><given-names>Pengcheng</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-163087"><name><surname>Hu</surname><given-names>Jiaming</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5306-445X</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-96936"><name><surname>Cai</surname><given-names>Xingya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7829-3833</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-182642"><name><surname>Song</surname><given-names>Qianling</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9177-7429</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-29950"><name><surname>Lu</surname><given-names>Haidong D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1739-9508</contrib-id><email>haidong@bnu.edu.cn</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>State Key Laboratory of Cognitive Neuroscience and Learning, IDG/McGovern Institute for Brain Research, Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>24</day><month>03</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e61317</elocation-id><history><date date-type="received" iso-8601-date="2020-07-22"><day>22</day><month>07</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-03-24"><day>24</day><month>03</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Ma et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Ma et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-61317-v2.pdf"/><abstract><p>Human and nonhuman primates are good at identifying an object based on its motion, a task that is believed to be carried out by the ventral visual pathway. However, the neural mechanisms underlying such ability remains unclear. We trained macaque monkeys to do orientation discrimination for motion boundaries (MBs) and recorded neuronal response in area V2 with microelectrode arrays. We found 10.9% of V2 neurons exhibited robust orientation selectivity to MBs, and their responses correlated with monkeys’ orientation-discrimination performances. Furthermore, the responses of V2 direction-selective neurons recorded at the same time showed correlated activity with MB neurons for particular MB stimuli, suggesting that these motion-sensitive neurons made specific functional contributions to MB discrimination tasks. Our findings support the view that V2 plays a critical role in MB analysis and may achieve this through a neural circuit within area V2.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>motion boundary</kwd><kwd>orientation discrimination</kwd><kwd>V2</kwd><kwd>macaque monkey</kwd><kwd>electrode array recording</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31625012</award-id><principal-award-recipient><name><surname>Lu</surname><given-names>Haidong D</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31530029</award-id><principal-award-recipient><name><surname>Lu</surname><given-names>Haidong D</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31371111</award-id><principal-award-recipient><name><surname>Lu</surname><given-names>Haidong D</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Area V2 in macaque monkeys contributes to the perception of the outlines of moving objects and achieves this through a local computation.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>It is an important task to recognize an object when it is in motion. Humans and nonhuman primates have an excellent ability in detection of motion boundaries (MBs) (<xref ref-type="bibr" rid="bib38">Regan, 1986</xref>; <xref ref-type="bibr" rid="bib39">Regan, 1989</xref>). In nonhuman primates, it has been shown that neurons selective for the orientations of MBs are located in the ventral visual pathway (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>; <xref ref-type="bibr" rid="bib31">Mysore et al., 2006</xref>; <xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>), but not in the dorsal pathway (<xref ref-type="bibr" rid="bib26">Marcar et al., 1995</xref>). Particularly, it has been shown that area V2 exhibits significant MB responses. Compared with V1, V2 has more MB orientation neurons (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>) and a significant map for MB orientation (<xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>). However, other visual areas, including V3 and V4, also have strong responses to MB (<xref ref-type="bibr" rid="bib52">Zeki et al., 2003</xref>; <xref ref-type="bibr" rid="bib31">Mysore et al., 2006</xref>). It is unclear whether all these areas contribute to the eventual perception of MBs. This question is particularly important for V2 since it is the lowest area in the visual processing hierarchy that possesses MB sensitivity.</p><p>V2 is the largest extrastriate visual area in primates. It receives inputs from V1 and contains a full retinotopic map (<xref ref-type="bibr" rid="bib11">Gattass et al., 1981</xref>). V2 has different CO stripes (thick, pale, thin), in which neurons exhibit different functional properties and project to different downstream areas (<xref ref-type="bibr" rid="bib40">Shipp and Zeki, 1985</xref>; <xref ref-type="bibr" rid="bib9">DeYoe and Van Essen, 1985</xref>; <xref ref-type="bibr" rid="bib30">Munk et al., 1995</xref>). V2 performs higher-level analysis on visual information in multiple dimensions, for example, shape, color, binocular disparity, and motion. Much of the analysis contributes to figure-ground segregation (e.g., <xref ref-type="bibr" rid="bib47">von der Heydt et al., 1984</xref>; <xref ref-type="bibr" rid="bib53">Zhou et al., 2000</xref>).</p><p>In the classical view, visual motion information is processed in the dorsal visual pathway. However, mounting evidences have shown that many other brain areas participate in visual motion processing (<xref ref-type="bibr" rid="bib32">Orban et al., 2003</xref>). In macaque monkeys, there are a large number of direction-selective (DS) neurons in V2. Nevertheless, their functional contributions to visual perception remain unclear. These DS neurons cluster and form functional maps in V2 (<xref ref-type="bibr" rid="bib25">Lu et al., 2010</xref>; <xref ref-type="bibr" rid="bib1">An et al., 2012</xref>). Cooling studies have found that these neurons do not contribute to the motion detection in the dorsal pathway (<xref ref-type="bibr" rid="bib35">Ponce et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Ponce et al., 2011</xref>). Compared with middle temporal (MT) neurons, V2 DS neurons have smaller receptive fields (RFs), stronger surround modulation, and higher sensitivity to motion contrast (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). Thus, these neurons are suitable for figure-ground segregation and/or MB detection (<xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). These findings suggest that V2 may calculate the MB orientation using a local DS-to-MB circuit. Testing this hypothesis will also help us to understand the motion processing in V2 and other extra-dorsal areas.</p><p>In this study, we trained two monkeys to perform an orientation-discrimination task. From electrode arrays implanted over areas V1 and V2, we recorded neural activity and examined (1) their selectivity to the orientation of MB, (2) their correlation with monkeys’ behavioral choice, and (3) neuronal couplings between DS neurons and MB neurons. We found that many neurons in V2 exhibited a robust orientation selectivity to MBs. The responses of V2 neurons to MBs also had a clear relationship with the animals’ behavioral choice. As a comparison, these features were much weaker or absent in area V1. Finally, cross-correlogram and timing analysis also showed a potential functional link between DS and MB neurons.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Two macaque monkeys (monkey S and monkey W) were trained to do orientation-discrimination tasks. In each of their four hemispheres, a surgery was performed, during which intrinsic signal optical imaging was performed and a 32-channel array was implanted. The array was placed to cover as much V2 direction-preferred domains as possible (<xref ref-type="fig" rid="fig1">Figure 1A–D</xref>). The depths of the electrode tips were ~600 μm. For each array, recordings were performed daily and lasted for 1.5–2 months. In 128 channels of the four arrays, 96 channels were located in area V2 and 32 were in V1. Recordings were performed on multiple days. We used three alternative methods in cell selection (with different levels of strictness) and constructed three cell datasets: (1) ‘all cell’ dataset (n = 723). For daily recordings, a spike sorting was first performed for each channel, and signal-to-noise ratios were calculated for the resulting clusters (see Materials and methods). The best signal-to-noise ratio cluster for a channel was selected if its signal-to-noise ratio was larger than 3.5. With this method, we obtained 723 units from 85 V2 channels. (2) ‘Unique-unit’ dataset (n = 287). Based on the ‘all cell’ dataset, we excluded potential duplicated units (i.e., had similar waveforms and tunings) recorded from the same electrodes on different days so that the remaining units were ‘unique’ ones. This means that the neurons in this dataset were either from different electrodes or from the same electrode but had different waveform or tunings. (3) ‘One-cell-per-channel’ dataset (n = 85). In this dataset, only one neuron was chosen for each channel based on the ‘all cell’ dataset. Detailed cell identification procedures can be found in Materials and methods.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Map-guided array recording and V2 motion boundary (MB) neurons.</title><p>(<bold>A</bold>) Illustration of an imaging chamber location and a 32-channel (4 × 8) array in an example case. Lu: lunate sulcus. (<bold>B</bold>) An ocular dominance map showing patterns in V1. The location of a 32-channel array is illustrated. (<bold>C</bold>) An orientation map for the same cortex region shown in (<bold>B</bold>). (<bold>D</bold>) A motion-direction map for the same cortex region shown in (<bold>B</bold>). (<bold>E</bold>) The responses of an example V2 neuron to sine-wave gratings presented in 12 drifting directions in 30° steps (six orientations). Short horizontal bars indicate stimulus presentation time (500 ms). (<bold>F</bold>) The responses of the same neuron to 12 MB1 stimuli (six orientations). In each MB1 stimulus, the moving axis of the random dots (RDs) was 45° clockwise from the midline. Each orientation was presented two times in which the RD-moving directions in the two sides were switched, plotted on opposite sides of the polar plot (also see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref>). This neuron exhibited a strong MB orientation tuning, which was similar to its tuning to gratings (<bold>E</bold>). (<bold>G</bold>) Similar to (<bold>F</bold>), the responses of the same neuron to another set of MB stimuli (MB2), in which motion axis of the RDs had a different angle with the MB (135° clockwise from the midline). Also see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref>. (<bold>H</bold>) For the 70 MB neurons, their preferred MB orientations were similar to their preferred grating orientations. (<bold>I</bold>) The distributions of the orientation selectivity index, measured with sine-wave gratings, for MB and non-MB neurons in V2. The MB neurons showed stronger orientation selectivity than the non-MB neurons (Wilcoxon test, p&lt;0.01). (<bold>J</bold>) The distributions of the receptive field sizes for the MB neurons and the non-MB neurons in V2 were similar.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Additional information on array recordings.</title><p>(<bold>A</bold>) An example of waveforms of isolated units in a 32-channel array recorded in 1 day. (<bold>B</bold>) Receptive fields of 13 neurons recorded in 1 day’s recording shown in (<bold>A</bold>). (<bold>C</bold>) Receptive field (RF) positions and sizes of all non-motion boundary (MB) neurons (gray crosses) in relative to the MB stimulus (dotted circle). (<bold>D</bold>) Similar to (<bold>C</bold>), but for all MB neurons. (<bold>E</bold>) The orientation tuning plots of the example neuron shown in <xref ref-type="fig" rid="fig1">Figure 1F, G</xref> with all the MB stimuli were plotted. (<bold>F</bold>) The censuses of recordings from V1 and V2. Numbers in each circle represent neurons that passed that test. The following three types of neurons were described in the results: ‘MB neurons’ are those in red circles (B + D + E). ‘Non-MB neurons’ are those labeled ‘A’. Note that we excluded DS neurons (C + F) from the ‘non-MB’ group since they respond strongly to the random dots in the MB stimuli. ‘DS neurons’ are those in blue circle ‘C + D + F’. Note that the four neurons in V2 group E were not orientation neurons (did not reach the criteria for orientation selectivity to grating stimuli). However, they exhibited MB orientation selectivity. Thus, these four neurons were considered MB neurons and included in the MB results.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Array locations in relative to the V2 compartments.</title><p>(<bold>A–D</bold>) Images of all four array implants in four hemispheres. (<bold>E–H</bold>) Corresponding to (<bold>A</bold>–<bold>D</bold>), ocular dominance maps imaged before the array implants. The white dashed lines represent V1/V2 borders according to the V1 ocular dominance patterns. (<bold>I–L</bold>) Corresponding to (<bold>E</bold>–<bold>H</bold>), color maps imaged before the array implants. The white dotted lines represent V1/V2 borders. Thin stripes were identified based on the color/luminance patches in V2 (black and white patched in V2). Thick (between two red dashed lines) and pale (between green and red dashed lines) stripes were identified between the thin stripes and according to their width ratio (thick:pale = 2:1.5, <xref ref-type="bibr" rid="bib41">Shipp and Zeki, 1989</xref>). (<bold>M</bold>) Numbers of different types of neurons recorded from each stripe type and percentages of the neurons in each stripe. Note that the tuning types were not mutually exclusive (e.g., a motion boundary neuron could also be an orientation neuron).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig1-figsupp2-v2.tif"/></fig></fig-group><p>In the above cell identification, the majority of the neurons were single units (SUs, see Materials and methods). The percentages of multiunits (MUs) were 29.3%, 12.5%, and 27% in ‘all cell’, ‘unique-unit’, and ‘one-cell-per-channel’ datasets, respectively. We also performed data analysis with only SUs in each dataset and found that the inclusion of MUs does not change the main conclusions (not shown).</p><p>We compared the results obtained from these three datasets and found that the main results were the same. In order to exhibit more details of the data, the results presented below are based on the ‘all cell’ dataset. The results from the other two datasets are presented in <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplements 2</xref> and <xref ref-type="fig" rid="fig5s3">3</xref> for comparison.</p><p>In daily recordings, we first performed basic RF tests when the monkey was doing a simple fixation, including cell RF mapping, orientation tests with sine-wave gratings, motion-direction tests with random dots (RDs), and MB orientation tests. The stimuli were 4° circular patches, covering the whole RF region of the array without being optimized for particular cells.</p><sec id="s2-1"><title>V2 neurons selective to MB orientation</title><p>As shown in <xref ref-type="fig" rid="fig1">Figure 1F</xref> and <xref ref-type="video" rid="video1">Video 1</xref>, MB stimuli were composed with moving RDs. In the circular stimulus, RDs moved in opposite directions in the two sides of the virtual midline. The dots were the same on the two sides except for their moving directions. Thus, the boundary was mostly induced by motion. Similar to previous work (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>; <xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>), two sets of MB stimuli were used in this study, in which the axes of the dot motion were either 45°-angle with the MB (MB1 stimuli) or 135°-angle with the MB (MB2 stimuli).</p><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-61317-video1.mp4"><label>Video 1.</label><caption><title>Motion boundary (MB) stimulus for fixation task.</title><p>The video shows the MB stimuli used to test neurons’ MB orientation tuning during the fixation tasks. A MB stimulus is shown in two orthogonal orientations, each having two conditions in which the moving direction of the dots on the two sides was switched.</p></caption></media><p>Neurons were considered MB orientation selective (MB neurons) if their response functions were well fitted (R<sup>2</sup> &gt;0.7), preferred orientations to the two MB stimulus sets were consistent (difference &lt;30°), and both orientation selectivity indices (OSIs) for MB stimuli were larger than 0.5. According to these criteria, 10.9% (70/642) of V2 neurons were MB neurons (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). This proportion is consistent with previous recordings in anesthetized monkey V2 (10.6%, 13/123, <xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>). Importantly, these MB neurons’ preferred MB orientations were very similar to their preferred orientations for grating stimuli (<xref ref-type="fig" rid="fig1">Figure 1H</xref>). Thus, these MB neurons exhibited cue invariance for their orientation selectivity. <xref ref-type="fig" rid="fig1">Figure 1I</xref> shows that, when tested with grating stimuli, MB neurons exhibited stronger orientation selectivity than those non-MB neurons (mean OSI: 0.85 ± 0.20 vs. 0.80 ± 0.17, p=0.0013, Wilcoxon test). Their RF sizes, however, do not differ with the non-MB neurons’ (2.38 ± 0.70° vs. 2.48 ± 0.87°, p=0.65, Wilcoxon test). Same for their response time delays (described in ‘Response time courses’).</p><p>These results were obtained in awake monkeys performing a fixation task and were very similar to those obtained in anesthetized monkey V2 (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>). Both studies showed that V2 has around 10% neurons that exhibit strong and robust orientation selectivity to both luminance and MBs, and their preferred orientation to these two stimuli is the same. These findings indicate that V2 has the capability to detect MBs and integrate this information with other boundary cues.</p></sec><sec id="s2-2"><title>Correlation between V2 activity and monkey behavior</title><p>To study whether V2 neurons contribute to MB perception, monkeys were trained to do an orientation-discrimination task. The task is illustrated in <xref ref-type="fig" rid="fig2">Figure 2A</xref>: after a sample MB stimulus was presented for 750 ms, two target dots were presented. The monkeys were required to indicate whether the MB line was tilted to the left or right of vertical by saccading to the left or right target. The difficulty of the task was adjusted by using different levels of motion coherence or dot brightness (in one chamber). After training, monkeys can perform well in MB orientation discrimination and achieved at least 95% correct rate for 100% coherence stimuli. <xref ref-type="fig" rid="fig2">Figure 2B</xref> shows the psychometric function (fitted with a Weibull function) for monkey S. The coherence thresholds, as determined at the 75% correct rate from the fitting function, were 36.7% for monkey S (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) and 67.2% for monkey W (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Animal performance and neural responses in the orientation-discrimination task.</title><p>(<bold>A</bold>) An illustration of the motion boundary (MB)-orientation-discrimination task. A fixation point appeared for 500 ms, then a MB stimulus appeared for 750 ms. The fixation point maintained for additional 200 ms before it was replaced by two saccade targets. During this period, the monkey was required to maintain fixation at the fixation point. The monkey needed to make an eye saccade choice within 1000 ms, according to the tilt of the MB line. For example, for MB stimulus tilted to the right of vertical (as shown in the top right), the monkey should saccade to the right target. (<bold>B</bold>) The psychometric function of monkey S in the MB-orientation-discrimination task. (<bold>C</bold>) The response peri-stimulus time histograms (PSTHs) of an example MB neuron to MB stimuli presented different levels of motion coherence (four out of seven were shown), and the red and black curves are for the preferred and null MB orientations, respectively. (<bold>D</bold>) The receiver operating characteristic (ROC) curves obtained from the response PSTHs in (<bold>C</bold>), and horizontal and vertical coordinates are false alarm rate and hit rates, respectively. (<bold>E</bold>) The neurometric function obtained from the ROC curves in (<bold>D</bold>). (<bold>F</bold>) The neurometric functions (gray) of the 15 MB neurons recorded with the coherence stimuli. The red dots represent the average of the 15 neurometric functions, and the black line is its fitted curve. The green dots represent the average psychometric function measured during the recordings of the 15 neurons, and the black dashed line is its fitted curve. (<bold>G</bold>) Comparison of the neuronal thresholds and behavioral thresholds. The inset plot shows the distribution of ratios of the neural and behavioral thresholds. (<bold>H</bold>) The distribution of the choice probability (CP) values for the 15 MB neurons tested with the coherence stimuli, in which 12 neurons had CPs significantly larger than 0.5 (filled bars). The mean CP value (0.59) is also larger than 0.5 (t-test, p&lt;0.001). The inset plot shows the distribution of CPs for all of the 32 neurons, including 15 tested with coherence stimuli (shown in the main panel) and 17 tested with brightness stimuli (also see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B–E</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Additional information for behavioral tests.</title><p>(<bold>A</bold>) Four psychometric functions measured during four array recordings using coherent stimuli. (<bold>B</bold>) The psychometric function measured in monkey S using brightness stimuli. (<bold>C</bold>) The 17 neurometric functions (gray) measured with brightness stimuli in monkey S. The red dots represent the average of the 17 neurometric functions, and the black line is its fitted curve. The green dots represent the average psychometric function measured during the recordings of the 17 neurons, and the black dashed line is its fitted curve. (<bold>D</bold>) Comparison of behavioral and neuronal thresholds for the 17 neurons recorded using brightness stimuli. The inset shows the ratio of neural-behavioral thresholds. (<bold>E</bold>) The distribution of choice probabilities (CPs) measured with brightness stimuli, three of which were significantly larger than 0.5 (bootstrap test, p&lt;0.05). (<bold>F</bold>) The relationship of neuron threshold with CP value for coherent stimuli and brightness stimuli, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig2-figsupp1-v2.tif"/></fig></fig-group><p>Based on the initial MB tests, we selected a MB cell for the following ‘MB-orientation-discrimination test’. The stimuli were similar to the one used in previous MB tests, and its position was centered at the MB neuron’s RF. Only two MB orientations were used either at the neuron's preferred orientation or orthogonal to that orientation. The stimuli were presented at different levels of difficulties (coherence or brightness). Recordings were made while the monkeys were performing an orientation-discrimination task. The responses of an example neuron are shown in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. While the coherence of the moving dots increased, the differences of responses to preferred and null MB orientations also increased. <xref ref-type="fig" rid="fig2">Figure 2D</xref> shows the receiver operating characteristic (ROC) curves for four out of seven tested coherence levels for this neuron. Each curve indicates the difference of responses to preferred and null orientations. <xref ref-type="fig" rid="fig2">Figure 2E</xref> shows the example neuron’s neurometric function, calculated based on the area sizes under the ROC curves. This curve is also well fitted by a Weibull function, and the threshold for this neuron is 40.1%. In our sampled neurons, this neuron was very sensitive to MB orientation. Its neurometric function and coherence threshold were both very similar to the monkey’s behavior measurements.</p><p>Fifteen MB neurons were tested with coherence-level stimuli (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). Their neurometric curves were generally shallower than the behavioral ones, and the neuronal thresholds were higher than the behavioral ones (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). The average ratio of neuronal and behavioral thresholds was 2.78 (<xref ref-type="fig" rid="fig2">Figure 2G</xref>, inset plot). These results indicate that most neurons had a poorer sensitivity to MB orientation compared with the animals’ behavioral performance. However, some most sensitive neurons had thresholds close to the behavioral ones. This indicates that at least some neurons had sufficient information to support the animals’ performance in the MB orientation-discrimination tasks.</p><p>We further calculated the choice probability (CP) for these MB neurons (<xref ref-type="fig" rid="fig2">Figure 2H</xref>), which reflect the biases of neurons when their responses were grouped according to the monkeys’ choices (<xref ref-type="bibr" rid="bib5">Britten et al., 1996</xref>). In these neurons, 12 had a CP significantly larger than the chance level of 0.5 (bootstrap test, p&lt;0.05). The average CP, 0.59, was also larger than 0.5 (t-test, p=1.4 × 10<sup>−5</sup>). This indicates that during the MB orientation-discrimination tasks MB neurons in V2 showed significant choice-related activity. In 17 neurons recorded in one array, we also tested neural-behavioral relevance with different levels of dot brightness. The overall CP was lower in neurons tested with dot brightness. This might be due to the relative easiness for the brightness task. Nevertheless, in both tasks, the average CPs were larger than 0.5 and portions of individual neurons had CPs values larger than 0.5 (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B–E</xref>). The CP distribution for the pooled neurons (n = 32, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>) is shown in <xref ref-type="fig" rid="fig2">Figure 2H</xref> inset, which also exhibit the same trend.</p><p>Thus, V2 not only contained neurons sensitive to MB orientation, the highest sensitive ones also exhibited orientation-discrimination performances that are close to the animal’s behavioral performances. Their random response fluctuations correlated with the fluctuation animals made in the MB orientation-discrimination tasks. All these results indicate that V2 MB neurons likely contribute to the MB discrimination task.</p></sec><sec id="s2-3"><title>Comparison of MB responses in V1 and V2</title><p>In our sampled V2 population, 63% of the neurons were not tuned for MB orientation (either one or two MB responses could not be well fitted by the fitting function, i.e., R<sup>2</sup> &lt;0.7), 26% either had a low OSI (&lt;0.5) or their two preferred MB orientations were different (&gt;30°), and the remaining 10.9% neurons were classified as MB neurons (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, top). In our array recordings, 32 channels in three arrays were located in area V1 and from which 93 V1 neurons were recorded (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Compared with V2, a higher percentage (82%) of V1 neurons were not tuned to MB orientation; 16% had a low OSI or their two preferred orientation differed; only 2% (two neurons) were classified as MB neurons (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, bottom). V1 and V2 were different in their cell distributions in the three groups (chi-squared test, χ²=14.2, p=8.25 × 10<sup>−4</sup>). In addition, the mean orientation index (OSI) for MB stimuli was larger for V2 neurons than for V1 neurons (calculated from the neurons whose responses could be well fitted, i.e., R²≥0.7). Thus, V2 exhibited significantly higher MB detection capability than V1 at the population level.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Comparison of V1 and V2 responses to motion boundary (MB) stimuli.</title><p>(<bold>A</bold>) Two pie charts show the percentages of neurons in the recorded V2 (above) and V1 (below) neurons. Light gray represents neurons whose responses could not be fitted (R²&lt;0.7) by the von Mises function (‘not fit’). Dark gray represents neurons that had their responses well fitted (R²≥0.7) but either had low orientation selectivity indices (&lt;0.5) or the two preferred MB orientations did not match (differed by &gt;30°). Red section represents MB neurons. On the right side of each pie chart, neurons’ orientation indices for MB1 and MB2 stimuli are plotted. The colors are consistent with those in the pie charts, and dashed lines are the diagonal lines. (<bold>B</bold>) The distributions of choice probabilities (CPs) for all measured V2 (top) and V1 (bottom) neurons (including MB and non-MB neurons). For non-MB neurons, the preferred choice was based on their preferred orientations for gratings. Filled bars represent neurons having CP significantly different from 0.5.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Comparison of receptive fields (RFs) of V1 and V2 neurons.</title><p>(<bold>A</bold>) The spatial relationship between the stimuli and RFs of non-motion boundary (MB) V2 neurons. Dots represent RF centers, and the gray bars represent the sizes of RFs in x (horizontal) and y (vertical) dimensions. The dashed circle represents the 4° stimulus patch. This panel is the same as <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>. (<bold>B</bold>) Similar to (<bold>A</bold>) but for V2 MB neurons. This panel is the same as <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>. (<bold>C</bold>) RF size distributions for MB and non-MB V2 neurons. This panel is the same as <xref ref-type="fig" rid="fig1">Figure 1J</xref>. The mean RF size for all V2 neurons was 2.47° ± 0.85°. (<bold>D</bold>) Distributions of distances between RF centers and the center of the stimuli for MB and non-MB V2 neurons. (<bold>E–H</bold>) Similar to (<bold>A</bold>–<bold>D</bold>) but for V1 neurons. The mean RF size for all V1 neurons was 2.5° ± 1.18°.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Choice probability (CP) distributions of motion boundary (MB) and non-MB neurons in V1 and V2.</title><p>(<bold>A</bold>) CP distribution for all 32 MB neurons in V2 (same as <xref ref-type="fig" rid="fig2">Figure 2H</xref> inset), in which 15 neurons had CPs significantly larger than 0.5 (filled bars). The arrow indicates the mean CP (0.56), which is larger than 0.5 (t-test, p&lt;0.001). (<bold>B</bold>) CP distribution for all 108 non-MB neurons in V2, in which 34 neurons had CPs significantly larger than 0.5 (filled bars). The arrow indicates the mean CP (0.53), which is larger than 0.5 (t-test, p&lt;0.001). (<bold>C</bold>) CP distribution for all two MB neurons in V1, in which one neuron had CP significantly larger than 0.5 (filled bar). (<bold>D</bold>) CP distribution for all 24 non-MB neurons in V1, in which five neurons had CPs significantly larger than 0.5 (filled bars). The arrow indicates the mean CP (0.51), which is not different from 0.5 (t-test, p=0.2098).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig3-figsupp2-v2.tif"/></fig></fig-group><p>In <xref ref-type="fig" rid="fig3">Figure 3A</xref>, we compared two OSIs for those well-fitted neurons, including both MB and non-MB neurons. V1 had an overall lower OSI value than that in V2 (V1: 0.36 ± 0.17; V2: 0.44 ± 0.19, p=0.033, Wilcoxon test). In both V1 and V2 neurons, their two OSIs were strongly correlated (V1: r = 0.70, p=0.0016; V2: r = 0.72, p=3.9 × 10<sup>−39</sup>). In addition, the OSI values of the MB and non-MB neurons were continuously distributed and did not form two clusters.</p><p>We further analyzed CPs for the whole V2 population and compared with those in V1. In this analysis, we also included both MB neurons and non-MB neurons. Most neurons recorded in an array had overlapped RFs (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). In offline analysis, we identified non-MB neurons that had their RFs and preferred/null orientations matched the MB stimuli tested on that day and calculated their CP values in a similar way as for the MB neurons (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). <xref ref-type="fig" rid="fig3">Figure 3B</xref> top panel shows the CP distribution for all V2 neurons suitable for CP analysis (n = 140), including 108 non-MB neurons and 32 MB neurons. V2 CPs had a unimodal distribution and shifted toward the right side. Its mean CP (0.53) was higher than 0.5 (t-test, p=1.9 × 10<sup>−12</sup>), but lower than the mean CP for MB neurons (0.56, <xref ref-type="fig" rid="fig2">Figure 2H</xref>). There were 49 V2 neurons that had a CP either larger or smaller than 0.5 (bootstrap test, p&lt;0.05), among which 15 were MB neurons (all had CPs larger than 0.5). For the neurons recorded in V1, 26 were suitable for CP analysis, including 2 MB neurons (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, bottom). The mean CP (0.51) was not different from 0.5 (t-test, p=0.11), and six neurons had a CP larger than 0.5 (bootstrap test, p&lt;0.05). In addition, non-MB V2 neurons (n = 108) had a mean CP (0.53) larger than 0.5 (t-test, p&lt;0.001), but not for non-MB V1 neurons (n = 24, CP = 0.51, p=0.21, t-test) (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B, D</xref>).</p><p>In summary, V2 not only had stronger orientation tuning to MB stimuli and more MB neurons than V1, their behavioral relevance was also stronger than the V1’s.</p></sec><sec id="s2-4"><title>Correlations between MB and DS neurons</title><p>In our array recordings, we also tested neurons’ direction selectivity with moving RDs. We identified 88 V2 DS neurons that had direction-selective index (DSI) larger than 0.5. In our hypothesis, V2 MB neurons receive their motion information from V2 DS neurons. In order to test this hypothesis, we examined the correlations between the MB and DS neurons for different types of visual stimuli.</p><p>The stimuli we used was a 4° square RD patch (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref> and <xref ref-type="video" rid="video2">Video 2</xref>) that was divided into two parts by a virtual line (MB). The RD in one part moved in the DS neuron’s preferred direction, and the RD in another part moved in its opposite direction (null direction). The square patch was rotated so that the MB matched the MB neuron’s preferred/null orientations. We tested seven MB locations. The monkey was performing an orientation-discrimination task. We found that when the MB stimuli was presented cross-correlograms (CCGs) show an elevated correlation at 0 time lag (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, data pooled for seven MB locations). Importantly, the correlation was much higher for the preferred MB orientation than the null one. Note that the moving directions of the RD were the same for these two conditions. We also analyzed DS–MB pairs (n = 5) in which DS neurons were not optimally stimulated. The CCGs for preferred MB and null MB do not differ (t-test, p=0.26). All CCGs we used were shuffle-corrected CCGs so that stimulus-related effects were removed.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Correlated activity between the direction-selective (DS) and motion boundary (MB) neurons in V2.</title><p>(<bold>A</bold>) Cross-correlograms (CCGs) for MB–DS pairs (left) and non-MB–DS pairs (right) in MB stimulus conditions. Red curves are for preferred orientations and black for null orientations. For non-MB neurons, MB stimuli were oriented along their preferred and null orientations for gratings. (<bold>B</bold>) Similar to (<bold>A</bold>), CCGs for real-line conditions. (<bold>C</bold>) Similar to (<bold>A</bold>) and (<bold>B</bold>), CCGs for temporal boundary conditions. (<bold>D</bold>) Accumulated CCGs for all stimulus conditions shown in (<bold>A</bold>–<bold>C</bold>). Only the MB–DS pairs in the MB conditions exhibited significantly higher correlation for the preferred orientation than the null one (t-test, p&lt;0.001). Error bar: SEM.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Additional information for the correlation tests.</title><p>(<bold>A</bold>) Illustrations of the three types of stimuli tested different boundary positions. (<bold>B</bold>) Similar to <xref ref-type="fig" rid="fig4">Figure 4D</xref>, with accumulative cross-correlograms (auCCGs) from different boundary positions plotted separately. Results from symmetrical positions were averaged. For temporal boundary stimuli, only one position was tested. (<bold>C</bold>) Top: average auCCG values for two stimulus conditions: random dot moving along the direction-selective (DS) neurons’ preferred direction (left bar) or, null direction (right bar), motion boundary (MB) was placed bordering the receptive field (RF) of the DS neurons. Although the average auCCG shows some difference, it is not statistically significant (paired t-test, p=0.39). Bottom, average auCCG values for two stimulus conditions: MB was placed bordering the RF of the DS neurons (left bar) or across the RF center (right bar). The ‘bordering’ condition had a higher but not significant value compared to the ‘center’ one (t-test, p=0.25).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig4-figsupp1-v2.tif"/></fig></fig-group><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-61317-video2.mp4"><label>Video 2.</label><caption><title>Motion boundary (MB)-position stimuli.</title><p>The video shows the MB-position stimuli used to test MB–DS correlation during the orientation-discrimination tasks. A MB was presented at different orientations and positions. DS: direction-selective.</p></caption></media><p>We tested a luminance-line control stimulus (real line) (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref> and <xref ref-type="video" rid="video3">Video 3</xref>), in which a white line replaced the MB, and in both sides the RD moved in two opposite directions (transparent motion). The correlation in CCG was reduced in these conditions and did not differ for the preferred and null orientations.</p><media id="video3" mime-subtype="mp4" mimetype="video" xlink:href="elife-61317-video3.mp4"><label>Video 3.</label><caption><title>Real-line position stimuli.</title><p>The video shows the real-line stimuli as control for the motion boundary-position stimuli.</p></caption></media><p>We further tested another version of control stimulus called temporal boundary (TB, <xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref> and <xref ref-type="video" rid="video4">Video 4</xref>). TB stimuli were similar to the MB except that RDs in the two sides of the TB moved in the same direction. The dots still disappeared and appeared at the virtual boundaries. In examined neurons, none exhibited tuning to the TB orientation. The animals also made random choices to these stimuli in the orientation-discrimination tasks. In CCG, the MB–DS pairs exhibited larger modulation amplitudes to the TB stimuli (note the scale difference), but did not peak at any particular positions (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). No differences were found for preferred and null orientations. The cortical distances of paired neurons in <xref ref-type="fig" rid="fig4">Figure 4A–C</xref> had a range of 0.93–1.1 mm.</p><media id="video4" mime-subtype="mp4" mimetype="video" xlink:href="elife-61317-video4.mp4"><label>Video 4.</label><caption><title>Temporal boundary (TB) stimuli.</title><p>The video shows the TB stimuli used as a control for the motion boundary-position stimuli.</p></caption></media><p>We did the same analysis on pairs of non-MB and DS neurons. To make fair comparisons, we randomly selected equal numbers of non-MB–DS pairs as the MB–DS pairs (<xref ref-type="fig" rid="fig4">Figure 4A–C</xref>, right panel). Among all three stimulus conditions (MB, real line, TB), only under the MB condition that the non-MB–DS pairs exhibited small peaks at time zero, but did not differ between two orientations. To quantify the CCGs, we calculated the area sizes under the CCG curves from −40 ms to 40 ms. As shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref>, only the MB–DS pairs under the MB condition showed significant differences between the preferred and null orientations (t-test, p=1.9 × 10<sup>−4</sup>).</p><p>In summary, results from response correlation analysis support the hypothesis that functional connections between V2 DS and MB neurons do exist. Such connections operate in specific stimulus conditions, but peak location (at time zero) is inconsistent with a simple DS to MB contribution model. These phenomena can also be due to bidirectional interactions between DS and MB neurons or their common inputs.</p></sec><sec id="s2-5"><title>Response time courses</title><p>To further investigate the mechanisms underlying V2 MB orientation selectivity, we measured the time courses of V2 MB neurons when they responded to the MB and real-line stimuli. Responses PSTHs (<xref ref-type="fig" rid="fig5">Figure 5A, B</xref>) were calculated from the data used in the correlation analysis above. In seven MB positions (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>), only the conditions that the MB was in the RF center (0°) were used in this analysis. With an analysis method similar to the one used in <xref ref-type="bibr" rid="bib8">Chen et al., 2017</xref>, we calculated a visual response latency (i.e., the time a neuron started to respond to the visual stimulus) and an orientation-selectivity latency (i.e., the time responses started to differ for preferred and null orientations). The orientation-selectivity latency for the MB stimuli (85 ms, <xref ref-type="fig" rid="fig5">Figure 5A</xref>) was 50 ms later than that for the real-line stimuli (35 ms, <xref ref-type="fig" rid="fig5">Figure 5B</xref>), while the visual response latencies for these two stimuli were similar (both were 37 ms, <xref ref-type="fig" rid="fig5">Figure 5A, B</xref>). This indicates that, compared with the luminance stimuli, additional time and circuits are required to calculate orientation from the MB stimuli. In addition, MB neurons had similar visual response latencies as those in non-MB neurons when they were responding to the MB stimuli (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A, B</xref>). This is different from the previous findings obtained in anesthetized monkeys (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>), where MB neurons responded slower to the MB stimuli than that of the non-MB neurons.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Response time courses of the motion boundary (MB) and direction-selective (DS) neurons.</title><p>(<bold>A</bold>) Average response PSTHs for the MB neurons to the MB stimuli presented at their preferred (red) and null orientations. The black asterisk indicates the time for visual response delay (37 ms), which was similar for these two stimulus conditions. This value was also similar to that in non-MB neurons for the same stimuli (39 ms, see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>). The red asterisk indicates the time point (85 ms) where responses to the preferred and null orientations started to show differences (i.e., MB orientation time). Error shading represents SEM, same for below. (<bold>B</bold>) Average response PSTHs for the MB neurons to the real-line stimuli. The two asterisks indicate the visual response delay (37 ms, black asterisk) and the orientation-selective response time (35 ms, red asterisk), respectively. Non-MB neurons’ responses to the real line were similar (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B</xref>). (<bold>C</bold>) Average response PSTHs for DS neurons in responding to three different stimuli: center only (red), center and surround with the same direction (black), and center and surround with opposite directions (blue). The center random dots were always moving at the DS cell’s preferred direction in these three conditions. The red asterisk indicates time when the ‘center surround same’ responses start to different from the ‘center-only’ responses. The blue asterisk indicates the time where the ‘center surround opposite’ responses started to different from the ‘center surround same’ responses. (<bold>D</bold>) A summary of time points shown in (<bold>A</bold>–<bold>C</bold>). The time MB neurons start to show MB orientation selectivity (85 ms) falls in the time range where surround effects emerge in the DS neurons.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Additional information for response delay.</title><p>(<bold>A</bold>) Comparison of response time courses of motion boundary (MB) neurons (left, same as in <xref ref-type="fig" rid="fig5">Figure 5A</xref>) and non-MB neurons (right) when they were responding to MB stimuli. (<bold>B</bold>) Comparison of response time courses of MB neurons (left, same as in <xref ref-type="fig" rid="fig5">Figure 5A</xref>) and non-MB neurons (right) when they were responding to real-line stimuli. (<bold>C</bold>) A summary table of delay times shown in (<bold>A</bold>) and (<bold>B</bold>). To compare with the delays measured with population method described in the main text, here we calculated the delays for each neuron and averaged. We found that delays calculated from the two methods were consistent. (<bold>D</bold>) A summary table of delay times for the direction-selective (DS) neurons, based on analysis of individual neurons. (<bold>E</bold>) The response time courses of DS neurons when they were responding to random dots stimuli. The red asterisk indicates the onset time of direction selectivity for DS neurons (49 ms). The black asterisk indicates the visual latency for DS neurons (39 ms, which is similar to that obtained by surround modulation stimuli, e.g., <xref ref-type="fig" rid="fig5">Figure 5D</xref>). (<bold>F</bold>) D' calculated for MB and non-MB neurons in MB stimulus conditions, plotted as a function of the MB positions. (<bold>G</bold>) D' calculated for MB and non-MB neurons in real-line stimulus conditions, plotted as a function of the MB positions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Results from ‘one-cell-per-channel’ dataset.</title><p>(<bold>A</bold>) Choice probability (CP) distribution for V2 motion boundary (MB) neurons (corresponding to inset plot in <xref ref-type="fig" rid="fig2">Figure 2H</xref>). (<bold>B</bold>) CP distribution for V2 MB and non-MB neurons (corresponding to <xref ref-type="fig" rid="fig3">Figure 3B</xref> top panel). (<bold>C</bold>) CP distribution for V1 MB and non-MB neurons (corresponding to <xref ref-type="fig" rid="fig3">Figure 3B</xref> bottom panel). (<bold>D</bold>) Cross-correlogram (CCG) for MB neurons responding to MB stimuli (corresponding to <xref ref-type="fig" rid="fig4">Figure 4A</xref> left panel). (<bold>E</bold>) Accumulative cross-correlogram (AuCCG) for MB neurons responding to six stimulus conditions (corresponding to <xref ref-type="fig" rid="fig4">Figure 4D</xref> left panel). (<bold>F</bold>) Response time courses of MB neurons to MB stimuli (corresponding to <xref ref-type="fig" rid="fig5">Figure 5A</xref>). (<bold>G</bold>) Response time courses of MB neurons to real-line stimuli (corresponding to <xref ref-type="fig" rid="fig5">Figure 5B</xref>). (<bold>H</bold>) Response time courses of direction-selective neurons (corresponding to <xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Main results analyzed based-on ‘unique-units’ dataset.</title><p>(<bold>A</bold>) Choice probability (CP) distribution for V2 motion boundary (MB) neurons (corresponding to inset plot in <xref ref-type="fig" rid="fig2">Figure 2H</xref>). (<bold>B</bold>) CP distribution for V2 MB and non-MB neurons (corresponding to <xref ref-type="fig" rid="fig3">Figure 3B</xref> top panel). (<bold>C</bold>) CP distribution for V1 MB and non-MB neurons (corresponding to <xref ref-type="fig" rid="fig3">Figure 3B</xref> bottom panel). (<bold>D</bold>) Cross-correlogram (CCG) for MB neurons responding to MB stimuli (corresponding to <xref ref-type="fig" rid="fig4">Figure 4A</xref> left panel). (<bold>E</bold>) Accumulative cross-correlogram (AuCCG) for MB neurons responding to six stimulus conditions (corresponding to <xref ref-type="fig" rid="fig4">Figure 4D</xref> left panel). (<bold>F</bold>) Response time courses of MB neurons to MB stimuli (corresponding to <xref ref-type="fig" rid="fig5">Figure 5A</xref>). (<bold>G</bold>) Response time courses of MB neurons to real-line stimuli (corresponding to <xref ref-type="fig" rid="fig5">Figure 5B</xref>). (<bold>H</bold>) Response time courses of direction-selective neurons (corresponding to <xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig5-figsupp3-v2.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>Two alternative direction-selective to motion boundary (DS-to-MB) models in which surround suppression of DS neurons plays different roles.</title><p>Both models show the spatial relationship between a MB (dashed line) and the receptive fields of DS and MB neurons (circles). The DS neurons have a center-surround organization, which prefers different motion directions (small arrows). Model 1: the MB runs across the edge between the center and surround of the DS receptive field. Similar to the center-surround mechanism in detection of various types of boundaries (e.g., luminance, color, disparity), here boundary detection relies on the center-surround mechanism of the DS neurons, which detect the motion contrast at the MB. Previous work has shown that, in such conditions, DS neurons are activated optimally (Figure 5 in <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). In addition, the precise location of the MB is detected at the same time. Model 2: MB detection is achieved by comparing the activation of two DS neurons based on their different preferred directions. Thus, surround suppression plays a less significant role in this model. Although this model is also applicable, it has been shown that DS neurons are suboptimally activated in such conditions (Figure 5 in <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>) and a precise MB location is unavailable. Thus, we mainly considered Model 1 in the present work.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-fig5-figsupp4-v2.tif"/></fig></fig-group><p>In order to see whether the response time of DS neurons falls into a reasonable range so that their contribution to MB neurons is valid, we analyzed the response time courses of V2 DS neurons (n = 9). Considering that V2 DS neurons have strong surround suppression (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>), we tested three types of RD stimuli to stimulate their RF centers and surrounds: (1) a center-only RD patch in which RDs moved in the neurons’ preferred directions; (2) a large RD patch covered both RF center and surround in which RDs moved in the neurons’ preferred directions; and (3) a center patch moved in the preferred directions and a surround patch (annulus) moved in the opposite (null) directions. Latencies were calculated with a population latency method (see Materials and methods). The visual response latency for DS neurons was 41 ms, similar for all three stimuli. The surround suppression time started at 51 ms, when responses to stimuli 1 and 2 started to differ. The surround modulation time started at 109 ms, when responses to stimuli 2 and 3 started to differ. These time points, together with those from MB neurons, are summarized in <xref ref-type="fig" rid="fig5">Figure 5D</xref>. Since we had only tested a limited number of DS neurons, and there are also large variations among DS neurons, these values may not be very precise. Nevertheless, what we can see is that the emergence of MB orientation selectivity (85 ms) roughly falls in the time range (51–109 ms) of surround effects operated in the DS neurons. This indicates that DS neurons have the potential to contribute to the MB orientation selectivity in MB neurons. In addition to the population latency method, we also calculated latencies for individual neurons, thus the variance can be evaluated (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1C, D</xref>). The temporal relationship between MB and DS responses calculated from these two methods was consistent.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We studied MB neurons in awake monkeys performing an orientation-discrimination task. There were 10.9% V2 neurons that exhibited robust, cue-invariant orientation selectivity to MB and luminance stimuli. V2 neurons also exhibited a correlation with animals’ MB orientation-discrimination behavior. Compared with V2, V1 had fewer MB neurons and a much weaker correlation with animals’ MB orientation-discrimination behavior. Evidence from temporal correlation between MB and DS neurons, as well as their response latencies, supports the model in which MB neurons receive input from DS neurons during MB orientation detection.</p><p>These results are largely consistent with previous findings on anesthetized monkeys (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>), which indicate that V2 is important for MB detection. With array recordings on awake behaving monkey, we provided novel evidence showing that (1) V2 MB neurons may contribute to MB perception and (2) V2 MB detection may use motion information within V2.</p><sec id="s3-1"><title>MB orientation selectivity in V2</title><p>A moving object contains much information that can aid object recognition, including figure-ground segregation (<xref ref-type="bibr" rid="bib20">Lamme, 1995</xref>) and contour recognition (<xref ref-type="bibr" rid="bib38">Regan, 1986</xref>). Compared with figure-ground segregation, contour recognition may require more precise location of the MB and more complicated boundary integration process. A major finding of this work is the correlation between V2 responses and behavioral MB perception. This finding supports the view that V2 is a key area in MB perception. It is also in line with findings in previous loss-of-function studies. For example, monkeys are unable to detect MB after a V2 lesion (<xref ref-type="bibr" rid="bib29">Merigan et al., 1993</xref>), and human patients with V2 lesions are unable to detect motion discontinuity (<xref ref-type="bibr" rid="bib46">Vaina et al., 2000</xref>).</p><p>In the distributions of OSI for MB stimuli (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), we found that MB neurons and non-MB neurons do not form two separate clusters, and neurons with different levels of MB orientation selectivity were all observed. Also, the mean CP for non-MB V2 neurons is higher than chance level 0.5 (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2B</xref>). Thus, the contribution V2 makes to MB perception is likely population-coding based and not limited to the strongest MB neurons. Through pooling, a stronger and more robust MB signal can be achieved in V2 at the population level or in the downstream boundary detection units. For example, a weighted summation model (<xref ref-type="bibr" rid="bib16">Jazayeri and Movshon, 2006</xref>) can be used in MB detection task. In this model, a likelihood function (i.e., a probability density function) is calculated based on the weighted-summing of all activated neurons (optimally and suboptimally). Based on the likelihood function, a series of behavioral tasks (e.g., detection, discrimination) can be achieved. Our previous work shows that V2 contained a strong orientation map for MBs (<xref ref-type="bibr" rid="bib8">Chen et al., 2017</xref>); that map may represent a summation of various levels of such contributions.</p><p>Compared with V1, V2 improves its MB detection in at least three aspects: the percentages of MB neurons, functional mapping signal obtained with optical imaging (<xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>), and correlations with MB perception. Nevertheless, such improvement is at population level. Although fewer, V1 does have MB neurons and neurons significantly correlated with animals’ MB perception. Such a V1–V2 difference was also observed in other second-order boundary responses (e.g., to illusory contours). A better understanding of neural mechanisms underlying MB detection can be achieved through correlation and time-course analysis on V1 neurons, which were not performed in this study due to limited cell numbers.</p><p>Our samples of V1/V2 neurons were limited to the regions close to the V1/V2 border. This might affect our results in several aspects. For example, although the ocular dominance maps show clear V1/V2 borders, the actual transition from V1 neurons to V2 neurons was unlikely that sharp, especially for neurons in superficial layers. There should be a narrow ‘transition zone’ in which V1 and V2 neurons were actually mixed or inseparable. Plus, there were always precision limits in our map-array alignments. Thus, it is possible that some of our V1 neurons were actually V2 neurons, or the other way around. The RF size of V1 neurons we measured was relatively large (2.5° ± 1.18°) and might be due to this factor. We analyzed a subset of V1 cells (n = 39) that were recorded from the electrodes further away from the V1/V2 border and found that their mean RF size was smaller (2.05°). The possible partial ‘mixture’ of V1 and V2 neurons in our samples would decrease the differences between the V1 and V2 population, which means the actual differences might be larger than what we observed. In addition, the relatively large stimulus size (0.8°) used in RF mapping, as well as the eye movements in awake recording, might also contribute to the relatively large V1 RF we measured. However, since the stimulus sizes were not adjusted based on the overestimated RFs, the RF centers were correctly measured (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), and the RFs were covered by a relatively large stimuli (4°), we think the larger V1 RF sizes we measured should not affect the main results we observed (<xref ref-type="fig" rid="fig3">Figure 3</xref>).</p><p>To isolate and study motion-induced boundary perception, we used a very specialized and unnatural stimulus, which contained only motion-direction contrast. Other motion-related aspects, for example, speed contrast, were not examined. Beside this, real object boundaries usually contain multiple cues (luminance, texture, color, disparity, motion, etc.). Previous studies (<xref ref-type="bibr" rid="bib34">Peterhans and Heydt, 1993</xref>; <xref ref-type="bibr" rid="bib21">Leventhal et al., 1998</xref>; <xref ref-type="bibr" rid="bib8">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib10">El-Shamayleh and Movshon, 2011</xref>; <xref ref-type="bibr" rid="bib48">von der Heydt et al., 2000</xref>) have found V2 neurons that respond selectively to these boundaries and their orientations. Portions of V2 neurons (<xref ref-type="bibr" rid="bib34">Peterhans and Heydt, 1993</xref>; <xref ref-type="bibr" rid="bib10">El-Shamayleh and Movshon, 2011</xref>; <xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>) also exhibit cue-invariant responses to these boundaries. Thus, our results join those previous findings to show that V2 is a key area for boundary detection and integration.</p><p>Considering CO histology is unavailable yet for these monkeys, we estimated stripe types based on optical imaging maps (ocular dominance, orientation, color, motion direction). To separate thick and pale stripes, we used a width ratio previously described (thick:pale = 2:1.5, <xref ref-type="bibr" rid="bib41">Shipp and Zeki, 1989</xref>). <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2I–L</xref> shows the locations of the four arrays overlaid on the corresponding color versus luminance maps. <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2M</xref> shows neuron numbers according to their stripe and tuning types. Although a statistical analysis was not available due to the overlapped tuning types, one can still draw some conclusions from the table. For example, DS neurons were more likely found in thick stripes, while MB neurons were more likely found in thick and pale stripes. These results were all consistent with previous findings (<xref ref-type="bibr" rid="bib14">Hubel and Livingstone, 1987</xref>; <xref ref-type="bibr" rid="bib22">Levitt et al., 1994</xref>; <xref ref-type="bibr" rid="bib42">Shipp and Zeki, 2002</xref>; <xref ref-type="bibr" rid="bib25">Lu et al., 2010</xref>; <xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>).</p></sec><sec id="s3-2"><title>MB coding mechanisms</title><p>Extracting boundary information from motion is important for object recognition (<xref ref-type="bibr" rid="bib38">Regan, 1986</xref>; <xref ref-type="bibr" rid="bib39">Regan, 1989</xref>), especially when other cues are unavailable or confusing (e.g., camouflage). In primates, MB orientation extraction does not occur in the dorsal pathway (<xref ref-type="bibr" rid="bib26">Marcar et al., 1995</xref>), where abundant motion information is available. Instead, this occurs in the ventral pathway and in which V2 plays a critical role. Two fundamental questions regarding the neural mechanisms underlying MB orientation detection are (1) the origin of motion signal for the MB calculation in the ventral areas. It can come from dorsal areas through dorsal–ventral connections or originate from within the ventral stream itself. (2) Whether the MB calculation occurs in V2? And if it does, how is it calculated? If it is not in V2, then where V2 obtains this ability?</p><p>Our hypothesis is that V2 is an important area calculating MB orientation, and it also uses its own motion signals for this process. The main supportive evidence is from previous work (<xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>) and the present study. These studies found that (1) V2 has abundant resources for the MB calculation, including a large number of DS neurons, which cluster and form functional domains. A biological system normally uses a simple solution instead of a complicated one if both achieve the same result. To calculate MB locally is apparently a simpler solution than to calculate it elsewhere and send it to V2. (2) The motion signal in V2 is especially suitable for MB calculation. V2 DS neurons have small RFs and a high motion contrast sensitivity (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). From their V1 inputs, V2 DS neurons retain and strengthen their center-surround modulation (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). Its functional ‘purpose’ is probably for MB detection. (3) The MB–DS functional correlation and time-course orders also support this hypothesis. Further evidence on correlation analysis, although did not reach statistical significance, also supports this hypothesis (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1C</xref>). (4) MB is a useful signal that presents everywhere in the dynamic visual world. V2 integrates boundary information from various types of cues (luminance, color, disparity, texture, etc.). An early processing and integration of these cues is beneficial and simplifies the downstream processes.</p><p>We further suggest that the center-surround mechanism of DS neurons plays a significant role in MB detection. Our previous work has shown that DS neurons were activated optimally when a MB line touched the edge of their RF center (Figure 5 in <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). In addition, the precise location of the MB line was also detected at the same time (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>, model 1). Theoretically, MB detection can also be achieved without relying on the center-surround mechanism of DS neurons. For example, by comparing the activation of DS neurons signaling the motion of the two moving objects (not the motion contrast) (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>, model 2). The onset time of direction selectivity for DS neuron (49 ms, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1E</xref>) was faster than the MB-selectivity time of MB neurons (85 ms), and thus was not against such models. However, we have shown that DS neurons are suboptimally activated in such conditions (Figure 5 in <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>) and a precise MB location is unavailable. Thus, a center-surround mechanism is more suitable for this task. In the primate visual system, such a center-surround mechanism appears to be used as a general strategy in detecting changes of first-order cues at edges (e.g., luminance, color, disparity, etc.).</p><p>This hypothesis does not mean to exclude the contribution of feedback (e.g., from V3 or V4). Feedback plays a role in many V2 processes, and very likely in MB process as well. A supportive evidence for feedback is that the both MB and non-MB cells had a longer stimulus onset latency for MB stimulus than for luminance stimulus (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>). However, the result was obtained from anesthetized monkeys. Our recordings from awake monkeys did not show such difference (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A, B</xref>). It is also possible that V2 and higher-level areas both do MB extraction but operate under different stimulus conditions. Higher-level areas may calculate MB for larger-scale stimuli or weaker motion contrast (thus requires larger spatial summation).</p><p>In an earlier study, it has been found that about 34% V2 neurons have orientation selectivity for coherently moving line of dots (<xref ref-type="bibr" rid="bib34">Peterhans and Heydt, 1993</xref>; <xref ref-type="bibr" rid="bib33">Peterhans et al., 2005</xref>). The neural mechanisms underlying these two types of orientation-from-motion selectivity, however, might be different. The MB detection we described is mainly based on the motion contrast between the figure and ground, while theirs relies on the coherent motion of the dots. The percentages of neurons were also different. Nevertheless, the neurons they described also performed orientation detection based on motion information. Both studies show the importance of motion information in boundary detection in V2.</p><p>In addition to basic orientation selectivity, V2 neurons respond to more complex contours (<xref ref-type="bibr" rid="bib18">Kobatake and Tanaka, 1994</xref>; <xref ref-type="bibr" rid="bib12">Hegdé and Van Essen, 2007</xref>; <xref ref-type="bibr" rid="bib15">Ito and Komatsu, 2004</xref>; <xref ref-type="bibr" rid="bib2">Anzai et al., 2007</xref>). A significant feature distinguishing V2 from V1 is its cue-invariant contour detection, for example, in illusory contours (<xref ref-type="bibr" rid="bib49">Von der Heydt and Peterhans, 1989</xref>), MB (<xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>; <xref ref-type="bibr" rid="bib51">Yin et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>), disparity-defined contours (<xref ref-type="bibr" rid="bib48">von der Heydt et al., 2000</xref>; <xref ref-type="bibr" rid="bib4">Bredfeldt and Cumming, 2006</xref>), and possibly texture-defined contours (<xref ref-type="bibr" rid="bib10">El-Shamayleh and Movshon, 2011</xref>). In addition, V2 shows border-ownership features (<xref ref-type="bibr" rid="bib53">Zhou et al., 2000</xref>). These findings suggest that figure-ground segregation is an emphasized visual process in area V2. The neural mechanisms underlying these processes remain unclear. Our work made an effort in examining the neural mechanisms underlying the MB detection in area V2.</p><p>For different types of contour cues, a common strategy can be used to extract contrast and then orientation. That is, a three-stage process (cue cell – contrast cell – boundary orientation cell). In this process, different cue cells involve in the first two stages, for example, DS neurons for motion contrast extraction (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>), or relative disparity neurons for disparity contrast (<xref ref-type="bibr" rid="bib45">Thomas et al., 2002</xref>). Different information may converge to common third-stage neurons for cue-invariant orientation detection, which not only enhances orientation sensitivity but also is more efficient.</p></sec><sec id="s3-3"><title>Functional contribution of V2 motion processing</title><p>Although there are abundant DS neurons in V2 (17.5%, <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>), the perceptual contributions of these DS neurons are still unknown. These DS neurons’ RF properties are quite different from those in MT (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). Neither do they project to MT (<xref ref-type="bibr" rid="bib35">Ponce et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Ponce et al., 2011</xref>). Their sensitivity to motion contrast makes them suitable for detection of motion parallax, and their small RFs provide precise locations of the motion contrast. To our knowledge, the MB–DS correlation we observed provides the first direct evidence showing what perceptual function V2 DS neurons may contribute to. Besides MB detection, the contributions of V2 DS neurons to other perceptual tasks, like biological motion, and 3D-structure-from-motion, remain to be explored.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type (species) <break/>or resource</th><th>Designation</th><th>Source or <break/>reference</th><th>Identifiers</th><th>Additional <break/>information</th></tr></thead><tbody><tr><td>Strain, strain background (macaque, male)</td><td><italic>Macaca mulatta</italic></td><td>Suzhou Xishan Zhongke animal Company, Ltd</td><td>NCBITaxon:9544</td><td><ext-link ext-link-type="uri" xlink:href="http://xsdw.bioon.com.cn/">http://xsdw.bioon.com.cn/</ext-link></td></tr><tr><td>Software, algorithm</td><td>MATLAB-R2018b</td><td>MathWorks</td><td>SCR_001622</td><td>R2018b</td></tr><tr><td>Software, algorithm</td><td>Codes and ‘all cell’ dataset</td><td>This paper</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.17632/fjy37kc8pd.3">http://dx.doi.org/10.17632/fjy37kc8pd.3</ext-link></td></tr><tr><td>Software, algorithm</td><td>Codes and unique-unit dataset</td><td>This paper</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.17632/fjy37kc8pd.3">http://dx.doi.org/10.17632/fjy37kc8pd.3</ext-link></td></tr><tr><td>Software, algorithm</td><td>Codes and ‘one-cell-per-channel’ dataset</td><td>This paper</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.17632/fjy37kc8pd.3">http://dx.doi.org/10.17632/fjy37kc8pd.3</ext-link></td></tr><tr><td>Other</td><td>32-channel-array</td><td>Blackrock Microsystems, LLC</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="https://www.blackrockmicro.com/">https://www.blackrockmicro.com/</ext-link></td></tr><tr><td>Other</td><td>64-channel Multichannel Neural Recording (AlphaLab SNR)</td><td>Alpha Omega</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="https://www.alphaomega-eng.com/">https://www.alphaomega-eng.com/</ext-link></td></tr><tr><td>Other</td><td>Imager 3001 (Optical Imaging)</td><td>Optical Imaging Ltd</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="https://optimaging.com/">https://optimaging.com/</ext-link></td></tr><tr><td>Other</td><td>Eyelink Desktop(eyelink 1000)</td><td>SR Research</td><td>N/A</td><td><ext-link ext-link-type="uri" xlink:href="https://www.srresearch.com/">https://www.srresearch.com/</ext-link></td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Experimental overview</title><p>Monkeys were trained to perform orientation-discrimination tasks after headpost implant. After the training, a surgery was performed, during which optical imaging was made and an array was implanted. After 1 week of recovery time, awake electrophysiological recordings were made daily and usually lasted 1.5–2 months.</p></sec><sec id="s4-2"><title>Visual stimuli for optical imaging</title><p>In order to identify area V2 and place the electrode arrays over the direction-preference domains, we performed optical imaging before the array implants. The visual stimuli used were the same as described previously (<xref ref-type="bibr" rid="bib25">Lu et al., 2010</xref>; <xref ref-type="bibr" rid="bib7">Chen et al., 2016</xref>). Briefly, we used square-wave gratings (SF: 1.5 c/deg, TF: 8 Hz) for mapping ocular dominance patterns in V1 (e.g., <xref ref-type="fig" rid="fig1">Figure 1B</xref>) and orientation maps in both V1 and V2 (e.g., <xref ref-type="fig" rid="fig1">Figure 1C</xref>). We used red–green isoluminant sine-wave gratings and black–white sine-wave gratings (SF: 0.15 c/deg, TF: 1 Hz, orientation: 45° and 135°) for mapping color/luminance patches in both V1 and V2 (e.g., <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2I–L</xref>). We used moving RDs (density: 3%, dot size: 0.1°, speed: 6°/s, monocularly presented) for mapping direction-preference maps in V2 (e.g., <xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><p>All visual stimuli were generated in ViSaGe (Cambridge Research System Ltd) with MATLAB scripts and were presented on a 21-inch CRT display (Dell P1130). The CRT display had a screen sized 80 × 60 cm, refreshed at 100 Hz, with maximum luminance (white) of 97.8 cd/m<sup>2</sup> and minimum (black) luminance of 0.03 cd/m<sup>2</sup>. The distance between the CRT screen and the animal eyes was 57 cm.</p></sec><sec id="s4-3"><title>Visual stimuli for electrophysiology</title><p>Similar to imaging stimuli, stimuli for electrophysiological recordings were also generated with ViSaGe using MATLAB scripts and presented on a 21-inch CRT display (SONY CPD-G520). The CRT screen was 80 × 60 cm, refreshed at 100 Hz, with maximum luminance (white) of 56.7 cd/m<sup>2</sup> and minimum (black) luminance of 0.04 cd/m<sup>2</sup>. The distance between the CRT screen and the animal eyes was 71 cm. The size of the stimulus was either a 4°-diameter circular, or a 4 × 4° square, except otherwise described. Stimulus presentation times were set for 500 ms (for the fixation tasks) or 750 ms (for the orientation-discrimination tasks).</p></sec><sec id="s4-4"><title>Moving gratings</title><p>Luminance sine-wave gratings were used to measure the orientation selectivity of neurons in the fixation tasks. The stimulus was a 4° circular patch, with SF of 2 c/deg and TF of 8 Hz (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). The grating patch had a mean luminance of 28.4 cd/m<sup>2</sup>, 100% contrast, and drifted at 12 different directions (in 30° steps). Background luminance was 28.4 cd/m<sup>2</sup>. Totally 12 conditions were tested.</p></sec><sec id="s4-5"><title>RF mapping</title><p>Two types of stimuli were used for RF mapping in fixation tasks. The stimulus was placed based on initial manual mapping. Depending on the array locations in V2, the centers of the stimuli were 0.3–0.8° from the vertical meridian horizontally and 2.3–3.1° below the fixation spot.</p><p>The first RF mapping stimulus was a 0.8° square-wave patch presented in a 4 × 4° square regions. Totally 25 possible locations in a 5 × 5 grid were tested (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>). The gratings had an SF of 2 c/deg and TF of 8 Hz, and a duty cycle of 0.5; background luminance was 28.4 cd/m<sup>2</sup>.</p><p>The second RF mapping stimulus was a white bar (56.7 cd/m<sup>2</sup>), presented either vertically (for X-axis mapping) or horizontally (for Y-axis mapping) at different positions. The bar was 4° long, 0.2° wide. After determining the approximate RF locations, 21 positions were tested along the X-axis (vertical bar) and the Y-axis (horizontal bar) randomly, centered at the RF center location (10 positions on each side). Each position was separated by 0.2°. Background luminance was 28.4 cd/m<sup>2</sup>. There were totally 42 conditions in this stimulus set.</p></sec><sec id="s4-6"><title>Random dots</title><p>Moving RDs were used to test the direction selectivity of neurons in the fixation tasks. RDs moved coherently in a 4° circular patch. Each dot was a pixel (0.04°), moved at 2°/s. Dot density was 5% (white dots cover 5% of the patch surface). The luminance of the dots and the background screen were white (56.7 cd/m<sup>2</sup>) and black (0.04 cd/m<sup>2</sup>), respectively. There were 12 moving directions (conditions) with a 30° interval.</p></sec><sec id="s4-7"><title>MB stimuli</title><p>The MB stimuli were used to test neurons’ MB orientation selectivity in the fixation tasks. The stimuli are also illustrated in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref> and <xref ref-type="video" rid="video1">Video 1</xref>. Similar to those used in previous studies (e.g., <xref ref-type="bibr" rid="bib27">Marcar et al., 2000</xref>), each MB stimulus was a 4° circular patch of RDs. The patch was divided into two halves by a virtual border in the middle. The dots in the two halves moved in opposite directions, along an axis either 45° angle (MB1) or 135° angle (MB2) to the midline. The other features of the dots on the two sides were the same, thus the MB in the middle only was visible when the dots were moving. Dots were 1 pixel in size (0.04°), moved at 2°/s, and had a density of 5%. The luminance of the dots and the background screen were the same with parameters of RDs. Six MB orientations, with an interval of 30°, were tested. For each MB orientation, there were four different conditions, including two dot-moving axes (MB1 and MB2) and two conditions in which dots on the two sides were switched. Thus, there were 24 conditions in this stimulus set.</p></sec><sec id="s4-8"><title>TB stimuli</title><p>The TB stimulus was used as a control for the MB stimulus in the fixation tasks. It was similar to the MB except that the dots on the two sides moved in the same direction. The dots still disappear or appear at the virtual border and created a weak boundary perception. Thus, the difference between TB and MB was that TB lacked motion contrast. Same as the MB stimuli, the TB stimuli had 24 conditions.</p></sec><sec id="s4-9"><title>MB orientation-discrimination stimuli</title><p>This stimulus set was used in orientation-discrimination tasks (e.g., <xref ref-type="fig" rid="fig2">Figure 2</xref>). The stimuli were similar to the ‘MB stimuli’ used in fixation tasks (described above), except they used seven levels of dot motion coherence or dot brightness. Typical values for the seven coherence levels were 65%, 70%, 75%, 80%, 85%, 90%, and 100% (for monkey W); and 20%, 30%, 40%, 50%, 60%, 70%, and 80% (for monkey S). Typical values for the seven brightness levels were 1.17, 2.87, 5.70, 11.36, 17.03, 22.69, and 28.35 cd/m<sup>2</sup> (only tested on monkey S). There were 56 conditions in this stimulus set (seven difficulty levels, two orientations, two dot-moving axes [45° and 135°], two dot-moving directions [toward/away from the MB]). Each stimulus condition was repeated 20–30 times. The average correct rate for this stimulus set was 80%.</p></sec><sec id="s4-10"><title>MB-position stimuli</title><p>This stimulus set was used to evaluate the correlation between neuron pairs and their time courses (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5</xref>) and tested when monkeys were performing an orientation-discrimination task. An illustration of the stimulus is shown in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> and <xref ref-type="video" rid="video2">Video 2</xref>. The stimulus was a 4 × 4° square of RDs, centered at the RF center of a selected MB neuron. The square was rotated so that its MB was oriented either at the MB neuron’s preferred orientation or its null orientation. Seven MB locations were tested, which were −1.25°, −1°, −0.5°, 0°, 0.5°, 1°, and 1.25° away from the neuron’s RF center, respectively. The moving directions of the RDs on each side of the MB were set at the preferred and null directions of a chosen direction-selective neuron. Other parameters of the RDs were the same as those in the ‘MB stimuli’ in fixation tasks. This stimulus set had 28 conditions. Each stimulus condition was repeated 30–50 times.</p></sec><sec id="s4-11"><title>Real-line stimuli</title><p>Real-line stimuli were used as control stimuli for the ‘MB-position stimuli’. It has a white line at the original MB location. The white line was 4° long, 0.1° thick, and had the same luminance level as the RDs (56.7 cd/m<sup>2</sup>). The RDs in both sides of the line were doing transparent motion, in preferred and null directions. Other parameters were the same as the ‘MB-position stimuli’ described above. This stimulus set had 14 conditions. Each stimulus condition was repeated 30–50 times. One hemisphere from each monkey was tested with this type of stimuli.</p></sec><sec id="s4-12"><title>TB-position stimuli</title><p>This stimulus set was also a control stimulus for the ‘MB-position’ stimulus and had a similar form. The RDs in the square patch moved in the same direction (as in the ‘TB stimuli’), either at the neuron's preferred direction or null direction. Two TB orientations, either at the MB neuron’s preferred orientation or null orientation, were tested. This stimulus set had four conditions (only center conditions). Each stimulus condition was repeated 30–50 times.</p></sec><sec id="s4-13"><title>Surround modulation stimuli</title><p>This stimulus set was used to evaluate the surround modulation effects in DS neurons and was used in fixation tasks. Similar to those used in previous studies (<xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>), the RD patches were divided into center and surround patches. The center patch was a circular one with size matching﻿ the cell's RF and had RDs moving in the neuron’s preferred direction. The surround patch was an annulus surrounding the center patch with an outside diameter of 6°. RDs in the surround patch moved in one of eight directions covering the 360° (interval 45°) starting at the neuron’s preferred direction. This stimulus set had nine conditions, including eight conditions for different surround directions and a center-alone condition. Similar to previous stimuli, the dots were 1 pixel in size (0.04°), moved at 2°/s, and had a density of 5%.</p></sec><sec id="s4-14"><title>Behavioral tasks</title><sec id="s4-14-1"><title>Fixation task</title><p>Monkeys were trained to maintain fixation during stimulus presentation. Eye position was monitored with an infrared eye tracker (EyeLink 1000, SR Research). Each trial started with the appearance of a red fixation spot (0.2°) in the middle of the screen. There were two stimuli presented sequentially in each trial. After the monkeys maintained 500 ms fixation, the first visual stimulus appeared and lasted for 500 ms. The second visual stimulus appeared after a 250 ms interval and also lasted for 500 ms. The monkeys received a water reward (~0.1 ml) after having successfully maintained fixation during this whole period. The fixation window was typically 1.2 × 1.2°. The trial was aborted if the animal lost fixation at any time during the trial, and the affected stimulus data were discarded (the unaffected stimulus data were still used). The intertrial interval was 1 s (for correct trials) or 1.5 s (for failed trials). Each stimulus condition was usually repeated at least 10 times, except for the RF mapping stimuli, which were repeated minimum of five times.</p></sec></sec><sec id="s4-15"><title>MB orientation-discrimination task</title><p>This task was a two-alternative forced-choice discrimination based on the MB orientation (illustrated in <xref ref-type="fig" rid="fig2">Figure 2A</xref>). The following visual stimulus sets were used in this task: ‘MB orientation-discrimination stimuli’, ‘MB-position stimuli’, ‘real-line stimuli’, and ‘TB-position stimuli’. After a 500 ms fixation time, visual stimulus was presented for 750 ms (700–850 ms, see below). The fixation spot stayed for an additional 200 ms and was replaced with two saccade targets, which were 0.2° red spots 3.5° away from the center on both sides of the screen. The animals were required to make an eye saccade choice within 1000 ms: to saccade to the right target if the MB line was tilted to the right of vertical or to left if the MB line was tilted to the left of vertical. Monkeys received a water reward for correct choice. Interstimulus interval was 1 s for correct trials and 1.5 s for failed ones. For technical limitations, the actual stimulus presentation time had a variation from trial to trial (700–850 ms). The actual stimulus presentation times were recorded with a photo diode attached to the CRT screen and aligned in the offline data analysis.</p></sec><sec id="s4-16"><title>Surgery</title><p>All surgical procedures were performed under sterile conditions and general anesthesia. Similar to the surgery procedures described previously (<xref ref-type="bibr" rid="bib23">Li et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>), a 20–21 cm circular craniotomy was made above areas V1 and V2 (center location: 17–18 mm anterior to the posterior bone ridge and 18–20 mm lateral to the midline). The dura was retracted and the cortex was stabilized with 3–4% agar and covered with a 18–20 mm diameter cover glass. Intrinsic signal optical imaging was performed in order to determine V1/V2 border and V2 functional maps (described below).</p><p>The cover glass and agar were carefully removed when the imaging was completed. Array implant locations were selected based on the mapping results, usually centered at a V2 DS domain (<xref ref-type="fig" rid="fig1">Figure 1A–D</xref>). All arrays used were 32-channel (4 × 8) Utah arrays. Electrode lengths were 1 mm, with a spacing of 0.4 mm, and impedance of 500 kΩ. The electrode tips were inserted to ~0.6 mm below the surface. The craniotomy was covered with dental cements, and the animals were recovered.</p></sec><sec id="s4-17"><title>Optical imaging</title><p>In array implant experiments, intrinsic signal optical imaging was performed in order to identify the extent of the exposed V2 and obtain functional maps of V2 to determine array locations. Optical imaging procedures were similar to those described previously (<xref ref-type="bibr" rid="bib25">Lu et al., 2010</xref>; <xref ref-type="bibr" rid="bib23">Li et al., 2013</xref>). Briefly, cortex was illuminated with 632 nm red light, and cortical reflectance was collected using Imager 3001 (Optical Imaging) while visual stimuli were presented. The imaging had a frame rate of 4 Hz and frame size of 540 × 654 pixels, corresponding to cortical region of 18 × 20 mm.</p></sec><sec id="s4-18"><title>Array recording</title><p>Array recordings were made 1 week after the implant surgery. On daily average, half of the channels had usable signals. Such condition usually lasted for 1.5–2 months, then the signal quality started to decline. Some arrays still had signals 6 months after the surgery. Parameters for the array are described in the surgery section. We used four 32 channels (4 × 8) for four hemispheres. In the 128 channels, 32 were V1 channels, in which 24 had neurons identified. In 96 V2 channels, 85 had neurons identified.</p><p>The electrophysiological recording system we used was AlphaLab SnR (Alpha Omega) 64-channel system. Neural signals were sampled at 22 kHz and filtered with a 800–7500 Hz bandpass filter. Daily recordings include mapping the RF locations, basic stimuli in fixation tasks for basic properties in each channel, and cell-specific stimuli in orientation-discrimination tasks.</p><p>For daily recordings, channel signals were spike-sorted (<xref ref-type="bibr" rid="bib6">Chen et al., 2014</xref>) both online and offline. For spike sorting, we first extracted discriminative features from spike waveforms based on principal component analysis (PCA) analysis, and then clustered these features by an expectation-maximization algorithm based on mixtures of multivariate t-distributions (<xref ref-type="bibr" rid="bib43">Shoham et al., 2003</xref>). Signal-to-noise ratio was defined as the average signal size (peak-valley amplitude) of the action potential (signal) divided by the standard error of the residuals of the waveform (noise). The sorted response clusters were usually MU responses, but no longer separable based on their waveforms. Only clusters having a signal-to-noise ratio larger than 3.5 were considered, among which the highest signal-to-noise ratio cluster was considered the ‘neuron’ for that channel (other clusters were discarded). This neuron was either a SU (interspike intervals larger than 2.5 ms) or a MU. We obtained 723 neurons with this method and called it ‘all cell’ dataset. In this dataset, 70.7% (511/723) units were SUs and the rest (29.3%, 212/723) were MUs.</p><p>Similar to other array recording studies (i.e., <xref ref-type="bibr" rid="bib37">Ponce et al., 2017</xref>), neurons recorded from the same channel over different days usually had different waveforms and/or tuning properties, thus were different cells. In addition to the full dataset (n = 723), we also analyzed data based on two stricter cell selection methods. In ‘unique-unit’ method, neurons were selected based on the ‘all cell’ dataset. We excluded potential duplicated units (i.e., had similar waveforms and tunings) recorded from the same electrodes on different days so that the remaining units were ‘unique’ ones. This means that the neurons in this dataset were either from different electrodes or from the same electrode but had different waveforms or tunings. For each electrode, we did this comparison on SUs first. Only when SUs were not available did we turn to compare and select MUs as supplements. With this method, we identified 287 neurons, in which 87.5% (251/287) were SUs and 12.5% (36/287) were MUs. In the third method, which was the strictest one, we identified only one cell for each channel (instead of averaging all the cells in that channel) based on the ‘all cell’ dataset. For 85 channels, we obtained 85 neurons, in which 73% (62/85) were SUs and 27% (23/85) were MUs. We found that the main results obtained using these three datasets were consistent.</p></sec><sec id="s4-19"><title>Quantification and statistical analysis</title><sec id="s4-19-1"><title>Imaging data analysis</title><p>Functional maps (e.g., <xref ref-type="fig" rid="fig1">Figure 1B</xref>) were calculated based on t-tests (<xref ref-type="bibr" rid="bib23">Li et al., 2013</xref>). For pixels in a t-map, its t-values were based on the pixel’s response to two stimulus conditions (e.g., left eye vs. right eye). Polar maps (e.g., <xref ref-type="fig" rid="fig1">Figure 1C, D</xref>) were vector-summed single-condition t-maps (<xref ref-type="bibr" rid="bib23">Li et al., 2013</xref>). Briefly, first we calculated single-condition t-maps comparing each stimulus condition with gray-screen blank condition, then these t-maps from all of the conditions were vector-summed to obtain a polar map (<xref ref-type="bibr" rid="bib3">Bosking et al., 1997</xref>). For pixels in the polar maps, the color represented the preferred orientation or direction and the brightness represented the strength of the preference.</p></sec></sec><sec id="s4-20"><title>Determining V1 and V2 electrodes</title><p>A picture of the cortex was obtained after the array implant (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A–D</xref>) and aligned to the imaging blood vessel map based on the surface blood vessel patterns (MATLAB, projective transformation). Then the array locations were transformed to the ocular dominance map (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2E–H</xref>), on which V1/V2 borders were clearly identified. From these maps, whether an electrode was in V1 or V2 was visually determined. For the four arrays shown in <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2E–H</xref>, the numbers of V1 channels were 8, 22, 0, and 2, respectively.</p></sec><sec id="s4-21"><title>Electrophysiology data analysis</title><p>For all neurons isolated in the spike sorting procedure, we performed three tests: orientation tuning, direction tuning, and MB orientation tuning. A neuron was used for the subsequent analysis only if it passed at least one of these three tests. According to these criteria, we obtained 723 neurons, of which 677 passed orientation test, 78 passed direction test, and 70 passed MB orientation test. There were nine neurons showing strong direction bias (DSI &gt; 0.5) to grating stimuli but did not show direction bias in direction test with RDs. We excluded these neurons in the subsequent analysis as a precaution that they may behave abnormally in MB stimuli. In V1, we obtained 97 neurons, of which 93 passed the orientation test, 3 passed the direction test, and 2 passed the MB test. The neuron population is illustrated in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>.</p></sec><sec id="s4-22"><title>Orientation tuning and direction tuning</title><p>Unless otherwise specified, neuron’s responses to a particular stimulus were measured as its baseline-subtracted mean spike rate during the stimulus presentation period. The baseline activity was the mean spike rate during the 200 ms period immediately before the stimulus onset.</p><p>Orientation tuning was calculated based on neuron’s responses to sine-wave gratings. Direction tuning was calculated from neuron’s responses to moving RDs. Response functions were fitted with a modified von Mises function (<xref ref-type="bibr" rid="bib28">Mardia, 1972</xref>; <xref ref-type="bibr" rid="bib23">Li et al., 2013</xref>): <inline-formula><mml:math id="inf1"><mml:mi mathvariant="normal">y</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">b</mml:mi><mml:mn>1</mml:mn><mml:mi mathvariant="normal">*</mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mi>*</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">b</mml:mi><mml:mn>2</mml:mn><mml:mi mathvariant="normal">*</mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mi>*</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:msup></mml:math></inline-formula>, in which x represents the directions tested, y represents the corresponding firing rates and is a function of x, where a is the baseline offset, and (b1, b2), (c1, c2), (d1, d2) determine the amplitude, shape, and position of the tuning curve, respectively. The OSI and DSI were calculated as described previously (<xref ref-type="bibr" rid="bib23">Li et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Hu et al., 2018</xref>): OSI = 1 null-orientation response/preferred orientation response; DSI = 1 anti-preferred direction response/preferred direction response.</p><p>Criteria for orientation-selective and direction-selective neurons were that their OSI or DSI was larger than 0.5, respectively, and the goodness of fit should be larger than 0.7.</p></sec><sec id="s4-23"><title>RF analysis</title><p>For the RF data from the grid-like RF mapping, we fitted the responses with a 2-D Gaussian function and only those having a goodness of fit larger than 0.7 were further analyzed. The center of the fitting function was recorded as the center of the RF. The RF size was calculated as 2 × 1.96 × SE-0.8, in which SE was the standard error of the Gaussian and 0.8 was the size of the grating stimuli.</p><p>For the RF data measured with bars, one-dimensional Gaussian was used for horizontal and vertical mappings, respectively. The RF center was determined by the Gaussian centers in x and y dimensions, and the sizes on both dimensions were estimated the same way as described above.</p><p>For most neurons, the RF information was obtained from the ‘grid’ mapping data. The ‘bar’ mapping data was used only when the ‘grid’ data was not good enough to meet the fitting criteria.</p></sec><sec id="s4-24"><title>Orientation tuning to MB/TB</title><p>Orientation tuning to MB stimuli was calculated similar to the orientation tuning to luminance gratings (described above). Tunings to MB1 and MB2 were calculated separately. The criteria for a MB neuron were goodness of fit was larger than 0.7, both OSIs for MB stimuli were larger than 0.5, and the difference between the two preferred MB orientation was smaller than 30°. Four MB neurons did not show orientation selectivity to gratings (group E in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>). We also performed the same analysis for TB orientation; however, none of the recorded neurons exhibited orientation tuning to TB stimuli.</p></sec><sec id="s4-25"><title>Neurometric function</title><p>Psychometric functions (e.g., <xref ref-type="fig" rid="fig2">Figure 2B</xref>) were fitted with a Weibull function using the Psignifit toolbox (<xref ref-type="bibr" rid="bib50">Wichmann and Hill, 2001</xref>). The behavioral threshold was obtained from the fitting function, where the correct rate was 75%.</p><p>For neuronal data, spike rate was measured from 100 to 700 ms after the stimulus onset and the baseline was subtracted. For each level of stimulus strength, a ROC was calculated based on the response distributions for the two orthogonal orientations (e.g., <xref ref-type="fig" rid="fig2">Figure 2D</xref>). A neurometric function (e.g., <xref ref-type="fig" rid="fig2">Figure 2E</xref>), which describes the neuron’s orientation sensitivity, was calculated as the area under the ROC curves, plotted as a function of orientation signal. These neurometric functions were analyzed the same way as the psychometric functions described above.</p></sec><sec id="s4-26"><title>Choice probability</title><p>CP was used to evaluate the relationship between neural responses and behavioral choice (<xref ref-type="bibr" rid="bib5">Britten et al., 1996</xref>). CP was also calculated using ROC analysis. For each level of stimulus strength, all trials (preferred and null orientations pooled) were separated into two groups based on the monkey’s choice (preferred orientation target vs. null orientation target). In order to do this calculation, the monkey needed to make at least five choices for each target and each orientation. A ROC curve was then calculated from the two response distributions. The CP value for a neuron was the average of CPs from different levels of stimulus strengths (<xref ref-type="bibr" rid="bib24">Liu and Pack, 2017</xref>; <xref ref-type="bibr" rid="bib17">Kang and Maunsell, 2012</xref>). A CP was considered significant if it is located outside the 95% range in the distribution generated with bootstrap.</p></sec><sec id="s4-27"><title>PSTH and normalization</title><p>PSTHs (<xref ref-type="fig" rid="fig2">Figure 2C,</xref> <xref ref-type="fig" rid="fig5">Figure 5</xref>) were calculated based on the averaged spike rate in 1 ms bins, from which the baseline was subtracted. The baseline was defined as the mean spike rate during the 300 ms (200 ms for the DS surround modulation data) period before the stimulus onset. The PSTH was smoothed using a Gaussian (sd: 10 ms). PSTHs were normalized based on their peak values for comparison.</p></sec><sec id="s4-28"><title>d' analysis</title><p>d' was used to evaluate the response differences to two different stimuli. It was calculated as<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mrow><mml:mo>′</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">u</mml:mi><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">u</mml:mi><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msqrt/><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf2"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are mean responses to two stimuli, and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are the corresponding standard errors. A d' was considered significant if it was larger or smaller than the 95% population that was obtained in a bootstrap analysis.</p></sec><sec id="s4-29"><title>Response delay</title><p>Average PSTH was analyzed with a 10 ms sliding window and 2 ms step size. To estimate the visual response delay, we calculated d' by comparing the responses in each time window during 0–500 ms period with the pre-stimulus baseline (average of −300 to 0 ms for saccade tasks, −200 to 0 ms for fixation tasks). If three consecutive d's were larger than 0, then the mid-window time of the first window was recorded as the visual response delay (<xref ref-type="bibr" rid="bib8">Chen et al., 2017</xref>). We had also used t-test to replace the d' evaluation; the results were the same.</p><p>In calculating other response times (e.g., MB orientation selectivity, surround suppression, and surround modulation, see <xref ref-type="fig" rid="fig5">Figure 5</xref>), the calculation was the same as above. Instead of comparing responses with baseline, responses to two different stimuli were compared. The results are presented in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1C, D</xref>.</p></sec><sec id="s4-30"><title>Population response delay</title><p>Population response delays (<xref ref-type="fig" rid="fig5">Figure 5</xref>) were calculated using the method described in <xref ref-type="bibr" rid="bib8">Chen et al., 2017</xref>. (1) For each neuron, a 10 ms sliding window (step size 2 ms) was used to compare the spike rate in the window with the pre-stimulus baseline. A d' was calculated, and its significance with 0 was evaluated with a bootstrap method. (2) In the neuron population, we calculated the proportion of neurons having d's significantly larger than 0 at each time point. (3) We calculate a ‘baseline proportion’ and its standard error by averaging all the proportions in pre-stimulus time windows. (4) If there were three consecutive proportions in the post-stimulus window larger than ‘baseline proportion’ plus three standard error, then the mid-window time for the first window was recorded as the population response delay. Similarly, we calculated the time the two responses started to show difference.</p></sec><sec id="s4-31"><title>Cross-correlogram</title><p>CCG was used to evaluate the probability of coactivation of two neurons (<xref ref-type="fig" rid="fig4">Figure 4</xref>). For raw CCG, we used 1 ms window, and the function was the same as used by <xref ref-type="bibr" rid="bib19">Kohn and Smith, 2005</xref>, <xref ref-type="bibr" rid="bib44">Smith and Kohn, 2008</xref>, and <xref ref-type="bibr" rid="bib6">Chen et al., 2014</xref>:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:msubsup><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf4"><mml:mrow><mml:msub><mml:mtext>c</mml:mtext><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>c</mml:mtext><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> represent spike trains of two neurons, <inline-formula><mml:math id="inf5"><mml:mi>m</mml:mi></mml:math></inline-formula> represents the number of trials, <inline-formula><mml:math id="inf6"><mml:mrow><mml:mo> </mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> represents the window number of each trial, and <inline-formula><mml:math id="inf7"><mml:mi>τ</mml:mi></mml:math></inline-formula> represents the time delay.</p><p>In order to remove the effects due to coactivation of the stimulus timing and firing rates, we calculated the CCG of trial shuffled responses. The final CCG (shuffle-corrected CCG) was calculated by subtracting the average of 1000 shift predictors from the raw CCG. All the CCGs presented in the results were shuffle-corrected CCG.</p></sec><sec id="s4-32"><title>Accumulative cross-correlograms</title><p>To quantify and compare different CCGs (<xref ref-type="fig" rid="fig4">Figure 4D</xref>), accumulative CCG (auCCG) was calculated by integrating the CCG curve between −40 and 40 ms (i.e., calculating the area size under the CCG curve).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Natural Science Foundation of China (31625012, 31530029, 31371111) to HD Lu. We thank lab members J Lu, Y Xiao, SD Zhu, PC Li, C Han, M Chen, HR Xu, Y Fang, JY Wang, R Zhang, C Liang, Y Li, C Fang, K Yan, RD Tang, JT Xu, and WH Zhao for their valuable technical assistance and discussion.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Investigation</p></fn><fn fn-type="con" id="con3"><p>Software, Investigation</p></fn><fn fn-type="con" id="con4"><p>Investigation</p></fn><fn fn-type="con" id="con5"><p>Investigation</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Software, Supervision, Funding acquisition, Validation, Visualization, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: Four hemispheres from two adult male macaque monkeys (<italic>Macaca mulatta</italic>) were used in this study. All procedures were performed in accordance with the National Institutes of Health Guidelines and were approved by the Institutional Animal Care and Use Committee of the Beijing Normal University (protocol number: IACUC(BNU)-NKCNL2013-13).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Number of V2 electrodes (and neurons) from which motion boundary neurons were recorded.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-61317-supp1-v2.docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Number of V2 electrodes (and neurons) from which choice probability was calculated.</title><p>Note: The right hemisphere array in monkey W had a low electrode number since two thirds of its electrodes were located in V1.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-61317-supp2-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-61317-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data and codes are available in the Mendeley dataset: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17632/fjy37kc8pd.3">https://doi.org/10.17632/fjy37kc8pd.3</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Song</surname><given-names>Q</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Processing of motion-boundary orientation in macaque V2</data-title><source>Mendeley Data</source><pub-id assigning-authority="other" pub-id-type="doi">10.17632/fjy37kc8pd.3</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>An</surname> <given-names>X</given-names></name><name><surname>Gong</surname> <given-names>H</given-names></name><name><surname>Qian</surname> <given-names>L</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Pan</surname> <given-names>Y</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Yang</surname> <given-names>Y</given-names></name><name><surname>Wang</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distinct functional organizations for processing different motion signals in V1, V2, and V4 of macaque</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>13363</fpage><lpage>13379</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1900-12.2012</pub-id><pub-id pub-id-type="pmid">23015427</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anzai</surname> <given-names>A</given-names></name><name><surname>Peng</surname> <given-names>X</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neurons in monkey visual area V2 encode combinations of orientations</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1313</fpage><lpage>1321</lpage><pub-id pub-id-type="doi">10.1038/nn1975</pub-id><pub-id pub-id-type="pmid">17873872</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bosking</surname> <given-names>WH</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>Schofield</surname> <given-names>B</given-names></name><name><surname>Fitzpatrick</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>2112</fpage><lpage>2127</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.17-06-02112.1997</pub-id><pub-id pub-id-type="pmid">9045738</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bredfeldt</surname> <given-names>CE</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A simple account of cyclopean edge responses in macaque v2</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>7581</fpage><lpage>7596</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5308-05.2006</pub-id><pub-id pub-id-type="pmid">16855086</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname> <given-names>KH</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Celebrini</surname> <given-names>S</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A relationship between behavioral choice and the visual responses of neurons in macaque MT</article-title><source>Visual Neuroscience</source><volume>13</volume><fpage>87</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1017/S095252380000715X</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Yan</surname> <given-names>Y</given-names></name><name><surname>Gong</surname> <given-names>X</given-names></name><name><surname>Gilbert</surname> <given-names>CD</given-names></name><name><surname>Liang</surname> <given-names>H</given-names></name><name><surname>Li</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Incremental integration of global contours through interplay between visual cortical Areas</article-title><source>Neuron</source><volume>82</volume><fpage>682</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.03.023</pub-id><pub-id pub-id-type="pmid">24811385</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An orientation map for motion boundaries in macaque V2</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>279</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu235</pub-id><pub-id pub-id-type="pmid">25260703</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>R</given-names></name><name><surname>Wang</surname> <given-names>F</given-names></name><name><surname>Liang</surname> <given-names>H</given-names></name><name><surname>Li</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Synergistic processing of visual contours across cortical layers in V1 and V2</article-title><source>Neuron</source><volume>96</volume><fpage>1388</fpage><lpage>1402</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.004</pub-id><pub-id pub-id-type="pmid">29224721</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeYoe</surname> <given-names>EA</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Segregation of efferent connections and receptive field properties in visual area V2 of the macaque</article-title><source>Nature</source><volume>317</volume><fpage>58</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1038/317058a0</pub-id><pub-id pub-id-type="pmid">2412132</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El-Shamayleh</surname> <given-names>Y</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neuronal responses to texture-defined form in macaque visual area V2</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>8543</fpage><lpage>8555</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5974-10.2011</pub-id><pub-id pub-id-type="pmid">21653858</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname> <given-names>R</given-names></name><name><surname>Gross</surname> <given-names>CG</given-names></name><name><surname>Sandell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Visual topography of V2 in the macaque</article-title><source>The Journal of Comparative Neurology</source><volume>201</volume><fpage>519</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1002/cne.902010405</pub-id><pub-id pub-id-type="pmid">7287933</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hegdé</surname> <given-names>J</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A comparative study of shape representation in macaque visual Areas v2 and v4</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>1100</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl020</pub-id><pub-id pub-id-type="pmid">16785255</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Ma</surname> <given-names>H</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Fang</surname> <given-names>C</given-names></name><name><surname>Cai</surname> <given-names>X</given-names></name><name><surname>Yan</surname> <given-names>K</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Visual motion processing in macaque V2</article-title><source>Cell Reports</source><volume>25</volume><fpage>157</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.09.014</pub-id><pub-id pub-id-type="pmid">30282025</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Segregation of form, color, and Stereopsis in primate area 18</article-title><source>The Journal of Neuroscience</source><volume>7</volume><fpage>3378</fpage><lpage>3415</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-11-03378.1987</pub-id><pub-id pub-id-type="pmid">2824714</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Komatsu</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Representation of angles embedded within contour stimuli in area V2 of macaque monkeys</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>3313</fpage><lpage>3324</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4364-03.2004</pub-id><pub-id pub-id-type="pmid">15056711</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname> <given-names>M</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal representation of sensory information by neural populations</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>690</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1038/nn1691</pub-id><pub-id pub-id-type="pmid">16617339</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname> <given-names>I</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Potential confounds in estimating trial-to-trial correlations between neuronal response and behavior using choice probabilities</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>3403</fpage><lpage>3415</lpage><pub-id pub-id-type="doi">10.1152/jn.00471.2012</pub-id><pub-id pub-id-type="pmid">22993262</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobatake</surname> <given-names>E</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex</article-title><source>Journal of Neurophysiology</source><volume>71</volume><fpage>856</fpage><lpage>867</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.71.3.856</pub-id><pub-id pub-id-type="pmid">8201425</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname> <given-names>A</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Stimulus dependence of neuronal correlation in primary visual cortex of the macaque</article-title><source>Journal of Neuroscience</source><volume>25</volume><fpage>3661</fpage><lpage>3673</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5106-04.2005</pub-id><pub-id pub-id-type="pmid">15814797</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamme</surname> <given-names>VA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The neurophysiology of figure-ground segregation in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>1605</fpage><lpage>1615</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-02-01605.1995</pub-id><pub-id pub-id-type="pmid">7869121</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leventhal</surname> <given-names>AG</given-names></name><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Schmolesky</surname> <given-names>MT</given-names></name><name><surname>Zhou</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Neural correlates of boundary perception</article-title><source>Visual Neuroscience</source><volume>15</volume><fpage>1107</fpage><lpage>1118</lpage><pub-id pub-id-type="doi">10.1017/S0952523898156110</pub-id><pub-id pub-id-type="pmid">9839975</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname> <given-names>JB</given-names></name><name><surname>Kiper</surname> <given-names>DC</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Receptive fields and functional architecture of macaque V2</article-title><source>Journal of Neurophysiology</source><volume>71</volume><fpage>2517</fpage><lpage>2542</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.71.6.2517</pub-id><pub-id pub-id-type="pmid">7931532</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A motion direction preference map in monkey V4</article-title><source>Neuron</source><volume>78</volume><fpage>376</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.024</pub-id><pub-id pub-id-type="pmid">23622068</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>LD</given-names></name><name><surname>Pack</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The contribution of area MT to visual motion perception depends on training</article-title><source>Neuron</source><volume>95</volume><fpage>436</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.024</pub-id><pub-id pub-id-type="pmid">28689980</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname> <given-names>HD</given-names></name><name><surname>Chen</surname> <given-names>G</given-names></name><name><surname>Tanigawa</surname> <given-names>H</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A motion direction map in macaque V2</article-title><source>Neuron</source><volume>68</volume><fpage>1002</fpage><lpage>1013</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.11.020</pub-id><pub-id pub-id-type="pmid">21145011</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcar</surname> <given-names>VL</given-names></name><name><surname>Xiao</surname> <given-names>DK</given-names></name><name><surname>Raiguel</surname> <given-names>SE</given-names></name><name><surname>Maes</surname> <given-names>H</given-names></name><name><surname>Orban</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Processing of kinetically defined boundaries in the cortical motion area MT of the macaque monkey</article-title><source>Journal of Neurophysiology</source><volume>74</volume><fpage>1258</fpage><lpage>1270</lpage><pub-id pub-id-type="doi">10.1152/jn.1995.74.3.1258</pub-id><pub-id pub-id-type="pmid">7500149</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcar</surname> <given-names>VL</given-names></name><name><surname>Raiguel</surname> <given-names>SE</given-names></name><name><surname>Xiao</surname> <given-names>D</given-names></name><name><surname>Orban</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Processing of kinetically defined boundaries in Areas V1 and V2 of the macaque monkey</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>2786</fpage><lpage>2798</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.84.6.2786</pub-id><pub-id pub-id-type="pmid">11110809</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mardia</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="1972">1972</year><source>Statistics of Directional Data</source><publisher-loc>London</publisher-loc><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merigan</surname> <given-names>WH</given-names></name><name><surname>Nealey</surname> <given-names>TA</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Visual effects of lesions of cortical area V2 in macaques</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>3180</fpage><lpage>3191</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-07-03180.1993</pub-id><pub-id pub-id-type="pmid">8331392</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Munk</surname> <given-names>MH</given-names></name><name><surname>Nowak</surname> <given-names>LG</given-names></name><name><surname>Girard</surname> <given-names>P</given-names></name><name><surname>Chounlamountri</surname> <given-names>N</given-names></name><name><surname>Bullier</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Visual latencies in cytochrome oxidase bands of macaque area V2</article-title><source>PNAS</source><volume>92</volume><fpage>988</fpage><lpage>992</lpage><pub-id pub-id-type="doi">10.1073/pnas.92.4.988</pub-id><pub-id pub-id-type="pmid">7862679</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mysore</surname> <given-names>SG</given-names></name><name><surname>Vogels</surname> <given-names>R</given-names></name><name><surname>Raiguel</surname> <given-names>SE</given-names></name><name><surname>Orban</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Processing of kinetic boundaries in macaque V4</article-title><source>Journal of Neurophysiology</source><volume>95</volume><fpage>1864</fpage><lpage>1880</lpage><pub-id pub-id-type="doi">10.1152/jn.00627.2005</pub-id><pub-id pub-id-type="pmid">16267116</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orban</surname> <given-names>GA</given-names></name><name><surname>Fize</surname> <given-names>D</given-names></name><name><surname>Peuskens</surname> <given-names>H</given-names></name><name><surname>Denys</surname> <given-names>K</given-names></name><name><surname>Nelissen</surname> <given-names>K</given-names></name><name><surname>Sunaert</surname> <given-names>S</given-names></name><name><surname>Todd</surname> <given-names>J</given-names></name><name><surname>Vanduffel</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Similarities and differences in motion processing between the human and macaque brain: evidence from fMRI</article-title><source>Neuropsychologia</source><volume>41</volume><fpage>1757</fpage><lpage>1768</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(03)00177-5</pub-id><pub-id pub-id-type="pmid">14527539</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterhans</surname> <given-names>E</given-names></name><name><surname>Heider</surname> <given-names>B</given-names></name><name><surname>Baumann</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neurons in monkey visual cortex detect lines defined by coherent motion of dots</article-title><source>European Journal of Neuroscience</source><volume>21</volume><fpage>1091</fpage><lpage>1100</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2005.03919.x</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterhans</surname> <given-names>E</given-names></name><name><surname>Heydt</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Functional organization of area V2 in the alert macaque</article-title><source>European Journal of Neuroscience</source><volume>5</volume><fpage>509</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.1993.tb00517.x</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce</surname> <given-names>CR</given-names></name><name><surname>Lomber</surname> <given-names>SG</given-names></name><name><surname>Born</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Integrating motion and depth via parallel pathways</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>216</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nn2039</pub-id><pub-id pub-id-type="pmid">18193039</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce</surname> <given-names>CR</given-names></name><name><surname>Hunter</surname> <given-names>JN</given-names></name><name><surname>Pack</surname> <given-names>CC</given-names></name><name><surname>Lomber</surname> <given-names>SG</given-names></name><name><surname>Born</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Contributions of indirect pathways to visual response properties in macaque middle temporal area MT</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>3894</fpage><lpage>3903</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5362-10.2011</pub-id><pub-id pub-id-type="pmid">21389244</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce</surname> <given-names>CR</given-names></name><name><surname>Hartmann</surname> <given-names>TS</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>End-Stopping predicts curvature tuning along the ventral stream</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>648</fpage><lpage>659</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2507-16.2016</pub-id><pub-id pub-id-type="pmid">28100746</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Form from motion parallax and form from luminance contrast: vernier discrimination</article-title><source>Spatial Vision</source><volume>1</volume><fpage>305</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1163/156856886X00106</pub-id><pub-id pub-id-type="pmid">3153787</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regan</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Orientation discrimination for objects defined by relative motion and objects defined by luminance contrast</article-title><source>Vision Research</source><volume>29</volume><fpage>1389</fpage><lpage>1400</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(89)90194-6</pub-id><pub-id pub-id-type="pmid">2635467</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipp</surname> <given-names>S</given-names></name><name><surname>Zeki</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Segregation of pathways leading from area V2 to Areas V4 and V5 of macaque monkey visual cortex</article-title><source>Nature</source><volume>315</volume><fpage>322</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.1038/315322a0</pub-id><pub-id pub-id-type="pmid">2987702</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipp</surname> <given-names>S</given-names></name><name><surname>Zeki</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The organization of connections between Areas V5 and V2 in macaque monkey visual cortex</article-title><source>European Journal of Neuroscience</source><volume>1</volume><fpage>333</fpage><lpage>354</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.1989.tb00799.x</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shipp</surname> <given-names>S</given-names></name><name><surname>Zeki</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The functional organization of area V2, II: the impact of stripes on visual topography</article-title><source>Visual Neuroscience</source><volume>19</volume><fpage>211</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1017/S0952523802191176</pub-id><pub-id pub-id-type="pmid">12385631</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shoham</surname> <given-names>S</given-names></name><name><surname>Fellows</surname> <given-names>MR</given-names></name><name><surname>Normann</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Robust, automatic spike sorting using mixtures of multivariate t-distributions</article-title><source>Journal of Neuroscience Methods</source><volume>127</volume><fpage>111</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(03)00120-1</pub-id><pub-id pub-id-type="pmid">12906941</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>MA</given-names></name><name><surname>Kohn</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatial and temporal scales of neuronal correlation in primary visual cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>12591</fpage><lpage>12603</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2929-08.2008</pub-id><pub-id pub-id-type="pmid">19036953</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname> <given-names>OM</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name><name><surname>Parker</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A specialization for relative disparity in V2</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>472</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1038/nn837</pub-id><pub-id pub-id-type="pmid">11967544</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaina</surname> <given-names>LM</given-names></name><name><surname>Soloviev</surname> <given-names>S</given-names></name><name><surname>Bienfang</surname> <given-names>DC</given-names></name><name><surname>Cowey</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A lesion of cortical area V2 selectively impairs the perception of the direction of first-order visual motion</article-title><source>NeuroReport</source><volume>11</volume><fpage>1039</fpage><lpage>1044</lpage><pub-id pub-id-type="doi">10.1097/00001756-200004070-00028</pub-id><pub-id pub-id-type="pmid">10790879</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von der Heydt</surname> <given-names>R</given-names></name><name><surname>Peterhans</surname> <given-names>E</given-names></name><name><surname>Baumgartner</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Illusory contours and cortical neuron responses</article-title><source>Science</source><volume>224</volume><fpage>1260</fpage><lpage>1262</lpage><pub-id pub-id-type="doi">10.1126/science.6539501</pub-id><pub-id pub-id-type="pmid">6539501</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von der Heydt</surname> <given-names>R</given-names></name><name><surname>Zhou</surname> <given-names>H</given-names></name><name><surname>Friedman</surname> <given-names>HS</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Representation of stereoscopic edges in monkey visual cortex</article-title><source>Vision Research</source><volume>40</volume><fpage>1955</fpage><lpage>1967</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(00)00044-4</pub-id><pub-id pub-id-type="pmid">10828464</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Von der Heydt</surname> <given-names>R</given-names></name><name><surname>Peterhans</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Mechanisms of contour perception lines of pattern discontinuity</article-title><source>Journal of Neuroscience</source><volume>9</volume><fpage>1731</fpage><lpage>1748</lpage></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wichmann</surname> <given-names>FA</given-names></name><name><surname>Hill</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The psychometric function: I. fitting, sampling, and goodness of fit</article-title><source>Perception &amp; Psychophysics</source><volume>63</volume><fpage>1293</fpage><lpage>1313</lpage><pub-id pub-id-type="doi">10.3758/BF03194544</pub-id><pub-id pub-id-type="pmid">11800458</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname> <given-names>J</given-names></name><name><surname>Gong</surname> <given-names>H</given-names></name><name><surname>An</surname> <given-names>X</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Lu</surname> <given-names>Y</given-names></name><name><surname>Andolina</surname> <given-names>IM</given-names></name><name><surname>McLoughlin</surname> <given-names>N</given-names></name><name><surname>Wang</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Wei wang breaking cover: neural responses to slow and fast camouflage-breaking motion</article-title><source>Proceedings. Biological Sciences</source><volume>282</volume><elocation-id>20151182</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2015.1182</pub-id><pub-id pub-id-type="pmid">26269500</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeki</surname> <given-names>S</given-names></name><name><surname>Perry</surname> <given-names>RJ</given-names></name><name><surname>Bartels</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The processing of kinetic contours in the brain</article-title><source>Cerebral Cortex</source><volume>13</volume><fpage>189</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1093/cercor/13.2.189</pub-id><pub-id pub-id-type="pmid">12507950</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>H</given-names></name><name><surname>Friedman</surname> <given-names>HS</given-names></name><name><surname>von der Heydt</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Coding of border ownership in monkey visual cortex</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>6594</fpage><lpage>6611</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-17-06594.2000</pub-id><pub-id pub-id-type="pmid">10964965</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.61317.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Angelucci</surname><given-names>Alessandra</given-names> </name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>The study by Lu and colleagues is an in-depth investigation into the selectivity of V2 neurons in the primate for motion-boundaries (MB), the underlying functional circuitry and the potential perceptual contribution of these neurons. Previous studies in anesthetized monkeys demonstrated that V2 contains neurons selective for the orientation of MB, and the authors previously showed that these neurons form a map of MB orientation. In this study, they confirm these previous findings in awake animals and further demonstrate that the responses of MB neurons correlate with the animals' behavioral performance in a MB orientation-discrimination task. The activity of MB neurons also correlates with that of direction selective V2 neurons. These findings are important for our understanding of the functional circuitry underlying shape perception in primates.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Processing of motion-boundary orientation in macaque V2&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Timothy Behrens as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Alessandra Angelucci (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional revisions and data are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>The study &quot;Processing of motion-boundary orientation in macaque V2&quot; by Lu and colleagues is an in-depth investigation into the selectivity of V2 neurons in the primate for motion-boundaries (MB), the underlying functional circuitry and the potential perceptual contribution of these neurons. Previous studies in anesthetized monkeys demonstrated that V2 contains neurons selective for the orientation of MB, and the authors previously showed that these neurons form a map of MB orientation. In this study, the authors confirm these previous findings in awake animals and further demonstrate that the responses of MB neurons correlate with the animal's behavioral performance in a MB orientation-discrimination task. Moreover, the authors demonstrate that the responses of direction selective (DS) V2 neurons are correlated in time with those of MB neurons and that the visual response latencies of DS cells are consistent with a model in which MB neurons integrate motion signals from DS neurons in V2 itself to extract information about the orientation of the MB. The results are novel and important, the study appears overall well executed.</p><p>However the presentation of the manuscript needs improvement by addition of more experimental details, explanations of rationales for some of the analyses, and substantial proof reading to clarify the language. Despite a large numbers (n) of neurons from array recordings, interpretation is in parts difficult because of the low n for neurons showing MB selectivity. To understand the robustness of MB results better, more detail is required in the main manuscript about the distribution of results for MB neurons across array electrodes, across the two animals as well as the relationship of MB results to stimulus size and position with regards to the neuronal selectivity. Finally, the interpretation of the cross-correlation and latency studies is somewhat weak and needs additional analysis and justification.</p><p>Detailed comments are provided below.</p><p>Essential revisions:</p><p>1. To understand the robustness of the results obtained for MB selective neurons better, more detail is required in the main manuscript about the distribution of MB neuron results across array electrodes, across the two animals and about the relationship of stimulus size and position to the neuronal selectivity:</p><p>– Figure 1: to what extent would the results be influenced by surround inhibition? Show RF positions and sizes of recorded neurons on the same plot as the stimulus position and size used.</p><p>– p6, line 140: 10.9% (70/642) of V2 neurons were MB neurons. From how many individual electrode points did they come in each of the monkeys and hemispheres?</p><p>– p8, line 207-226 and Figure 2. CP and neurometric measurements</p><p>Given the low n, how many unique electrode points in each of the two monkeys do the data stem from?</p><p>– p9: V1/V2 comparison first paragraph (&quot;significantly higher percentage MD detection capability&quot;). Given the small sample size in V1, what is the statistics on differences in distribution – is this really significant given the small sample size ? Also, where &quot;could not be fitted&quot; or &quot;is well fitted&quot; is mentioned, please provide the specific fit, goodness-of-fit measure and statistical criterion in the text.</p><p>– p9: V1/V2 comparison. Figure 3. Please show graphically V1 RF positions and size in relation to stimulus position and size. Were the same stimulus parameters used for V1 as for V2. If yes, could surround suppression account for the poorer results in V1 (MB tuning distribution, lower OSI, lower CP)?</p><p>– p11. Figure 4: Could the coverage of the DS RF by the preferred motion direction component of the MB stimulus explain some of the interneuronal correlation? For example, between pref and null orientation, when the angle of the dividing line changes, the RF parts that are exposed to preferred and null motion change around the line. Please mention in the main manuscript the range of cortical distances over which pairs of neurons have been simultaneously recorded.</p><p>– p12, lines 320- 328: Were TBs resented at pref or null motion direction or both. Were monkeys rewarded for correct choices only as for MBs?</p><p>– p14, line 388: please give n of neurons for time course data. Also state for delay times whether this is the mean (across how many neurons?) and what the standard deviation is.</p><p>– The authors should discuss how these results might relate to the distribution across different types of stripes (thick, thin, interstripe) across their recording sites in V2.</p><p>2. The authors used optical imaging to position the recording arrays to MB-selective domains in V2. How was the exact position of the recording channels relative to the imaging maps of V1 and V2 recovered? Using imaging as the only guidance is relatively imprecise. Could additional criteria to discern between V1 and V2 cells, such as receptive field (RF) size and retinotopy be used?</p><p>The authors state that spike sorting was used to isolate single units (SUs) from multiunits (MUA). On p. 4, lines 91-95 they state: &quot;…we found that neurons recorded from the same channel over different days usually had different waveforms and/or tuning-properties, thus were different cells. We compared the results obtained either using the whole dataset (&quot;all-cells&quot;, n=723) or the &quot;one-cell-per-channel&quot; dataset (n=85). However, neither approach is accurate, as the first approach will count some of the same neurons twice, and the second approach averages across different, rather than the same, cells. The authors should spike sort the cells, then select SUs based on the spike waveform and tuning across days. That should be their n.</p><p>3. Figure 2F: Please describe in the figure legend what the black curve and red dots are. Is this the mean of all neuronal neurometric functions? Also please add the psycometric function on this plot for reference.</p><p>4. Lines 223-225: &quot;In 17 neurons recorded in one array, we also tested neural-behavioral relevance with different levels of dot brightness. The results were similar as those from coherence stimuli (Figure S2B-E)&quot;. In fact, the results are not so similar. It seems much fewer neurons had CPs that were significantly larger than chance. How do the authors interpret this result?</p><p>5. Lines 267-276. Wouldn't a better comparison be between the CP distribution of MB neurons vs non-MB neurons, instead of vs. all V2 neurons? The same apply to the comparison with V1, although We do realize that only 2 cells in their sample passed the test for MB neuron classification.</p><p>6. Lines 303-313: a good control here would be to look at the correlation with DS cells whose preference does not match the motion of the random dots generating the MB.</p><p>7. Analysis of time correlations. It is unclear to us why the authors interpret CCGs between the responses of DS and MB neurons peaking at zero, as supporting their model of MB responses resulting from integration of DS responses. Doesn't such a model predict that the responses of DS cells should rather precede those of MB cells?</p><p>8. Analysis of response time course. The authors find that the latency of MB selectivity falls within the range of latencies of surround suppression in DS neurons, and from this finding conclude that this suggests that V2 DS neurons contribute to the generation of MB responses in V2 MB neurons. The rationale for why surround suppression in DS neurons contributes to MB is unclear to us. MB responses occur within the RF of the V2 MB cells, so how does surround suppression play a role in their generation? Perhaps, we are failing to understand something here, but this needs to be better explained. Also, given the hypothesis here is that DS neurons contribute to MB responses, shouldn't the authors look at the onset latency of direction selectivity in DS neurons? Our rationale is that inputs regarding the direction of RDs need to be fed to the MB neurons in order to extract the MB orientation. The authors need to provide a better explanation of what model they have in mind for how DS cells contribute to the extraction of MB in MB neurons.</p><p>9. Lines 440-442. A simple model to support the statement that MB detection results from population coding would help here. At a minimum the authors should provide a sense of how this could be achieved. Also, why couldn't MB detection result from the activity of the fewer neurons that show neurometric functions and thresholds similar to the psychometric functions?</p><p>10. Was eye movements correction applied to the data analysis? how? Please specify.</p><p>11. Line 825: what algorithm/method was used for spike sorting? Please describe in the Methods.</p><p>12. Figure S1 legend line 988-989: the definition of MB neurons provided here does not match that provided in the results, according to which MB neurons were considered those that respond to MB AND are orientation selective. So group E in panel E does not fit this definition.</p><p>13. In the methods, the authors often refer to their previous publications for method and analysis details. However, at brief description should be provided in this manuscript. For example, on line 867: how were OSI and DSI defined?</p><p>14. Monkey task (page 6, line 162 and methods line 778): to me, the expression that the monkeys did discriminated between an acute or obtuse angle does not mean much in this contexts I am unclear which angle they refer to. If the authors meant, the monkeys discriminated whether the MB line was tilted e.g. left or right of vertical (or another axis), they need to say so more explicitly. The specific tasks the monkey had to carry out need a better description and figures to understand what stimuli configurations would lead to which choices.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Processing of motion-boundary orientation in macaque V2&quot; for further consideration by <italic>eLife</italic>. Your revised article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Timothy Behrens as the Senior Editor.</p><p>We found that you have thoroughly revised the manuscript and performed additional analyses according to the Reviewer's comments, which is appreciated. The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>1. We are somewhat concerned about the lack of significant difference in the receptive field (RF) size of V1 and V2 neurons. The reported 2.5 deg mean RF size for V1 cells is certainly inconsistent with what has been reported in the literature for parafoveal V1 neurons (more around 0.8-1 deg). This discrepancy to the published literature should be discussed in the paper – alongside the potential reasons for this, specifically:</p><p>a. The most likely cause for this is eye movements (in fact the fixation window is reported to be 1.2deg, which is rather coarse for V1). The question here is in what way this imprecision in the mapping of V1 RFs may have affected the results, e.g. the reported differences between V1 and V2 cells. You should at the very least add a discussion of this issue.</p><p>b. The illustrated placement of the arrays looks like that for 3 out of 4 arrays very few electrodes would be safely in V1, which could also explain the lack of a difference in RF size. You should specify in the methods of the paper how exactly they determined functionally whether each electrode was in V1 or V2.</p><p>c. The V1 RF measurements shown in the authors' response in comparison with V2 should also be included in the supplementary figure (could be added to the supplement to Figure 3).</p><p>2. Authors' Reply point 7). Here, you acknowledge that the zero lag in the CCG between DS and MB neuron responses is inconsistent with your hypothesis of DS inputs contributing to the MB responses. Yet, in the Results section of the paper you do not say so, rather you still maintain that the results are consistent with your hypothesis but concede that alternative/additional mechanisms may also be at play. If you indeed agree this result is inconsistent with your hypothesis, you should state so. Alternatively, you should clarify in the manuscript why you think this result may still be consistent with your hypothesis.</p><p>3. Authors' Reply point 9. The two alternative model schemes do a good job at clarifying why and you think that surround suppression may play a role in the generation of MB responses and how. We recommend to include this figure in the discussion of the paper.</p><p>4. Authors' Reply point 11. Please include in the manuscript your explanation provided here of why the 4 neurons in group E were included in the MB population analysis. This is ok, but this needs to be clear in the manuscript (methods and figure legend need to be consistent).</p><p>5. line 1041-1051: &quot;.… sorted response clusters were usually multi-unit responses,.…&quot; &quot;Neurons with inter-spike-intervals larger than 2.5 ms were identified as SUs.&quot; The paragraph reads as if most data presented in the paper were multi-unit, but were re-classified as SU based on spike timing only, which by itself is not enough. The main results (line 106) however state that SUs were identified on unique spike wave form and asserts that most cells are SU. We presume this means that the SUs were clearly separable from the remaining MU or noise.</p><p>There need to be clear, consistent statements in both Results and Methods, as the reader needs to know (i) whether they are dealing with SU or MU results and (ii) if both were combined whether specific results about basic MB tuning differ for clear SUs und MUs.</p><p>6. The reviewers would be grateful if you could please always point to the pages in the revised manuscript where the revisions were made. It really saves reviewers a lot of time.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.61317.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. To understand the robustness of the results obtained for MB selective neurons better, more detail is required in the main manuscript about the distribution of MB neuron results across array electrodes, across the two animals and about the relationship of stimulus size and position to the neuronal selectivity:</p><p>– Figure 1: to what extent would the results be influenced by surround inhibition? Show RF positions and sizes of recorded neurons on the same plot as the stimulus position and size used.</p></disp-quote><p>Figure 3—figure supplement 1 shows the spatial relationship between V2 RFs and the stimuli (A-D). The dotted circles represent the 4° stimulus patch. Since the stimuli were not adjusted for individual neurons, their size was chosen to slightly larger than the V2 RF (2.47±0.85°), Therefore, there should be some surround inhibition for these neurons. However, this effect should be similar for the MB and non-MB neurons, since the sizes of their RFs were similar (C, same as in Figure 1J), and their RF centers were located in similar distances to the stimulus center (D). In addition, the major stimuli we used were oppositely moving random dots, which were different from those homogenous stimuli that usually cause strong surround inhibition.</p><p>Similarly, V1 RFs are also plotted in Figure 3—figure supplement 1E-H, and related to the answers to another question below.</p><disp-quote content-type="editor-comment"><p>– p6, line 140: 10.9% (70/642) of V2 neurons were MB neurons. From how many individual electrode points did they come in each of the monkeys and hemispheres?</p></disp-quote><p>The 70 MB neurons were from 26 individual electrodes. In the revised manuscript, we added a table showing the detailed information (Supplementary File 1).</p><disp-quote content-type="editor-comment"><p>– p8, line 207-226 and Figure 2. CP and neurometric measurements</p><p>Given the low n, how many unique electrode points in each of the two monkeys do the data stem from?</p></disp-quote><p>In the revised manuscript, we included a table (Supplementary File 2) showing the number of unique electrodes from each hemisphere that neurons’ CPs were calculated.</p><disp-quote content-type="editor-comment"><p>– p9: V1/V2 comparison first paragraph (&quot;significantly higher percentage MD detection capability&quot;). Given the small sample size in V1, what is the statistics on differences in distribution – is this really significant given the small sample size ? Also, where &quot;could not be fitted&quot; or &quot;is well fitted&quot; is mentioned, please provide the specific fit, goodness-of-fit measure and statistical criterion in the text.</p></disp-quote><p>In the revised manuscript, we added statistics to support the above conclusions. <xref ref-type="table" rid="resptable1">Author response table 1</xref> shows the neuron numbers being compared (same as in Figure 3A). V1 and V2 were different in their cell distributions in the 3 groups (Chi-squared test, χ²=14.2，p=8.25×10<sup>-4</sup>). In addition, the mean orientation index (OSI) for MB stimuli was larger for V2 neurons than for V1 neurons (calculated from the neurons in the first two rows whose responses could be well fitted, i.e. R²≥0.7). We also added fitting criterion into the main text: The fitting criteria for MB was the same as for gratings, i.e. with von Mises function, R²&lt;0.7 was considered not fitted; R²≥0.7 was well fitted.</p><table-wrap id="resptable1" position="anchor"><label>Author response table 1.</label><table frame="hsides" rules="groups"><thead><tr><th/><th>V1</th><th>V2</th></tr></thead><tbody><tr><td>MB neurons</td><td>2</td><td>70</td></tr><tr><td>Well fitted (R²≥0.7), but OSI&lt;0.5 or two preferred MB orientation were different (&gt;30°);</td><td>15</td><td>169</td></tr><tr><td>Can not fit (R²&lt;0.7)</td><td>76</td><td>403</td></tr></tbody></table></table-wrap><disp-quote content-type="editor-comment"><p>– p9: V1/V2 comparison. Figure 3. Please show graphically V1 RF positions and size in relation to stimulus position and size. Were the same stimulus parameters used for V1 as for V2. If yes, could surround suppression account for the poorer results in V1 (MB tuning distribution, lower OSI, lower CP)?</p></disp-quote><p>The same stimuli were used for V1 and V2 neurons in our experiments. In the figure for question 1 above, we also plotted V1 RF positions and sizes. V1 and V2 neurons we recorded had similar RF sizes (V1: 2.50±1.18°; V2: 2.47±0.85°; p=0.77, Wilcoxon test). The distances between the RF centers and stimulus center were slightly larger for V1 neurons (V1: 0.47±0.41°; V2: 0.33±0.24°; p=2.97×10<sup>-4</sup>, Wilcoxon test), but the difference was relatively small (0.14°). We also compared the firing rate of V1 and V2 neurons in two arrays having sufficient numbers of V1 neurons, and observed no differences (Monkey S, right hemisphere: V2 13.95±8.60 spike/s; V1: 12.63±6.84 spike/s, p=0.45, t-test; Monkey W，right hemisphere: V2: 15.55±6.34 spike/s; V1: 15.36±13.60 spike/s, p=0.93, t-test). Thus, we believe that the surround inhibition caused by the common stimuli was similar for V1 and V2, and was not the cause for the poorer results in V1.</p><disp-quote content-type="editor-comment"><p>– p11. Figure 4: Could the coverage of the DS RF by the preferred motion direction component of the MB stimulus explain some of the interneuronal correlation? For example, between pref and null orientation, when the angle of the dividing line changes, the RF parts that are exposed to preferred and null motion change around the line. Please mention in the main manuscript the range of cortical distances over which pairs of neurons have been simultaneously recorded.</p></disp-quote><p>The reviewer is correct that a DS neuron might have different response levels to the two MB orientations (preferred and null) due to the change of preferred motion in its RF. However, since this factor was random for the two MB orientations, it would not cause a biased enhancement of the MB-DS correlation for a particular MB orientation. To confirm this, we identified and removed DS neurons (n=4) that had large RF coverage differences in preferred and null conditions and found that the auCCG was still significantly larger for the preferred condition (preMB: 0.10±0.016 vs. nullMB: 0.05±0.011, p=3.11X10<sup>-4</sup>, t-test). The cortical distances of paired neurons in Figure 4A-C had a range of 0.93~1.1 mm. We have added this information into the main text.</p><disp-quote content-type="editor-comment"><p>– p12, lines 320- 328: Were TBs resented at pref or null motion direction or both. Were monkeys rewarded for correct choices only as for MBs?</p></disp-quote><p>Yes, the TB stimuli were presented at both preferred and null directions. The monkeys were rewarded for correct choices. However, the correct rate for TB was around 50%.</p><disp-quote content-type="editor-comment"><p>– p14, line 388: please give n of neurons for time course data. Also state for delay times whether this is the mean (across how many neurons?) and what the standard deviation is.</p></disp-quote><p>We have added n=9 for the number of DS neurons. We calculated delay times with two methods, the one described in the main text was based on population time courses (no standard deviation), and another based on individual neurons’ time courses (Figure 5—figure supplement 1D). We’ve now described this in the main text.</p><disp-quote content-type="editor-comment"><p>– The authors should discuss how these results might relate to the distribution across different types of stripes (thick, thin, interstripe) across their recording sites in V2.</p></disp-quote><p>We have added discussion about the stripe types in the manuscript (line 531-542). Since CO histology is unavailable for these monkeys. The stripe types were estimated based on optical imaging maps (ocular dominance, orientation, color, motion direction). To separate thick and pale stripes, we use a width ratio previously described (thick : pale=2 : 1.5, Shipp and Zeki 1989). Figure 1—figure supplement 2 shows the locations of the 4 arrays overlaid on the corresponding color vs. luminance maps. The white dotted lines represent V1/V2 borders. The thin stripes were identified based on the color/luminance patches in V2 (black and white patched in V2). Thick (between two red dashed lines) and pale (between green and red dashed lines) stripes were identified between the thin stripes and according to their width ratio. For all V2 channels, the total numbers of channels located in thin, thick and pale stripes were: 15, 44, and 37, respectively. Figure 1—figure supplement 2M lists neuron numbers according to their stripe and tuning types. Note that the tuning types were not mutually exclusive (e.g. a MB neuron could also be an orientation neuron). The percentage values were calculated for each stripe types. Although a statistical analysis was not available due to the overlapped tuning types, one can still draw some conclusions from the table. For example, DS neurons were more likely found in thick stripes, while MB neurons were more likely found in thick and pale stripes. These results were consistent with previous findings (Hubel and Livingstone, 1987; Levitt et al., 1994; Shipp and Zeki, 2002; Lu et al. 2010; Chen et al. 2016).</p><disp-quote content-type="editor-comment"><p>2. The authors used optical imaging to position the recording arrays to MB-selective domains in V2. How was the exact position of the recording channels relative to the imaging maps of V1 and V2 recovered? Using imaging as the only guidance is relatively imprecise. Could additional criteria to discern between V1 and V2 cells, such as receptive field (RF) size and retinotopy be used?</p></disp-quote><p>We estimated the electrode locations by comparing the blood vessel pictures taken before and after the array implants. We agree with the reviewer that this method is relatively imprecise (the maximum offset we estimate is within 200 um). According to the reviewers’ suggestion, we compared the RF sizes and retinotopy for the V1 and V2 neurons. However, no significant trends were observed, and thus did not help in determining the V1/V2 borders. In one array we also tested the monocular/binocular driven properties of the neurons. Probably due to the superficial layers the electrodes located (layer 2/3), neither did we observe monocularly-driven neurons even in electrodes obviously located in V1. A post-mortem histology would help but is not available at this time.</p><disp-quote content-type="editor-comment"><p>The authors state that spike sorting was used to isolate single units (SUs) from multiunits (MUA). On p. 4, lines 91-95 they state: &quot;…we found that neurons recorded from the same channel over different days usually had different waveforms and/or tuning-properties, thus were different cells. We compared the results obtained either using the whole dataset (&quot;all-cells&quot;, n=723) or the &quot;one-cell-per-channel&quot; dataset (n=85). However, neither approach is accurate, as the first approach will count some of the same neurons twice, and the second approach averages across different, rather than the same, cells. The authors should spike sort the cells, then select SUs based on the spike waveform and tuning across days. That should be their n.</p></disp-quote><p>Following the reviewers’ suggestions, we used a “unique-unit method”. In unique-unit method, we first spike sorted the neurons according to their waveforms, then identified single-units (SUs) that had unique waveforms or tuning properties. If for a channel no SU was found from all the recording days, we used multi-units (MUs) from different cell types as supplements. We obtained 287 unique-units (251 SUs and 36 MUs) in V2 with this method. We repeated the data analysis on this cell set and obtained similar results (Figure 5—figure supplement 3) as those obtained with the cell sets described in the original manuscript. Thus, we have 3 cell identification methods: “all-cells n=723”, “unique-units, n=287”, and “one-cell-per-channel, n=85”, in order of the selection strictness. The main conclusions obtained from these 3 datasets were the same. We added this into the manuscript.</p><p>Additional notes: In “one-cell-per-channel” method, we identified only one cell for each channel (instead of averaging all the cells in that channel), and thus this method is the strictest one among the 3 methods.</p><disp-quote content-type="editor-comment"><p>3. Figure 2F: Please describe in the figure legend what the black curve and red dots are. Is this the mean of all neuronal neurometric functions? Also please add the psycometric function on this plot for reference.</p></disp-quote><p>In Figure 2 legend we have added appropriate descriptions. The red dots are mean values of the neurometric functions and the black curve is the fitting curve. In Figure 2F, we also added the psychometric function obtained by averaging the behavioral performance during the 15 neurons’ recordings (green dots). Similarly, average psychometric function was added into Figure 2—figure supplement 1C for neurons tested with brightness stimuli.</p><disp-quote content-type="editor-comment"><p>4. Lines 223-225: &quot;In 17 neurons recorded in one array, we also tested neural-behavioral relevance with different levels of dot brightness. The results were similar as those from coherence stimuli (Figure S2B-E)&quot;. In fact, the results are not so similar. It seems much fewer neurons had CPs that were significantly larger than chance. How do the authors interpret this result?</p></disp-quote><p>We agree that the overall CP was lower in neurons tested with dot brightness. This might be due to the relatively easiness for the brightness task. In 5-6 brightness levels, the monkey achieved more than 80% correct rate. In contrast, the same monkey achieved 80% correct rate in only 3-4 levels in the coherence tasks. An easier task requires less effort and may lead to lower CP values. Nevertheless, in both tasks, the average CPs were both larger than 0.5 and portions of neurons had CP values larger than 0.5. We revised the manuscript to reflect both the differences and similarity.</p><disp-quote content-type="editor-comment"><p>5. Lines 267-276. Wouldn't a better comparison be between the CP distribution of MB neurons vs non-MB neurons, instead of vs. all V2 neurons? The same apply to the comparison with V1, although We do realize that only 2 cells in their sample passed the test for MB neuron classification.</p></disp-quote><p>We added a figure (Figure 3—figure supplement 2) into the manuscript, in which CP distributions for MB and non-MB neurons are compared. In V2, although non-MB neurons had a lower mean CP (0.53) than the MB neurons’ (0.56), this value was still significantly larger than 0.5 (t-test, p&lt;0.001). There were 31.5% (34/108) non-MB neurons had a CP larger than 0.5 (bootstrap test, p&lt;0.05). In comparison, this proportion in MB neurons was 46.9% (15/32). In V1, non-MB neurons had a non-significant mean CP (0.51) and the portion of significant CP neurons was low (21%). These results were now added into the manuscript.</p><disp-quote content-type="editor-comment"><p>6. Lines 303-313: a good control here would be to look at the correlation with DS cells whose preference does not match the motion of the random dots generating the MB.</p></disp-quote><p>We took the reviewers’ suggestion and analyzed DS-MB pairs in which DS neurons were not optimally stimulated. The results are shown in <xref ref-type="fig" rid="respfig1">Author response image 1</xref>. It shows that the CCGs for preferred MB and null MB do not differ (5 pairs, t-test, p=0.26), which is consistent with our hypothesis. In the revised manuscript, we have included this results.</p><fig id="respfig1"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61317-resp-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>7. Analysis of time correlations. It is unclear to us why the authors interpret CCGs between the responses of DS and MB neurons peaking at zero, as supporting their model of MB responses resulting from integration of DS responses. Doesn't such a model predict that the responses of DS cells should rather precede those of MB cells?</p></disp-quote><p>Indeed, according to our model, the DS neurons made contribution to the MB neurons, and CCG should peak at the right side of zero. However, the peak we observed was centered at zero (Figure 3A). In addition, similar peaks were also observed in control conditions (e.g. real line in Figure 3B). These phenomena were not predicted by our model, and possibly due to other extra connections. For example, both DS and MB neurons might receive certain common inputs, or these neurons had bi-directional interactions (Bastos and Schoffelen 2016). Similar phenomena were also observed in previous pair-recording studies (e.g. orientation neurons in V1 and V2 in Roe and Ts’o 2015). We revised the interpretation in the manuscript accordingly.</p><disp-quote content-type="editor-comment"><p>8. Analysis of response time course. The authors find that the latency of MB selectivity falls within the range of latencies of surround suppression in DS neurons, and from this finding conclude that this suggests that V2 DS neurons contribute to the generation of MB responses in V2 MB neurons. The rationale for why surround suppression in DS neurons contributes to MB is unclear to us. MB responses occur within the RF of the V2 MB cells, so how does surround suppression play a role in their generation? Perhaps, we are failing to understand something here, but this needs to be better explained. Also, given the hypothesis here is that DS neurons contribute to MB responses, shouldn't the authors look at the onset latency of direction selectivity in DS neurons? Our rationale is that inputs regarding the direction of RDs need to be fed to the MB neurons in order to extract the MB orientation. The authors need to provide a better explanation of what model they have in mind for how DS cells contribute to the extraction of MB in MB neurons.</p></disp-quote><p>We took the reviewers’ suggestion and considered two DS-MB models, in which surround suppression plays different roles (see Figure 5—figure supplement 4).</p><p>In model 1, MB detection mainly relies on the center-surround mechanism of the DS neurons, which detect the motion contrast at the MB. Our previous work has shown that, in this condition DS neurons are activated optimally (Figure 5 in Hu et al. 2018). Also, the precise location of the MB is detected at the same time. In the primate visual system, such a center-surround mechanism appears to be used as a general strategy in detecting changes of first order cues at edges (e.g. luminance, color, disparity etc.).</p><p>In model 2, MB detection is achieved by comparing the activation of two DS neurons, and surround suppression plays a less significant role in this condition. We have shown that DS neurons are sub-optimally activated in such conditions (Figure 5 in Hu et al. 2018), and a precise MB location is unavailable.</p><p>Thus, we mainly considered Model 1 in our manuscript. The onset time of direction selectivity for DS neuron was 49 ms. It was faster than the MB-selectivity time of MB neurons (85 ms) and thus was not against Model 2. In the revised manuscript we added relevant discussions.</p><disp-quote content-type="editor-comment"><p>9. Lines 440-442. A simple model to support the statement that MB detection results from population coding would help here. At a minimum the authors should provide a sense of how this could be achieved. Also, why couldn't MB detection result from the activity of the fewer neurons that show neurometric functions and thresholds similar to the psychometric functions?</p></disp-quote><p>In our results, the MB orientation index is a continuous distribution (Figure 3A). Similarly, the CP distribution does not show a bimodal distribution (Figure 3B). These results indicate that MB information is likely coded in a distributed fashion in V2. Since single neuron’s response is intrinsically noisy, a detection mechanism only relies on a few high-performance neurons may not be the best solution. Population coding strategy overcomes this by using all available useful information. For example, a weighted summation model (Jazayeri and Movshon 2006) can be used in MB detection task. In this model, a likelihood function (i.e. a probability density function) is calculated based on the weighted-summing of all activated neurons (optimally and sub-optimally). Based on the likelihood function, a series of behavioral tasks (e.g. detection, discrimination) can be achieved. We have added this discussion into the manuscript.</p><disp-quote content-type="editor-comment"><p>10. Was eye movements correction applied to the data analysis? how? Please specify.</p></disp-quote><p>We continuously monitored the eye movements during the awake experiments. The fixation window was a 1.2° square. If the eye position moved outside this window for 20 ms, the task was aborted and the data was discarded. Therefore, all the data presented in the manuscript was collected for eye movement within ±0.6°. During the awake experiments, the measured eye position usually had some baseline drift over the time due to the system factors. We monitored the eye position and corrected the drift manually when necessary.</p><p>We calculated the mean eye movement for each monkey during the fixation period: Monkey S: 0.05° (horizontal) and 0.08° (vertical); Monkey W: 0.05° (horizontal) and 0.1° (vertical). These values were relatively small. We did not find a correlation between the eye movement size and the main results (behavioral performance, CP, and auCCG).</p><disp-quote content-type="editor-comment"><p>11. Line 825: what algorithm/method was used for spike sorting? Please describe in the Methods.</p></disp-quote><p>We added the spike sorting procedures into the Method.</p><disp-quote content-type="editor-comment"><p>12. Figure S1 legend line 988-989: the definition of MB neurons provided here does not match that provided in the results, according to which MB neurons were considered those that respond to MB AND are orientation selective. So group E in panel E does not fit this definition.</p></disp-quote><p>Our definition of MB neuron was: Their MB responses can be fitted by a von Mises function, and exhibit orientation selectivity to MB stimuli (i.e. OSI<sub>MB</sub> &gt;0.5). In Figure 1—figure supplement 1E, the 4 neurons in group E were not orientation neurons (did not reach the criteria for orientation selectivity to grating stimuli). However, they exhibited MB orientation selectivity. Thus, these 4 neurons were considered MB neurons and included in the MB results.</p><disp-quote content-type="editor-comment"><p>13. In the methods, the authors often refer to their previous publications for method and analysis details. However, at brief description should be provided in this manuscript. For example, on line 867: how were OSI and DSI defined?</p></disp-quote><p>We now added descriptions in methods and do not relies on previous publications.</p><p>OSI=1- null-orientation response /preferred orientation response;</p><p>DSI=1- anti-preferred direction response /preferred direction response;</p><disp-quote content-type="editor-comment"><p>14. Monkey task (page 6, line 162 and methods line778): to me, the expression that the monkeys did discriminated between an acute or obtuse angle does not mean much in this contexts I am unclear which angle they refer to. If the authors meant, the monkeys discriminated whether the MB line was tilted e.g. left or right of vertical (or another axis), they need to say so more explicitly. The specific tasks the monkey had to carry out need a better description and figures to understand what stimuli configurations would lead to which choices.</p></disp-quote><p>We revised the text and Figure to reflect the details of animal tasks.</p><p>References:</p><p>Anzai A, Peng X, Van Essen DC. Neurons in monkey visual area V2 encode combinations of orientations. Nat Neurosci. 2007;10:1313-1321.</p><p>Bastos, A. M., and Schoffelen, J.-M. (2016). A Tutorial Review of Functional Connectivity Analysis Methods and Their Interpretational Pitfalls. Frontiers in Systems Neuroscience, 9:175, 1–23.</p><p>Bredfeldt, C. E., and Cumming, B. G. (2006). A simple account of cyclopean edge responses in macaque V2. Journal of Neuroscience, 26(29), 7581–7596.</p><p>Britten, K. H., Shadlen, M. N., Newsome, W. T., and Movshon, J. a. (1992). The analysis of visual motion: a comparison of neuronal and psychophysical performance. The Journal of Neuroscience : The Official Journal of the Society for Neuroscience, 12(12), 4745–4765.</p><p>Chen, M., Li, P., Zhu, S., Han, C., Xu, H., Fang, Y., Hu, J., Roe, A.W., and Lu, H.D. (2016). An Orientation Map for Motion Boundaries in Macaque V2. Cereb. Cortex 26, 279–287.</p><p>DeYoe, E.A. and Van Essen, D.C. (1985). Segregation of efferent connections and receptive field properties in visual area 2 of the macaque. Nature 317, 58–61.</p><p>El-Shamayleh, Y., and Anthony Movshon, J. (2011). Neuronal responses to texture-defined form in macaque visual area V2. Journal of Neuroscience, 31(23), 8543–8555.</p><p>Gattass, R., Gross, C. G., and Sandell, J. H. (1981). Visual topography of V2 in the macaque. Journal of Comparative Neurology, 201(4), 519–539.</p><p>Hegdé, J., and Van Essen, D. C. (2007). A comparative study of shape representation in macaque visual areas V2 and V4. Cerebral Cortex, 17(5), 1100–1116.</p><p>Hu, J., Ma, H., Zhu, S.,, Li, P., Xu, H., Fang, Y., Chen, M., Han, C., Fang, C., Cai, X., Yan, K., Lu, H.D. (2018) Visual Motion Processing in Macaque V2. Cell Reports. 25, 157–167..</p><p>Hubel D. H., Livingstone M. S. (1987). Segregation of form, color and stereopsis in primate area 18. J. Neurosci. 7, 3378–3415</p><p>Ito, M., and Komatsu, H. (2004). Representation of Angles Embedded within Contour Stimuli in Area V2 of Macaque Monkeys. Journal of Neuroscience, 24(13), 3313–3324.</p><p>Jazayeri, M., and Movshon, J. A. (2006). Optimal representation of sensory information by neural populations. Nature Neuroscience, 9(5), 690–696.</p><p>Jiapeng Yin, Hongliang Gong, Xu An, Zheyuan Chen, Yiliang Lu, Ian M. Andolina, Niall McLoughlin, Wei Wang Breaking cover: neural responses to slow and fast camouflage-breaking motionProc Biol Sci. 2015 282: 20151182.</p><p>Kobatake, E., and Tanaka, K. (1994). Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex. Journal of Neurophysiology, 71, 856–867.</p><p>Levitt, J. B., Kiper, D. C., and Movshon, J. A. (1994). Receptive fields and functional architecture of macaque V2. Journal of Neurophysiology, 71(6), 2517–2542.</p><p>Lu, H.D., Chen, G., Tanigawa, H., and Roe, A.W. (2010). A motion direction map in macaque V2. Neuron 68, 1002–1013.</p><p>M H Munk, L G Nowak, P Girard, N Chounlamountri, J Bullier Visual latencies in cytochrome oxidase bands of macaque area V2. Proc Natl Acad Sci U S A. 1995 92: 988-992.</p><p>Marcar, V.L., Raiguel, S.E., Xiao, D., and Orban, G.A. (2000). Processing of kinetically defined boundaries in areas V1 and V2 of the macaque monkey. J. Neurophysiol. 84, 2786–2798.</p><p>Peterhans, E., Heider, B., and Baumann, R. (2005). Neurons in monkey visual cortex detect lines defined by coherent motion of dots. European Journal of Neuroscience, 21(4), 1091–1100.</p><p>Peterhans, E., and von der Heydt, R. (1993). Functional Organization of Area V2 in the Alert Macaque. European Journal of Neuroscience, 5(5), 509–524.</p><p>Roe, A. W., and Ts’o, D. Y. (2015). Specificity of V1-V2 orientation networks in the primate visual cortex. Cortex, 72, 168–178.</p><p>Shipp, S. and Zeki, S. (1985). Segregation of pathways leading from area V2 to areas V4 and V5 of macaque monkey visual cortex. Nature 315, 322–325.</p><p>Shipp S, Zeki S (1989) The organization of connections between areas V5 and V2 of macaque monkey visual cortex. Eur J Neurosci 1:333–354.</p><p>Shipp, S., and Zeki, S. (2002). The functional organization of area V2, II: The impact of stripes on visual topography. Visual Neuroscience, 19(2), 211–231.</p><p>Sincich LC, Horton JC. The circuitry of V1 and V2: integration of color, form, and motion. Annual Review of Neuroscience. 2005;28:303–326.</p><p>Thomas OM, Cumming BG, Parker AJ. A specialization for relative disparity in V2. Nat Neurosci 5: 472–478, 2002.</p><p>Von der Heydt, R., Peterhans, E., and Baumgartner, G. (1984). Illusory contours and cortical neuron responses. Science, 224(4654), 1260–1262.</p><p>Von der Heydt, R., and Peterhans, E. (1989). Mechanisms of Contour Perception Lines of Pattern Discontinuity. Journal of Neuroscience, 9(5), 1731-1748.</p><p>Von der Heydt R, Zhou H, Friedman HS (2000) Representation of stereoscopic edges in monkey visual cortex. Vision Res 40:1955–1967.</p><p>Zhou, H., Friedman, H. S., and von der Heydt, R. (2000). Coding of Border Ownership in Monkey Visual Cortex. The Journal of Neuroscience, 20(17), 6594–6611.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>We found that you have thoroughly revised the manuscript and performed additional analyses according to the Reviewer's comments, which is appreciated. The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>1. We are somewhat concerned about the lack of significant difference in the receptive field (RF) size of V1 and V2 neurons. The reported 2.5 deg mean RF size for V1 cells is certainly inconsistent with what has been reported in the literature for parafoveal V1 neurons (more around 0.8-1 deg). This discrepancy to the published literature should be discussed in the paper – alongside the potential reasons for this, specifically:</p><p>a. The most likely cause for this is eye movements (in fact the fixation window is reported to be 1.2deg, which is rather coarse for V1). The question here is in what way this imprecision in the mapping of V1 RFs may have affected the results, e.g. the reported differences between V1 and V2 cells. You should at the very least add a discussion of this issue.</p></disp-quote><p>We agree with the reviewers that the measured RF size for V1 (2.5 deg) was larger than those previously reported. Eye movements could be a cause, but it would equally increase the measurements of RF sizes for V2 neurons. In our recordings, the mean RF size for V2 neurons was 2.47 deg. Thus, we suspect that other factors (see below) might contribute more to the large V1 RF we measured. In the revised manuscript, whether the imprecision of V1 RF mapping affected the results was discussed (page 19 line 537-556).</p><disp-quote content-type="editor-comment"><p>b. The illustrated placement of the arrays looks like that for 3 out of 4 arrays very few electrodes would be safely in V1, which could also explain the lack of a difference in RF size. You should specify in the methods of the paper how exactly they determined functionally whether each electrode was in V1 or V2.</p></disp-quote><p>We added detailed description in Methods on how we determined that the electrodes were in V1 (page 34 line 1116-1123). We also added V1 ocular dominance maps into Figure 1—figure supplement 2 to show how the V1/V2 borders were determined.</p><p>Although these maps show clear V1/V2 borders, the actual transition from V1 neurons to V2 neurons was unlikely that sharp, especially for neurons in superficial layers. There should be a narrow “transition zone” in which V1 and V2 neurons were actually mixed or inseparable. Plus, there were always precision limits in our map-array alignments. Thus, it is possible that some of our V1 neurons were actually V2 neurons, or the other way around. We analyzed a subset of V1 cells (n=39) that were recorded from the electrodes further away from the V1/V2 border and found that their mean RF size was relatively smaller (2.05 deg).</p><p>The stimulus we used in measuring the RF size was a 0.8 deg grating patch, its size was also a little too large for V1 RF mapping. We added above information into discussion (page 19 line 537-556).</p><disp-quote content-type="editor-comment"><p>c. The V1 RF measurements shown in the authors' response in comparison with V2 should also be included in the supplementary figure (could be added to the supplement to Figure 3).</p></disp-quote><p>We have added the RF measurements into Figure 3—figure supplement 1.</p><disp-quote content-type="editor-comment"><p>2. Authors' Reply point 7). Here, you acknowledge that the zero lag in the CCG between DS and MB neuron responses is inconsistent with your hypothesis of DS inputs contributing to the MB responses. Yet, in the Results section of the paper you do not say so, rather you still maintain that the results are consistent with your hypothesis but concede that alternative/additional mechanisms may also be at play. If you indeed agree this result is inconsistent with your hypothesis, you should state so. Alternatively, you should clarify in the manuscript why you think this result may still be consistent with your hypothesis.</p></disp-quote><p>We revised the Results section to clearly indicate that the zero time lag is inconsistent with a simple DS-MB contribution model (page 15 line 407-410).</p><disp-quote content-type="editor-comment"><p>3. Authors' Reply point 8. The two alternative model schemes do a good job at clarifying why and you think that surround suppression may play a role in the generation of MB responses and how. We recommend to include this figure in the discussion of the paper.</p></disp-quote><p>We included this figure as Figure 5—figure supplement 4 and linked it to the relevant discussion (page 21 line 615-630).</p><disp-quote content-type="editor-comment"><p>4. Authors' Reply point 11. Please include in the manuscript your explanation provided here of why the 4 neurons in group E were included in the MB population analysis. This is ok, but this needs to be clear in the manuscript (methods and figure legend need to be consistent).</p></disp-quote><p>We have added the explanation into the Method section and the corresponding figure legend.</p><disp-quote content-type="editor-comment"><p>5. line 1041-1051: &quot;.… sorted response clusters were usually multi-unit responses,.…&quot; &quot;Neurons with inter-spike-intervals larger than 2.5 ms were identified as SUs.&quot; The paragraph reads as if most data presented in the paper were multi-unit, but were re-classified as SU based on spike timing only, which by itself is not enough. The main results (line 106) however state that SUs were identified on unique spike wave form and asserts that most cells are SU. We presume this means that the SUs were clearly separable from the remaining MU or noise.</p><p>There need to be clear, consistent statements in both Results and Methods, as the reader needs to know (i) whether they are dealing with SU or MU results and (ii) if both were combined whether specific results about basic MB tuning differ for clear SUs und MUs.</p></disp-quote><p>We thank the reviewer for pointing out these unclear statements. In the revised manuscript, we have clarified the definition of SU (page 33 line 1073-1079), how much percentages of SUs in the 3 datasets, and whether inclusion of MUs affects the results (page 5 line 100-119 and page 33-34 line 1087-1100).</p><disp-quote content-type="editor-comment"><p>6. The reviewers would be grateful if you could please always point to the pages in the revised manuscript where the revisions were made. It really saves reviewers a lot of time.</p></disp-quote><p>We are very sorry for the inconvenience we made, we did so in this response letter.</p></body></sub-article></article>